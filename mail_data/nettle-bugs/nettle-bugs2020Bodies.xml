<?xml version="1.0" encoding="utf-8"?>
<emails><email><emailId>20200102115543</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-02 11:55:43-0400</timestampReceived><subject>Re: [PATCH 0/8] Implement Curve448 ECDH and Ed448</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; Daiki Ueno &lt;ueno@gnu.org&gt; writes:
&gt;
&gt;&gt; For curve25519, q is defined as:
&gt;&gt;
&gt;&gt;   2^252 + 0x14def9dea2f79cd65812631a5cf5d3ed
&gt;&gt;
&gt;&gt; whose bit pattern starts with 0x1000, so r - q * (r&gt;&gt;252) should
&gt;&gt; work.
&gt;&gt;
&gt;&gt; On the other hand, for curve448, q is defined as:
&gt;&gt;
&gt;&gt;   2^446 - 0x8335dc163bb124b65129c96fde933d8d723a70aadc873d6d54a7bb0d
&gt;&gt;
&gt;&gt; whose bit pattern starts with 0xFFFF.  In that case the formula (r - q *
&gt;&gt; (r&gt;&gt;445)) could be incorrect due to the accumulated errors by
&gt;&gt; multiplication (i.e. q * 0x7FFF...).
&gt;
&gt; Good catch! Right, this needs a bit more analysis. Fur curve25519, the
&gt; subtraction can underflow (unlikely), which is addressed with the
&gt; conditional addition a few lines down.

For ecc_ah_to_a, this code was deleted, but it's still an issue for
eddsa_sign. Maybe need special cases for both ed25519 and ed448 for now.
Or some logic looking at the high limb of q.
 
These corner cases are a bit hard to test.

&gt; It might make sense to instead add a function pointer to struct
&gt; ecc_modulo to do canonical reduction; that's needed in a few different
&gt; places, not only here.

I still think think this makes sense, but it's not clear to me what the
usage really is.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200102165042</emailId><senderName>Daiki Ueno</senderName><senderEmail>ueno@gnu.org</senderEmail><timestampReceived>2020-01-02 16:50:42-0400</timestampReceived><subject>Re: [PATCH 0/8] Implement Curve448 ECDH and Ed448</subject><body>

Hello Niels,

Thank you very much for all the Curve448/SHAKE256 work for merging (I'm
slowly catching up).

nisse@lysator.liu.se (Niels Möller) writes:

&gt; nisse@lysator.liu.se (Niels Möller) writes:
&gt; 
&gt; &gt; Daiki Ueno &lt;ueno@gnu.org&gt; writes:
&gt; &gt; 
&gt; &gt; &gt; For curve25519, q is defined as:
&gt; &gt; &gt; 
&gt; &gt; &gt; 2^252 + 0x14def9dea2f79cd65812631a5cf5d3ed
&gt; &gt; &gt; 
&gt; &gt; &gt; whose bit pattern starts with 0x1000, so r - q * (r&gt;&gt;252) should
&gt; &gt; &gt; work.
&gt; &gt; &gt; 
&gt; &gt; &gt; On the other hand, for curve448, q is defined as:
&gt; &gt; &gt; 
&gt; &gt; &gt; 2^446 - 0x8335dc163bb124b65129c96fde933d8d723a70aadc873d6d54a7bb0d
&gt; &gt; &gt; 
&gt; &gt; &gt; whose bit pattern starts with 0xFFFF.  In that case the formula (r - q *
&gt; &gt; &gt; (r&gt;&gt;445)) could be incorrect due to the accumulated errors by
&gt; &gt; &gt; multiplication (i.e. q * 0x7FFF...).
&gt; &gt; 
&gt; &gt; Good catch! Right, this needs a bit more analysis. Fur curve25519, the
&gt; &gt; subtraction can underflow (unlikely), which is addressed with the
&gt; &gt; conditional addition a few lines down.
&gt; 
&gt; For ecc_ah_to_a, this code was deleted, but it's still an issue for
&gt; eddsa_sign. Maybe need special cases for both ed25519 and ed448 for now.
&gt; Or some logic looking at the high limb of q.
&gt; 
&gt; These corner cases are a bit hard to test.

For what it's worth, the original issue was reliably reproducible with
the GnuTLS port[1] against the OpenSSL client.  Here is a test vector
extracted from the interaction:

      test_one ("0cf87eb094bf46d161bde3b99d1d32856fecfae0142392cd98c091db206d174bbf8ef476a9cf746d94306c565f97ac50796f021eff8d779ca5"
  "9addde61f668f2dbc0ac24874adb47a2aa6ad59fa888bdc5d430705ed0796a8c330782b51860785be63fd79b1c7cf58fd728b2bf3d77395100:"
  "9addde61f668f2dbc0ac24874adb47a2aa6ad59fa888bdc5d430705ed0796a8c330782b51860785be63fd79b1c7cf58fd728b2bf3d77395100:"
  "20202020202020202020202020202020202020202020202020202020202020202020202020202020202 \
020202020202020202020202020202020202020202020544c5320312e332c2073657276657220436572746 \
96669636174655665726966790090da2c6178a3019274ed029ba5ad28f25662a78d71e8429c19f96007df39d7a77d7cb80f221c76db5e1c397714f48692:"
  "91554b9b85058d3d6885997adf47e1f766ae780018ca26873de854fb12d789f3bf1f85d3ce5b23265d8 \
d8900f62906e2eb4a064887beaf00009cea26f0edeff35be1e969df77ab1368ced966beb0c7b6242aa0d8844d773e254cfed823d3a5e53b3ef557e716ce7cc2aaca127e86798f2b00"
  "20202020202020202020202020202020202020202020202020202020202020202020202020202020202 \
020202020202020202020202020202020202020202020544c5320312e332c2073657276657220436572746 \
96669636174655665726966790090da2c6178a3019274ed029ba5ad28f25662a78d71e8429c19f96007df39d7a77d7cb80f221c76db5e1c397714f48692:");


&gt; &gt; It might make sense to instead add a function pointer to struct
&gt; &gt; ecc_modulo to do canonical reduction; that's needed in a few different
&gt; &gt; places, not only here.
&gt; 
&gt; I still think think this makes sense, but it's not clear to me what the
&gt; usage really is.

Regards,

Footnotes:
[1]  https://gitlab.com/gnutls/gnutls/merge_requests/984

-- 
Daiki Ueno
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200102190817</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-02 19:08:17-0400</timestampReceived><subject>Re: [PATCH 0/8] Implement Curve448 ECDH and Ed448</subject><body>

Daiki Ueno &lt;ueno@gnu.org&gt; writes:

&gt; Thank you very much for all the Curve448/SHAKE256 work for merging (I'm
&gt; slowly catching up).

I think this is complete now (except updating hogweed-benchmark), just
pushed to the ed448 branch. Thanks for the patience.

&gt;&gt; These corner cases are a bit hard to test.
&gt;
&gt; For what it's worth, the original issue was reliably reproducible with
&gt; the GnuTLS port[1] against the OpenSSL client.  Here is a test vector
&gt; extracted from the interaction:

I'm afraid this doesn't exercise the corner cases. The thing is, we have q
close to 2^k (k = 2^252 for ed25519, k = 446 for ed448).

Then we want to reduce 

  r = hi 2^k + lo

modulo q, canonically. If we set 

  r' = r - hi * q

then it's highly likely that 0 &lt;= r' &lt; q, but not certain. 

For ed25519, q &gt; 2^k, so we are guaranteed that r' &lt; 2^k &lt; q, but we may
get r' &lt; 0.

For ed448, q &lt; 2^k, so we are guaranteed that r' &gt; 0, and we may instead
get r' &gt;= q. 

For now, I've added the following logic to _eddsa_sign:

  if (ecc-&gt;p.bit_size == 255)
    {
      /* FIXME: Special code duplicated in ecc_25519_modq
	 Define a suitable method for canonical reduction? */

      /* q is slightly larger than 2^252, underflow from below
         mpn_submul_1 is unlikely. */
      unsigned shift = 252 - GMP_NUMB_BITS * (ecc-&gt;p.size - 1);
      q = sp[ecc-&gt;p.size-1] &gt;&gt; shift;
    }
  else
    {
      unsigned shift;

      assert (ecc-&gt;p.bit_size == 448);
      /* q is slightly smaller than 2^446 */
      shift = 446 - GMP_NUMB_BITS * (ecc-&gt;p.size - 1);
      /* Add one, then it's possible but unlikely that below
	 mpn_submul_1 does *not* underflow. */
      q = (sp[ecc-&gt;p.size-1] &gt;&gt; shift) + 1;
    }

  cy = mpn_submul_1 (sp, ecc-&gt;q.m, ecc-&gt;p.size, q);
  assert (cy &lt; 2);
  cy -= cnd_add_n (cy, sp, ecc-&gt;q.m, ecc-&gt;p.size);
  assert (cy == 0);

I think that's correct, but it seems tricky to find inputs to
_eddsa_sign that will hit the corner cases. I've added some debug
printouts to verify that mpn_submul_1 returns 0 for the ed25519
testcases, and 1 for all the ed448 testcases. If it's taken out to a
separate function/method, then it gets easier to unit test.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200102203159</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-02 20:31:59-0400</timestampReceived><subject>Re: [PATCH 0/8] Implement Curve448 ECDH and Ed448</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; I think this is complete now (except updating hogweed-benchmark), just
&gt; pushed to the ed448 branch. Thanks for the patience.

It seems I forgot to add the new files in the first attempt. Ooops.
Fixed with a forced update on this branch.

Now ubsan fails, it doesn't like calling memcpy with null ptr and zero
size. I have to fix that. Not sure what's prettiest, either a
conditional, or a function pointer like it was done in the original patch.

In the mean time, I've updated hogweed benchmark (not yet committed).
This is what I get on my old (x86_64) laptop:

            name size   sign/ms verify/ms
           ecdsa  192    5.2194    1.7914
           ecdsa  224    3.2297    1.1658
           ecdsa  256    3.1153    1.0347
           ecdsa  384    1.4393    0.4607
           ecdsa  521    0.7277    0.2308
           eddsa  255    6.0243    1.5598
           eddsa  448    1.7464    0.4595

So speedwise, ed25519 is comparable to ecdsa on secp_192r1, and ed448 is
comparable to ecdsa on secp_384r1. In both cases, signing is a bit
faster (15%-20%), and verify is the same or a bit slower.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200201133523</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-02-01 13:35:23-0400</timestampReceived><subject>sha1-compress-2.s:74: Error: no such instruction: `sha1rnds4 $0, %xmm5, %xmm4'</subject><body>

Hi Everyone,

I'm working on Solaris 11.3 i86pc. I'm building the Nettle 3.5.1
release tarball.

configure: summary of build options:

  Version:           nettle 3.5.1
  Host type:         x86_64-sun-solaris2
  ABI:               64
  Assembly files:    x86_64/fat x86_64
  Install prefix:    /usr/local
  Library directory: /usr/local/lib
  Compiler:          gcc
  Static libraries:  yes
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

Running make results in:

gcc -I. -I/usr/local/include -DNDEBUG -DHAVE_CONFIG_H -g2 -O2 -m64
-march=native -fPIC -pthread -ggdb3 -Wno-pointer-sign -Wall -W
-Wmissing-prototypes -Wmissing-declarations -Wstrict-prototypes
-Wpointer-arith -Wbad-function-cast -Wnested-externs -fPIC -MT
sha256-compress-2.o -MD -MP -MF sha256-compress-2.o.d -c
sha256-compress-2.s
sha1-compress-2.s: Assembler messages:
sha1-compress-2.s:74: Error: no such instruction: `sha1rnds4 $0,%xmm5,%xmm4'
sha1-compress-2.s:79: Error: no such instruction: `sha1nexte %xmm1,%xmm6'
sha1-compress-2.s:81: Error: no such instruction: `sha1rnds4 $0,%xmm6,%xmm4'
sha1-compress-2.s:82: Error: no such instruction: `sha1msg1 %xmm1,%xmm0'
sha1-compress-2.s:87: Error: no such instruction: `sha1nexte %xmm2,%xmm5'
...

Sun provides an old GCC. The compiler supports AES-NI, but it lacks SHA.

    $ gcc --version
    gcc (GCC) 4.8.2

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200303222009</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-03-03 22:20:09-0400</timestampReceived><subject>Re: [PATCH] chacha: add function to set the initial value of counter</subject><body>

Daiki Ueno &lt;ueno@gnu.org&gt; writes:

&gt; The ChaCha20 based header protection algorithm in QUIC requires a way
&gt; to set the initial value of counter:
&gt; https://quicwg.org/base-drafts/draft-ietf-quic-tls.html#name-chacha20-based-header-prote

Out of curiosity, are you aware on any quic implementation using Nettle?

&gt; This will add a new function chacha_set_nonce128, which takes the
&gt; counter value embedded in the nonce.

I see two issues with this change as is.

First is purely an interface design issue. It may be more useful to have
a separate function to set the 32-bit counter. E.g., that would be
convenient for random access to a chacha-encrypted file.

The other is more subtle and with interop implications. The way the
counter is currently updated in chacha_crypt still assumes a 64-bit
counter (as in the original chacha papers with 64 bits each for nonce
and counter). This is compatible with RFC 8439, as long as the counter
is initialized to a small value such as 0 or 1. But if counter is
initialized to a random 32-bit value, and is expected to wrap around mod
2^32, then Nettle will not work as expected but propagate carry into the
first 32-bits of the nonce.

Not sure how to best deal with this.

It looks like chacha was added in Nettle-3.0, and chacha_set_nonce96
added in Nettle-3.1 (undocumented and used in the implementation of
ChaCha-Poly1305). The Nettle-3.1 release also updated chacha-poly1305 to
follow draft-irtf-cfrg-chacha20-poly1305-08 (which later evolved into
RFC 8439, if I understood the document history correstly). It seems this
change is not documented in the manual or in NEWS; the manual still says
that chacha-poly1305 use 64-bit nonce and is experimental.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200328055205</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-03-28 05:52:05-0400</timestampReceived><subject>Nettle 3.5.1 and OS X 10.12 patch</subject><body>

Hi Everyone/Niels,

I've got a bare-bones Mac-mini without Xcode. It has CC Tools but that
is it. It is in a stock configuration.

When I attempt to run 'make check' nearly every test failed due to
missing libnettle and libhogweed. The libraries were present in .lib/,
but something was blowing away LD_LIBRARY_PATH and DYLD_LIBRARY_PATH.
My driver script set it, and the Nettle sources also set it after I
set it. But by the times the test runner scripts were run, they were
empty again (they were empty at the Makefile, before hitting the test
runners).

I know Apple did some hardening lately but I have not read anything
about scrubbing LD_LIBRARY_PATH and DYLD_LIBRARY_PATH. But it appears
something was sanitizing the environment.

Attached is the patch I needed for the issue on OS X 10.12. It also
tested good on Ubuntu 18.04 and Solaris 11.3. Earlier versions of OS
X, like OS X 10.9 and OS X 10.5, were OK. It was just OS X 10.12.

The short of it is, each test runner, like run-tests.sh, needed to
restore the variables using an absolute path. dirname is Posix so it
is available to strip the unwanted path component, like testsuite/ or
example/.

+nettle_lib_dir=`dirname $PWD`/.lib
+LD_LIBRARY_PATH=$nettle_lib_dir
+DYLD_LIBRARY_PATH=$nettle_lib_dir
+
+export LD_LIBRARY_PATH
+export DYLD_LIBRARY_PATH

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200504145613</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-05-04 14:56:13-0400</timestampReceived><subject>Re: ANNOUNCE: Nettle-3.6</subject><body>

Hello,

I just wanted to point that git tree was not updated for the release.

-- 
With best wishes
Dmitry

ср, 29 апр. 2020 г., 23:05 Niels Möller &lt;nisse@lysator.liu.se&gt;:

&gt; -----BEGIN PGP SIGNED MESSAGE-----
&gt; Hash: SHA256
&gt;
&gt; I'm happy to announce a new release of GNU Nettle, a low-level
&gt; cryptographics library. This version includes several new features, and
&gt; a couple of bug fixes, see NEWS entries below.
&gt;
&gt; The Nettle home page can be found at
&gt; https://www.lysator.liu.se/~nisse/nettle/, and the manual at
&gt; https://www.lysator.liu.se/~nisse/nettle/nettle.html.
&gt;
&gt; The release can be downloaded from
&gt;
&gt;   https://ftp.gnu.org/gnu/nettle/nettle-3.6.tar.gz
&gt;   ftp://ftp.gnu.org/gnu/nettle/nettle-3.6.tar.gz
&gt;   https://www.lysator.liu.se/~nisse/archive/nettle-3.6.tar.gz
&gt;
&gt; Happy hacking,
&gt; /Niels Möller
&gt;
&gt; NEWS for the Nettle 3.6 release
&gt;
&gt;         This release adds a couple of new features, most notable being
&gt;         support for ED448 signatures.
&gt;
&gt;         It is not binary compatible with earlier releases. The shared
&gt;         library names are libnettle.so.8.0 and libhogweed.so.6.0, with
&gt;         sonames nibnettle.so.8 and libhogweed.so.6. The changed
&gt;         sonames are mainly to avoid upgrade problems with recent
&gt;         GnuTLS versions, that depend on Nettle internals outside of
&gt;         the advertised ABI. But also because of the removal of
&gt;         internal poly1305 functions which were undocumented but
&gt;         declared in an installed header file, see Interface changes
&gt;         below.
&gt;
&gt;         New features:
&gt;
&gt;         * Support for Curve448 and ED448 signatures. Contributed by
&gt;           Daiki Ueno.
&gt;
&gt;         * Support for SHAKE256 (SHA3 variant with arbitrary output
&gt;           size). Contributed by Daiki Ueno.
&gt;
&gt;         * Support for SIV-CMAC (Synthetic Initialization Vector) mode,
&gt;           contributed by Nikos Mavrogiannopoulos.
&gt;
&gt;         * Support for CMAC64, contributed by Dmitry Baryshkov.
&gt;
&gt;         * Support for the "CryptoPro" variant of the GOST hash
&gt;           function, as gosthash94cp. Contributed by Dmitry Baryshkov.
&gt;
&gt;         * Support for GOST DSA signatures, including GOST curves
&gt;           gc256b and gc512a. Contributed by Dmitry Baryshkov.
&gt;
&gt;         * Support for Intel CET in x86 and x86_64 assembly files, if
&gt;           enabled via CFLAGS (gcc --fcf-protection=full). Contributed
&gt;           by H.J. Lu and Simo Sorce.
&gt;
&gt;         * A few new functions to improve support for the Chacha
&gt;           variant with 96-bit nonce and 32-bit block counter (the
&gt;           existing functions use nonce and counter of 64-bit each),
&gt;           and functions to set the counter. Contributed by Daiki Ueno.
&gt;
&gt;         * New interface, struct nettle_mac, for MAC (message
&gt;           authentication code) algorithms. This abstraction is only
&gt;           for MACs that don't require a per-message nonce. For HMAC,
&gt;           the key size is fixed, and equal the digest size of the
&gt;           underlying hash function.
&gt;
&gt;         Bug fixes:
&gt;
&gt;         * Fix bug in cfb8_decrypt. Previously, the IV was not updated
&gt;           correctly in the case of input data shorter than the block
&gt;           size. Reported by Stephan Mueller, fixed by Daiki Ueno.
&gt;
&gt;         * Fix configure check for __builtin_bswap64, the incorrect
&gt;           check would result in link errors on platforms missing this
&gt;           function. Patch contributed by George Koehler.
&gt;
&gt;         * All use of old-fashioned suffix rules in the Makefiles have
&gt;           been replaced with %-pattern rules. Nettle's use of suffix
&gt;           rules in earlier versions depended on undocumented GNU make
&gt;           behavior, which is being deprecated in GNU make 4.3.
&gt;
&gt;           Building with other make programs than GNU make is untested
&gt;           and unsupported. (Building with BSD make or Solaris make
&gt;           used to work years ago, but has not been tested recently).
&gt;
&gt;         Interface changes:
&gt;
&gt;         * Declarations of internal poly1305.h functions have been
&gt;           removed from the header file poly1305.h, to make it clear
&gt;           that they are not part of the advertised API or ABI.
&gt;
&gt;         Miscellaneous:
&gt;
&gt;         * Building the public key support of nettle now requires GMP
&gt;           version 6.1.0 or later (unless --enable-mini-gmp is used).
&gt;
&gt;         * A fair amount of changes to ECC internals, with a few
&gt;           deleted and a few new fields in the internal struct
&gt;           ecc_curve. Files and functions have been renamed to more
&gt;           consistently match the curve name, e.g., ecc-256.c has been
&gt;           renamed to ecc-secp256r1.c.
&gt;
&gt;         * Documentation for chacha-poly1305 updated. It is no longer
&gt;           experimental. The implementation was updated to follow RFC
&gt;           8439 in Nettle-3.1, but that was not documented or announced
&gt;           at the time.
&gt;
&gt; - --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt;
&gt; -----BEGIN PGP SIGNATURE-----
&gt;
&gt; iQEzBAEBCAAdFiEEy0li0HDXfX/Li6Nicdjx/zaMZncFAl6p3hsACgkQcdjx/zaM
&gt; ZneC5gf7BZuz13jnIzETuRCtqwcV8BaFZOhBrDmqPxHeCVL2BVZwUxVpIVZAhqKu
&gt; ngj5i4GEQBHLg5BRJk/97gyn4YCbWfr7397tqBdUWO2VWFKaG+5QGCG3pjjxyjgm
&gt; hECNrRpSLHHVzUFi2bLCo4Ur+R2d52I1l+hI7CekTxAk1c01xhpobs0pSUDUCfco
&gt; /c8gNbbrNZc/KxUq1qtaWucxvysa4BsfnqucnhjAftMrmishFdr282gWNrnK3q9K
&gt; kHIxCL01bYIQVQmYdH0VglGtq7rYCkL870Ip21OOaL+LIHm1FMaDpXHbXi/GkGqK
&gt; Ukre//RxgMbwPMsM7eh5rp7pOAqdug==
&gt; =QvUR
&gt; -----END PGP SIGNATURE-----
&gt; _______________________________________________
&gt; nettle-bugs mailing list
&gt; nettle-bugs@lists.lysator.liu.se
&gt; http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200602104533</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-06-02 10:45:33-0400</timestampReceived><subject>[PATCH v2 1/8] Implement GOST R 34.11-2012 (Streebog) hash function</subject><body>

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 Makefile.in     |    3 +-
 streebog-meta.c |   44 ++
 streebog.c      | 1334 +++++++++++++++++++++++++++++++++++++++++++++++
 streebog.h      |   99 ++++
 4 files changed, 1479 insertions(+), 1 deletion(-)
 create mode 100644 streebog-meta.c
 create mode 100644 streebog.c
 create mode 100644 streebog.h

diff --git a/Makefile.in b/Makefile.in
index e5ccfc76b901..c36764dc4c45 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -137,6 +137,7 @@ nettle_SOURCES = aes-decrypt-internal.c aes-decrypt.c \
 		 shake256.c \
 		 serpent-set-key.c serpent-encrypt.c serpent-decrypt.c \
 		 serpent-meta.c \
+		 streebog.c streebog-meta.c \
 		 twofish.c twofish-meta.c \
 		 umac-nh.c umac-nh-n.c umac-l2.c umac-l3.c \
 		 umac-poly64.c umac-poly128.c umac-set-key.c \
@@ -222,7 +223,7 @@ HEADERS = aes.h arcfour.h arctwo.h asn1.h blowfish.h \
 	  pbkdf2.h \
 	  pgp.h pkcs1.h pss.h pss-mgf1.h realloc.h ripemd160.h rsa.h \
 	  salsa20.h sexp.h \
-	  serpent.h sha.h sha1.h sha2.h sha3.h twofish.h \
+	  serpent.h sha.h sha1.h sha2.h sha3.h streebog.h twofish.h \
 	  umac.h yarrow.h xts.h poly1305.h
 
 INSTALL_HEADERS = $(HEADERS) version.h @IF_MINI_GMP@ mini-gmp.h
diff --git a/streebog-meta.c b/streebog-meta.c
new file mode 100644
index 000000000000..de88651b8810
--- /dev/null
+++ b/streebog-meta.c
@@ -0,0 +1,44 @@
+/* streebog-meta.c
+
+   Copyright (C) 2020 Dmitry Baryshkov
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include "nettle-meta.h"
+
+#include "streebog.h"
+
+const struct nettle_hash nettle_streebog512
+= _NETTLE_HASH(streebog512, STREEBOG512);
+
+const struct nettle_hash nettle_streebog256
+= _NETTLE_HASH(streebog256, STREEBOG256);
diff --git a/streebog.c b/streebog.c
new file mode 100644
index 000000000000..3f2fc2f40dfb
--- /dev/null
+++ b/streebog.c
@@ -0,0 +1,1334 @@
+/* streebog.c - GOST R 34.11-2012 (Streebog) hash function
+
+   Copyright (C) 2020 Dmitry Baryshkov
+
+   Based on my code in libgcrypt.
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+ */
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;stdlib.h&gt;
+#include &lt;string.h&gt;
+
+#include "streebog.h"
+
+#include "macros.h"
+#include "nettle-write.h"
+
+
+/* Pre-computed results of multiplication of bytes on A and reordered with
+   Pi[]. */
+static const uint64_t streebog_table[8][256] =
+{
+  /* 0 */
+  { 0xd01f715b5c7ef8e6ULL, 0x16fa240980778325ULL,
+    0xa8a42e857ee049c8ULL, 0x6ac1068fa186465bULL,
+    0x6e417bd7a2e9320bULL, 0x665c8167a437daabULL,
+    0x7666681aa89617f6ULL, 0x4b959163700bdcf5ULL,
+    0xf14be6b78df36248ULL, 0xc585bd689a625cffULL,
+    0x9557d7fca67d82cbULL, 0x89f0b969af6dd366ULL,
+    0xb0833d48749f6c35ULL, 0xa1998c23b1ecbc7cULL,
+    0x8d70c431ac02a736ULL, 0xd6dfbc2fd0a8b69eULL,
+    0x37aeb3e551fa198bULL, 0x0b7d128a40b5cf9cULL,
+    0x5a8f2008b5780cbcULL, 0xedec882284e333e5ULL,
+    0xd25fc177d3c7c2ceULL, 0x5e0f5d50b61778ecULL,
+    0x1d873683c0c24cb9ULL, 0xad040bcbb45d208cULL,
+    0x2f89a0285b853c76ULL, 0x5732fff6791b8d58ULL,
+    0x3e9311439ef6ec3fULL, 0xc9183a809fd3c00fULL,
+    0x83adf3f5260a01eeULL, 0xa6791941f4e8ef10ULL,
+    0x103ae97d0ca1cd5dULL, 0x2ce948121dee1b4aULL,
+    0x39738421dbf2bf53ULL, 0x093da2a6cf0cf5b4ULL,
+    0xcd9847d89cbcb45fULL, 0xf9561c078b2d8ae8ULL,
+    0x9c6a755a6971777fULL, 0xbc1ebaa0712ef0c5ULL,
+    0x72e61542abf963a6ULL, 0x78bb5fde229eb12eULL,
+    0x14ba94250fceb90dULL, 0x844d6697630e5282ULL,
+    0x98ea08026a1e032fULL, 0xf06bbea144217f5cULL,
+    0xdb6263d11ccb377aULL, 0x641c314b2b8ee083ULL,
+    0x320e96ab9b4770cfULL, 0x1ee7deb986a96b85ULL,
+    0xe96cf57a878c47b5ULL, 0xfdd6615f8842feb8ULL,
+    0xc83862965601dd1bULL, 0x2ea9f83e92572162ULL,
+    0xf876441142ff97fcULL, 0xeb2c455608357d9dULL,
+    0x5612a7e0b0c9904cULL, 0x6c01cbfb2d500823ULL,
+    0x4548a6a7fa037a2dULL, 0xabc4c6bf388b6ef4ULL,
+    0xbade77d4fdf8bebdULL, 0x799b07c8eb4cac3aULL,
+    0x0c9d87e805b19cf0ULL, 0xcb588aac106afa27ULL,
+    0xea0c1d40c1e76089ULL, 0x2869354a1e816f1aULL,
+    0xff96d17307fbc490ULL, 0x9f0a9d602f1a5043ULL,
+    0x96373fc6e016a5f7ULL, 0x5292dab8b3a6e41cULL,
+    0x9b8ae0382c752413ULL, 0x4f15ec3b7364a8a5ULL,
+    0x3fb349555724f12bULL, 0xc7c50d4415db66d7ULL,
+    0x92b7429ee379d1a7ULL, 0xd37f99611a15dfdaULL,
+    0x231427c05e34a086ULL, 0xa439a96d7b51d538ULL,
+    0xb403401077f01865ULL, 0xdda2aea5901d7902ULL,
+    0x0a5d4a9c8967d288ULL, 0xc265280adf660f93ULL,
+    0x8bb0094520d4e94eULL, 0x2a29856691385532ULL,
+    0x42a833c5bf072941ULL, 0x73c64d54622b7eb2ULL,
+    0x07e095624504536cULL, 0x8a905153e906f45aULL,
+    0x6f6123c16b3b2f1fULL, 0xc6e55552dc097bc3ULL,
+    0x4468feb133d16739ULL, 0xe211e7f0c7398829ULL,
+    0xa2f96419f7879b40ULL, 0x19074bdbc3ad38e9ULL,
+    0xf4ebc3f9474e0b0cULL, 0x43886bd376d53455ULL,
+    0xd8028beb5aa01046ULL, 0x51f23282f5cdc320ULL,
+    0xe7b1c2be0d84e16dULL, 0x081dfab006dee8a0ULL,
+    0x3b33340d544b857bULL, 0x7f5bcabc679ae242ULL,
+    0x0edd37c48a08a6d8ULL, 0x81ed43d9a9b33bc6ULL,
+    0xb1a3655ebd4d7121ULL, 0x69a1eeb5e7ed6167ULL,
+    0xf6ab73d5c8f73124ULL, 0x1a67a3e185c61fd5ULL,
+    0x2dc91004d43c065eULL, 0x0240b02c8fb93a28ULL,
+    0x90f7f2b26cc0eb8fULL, 0x3cd3a16f114fd617ULL,
+    0xaae49ea9f15973e0ULL, 0x06c0cd748cd64e78ULL,
+    0xda423bc7d5192a6eULL, 0xc345701c16b41287ULL,
+    0x6d2193ede4821537ULL, 0xfcf639494190e3acULL,
+    0x7c3b228621f1c57eULL, 0xfb16ac2b0494b0c0ULL,
+    0xbf7e529a3745d7f9ULL, 0x6881b6a32e3f7c73ULL,
+    0xca78d2bad9b8e733ULL, 0xbbfe2fc2342aa3a9ULL,
+    0x0dbddffecc6381e4ULL, 0x70a6a56e2440598eULL,
+    0xe4d12a844befc651ULL, 0x8c509c2765d0ba22ULL,
+    0xee8c6018c28814d9ULL, 0x17da7c1f49a59e31ULL,
+    0x609c4c1328e194d3ULL, 0xb3e3d57232f44b09ULL,
+    0x91d7aaa4a512f69bULL, 0x0ffd6fd243dabbccULL,
+    0x50d26a943c1fde34ULL, 0x6be15e9968545b4fULL,
+    0x94778fea6faf9fdfULL, 0x2b09dd7058ea4826ULL,
+    0x677cd9716de5c7bfULL, 0x49d5214fffb2e6ddULL,
+    0x0360e83a466b273cULL, 0x1fc786af4f7b7691ULL,
+    0xa0b9d435783ea168ULL, 0xd49f0c035f118cb6ULL,
+    0x01205816c9d21d14ULL, 0xac2453dd7d8f3d98ULL,
+    0x545217cc3f70aa64ULL, 0x26b4028e9489c9c2ULL,
+    0xdec2469fd6765e3eULL, 0x04807d58036f7450ULL,
+    0xe5f17292823ddb45ULL, 0xf30b569b024a5860ULL,
+    0x62dcfc3fa758aefbULL, 0xe84cad6c4e5e5aa1ULL,
+    0xccb81fce556ea94bULL, 0x53b282ae7a74f908ULL,
+    0x1b47fbf74c1402c1ULL, 0x368eebf39828049fULL,
+    0x7afbeff2ad278b06ULL, 0xbe5e0a8cfe97caedULL,
+    0xcfd8f7f413058e77ULL, 0xf78b2bc301252c30ULL,
+    0x4d555c17fcdd928dULL, 0x5f2f05467fc565f8ULL,
+    0x24f4b2a21b30f3eaULL, 0x860dd6bbecb768aaULL,
+    0x4c750401350f8f99ULL, 0x0000000000000000ULL,
+    0xecccd0344d312ef1ULL, 0xb5231806be220571ULL,
+    0xc105c030990d28afULL, 0x653c695de25cfd97ULL,
+    0x159acc33c61ca419ULL, 0xb89ec7f872418495ULL,
+    0xa9847693b73254dcULL, 0x58cf90243ac13694ULL,
+    0x59efc832f3132b80ULL, 0x5c4fed7c39ae42c4ULL,
+    0x828dabe3efd81cfaULL, 0xd13f294d95ace5f2ULL,
+    0x7d1b7a90e823d86aULL, 0xb643f03cf849224dULL,
+    0x3df3f979d89dcb03ULL, 0x7426d836272f2ddeULL,
+    0xdfe21e891fa4432aULL, 0x3a136c1b9d99986fULL,
+    0xfa36f43dcd46add4ULL, 0xc025982650df35bbULL,
+    0x856d3e81aadc4f96ULL, 0xc4a5e57e53b041ebULL,
+    0x4708168b75ba4005ULL, 0xaf44bbe73be41aa4ULL,
+    0x971767d029c4b8e3ULL, 0xb9be9feebb939981ULL,
+    0x215497ecd18d9aaeULL, 0x316e7e91dd2c57f3ULL,
+    0xcef8afe2dad79363ULL, 0x3853dc371220a247ULL,
+    0x35ee03c9de4323a3ULL, 0xe6919aa8c456fc79ULL,
+    0xe05157dc4880b201ULL, 0x7bdbb7e464f59612ULL,
+    0x127a59518318f775ULL, 0x332ecebd52956ddbULL,
+    0x8f30741d23bb9d1eULL, 0xd922d3fd93720d52ULL,
+    0x7746300c61440ae2ULL, 0x25d4eab4d2e2eefeULL,
+    0x75068020eefd30caULL, 0x135a01474acaea61ULL,
+    0x304e268714fe4ae7ULL, 0xa519f17bb283c82cULL,
+    0xdc82f6b359cf6416ULL, 0x5baf781e7caa11a8ULL,
+    0xb2c38d64fb26561dULL, 0x34ce5bdf17913eb7ULL,
+    0x5d6fb56af07c5fd0ULL, 0x182713cd0a7f25fdULL,
+    0x9e2ac576e6c84d57ULL, 0x9aaab82ee5a73907ULL,
+    0xa3d93c0f3e558654ULL, 0x7e7b92aaae48ff56ULL,
+    0x872d8ead256575beULL, 0x41c8dbfff96c0e7dULL,
+    0x99ca5014a3cc1e3bULL, 0x40e883e930be1369ULL,
+    0x1ca76e95091051adULL, 0x4e35b42dbab6b5b1ULL,
+    0x05a0254ecabd6944ULL, 0xe1710fca8152af15ULL,
+    0xf22b0e8dcb984574ULL, 0xb763a82a319b3f59ULL,
+    0x63fca4296e8ab3efULL, 0x9d4a2d4ca0a36a6bULL,
+    0xe331bfe60eeb953dULL, 0xd5bf541596c391a2ULL,
+    0xf5cb9bef8e9c1618ULL, 0x46284e9dbc685d11ULL,
+    0x2074cffa185f87baULL, 0xbd3ee2b6b8fcedd1ULL,
+    0xae64e3f1f23607b0ULL, 0xfeb68965ce29d984ULL,
+    0x55724fdaf6a2b770ULL, 0x29496d5cd753720eULL,
+    0xa75941573d3af204ULL, 0x8e102c0bea69800aULL,
+    0x111ab16bc573d049ULL, 0xd7ffe439197aab8aULL,
+    0xefac380e0b5a09cdULL, 0x48f579593660fbc9ULL,
+    0x22347fd697e6bd92ULL, 0x61bc1405e13389c7ULL,
+    0x4ab5c975b9d9c1e1ULL, 0x80cd1bcf606126d2ULL,
+    0x7186fd78ed92449aULL, 0x93971a882aabccb3ULL,
+    0x88d0e17f66bfce72ULL, 0x27945a985d5bd4d6ULL },
+  /* 1 */
+  { 0xde553f8c05a811c8ULL, 0x1906b59631b4f565ULL,
+    0x436e70d6b1964ff7ULL, 0x36d343cb8b1e9d85ULL,
+    0x843dfacc858aab5aULL, 0xfdfc95c299bfc7f9ULL,
+    0x0f634bdea1d51fa2ULL, 0x6d458b3b76efb3cdULL,
+    0x85c3f77cf8593f80ULL, 0x3c91315fbe737cb2ULL,
+    0x2148b03366ace398ULL, 0x18f8b8264c6761bfULL,
+    0xc830c1c495c9fb0fULL, 0x981a76102086a0aaULL,
+    0xaa16012142f35760ULL, 0x35cc54060c763cf6ULL,
+    0x42907d66cc45db2dULL, 0x8203d44b965af4bcULL,
+    0x3d6f3cefc3a0e868ULL, 0xbc73ff69d292bda7ULL,
+    0x8722ed0102e20a29ULL, 0x8f8185e8cd34deb7ULL,
+    0x9b0561dda7ee01d9ULL, 0x5335a0193227fad6ULL,
+    0xc9cecc74e81a6fd5ULL, 0x54f5832e5c2431eaULL,
+    0x99e47ba05d553470ULL, 0xf7bee756acd226ceULL,
+    0x384e05a5571816fdULL, 0xd1367452a47d0e6aULL,
+    0xf29fde1c386ad85bULL, 0x320c77316275f7caULL,
+    0xd0c879e2d9ae9ab0ULL, 0xdb7406c69110ef5dULL,
+    0x45505e51a2461011ULL, 0xfc029872e46c5323ULL,
+    0xfa3cb6f5f7bc0cc5ULL, 0x031f17cd8768a173ULL,
+    0xbd8df2d9af41297dULL, 0x9d3b4f5ab43e5e3fULL,
+    0x4071671b36feee84ULL, 0x716207e7d3e3b83dULL,
+    0x48d20ff2f9283a1aULL, 0x27769eb4757cbc7eULL,
+    0x5c56ebc793f2e574ULL, 0xa48b474f9ef5dc18ULL,
+    0x52cbada94ff46e0cULL, 0x60c7da982d8199c6ULL,
+    0x0e9d466edc068b78ULL, 0x4eec2175eaf865fcULL,
+    0x550b8e9e21f7a530ULL, 0x6b7ba5bc653fec2bULL,
+    0x5eb7f1ba6949d0ddULL, 0x57ea94e3db4c9099ULL,
+    0xf640eae6d101b214ULL, 0xdd4a284182c0b0bbULL,
+    0xff1d8fbf6304f250ULL, 0xb8accb933bf9d7e8ULL,
+    0xe8867c478eb68c4dULL, 0x3f8e2692391bddc1ULL,
+    0xcb2fd60912a15a7cULL, 0xaec935dbab983d2fULL,
+    0xf55ffd2b56691367ULL, 0x80e2ce366ce1c115ULL,
+    0x179bf3f8edb27e1dULL, 0x01fe0db07dd394daULL,
+    0xda8a0b76ecc37b87ULL, 0x44ae53e1df9584cbULL,
+    0xb310b4b77347a205ULL, 0xdfab323c787b8512ULL,
+    0x3b511268d070b78eULL, 0x65e6e3d2b9396753ULL,
+    0x6864b271e2574d58ULL, 0x259784c98fc789d7ULL,
+    0x02e11a7dfabb35a9ULL, 0x8841a6dfa337158bULL,
+    0x7ade78c39b5dcdd0ULL, 0xb7cf804d9a2cc84aULL,
+    0x20b6bd831b7f7742ULL, 0x75bd331d3a88d272ULL,
+    0x418f6aab4b2d7a5eULL, 0xd9951cbb6babdaf4ULL,
+    0xb6318dfde7ff5c90ULL, 0x1f389b112264aa83ULL,
+    0x492c024284fbaec0ULL, 0xe33a0363c608f9a0ULL,
+    0x2688930408af28a4ULL, 0xc7538a1a341ce4adULL,
+    0x5da8e677ee2171aeULL, 0x8c9e92254a5c7fc4ULL,
+    0x63d8cd55aae938b5ULL, 0x29ebd8daa97a3706ULL,
+    0x959827b37be88aa1ULL, 0x1484e4356adadf6eULL,
+    0xa7945082199d7d6bULL, 0xbf6ce8a455fa1cd4ULL,
+    0x9cc542eac9edcae5ULL, 0x79c16f0e1c356ca3ULL,
+    0x89bfab6fdee48151ULL, 0xd4174d1830c5f0ffULL,
+    0x9258048415eb419dULL, 0x6139d72850520d1cULL,
+    0x6a85a80c18ec78f1ULL, 0xcd11f88e0171059aULL,
+    0xcceff53e7ca29140ULL, 0xd229639f2315af19ULL,
+    0x90b91ef9ef507434ULL, 0x5977d28d074a1be1ULL,
+    0x311360fce51d56b9ULL, 0xc093a92d5a1f2f91ULL,
+    0x1a19a25bb6dc5416ULL, 0xeb996b8a09de2d3eULL,
+    0xfee3820f1ed7668aULL, 0xd7085ad5b7ad518cULL,
+    0x7fff41890fe53345ULL, 0xec5948bd67dde602ULL,
+    0x2fd5f65dbaaa68e0ULL, 0xa5754affe32648c2ULL,
+    0xf8ddac880d07396cULL, 0x6fa491468c548664ULL,
+    0x0c7c5c1326bdbed1ULL, 0x4a33158f03930fb3ULL,
+    0x699abfc19f84d982ULL, 0xe4fa2054a80b329cULL,
+    0x6707f9af438252faULL, 0x08a368e9cfd6d49eULL,
+    0x47b1442c58fd25b8ULL, 0xbbb3dc5ebc91769bULL,
+    0x1665fe489061eac7ULL, 0x33f27a811fa66310ULL,
+    0x93a609346838d547ULL, 0x30ed6d4c98cec263ULL,
+    0x1dd9816cd8df9f2aULL, 0x94662a03063b1e7bULL,
+    0x83fdd9fbeb896066ULL, 0x7b207573e68e590aULL,
+    0x5f49fc0a149a4407ULL, 0x343259b671a5a82cULL,
+    0xfbc2bb458a6f981fULL, 0xc272b350a0a41a38ULL,
+    0x3aaf1fd8ada32354ULL, 0x6cbb868b0b3c2717ULL,
+    0xa2b569c88d2583feULL, 0xf180c9d1bf027928ULL,
+    0xaf37386bd64ba9f5ULL, 0x12bacab2790a8088ULL,
+    0x4c0d3b0810435055ULL, 0xb2eeb9070e9436dfULL,
+    0xc5b29067cea7d104ULL, 0xdcb425f1ff132461ULL,
+    0x4f122cc5972bf126ULL, 0xac282fa651230886ULL,
+    0xe7e537992f6393efULL, 0xe61b3a2952b00735ULL,
+    0x709c0a57ae302ce7ULL, 0xe02514ae416058d3ULL,
+    0xc44c9dd7b37445deULL, 0x5a68c5408022ba92ULL,
+    0x1c278cdca50c0bf0ULL, 0x6e5a9cf6f18712beULL,
+    0x86dce0b17f319ef3ULL, 0x2d34ec2040115d49ULL,
+    0x4bcd183f7e409b69ULL, 0x2815d56ad4a9a3dcULL,
+    0x24698979f2141d0dULL, 0x0000000000000000ULL,
+    0x1ec696a15fb73e59ULL, 0xd86b110b16784e2eULL,
+    0x8e7f8858b0e74a6dULL, 0x063e2e8713d05fe6ULL,
+    0xe2c40ed3bbdb6d7aULL, 0xb1f1aeca89fc97acULL,
+    0xe1db191e3cb3cc09ULL, 0x6418ee62c4eaf389ULL,
+    0xc6ad87aa49cf7077ULL, 0xd6f65765ca7ec556ULL,
+    0x9afb6c6dda3d9503ULL, 0x7ce05644888d9236ULL,
+    0x8d609f95378feb1eULL, 0x23a9aa4e9c17d631ULL,
+    0x6226c0e5d73aac6fULL, 0x56149953a69f0443ULL,
+    0xeeb852c09d66d3abULL, 0x2b0ac2a753c102afULL,
+    0x07c023376e03cb3cULL, 0x2ccae1903dc2c993ULL,
+    0xd3d76e2f5ec63bc3ULL, 0x9e2458973356ff4cULL,
+    0xa66a5d32644ee9b1ULL, 0x0a427294356de137ULL,
+    0x783f62be61e6f879ULL, 0x1344c70204d91452ULL,
+    0x5b96c8f0fdf12e48ULL, 0xa90916ecc59bf613ULL,
+    0xbe92e5142829880eULL, 0x727d102a548b194eULL,
+    0x1be7afebcb0fc0ccULL, 0x3e702b2244c8491bULL,
+    0xd5e940a84d166425ULL, 0x66f9f41f3e51c620ULL,
+    0xabe80c913f20c3baULL, 0xf07ec461c2d1edf2ULL,
+    0xf361d3ac45b94c81ULL, 0x0521394a94b8fe95ULL,
+    0xadd622162cf09c5cULL, 0xe97871f7f3651897ULL,
+    0xf4a1f09b2bba87bdULL, 0x095d6559b2054044ULL,
+    0x0bbc7f2448be75edULL, 0x2af4cf172e129675ULL,
+    0x157ae98517094bb4ULL, 0x9fda55274e856b96ULL,
+    0x914713499283e0eeULL, 0xb952c623462a4332ULL,
+    0x74433ead475b46a8ULL, 0x8b5eb112245fb4f8ULL,
+    0xa34b6478f0f61724ULL, 0x11a5dd7ffe6221fbULL,
+    0xc16da49d27ccbb4bULL, 0x76a224d0bde07301ULL,
+    0x8aa0bca2598c2022ULL, 0x4df336b86d90c48fULL,
+    0xea67663a740db9e4ULL, 0xef465f70e0b54771ULL,
+    0x39b008152acb8227ULL, 0x7d1e5bf4f55e06ecULL,
+    0x105bd0cf83b1b521ULL, 0x775c2960c033e7dbULL,
+    0x7e014c397236a79fULL, 0x811cc386113255cfULL,
+    0xeda7450d1a0e72d8ULL, 0x5889df3d7a998f3bULL,
+    0x2e2bfbedc779fc3aULL, 0xce0eef438619a4e9ULL,
+    0x372d4e7bf6cd095fULL, 0x04df34fae96b6a4fULL,
+    0xf923a13870d4adb6ULL, 0xa1aa7e050a4d228dULL,
+    0xa8f71b5cb84862c9ULL, 0xb52e9a306097fde3ULL,
+    0x0d8251a35b6e2a0bULL, 0x2257a7fee1c442ebULL,
+    0x73831d9a29588d94ULL, 0x51d4ba64c89ccf7fULL,
+    0x502ab7d4b54f5ba5ULL, 0x97793dce8153bf08ULL,
+    0xe5042de4d5d8a646ULL, 0x9687307efc802bd2ULL,
+    0xa05473b5779eb657ULL, 0xb4d097801d446939ULL,
+    0xcff0e2f3fbca3033ULL, 0xc38cbee0dd778ee2ULL,
+    0x464f499c252eb162ULL, 0xcad1dbb96f72cea6ULL,
+    0xba4dd1eec142e241ULL, 0xb00fa37af42f0376ULL },
+  /* 2 */
+  { 0xcce4cd3aa968b245ULL, 0x089d5484e80b7fafULL,
+    0x638246c1b3548304ULL, 0xd2fe0ec8c2355492ULL,
+    0xa7fbdf7ff2374eeeULL, 0x4df1600c92337a16ULL,
+    0x84e503ea523b12fbULL, 0x0790bbfd53ab0c4aULL,
+    0x198a780f38f6ea9dULL, 0x2ab30c8f55ec48cbULL,
+    0xe0f7fed6b2c49db5ULL, 0xb6ecf3f422cadbdcULL,
+    0x409c9a541358df11ULL, 0xd3ce8a56dfde3fe3ULL,
+    0xc3e9224312c8c1a0ULL, 0x0d6dfa58816ba507ULL,
+    0xddf3e1b179952777ULL, 0x04c02a42748bb1d9ULL,
+    0x94c2abff9f2decb8ULL, 0x4f91752da8f8acf4ULL,
+    0x78682befb169bf7bULL, 0xe1c77a48af2ff6c4ULL,
+    0x0c5d7ec69c80ce76ULL, 0x4cc1e4928fd81167ULL,
+    0xfeed3d24d9997b62ULL, 0x518bb6dfc3a54a23ULL,
+    0x6dbf2d26151f9b90ULL, 0xb5bc624b05ea664fULL,
+    0xe86aaa525acfe21aULL, 0x4801ced0fb53a0beULL,
+    0xc91463e6c00868edULL, 0x1027a815cd16fe43ULL,
+    0xf67069a0319204cdULL, 0xb04ccc976c8abce7ULL,
+    0xc0b9b3fc35e87c33ULL, 0xf380c77c58f2de65ULL,
+    0x50bb3241de4e2152ULL, 0xdf93f490435ef195ULL,
+    0xf1e0d25d62390887ULL, 0xaf668bfb1a3c3141ULL,
+    0xbc11b251f00a7291ULL, 0x73a5eed47e427d47ULL,
+    0x25bee3f6ee4c3b2eULL, 0x43cc0beb34786282ULL,
+    0xc824e778dde3039cULL, 0xf97d86d98a327728ULL,
+    0xf2b043e24519b514ULL, 0xe297ebf7880f4b57ULL,
+    0x3a94a49a98fab688ULL, 0x868516cb68f0c419ULL,
+    0xeffa11af0964ee50ULL, 0xa4ab4ec0d517f37dULL,
+    0xa9c6b498547c567aULL, 0x8e18424f80fbbbb6ULL,
+    0x0bcdc53bcf2bc23cULL, 0x137739aaea3643d0ULL,
+    0x2c1333ec1bac2ff0ULL, 0x8d48d3f0a7db0625ULL,
+    0x1e1ac3f26b5de6d7ULL, 0xf520f81f16b2b95eULL,
+    0x9f0f6ec450062e84ULL, 0x0130849e1deb6b71ULL,
+    0xd45e31ab8c7533a9ULL, 0x652279a2fd14e43fULL,
+    0x3209f01e70f1c927ULL, 0xbe71a770cac1a473ULL,
+    0x0e3d6be7a64b1894ULL, 0x7ec8148cff29d840ULL,
+    0xcb7476c7fac3be0fULL, 0x72956a4a63a91636ULL,
+    0x37f95ec21991138fULL, 0x9e3fea5a4ded45f5ULL,
+    0x7b38ba50964902e8ULL, 0x222e580bbde73764ULL,
+    0x61e253e0899f55e6ULL, 0xfc8d2805e352ad80ULL,
+    0x35994be3235ac56dULL, 0x09add01af5e014deULL,
+    0x5e8659a6780539c6ULL, 0xb17c48097161d796ULL,
+    0x026015213acbd6e2ULL, 0xd1ae9f77e515e901ULL,
+    0xb7dc776a3f21b0adULL, 0xaba6a1b96eb78098ULL,
+    0x9bcf4486248d9f5dULL, 0x582666c536455efdULL,
+    0xfdbdac9bfeb9c6f1ULL, 0xc47999be4163cdeaULL,
+    0x765540081722a7efULL, 0x3e548ed8ec710751ULL,
+    0x3d041f67cb51bac2ULL, 0x7958af71ac82d40aULL,
+    0x36c9da5c047a78feULL, 0xed9a048e33af38b2ULL,
+    0x26ee7249c96c86bdULL, 0x900281bdeba65d61ULL,
+    0x11172c8bd0fd9532ULL, 0xea0abf73600434f8ULL,
+    0x42fc8f75299309f3ULL, 0x34a9cf7d3eb1ae1cULL,
+    0x2b838811480723baULL, 0x5ce64c8742ceef24ULL,
+    0x1adae9b01fd6570eULL, 0x3c349bf9d6bad1b3ULL,
+    0x82453c891c7b75c0ULL, 0x97923a40b80d512bULL,
+    0x4a61dbf1c198765cULL, 0xb48ce6d518010d3eULL,
+    0xcfb45c858e480fd6ULL, 0xd933cbf30d1e96aeULL,
+    0xd70ea014ab558e3aULL, 0xc189376228031742ULL,
+    0x9262949cd16d8b83ULL, 0xeb3a3bed7def5f89ULL,
+    0x49314a4ee6b8cbcfULL, 0xdcc3652f647e4c06ULL,
+    0xda635a4c2a3e2b3dULL, 0x470c21a940f3d35bULL,
+    0x315961a157d174b4ULL, 0x6672e81dda3459acULL,
+    0x5b76f77a1165e36eULL, 0x445cb01667d36ec8ULL,
+    0xc5491d205c88a69bULL, 0x456c34887a3805b9ULL,
+    0xffddb9bac4721013ULL, 0x99af51a71e4649bfULL,
+    0xa15be01cbc7729d5ULL, 0x52db2760e485f7b0ULL,
+    0x8c78576eba306d54ULL, 0xae560f6507d75a30ULL,
+    0x95f22f6182c687c9ULL, 0x71c5fbf54489aba5ULL,
+    0xca44f259e728d57eULL, 0x88b87d2ccebbdc8dULL,
+    0xbab18d32be4a15aaULL, 0x8be8ec93e99b611eULL,
+    0x17b713e89ebdf209ULL, 0xb31c5d284baa0174ULL,
+    0xeeca9531148f8521ULL, 0xb8d198138481c348ULL,
+    0x8988f9b2d350b7fcULL, 0xb9e11c8d996aa839ULL,
+    0x5a4673e40c8e881fULL, 0x1687977683569978ULL,
+    0xbf4123eed72acf02ULL, 0x4ea1f1b3b513c785ULL,
+    0xe767452be16f91ffULL, 0x7505d1b730021a7cULL,
+    0xa59bca5ec8fc980cULL, 0xad069eda20f7e7a3ULL,
+    0x38f4b1bba231606aULL, 0x60d2d77e94743e97ULL,
+    0x9affc0183966f42cULL, 0x248e6768f3a7505fULL,
+    0xcdd449a4b483d934ULL, 0x87b59255751baf68ULL,
+    0x1bea6d2e023d3c7fULL, 0x6b1f12455b5ffcabULL,
+    0x743555292de9710dULL, 0xd8034f6d10f5fddfULL,
+    0xc6198c9f7ba81b08ULL, 0xbb8109aca3a17edbULL,
+    0xfa2d1766ad12cabbULL, 0xc729080166437079ULL,
+    0x9c5fff7b77269317ULL, 0x0000000000000000ULL,
+    0x15d706c9a47624ebULL, 0x6fdf38072fd44d72ULL,
+    0x5fb6dd3865ee52b7ULL, 0xa33bf53d86bcff37ULL,
+    0xe657c1b5fc84fa8eULL, 0xaa962527735cebe9ULL,
+    0x39c43525bfda0b1bULL, 0x204e4d2a872ce186ULL,
+    0x7a083ece8ba26999ULL, 0x554b9c9db72efbfaULL,
+    0xb22cd9b656416a05ULL, 0x96a2bedea5e63a5aULL,
+    0x802529a826b0a322ULL, 0x8115ad363b5bc853ULL,
+    0x8375b81701901eb1ULL, 0x3069e53f4a3a1fc5ULL,
+    0xbd2136cfede119e0ULL, 0x18bafc91251d81ecULL,
+    0x1d4a524d4c7d5b44ULL, 0x05f0aedc6960daa8ULL,
+    0x29e39d3072ccf558ULL, 0x70f57f6b5962c0d4ULL,
+    0x989fd53903ad22ceULL, 0xf84d024797d91c59ULL,
+    0x547b1803aac5908bULL, 0xf0d056c37fd263f6ULL,
+    0xd56eb535919e58d8ULL, 0x1c7ad6d351963035ULL,
+    0x2e7326cd2167f912ULL, 0xac361a443d1c8cd2ULL,
+    0x697f076461942a49ULL, 0x4b515f6fdc731d2dULL,
+    0x8ad8680df4700a6fULL, 0x41ac1eca0eb3b460ULL,
+    0x7d988533d80965d3ULL, 0xa8f6300649973d0bULL,
+    0x7765c4960ac9cc9eULL, 0x7ca801adc5e20ea2ULL,
+    0xdea3700e5eb59ae4ULL, 0xa06b6482a19c42a4ULL,
+    0x6a2f96db46b497daULL, 0x27def6d7d487edccULL,
+    0x463ca5375d18b82aULL, 0xa6cb5be1efdc259fULL,
+    0x53eba3fef96e9cc1ULL, 0xce84d81b93a364a7ULL,
+    0xf4107c810b59d22fULL, 0x333974806d1aa256ULL,
+    0x0f0def79bba073e5ULL, 0x231edc95a00c5c15ULL,
+    0xe437d494c64f2c6cULL, 0x91320523f64d3610ULL,
+    0x67426c83c7df32ddULL, 0x6eefbc99323f2603ULL,
+    0x9d6f7be56acdf866ULL, 0x5916e25b2bae358cULL,
+    0x7ff89012e2c2b331ULL, 0x035091bf2720bd93ULL,
+    0x561b0d22900e4669ULL, 0x28d319ae6f279e29ULL,
+    0x2f43a2533c8c9263ULL, 0xd09e1be9f8fe8270ULL,
+    0xf740ed3e2c796fbcULL, 0xdb53ded237d5404cULL,
+    0x62b2c25faebfe875ULL, 0x0afd41a5d2c0a94dULL,
+    0x6412fd3ce0ff8f4eULL, 0xe3a76f6995e42026ULL,
+    0x6c8fa9b808f4f0e1ULL, 0xc2d9a6dd0f23aad1ULL,
+    0x8f28c6d19d10d0c7ULL, 0x85d587744fd0798aULL,
+    0xa20b71a39b579446ULL, 0x684f83fa7c7f4138ULL,
+    0xe507500adba4471dULL, 0x3f640a46f19a6c20ULL,
+    0x1247bd34f7dd28a1ULL, 0x2d23b77206474481ULL,
+    0x93521002cc86e0f2ULL, 0x572b89bc8de52d18ULL,
+    0xfb1d93f8b0f9a1caULL, 0xe95a2ecc4724896bULL,
+    0x3ba420048511ddf9ULL, 0xd63e248ab6bee54bULL,
+    0x5dd6c8195f258455ULL, 0x06a03f634e40673bULL,
+    0x1f2a476c76b68da6ULL, 0x217ec9b49ac78af7ULL,
+    0xecaa80102e4453c3ULL, 0x14e78257b99d4f9aULL },
+  /* 3 */
+  { 0x20329b2cc87bba05ULL, 0x4f5eb6f86546a531ULL,
+    0xd4f44775f751b6b1ULL, 0x8266a47b850dfa8bULL,
+    0xbb986aa15a6ca985ULL, 0xc979eb08f9ae0f99ULL,
+    0x2da6f447a2375ea1ULL, 0x1e74275dcd7d8576ULL,
+    0xbc20180a800bc5f8ULL, 0xb4a2f701b2dc65beULL,
+    0xe726946f981b6d66ULL, 0x48e6c453bf21c94cULL,
+    0x42cad9930f0a4195ULL, 0xefa47b64aacccd20ULL,
+    0x71180a8960409a42ULL, 0x8bb3329bf6a44e0cULL,
+    0xd34c35de2d36daccULL, 0xa92f5b7cbc23dc96ULL,
+    0xb31a85aa68bb09c3ULL, 0x13e04836a73161d2ULL,
+    0xb24dfc4129c51d02ULL, 0x8ae44b70b7da5acdULL,
+    0xe671ed84d96579a7ULL, 0xa4bb3417d66f3832ULL,
+    0x4572ab38d56d2de8ULL, 0xb1b47761ea47215cULL,
+    0xe81c09cf70aba15dULL, 0xffbdb872ce7f90acULL,
+    0xa8782297fd5dc857ULL, 0x0d946f6b6a4ce4a4ULL,
+    0xe4df1f4f5b995138ULL, 0x9ebc71edca8c5762ULL,
+    0x0a2c1dc0b02b88d9ULL, 0x3b503c115d9d7b91ULL,
+    0xc64376a8111ec3a2ULL, 0xcec199a323c963e4ULL,
+    0xdc76a87ec58616f7ULL, 0x09d596e073a9b487ULL,
+    0x14583a9d7d560dafULL, 0xf4c6dc593f2a0cb4ULL,
+    0xdd21d19584f80236ULL, 0x4a4836983ddde1d3ULL,
+    0xe58866a41ae745f9ULL, 0xf591a5b27e541875ULL,
+    0x891dc05074586693ULL, 0x5b068c651810a89eULL,
+    0xa30346bc0c08544fULL, 0x3dbf3751c684032dULL,
+    0x2a1e86ec785032dcULL, 0xf73f5779fca830eaULL,
+    0xb60c05ca30204d21ULL, 0x0cc316802b32f065ULL,
+    0x8770241bdd96be69ULL, 0xb861e18199ee95dbULL,
+    0xf805cad91418fcd1ULL, 0x29e70dccbbd20e82ULL,
+    0xc7140f435060d763ULL, 0x0f3a9da0e8b0cc3bULL,
+    0xa2543f574d76408eULL, 0xbd7761e1c175d139ULL,
+    0x4b1f4f737ca3f512ULL, 0x6dc2df1f2fc137abULL,
+    0xf1d05c3967b14856ULL, 0xa742bf3715ed046cULL,
+    0x654030141d1697edULL, 0x07b872abda676c7dULL,
+    0x3ce84eba87fa17ecULL, 0xc1fb0403cb79afdfULL,
+    0x3e46bc7105063f73ULL, 0x278ae987121cd678ULL,
+    0xa1adb4778ef47cd0ULL, 0x26dd906c5362c2b9ULL,
+    0x05168060589b44e2ULL, 0xfbfc41f9d79ac08fULL,
+    0x0e6de44ba9ced8faULL, 0x9feb08068bf243a3ULL,
+    0x7b341749d06b129bULL, 0x229c69e74a87929aULL,
+    0xe09ee6c4427c011bULL, 0x5692e30e725c4c3aULL,
+    0xda99a33e5e9f6e4bULL, 0x353dd85af453a36bULL,
+    0x25241b4c90e0fee7ULL, 0x5de987258309d022ULL,
+    0xe230140fc0802984ULL, 0x93281e86a0c0b3c6ULL,
+    0xf229d719a4337408ULL, 0x6f6c2dd4ad3d1f34ULL,
+    0x8ea5b2fbae3f0aeeULL, 0x8331dd90c473ee4aULL,
+    0x346aa1b1b52db7aaULL, 0xdf8f235e06042aa9ULL,
+    0xcc6f6b68a1354b7bULL, 0x6c95a6f46ebf236aULL,
+    0x52d31a856bb91c19ULL, 0x1a35ded6d498d555ULL,
+    0xf37eaef2e54d60c9ULL, 0x72e181a9a3c2a61cULL,
+    0x98537aad51952fdeULL, 0x16f6c856ffaa2530ULL,
+    0xd960281e9d1d5215ULL, 0x3a0745fa1ce36f50ULL,
+    0x0b7b642bf1559c18ULL, 0x59a87eae9aec8001ULL,
+    0x5e100c05408bec7cULL, 0x0441f98b19e55023ULL,
+    0xd70dcc5534d38aefULL, 0x927f676de1bea707ULL,
+    0x9769e70db925e3e5ULL, 0x7a636ea29115065aULL,
+    0x468b201816ef11b6ULL, 0xab81a9b73edff409ULL,
+    0xc0ac7de88a07bb1eULL, 0x1f235eb68c0391b7ULL,
+    0x6056b074458dd30fULL, 0xbe8eeac102f7ed67ULL,
+    0xcd381283e04b5fbaULL, 0x5cbefecec277c4e3ULL,
+    0xd21b4c356c48ce0dULL, 0x1019c31664b35d8cULL,
+    0x247362a7d19eea26ULL, 0xebe582efb3299d03ULL,
+    0x02aef2cb82fc289fULL, 0x86275df09ce8aaa8ULL,
+    0x28b07427faac1a43ULL, 0x38a9b7319e1f47cfULL,
+    0xc82e92e3b8d01b58ULL, 0x06ef0b409b1978bcULL,
+    0x62f842bfc771fb90ULL, 0x9904034610eb3b1fULL,
+    0xded85ab5477a3e68ULL, 0x90d195a663428f98ULL,
+    0x5384636e2ac708d8ULL, 0xcbd719c37b522706ULL,
+    0xae9729d76644b0ebULL, 0x7c8c65e20a0c7ee6ULL,
+    0x80c856b007f1d214ULL, 0x8c0b40302cc32271ULL,
+    0xdbcedad51fe17a8aULL, 0x740e8ae938dbdea0ULL,
+    0xa615c6dc549310adULL, 0x19cc55f6171ae90bULL,
+    0x49b1bdb8fe5fdd8dULL, 0xed0a89af2830e5bfULL,
+    0x6a7aadb4f5a65bd6ULL, 0x7e22972988f05679ULL,
+    0xf952b3325566e810ULL, 0x39fecedadf61530eULL,
+    0x6101c99f04f3c7ceULL, 0x2e5f7f6761b562ffULL,
+    0xf08725d226cf5c97ULL, 0x63af3b54860fef51ULL,
+    0x8ff2cb10ef411e2fULL, 0x884ab9bb35267252ULL,
+    0x4df04433e7ba8daeULL, 0x9afd8866d3690741ULL,
+    0x66b9bb34de94abb3ULL, 0x9baaf18d92171380ULL,
+    0x543c11c5f0a064a5ULL, 0x17a1b1bdbed431f1ULL,
+    0xb5f58eeaf3a2717fULL, 0xc355f6c849858740ULL,
+    0xec5df044694ef17eULL, 0xd83751f5dc6346d4ULL,
+    0xfc4433520dfdacf2ULL, 0x0000000000000000ULL,
+    0x5a51f58e596ebc5fULL, 0x3285aaf12e34cf16ULL,
+    0x8d5c39db6dbd36b0ULL, 0x12b731dde64f7513ULL,
+    0x94906c2d7aa7dfbbULL, 0x302b583aacc8e789ULL,
+    0x9d45facd090e6b3cULL, 0x2165e2c78905aec4ULL,
+    0x68d45f7f775a7349ULL, 0x189b2c1d5664fdcaULL,
+    0xe1c99f2f030215daULL, 0x6983269436246788ULL,
+    0x8489af3b1e148237ULL, 0xe94b702431d5b59cULL,
+    0x33d2d31a6f4adbd7ULL, 0xbfd9932a4389f9a6ULL,
+    0xb0e30e8aab39359dULL, 0xd1e2c715afcaf253ULL,
+    0x150f43763c28196eULL, 0xc4ed846393e2eb3dULL,
+    0x03f98b20c3823c5eULL, 0xfd134ab94c83b833ULL,
+    0x556b682eb1de7064ULL, 0x36c4537a37d19f35ULL,
+    0x7559f30279a5ca61ULL, 0x799ae58252973a04ULL,
+    0x9c12832648707ffdULL, 0x78cd9c6913e92ec5ULL,
+    0x1d8dac7d0effb928ULL, 0x439da0784e745554ULL,
+    0x413352b3cc887dcbULL, 0xbacf134a1b12bd44ULL,
+    0x114ebafd25cd494dULL, 0x2f08068c20cb763eULL,
+    0x76a07822ba27f63fULL, 0xeab2fb04f25789c2ULL,
+    0xe3676de481fe3d45ULL, 0x1b62a73d95e6c194ULL,
+    0x641749ff5c68832cULL, 0xa5ec4dfc97112cf3ULL,
+    0xf6682e92bdd6242bULL, 0x3f11c59a44782bb2ULL,
+    0x317c21d1edb6f348ULL, 0xd65ab5be75ad9e2eULL,
+    0x6b2dd45fb4d84f17ULL, 0xfaab381296e4d44eULL,
+    0xd0b5befeeeb4e692ULL, 0x0882ef0b32d7a046ULL,
+    0x512a91a5a83b2047ULL, 0x963e9ee6f85bf724ULL,
+    0x4e09cf132438b1f0ULL, 0x77f701c9fb59e2feULL,
+    0x7ddb1c094b726a27ULL, 0x5f4775ee01f5f8bdULL,
+    0x9186ec4d223c9b59ULL, 0xfeeac1998f01846dULL,
+    0xac39db1ce4b89874ULL, 0xb75b7c21715e59e0ULL,
+    0xafc0503c273aa42aULL, 0x6e3b543fec430bf5ULL,
+    0x704f7362213e8e83ULL, 0x58ff0745db9294c0ULL,
+    0x67eec2df9feabf72ULL, 0xa0facd9ccf8a6811ULL,
+    0xb936986ad890811aULL, 0x95c715c63bd9cb7aULL,
+    0xca8060283a2c33c7ULL, 0x507de84ee9453486ULL,
+    0x85ded6d05f6a96f6ULL, 0x1cdad5964f81ade9ULL,
+    0xd5a33e9eb62fa270ULL, 0x40642b588df6690aULL,
+    0x7f75eec2c98e42b8ULL, 0x2cf18dace3494a60ULL,
+    0x23cb100c0bf9865bULL, 0xeef3028febb2d9e1ULL,
+    0x4425d2d394133929ULL, 0xaad6d05c7fa1e0c8ULL,
+    0xad6ea2f7a5c68cb5ULL, 0xc2028f2308fb9381ULL,
+    0x819f2f5b468fc6d5ULL, 0xc5bafd88d29cfffcULL,
+    0x47dc59f357910577ULL, 0x2b49ff07392e261dULL,
+    0x57c59ae5332258fbULL, 0x73b6f842e2bcb2ddULL,
+    0xcf96e04862b77725ULL, 0x4ca73dd8a6c4996fULL,
+    0x015779eb417e14c1ULL, 0x37932a9176af8bf4ULL },
+  /* 4 */
+  { 0x190a2c9b249df23eULL, 0x2f62f8b62263e1e9ULL,
+    0x7a7f754740993655ULL, 0x330b7ba4d5564d9fULL,
+    0x4c17a16a46672582ULL, 0xb22f08eb7d05f5b8ULL,
+    0x535f47f40bc148ccULL, 0x3aec5d27d4883037ULL,
+    0x10ed0a1825438f96ULL, 0x516101f72c233d17ULL,
+    0x13cc6f949fd04eaeULL, 0x739853c441474bfdULL,
+    0x653793d90d3f5b1bULL, 0x5240647b96b0fc2fULL,
+    0x0c84890ad27623e0ULL, 0xd7189b32703aaea3ULL,
+    0x2685de3523bd9c41ULL, 0x99317c5b11bffefaULL,
+    0x0d9baa854f079703ULL, 0x70b93648fbd48ac5ULL,
+    0xa80441fce30bc6beULL, 0x7287704bdc36ff1eULL,
+    0xb65384ed33dc1f13ULL, 0xd36417343ee34408ULL,
+    0x39cd38ab6e1bf10fULL, 0x5ab861770a1f3564ULL,
+    0x0ebacf09f594563bULL, 0xd04572b884708530ULL,
+    0x3cae9722bdb3af47ULL, 0x4a556b6f2f5cbaf2ULL,
+    0xe1704f1f76c4bd74ULL, 0x5ec4ed7144c6dfcfULL,
+    0x16afc01d4c7810e6ULL, 0x283f113cd629ca7aULL,
+    0xaf59a8761741ed2dULL, 0xeed5a3991e215facULL,
+    0x3bf37ea849f984d4ULL, 0xe413e096a56ce33cULL,
+    0x2c439d3a98f020d1ULL, 0x637559dc6404c46bULL,
+    0x9e6c95d1e5f5d569ULL, 0x24bb9836045fe99aULL,
+    0x44efa466dac8ecc9ULL, 0xc6eab2a5c80895d6ULL,
+    0x803b50c035220cc4ULL, 0x0321658cba93c138ULL,
+    0x8f9ebc465dc7ee1cULL, 0xd15a5137190131d3ULL,
+    0x0fa5ec8668e5e2d8ULL, 0x91c979578d1037b1ULL,
+    0x0642ca05693b9f70ULL, 0xefca80168350eb4fULL,
+    0x38d21b24f36a45ecULL, 0xbeab81e1af73d658ULL,
+    0x8cbfd9cae7542f24ULL, 0xfd19cc0d81f11102ULL,
+    0x0ac6430fbb4dbc90ULL, 0x1d76a09d6a441895ULL,
+    0x2a01573ff1cbbfa1ULL, 0xb572e161894fde2bULL,
+    0x8124734fa853b827ULL, 0x614b1fdf43e6b1b0ULL,
+    0x68ac395c4238cc18ULL, 0x21d837bfd7f7b7d2ULL,
+    0x20c714304a860331ULL, 0x5cfaab726324aa14ULL,
+    0x74c5ba4eb50d606eULL, 0xf3a3030474654739ULL,
+    0x23e671bcf015c209ULL, 0x45f087e947b9582aULL,
+    0xd8bd77b418df4c7bULL, 0xe06f6c90ebb50997ULL,
+    0x0bd96080263c0873ULL, 0x7e03f9410e40dcfeULL,
+    0xb8e94be4c6484928ULL, 0xfb5b0608e8ca8e72ULL,
+    0x1a2b49179e0e3306ULL, 0x4e29e76961855059ULL,
+    0x4f36c4e6fcf4e4baULL, 0x49740ee395cf7bcaULL,
+    0xc2963ea386d17f7dULL, 0x90d65ad810618352ULL,
+    0x12d34c1b02a1fa4dULL, 0xfa44258775bb3a91ULL,
+    0x18150f14b9ec46ddULL, 0x1491861e6b9a653dULL,
+    0x9a1019d7ab2c3fc2ULL, 0x3668d42d06fe13d7ULL,
+    0xdcc1fbb25606a6d0ULL, 0x969490dd795a1c22ULL,
+    0x3549b1a1bc6dd2efULL, 0xc94f5e23a0ed770eULL,
+    0xb9f6686b5b39fdcbULL, 0xc4d4f4a6efeae00dULL,
+    0xe732851a1fff2204ULL, 0x94aad6de5eb869f9ULL,
+    0x3f8ff2ae07206e7fULL, 0xfe38a9813b62d03aULL,
+    0xa7a1ad7a8bee2466ULL, 0x7b6056c8dde882b6ULL,
+    0x302a1e286fc58ca7ULL, 0x8da0fa457a259bc7ULL,
+    0xb3302b64e074415bULL, 0x5402ae7eff8b635fULL,
+    0x08f8050c9cafc94bULL, 0xae468bf98a3059ceULL,
+    0x88c355cca98dc58fULL, 0xb10e6d67c7963480ULL,
+    0xbad70de7e1aa3cf3ULL, 0xbfb4a26e320262bbULL,
+    0xcb711820870f02d5ULL, 0xce12b7a954a75c9dULL,
+    0x563ce87dd8691684ULL, 0x9f73b65e7884618aULL,
+    0x2b1e74b06cba0b42ULL, 0x47cec1ea605b2df1ULL,
+    0x1c698312f735ac76ULL, 0x5fdbcefed9b76b2cULL,
+    0x831a354c8fb1cdfcULL, 0x820516c312c0791fULL,
+    0xb74ca762aeadabf0ULL, 0xfc06ef821c80a5e1ULL,
+    0x5723cbf24518a267ULL, 0x9d4df05d5f661451ULL,
+    0x588627742dfd40bfULL, 0xda8331b73f3d39a0ULL,
+    0x17b0e392d109a405ULL, 0xf965400bcf28fba9ULL,
+    0x7c3dbf4229a2a925ULL, 0x023e460327e275dbULL,
+    0x6cd0b55a0ce126b3ULL, 0xe62da695828e96e7ULL,
+    0x42ad6e63b3f373b9ULL, 0xe50cc319381d57dfULL,
+    0xc5cbd729729b54eeULL, 0x46d1e265fd2a9912ULL,
+    0x6428b056904eeff8ULL, 0x8be23040131e04b7ULL,
+    0x6709d5da2add2ec0ULL, 0x075de98af44a2b93ULL,
+    0x8447dcc67bfbe66fULL, 0x6616f655b7ac9a23ULL,
+    0xd607b8bded4b1a40ULL, 0x0563af89d3a85e48ULL,
+    0x3db1b4ad20c21ba4ULL, 0x11f22997b8323b75ULL,
+    0x292032b34b587e99ULL, 0x7f1cdace9331681dULL,
+    0x8e819fc9c0b65affULL, 0xa1e3677fe2d5bb16ULL,
+    0xcd33d225ee349da5ULL, 0xd9a2543b85aef898ULL,
+    0x795e10cbfa0af76dULL, 0x25a4bbb9992e5d79ULL,
+    0x78413344677b438eULL, 0xf0826688cef68601ULL,
+    0xd27b34bba392f0ebULL, 0x551d8df162fad7bcULL,
+    0x1e57c511d0d7d9adULL, 0xdeffbdb171e4d30bULL,
+    0xf4feea8e802f6caaULL, 0xa480c8f6317de55eULL,
+    0xa0fc44f07fa40ff5ULL, 0x95b5f551c3c9dd1aULL,
+    0x22f952336d6476eaULL, 0x0000000000000000ULL,
+    0xa6be8ef5169f9085ULL, 0xcc2cf1aa73452946ULL,
+    0x2e7ddb39bf12550aULL, 0xd526dd3157d8db78ULL,
+    0x486b2d6c08becf29ULL, 0x9b0f3a58365d8b21ULL,
+    0xac78cdfaadd22c15ULL, 0xbc95c7e28891a383ULL,
+    0x6a927f5f65dab9c3ULL, 0xc3891d2c1ba0cb9eULL,
+    0xeaa92f9f50f8b507ULL, 0xcf0d9426c9d6e87eULL,
+    0xca6e3baf1a7eb636ULL, 0xab25247059980786ULL,
+    0x69b31ad3df4978fbULL, 0xe2512a93cc577c4cULL,
+    0xff278a0ea61364d9ULL, 0x71a615c766a53e26ULL,
+    0x89dc764334fc716cULL, 0xf87a638452594f4aULL,
+    0xf2bc208be914f3daULL, 0x8766b94ac1682757ULL,
+    0xbbc82e687cdb8810ULL, 0x626a7a53f9757088ULL,
+    0xa2c202f358467a2eULL, 0x4d0882e5db169161ULL,
+    0x09e7268301de7da8ULL, 0xe897699c771ac0dcULL,
+    0xc8507dac3d9cc3edULL, 0xc0a878a0a1330aa6ULL,
+    0x978bb352e42ba8c1ULL, 0xe9884a13ea6b743fULL,
+    0x279afdbabecc28a2ULL, 0x047c8c064ed9eaabULL,
+    0x507e2278b15289f4ULL, 0x599904fbb08cf45cULL,
+    0xbd8ae46d15e01760ULL, 0x31353da7f2b43844ULL,
+    0x8558ff49e68a528cULL, 0x76fbfc4d92ef15b5ULL,
+    0x3456922e211c660cULL, 0x86799ac55c1993b4ULL,
+    0x3e90d1219a51da9cULL, 0x2d5cbeb505819432ULL,
+    0x982e5fd48cce4a19ULL, 0xdb9c1238a24c8d43ULL,
+    0xd439febecaa96f9bULL, 0x418c0bef0960b281ULL,
+    0x158ea591f6ebd1deULL, 0x1f48e69e4da66d4eULL,
+    0x8afd13cf8e6fb054ULL, 0xf5e1c9011d5ed849ULL,
+    0xe34e091c5126c8afULL, 0xad67ee7530a398f6ULL,
+    0x43b24dec2e82c75aULL, 0x75da99c1287cd48dULL,
+    0x92e81cdb3783f689ULL, 0xa3dd217cc537cecdULL,
+    0x60543c50de970553ULL, 0x93f73f54aaf2426aULL,
+    0xa91b62737e7a725dULL, 0xf19d4507538732e2ULL,
+    0x77e4dfc20f9ea156ULL, 0x7d229ccdb4d31dc6ULL,
+    0x1b346a98037f87e5ULL, 0xedf4c615a4b29e94ULL,
+    0x4093286094110662ULL, 0xb0114ee85ae78063ULL,
+    0x6ff1d0d6b672e78bULL, 0x6dcf96d591909250ULL,
+    0xdfe09e3eec9567e8ULL, 0x3214582b4827f97cULL,
+    0xb46dc2ee143e6ac8ULL, 0xf6c0ac8da7cd1971ULL,
+    0xebb60c10cd8901e4ULL, 0xf7df8f023abcad92ULL,
+    0x9c52d3d2c217a0b2ULL, 0x6b8d5cd0f8ab0d20ULL,
+    0x3777f7a29b8fa734ULL, 0x011f238f9d71b4e3ULL,
+    0xc1b75b2f3c42be45ULL, 0x5de588fdfe551ef7ULL,
+    0x6eeef3592b035368ULL, 0xaa3a07ffc4e9b365ULL,
+    0xecebe59a39c32a77ULL, 0x5ba742f8976e8187ULL,
+    0x4b4a48e0b22d0e11ULL, 0xddded83dcb771233ULL,
+    0xa59feb79ac0c51bdULL, 0xc7f5912a55792135ULL },
+  /* 5 */
+  { 0x6d6ae04668a9b08aULL, 0x3ab3f04b0be8c743ULL,
+    0xe51e166b54b3c908ULL, 0xbe90a9eb35c2f139ULL,
+    0xb2c7066637f2bec1ULL, 0xaa6945613392202cULL,
+    0x9a28c36f3b5201ebULL, 0xddce5a93ab536994ULL,
+    0x0e34133ef6382827ULL, 0x52a02ba1ec55048bULL,
+    0xa2f88f97c4b2a177ULL, 0x8640e513ca2251a5ULL,
+    0xcdf1d36258137622ULL, 0xfe6cb708dedf8ddbULL,
+    0x8a174a9ec8121e5dULL, 0x679896036b81560eULL,
+    0x59ed033395795feeULL, 0x1dd778ab8b74edafULL,
+    0xee533ef92d9f926dULL, 0x2a8c79baf8a8d8f5ULL,
+    0x6bcf398e69b119f6ULL, 0xe20491742fafdd95ULL,
+    0x276488e0809c2aecULL, 0xea955b82d88f5cceULL,
+    0x7102c63a99d9e0c4ULL, 0xf9763017a5c39946ULL,
+    0x429fa2501f151b3dULL, 0x4659c72bea05d59eULL,
+    0x984b7fdccf5a6634ULL, 0xf742232953fbb161ULL,
+    0x3041860e08c021c7ULL, 0x747bfd9616cd9386ULL,
+    0x4bb1367192312787ULL, 0x1b72a1638a6c44d3ULL,
+    0x4a0e68a6e8359a66ULL, 0x169a5039f258b6caULL,
+    0xb98a2ef44edee5a4ULL, 0xd9083fe85e43a737ULL,
+    0x967f6ce239624e13ULL, 0x8874f62d3c1a7982ULL,
+    0x3c1629830af06e3fULL, 0x9165ebfd427e5a8eULL,
+    0xb5dd81794ceeaa5cULL, 0x0de8f15a7834f219ULL,
+    0x70bd98ede3dd5d25ULL, 0xaccc9ca9328a8950ULL,
+    0x56664eda1945ca28ULL, 0x221db34c0f8859aeULL,
+    0x26dbd637fa98970dULL, 0x1acdffb4f068f932ULL,
+    0x4585254f64090fa0ULL, 0x72de245e17d53afaULL,
+    0x1546b25d7c546cf4ULL, 0x207e0ffffb803e71ULL,
+    0xfaaad2732bcf4378ULL, 0xb462dfae36ea17bdULL,
+    0xcf926fd1ac1b11fdULL, 0xe0672dc7dba7ba4aULL,
+    0xd3fa49ad5d6b41b3ULL, 0x8ba81449b216a3bcULL,
+    0x14f9ec8a0650d115ULL, 0x40fc1ee3eb1d7ce2ULL,
+    0x23a2ed9b758ce44fULL, 0x782c521b14fddc7eULL,
+    0x1c68267cf170504eULL, 0xbcf31558c1ca96e6ULL,
+    0xa781b43b4ba6d235ULL, 0xf6fd7dfe29ff0c80ULL,
+    0xb0a4bad5c3fad91eULL, 0xd199f51ea963266cULL,
+    0x414340349119c103ULL, 0x5405f269ed4dadf7ULL,
+    0xabd61bb649969dcdULL, 0x6813dbeae7bdc3c8ULL,
+    0x65fb2ab09f8931d1ULL, 0xf1e7fae152e3181dULL,
+    0xc1a67cef5a2339daULL, 0x7a4feea8e0f5bba1ULL,
+    0x1e0b9acf05783791ULL, 0x5b8ebf8061713831ULL,
+    0x80e53cdbcb3af8d9ULL, 0x7e898bd315e57502ULL,
+    0xc6bcfbf0213f2d47ULL, 0x95a38e86b76e942dULL,
+    0x092e94218d243cbaULL, 0x8339debf453622e7ULL,
+    0xb11be402b9fe64ffULL, 0x57d9100d634177c9ULL,
+    0xcc4e8db52217cbc3ULL, 0x3b0cae9c71ec7aa2ULL,
+    0xfb158ca451cbfe99ULL, 0x2b33276d82ac6514ULL,
+    0x01bf5ed77a04bde1ULL, 0xc5601994af33f779ULL,
+    0x75c4a3416cc92e67ULL, 0xf3844652a6eb7fc2ULL,
+    0x3487e375fdd0ef64ULL, 0x18ae430704609eedULL,
+    0x4d14efb993298efbULL, 0x815a620cb13e4538ULL,
+    0x125c354207487869ULL, 0x9eeea614ce42cf48ULL,
+    0xce2d3106d61fac1cULL, 0xbbe99247bad6827bULL,
+    0x071a871f7b1c149dULL, 0x2e4a1cc10db81656ULL,
+    0x77a71ff298c149b8ULL, 0x06a5d9c80118a97cULL,
+    0xad73c27e488e34b1ULL, 0x443a7b981e0db241ULL,
+    0xe3bbcfa355ab6074ULL, 0x0af276450328e684ULL,
+    0x73617a896dd1871bULL, 0x58525de4ef7de20fULL,
+    0xb7be3dcab8e6cd83ULL, 0x19111dd07e64230cULL,
+    0x842359a03e2a367aULL, 0x103f89f1f3401fb6ULL,
+    0xdc710444d157d475ULL, 0xb835702334da5845ULL,
+    0x4320fc876511a6dcULL, 0xd026abc9d3679b8dULL,
+    0x17250eee885c0b2bULL, 0x90dab52a387ae76fULL,
+    0x31fed8d972c49c26ULL, 0x89cba8fa461ec463ULL,
+    0x2ff5421677bcabb7ULL, 0x396f122f85e41d7dULL,
+    0xa09b332430bac6a8ULL, 0xc888e8ced7070560ULL,
+    0xaeaf201ac682ee8fULL, 0x1180d7268944a257ULL,
+    0xf058a43628e7a5fcULL, 0xbd4c4b8fbbce2b07ULL,
+    0xa1246df34abe7b49ULL, 0x7d5569b79be9af3cULL,
+    0xa9b5a705bd9efa12ULL, 0xdb6b835baa4bc0e8ULL,
+    0x05793bac8f147342ULL, 0x21c1512881848390ULL,
+    0xfdb0556c50d357e5ULL, 0x613d4fcb6a99ff72ULL,
+    0x03dce2648e0cda3eULL, 0xe949b9e6568386f0ULL,
+    0xfc0f0bbb2ad7ea04ULL, 0x6a70675913b5a417ULL,
+    0x7f36d5046fe1c8e3ULL, 0x0c57af8d02304ff8ULL,
+    0x32223abdfcc84618ULL, 0x0891caf6f720815bULL,
+    0xa63eeaec31a26fd4ULL, 0x2507345374944d33ULL,
+    0x49d28ac266394058ULL, 0xf5219f9aa7f3d6beULL,
+    0x2d96fea583b4cc68ULL, 0x5a31e1571b7585d0ULL,
+    0x8ed12fe53d02d0feULL, 0xdfade6205f5b0e4bULL,
+    0x4cabb16ee92d331aULL, 0x04c6657bf510cea3ULL,
+    0xd73c2cd6a87b8f10ULL, 0xe1d87310a1a307abULL,
+    0x6cd5be9112ad0d6bULL, 0x97c032354366f3f2ULL,
+    0xd4e0ceb22677552eULL, 0x0000000000000000ULL,
+    0x29509bde76a402cbULL, 0xc27a9e8bd42fe3e4ULL,
+    0x5ef7842cee654b73ULL, 0xaf107ecdbc86536eULL,
+    0x3fcacbe784fcb401ULL, 0xd55f90655c73e8cfULL,
+    0xe6c2f40fdabf1336ULL, 0xe8f6e7312c873b11ULL,
+    0xeb2a0555a28be12fULL, 0xe4a148bc2eb774e9ULL,
+    0x9b979db84156bc0aULL, 0x6eb60222e6a56ab4ULL,
+    0x87ffbbc4b026ec44ULL, 0xc703a5275b3b90a6ULL,
+    0x47e699fc9001687fULL, 0x9c8d1aa73a4aa897ULL,
+    0x7cea3760e1ed12ddULL, 0x4ec80ddd1d2554c5ULL,
+    0x13e36b957d4cc588ULL, 0x5d2b66486069914dULL,
+    0x92b90999cc7280b0ULL, 0x517cc9c56259deb5ULL,
+    0xc937b619ad03b881ULL, 0xec30824ad997f5b2ULL,
+    0xa45d565fc5aa080bULL, 0xd6837201d27f32f1ULL,
+    0x635ef3789e9198adULL, 0x531f75769651b96aULL,
+    0x4f77530a6721e924ULL, 0x486dd4151c3dfdb9ULL,
+    0x5f48dafb9461f692ULL, 0x375b011173dc355aULL,
+    0x3da9775470f4d3deULL, 0x8d0dcd81b30e0ac0ULL,
+    0x36e45fc609d888bbULL, 0x55baacbe97491016ULL,
+    0x8cb29356c90ab721ULL, 0x76184125e2c5f459ULL,
+    0x99f4210bb55edbd5ULL, 0x6f095cf59ca1d755ULL,
+    0x9f51f8c3b44672a9ULL, 0x3538bda287d45285ULL,
+    0x50c39712185d6354ULL, 0xf23b1885dcefc223ULL,
+    0x79930ccc6ef9619fULL, 0xed8fdc9da3934853ULL,
+    0xcb540aaa590bdf5eULL, 0x5c94389f1a6d2cacULL,
+    0xe77daad8a0bbaed7ULL, 0x28efc5090ca0bf2aULL,
+    0xbf2ff73c4fc64cd8ULL, 0xb37858b14df60320ULL,
+    0xf8c96ec0dfc724a7ULL, 0x828680683f329f06ULL,
+    0x941cd051cd6a29ccULL, 0xc3c5c05cae2b5e05ULL,
+    0xb601631dc2e27062ULL, 0xc01922382027843bULL,
+    0x24b86a840e90f0d2ULL, 0xd245177a276ffc52ULL,
+    0x0f8b4de98c3c95c6ULL, 0x3e759530fef809e0ULL,
+    0x0b4d2892792c5b65ULL, 0xc4df4743d5374a98ULL,
+    0xa5e20888bfaeb5eaULL, 0xba56cc90c0d23f9aULL,
+    0x38d04cf8ffe0a09cULL, 0x62e1adafe495254cULL,
+    0x0263bcb3f40867dfULL, 0xcaeb547d230f62bfULL,
+    0x6082111c109d4293ULL, 0xdad4dd8cd04f7d09ULL,
+    0xefec602e579b2f8cULL, 0x1fb4c4187f7c8a70ULL,
+    0xffd3e9dfa4db303aULL, 0x7bf0b07f9af10640ULL,
+    0xf49ec14dddf76b5fULL, 0x8f6e713247066d1fULL,
+    0x339d646a86ccfbf9ULL, 0x64447467e58d8c30ULL,
+    0x2c29a072f9b07189ULL, 0xd8b7613f24471ad6ULL,
+    0x6627c8d41185ebefULL, 0xa347d140beb61c96ULL,
+    0xde12b8f7255fb3aaULL, 0x9d324470404e1576ULL,
+    0x9306574eb6763d51ULL, 0xa80af9d2c79a47f3ULL,
+    0x859c0777442e8b9bULL, 0x69ac853d9db97e29ULL },
+  /* 6 */
+  { 0xc3407dfc2de6377eULL, 0x5b9e93eea4256f77ULL,
+    0xadb58fdd50c845e0ULL, 0x5219ff11a75bed86ULL,
+    0x356b61cfd90b1de9ULL, 0xfb8f406e25abe037ULL,
+    0x7a5a0231c0f60796ULL, 0x9d3cd216e1f5020bULL,
+    0x0c6550fb6b48d8f3ULL, 0xf57508c427ff1c62ULL,
+    0x4ad35ffa71cb407dULL, 0x6290a2da1666aa6dULL,
+    0xe284ec2349355f9fULL, 0xb3c307c53d7c84ecULL,
+    0x05e23c0468365a02ULL, 0x190bac4d6c9ebfa8ULL,
+    0x94bbbee9e28b80faULL, 0xa34fc777529cb9b5ULL,
+    0xcc7b39f095bcd978ULL, 0x2426addb0ce532e3ULL,
+    0x7e79329312ce4fc7ULL, 0xab09a72eebec2917ULL,
+    0xf8d15499f6b9d6c2ULL, 0x1a55b8babf8c895dULL,
+    0xdb8add17fb769a85ULL, 0xb57f2f368658e81bULL,
+    0x8acd36f18f3f41f6ULL, 0x5ce3b7bba50f11d3ULL,
+    0x114dcc14d5ee2f0aULL, 0xb91a7fcded1030e8ULL,
+    0x81d5425fe55de7a1ULL, 0xb6213bc1554adeeeULL,
+    0x80144ef95f53f5f2ULL, 0x1e7688186db4c10cULL,
+    0x3b912965db5fe1bcULL, 0xc281715a97e8252dULL,
+    0x54a5d7e21c7f8171ULL, 0x4b12535ccbc5522eULL,
+    0x1d289cefbea6f7f9ULL, 0x6ef5f2217d2e729eULL,
+    0xe6a7dc819b0d17ceULL, 0x1b94b41c05829b0eULL,
+    0x33d7493c622f711eULL, 0xdcf7f942fa5ce421ULL,
+    0x600fba8b7f7a8ecbULL, 0x46b60f011a83988eULL,
+    0x235b898e0dcf4c47ULL, 0x957ab24f588592a9ULL,
+    0x4354330572b5c28cULL, 0xa5f3ef84e9b8d542ULL,
+    0x8c711e02341b2d01ULL, 0x0b1874ae6a62a657ULL,
+    0x1213d8e306fc19ffULL, 0xfe6d7c6a4d9dba35ULL,
+    0x65ed868f174cd4c9ULL, 0x88522ea0e6236550ULL,
+    0x899322065c2d7703ULL, 0xc01e690bfef4018bULL,
+    0x915982ed8abddaf8ULL, 0xbe675b98ec3a4e4cULL,
+    0xa996bf7f82f00db1ULL, 0xe1daf8d49a27696aULL,
+    0x2effd5d3dc8986e7ULL, 0xd153a51f2b1a2e81ULL,
+    0x18caa0ebd690adfbULL, 0x390e3134b243c51aULL,
+    0x2778b92cdff70416ULL, 0x029f1851691c24a6ULL,
+    0x5e7cafeacc133575ULL, 0xfa4e4cc89fa5f264ULL,
+    0x5a5f9f481e2b7d24ULL, 0x484c47ab18d764dbULL,
+    0x400a27f2a1a7f479ULL, 0xaeeb9b2a83da7315ULL,
+    0x721c626879869734ULL, 0x042330a2d2384851ULL,
+    0x85f672fd3765aff0ULL, 0xba446b3a3e02061dULL,
+    0x73dd6ecec3888567ULL, 0xffac70ccf793a866ULL,
+    0xdfa9edb5294ed2d4ULL, 0x6c6aea7014325638ULL,
+    0x834a5a0e8c41c307ULL, 0xcdba35562fb2cb2bULL,
+    0x0ad97808d06cb404ULL, 0x0f3b440cb85aee06ULL,
+    0xe5f9c876481f213bULL, 0x98deee1289c35809ULL,
+    0x59018bbfcd394bd1ULL, 0xe01bf47220297b39ULL,
+    0xde68e1139340c087ULL, 0x9fa3ca4788e926adULL,
+    0xbb85679c840c144eULL, 0x53d8f3b71d55ffd5ULL,
+    0x0da45c5dd146caa0ULL, 0x6f34fe87c72060cdULL,
+    0x57fbc315cf6db784ULL, 0xcee421a1fca0fddeULL,
+    0x3d2d0196607b8d4bULL, 0x642c8a29ad42c69aULL,
+    0x14aff010bdd87508ULL, 0xac74837beac657b3ULL,
+    0x3216459ad821634dULL, 0x3fb219c70967a9edULL,
+    0x06bc28f3bb246cf7ULL, 0xf2082c9126d562c6ULL,
+    0x66b39278c45ee23cULL, 0xbd394f6f3f2878b9ULL,
+    0xfd33689d9e8f8cc0ULL, 0x37f4799eb017394fULL,
+    0x108cc0b26fe03d59ULL, 0xda4bd1b1417888d6ULL,
+    0xb09d1332ee6eb219ULL, 0x2f3ed975668794b4ULL,
+    0x58c0871977375982ULL, 0x7561463d78ace990ULL,
+    0x09876cff037e82f1ULL, 0x7fb83e35a8c05d94ULL,
+    0x26b9b58a65f91645ULL, 0xef20b07e9873953fULL,
+    0x3148516d0b3355b8ULL, 0x41cb2b541ba9e62aULL,
+    0x790416c613e43163ULL, 0xa011d380818e8f40ULL,
+    0x3a5025c36151f3efULL, 0xd57095bdf92266d0ULL,
+    0x498d4b0da2d97688ULL, 0x8b0c3a57353153a5ULL,
+    0x21c491df64d368e1ULL, 0x8f2f0af5e7091bf4ULL,
+    0x2da1c1240f9bb012ULL, 0xc43d59a92ccc49daULL,
+    0xbfa6573e56345c1fULL, 0x828b56a8364fd154ULL,
+    0x9a41f643e0df7cafULL, 0xbcf843c985266aeaULL,
+    0x2b1de9d7b4bfdce5ULL, 0x20059d79dedd7ab2ULL,
+    0x6dabe6d6ae3c446bULL, 0x45e81bf6c991ae7bULL,
+    0x6351ae7cac68b83eULL, 0xa432e32253b6c711ULL,
+    0xd092a9b991143cd2ULL, 0xcac711032e98b58fULL,
+    0xd8d4c9e02864ac70ULL, 0xc5fc550f96c25b89ULL,
+    0xd7ef8dec903e4276ULL, 0x67729ede7e50f06fULL,
+    0xeac28c7af045cf3dULL, 0xb15c1f945460a04aULL,
+    0x9cfddeb05bfb1058ULL, 0x93c69abce3a1fe5eULL,
+    0xeb0380dc4a4bdd6eULL, 0xd20db1e8f8081874ULL,
+    0x229a8528b7c15e14ULL, 0x44291750739fbc28ULL,
+    0xd3ccbd4e42060a27ULL, 0xf62b1c33f4ed2a97ULL,
+    0x86a8660ae4779905ULL, 0xd62e814a2a305025ULL,
+    0x477703a7a08d8addULL, 0x7b9b0e977af815c5ULL,
+    0x78c51a60a9ea2330ULL, 0xa6adfb733aaae3b7ULL,
+    0x97e5aa1e3199b60fULL, 0x0000000000000000ULL,
+    0xf4b404629df10e31ULL, 0x5564db44a6719322ULL,
+    0x9207961a59afec0dULL, 0x9624a6b88b97a45cULL,
+    0x363575380a192b1cULL, 0x2c60cd82b595a241ULL,
+    0x7d272664c1dc7932ULL, 0x7142769faa94a1c1ULL,
+    0xa1d0df263b809d13ULL, 0x1630e841d4c451aeULL,
+    0xc1df65ad44fa13d8ULL, 0x13d2d445bcf20bacULL,
+    0xd915c546926abe23ULL, 0x38cf3d92084dd749ULL,
+    0xe766d0272103059dULL, 0xc7634d5effde7f2fULL,
+    0x077d2455012a7ea4ULL, 0xedbfa82ff16fb199ULL,
+    0xaf2a978c39d46146ULL, 0x42953fa3c8bbd0dfULL,
+    0xcb061da59496a7dcULL, 0x25e7a17db6eb20b0ULL,
+    0x34aa6d6963050fbaULL, 0xa76cf7d580a4f1e4ULL,
+    0xf7ea10954ee338c4ULL, 0xfcf2643b24819e93ULL,
+    0xcf252d0746aeef8dULL, 0x4ef06f58a3f3082cULL,
+    0x563acfb37563a5d7ULL, 0x5086e740ce47c920ULL,
+    0x2982f186dda3f843ULL, 0x87696aac5e798b56ULL,
+    0x5d22bb1d1f010380ULL, 0x035e14f7d31236f5ULL,
+    0x3cec0d30da759f18ULL, 0xf3c920379cdb7095ULL,
+    0xb8db736b571e22bbULL, 0xdd36f5e44052f672ULL,
+    0xaac8ab8851e23b44ULL, 0xa857b3d938fe1fe2ULL,
+    0x17f1e4e76eca43fdULL, 0xec7ea4894b61a3caULL,
+    0x9e62c6e132e734feULL, 0xd4b1991b432c7483ULL,
+    0x6ad6c283af163acfULL, 0x1ce9904904a8e5aaULL,
+    0x5fbda34c761d2726ULL, 0xf910583f4cb7c491ULL,
+    0xc6a241f845d06d7cULL, 0x4f3163fe19fd1a7fULL,
+    0xe99c988d2357f9c8ULL, 0x8eee06535d0709a7ULL,
+    0x0efa48aa0254fc55ULL, 0xb4be23903c56fa48ULL,
+    0x763f52caabbedf65ULL, 0xeee1bcd8227d876cULL,
+    0xe345e085f33b4dccULL, 0x3e731561b369bbbeULL,
+    0x2843fd2067adea10ULL, 0x2adce5710eb1ceb6ULL,
+    0xb7e03767ef44ccbdULL, 0x8db012a48e153f52ULL,
+    0x61ceb62dc5749c98ULL, 0xe85d942b9959eb9bULL,
+    0x4c6f7709caef2c8aULL, 0x84377e5b8d6bbda3ULL,
+    0x30895dcbb13d47ebULL, 0x74a04a9bc2a2fbc3ULL,
+    0x6b17ce251518289cULL, 0xe438c4d0f2113368ULL,
+    0x1fb784bed7bad35fULL, 0x9b80fae55ad16efcULL,
+    0x77fe5e6c11b0cd36ULL, 0xc858095247849129ULL,
+    0x08466059b97090a2ULL, 0x01c10ca6ba0e1253ULL,
+    0x6988d6747c040c3aULL, 0x6849dad2c60a1e69ULL,
+    0x5147ebe67449db73ULL, 0xc99905f4fd8a837aULL,
+    0x991fe2b433cd4a5aULL, 0xf09734c04fc94660ULL,
+    0xa28ecbd1e892abe6ULL, 0xf1563866f5c75433ULL,
+    0x4dae7baf70e13ed9ULL, 0x7ce62ac27bd26b61ULL,
+    0x70837a39109ab392ULL, 0x90988e4b30b3c8abULL,
+    0xb2020b63877296bfULL, 0x156efcb607d6675bULL },
+  /* 7 */
+  { 0xe63f55ce97c331d0ULL, 0x25b506b0015bba16ULL,
+    0xc8706e29e6ad9ba8ULL, 0x5b43d3775d521f6aULL,
+    0x0bfa3d577035106eULL, 0xab95fc172afb0e66ULL,
+    0xf64b63979e7a3276ULL, 0xf58b4562649dad4bULL,
+    0x48f7c3dbae0c83f1ULL, 0xff31916642f5c8c5ULL,
+    0xcbb048dc1c4a0495ULL, 0x66b8f83cdf622989ULL,
+    0x35c130e908e2b9b0ULL, 0x7c761a61f0b34fa1ULL,
+    0x3601161cf205268dULL, 0x9e54ccfe2219b7d6ULL,
+    0x8b7d90a538940837ULL, 0x9cd403588ea35d0bULL,
+    0xbc3c6fea9ccc5b5aULL, 0xe5ff733b6d24aeedULL,
+    0xceed22de0f7eb8d2ULL, 0xec8581cab1ab545eULL,
+    0xb96105e88ff8e71dULL, 0x8ca03501871a5eadULL,
+    0x76ccce65d6db2a2fULL, 0x5883f582a7b58057ULL,
+    0x3f7be4ed2e8adc3eULL, 0x0fe7be06355cd9c9ULL,
+    0xee054e6c1d11be83ULL, 0x1074365909b903a6ULL,
+    0x5dde9f80b4813c10ULL, 0x4a770c7d02b6692cULL,
+    0x5379c8d5d7809039ULL, 0xb4067448161ed409ULL,
+    0x5f5e5026183bd6cdULL, 0xe898029bf4c29df9ULL,
+    0x7fb63c940a54d09cULL, 0xc5171f897f4ba8bcULL,
+    0xa6f28db7b31d3d72ULL, 0x2e4f3be7716eaa78ULL,
+    0x0d6771a099e63314ULL, 0x82076254e41bf284ULL,
+    0x2f0fd2b42733df98ULL, 0x5c9e76d3e2dc49f0ULL,
+    0x7aeb569619606cdbULL, 0x83478b07b2468764ULL,
+    0xcfadcb8d5923cd32ULL, 0x85dac7f05b95a41eULL,
+    0xb5469d1b4043a1e9ULL, 0xb821ecbbd9a592fdULL,
+    0x1b8e0b0e798c13c8ULL, 0x62a57b6d9a0be02eULL,
+    0xfcf1b793b81257f8ULL, 0x9d94ea0bd8fe28ebULL,
+    0x4cea408aeb654a56ULL, 0x23284a47e888996cULL,
+    0x2d8f1d128b893545ULL, 0xf4cbac3132c0d8abULL,
+    0xbd7c86b9ca912ebaULL, 0x3a268eef3dbe6079ULL,
+    0xf0d62f6077a9110cULL, 0x2735c916ade150cbULL,
+    0x89fd5f03942ee2eaULL, 0x1acee25d2fd16628ULL,
+    0x90f39bab41181bffULL, 0x430dfe8cde39939fULL,
+    0xf70b8ac4c8274796ULL, 0x1c53aeaac6024552ULL,
+    0x13b410acf35e9c9bULL, 0xa532ab4249faa24fULL,
+    0x2b1251e5625a163fULL, 0xd7e3e676da4841c7ULL,
+    0xa7b264e4e5404892ULL, 0xda8497d643ae72d3ULL,
+    0x861ae105a1723b23ULL, 0x38a6414991048aa4ULL,
+    0x6578dec92585b6b4ULL, 0x0280cfa6acbaeaddULL,
+    0x88bdb650c273970aULL, 0x9333bd5ebbff84c2ULL,
+    0x4e6a8f2c47dfa08bULL, 0x321c954db76cef2aULL,
+    0x418d312a72837942ULL, 0xb29b38bfffcdf773ULL,
+    0x6c022c38f90a4c07ULL, 0x5a033a240b0f6a8aULL,
+    0x1f93885f3ce5da6fULL, 0xc38a537e96988bc6ULL,
+    0x39e6a81ac759ff44ULL, 0x29929e43cee0fce2ULL,
+    0x40cdd87924de0ca2ULL, 0xe9d8ebc8a29fe819ULL,
+    0x0c2798f3cfbb46f4ULL, 0x55e484223e53b343ULL,
+    0x4650948ecd0d2fd8ULL, 0x20e86cb2126f0651ULL,
+    0x6d42c56baf5739e7ULL, 0xa06fc1405ace1e08ULL,
+    0x7babbfc54f3d193bULL, 0x424d17df8864e67fULL,
+    0xd8045870ef14980eULL, 0xc6d7397c85ac3781ULL,
+    0x21a885e1443273b1ULL, 0x67f8116f893f5c69ULL,
+    0x24f5efe35706cff6ULL, 0xd56329d076f2ab1aULL,
+    0x5e1eb9754e66a32dULL, 0x28d2771098bd8902ULL,
+    0x8f6013f47dfdc190ULL, 0x17a993fdb637553cULL,
+    0xe0a219397e1012aaULL, 0x786b9930b5da8606ULL,
+    0x6e82e39e55b0a6daULL, 0x875a0856f72f4ec3ULL,
+    0x3741ff4fa458536dULL, 0xac4859b3957558fcULL,
+    0x7ef6d5c75c09a57cULL, 0xc04a758b6c7f14fbULL,
+    0xf9acdd91ab26ebbfULL, 0x7391a467c5ef9668ULL,
+    0x335c7c1ee1319acaULL, 0xa91533b18641e4bbULL,
+    0xe4bf9a683b79db0dULL, 0x8e20faa72ba0b470ULL,
+    0x51f907737b3a7ae4ULL, 0x2268a314bed5ec8cULL,
+    0xd944b123b949edeeULL, 0x31dcb3b84d8b7017ULL,
+    0xd3fe65279f218860ULL, 0x097af2f1dc8ffab3ULL,
+    0x9b09a6fc312d0b91ULL, 0xcc6ded78a3c4520fULL,
+    0x3481d9ba5ebfcc50ULL, 0x4f2a667f1182d56bULL,
+    0xdfd9fdd4509ace94ULL, 0x26752045fbbc252bULL,
+    0xbffc491f662bc467ULL, 0xdd593272fc202449ULL,
+    0x3cbbc218d46d4303ULL, 0x91b372f817456e1fULL,
+    0x681faf69bc6385a0ULL, 0xb686bbeebaa43ed4ULL,
+    0x1469b5084cd0ca01ULL, 0x98c98009cbca94acULL,
+    0x6438379a73d8c354ULL, 0xc2caba2dc0c5fe26ULL,
+    0x3e3b0dbe78d7a9deULL, 0x50b9ee202d670f04ULL,
+    0x4590b27b37eab0e5ULL, 0x6025b4cb36b10af3ULL,
+    0xfb2c1237079c0162ULL, 0xa12f28130c936be8ULL,
+    0x4b37e52e54eb1cccULL, 0x083a1ba28ad28f53ULL,
+    0xc10a9cd83a22611bULL, 0x9f1425ad7444c236ULL,
+    0x069d4cf7e9d3237aULL, 0xedc56899e7f621beULL,
+    0x778c273680865fcfULL, 0x309c5aeb1bd605f7ULL,
+    0x8de0dc52d1472b4dULL, 0xf8ec34c2fd7b9e5fULL,
+    0xea18cd3d58787724ULL, 0xaad515447ca67b86ULL,
+    0x9989695a9d97e14cULL, 0x0000000000000000ULL,
+    0xf196c63321f464ecULL, 0x71116bc169557cb5ULL,
+    0xaf887f466f92c7c1ULL, 0x972e3e0ffe964d65ULL,
+    0x190ec4a8d536f915ULL, 0x95aef1a9522ca7b8ULL,
+    0xdc19db21aa7d51a9ULL, 0x94ee18fa0471d258ULL,
+    0x8087adf248a11859ULL, 0xc457f6da2916dd5cULL,
+    0xfa6cfb6451c17482ULL, 0xf256e0c6db13fbd1ULL,
+    0x6a9f60cf10d96f7dULL, 0x4daaa9d9bd383fb6ULL,
+    0x03c026f5fae79f3dULL, 0xde99148706c7bb74ULL,
+    0x2a52b8b6340763dfULL, 0x6fc20acd03edd33aULL,
+    0xd423c08320afdefaULL, 0xbbe1ca4e23420dc0ULL,
+    0x966ed75ca8cb3885ULL, 0xeb58246e0e2502c4ULL,
+    0x055d6a021334bc47ULL, 0xa47242111fa7d7afULL,
+    0xe3623fcc84f78d97ULL, 0x81c744a11efc6db9ULL,
+    0xaec8961539cfb221ULL, 0xf31609958d4e8e31ULL,
+    0x63e5923ecc5695ceULL, 0x47107ddd9b505a38ULL,
+    0xa3afe7b5a0298135ULL, 0x792b7063e387f3e6ULL,
+    0x0140e953565d75e0ULL, 0x12f4f9ffa503e97bULL,
+    0x750ce8902c3cb512ULL, 0xdbc47e8515f30733ULL,
+    0x1ed3610c6ab8af8fULL, 0x5239218681dde5d9ULL,
+    0xe222d69fd2aaf877ULL, 0xfe71783514a8bd25ULL,
+    0xcaf0a18f4a177175ULL, 0x61655d9860ec7f13ULL,
+    0xe77fbc9dc19e4430ULL, 0x2ccff441ddd440a5ULL,
+    0x16e97aaee06a20dcULL, 0xa855dae2d01c915bULL,
+    0x1d1347f9905f30b2ULL, 0xb7c652bdecf94b34ULL,
+    0xd03e43d265c6175dULL, 0xfdb15ec0ee4f2218ULL,
+    0x57644b8492e9599eULL, 0x07dda5a4bf8e569aULL,
+    0x54a46d71680ec6a3ULL, 0x5624a2d7c4b42c7eULL,
+    0xbebca04c3076b187ULL, 0x7d36f332a6ee3a41ULL,
+    0x3b6667bc6be31599ULL, 0x695f463aea3ef040ULL,
+    0xad08b0e0c3282d1cULL, 0xb15b1e4a052a684eULL,
+    0x44d05b2861b7c505ULL, 0x15295c5b1a8dbfe1ULL,
+    0x744c01c37a61c0f2ULL, 0x59c31cd1f1e8f5b7ULL,
+    0xef45a73f4b4ccb63ULL, 0x6bdf899c46841a9dULL,
+    0x3dfb2b4b823036e3ULL, 0xa2ef0ee6f674f4d5ULL,
+    0x184e2dfb836b8cf5ULL, 0x1134df0a5fe47646ULL,
+    0xbaa1231d751f7820ULL, 0xd17eaa81339b62bdULL,
+    0xb01bf71953771daeULL, 0x849a2ea30dc8d1feULL,
+    0x705182923f080955ULL, 0x0ea757556301ac29ULL,
+    0x041d83514569c9a7ULL, 0x0abad4042668658eULL,
+    0x49b72a88f851f611ULL, 0x8a3d79f66ec97dd7ULL,
+    0xcd2d042bf59927efULL, 0xc930877ab0f0ee48ULL,
+    0x9273540deda2f122ULL, 0xc797d02fd3f14261ULL,
+    0xe1e2f06a284d674aULL, 0xd2be8c74c97cfd80ULL,
+    0x9a494faf67707e71ULL, 0xb3dbd1eca9908293ULL,
+    0x72d14d3493b2e388ULL, 0xd6a30f258c153427ULL },
+};
+
+static const uint64_t C16[12][8] =
+{
+  { 0xdd806559f2a64507ULL, 0x05767436cc744d23ULL,
+    0xa2422a08a460d315ULL, 0x4b7ce09192676901ULL,
+    0x714eb88d7585c4fcULL, 0x2f6a76432e45d016ULL,
+    0xebcb2f81c0657c1fULL, 0xb1085bda1ecadae9ULL },
+  { 0xe679047021b19bb7ULL, 0x55dda21bd7cbcd56ULL,
+    0x5cb561c2db0aa7caULL, 0x9ab5176b12d69958ULL,
+    0x61d55e0f16b50131ULL, 0xf3feea720a232b98ULL,
+    0x4fe39d460f70b5d7ULL, 0x6fa3b58aa99d2f1aULL },
+  { 0x991e96f50aba0ab2ULL, 0xc2b6f443867adb31ULL,
+    0xc1c93a376062db09ULL, 0xd3e20fe490359eb1ULL,
+    0xf2ea7514b1297b7bULL, 0x06f15e5f529c1f8bULL,
+    0x0a39fc286a3d8435ULL, 0xf574dcac2bce2fc7ULL },
+  { 0x220cbebc84e3d12eULL, 0x3453eaa193e837f1ULL,
+    0xd8b71333935203beULL, 0xa9d72c82ed03d675ULL,
+    0x9d721cad685e353fULL, 0x488e857e335c3c7dULL,
+    0xf948e1a05d71e4ddULL, 0xef1fdfb3e81566d2ULL },
+  { 0x601758fd7c6cfe57ULL, 0x7a56a27ea9ea63f5ULL,
+    0xdfff00b723271a16ULL, 0xbfcd1747253af5a3ULL,
+    0x359e35d7800fffbdULL, 0x7f151c1f1686104aULL,
+    0x9a3f410c6ca92363ULL, 0x4bea6bacad474799ULL },
+  { 0xfa68407a46647d6eULL, 0xbf71c57236904f35ULL,
+    0x0af21f66c2bec6b6ULL, 0xcffaa6b71c9ab7b4ULL,
+    0x187f9ab49af08ec6ULL, 0x2d66c4f95142a46cULL,
+    0x6fa4c33b7a3039c0ULL, 0xae4faeae1d3ad3d9ULL },
+  { 0x8886564d3a14d493ULL, 0x3517454ca23c4af3ULL,
+    0x06476983284a0504ULL, 0x0992abc52d822c37ULL,
+    0xd3473e33197a93c9ULL, 0x399ec6c7e6bf87c9ULL,
+    0x51ac86febf240954ULL, 0xf4c70e16eeaac5ecULL },
+  { 0xa47f0dd4bf02e71eULL, 0x36acc2355951a8d9ULL,
+    0x69d18d2bd1a5c42fULL, 0xf4892bcb929b0690ULL,
+    0x89b4443b4ddbc49aULL, 0x4eb7f8719c36de1eULL,
+    0x03e7aa020c6e4141ULL, 0x9b1f5b424d93c9a7ULL },
+  { 0x7261445183235adbULL, 0x0e38dc92cb1f2a60ULL,
+    0x7b2b8a9aa6079c54ULL, 0x800a440bdbb2ceb1ULL,
+    0x3cd955b7e00d0984ULL, 0x3a7d3a1b25894224ULL,
+    0x944c9ad8ec165fdeULL, 0x378f5a541631229bULL },
+  { 0x74b4c7fb98459cedULL, 0x3698fad1153bb6c3ULL,
+    0x7a1e6c303b7652f4ULL, 0x9fe76702af69334bULL,
+    0x1fffe18a1b336103ULL, 0x8941e71cff8a78dbULL,
+    0x382ae548b2e4f3f3ULL, 0xabbedea680056f52ULL },
+  { 0x6bcaa4cd81f32d1bULL, 0xdea2594ac06fd85dULL,
+    0xefbacd1d7d476e98ULL, 0x8a1d71efea48b9caULL,
+    0x2001802114846679ULL, 0xd8fa6bbbebab0761ULL,
+    0x3002c6cd635afe94ULL, 0x7bcd9ed0efc889fbULL },
+  { 0x48bc924af11bd720ULL, 0xfaf417d5d9b21b99ULL,
+    0xe71da4aa88e12852ULL, 0x5d80ef9d1891cc86ULL,
+    0xf82012d430219f9bULL, 0xcda43c32bcdf1d77ULL,
+    0xd21380b00449b17aULL, 0x378ee767f11631baULL },
+};
+
+#define strido(out, temp, i) do { \
+	uint64_t t; \
+	t  = streebog_table[0][(temp[0] &gt;&gt; (i * 8)) &amp; 0xff]; \
+	t ^= streebog_table[1][(temp[1] &gt;&gt; (i * 8)) &amp; 0xff]; \
+	t ^= streebog_table[2][(temp[2] &gt;&gt; (i * 8)) &amp; 0xff]; \
+	t ^= streebog_table[3][(temp[3] &gt;&gt; (i * 8)) &amp; 0xff]; \
+	t ^= streebog_table[4][(temp[4] &gt;&gt; (i * 8)) &amp; 0xff]; \
+	t ^= streebog_table[5][(temp[5] &gt;&gt; (i * 8)) &amp; 0xff]; \
+	t ^= streebog_table[6][(temp[6] &gt;&gt; (i * 8)) &amp; 0xff]; \
+	t ^= streebog_table[7][(temp[7] &gt;&gt; (i * 8)) &amp; 0xff]; \
+	out[i] = t; } while(0)
+
+static void LPSX (uint64_t *out, const uint64_t *a, const uint64_t *b)
+{
+  uint64_t temp[8];
+  temp[0] = a[0] ^ b[0];
+  temp[1] = a[1] ^ b[1];
+  temp[2] = a[2] ^ b[2];
+  temp[3] = a[3] ^ b[3];
+  temp[4] = a[4] ^ b[4];
+  temp[5] = a[5] ^ b[5];
+  temp[6] = a[6] ^ b[6];
+  temp[7] = a[7] ^ b[7];
+  strido (out, temp, 0);
+  strido (out, temp, 1);
+  strido (out, temp, 2);
+  strido (out, temp, 3);
+  strido (out, temp, 4);
+  strido (out, temp, 5);
+  strido (out, temp, 6);
+  strido (out, temp, 7);
+}
+
+static inline void g (uint64_t *h, uint64_t *m, uint64_t *N)
+{
+  uint64_t K[8];
+  uint64_t T[8];
+  int i;
+
+  LPSX (K, h, N);
+
+  LPSX (T, K, m);
+  LPSX (K, K, C16[0]);
+  for (i = 1; i &lt; 12; i++)
+    {
+      LPSX (T, K, T);
+      LPSX (K, K, C16[i]);
+    }
+
+  h[0] ^= T[0] ^ K[0] ^ m[0];
+  h[1] ^= T[1] ^ K[1] ^ m[1];
+  h[2] ^= T[2] ^ K[2] ^ m[2];
+  h[3] ^= T[3] ^ K[3] ^ m[3];
+  h[4] ^= T[4] ^ K[4] ^ m[4];
+  h[5] ^= T[5] ^ K[5] ^ m[5];
+  h[6] ^= T[6] ^ K[6] ^ m[6];
+  h[7] ^= T[7] ^ K[7] ^ m[7];
+}
+
+
+static void
+streebog512_compress (struct streebog512_ctx *ctx, const uint8_t *input, size_t count)
+{
+  uint64_t M[8];
+  uint64_t l, cf;
+  int i;
+
+  for (i = 0; i &lt; 8; i++, input += 8)
+    M[i] = LE_READ_UINT64(input);
+
+  g (ctx-&gt;state, M, ctx-&gt;count);
+  l = ctx-&gt;count[0];
+  ctx-&gt;count[0] += count;
+  if (ctx-&gt;count[0] &lt; l)
+    { /* overflow */
+      for (i = 1; i &lt; 8; i++)
+        {
+          ctx-&gt;count[i]++;
+          if (ctx-&gt;count[i] != 0)
+            break;
+        }
+    }
+
+  cf = 0;
+  ctx-&gt;sigma[0] += M[0];
+  for (i = 1; i &lt; 8; i++)
+    {
+      if (ctx-&gt;sigma[i-1] != M[i-1])
+	cf = (ctx-&gt;sigma[i-1] &lt; M[i-1]);
+      ctx-&gt;sigma[i] += M[i] + cf;
+    }
+}
+
+static void
+streebog_final (struct streebog512_ctx *ctx)
+{
+  uint64_t Z[8] = {};
+  unsigned int i;
+
+  /* PAD. It does not count towards message length */
+  i = ctx-&gt;index;
+  /* We have at least one byte free) */
+  ctx-&gt;block[i++] = 1;
+  while (i &lt; 64)
+    ctx-&gt;block[i++] = 0;
+  streebog512_compress (ctx, ctx-&gt;block, ctx-&gt;index * 8);
+
+  g (ctx-&gt;state, ctx-&gt;count, Z);
+  g (ctx-&gt;state, ctx-&gt;sigma, Z);
+}
+
+#define COMPRESS(ctx, data) (streebog512_compress((ctx), (data), 64 * 8))
+
+void
+streebog512_init(struct streebog512_ctx *ctx)
+{
+  memset(ctx-&gt;state, 0, sizeof(ctx-&gt;state));
+  memset(ctx-&gt;count, 0, sizeof(ctx-&gt;count));
+  memset(ctx-&gt;sigma, 0, sizeof(ctx-&gt;sigma));
+
+  /* Initialize buffer */
+  ctx-&gt;index = 0;
+}
+
+void
+streebog512_update(struct streebog512_ctx *ctx,
+                   size_t length, const uint8_t *data)
+{
+  MD_UPDATE (ctx, length, data, COMPRESS, (void)0);
+}
+
+static void
+streebog512_write_digest(struct streebog512_ctx *ctx,
+                         size_t offset, size_t length,
+                         uint8_t *digest)
+{
+  unsigned i;
+  unsigned words;
+  unsigned leftover;
+
+  assert(offset + length &lt;= STREEBOG512_DIGEST_SIZE);
+
+  streebog_final(ctx);
+
+  words = length / 8;
+  leftover = length % 8;
+
+  for (i = 0; i &lt; words; i++, digest += 8)
+    LE_WRITE_UINT64(digest, ctx-&gt;state[offset + i]);
+
+  if (leftover)
+    {
+      /* Truncate to the right size */
+      uint64_t word = ctx-&gt;state[offset + i] &lt;&lt; (8*(8 - leftover));
+
+      do {
+	digest[--leftover] = (word &gt;&gt; 56) &amp; 0xff;
+	word &lt;&lt;= 8;
+      } while (leftover);
+    }
+}
+
+void
+streebog512_digest(struct streebog512_ctx *ctx,
+		   size_t length,
+		   uint8_t *digest)
+{
+  assert(length &lt;= STREEBOG512_DIGEST_SIZE);
+
+  streebog512_write_digest(ctx, 0, length, digest);
+  streebog512_init(ctx);
+}
+
+void
+streebog256_init(struct streebog256_ctx *ctx)
+{
+  memset(ctx-&gt;state, 1, sizeof(ctx-&gt;state));
+  memset(ctx-&gt;count, 0, sizeof(ctx-&gt;count));
+  memset(ctx-&gt;sigma, 0, sizeof(ctx-&gt;sigma));
+
+  /* Initialize buffer */
+  ctx-&gt;index = 0;
+}
+
+void
+streebog256_digest(struct streebog256_ctx *ctx,
+                   size_t length,
+                   uint8_t *digest)
+{
+  assert(length &lt;= STREEBOG256_DIGEST_SIZE);
+
+  streebog512_write_digest(ctx,
+      4,
+      length,
+      digest);
+  streebog256_init(ctx);
+}
diff --git a/streebog.h b/streebog.h
new file mode 100644
index 000000000000..69ac0d5c2746
--- /dev/null
+++ b/streebog.h
@@ -0,0 +1,99 @@
+/* streebog.h
+
+   The Streebog family of hash functions.
+
+   Copyright (C) 2020 Dmitry Baryshkov
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+ 
+#ifndef NETTLE_STREEBOG_H_INCLUDED
+#define NETTLE_STREEBOG_H_INCLUDED
+
+#include "nettle-types.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/* Name mangling */
+#define streebog256_init nettle_streebog256_init
+#define streebog256_digest nettle_streebog256_digest
+#define streebog512_init nettle_streebog512_init
+#define streebog512_update nettle_streebog512_update
+#define streebog512_digest nettle_streebog512_digest
+
+/* STREEBOG512 */
+
+#define STREEBOG512_DIGEST_SIZE 64
+#define STREEBOG512_BLOCK_SIZE 64
+
+/* Digest is kept internally as 8 64-bit words. */
+#define _STREEBOG512_DIGEST_LENGTH 8
+
+struct streebog512_ctx
+{
+  uint64_t state[_STREEBOG512_DIGEST_LENGTH];    /* State variables */
+  uint64_t count[_STREEBOG512_DIGEST_LENGTH];
+  uint64_t sigma[_STREEBOG512_DIGEST_LENGTH];
+  unsigned int index;                       /* index into buffer */
+  uint8_t block[STREEBOG512_BLOCK_SIZE];          /* STREEBOG512 data buffer */
+};
+
+void
+streebog512_init(struct streebog512_ctx *ctx);
+
+void
+streebog512_update(struct streebog512_ctx *ctx,
+	      size_t length,
+	      const uint8_t *data);
+
+void
+streebog512_digest(struct streebog512_ctx *ctx,
+	      size_t length,
+	      uint8_t *digest);
+
+
+#define STREEBOG256_DIGEST_SIZE 32
+#define STREEBOG256_BLOCK_SIZE STREEBOG512_BLOCK_SIZE
+#define streebog256_ctx streebog512_ctx
+
+void
+streebog256_init(struct streebog256_ctx *ctx);
+
+#define streebog256_update nettle_streebog512_update
+
+void
+streebog256_digest(struct streebog256_ctx *ctx,
+		  size_t length,
+		  uint8_t *digest);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* NETTLE_STREEBOG_H_INCLUDED */
-- 
2.26.2

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200701093633</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-07-01 09:36:33-0400</timestampReceived><subject>[PATCH] Add bcrypt tests to testsuite.</subject><body>

---
 testsuite/blowfish-test.c | 47 +++++++++++++++++++++++++++++++++++++++
 1 file changed, 47 insertions(+)

diff --git a/testsuite/blowfish-test.c b/testsuite/blowfish-test.c
index cadeda5f..c495b301 100644
--- a/testsuite/blowfish-test.c
+++ b/testsuite/blowfish-test.c
@@ -45,6 +45,22 @@ test_blowfish(const struct tstring *key,
   free(data);
 }
 
+static void
+test_bcrypt(int succeed, const struct tstring *key,
+	    const struct tstring *hash)
+{
+  if (succeed != blowfish_bcrypt_verify(key-&gt;length, key-&gt;data,
+                                       hash-&gt;length, hash-&gt;data))
+    {
+      fprintf(stderr, "blowfish_bcrypt_verify failed:\nKey:");
+      tstring_print_hex(key);
+      fprintf(stderr, "\nHash: ");
+      tstring_print_hex(hash);
+      fprintf(stderr, "\n");
+      FAIL();
+    }
+}
+
 void
 test_main(void)
 {
@@ -52,4 +68,35 @@ test_main(void)
   test_blowfish(SDATA("abcdefghijklmnopqrstuvwxyz"),
 		SDATA("BLOWFISH"),
 		SHEX("32 4E D0 FE F4 13 A2 03"));
+  /* Tests for BSD-style bcrypt.
+     From John the Ripper 1.7.9 via Phpass */
+  test_bcrypt(1, SDATA("U*U"), \
SDATA("$2a$05$CCCCCCCCCCCCCCCCCCCCC.E5YPO9kmyuRGyh0XouQYb4YMJKvyOeW")); +  \
test_bcrypt(1, SDATA("U*U*"), \
SDATA("$2a$05$CCCCCCCCCCCCCCCCCCCCC.VGOzA784oUp/Z0DY336zx7pLYAy0lwK")); +  \
test_bcrypt(1, SDATA("U*U*U"), \
SDATA("$2a$05$XXXXXXXXXXXXXXXXXXXXXOAcXxm9kjPGEMsLznoKqmqw7tc8WCx4a")); +  \
test_bcrypt(1, SDATA(""), \
SDATA("$2a$05$CCCCCCCCCCCCCCCCCCCCC.7uG0VCzI2bS7j6ymqJi9CdcdxiRTWNy")); +  \
test_bcrypt(1, SDATA("0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789chars \
after 72 are ignored"), \
SDATA("$2a$05$abcdefghijklmnopqrstuu5s2v8.iXieOjg/.AySBTTZIIVFJeBui")); +  \
test_bcrypt(1, SDATA("\xa3"), \
SDATA("$2x$05$/OK.fbVrR/bpIqNJ5ianF.CE5elHaaO4EbggVDjb8P19RukzXSM3e")); +  \
test_bcrypt(1, SDATA("\xa3"), \
SDATA("$2y$05$/OK.fbVrR/bpIqNJ5ianF.Sa7shbm4.OzKpvFnX1pQLmQW96oUlCq")); +  \
test_bcrypt(1, SDATA("\xd1\x91"), \
SDATA("$2x$05$6bNw2HLQYeqHYyBfLMsv/OiwqTymGIGzFsA4hOTWebfehXHNprcAS")); +  \
test_bcrypt(1, SDATA("\xd0\xc1\xd2\xcf\xcc\xd8"), \
SDATA("$2x$05$6bNw2HLQYeqHYyBfLMsv/O9LIGgn8OMzuDoHfof8AQimSGfcSWxnS")); +  \
test_bcrypt(1, SDATA("\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa \
\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\x \
aa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa\xaa""chars \
after 72 are ignored as usual"), \
SDATA("$2a$05$/OK.fbVrR/bpIqNJ5ianF.swQOIzjOiJ9GHEPuhEkvqrUyvWhEMx6")); +  \
test_bcrypt(1, SDATA("\xaa\x55\xaa\x55\xaa\x55\xaa\x55\xaa\x55\xaa\x55\xaa\x55\xaa\x55 \
\xaa\x55\xaa\x55\xaa\x55\xaa\x55\xaa\x55\xaa\x55\xaa\x55\xaa\x55\xaa\x55\xaa\x55\xaa\x \
55\xaa\x55\xaa\x55\xaa\x55\xaa\x55\xaa\x55\xaa\x55\xaa\x55\xaa\x55\xaa\x55\xaa\x55\xaa\x55\xaa\x55\xaa\x55\xaa\x55\xaa\x55\xaa\x55\xaa\x55"), \
SDATA("$2a$05$/OK.fbVrR/bpIqNJ5ianF.R9xrDjiycxMbQE2bp.vgqlYpW5wx2yy")); +  \
test_bcrypt(1, SDATA(""), \
SDATA("$2a$05$CCCCCCCCCCCCCCCCCCCCC.7uG0VCzI2bS7j6ymqJi9CdcdxiRTWNy")); +  \
test_bcrypt(1, SDATA("\x55\xaa\xff\x55\xaa\xff\x55\xaa\xff\x55\xaa\xff\x55\xaa\xff\x55 \
\xaa\xff\x55\xaa\xff\x55\xaa\xff\x55\xaa\xff\x55\xaa\xff\x55\xaa\xff\x55\xaa\xff\x55\x \
aa\xff\x55\xaa\xff\x55\xaa\xff\x55\xaa\xff\x55\xaa\xff\x55\xaa\xff\x55\xaa\xff\x55\xaa\xff\x55\xaa\xff\x55\xaa\xff\x55\xaa\xff\x55\xaa\xff"), \
SDATA("$2a$05$/OK.fbVrR/bpIqNJ5ianF.9tQZzcJfm3uj2NvJ/n5xkhpqLrMpWCe")); +  /* From \
Openwall's crypt v1.2 via Phpass */ +  test_bcrypt(0, SDATA(""), \
SDATA("$2a$03$CCCCCCCCCCCCCCCCCCCCC.")); +  test_bcrypt(0, SDATA(""), \
SDATA("$2a$32$CCCCCCCCCCCCCCCCCCCCC.")); +  test_bcrypt(0, SDATA(""), \
SDATA("$2z$05$CCCCCCCCCCCCCCCCCCCCC.")); +  test_bcrypt(0, SDATA(""), \
SDATA("$2`$05$CCCCCCCCCCCCCCCCCCCCC.")); +  test_bcrypt(0, SDATA(""), \
SDATA("$2{$05$CCCCCCCCCCCCCCCCCCCCC.")); +  /* Stephen's personal tests */
+  test_bcrypt(1, SDATA("yawinpassword"),
+     SDATA("$2a$04$MzVXtd4o0y4DOlyHMMLMDeE4/eezrsT5Xad.2lmGr/NkCpwBgvn3e"));
+  test_bcrypt(0, SDATA("xawinpassword"),
+     SDATA("$2a$04$MzVXtd4o0y4DOlyHMMLMDeE4/eezrsT5Xad.2lmGr/NkCpwBgvn3e"));
+  test_bcrypt(1, SDATA("Bootq9sH5"),
+     SDATA("$2y$10$1b2lPgo4XumibnJGN3r3sOsXFfVVYlebFjlw47qpaslC4KIwu9dAK"));
+  test_bcrypt(0, SDATA("Bootq9sH6"),
+     SDATA("$2y$10$1b2lPgo4XumibnJGN3r3sOsXFfVVYlebFjlw47qpaslC4KIwu9dAK"));
+  test_bcrypt(0, SDATA("1234"), SDATA("$2y$"));
 }
-- 
2.20.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200709063831</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-07-09 06:38:31-0400</timestampReceived><subject>[PATCH] Add missing undef directives in configure.ac"</subject><body>

---
 configure.ac | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/configure.ac b/configure.ac
index cc0d67ec..d7020fd6 100644
--- a/configure.ac
+++ b/configure.ac
@@ -582,7 +582,9 @@ AH_VERBATIM([HAVE_NATIVE],
 #undef HAVE_NATIVE_ecc_secp384r1_redc
 #undef HAVE_NATIVE_ecc_secp521r1_modp
 #undef HAVE_NATIVE_ecc_secp521r1_redc
+#undef HAVE_NATIVE_gcm_init_key8
 #undef HAVE_NATIVE_gcm_hash8
+#undef HAVE_NATIVE_gcm_fill
 #undef HAVE_NATIVE_salsa20_core
 #undef HAVE_NATIVE_sha1_compress
 #undef HAVE_NATIVE_sha256_compress
--
2.17.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200709061551</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-07-09 06:15:51-0400</timestampReceived><subject>[PATCH 3/4] Add test 128 bytes to gcm-test</subject><body>

---
 testsuite/gcm-test.c | 23 +++++++++++++++++++++++
 1 file changed, 23 insertions(+)

diff --git a/testsuite/gcm-test.c b/testsuite/gcm-test.c
index c8174019..df1fc94a 100644
--- a/testsuite/gcm-test.c
+++ b/testsuite/gcm-test.c
@@ -170,6 +170,29 @@ test_main(void)
  "16aedbf5a0de6a57a637b39b"),
     SHEX("619cc5aefffe0bfa462af43c1699d050"));

+  /* Test 128 bytes */
+  test_aead(&amp;nettle_gcm_aes128, NULL,
+    SHEX("feffe9928665731c6d6a8f9467308308"),
+    SHEX(""),
+    SHEX("d9313225f88406e5a55909c5aff5269a"
+ "86a7a9531534f7da2e4c303d8a318a72"
+ "1c3c0c95956809532fcf0e2449a6b525"
+ "b16aedf5aa0de657ba637b391aafd255"
+ "5ae376bc5e9f6a1b08e34db7a6ee0736"
+ "9ba662ea12f6f197e6bc3ed69d2480f3"
+ "ea5691347f2ba69113eb37910ebc18c8"
+ "0f697234582016fa956ca8f63ae6b473"),
+    SHEX("42831ec2217774244b7221b784d0d49c"
+ "e3aa212f2c02a4e035c17e2329aca12e"
+ "21d514b25466931c7d8f6a5aac84aa05"
+ "1ba30b396a0aac973d58e091473f5985"
+ "874b1178906ddbeab04ab2fe6cce8c57"
+ "8d7e961bd13fd6a8c56b66ca5e576492"
+ "1a48cd8bda04e66343e73055118b69b9"
+ "ced486813846958a11e602c03cfc232b"),
+    SHEX("cafebabefacedbaddecaf888"),
+    SHEX("796836f1246c9d735c5e1be0a715ccc3"));
+
   /* Test case 7 */
   test_aead(&amp;nettle_gcm_aes192, NULL,
     SHEX("00000000000000000000000000000000"
-- 
2.17.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200709061619</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-07-09 06:16:19-0400</timestampReceived><subject>[PATCH 4/4] Add AES [Enc|Dec] optimized implementations for PowerPC64</subject><body>

---
 powerpc64/aes-decrypt-internal.asm | 579
+++++++++++++++++++++++++++++++++++++
 powerpc64/aes-encrypt-internal.asm | 540 ++++++++++++++++++++++++++++++++++
 2 files changed, 1119 insertions(+)
 create mode 100644 powerpc64/aes-decrypt-internal.asm
 create mode 100644 powerpc64/aes-encrypt-internal.asm

diff --git a/powerpc64/aes-decrypt-internal.asm
b/powerpc64/aes-decrypt-internal.asm
new file mode 100644
index 00000000..b194d65f
--- /dev/null
+++ b/powerpc64/aes-decrypt-internal.asm
@@ -0,0 +1,579 @@
+C powerpc64/aes-decrypt-internal.asm
+
+ifelse(&lt;
+   Copyright (C) 2020 Mamone Tarsha
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+&gt;)
+
+C Register usage:
+
+define(&lt;SP&gt;, &lt;1&gt;)
+define(&lt;TOCP&gt;, &lt;2&gt;)
+
+define(&lt;ROUNDS&gt;, &lt;3&gt;)
+define(&lt;KEYS&gt;, &lt;4&gt;)
+define(&lt;LENGTH&gt;, &lt;6&gt;)
+define(&lt;DST&gt;, &lt;7&gt;)
+define(&lt;SRC&gt;, &lt;8&gt;)
+
+define(&lt;swap_mask&gt;, &lt;0&gt;)
+
+define(&lt;K&gt;, &lt;1&gt;)
+define(&lt;S0&gt;, &lt;2&gt;)
+define(&lt;S1&gt;, &lt;3&gt;)
+define(&lt;S2&gt;, &lt;4&gt;)
+define(&lt;S3&gt;, &lt;5&gt;)
+define(&lt;S4&gt;, &lt;6&gt;)
+define(&lt;S5&gt;, &lt;7&gt;)
+define(&lt;S6&gt;, &lt;8&gt;)
+define(&lt;S7&gt;, &lt;9&gt;)
+define(&lt;S8&gt;, &lt;10&gt;)
+define(&lt;S9&gt;, &lt;11&gt;)
+define(&lt;S10&gt;, &lt;12&gt;)
+define(&lt;S11&gt;, &lt;13&gt;)
+define(&lt;S12&gt;, &lt;14&gt;)
+define(&lt;S13&gt;, &lt;15&gt;)
+define(&lt;S14&gt;, &lt;16&gt;)
+define(&lt;S15&gt;, &lt;17&gt;)
+
+define(&lt;KX&gt;, &lt;33&gt;)
+define(&lt;S0X&gt;, &lt;34&gt;)
+define(&lt;S1X&gt;, &lt;35&gt;)
+define(&lt;S2X&gt;, &lt;36&gt;)
+define(&lt;S3X&gt;, &lt;37&gt;)
+define(&lt;S4X&gt;, &lt;38&gt;)
+define(&lt;S5X&gt;, &lt;39&gt;)
+define(&lt;S6X&gt;, &lt;40&gt;)
+define(&lt;S7X&gt;, &lt;41&gt;)
+define(&lt;S8X&gt;, &lt;42&gt;)
+define(&lt;S9X&gt;, &lt;43&gt;)
+define(&lt;S10X&gt;, &lt;44&gt;)
+define(&lt;S11X&gt;, &lt;45&gt;)
+define(&lt;S12X&gt;, &lt;46&gt;)
+define(&lt;S13X&gt;, &lt;47&gt;)
+define(&lt;S14X&gt;, &lt;48&gt;)
+define(&lt;S15X&gt;, &lt;49&gt;)
+
+C ZERO vector register is used in place of RoundKey
+C for vncipher instruction because the order of InvMixColumns
+C and Xor processes are flipped in that instruction.
+C The Xor process with RoundKey is executed afterward.
+define(&lt;ZERO&gt;, &lt;18&gt;)
+
+.file "aes-decrypt-internal.asm"
+
+IF_LE(&lt;.abiversion 2&gt;)
+.text
+
+ C _aes_decrypt(unsigned rounds, const uint32_t *keys,
+ C       const struct aes_table *T,
+ C       size_t length, uint8_t *dst,
+ C       uint8_t *src)
+
+PROLOGUE(_nettle_aes_decrypt)
+ vxor ZERO,ZERO,ZERO
+
+ ld 5,.swap_mask@got(TOCP)
+ lvx swap_mask,0,5
+
+ subi ROUNDS,ROUNDS,1
+ srdi LENGTH,LENGTH,4
+
+ srdi 5,LENGTH,4 #16x loop count
+ cmpldi 5,0
+ beq L8x
+
+ std 17,-120(SP);
+ std 18,-112(SP);
+ std 19,-104(SP);
+ std 20,-96(SP);
+ std 21,-88(SP);
+ std 22,-80(SP);
+ std 23,-72(SP);
+ std 24,-64(SP);
+ std 25,-56(SP);
+ std 26,-48(SP);
+ std 27,-40(SP);
+ std 28,-32(SP);
+ std 29,-24(SP);
+ std 30,-16(SP);
+ std 31,-8(SP);
+
+ li 17,0x10
+ li 18,0x20
+ li 19,0x30
+ li 20,0x40
+ li 21,0x50
+ li 22,0x60
+ li 23,0x70
+ li 24,0x80
+ li 25,0x90
+ li 26,0xA0
+ li 27,0xB0
+ li 28,0xC0
+ li 29,0xD0
+ li 30,0xE0
+ li 31,0xF0
+
+.align 5
+Lx16_loop:
+ lxvd2x KX,0,KEYS
+ vperm   K,K,K,swap_mask
+
+ lxvd2x S0X,0,SRC
+ lxvd2x S1X,17,SRC
+ lxvd2x S2X,18,SRC
+ lxvd2x S3X,19,SRC
+ lxvd2x S4X,20,SRC
+ lxvd2x S5X,21,SRC
+ lxvd2x S6X,22,SRC
+ lxvd2x S7X,23,SRC
+ lxvd2x S8X,24,SRC
+ lxvd2x S9X,25,SRC
+ lxvd2x S10X,26,SRC
+ lxvd2x S11X,27,SRC
+ lxvd2x S12X,28,SRC
+ lxvd2x S13X,29,SRC
+ lxvd2x S14X,30,SRC
+ lxvd2x S15X,31,SRC
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask
+ vperm S4,S4,S4,swap_mask
+ vperm S5,S5,S5,swap_mask
+ vperm S6,S6,S6,swap_mask
+ vperm S7,S7,S7,swap_mask
+ vperm S8,S8,S8,swap_mask
+ vperm S9,S9,S9,swap_mask
+ vperm S10,S10,S10,swap_mask
+ vperm S11,S11,S11,swap_mask
+ vperm S12,S12,S12,swap_mask
+ vperm S13,S13,S13,swap_mask
+ vperm S14,S14,S14,swap_mask
+ vperm S15,S15,S15,swap_mask&gt;)
+
+ vxor S0,S0,K
+ vxor S1,S1,K
+ vxor S2,S2,K
+ vxor S3,S3,K
+ vxor S4,S4,K
+ vxor S5,S5,K
+ vxor S6,S6,K
+ vxor S7,S7,K
+ vxor S8,S8,K
+ vxor S9,S9,K
+ vxor S10,S10,K
+ vxor S11,S11,K
+ vxor S12,S12,K
+ vxor S13,S13,K
+ vxor S14,S14,K
+ vxor S15,S15,K
+
+ mtctr ROUNDS
+ li 10,0x10
+.align 5
+L16x_round_loop:
+ lxvd2x KX,10,KEYS
+ vperm   K,K,K,swap_mask
+ vncipher S0,S0,ZERO
+ vncipher S1,S1,ZERO
+ vncipher S2,S2,ZERO
+ vncipher S3,S3,ZERO
+ vncipher S4,S4,ZERO
+ vncipher S5,S5,ZERO
+ vncipher S6,S6,ZERO
+ vncipher S7,S7,ZERO
+ vncipher S8,S8,ZERO
+ vncipher S9,S9,ZERO
+ vncipher S10,S10,ZERO
+ vncipher S11,S11,ZERO
+ vncipher S12,S12,ZERO
+ vncipher S13,S13,ZERO
+ vncipher S14,S14,ZERO
+ vncipher S15,S15,ZERO
+ vxor S0,S0,K
+ vxor S1,S1,K
+ vxor S2,S2,K
+ vxor S3,S3,K
+ vxor S4,S4,K
+ vxor S5,S5,K
+ vxor S6,S6,K
+ vxor S7,S7,K
+ vxor S8,S8,K
+ vxor S9,S9,K
+ vxor S10,S10,K
+ vxor S11,S11,K
+ vxor S12,S12,K
+ vxor S13,S13,K
+ vxor S14,S14,K
+ vxor S15,S15,K
+ addi 10,10,0x10
+ bdnz L16x_round_loop
+
+ lxvd2x KX,10,KEYS
+ vperm   K,K,K,swap_mask
+ vncipherlast S0,S0,K
+ vncipherlast S1,S1,K
+ vncipherlast S2,S2,K
+ vncipherlast S3,S3,K
+ vncipherlast S4,S4,K
+ vncipherlast S5,S5,K
+ vncipherlast S6,S6,K
+ vncipherlast S7,S7,K
+ vncipherlast S8,S8,K
+ vncipherlast S9,S9,K
+ vncipherlast S10,S10,K
+ vncipherlast S11,S11,K
+ vncipherlast S12,S12,K
+ vncipherlast S13,S13,K
+ vncipherlast S14,S14,K
+ vncipherlast S15,S15,K
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask
+ vperm S4,S4,S4,swap_mask
+ vperm S5,S5,S5,swap_mask
+ vperm S6,S6,S6,swap_mask
+ vperm S7,S7,S7,swap_mask
+ vperm S8,S8,S8,swap_mask
+ vperm S9,S9,S9,swap_mask
+ vperm S10,S10,S10,swap_mask
+ vperm S11,S11,S11,swap_mask
+ vperm S12,S12,S12,swap_mask
+ vperm S13,S13,S13,swap_mask
+ vperm S14,S14,S14,swap_mask
+ vperm S15,S15,S15,swap_mask&gt;)
+
+ stxvd2x S0X,0,DST
+ stxvd2x S1X,17,DST
+ stxvd2x S2X,18,DST
+ stxvd2x S3X,19,DST
+ stxvd2x S4X,20,DST
+ stxvd2x S5X,21,DST
+ stxvd2x S6X,22,DST
+ stxvd2x S7X,23,DST
+ stxvd2x S8X,24,DST
+ stxvd2x S9X,25,DST
+ stxvd2x S10X,26,DST
+ stxvd2x S11X,27,DST
+ stxvd2x S12X,28,DST
+ stxvd2x S13X,29,DST
+ stxvd2x S14X,30,DST
+ stxvd2x S15X,31,DST
+
+ addi SRC,SRC,0x100
+ addi DST,DST,0x100
+ subic. 5,5,1
+ bne Lx16_loop
+
+ ld 17,-120(SP);
+ ld 18,-112(SP);
+ ld 19,-104(SP);
+ ld 20,-96(SP);
+ ld 21,-88(SP);
+ ld 22,-80(SP);
+ ld 23,-72(SP);
+ ld 24,-64(SP);
+ ld 25,-56(SP);
+ ld 26,-48(SP);
+ ld 27,-40(SP);
+ ld 28,-32(SP);
+ ld 29,-24(SP);
+ ld 30,-16(SP);
+ ld 31,-8(SP);
+
+ clrldi LENGTH,LENGTH,60
+
+L8x:
+ srdi 5,LENGTH,3
+ cmpldi 5,0
+ beq L4x
+
+ lxvd2x KX,0,KEYS
+ vperm   K,K,K,swap_mask
+
+ lxvd2x S0X,0,SRC
+ li   9,0x10
+ lxvd2x S1X,9,SRC
+ addi   9,9,0x10
+ lxvd2x S2X,9,SRC
+ addi   9,9,0x10
+ lxvd2x S3X,9,SRC
+ addi  9,9,0x10
+ lxvd2x S4X,9,SRC
+ addi   9,9,0x10
+ lxvd2x S5X,9,SRC
+ addi   9,9,0x10
+ lxvd2x S6X,9,SRC
+ addi  9,9,0x10
+ lxvd2x S7X,9,SRC
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask
+ vperm S4,S4,S4,swap_mask
+ vperm S5,S5,S5,swap_mask
+ vperm S6,S6,S6,swap_mask
+ vperm S7,S7,S7,swap_mask&gt;)
+
+ vxor S0,S0,K
+ vxor S1,S1,K
+ vxor S2,S2,K
+ vxor S3,S3,K
+ vxor S4,S4,K
+ vxor S5,S5,K
+ vxor S6,S6,K
+ vxor S7,S7,K
+
+ mtctr ROUNDS
+ li 10,0x10
+.align 5
+L8x_round_loop:
+ lxvd2x KX,10,KEYS
+ vperm   K,K,K,swap_mask
+ vncipher S0,S0,ZERO
+ vncipher S1,S1,ZERO
+ vncipher S2,S2,ZERO
+ vncipher S3,S3,ZERO
+ vncipher S4,S4,ZERO
+ vncipher S5,S5,ZERO
+ vncipher S6,S6,ZERO
+ vncipher S7,S7,ZERO
+ vxor S0,S0,K
+ vxor S1,S1,K
+ vxor S2,S2,K
+ vxor S3,S3,K
+ vxor S4,S4,K
+ vxor S5,S5,K
+ vxor S6,S6,K
+ vxor S7,S7,K
+ addi 10,10,0x10
+ bdnz L8x_round_loop
+
+ lxvd2x  KX,10,KEYS
+ vperm       K,K,K,swap_mask
+ vncipherlast S0,S0,K
+ vncipherlast S1,S1,K
+ vncipherlast S2,S2,K
+ vncipherlast S3,S3,K
+ vncipherlast S4,S4,K
+ vncipherlast S5,S5,K
+ vncipherlast S6,S6,K
+ vncipherlast S7,S7,K
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask
+ vperm S4,S4,S4,swap_mask
+ vperm S5,S5,S5,swap_mask
+ vperm S6,S6,S6,swap_mask
+ vperm S7,S7,S7,swap_mask&gt;)
+
+ stxvd2x S0X,0,DST
+ li  9,0x10
+ stxvd2x S1X,9,DST
+ addi  9,9,0x10
+ stxvd2x S2X,9,DST
+ addi   9,9,0x10
+ stxvd2x S3X,9,DST
+ addi   9,9,0x10
+ stxvd2x S4X,9,DST
+ addi   9,9,0x10
+ stxvd2x S5X,9,DST
+ addi   9,9,0x10
+ stxvd2x S6X,9,DST
+ addi   9,9,0x10
+ stxvd2x S7X,9,DST
+
+ addi   SRC,SRC,0x80
+ addi   DST,DST,0x80
+
+ clrldi LENGTH,LENGTH,61
+
+L4x:
+ srdi   5,LENGTH,2
+ cmpldi   5,0
+ beq   L2x
+
+ lxvd2x   KX,0,KEYS
+ vperm   K,K,K,swap_mask
+
+ lxvd2x S0X,0,SRC
+ li  9,0x10
+ lxvd2x S1X,9,SRC
+ addi   9,9,0x10
+ lxvd2x S2X,9,SRC
+ addi   9,9,0x10
+ lxvd2x S3X,9,SRC
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask&gt;)
+
+ vxor S0,S0,K
+ vxor S1,S1,K
+ vxor S2,S2,K
+ vxor S3,S3,K
+
+ mtctr ROUNDS
+ li 10,0x10
+.align 5
+L4x_round_loop:
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vncipher S0,S0,ZERO
+ vncipher S1,S1,ZERO
+ vncipher S2,S2,ZERO
+ vncipher S3,S3,ZERO
+ vxor   S0,S0,K
+ vxor  S1,S1,K
+ vxor   S2,S2,K
+ vxor   S3,S3,K
+ addi   10,10,0x10
+ bdnz  L4x_round_loop
+
+ lxvd2x KX,10,KEYS
+ vperm   K,K,K,swap_mask
+ vncipherlast S0,S0,K
+ vncipherlast S1,S1,K
+ vncipherlast S2,S2,K
+ vncipherlast S3,S3,K
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask&gt;)
+
+ stxvd2x S0X,0,DST
+ li  9,0x10
+ stxvd2x S1X,9,DST
+ addi   9,9,0x10
+ stxvd2x S2X,9,DST
+ addi  9,9,0x10
+ stxvd2x S3X,9,DST
+
+ addi   SRC,SRC,0x40
+ addi   DST,DST,0x40
+
+ clrldi LENGTH,LENGTH,62
+
+L2x:
+ srdi  5,LENGTH,1
+ cmpldi  5,0
+ beq   L1x
+
+ lxvd2x KX,0,KEYS
+ vperm K,K,K,swap_mask
+
+ lxvd2x S0X,0,SRC
+ li   9,0x10
+ lxvd2x S1X,9,SRC
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask&gt;)
+
+ vxor  S0,S0,K
+ vxor   S1,S1,K
+
+ mtctr   ROUNDS
+ li  10,0x10
+.align 5
+L2x_round_loop:
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vncipher S0,S0,ZERO
+ vncipher S1,S1,ZERO
+ vxor  S0,S0,K
+ vxor  S1,S1,K
+ addi   10,10,0x10
+ bdnz   L2x_round_loop
+
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vncipherlast S0,S0,K
+ vncipherlast S1,S1,K
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask&gt;)
+
+ stxvd2x S0X,0,DST
+ li  9,0x10
+ stxvd2x S1X,9,DST
+
+ addi   SRC,SRC,0x20
+ addi   DST,DST,0x20
+
+ clrldi LENGTH,LENGTH,63
+
+L1x:
+ cmpldi LENGTH,0
+ beq   Ldone
+
+ lxvd2x KX,0,KEYS
+ vperm   K,K,K,swap_mask
+
+ lxvd2x S0X,0,SRC
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask&gt;)
+
+ vxor   S0,S0,K
+
+ mtctr   ROUNDS
+ li   10,0x10
+.align 5
+L1x_round_loop:
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vncipher S0,S0,ZERO
+ vxor   S0,S0,K
+ addi   10,10,0x10
+ bdnz   L1x_round_loop
+
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vncipherlast S0,S0,K
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask&gt;)
+
+ stxvd2x S0X,0,DST
+
+Ldone:
+ blr
+EPILOGUE(_nettle_aes_decrypt)
+
+ .data
+ .align 4
+.swap_mask:
+IF_LE(&lt;.byte 8,9,10,11,12,13,14,15,0,1,2,3,4,5,6,7&gt;)
+IF_BE(&lt;.byte 3,2,1,0,7,6,5,4,11,10,9,8,15,14,13,12&gt;)
diff --git a/powerpc64/aes-encrypt-internal.asm
b/powerpc64/aes-encrypt-internal.asm
new file mode 100644
index 00000000..76630222
--- /dev/null
+++ b/powerpc64/aes-encrypt-internal.asm
@@ -0,0 +1,540 @@
+C powerpc64/aes-encrypt-internal.asm
+
+ifelse(&lt;
+   Copyright (C) 2020 Mamone Tarsha
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+&gt;)
+
+C Register usage:
+
+define(&lt;SP&gt;, &lt;1&gt;)
+define(&lt;TOCP&gt;, &lt;2&gt;)
+
+define(&lt;ROUNDS&gt;, &lt;3&gt;)
+define(&lt;KEYS&gt;, &lt;4&gt;)
+define(&lt;LENGTH&gt;, &lt;6&gt;)
+define(&lt;DST&gt;, &lt;7&gt;)
+define(&lt;SRC&gt;, &lt;8&gt;)
+
+define(&lt;swap_mask&gt;, &lt;0&gt;)
+
+define(&lt;K&gt;, &lt;1&gt;)
+define(&lt;S0&gt;, &lt;2&gt;)
+define(&lt;S1&gt;, &lt;3&gt;)
+define(&lt;S2&gt;, &lt;4&gt;)
+define(&lt;S3&gt;, &lt;5&gt;)
+define(&lt;S4&gt;, &lt;6&gt;)
+define(&lt;S5&gt;, &lt;7&gt;)
+define(&lt;S6&gt;, &lt;8&gt;)
+define(&lt;S7&gt;, &lt;9&gt;)
+define(&lt;S8&gt;, &lt;10&gt;)
+define(&lt;S9&gt;, &lt;11&gt;)
+define(&lt;S10&gt;, &lt;12&gt;)
+define(&lt;S11&gt;, &lt;13&gt;)
+define(&lt;S12&gt;, &lt;14&gt;)
+define(&lt;S13&gt;, &lt;15&gt;)
+define(&lt;S14&gt;, &lt;16&gt;)
+define(&lt;S15&gt;, &lt;17&gt;)
+
+define(&lt;KX&gt;, &lt;33&gt;)
+define(&lt;S0X&gt;, &lt;34&gt;)
+define(&lt;S1X&gt;, &lt;35&gt;)
+define(&lt;S2X&gt;, &lt;36&gt;)
+define(&lt;S3X&gt;, &lt;37&gt;)
+define(&lt;S4X&gt;, &lt;38&gt;)
+define(&lt;S5X&gt;, &lt;39&gt;)
+define(&lt;S6X&gt;, &lt;40&gt;)
+define(&lt;S7X&gt;, &lt;41&gt;)
+define(&lt;S8X&gt;, &lt;42&gt;)
+define(&lt;S9X&gt;, &lt;43&gt;)
+define(&lt;S10X&gt;, &lt;44&gt;)
+define(&lt;S11X&gt;, &lt;45&gt;)
+define(&lt;S12X&gt;, &lt;46&gt;)
+define(&lt;S13X&gt;, &lt;47&gt;)
+define(&lt;S14X&gt;, &lt;48&gt;)
+define(&lt;S15X&gt;, &lt;49&gt;)
+
+.file "aes-encrypt-internal.asm"
+
+IF_LE(&lt;.abiversion 2&gt;)
+.text
+
+ C _aes_encrypt(unsigned rounds, const uint32_t *keys,
+ C       const struct aes_table *T,
+ C       size_t length, uint8_t *dst,
+ C       uint8_t *src)
+
+PROLOGUE(_nettle_aes_encrypt)
+ ld 5,.swap_mask@got(TOCP)
+ lvx swap_mask,0,5
+
+ subi ROUNDS,ROUNDS,1
+ srdi LENGTH,LENGTH,4
+
+ srdi 5,LENGTH,4 #16x loop count
+ cmpldi 5,0
+ beq L8x
+
+ std 17,-120(SP);
+ std 18,-112(SP);
+ std 19,-104(SP);
+ std 20,-96(SP);
+ std 21,-88(SP);
+ std 22,-80(SP);
+ std 23,-72(SP);
+ std 24,-64(SP);
+ std 25,-56(SP);
+ std 26,-48(SP);
+ std 27,-40(SP);
+ std 28,-32(SP);
+ std 29,-24(SP);
+ std 30,-16(SP);
+ std 31,-8(SP);
+
+ li 17,0x10
+ li 18,0x20
+ li 19,0x30
+ li 20,0x40
+ li 21,0x50
+ li 22,0x60
+ li 23,0x70
+ li 24,0x80
+ li 25,0x90
+ li 26,0xA0
+ li 27,0xB0
+ li 28,0xC0
+ li 29,0xD0
+ li 30,0xE0
+ li 31,0xF0
+
+.align 5
+Lx16_loop:
+ lxvd2x KX,0,KEYS
+ vperm   K,K,K,swap_mask
+
+ lxvd2x S0X,0,SRC
+ lxvd2x S1X,17,SRC
+ lxvd2x S2X,18,SRC
+ lxvd2x S3X,19,SRC
+ lxvd2x S4X,20,SRC
+ lxvd2x S5X,21,SRC
+ lxvd2x S6X,22,SRC
+ lxvd2x S7X,23,SRC
+ lxvd2x S8X,24,SRC
+ lxvd2x S9X,25,SRC
+ lxvd2x S10X,26,SRC
+ lxvd2x S11X,27,SRC
+ lxvd2x S12X,28,SRC
+ lxvd2x S13X,29,SRC
+ lxvd2x S14X,30,SRC
+ lxvd2x S15X,31,SRC
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask
+ vperm S4,S4,S4,swap_mask
+ vperm S5,S5,S5,swap_mask
+ vperm S6,S6,S6,swap_mask
+ vperm S7,S7,S7,swap_mask
+ vperm S8,S8,S8,swap_mask
+ vperm S9,S9,S9,swap_mask
+ vperm S10,S10,S10,swap_mask
+ vperm S11,S11,S11,swap_mask
+ vperm S12,S12,S12,swap_mask
+ vperm S13,S13,S13,swap_mask
+ vperm S14,S14,S14,swap_mask
+ vperm S15,S15,S15,swap_mask&gt;)
+
+ vxor S0,S0,K
+ vxor S1,S1,K
+ vxor S2,S2,K
+ vxor S3,S3,K
+ vxor S4,S4,K
+ vxor S5,S5,K
+ vxor S6,S6,K
+ vxor S7,S7,K
+ vxor S8,S8,K
+ vxor S9,S9,K
+ vxor S10,S10,K
+ vxor S11,S11,K
+ vxor S12,S12,K
+ vxor S13,S13,K
+ vxor S14,S14,K
+ vxor S15,S15,K
+
+ mtctr ROUNDS
+ li 10,0x10
+.align 5
+L16x_round_loop:
+ lxvd2x KX,10,KEYS
+ vperm   K,K,K,swap_mask
+ vcipher S0,S0,K
+ vcipher S1,S1,K
+ vcipher S2,S2,K
+ vcipher S3,S3,K
+ vcipher S4,S4,K
+ vcipher S5,S5,K
+ vcipher S6,S6,K
+ vcipher S7,S7,K
+ vcipher S8,S8,K
+ vcipher S9,S9,K
+ vcipher S10,S10,K
+ vcipher S11,S11,K
+ vcipher S12,S12,K
+ vcipher S13,S13,K
+ vcipher S14,S14,K
+ vcipher S15,S15,K
+ addi 10,10,0x10
+ bdnz L16x_round_loop
+
+ lxvd2x KX,10,KEYS
+ vperm   K,K,K,swap_mask
+ vcipherlast S0,S0,K
+ vcipherlast S1,S1,K
+ vcipherlast S2,S2,K
+ vcipherlast S3,S3,K
+ vcipherlast S4,S4,K
+ vcipherlast S5,S5,K
+ vcipherlast S6,S6,K
+ vcipherlast S7,S7,K
+ vcipherlast S8,S8,K
+ vcipherlast S9,S9,K
+ vcipherlast S10,S10,K
+ vcipherlast S11,S11,K
+ vcipherlast S12,S12,K
+ vcipherlast S13,S13,K
+ vcipherlast S14,S14,K
+ vcipherlast S15,S15,K
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask
+ vperm S4,S4,S4,swap_mask
+ vperm S5,S5,S5,swap_mask
+ vperm S6,S6,S6,swap_mask
+ vperm S7,S7,S7,swap_mask
+ vperm S8,S8,S8,swap_mask
+ vperm S9,S9,S9,swap_mask
+ vperm S10,S10,S10,swap_mask
+ vperm S11,S11,S11,swap_mask
+ vperm S12,S12,S12,swap_mask
+ vperm S13,S13,S13,swap_mask
+ vperm S14,S14,S14,swap_mask
+ vperm S15,S15,S15,swap_mask&gt;)
+
+ stxvd2x S0X,0,DST
+ stxvd2x S1X,17,DST
+ stxvd2x S2X,18,DST
+ stxvd2x S3X,19,DST
+ stxvd2x S4X,20,DST
+ stxvd2x S5X,21,DST
+ stxvd2x S6X,22,DST
+ stxvd2x S7X,23,DST
+ stxvd2x S8X,24,DST
+ stxvd2x S9X,25,DST
+ stxvd2x S10X,26,DST
+ stxvd2x S11X,27,DST
+ stxvd2x S12X,28,DST
+ stxvd2x S13X,29,DST
+ stxvd2x S14X,30,DST
+ stxvd2x S15X,31,DST
+
+ addi SRC,SRC,0x100
+ addi DST,DST,0x100
+ subic. 5,5,1
+ bne Lx16_loop
+
+ ld 17,-120(SP);
+ ld 18,-112(SP);
+ ld 19,-104(SP);
+ ld 20,-96(SP);
+ ld 21,-88(SP);
+ ld 22,-80(SP);
+ ld 23,-72(SP);
+ ld 24,-64(SP);
+ ld 25,-56(SP);
+ ld 26,-48(SP);
+ ld 27,-40(SP);
+ ld 28,-32(SP);
+ ld 29,-24(SP);
+ ld 30,-16(SP);
+ ld 31,-8(SP);
+
+ clrldi LENGTH,LENGTH,60
+
+L8x:
+ srdi 5,LENGTH,3
+ cmpldi 5,0
+ beq L4x
+
+ lxvd2x KX,0,KEYS
+ vperm   K,K,K,swap_mask
+
+ lxvd2x S0X,0,SRC
+ li   9,0x10
+ lxvd2x S1X,9,SRC
+ addi   9,9,0x10
+ lxvd2x S2X,9,SRC
+ addi   9,9,0x10
+ lxvd2x S3X,9,SRC
+ addi  9,9,0x10
+ lxvd2x S4X,9,SRC
+ addi   9,9,0x10
+ lxvd2x S5X,9,SRC
+ addi   9,9,0x10
+ lxvd2x S6X,9,SRC
+ addi  9,9,0x10
+ lxvd2x S7X,9,SRC
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask
+ vperm S4,S4,S4,swap_mask
+ vperm S5,S5,S5,swap_mask
+ vperm S6,S6,S6,swap_mask
+ vperm S7,S7,S7,swap_mask&gt;)
+
+ vxor S0,S0,K
+ vxor S1,S1,K
+ vxor S2,S2,K
+ vxor S3,S3,K
+ vxor S4,S4,K
+ vxor S5,S5,K
+ vxor S6,S6,K
+ vxor S7,S7,K
+
+ mtctr ROUNDS
+ li 10,0x10
+.align 5
+L8x_round_loop:
+ lxvd2x KX,10,KEYS
+ vperm   K,K,K,swap_mask
+ vcipher S0,S0,K
+ vcipher S1,S1,K
+ vcipher S2,S2,K
+ vcipher S3,S3,K
+ vcipher S4,S4,K
+ vcipher S5,S5,K
+ vcipher S6,S6,K
+ vcipher S7,S7,K
+ addi 10,10,0x10
+ bdnz L8x_round_loop
+
+ lxvd2x  KX,10,KEYS
+ vperm       K,K,K,swap_mask
+ vcipherlast S0,S0,K
+ vcipherlast S1,S1,K
+ vcipherlast S2,S2,K
+ vcipherlast S3,S3,K
+ vcipherlast S4,S4,K
+ vcipherlast S5,S5,K
+ vcipherlast S6,S6,K
+ vcipherlast S7,S7,K
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask
+ vperm S4,S4,S4,swap_mask
+ vperm S5,S5,S5,swap_mask
+ vperm S6,S6,S6,swap_mask
+ vperm S7,S7,S7,swap_mask&gt;)
+
+ stxvd2x S0X,0,DST
+ li  9,0x10
+ stxvd2x S1X,9,DST
+ addi  9,9,0x10
+ stxvd2x S2X,9,DST
+ addi   9,9,0x10
+ stxvd2x S3X,9,DST
+ addi   9,9,0x10
+ stxvd2x S4X,9,DST
+ addi   9,9,0x10
+ stxvd2x S5X,9,DST
+ addi   9,9,0x10
+ stxvd2x S6X,9,DST
+ addi   9,9,0x10
+ stxvd2x S7X,9,DST
+
+ addi   SRC,SRC,0x80
+ addi   DST,DST,0x80
+
+ clrldi LENGTH,LENGTH,61
+
+L4x:
+ srdi   5,LENGTH,2
+ cmpldi   5,0
+ beq   L2x
+
+ lxvd2x   KX,0,KEYS
+ vperm   K,K,K,swap_mask
+
+ lxvd2x S0X,0,SRC
+ li  9,0x10
+ lxvd2x S1X,9,SRC
+ addi   9,9,0x10
+ lxvd2x S2X,9,SRC
+ addi   9,9,0x10
+ lxvd2x S3X,9,SRC
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask&gt;)
+
+ vxor S0,S0,K
+ vxor S1,S1,K
+ vxor S2,S2,K
+ vxor S3,S3,K
+
+ mtctr ROUNDS
+ li 10,0x10
+.align 5
+L4x_round_loop:
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vcipher S0,S0,K
+ vcipher S1,S1,K
+ vcipher S2,S2,K
+ vcipher S3,S3,K
+ addi   10,10,0x10
+ bdnz  L4x_round_loop
+
+ lxvd2x KX,10,KEYS
+ vperm   K,K,K,swap_mask
+ vcipherlast S0,S0,K
+ vcipherlast S1,S1,K
+ vcipherlast S2,S2,K
+ vcipherlast S3,S3,K
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask&gt;)
+
+ stxvd2x S0X,0,DST
+ li  9,0x10
+ stxvd2x S1X,9,DST
+ addi   9,9,0x10
+ stxvd2x S2X,9,DST
+ addi  9,9,0x10
+ stxvd2x S3X,9,DST
+
+ addi   SRC,SRC,0x40
+ addi   DST,DST,0x40
+
+ clrldi LENGTH,LENGTH,62
+
+L2x:
+ srdi  5,LENGTH,1
+ cmpldi  5,0
+ beq   L1x
+
+ lxvd2x KX,0,KEYS
+ vperm K,K,K,swap_mask
+
+ lxvd2x S0X,0,SRC
+ li   9,0x10
+ lxvd2x S1X,9,SRC
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask&gt;)
+
+ vxor  S0,S0,K
+ vxor   S1,S1,K
+
+ mtctr   ROUNDS
+ li  10,0x10
+.align 5
+L2x_round_loop:
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vcipher S0,S0,K
+ vcipher S1,S1,K
+ addi   10,10,0x10
+ bdnz   L2x_round_loop
+
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vcipherlast S0,S0,K
+ vcipherlast S1,S1,K
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask&gt;)
+
+ stxvd2x S0X,0,DST
+ li  9,0x10
+ stxvd2x S1X,9,DST
+
+ addi   SRC,SRC,0x20
+ addi   DST,DST,0x20
+
+ clrldi LENGTH,LENGTH,63
+
+L1x:
+ cmpldi LENGTH,0
+ beq   Ldone
+
+ lxvd2x KX,0,KEYS
+ vperm   K,K,K,swap_mask
+
+ lxvd2x S0X,0,SRC
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask&gt;)
+
+ vxor   S0,S0,K
+
+ mtctr   ROUNDS
+ li   10,0x10
+.align 5
+L1x_round_loop:
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vcipher S0,S0,K
+ addi   10,10,0x10
+ bdnz   L1x_round_loop
+
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vcipherlast S0,S0,K
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask&gt;)
+
+ stxvd2x S0X,0,DST
+
+Ldone:
+ blr
+EPILOGUE(_nettle_aes_encrypt)
+
+ .data
+ .align 4
+.swap_mask:
+IF_LE(&lt;.byte 8,9,10,11,12,13,14,15,0,1,2,3,4,5,6,7&gt;)
+IF_BE(&lt;.byte 3,2,1,0,7,6,5,4,11,10,9,8,15,14,13,12&gt;)
-- 
2.17.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200709061420</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-07-09 06:14:20-0400</timestampReceived><subject>[PATCH 1/4] Check for PowerPC64 assembly if crypto extensions are available</subject><body>

---
 Makefile.in          |  2 +-
 aclocal.m4           | 52 ++++++++++++++++++++++++++++++++++++++++
 configure.ac         | 11 +++++++++
 powerpc64/README     | 67
++++++++++++++++++++++++++++++++++++++++++++++++++++
 powerpc64/machine.m4 | 24 +++++++++++++++++++
 5 files changed, 155 insertions(+), 1 deletion(-)
 create mode 100644 powerpc64/README
 create mode 100644 powerpc64/machine.m4

diff --git a/Makefile.in b/Makefile.in
index 77efb5c9..1508e8f4 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -603,7 +603,7 @@ distdir: $(DISTFILES)
  done
  set -e; for d in sparc32 sparc64 x86 \
  x86_64 x86_64/aesni x86_64/sha_ni x86_64/fat \
- arm arm/neon arm/v6 arm/fat ; do \
+ arm arm/neon arm/v6 arm/fat powerpc64 ; do \
   mkdir "$(distdir)/$$d" ; \
   find "$(srcdir)/$$d" -maxdepth 1 '(' -name '*.asm' -o -name '*.m4' ')' \
     -exec cp '{}' "$(distdir)/$$d" ';' ; \
diff --git a/aclocal.m4 b/aclocal.m4
index 513b2df4..e38181ad 100644
--- a/aclocal.m4
+++ b/aclocal.m4
@@ -462,6 +462,58 @@ foo:
 fi
 ])

+dnl NETTLE_CHECK_POWER_CRYPTO_EXT
+dnl ---------------------
+dnl Check if POWER crypto extensions should be used.
+dnl Obeys enable_power_crypto_ext, which should be set earlier.
+AC_DEFUN([NETTLE_CHECK_POWER_CRYPTO_EXT],
+[if test "$enable_power_crypto_ext" = auto ; then
+  if test "$cross_compiling" = yes ; then
+    dnl Check if compiler/assembler accepts it.
+    AC_CACHE_CHECK([if assembler accepts crypto instructions],
+      nettle_cv_asm_power_vcrypto,
+      [GMP_TRY_ASSEMBLE([
+.text
+foo:
+ vcipher 0, 0, 1
+],
+      [nettle_cv_asm_power_vcrypto=yes],
+      [nettle_cv_asm_power_vcrypto=no])])
+    enable_power_crypto_ext="$nettle_cv_asm_power_vcrypto"
+  else
+    AC_CACHE_CHECK([if crypto extensions supported],
+      nettle_cv_asm_power_vcrypto,
+      [AC_RUN_IFELSE([AC_LANG_PROGRAM([[
+#if defined(__FreeBSD__) &amp;&amp; __FreeBSD__ &lt; 12
+#include &lt;sys/sysctl.h&gt;
+#else
+#include &lt;sys/auxv.h&gt;
+#endif
+// Define from arch/powerpc/include/uapi/asm/cputable.h in Linux kernel
+#ifndef PPC_FEATURE2_VEC_CRYPTO
+#define PPC_FEATURE2_VEC_CRYPTO 0x02000000
+#endif
+          unsigned long hwcap2 = 0;
+        ]], [[
+#if defined(__FreeBSD__)
+#if __FreeBSD__ &lt; 12
+          size_t len = sizeof(hwcap2);
+          sysctlbyname("hw.cpu_features2", &amp;hwcap2, &amp;len, NULL, 0);
+#else
+          elf_aux_info(AT_HWCAP2, &amp;hwcap2, sizeof(hwcap2));
+#endif
+#else
+          hwcap2 = getauxval(AT_HWCAP2);
+#endif
+          return (hwcap2 &amp; PPC_FEATURE2_VEC_CRYPTO) ==
PPC_FEATURE2_VEC_CRYPTO ? 0 : 1;
+        ]])],
+        [nettle_cv_asm_power_vcrypto=yes],
+        [nettle_cv_asm_power_vcrypto=no])])
+    enable_power_crypto_ext="$nettle_cv_asm_power_vcrypto"
+  fi
+fi
+])
+
 dnl NETTLE_CHECK_IFUNC
 dnl ------------------
 dnl Check if __attribute__ ((ifunc(...))) works
diff --git a/configure.ac b/configure.ac
index 1c0b7393..cc0d67ec 100644
--- a/configure.ac
+++ b/configure.ac
@@ -89,6 +89,10 @@ AC_ARG_ENABLE(x86-sha-ni,
   AC_HELP_STRING([--enable-x86-sha-ni], [Enable x86_64 sha_ni
instructions. (default=no)]),,
   [enable_x86_sha_ni=no])

+AC_ARG_ENABLE(power-crypto-ext,
+  AC_HELP_STRING([--enable-power-crypto-ext], [Enable POWER crypto
extentions. (default=auto)]),,
+  [enable_power_crypto_ext=auto])
+
 AC_ARG_ENABLE(mini-gmp,
   AC_HELP_STRING([--enable-mini-gmp], [Enable mini-gmp, used instead of
libgmp.]),,
   [enable_mini_gmp=no])
@@ -434,6 +438,13 @@ if test "x$enable_assembler" = xyes ; then
  fi
       fi
       ;;
+    *powerpc64*)
+      NETTLE_CHECK_POWER_CRYPTO_EXT
+
+      if test "x$enable_power_crypto_ext" = xyes ; then
+        asm_path=powerpc64
+      fi
+      ;;
     *)
       enable_assembler=no
       ;;
diff --git a/powerpc64/README b/powerpc64/README
new file mode 100644
index 00000000..1890ee9a
--- /dev/null
+++ b/powerpc64/README
@@ -0,0 +1,67 @@
+General-Purpose Register Conventions
+
+Register Status Use
+
+GPR0 volatile In function prologs.
+GPR1 dedicated Stack pointer.
+GPR2 dedicated Table of Contents (TOC) pointer.
+GPR3 volatile First word of a function's argument list;
+    first word of a scalar function return.
+GPR4 volatile Second word of a function's argument list;
+    second word of a scalar function return.
+GPR5 volatile Third word of a function's argument list.
+GPR6 volatile Fourth word of a function's argument list.
+GPR7 volatile Fifth word of a function's argument list.
+GPR8 volatile Sixth word of a function's argument list.
+GPR9 volatile Seventh word of a function's argument list.
+GPR10 volatile Eighth word of a function's argument list.
+GPR11 volatile In calls by pointer and as an environment pointer for
languages
+    that require it (for example, PASCAL).
+GPR12 volatile For special exception handling required by certain
languages and in
+    glink code.
+GPR13 reserved Reserved under 64-bit environment; not restored across
system calls.
+GPR14:GPR31 nonvolatile These registers must be preserved across a
function call.
+
+Vector Register Conventions
+
+Register Status
+
+VR0 Volatile
+VR1 Volatile
+VR2 Volatile
+VR3 Volatile
+VR4 Volatile
+VR5 Volatile
+VR6 Volatile
+VR7 Volatile
+VR8 Volatile
+VR9 Volatile
+VR10 Volatile
+VR11 Volatile
+VR12 Volatile
+VR13 Volatile
+VR14 Volatile
+VR15 Volatile
+VR16 Volatile
+VR17 Volatile
+VR18 Volatile
+VR19 Volatile
+VR20:31 Nonvolatile (extended ABI mode) their values are preserved across
function calls
+
+Addressing memory
+
+There are many ways to reference data, the current implementations uses
GOT-indirect addressing
+(Accessing data through the global offset table):
+1. Define data in .data section
+2. Load the address of data into register from the global offset table
e.g. ld 7, my_var@got(2)
+3. Use the address to load the value of data into register e.g. ld 3, 0(7)
+
+VSX instructions (lxvd2x and stxvd2x) are used to load and store data to
memory
+instead of VR instructions (lvx and stvx) as it produces a fewer
instructions
+(lvx and stvx) can be used to load and store data into storage operands
+but additional instructions are needed to access unaligned storage
operands, please
+refer to "6.4.1 Accessing Unaligned Storage Operands" in "POWER ISA
Version 2.07 B"
+to see an example of accessing unaligned storage operands (lxvd2x and
stxvd2x) can
+be used to load and store data into unaligned storage operands but
permuting is needed
+for loading and storing data in little-endian mode
+VSX registers are defined with "X" suffix
diff --git a/powerpc64/machine.m4 b/powerpc64/machine.m4
new file mode 100644
index 00000000..c8005cd8
--- /dev/null
+++ b/powerpc64/machine.m4
@@ -0,0 +1,24 @@
+define(&lt;PROLOGUE&gt;,
+&lt;ifelse(WORDS_BIGENDIAN,no,
+&lt;.align 5
+.globl C_NAME($1)
+DECLARE_FUNC(C_NAME($1))
+C_NAME($1):
+addis 2,12,(.TOC.-C_NAME($1))@ha
+addi 2,2,(.TOC.-C_NAME($1))@l
+.localentry C_NAME($1), .-C_NAME($1)&gt;,
+&lt;.globl C_NAME($1)
+DECLARE_FUNC(C_NAME($1))
+.section ".opd","aw"
+.align 3
+C_NAME($1):
+.quad .C_NAME($1),.TOC.@tocbase,0
+.previous
+.align 5
+.C_NAME($1):&gt;)&gt;)
+
+define(&lt;EPILOGUE&gt;,
+&lt;ifelse(WORDS_BIGENDIAN,no,
+&lt;.size C_NAME($1), . - C_NAME($1)&gt;,
+&lt;.size .C_NAME($1), . - .C_NAME($1)
+.size C_NAME($1), . - .C_NAME($1)&gt;)&gt;)
-- 
2.17.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200714114306</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-07-14 11:43:06-0400</timestampReceived><subject>[PATCH 2/6] "PowerPC64" Add optimized AES [Enc|Dec]</subject><body>

I measured the latency and throughput of vcipher/vncipher/vxor instructions
for POWER8
vcipher/vncipher
throughput 6 instructions per cycle
latency 0.91 clock cycles
vxor
throughput 6 instructions per cycle
latency 0.32 clock cycles
So the ideal option for POWER8 is processing 8 blocks, it has +12%
performance over processing 4 blocks.

---
 powerpc64/P8/aes-decrypt-internal.asm | 367
++++++++++++++++++++++++++++++++++
 powerpc64/P8/aes-encrypt-internal.asm | 344 +++++++++++++++++++++++++++++++
 2 files changed, 711 insertions(+)
 create mode 100644 powerpc64/P8/aes-decrypt-internal.asm
 create mode 100644 powerpc64/P8/aes-encrypt-internal.asm

diff --git a/powerpc64/P8/aes-decrypt-internal.asm
b/powerpc64/P8/aes-decrypt-internal.asm
new file mode 100644
index 00000000..f5d64548
--- /dev/null
+++ b/powerpc64/P8/aes-decrypt-internal.asm
@@ -0,0 +1,367 @@
+C powerpc64/P8/aes-decrypt-internal.asm
+
+ifelse(&lt;
+   Copyright (C) 2020 Mamone Tarsha
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+&gt;)
+
+C Register usage:
+
+define(&lt;SP&gt;, &lt;1&gt;)
+define(&lt;TOCP&gt;, &lt;2&gt;)
+
+define(&lt;ROUNDS&gt;, &lt;3&gt;)
+define(&lt;KEYS&gt;, &lt;4&gt;)
+define(&lt;LENGTH&gt;, &lt;6&gt;)
+define(&lt;DST&gt;, &lt;7&gt;)
+define(&lt;SRC&gt;, &lt;8&gt;)
+
+define(&lt;swap_mask&gt;, &lt;0&gt;)
+
+define(&lt;K&gt;, &lt;1&gt;)
+define(&lt;S0&gt;, &lt;2&gt;)
+define(&lt;S1&gt;, &lt;3&gt;)
+define(&lt;S2&gt;, &lt;4&gt;)
+define(&lt;S3&gt;, &lt;5&gt;)
+define(&lt;S4&gt;, &lt;6&gt;)
+define(&lt;S5&gt;, &lt;7&gt;)
+define(&lt;S6&gt;, &lt;8&gt;)
+define(&lt;S7&gt;, &lt;9&gt;)
+
+define(&lt;KX&gt;, &lt;33&gt;)
+define(&lt;S0X&gt;, &lt;34&gt;)
+define(&lt;S1X&gt;, &lt;35&gt;)
+define(&lt;S2X&gt;, &lt;36&gt;)
+define(&lt;S3X&gt;, &lt;37&gt;)
+define(&lt;S4X&gt;, &lt;38&gt;)
+define(&lt;S5X&gt;, &lt;39&gt;)
+define(&lt;S6X&gt;, &lt;40&gt;)
+define(&lt;S7X&gt;, &lt;41&gt;)
+
+C ZERO vector register is used in place of RoundKey
+C for vncipher instruction because the order of InvMixColumns
+C and Xor processes are flipped in that instruction.
+C The Xor process with RoundKey is executed afterward.
+define(&lt;ZERO&gt;, &lt;10&gt;)
+
+.file "aes-decrypt-internal.asm"
+
+IF_LE(&lt;.abiversion 2&gt;)
+.text
+
+ C _aes_decrypt(unsigned rounds, const uint32_t *keys,
+ C       const struct aes_table *T,
+ C       size_t length, uint8_t *dst,
+ C       uint8_t *src)
+
+define(&lt;FUNC_ALIGN&gt;, &lt;5&gt;)
+PROLOGUE(_nettle_aes_decrypt)
+ vxor ZERO,ZERO,ZERO
+
+ DATA_LOAD_VEC(swap_mask,.swap_mask,5)
+
+ subi ROUNDS,ROUNDS,1
+ srdi LENGTH,LENGTH,4
+
+ srdi 5,LENGTH,3 #8x loop count
+ cmpldi 5,0
+ beq L4x
+
+ std 25,-56(SP);
+ std 26,-48(SP);
+ std 27,-40(SP);
+ std 28,-32(SP);
+ std 29,-24(SP);
+ std 30,-16(SP);
+ std 31,-8(SP);
+
+ li 25,0x10
+ li 26,0x20
+ li 27,0x30
+ li 28,0x40
+ li 29,0x50
+ li 30,0x60
+ li 31,0x70
+
+.align 5
+Lx8_loop:
+ lxvd2x KX,0,KEYS
+ vperm   K,K,K,swap_mask
+
+ lxvd2x S0X,0,SRC
+ lxvd2x S1X,25,SRC
+ lxvd2x S2X,26,SRC
+ lxvd2x S3X,27,SRC
+ lxvd2x S4X,28,SRC
+ lxvd2x S5X,29,SRC
+ lxvd2x S6X,30,SRC
+ lxvd2x S7X,31,SRC
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask
+ vperm S4,S4,S4,swap_mask
+ vperm S5,S5,S5,swap_mask
+ vperm S6,S6,S6,swap_mask
+ vperm S7,S7,S7,swap_mask&gt;)
+
+ vxor S0,S0,K
+ vxor S1,S1,K
+ vxor S2,S2,K
+ vxor S3,S3,K
+ vxor S4,S4,K
+ vxor S5,S5,K
+ vxor S6,S6,K
+ vxor S7,S7,K
+
+ mtctr ROUNDS
+ li 10,0x10
+.align 5
+L8x_round_loop:
+ lxvd2x KX,10,KEYS
+ vperm   K,K,K,swap_mask
+ vncipher S0,S0,ZERO
+ vncipher S1,S1,ZERO
+ vncipher S2,S2,ZERO
+ vncipher S3,S3,ZERO
+ vncipher S4,S4,ZERO
+ vncipher S5,S5,ZERO
+ vncipher S6,S6,ZERO
+ vncipher S7,S7,ZERO
+ vxor S0,S0,K
+ vxor S1,S1,K
+ vxor S2,S2,K
+ vxor S3,S3,K
+ vxor S4,S4,K
+ vxor S5,S5,K
+ vxor S6,S6,K
+ vxor S7,S7,K
+ addi 10,10,0x10
+ bdnz L8x_round_loop
+
+ lxvd2x KX,10,KEYS
+ vperm   K,K,K,swap_mask
+ vncipherlast S0,S0,K
+ vncipherlast S1,S1,K
+ vncipherlast S2,S2,K
+ vncipherlast S3,S3,K
+ vncipherlast S4,S4,K
+ vncipherlast S5,S5,K
+ vncipherlast S6,S6,K
+ vncipherlast S7,S7,K
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask
+ vperm S4,S4,S4,swap_mask
+ vperm S5,S5,S5,swap_mask
+ vperm S6,S6,S6,swap_mask
+ vperm S7,S7,S7,swap_mask&gt;)
+
+ stxvd2x S0X,0,DST
+ stxvd2x S1X,25,DST
+ stxvd2x S2X,26,DST
+ stxvd2x S3X,27,DST
+ stxvd2x S4X,28,DST
+ stxvd2x S5X,29,DST
+ stxvd2x S6X,30,DST
+ stxvd2x S7X,31,DST
+
+ addi SRC,SRC,0x80
+ addi DST,DST,0x80
+ subic. 5,5,1
+ bne Lx8_loop
+
+ ld 25,-56(SP);
+ ld 26,-48(SP);
+ ld 27,-40(SP);
+ ld 28,-32(SP);
+ ld 29,-24(SP);
+ ld 30,-16(SP);
+ ld 31,-8(SP);
+
+ clrldi LENGTH,LENGTH,61
+
+L4x:
+ srdi   5,LENGTH,2
+ cmpldi   5,0
+ beq   L2x
+
+ lxvd2x   KX,0,KEYS
+ vperm   K,K,K,swap_mask
+
+ lxvd2x S0X,0,SRC
+ li  9,0x10
+ lxvd2x S1X,9,SRC
+ addi   9,9,0x10
+ lxvd2x S2X,9,SRC
+ addi   9,9,0x10
+ lxvd2x S3X,9,SRC
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask&gt;)
+
+ vxor S0,S0,K
+ vxor S1,S1,K
+ vxor S2,S2,K
+ vxor S3,S3,K
+
+ mtctr ROUNDS
+ li 10,0x10
+.align 5
+L4x_round_loop:
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vncipher S0,S0,ZERO
+ vncipher S1,S1,ZERO
+ vncipher S2,S2,ZERO
+ vncipher S3,S3,ZERO
+ vxor   S0,S0,K
+ vxor  S1,S1,K
+ vxor   S2,S2,K
+ vxor   S3,S3,K
+ addi   10,10,0x10
+ bdnz  L4x_round_loop
+
+ lxvd2x KX,10,KEYS
+ vperm   K,K,K,swap_mask
+ vncipherlast S0,S0,K
+ vncipherlast S1,S1,K
+ vncipherlast S2,S2,K
+ vncipherlast S3,S3,K
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask&gt;)
+
+ stxvd2x S0X,0,DST
+ li  9,0x10
+ stxvd2x S1X,9,DST
+ addi   9,9,0x10
+ stxvd2x S2X,9,DST
+ addi  9,9,0x10
+ stxvd2x S3X,9,DST
+
+ addi   SRC,SRC,0x40
+ addi   DST,DST,0x40
+
+ clrldi LENGTH,LENGTH,62
+
+L2x:
+ srdi  5,LENGTH,1
+ cmpldi  5,0
+ beq   L1x
+
+ lxvd2x KX,0,KEYS
+ vperm K,K,K,swap_mask
+
+ lxvd2x S0X,0,SRC
+ li   9,0x10
+ lxvd2x S1X,9,SRC
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask&gt;)
+
+ vxor  S0,S0,K
+ vxor   S1,S1,K
+
+ mtctr   ROUNDS
+ li  10,0x10
+.align 5
+L2x_round_loop:
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vncipher S0,S0,ZERO
+ vncipher S1,S1,ZERO
+ vxor  S0,S0,K
+ vxor  S1,S1,K
+ addi   10,10,0x10
+ bdnz   L2x_round_loop
+
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vncipherlast S0,S0,K
+ vncipherlast S1,S1,K
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask&gt;)
+
+ stxvd2x S0X,0,DST
+ li  9,0x10
+ stxvd2x S1X,9,DST
+
+ addi   SRC,SRC,0x20
+ addi   DST,DST,0x20
+
+ clrldi LENGTH,LENGTH,63
+
+L1x:
+ cmpldi LENGTH,0
+ beq   Ldone
+
+ lxvd2x KX,0,KEYS
+ vperm   K,K,K,swap_mask
+
+ lxvd2x S0X,0,SRC
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask&gt;)
+
+ vxor   S0,S0,K
+
+ mtctr   ROUNDS
+ li   10,0x10
+.align 5
+L1x_round_loop:
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vncipher S0,S0,ZERO
+ vxor   S0,S0,K
+ addi   10,10,0x10
+ bdnz   L1x_round_loop
+
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vncipherlast S0,S0,K
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask&gt;)
+
+ stxvd2x S0X,0,DST
+
+Ldone:
+ blr
+EPILOGUE(_nettle_aes_decrypt)
+
+ .data
+ .align 4
+.swap_mask:
+IF_LE(&lt;.byte 8,9,10,11,12,13,14,15,0,1,2,3,4,5,6,7&gt;)
+IF_BE(&lt;.byte 3,2,1,0,7,6,5,4,11,10,9,8,15,14,13,12&gt;)
diff --git a/powerpc64/P8/aes-encrypt-internal.asm
b/powerpc64/P8/aes-encrypt-internal.asm
new file mode 100644
index 00000000..3e0fa6f0
--- /dev/null
+++ b/powerpc64/P8/aes-encrypt-internal.asm
@@ -0,0 +1,344 @@
+C powerpc64/P8/aes-encrypt-internal.asm
+
+ifelse(&lt;
+   Copyright (C) 2020 Mamone Tarsha
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+&gt;)
+
+C Register usage:
+
+define(&lt;SP&gt;, &lt;1&gt;)
+define(&lt;TOCP&gt;, &lt;2&gt;)
+
+define(&lt;ROUNDS&gt;, &lt;3&gt;)
+define(&lt;KEYS&gt;, &lt;4&gt;)
+define(&lt;LENGTH&gt;, &lt;6&gt;)
+define(&lt;DST&gt;, &lt;7&gt;)
+define(&lt;SRC&gt;, &lt;8&gt;)
+
+define(&lt;swap_mask&gt;, &lt;0&gt;)
+
+define(&lt;K&gt;, &lt;1&gt;)
+define(&lt;S0&gt;, &lt;2&gt;)
+define(&lt;S1&gt;, &lt;3&gt;)
+define(&lt;S2&gt;, &lt;4&gt;)
+define(&lt;S3&gt;, &lt;5&gt;)
+define(&lt;S4&gt;, &lt;6&gt;)
+define(&lt;S5&gt;, &lt;7&gt;)
+define(&lt;S6&gt;, &lt;8&gt;)
+define(&lt;S7&gt;, &lt;9&gt;)
+
+define(&lt;KX&gt;, &lt;33&gt;)
+define(&lt;S0X&gt;, &lt;34&gt;)
+define(&lt;S1X&gt;, &lt;35&gt;)
+define(&lt;S2X&gt;, &lt;36&gt;)
+define(&lt;S3X&gt;, &lt;37&gt;)
+define(&lt;S4X&gt;, &lt;38&gt;)
+define(&lt;S5X&gt;, &lt;39&gt;)
+define(&lt;S6X&gt;, &lt;40&gt;)
+define(&lt;S7X&gt;, &lt;41&gt;)
+
+.file "aes-encrypt-internal.asm"
+
+IF_LE(&lt;.abiversion 2&gt;)
+.text
+
+ C _aes_encrypt(unsigned rounds, const uint32_t *keys,
+ C       const struct aes_table *T,
+ C       size_t length, uint8_t *dst,
+ C       uint8_t *src)
+
+define(&lt;FUNC_ALIGN&gt;, &lt;5&gt;)
+PROLOGUE(_nettle_aes_encrypt)
+ DATA_LOAD_VEC(swap_mask,.swap_mask,5)
+
+ subi ROUNDS,ROUNDS,1
+ srdi LENGTH,LENGTH,4
+
+ srdi 5,LENGTH,3 #8x loop count
+ cmpldi 5,0
+ beq L4x
+
+ std 25,-56(SP);
+ std 26,-48(SP);
+ std 27,-40(SP);
+ std 28,-32(SP);
+ std 29,-24(SP);
+ std 30,-16(SP);
+ std 31,-8(SP);
+
+ li 25,0x10
+ li 26,0x20
+ li 27,0x30
+ li 28,0x40
+ li 29,0x50
+ li 30,0x60
+ li 31,0x70
+
+.align 5
+Lx8_loop:
+ lxvd2x KX,0,KEYS
+ vperm   K,K,K,swap_mask
+
+ lxvd2x S0X,0,SRC
+ lxvd2x S1X,25,SRC
+ lxvd2x S2X,26,SRC
+ lxvd2x S3X,27,SRC
+ lxvd2x S4X,28,SRC
+ lxvd2x S5X,29,SRC
+ lxvd2x S6X,30,SRC
+ lxvd2x S7X,31,SRC
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask
+ vperm S4,S4,S4,swap_mask
+ vperm S5,S5,S5,swap_mask
+ vperm S6,S6,S6,swap_mask
+ vperm S7,S7,S7,swap_mask&gt;)
+
+ vxor S0,S0,K
+ vxor S1,S1,K
+ vxor S2,S2,K
+ vxor S3,S3,K
+ vxor S4,S4,K
+ vxor S5,S5,K
+ vxor S6,S6,K
+ vxor S7,S7,K
+
+ mtctr ROUNDS
+ li 10,0x10
+.align 5
+L8x_round_loop:
+ lxvd2x KX,10,KEYS
+ vperm   K,K,K,swap_mask
+ vcipher S0,S0,K
+ vcipher S1,S1,K
+ vcipher S2,S2,K
+ vcipher S3,S3,K
+ vcipher S4,S4,K
+ vcipher S5,S5,K
+ vcipher S6,S6,K
+ vcipher S7,S7,K
+ addi 10,10,0x10
+ bdnz L8x_round_loop
+
+ lxvd2x KX,10,KEYS
+ vperm   K,K,K,swap_mask
+ vcipherlast S0,S0,K
+ vcipherlast S1,S1,K
+ vcipherlast S2,S2,K
+ vcipherlast S3,S3,K
+ vcipherlast S4,S4,K
+ vcipherlast S5,S5,K
+ vcipherlast S6,S6,K
+ vcipherlast S7,S7,K
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask
+ vperm S4,S4,S4,swap_mask
+ vperm S5,S5,S5,swap_mask
+ vperm S6,S6,S6,swap_mask
+ vperm S7,S7,S7,swap_mask&gt;)
+
+ stxvd2x S0X,0,DST
+ stxvd2x S1X,25,DST
+ stxvd2x S2X,26,DST
+ stxvd2x S3X,27,DST
+ stxvd2x S4X,28,DST
+ stxvd2x S5X,29,DST
+ stxvd2x S6X,30,DST
+ stxvd2x S7X,31,DST
+
+ addi SRC,SRC,0x80
+ addi DST,DST,0x80
+ subic. 5,5,1
+ bne Lx8_loop
+
+ ld 25,-56(SP);
+ ld 26,-48(SP);
+ ld 27,-40(SP);
+ ld 28,-32(SP);
+ ld 29,-24(SP);
+ ld 30,-16(SP);
+ ld 31,-8(SP);
+
+ clrldi LENGTH,LENGTH,61
+
+L4x:
+ srdi   5,LENGTH,2
+ cmpldi   5,0
+ beq   L2x
+
+ lxvd2x   KX,0,KEYS
+ vperm   K,K,K,swap_mask
+
+ lxvd2x S0X,0,SRC
+ li  9,0x10
+ lxvd2x S1X,9,SRC
+ addi   9,9,0x10
+ lxvd2x S2X,9,SRC
+ addi   9,9,0x10
+ lxvd2x S3X,9,SRC
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask&gt;)
+
+ vxor S0,S0,K
+ vxor S1,S1,K
+ vxor S2,S2,K
+ vxor S3,S3,K
+
+ mtctr ROUNDS
+ li 10,0x10
+.align 5
+L4x_round_loop:
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vcipher S0,S0,K
+ vcipher S1,S1,K
+ vcipher S2,S2,K
+ vcipher S3,S3,K
+ addi   10,10,0x10
+ bdnz  L4x_round_loop
+
+ lxvd2x KX,10,KEYS
+ vperm   K,K,K,swap_mask
+ vcipherlast S0,S0,K
+ vcipherlast S1,S1,K
+ vcipherlast S2,S2,K
+ vcipherlast S3,S3,K
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask&gt;)
+
+ stxvd2x S0X,0,DST
+ li  9,0x10
+ stxvd2x S1X,9,DST
+ addi   9,9,0x10
+ stxvd2x S2X,9,DST
+ addi  9,9,0x10
+ stxvd2x S3X,9,DST
+
+ addi   SRC,SRC,0x40
+ addi   DST,DST,0x40
+
+ clrldi LENGTH,LENGTH,62
+
+L2x:
+ srdi  5,LENGTH,1
+ cmpldi  5,0
+ beq   L1x
+
+ lxvd2x KX,0,KEYS
+ vperm K,K,K,swap_mask
+
+ lxvd2x S0X,0,SRC
+ li   9,0x10
+ lxvd2x S1X,9,SRC
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask&gt;)
+
+ vxor  S0,S0,K
+ vxor   S1,S1,K
+
+ mtctr   ROUNDS
+ li  10,0x10
+.align 5
+L2x_round_loop:
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vcipher S0,S0,K
+ vcipher S1,S1,K
+ addi   10,10,0x10
+ bdnz   L2x_round_loop
+
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vcipherlast S0,S0,K
+ vcipherlast S1,S1,K
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask&gt;)
+
+ stxvd2x S0X,0,DST
+ li  9,0x10
+ stxvd2x S1X,9,DST
+
+ addi   SRC,SRC,0x20
+ addi   DST,DST,0x20
+
+ clrldi LENGTH,LENGTH,63
+
+L1x:
+ cmpldi LENGTH,0
+ beq   Ldone
+
+ lxvd2x KX,0,KEYS
+ vperm   K,K,K,swap_mask
+
+ lxvd2x S0X,0,SRC
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask&gt;)
+
+ vxor   S0,S0,K
+
+ mtctr   ROUNDS
+ li   10,0x10
+.align 5
+L1x_round_loop:
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vcipher S0,S0,K
+ addi   10,10,0x10
+ bdnz   L1x_round_loop
+
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vcipherlast S0,S0,K
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask&gt;)
+
+ stxvd2x S0X,0,DST
+
+Ldone:
+ blr
+EPILOGUE(_nettle_aes_encrypt)
+
+ .data
+ .align 4
+.swap_mask:
+IF_LE(&lt;.byte 8,9,10,11,12,13,14,15,0,1,2,3,4,5,6,7&gt;)
+IF_BE(&lt;.byte 3,2,1,0,7,6,5,4,11,10,9,8,15,14,13,12&gt;)
-- 
2.17.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200720174100</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-07-20 17:41:00-0400</timestampReceived><subject>Re: [PATCH 2/6] "PowerPC64" Add optimized AES [Enc|Dec]</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; I measured the latency and throughput of vcipher/vncipher/vxor instructions
&gt; for POWER8
&gt; vcipher/vncipher
&gt; throughput 6 instructions per cycle
&gt; latency 0.91 clock cycles
&gt; vxor
&gt; throughput 6 instructions per cycle
&gt; latency 0.32 clock cycles

Latency less than one cycle sounds wrong. Usually, simple ALU
instructions like xor has a latency of exactly one cycle (i.e., when an
instruction starts executing (all inputs are available), the result is
available for depending instructions exactly one cycle later). While
deeply pipelined instructions, e.g., multiplication, can have a latency
of several cycles but still a throughput of one or a few instructions
per cycle.

See https://gmplib.org/~tege/x86-timing.pdf for background and lots of
numbers for x86 processors.

&gt; So the ideal option for POWER8 is processing 8 blocks, it has +12%
&gt; performance over processing 4 blocks.

Sounds reasonable to me. 

&gt; ---
&gt;  powerpc64/P8/aes-decrypt-internal.asm | 367

I take it "P8" in the path is for power 8? Are the crypto extensions
always available for power 8? If not, directory should be named
differently.

To get going, I've merged this and the machine.m4 patch to a development
branch. I'd like to do things stepwise, first do the minimal configure
changes to get AES working (and maybe with default on, to get it
exercised by the .gitlab-ci machinery), then add ghash and fat builds
(not sure in which order). I wanted to also merge the README patch right
away, but that failed due to line breaks in the email. 

BTW, about fat tests, I'm considering adding a make target "check-fat"
which will run make check with some different settings of
NETTLE_FAT_OVERRIDE (platform specific, and determined by configure).

Regards
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200720202719</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-07-20 20:27:19-0400</timestampReceived><subject>Re: [PATCH 2/6] "PowerPC64" Add optimized AES [Enc|Dec]</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; To get going, I've merged this and the machine.m4 patch to a development
&gt; branch. I'd like to do things stepwise, first do the minimal configure
&gt; changes to get AES working (and maybe with default on, to get it
&gt; exercised by the .gitlab-ci machinery),

Seems to pass tests! See
https://gitlab.com/gnutls/nettle/-/jobs/647514000 and
https://gitlab.com/gnutls/nettle/-/jobs/647514003

The branch is named "power-asm-wip".

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200721091115</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-07-21 09:11:15-0400</timestampReceived><subject>Re: [PATCH 2/6] "PowerPC64" Add optimized AES [Enc|Dec]</subject><body>

On Mon, Jul 20, 2020 at 8:41 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

Latency less than one cycle sounds wrong. Usually, simple ALU
&gt; instructions like xor has a latency of exactly one cycle (i.e., when an
&gt; instruction starts executing (all inputs are available), the result is
&gt; available for depending instructions exactly one cycle later). While
&gt; deeply pipelined instructions, e.g., multiplication, can have a latency
&gt; of several cycles but still a throughput of one or a few instructions
&gt; per cycle.
&gt;

I had the same concern, I measured the clock time from the start of the
instruction execution until the start of the next dependent instruction.
I'm sure about the latency numbers but not sure how to subtend them with
cycle numbers.

I take it "P8" in the path is for power 8? Are the crypto extensions
&gt; always available for power 8? If not, directory should be named
&gt; differently.
&gt;

Yes, it stands for POWER8, it's the minimal processor that supports the
crypto extensions, sticking  crypto extensions with POWER8 is fine.

To get going, I've merged this and the machine.m4 patch to a development
&gt; branch. I'd like to do things stepwise, first do the minimal configure
&gt; changes to get AES working (and maybe with default on, to get it
&gt; exercised by the .gitlab-ci machinery), then add ghash and fat builds
&gt; (not sure in which order). I wanted to also merge the README patch right
&gt; away, but that failed due to line breaks in the email.


Great, I will reupload the README file without incompatible line breaks.

BTW, about fat tests, I'm considering adding a make target "check-fat"
&gt; which will run make check with some different settings of
&gt; NETTLE_FAT_OVERRIDE (platform specific, and determined by configure).
&gt;

 I can help implementing this feature if you give me more details on how to
go with it.

Regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200722150425</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-07-22 15:04:25-0400</timestampReceived><subject>Re: [PATCH 2/6] "PowerPC64" Add optimized AES [Enc|Dec]</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; On Mon, Jul 20, 2020 at 8:41 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt;&gt; Latency less than one cycle sounds wrong.

&gt; I had the same concern, I measured the clock time from the start of the
&gt; instruction execution until the start of the next dependent instruction.
&gt; I'm sure about the latency numbers but not sure how to subtend them with
&gt; cycle numbers.

You may need to have a *long* chain of depending instructions to get an
accurate measurement of latency.
 
&gt;&gt; I take it "P8" in the path is for power 8? Are the crypto extensions
&gt;&gt; always available for power 8? If not, directory should be named
&gt;&gt; differently.
&gt;&gt;
&gt;
&gt; Yes, it stands for POWER8, it's the minimal processor that supports the
&gt; crypto extensions, sticking  crypto extensions with POWER8 is fine.

But in the patch for fat builds, you do the runtime check as

+  hwcap2 = getauxval(AT_HWCAP2);

+  features-&gt;have_crypto_ext =
+   (hwcap2 &amp; PPC_FEATURE2_VEC_CRYPTO) == PPC_FEATURE2_VEC_CRYPTO ? 1 : 0;

I think I would prefer to have a matching directory name in the source
tree, e.g., powerpc64/crypto_ext. 

Are the aes instructions and the ghash instructions (which I imagine
also has non-cryptographic uses) part of the same extension?

&gt;&gt; BTW, about fat tests, I'm considering adding a make target "check-fat"
&gt;&gt; which will run make check with some different settings of
&gt;&gt; NETTLE_FAT_OVERRIDE (platform specific, and determined by configure).
&gt;&gt;
&gt;
&gt;  I can help implementing this feature if you give me more details on how to
&gt; go with it.

The main thing I'm unsure about is that I don't know what extensions the
ci test machines can be expected to have. For cross tests, it
shouldn't be an issue as long as qemu supports all extensions of
interest. But for a native x86_64 fat build, do the test machines
have, e.g., the "sha_ni" extension? If not, we'd need to find out, and
prune what fat variants we test.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200904095509</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-09-04 09:55:09-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" AES improve syntax</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; This patch adds "VSR" macro to improve the syntax of assembly code,

Thanks, merged to master now.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200904100700</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-09-04 10:07:00-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" AES improve syntax</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; This patch adds "VSR" macro to improve the syntax of assembly code,

Speaking of syntax, I've had quick look at the powerpc64 assembly in
GMP, and it seems to use symbols like r1, r2, r3 etc for the general
purpose registers, and v0, v1, v2 etc for the vector registers. I think
that's a bit clearer than using raw numbers to reference registers. And
should hopefully result in compile time errors if one accidentally uses
a general purpose register where a vector register is expected, or vice
versa.

I guess both ways work with relevant assemblers?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200904120944</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-09-04 12:09:44-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" AES improve syntax</subject><body>

If these registers are used explicitly, GAS will yield a bunch of errors
like "Error: unsupported relocation against r1" unless "-mregnames" is
passed to the assembler. I can add "-Wa,-mregnames" to CFLAGS in
configure.ac and modify the assembly files to improve the syntax.

On Fri, Sep 4, 2020 at 1:07 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt; This patch adds "VSR" macro to improve the syntax of assembly code,
&gt;
&gt; Speaking of syntax, I've had quick look at the powerpc64 assembly in
&gt; GMP, and it seems to use symbols like r1, r2, r3 etc for the general
&gt; purpose registers, and v0, v1, v2 etc for the vector registers. I think
&gt; that's a bit clearer than using raw numbers to reference registers. And
&gt; should hopefully result in compile time errors if one accidentally uses
&gt; a general purpose register where a vector register is expected, or vice
&gt; versa.
&gt;
&gt; I guess both ways work with relevant assemblers?
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200723193532</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-07-23 19:35:32-0400</timestampReceived><subject>Re: [PATCH 2/6] "PowerPC64" Add optimized AES [Enc|Dec]</subject><body>

On Wed, Jul 22, 2020 at 6:04 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; But in the patch for fat builds, you do the runtime check as
&gt;
&gt; +  hwcap2 = getauxval(AT_HWCAP2);
&gt;
&gt; +  features-&gt;have_crypto_ext =
&gt; +   (hwcap2 &amp; PPC_FEATURE2_VEC_CRYPTO) == PPC_FEATURE2_VEC_CRYPTO ? 1 : 0;
&gt;
&gt; I think I would prefer to have a matching directory name in the source
&gt; tree, e.g., powerpc64/crypto_ext.
&gt;
&gt; Are the aes instructions and the ghash instructions (which I imagine
&gt; also has non-cryptographic uses) part of the same extension?
&gt;

Yes, both are part of the same extension. I considered calling the
directory "P8" for three reasons:
- POWER8 is the minimal processor that support the crypto extensions
- I measured the throughput and latency of the instructions on POWER8
- The current implementations can be enhanced further for POWER9 and newer
by using arch 3.00 specific instructions which was introduced in POWER9 so
we can call the directory of new implementations "P9"


&gt; The main thing I'm unsure about is that I don't know what extensions the
&gt; ci test machines can be expected to have. For cross tests, it
&gt; shouldn't be an issue as long as qemu supports all extensions of
&gt; interest. But for a native x86_64 fat build, do the test machines
&gt; have, e.g., the "sha_ni" extension? If not, we'd need to find out, and
&gt; prune what fat variants we test.
&gt;

I tested on my fork, "sha_ni" is not supported on gitlab ci

Regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200723211626</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-07-23 21:16:26-0400</timestampReceived><subject>Re: [PATCH 2/6] "PowerPC64" Add optimized AES [Enc|Dec]</subject><body>

On Mon, Jul 20, 2020 at 8:41 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; then add ghash and fat builds
&gt; (not sure in which order).
&gt;

I forgot to mention that you can merge them at any order.

Regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200731175640</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-07-31 17:56:40-0400</timestampReceived><subject>Re: [PATCH 2/6] "PowerPC64" Add optimized AES [Enc|Dec]</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; BTW, about fat tests, I'm considering adding a make target "check-fat"
&gt; which will run make check with some different settings of
&gt; NETTLE_FAT_OVERRIDE (platform specific, and determined by configure).

I've added this now, with fairly solid coverage for ARM and less
coverage for x86_64.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200801115317</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-08-01 11:53:17-0400</timestampReceived><subject>Re: [PATCH 2/6] "PowerPC64" Add optimized AES [Enc|Dec]</subject><body>

Sounds good.

Thank you,
Mamone

On Fri, Jul 31, 2020 at 9:42 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt; Yes, both are part of the same extension. I considered calling the
&gt; &gt; directory "P8" for three reasons:
&gt; &gt; - POWER8 is the minimal processor that support the crypto extensions
&gt; &gt; - I measured the throughput and latency of the instructions on POWER8
&gt; &gt; - The current implementations can be enhanced further for POWER9 and
&gt; newer
&gt; &gt; by using arch 3.00 specific instructions which was introduced in POWER9
&gt; so
&gt; &gt; we can call the directory of new implementations "P9"
&gt;
&gt; Ok, let's stay with that naming (but I'll consider changing to lowercase
&gt; "p8", to match other directory names). If it turns out something more
&gt; fine grained is needed later, files can be mover around then.
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200709131119</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-07-09 13:11:19-0400</timestampReceived><subject>Re: [PATCH 1/4] Check for PowerPC64 assembly if crypto extensions are available</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; +dnl NETTLE_CHECK_POWER_CRYPTO_EXT
&gt; +dnl ---------------------
&gt; +dnl Check if POWER crypto extensions should be used.
&gt; +dnl Obeys enable_power_crypto_ext, which should be set earlier.
&gt; +AC_DEFUN([NETTLE_CHECK_POWER_CRYPTO_EXT],
&gt; +[if test "$enable_power_crypto_ext" = auto ; then
&gt; +  if test "$cross_compiling" = yes ; then
&gt; +    dnl Check if compiler/assembler accepts it.
&gt; +    AC_CACHE_CHECK([if assembler accepts crypto instructions],
&gt; +      nettle_cv_asm_power_vcrypto,
&gt; +      [GMP_TRY_ASSEMBLE([
&gt; +.text
&gt; +foo:
&gt; + vcipher 0, 0, 1
&gt; +],
&gt; +      [nettle_cv_asm_power_vcrypto=yes],
&gt; +      [nettle_cv_asm_power_vcrypto=no])])
&gt; +    enable_power_crypto_ext="$nettle_cv_asm_power_vcrypto"
&gt; +  else
&gt; +    AC_CACHE_CHECK([if crypto extensions supported],
&gt; +      nettle_cv_asm_power_vcrypto,
&gt; +      [AC_RUN_IFELSE([AC_LANG_PROGRAM([[
&gt; +#if defined(__FreeBSD__) &amp;&amp; __FreeBSD__ &lt; 12
&gt; +#include &lt;sys/sysctl.h&gt;
&gt; +#else
&gt; +#include &lt;sys/auxv.h&gt;
&gt; +#endif

Do you expect that this "auto" logic does what that user wants? I'm
thinking, maybe it's simpler to stick with just yes/no (no being the
default), and then add support for --enable-fat later, to select code at
run-time?

&gt; --- /dev/null
&gt; +++ b/powerpc64/machine.m4
&gt; @@ -0,0 +1,24 @@
&gt; +define(&lt;PROLOGUE&gt;,
&gt; +&lt;ifelse(WORDS_BIGENDIAN,no,
&gt; +&lt;.align 5
&gt; +.globl C_NAME($1)
&gt; +DECLARE_FUNC(C_NAME($1))
&gt; +C_NAME($1):
&gt; +addis 2,12,(.TOC.-C_NAME($1))@ha
&gt; +addi 2,2,(.TOC.-C_NAME($1))@l
&gt; +.localentry C_NAME($1), .-C_NAME($1)&gt;,
&gt; +&lt;.globl C_NAME($1)
&gt; +DECLARE_FUNC(C_NAME($1))
&gt; +.section ".opd","aw"
&gt; +.align 3
&gt; +C_NAME($1):
&gt; +.quad .C_NAME($1),.TOC.@tocbase,0
&gt; +.previous
&gt; +.align 5
&gt; +.C_NAME($1):&gt;)&gt;)

Overriding PROLOGUE here looks fine, but it would be nice with a comment
explaining what's needed, and/or linking the some appropriate ABI
specification.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200709145854</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-07-09 14:58:54-0400</timestampReceived><subject>Re: [PATCH 4/4] Add AES [Enc|Dec] optimized implementations for PowerPC64</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; +L16x_round_loop:
&gt; + lxvd2x KX,10,KEYS
&gt; + vperm   K,K,K,swap_mask
&gt; + vncipher S0,S0,ZERO
&gt; + vncipher S1,S1,ZERO
&gt; + vncipher S2,S2,ZERO
&gt; + vncipher S3,S3,ZERO
&gt; + vncipher S4,S4,ZERO
&gt; + vncipher S5,S5,ZERO
&gt; + vncipher S6,S6,ZERO
&gt; + vncipher S7,S7,ZERO
&gt; + vncipher S8,S8,ZERO
&gt; + vncipher S9,S9,ZERO
&gt; + vncipher S10,S10,ZERO
&gt; + vncipher S11,S11,ZERO
&gt; + vncipher S12,S12,ZERO
&gt; + vncipher S13,S13,ZERO
&gt; + vncipher S14,S14,ZERO
&gt; + vncipher S15,S15,ZERO
&gt; + vxor S0,S0,K
&gt; + vxor S1,S1,K
&gt; + vxor S2,S2,K
&gt; + vxor S3,S3,K
&gt; + vxor S4,S4,K
&gt; + vxor S5,S5,K
&gt; + vxor S6,S6,K
&gt; + vxor S7,S7,K
&gt; + vxor S8,S8,K
&gt; + vxor S9,S9,K
&gt; + vxor S10,S10,K
&gt; + vxor S11,S11,K
&gt; + vxor S12,S12,K
&gt; + vxor S13,S13,K
&gt; + vxor S14,S14,K
&gt; + vxor S15,S15,K
&gt; + addi 10,10,0x10
&gt; + bdnz L16x_round_loop

Do you really need to go all the way to 16 blocks in parallel to
saturate the execution units? I'm used to defining throughput and
latency of an instruction (e.g., vncipher) as follows:

Throughput: The number of independent vncipher instructions that can be
executed per cycle. Can be measured by benchmarking a loop of
independent instructions.

Latency: The number of cycles from the start of execution of a vncipher
instruction until execution of an instruction depending on the vncipher
result can start. Can be measured by benchmarking a loop where each
instruction depends on the result of the preceding instruction.

Do you know throughput and latency of the vncipher and vxor
instructions? (Official manuals are not always to be trusted). Those
numbers determines how much parallelism is needed, typically the product
of latency and throughput.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200702115841</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-07-02 11:58:41-0400</timestampReceived><subject>Re: [PATCH] Add bcrypt tests to testsuite.</subject><body>

"Stephen R. van den Berg" &lt;srb@cuci.nl&gt; writes:

&gt;  testsuite/blowfish-test.c | 47 +++++++++++++++++++++++++++++++++++++++
&gt;  1 file changed, 47 insertions(+)

Thanks. I've moved the tests to its own file, and pushed to the bcrypt
branch.

I'm thinking, maybe it makes sense to also move the bcrypt-related
declarations to a new (public) header file, bcrypt.h ?

Opinions?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200702131432</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-07-02 13:14:32-0400</timestampReceived><subject>Re: [PATCH] Add bcrypt tests to testsuite.</subject><body>

On Thu, Jul 2, 2020 at 1:58 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; I'm thinking, maybe it makes sense to also move the bcrypt-related
&gt; declarations to a new (public) header file, bcrypt.h ?


Considering that:
- The function names currently are prefixed by blowfish_.
- The footprint of the declarations is not overly large (two extra
functions and two macros).
- When linking, the bcrypt functions will not be linked in unless needed,
already.

It would only make programming for it more complicated to separate them
into a different file for no apparent benefit.
So I'd prefer the current setup.
-- 
Stephen.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200704123824</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-07-04 12:38:24-0400</timestampReceived><subject>Re: [PATCH] Add bcrypt tests to testsuite.</subject><body>

"Stephen R. van den Berg" &lt;srb@cuci.nl&gt; writes:

&gt; It would only make programming for it more complicated to separate them
&gt; into a different file for no apparent benefit.
&gt; So I'd prefer the current setup.

I was thinking that it seems unusual for an application to want use both
blowfish and bcrypt (directly), since they are quite differently shaped
pieces. But I have no strong opinion on this.

Regards,
/Niels 

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200704202130</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-07-04 20:21:30-0400</timestampReceived><subject>Re: [PATCH] Add bcrypt tests to testsuite.</subject><body>

On Sat, Jul 4, 2020 at 2:38 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; I was thinking that it seems unusual for an application to want use both
&gt; blowfish and bcrypt (directly), since they are quite differently shaped
&gt; pieces.


True, but I fail to see how separating it into a different headerfile will
make this easier or more efficient.
In general, if you ask me, I'd say the more headerfiles you provide, the
more complicated it becomes to program to the API.
-- 
Stephen.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200604175923</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-06-04 17:59:23-0400</timestampReceived><subject>Re: [PATCH v2 1/8] Implement GOST R 34.11-2012 (Streebog) hash function</subject><body>

Thanks for splitting this out for review. Looks pretty good, a few minor
comments below.

Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:

&gt; --- /dev/null
&gt; +++ b/streebog.c
&gt; @@ -0,0 +1,1334 @@
&gt; +/* streebog.c - GOST R 34.11-2012 (Streebog) hash function

Would be nice with a reference to an English language spec, both in the
file header and the docs (later patch). I take it it's RFC 6986?

&gt; +/* Pre-computed results of multiplication of bytes on A and reordered with
&gt; +   Pi[]. */
&gt; +static const uint64_t streebog_table[8][256] =
&gt; +{
&gt; +  /* 0 */
&gt; +  { 0xd01f715b5c7ef8e6ULL, 0x16fa240980778325ULL,

In some ways, UINT64_C(0xd01f715b5c7ef8e6), from stdint.h, is more
kosher. But ULL is a bit more readable (IMO), so unless it causes any
practical problems on some platform, I think it's fine as is.

&gt; +static void
&gt; +streebog512_compress (struct streebog512_ctx *ctx, const uint8_t *input, size_t count)
&gt; +{
&gt; +  uint64_t M[8];
&gt; +  uint64_t l, cf;
&gt; +  int i;
&gt; +
&gt; +  for (i = 0; i &lt; 8; i++, input += 8)
&gt; +    M[i] = LE_READ_UINT64(input);
&gt; +
&gt; +  g (ctx-&gt;state, M, ctx-&gt;count);
&gt; +  l = ctx-&gt;count[0];
&gt; +  ctx-&gt;count[0] += count;
&gt; +  if (ctx-&gt;count[0] &lt; l)

The overflow check could be written

  if (ctx-&gt;count[0] &lt; count)

and then the local variable l can be deleted. I also think it would be
clearer to change the type of count to uint64_t to match the type of
ctx-&gt;count. Do I get it right, that the count argument always is fairly
small?

&gt; +    { /* overflow */
&gt; +      for (i = 1; i &lt; 8; i++)
&gt; +        {
&gt; +          ctx-&gt;count[i]++;
&gt; +          if (ctx-&gt;count[i] != 0)
&gt; +            break;
&gt; +        }
&gt; +    }

How far can carry propagate here? If I read it correctly, the count
array represents a 512 bit number, initialized to zero. So will be
tricky to get test coverage. 

&gt; +  cf = 0;
&gt; +  ctx-&gt;sigma[0] += M[0];
&gt; +  for (i = 1; i &lt; 8; i++)
&gt; +    {
&gt; +      if (ctx-&gt;sigma[i-1] != M[i-1])
&gt; +	cf = (ctx-&gt;sigma[i-1] &lt; M[i-1]);
&gt; +      ctx-&gt;sigma[i] += M[i] + cf;
&gt; +    }

This is a bignum addition of the sigma and the M arrays? I think I would
write it as something like (untested):

  ctx-&gt;sigma[0] += M[0];
  cf = (ctx-&gt;sigma[0] &lt; M[0]);
  for (i = 1; i &lt; 8; i++)
    {
      ctx-&gt;sigma[i] += cf;
      cf = (ctx-&gt;sigma[i] &lt; cf);
      ctx-&gt;sigma[i] += M[i];
      cf += (ctx-&gt;sigma[i] &lt; M[i]);  /* |= works fine too */
    }

Or maybe with

  for (i = 1; i &lt; 7; i++) {...}
  ctx-&gt;sigma[7] += M[7] + cf;

if we want to skip operations for the final carry out.

Maybe with a local variable accumulating the final value for sigma[i],
to not have to read and write multiple times (but maybe the compiler
will eliminate memory accesses). For reference, the corresponding GMP C
loop is at https://gmplib.org/repo/gmp/file/tip/mpn/generic/add_n.c#l37

&gt; +static void
&gt; +streebog512_write_digest(struct streebog512_ctx *ctx,
&gt; +                         size_t offset, size_t length,
&gt; +                         uint8_t *digest)
&gt; +{
&gt; +  unsigned i;
&gt; +  unsigned words;
&gt; +  unsigned leftover;
&gt; +
&gt; +  assert(offset + length &lt;= STREEBOG512_DIGEST_SIZE);
&gt; +
&gt; +  streebog_final(ctx);
&gt; +
&gt; +  words = length / 8;
&gt; +  leftover = length % 8;
&gt; +
&gt; +  for (i = 0; i &lt; words; i++, digest += 8)
&gt; +    LE_WRITE_UINT64(digest, ctx-&gt;state[offset + i]);
&gt; +
&gt; +  if (leftover)
&gt; +    {
&gt; +      /* Truncate to the right size */
&gt; +      uint64_t word = ctx-&gt;state[offset + i] &lt;&lt; (8*(8 - leftover));
&gt; +
&gt; +      do {
&gt; +	digest[--leftover] = (word &gt;&gt; 56) &amp; 0xff;
&gt; +	word &lt;&lt;= 8;
&gt; +      } while (leftover);
&gt; +    }

Could this use _nettle_write_le64 instead?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200504172416</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-05-04 17:24:16-0400</timestampReceived><subject>Re: ANNOUNCE: Nettle-3.6</subject><body>

Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:

&gt; I just wanted to point that git tree was not updated for the release.

Thanks for telling me! Should be up to date now. 

I think the way it happened, was that I ran git push --tags under the
assumption that it would push tags in addition to the current branch,
and I didn't pay close attention.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200330131628</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2020-03-30 13:16:28-0400</timestampReceived><subject>Re: Nettle 3.5.1 and OS X 10.12 patch</subject><body>

Hi Jeff,

On Sat, Mar 28, 2020 at 01:52:05AM -0400, Jeffrey Walton wrote:

&gt; I know Apple did some hardening lately but I have not read anything
&gt; about scrubbing LD_LIBRARY_PATH and DYLD_LIBRARY_PATH. But it appears
&gt; something was sanitizing the environment.

In a quick test on Mojave it appears that any attempt to setenv() a
variable that starts with DYLD_ is silently ignored. Can you confirm
that? My testcase is:

DYLD_FOO=foo DLYD_FOO=bar bash -c 'echo $DYLD_FOO $DLYD_FOO'

from which I get only 'bar' and no 'foo'.

&gt; The short of it is, each test runner, like run-tests.sh, needed to
&gt; restore the variables using an absolute path. dirname is Posix so it
&gt; is available to strip the unwanted path component, like testsuite/ or
&gt; example/.

&gt; +nettle_lib_dir=`dirname $PWD`/.lib
&gt; +LD_LIBRARY_PATH=$nettle_lib_dir
&gt; +DYLD_LIBRARY_PATH=$nettle_lib_dir
&gt; +
&gt; +export LD_LIBRARY_PATH
&gt; +export DYLD_LIBRARY_PATH

I recently ran into a similar problem where uClibc on Linux by default
ignores relative paths in LD_LIBRARY_PATH causing the same problems when
running the test suite. So there's two reasons to think about
alternatives to setting the variable.

Is the testsuite supposed to be relocatable or installable? If not, we
could link with something like -Wl,-rpath,$(dir $(shell pwd))/.lib to
avoid this issue (until Apple or uClibc hardens some more ;). I see that
configure already checks and sets RPATHFLAG (seems unused though!?), so
we could reuse that to try and avoid other fallout.
-- 
Best wishes,
Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200331072702</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-03-31 07:27:02-0400</timestampReceived><subject>Re: Nettle 3.5.1 and OS X 10.12 patch</subject><body>

Michael Weiser &lt;michael.weiser@gmx.de&gt; writes:

&gt; In a quick test on Mojave it appears that any attempt to setenv() a
&gt; variable that starts with DYLD_ is silently ignored. Can you confirm
&gt; that? My testcase is:
&gt;
&gt; DYLD_FOO=foo DLYD_FOO=bar bash -c 'echo $DYLD_FOO $DLYD_FOO'
&gt;
&gt; from which I get only 'bar' and no 'foo'.

Odd. I hope it's still possible to set DYLD_LIBRARY_PATH to a valid
absolute name of a directory?

&gt; I recently ran into a similar problem where uClibc on Linux by default
&gt; ignores relative paths in LD_LIBRARY_PATH causing the same problems when
&gt; running the test suite. So there's two reasons to think about
&gt; alternatives to setting the variable.

I think a reasonable way is to add 

abs_top_builddir = @abs_top_builddir@

TEST_SHLIB_DIR = "${abs_top_builddir}/.lib"

to config.make.in, and use that to set LD_LIBRARY_PATH. And possibly
only pass TEST_SHLIB_DIR to the run-tests script, and move the logic to
setup the environment.

&gt; Is the testsuite supposed to be relocatable or installable? 

Not the test programs, but the programs in tools/ are, and they're also
run by the testsuite.

&gt; If not, we could link with something like -Wl,-rpath,$(dir $(shell
&gt; pwd))/.lib to avoid this issue (until Apple or uClibc hardens some
&gt; more ;). I see that configure already checks and sets RPATHFLAG (seems
&gt; unused though!?), so we could reuse that to try and avoid other
&gt; fallout.

It's used by LSH_RPATH_FIX, just after the check for gmp.

: # Checks for libraries
: if test "x$enable_public_key" = "xyes" ; then
:   if test "x$enable_mini_gmp" = "xno" ; then
:     AC_CHECK_LIB(gmp, __gmpn_sec_div_r,,
:         [AC_MSG_WARN(
:     [GNU MP not found, or too old. GMP-6.0 or later is needed, see
:     https://gmplib.org/.
:     Support for public key algorithms will be unavailable.])]
:         enable_public_key=no)
: 
:     # Add -R flags needed to run programs linked with gmp
:     LSH_RPATH_FIX
:   fi
: fi

This is intended to handle the case that gmp is in /usr/local, you
configure with --with-lib-path=/usr/local/lib
--with-inlcude-path=/usr/local/include, but the runtime linker doesn't
look in /usr/local/lib. Then LSH_RPATH_FIX will add the appropriate
flag to set rpath. (I see there are some other unused macros in
aclocal.m4, left overs from when nettle was taken out of lsh).

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200331093308</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2020-03-31 09:33:08-0400</timestampReceived><subject>Re: Nettle 3.5.1 and OS X 10.12 patch</subject><body>

Hello Niels,

On Tue, Mar 31, 2020 at 09:27:02AM +0200, Niels Möller wrote:

&gt; &gt; In a quick test on Mojave it appears that any attempt to setenv() a
&gt; &gt; variable that starts with DYLD_ is silently ignored. Can you confirm
&gt; &gt; that? My testcase is:
&gt; &gt;
&gt; &gt; DYLD_FOO=foo DLYD_FOO=bar bash -c 'echo $DYLD_FOO $DLYD_FOO'
&gt; &gt;
&gt; &gt; from which I get only 'bar' and no 'foo'.
&gt; Odd. I hope it's still possible to set DYLD_LIBRARY_PATH to a valid
&gt; absolute name of a directory?

No, unfortunately it's not. Any attempt to set an environment variable
whose name starts with DYLD_ seems to be ignored. It doesn't matter if
you're a normal, admin or the root user either. It appears to be caused
by SIP (System Integrity Protection):

https://github.com/nasa/europa/issues/181

And indeed on another system where I have SIP disabled, exporting
DYLD_-variables works as expected with above test case. dyld even prints
a warning that it doesn't know variable DYLD_FOO.
-- 
Thanks,
Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200331095138</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-03-31 09:51:38-0400</timestampReceived><subject>Re: Nettle 3.5.1 and OS X 10.12 patch</subject><body>

On Tue, Mar 31, 2020 at 5:45 AM Michael Weiser &lt;michael.weiser@gmx.de&gt; wrote:
&gt;
&gt; On Tue, Mar 31, 2020 at 09:27:02AM +0200, Niels Möller wrote:
&gt;
&gt; &gt; &gt; In a quick test on Mojave it appears that any attempt to setenv() a
&gt; &gt; &gt; variable that starts with DYLD_ is silently ignored. Can you confirm
&gt; &gt; &gt; that? My testcase is:
&gt; &gt; &gt;
&gt; &gt; &gt; DYLD_FOO=foo DLYD_FOO=bar bash -c 'echo $DYLD_FOO $DLYD_FOO'
&gt; &gt; &gt;
&gt; &gt; &gt; from which I get only 'bar' and no 'foo'.
&gt; &gt; Odd. I hope it's still possible to set DYLD_LIBRARY_PATH to a valid
&gt; &gt; absolute name of a directory?
&gt;
&gt; No, unfortunately it's not. Any attempt to set an environment variable
&gt; whose name starts with DYLD_ seems to be ignored. It doesn't matter if
&gt; you're a normal, admin or the root user either. It appears to be caused
&gt; by SIP (System Integrity Protection):

SIP came to mind for me, too. I know SIP forbids installation in
directories other then /usr/local. But I could not find reading that
said it scrubbed the environmental variables.

I think Nettle's best choice is to set the variable in its test runner
scripts, like run-tests.sh. We know things work when set from there.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200331102809</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2020-03-31 10:28:09-0400</timestampReceived><subject>Re: Nettle 3.5.1 and OS X 10.12 patch</subject><body>

Hi Jeff,

On Tue, Mar 31, 2020 at 05:51:38AM -0400, Jeffrey Walton wrote:

&gt; &gt; &gt; &gt; In a quick test on Mojave it appears that any attempt to setenv() a
&gt; &gt; &gt; &gt; variable that starts with DYLD_ is silently ignored. Can you confirm
&gt; &gt; &gt; Odd. I hope it's still possible to set DYLD_LIBRARY_PATH to a valid
&gt; &gt; &gt; absolute name of a directory?
&gt; &gt; No, unfortunately it's not. Any attempt to set an environment variable
&gt; &gt; whose name starts with DYLD_ seems to be ignored. It doesn't matter if
&gt; &gt; you're a normal, admin or the root user either. It appears to be caused
&gt; &gt; by SIP (System Integrity Protection):
&gt; I think Nettle's best choice is to set the variable in its test runner
&gt; scripts, like run-tests.sh. We know things work when set from there.

Looking at your original mail I'm now struggling to see how exporting
DYLD_LIBRARY_PATH closer to the test execution solves the issue. In my
quick tests, exporting the variable is always ignored, no matter where
and also in shell scripts.

(BTW: Apart from the code lines in your mail there was no patch attached
to your mail. Was that intentional?)

I'm currently downloading Xcode and command line devel tools for Mojave
to be able to test directly on the SIP-enabled box.

The github issue I referenced has a pretty comprehensive list of
options
(https://github.com/nasa/europa/issues/181#issuecomment-496614956):

1. Disable SIP as @theronic suggests.
2. Set DYLD_LIBRARY_PATH in main via setenv()
3. Link statically
4. Use otool to fix up the paths

(1. being a practical no-go)
(2. not being an option for the tests because they already need to have
    found, loaded and linked the correct libnettle when their main is
    invoked. I think this would only work with dlopen().)

I already added:
5. Link with runtime path.

What also comes to mind is:
6. Link with @origin or @executable relative paths. That's something ELF
can do also.

Seems a lot of effort just for the test suite though.
-- 
Best wishes,
Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200331104458</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-03-31 10:44:58-0400</timestampReceived><subject>Re: Nettle 3.5.1 and OS X 10.12 patch</subject><body>

On Tue, Mar 31, 2020 at 6:30 AM Michael Weiser &lt;michael.weiser@gmx.de&gt; wrote:
&gt; 
&gt; On Tue, Mar 31, 2020 at 05:51:38AM -0400, Jeffrey Walton wrote:
&gt; 
&gt; &gt; &gt; &gt; &gt; In a quick test on Mojave it appears that any attempt to setenv() a
&gt; &gt; &gt; &gt; &gt; variable that starts with DYLD_ is silently ignored. Can you confirm
&gt; &gt; &gt; &gt; Odd. I hope it's still possible to set DYLD_LIBRARY_PATH to a valid
&gt; &gt; &gt; &gt; absolute name of a directory?
&gt; &gt; &gt; No, unfortunately it's not. Any attempt to set an environment variable
&gt; &gt; &gt; whose name starts with DYLD_ seems to be ignored. It doesn't matter if
&gt; &gt; &gt; you're a normal, admin or the root user either. It appears to be caused
&gt; &gt; &gt; by SIP (System Integrity Protection):
&gt; &gt; I think Nettle's best choice is to set the variable in its test runner
&gt; &gt; scripts, like run-tests.sh. We know things work when set from there.
&gt; 
&gt; Looking at your original mail I'm now struggling to see how exporting
&gt; DYLD_LIBRARY_PATH closer to the test execution solves the issue. In my
&gt; quick tests, exporting the variable is always ignored, no matter where
&gt; and also in shell scripts.

Here's another example:
https://apple.stackexchange.com/questions/286315/system-integrity-protection-breaks-dyld-library-path-for-python-scripts


Apparently /bin/sh and /usr/bin/env are SIP protected, so they get
some of their variables scrubbed.

I believe the reason the patch works is, the environment is scrubbed
before run-tests.sh is run. run-tests.sh then sets DYLD_LIBRARY_PATH
(and friends). Since the test runner is calling programs outside the
SIP boundary, the variables persist.

&gt; (BTW: Apart from the code lines in your mail there was no patch attached
&gt; to your mail. Was that intentional?)

My bad... I thought it was attached.

Here is the patch online:
https://github.com/noloader/Build-Scripts/blob/master/patch/nettle.patch
. Ignore the xts.c and ctr.c parts. They are hacks to work around
another issue on older 32-bit machines.

&gt; I'm currently downloading Xcode and command line devel tools for Mojave
&gt; to be able to test directly on the SIP-enabled box.
&gt; 
&gt; The github issue I referenced has a pretty comprehensive list of
&gt; options
&gt; (https://github.com/nasa/europa/issues/181#issuecomment-496614956):
&gt; 
&gt; 1. Disable SIP as @theronic suggests.
&gt; 2. Set DYLD_LIBRARY_PATH in main via setenv()
&gt; 3. Link statically
&gt; 4. Use otool to fix up the paths
&gt; 
&gt; (1. being a practical no-go)
&gt; (2. not being an option for the tests because they already need to have
&gt; found, loaded and linked the correct libnettle when their main is
&gt; invoked. I think this would only work with dlopen().)
&gt; 
&gt; I already added:
&gt; 5. Link with runtime path.
&gt; 
&gt; What also comes to mind is:
&gt; 6. Link with @origin or @executable relative paths. That's something ELF
&gt; can do also.
&gt; 
&gt; Seems a lot of effort just for the test suite though.

(2) may work, but it is not needed (based on my experience). Just set
LD_LIBRARY_PATH and DYLD_LIBRARY_PATH in the test runner.

It may be worth mentioning that once Nettle is installed into
/usr/local, then everything is OK. The thorny part is 'make check'
before install. The test runners need &lt;nettle dir&gt;/.lib on-path to
find the new libraries before install.

And if you already have Nettle installed, then you probably won't
encounter the issue because the system will find the *.dylibs in
/usr/local instead of using the ones at &lt;nettle dir&gt;/.lib.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200331105137</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-03-31 10:51:37-0400</timestampReceived><subject>Re: Nettle 3.5.1 and OS X 10.12 patch</subject><body>

On Tue, Mar 31, 2020 at 6:44 AM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:
&gt; 
&gt; On Tue, Mar 31, 2020 at 6:30 AM Michael Weiser &lt;michael.weiser@gmx.de&gt; wrote:
&gt; &gt; 
&gt; &gt; On Tue, Mar 31, 2020 at 05:51:38AM -0400, Jeffrey Walton wrote:
&gt; &gt; 
&gt; &gt; &gt; &gt; &gt; &gt; In a quick test on Mojave it appears that any attempt to setenv() a
&gt; &gt; &gt; &gt; &gt; &gt; variable that starts with DYLD_ is silently ignored. Can you confirm
&gt; &gt; &gt; &gt; &gt; Odd. I hope it's still possible to set DYLD_LIBRARY_PATH to a valid
&gt; &gt; &gt; &gt; &gt; absolute name of a directory?
&gt; &gt; &gt; &gt; No, unfortunately it's not. Any attempt to set an environment variable
&gt; &gt; &gt; &gt; whose name starts with DYLD_ seems to be ignored. It doesn't matter if
&gt; &gt; &gt; &gt; you're a normal, admin or the root user either. It appears to be caused
&gt; &gt; &gt; &gt; by SIP (System Integrity Protection):
&gt; &gt; &gt; I think Nettle's best choice is to set the variable in its test runner
&gt; &gt; &gt; scripts, like run-tests.sh. We know things work when set from there.
&gt; &gt; 
&gt; &gt; Looking at your original mail I'm now struggling to see how exporting
&gt; &gt; DYLD_LIBRARY_PATH closer to the test execution solves the issue. In my
&gt; &gt; quick tests, exporting the variable is always ignored, no matter where
&gt; &gt; and also in shell scripts.
&gt; 
&gt; Here's another example:
&gt; https://apple.stackexchange.com/questions/286315/system-integrity-protection-breaks-dyld-library-path-for-python-scripts
&gt;  
&gt; Apparently /bin/sh and /usr/bin/env are SIP protected, so they get
&gt; some of their variables scrubbed.
&gt; 
&gt; I believe the reason the patch works is, the environment is scrubbed
&gt; before run-tests.sh is run. run-tests.sh then sets DYLD_LIBRARY_PATH
&gt; (and friends). Since the test runner is calling programs outside the
&gt; SIP boundary, the variables persist.
&gt; 
&gt; &gt; (BTW: Apart from the code lines in your mail there was no patch attached
&gt; &gt; to your mail. Was that intentional?)
&gt; 
&gt; My bad... I thought it was attached.
&gt; 
&gt; Here is the patch online:
&gt; https://github.com/noloader/Build-Scripts/blob/master/patch/nettle.patch
&gt; . Ignore the xts.c and ctr.c parts. They are hacks to work around
&gt; another issue on older 32-bit machines.
&gt; 
&gt; &gt; I'm currently downloading Xcode and command line devel tools for Mojave
&gt; &gt; to be able to test directly on the SIP-enabled box.
&gt; &gt; 
&gt; &gt; The github issue I referenced has a pretty comprehensive list of
&gt; &gt; options
&gt; &gt; (https://github.com/nasa/europa/issues/181#issuecomment-496614956):
&gt; &gt; 
&gt; &gt; 1. Disable SIP as @theronic suggests.
&gt; &gt; 2. Set DYLD_LIBRARY_PATH in main via setenv()
&gt; &gt; 3. Link statically
&gt; &gt; 4. Use otool to fix up the paths
&gt; &gt; 
&gt; &gt; (1. being a practical no-go)
&gt; &gt; (2. not being an option for the tests because they already need to have
&gt; &gt; found, loaded and linked the correct libnettle when their main is
&gt; &gt; invoked. I think this would only work with dlopen().)
&gt; &gt; 
&gt; &gt; I already added:
&gt; &gt; 5. Link with runtime path.
&gt; &gt; 
&gt; &gt; What also comes to mind is:
&gt; &gt; 6. Link with @origin or @executable relative paths. That's something ELF
&gt; &gt; can do also.
&gt; &gt; 
&gt; &gt; Seems a lot of effort just for the test suite though.
&gt; 
&gt; (2) may work, but it is not needed (based on my experience). Just set
&gt; LD_LIBRARY_PATH and DYLD_LIBRARY_PATH in the test runner.
&gt; 
&gt; It may be worth mentioning that once Nettle is installed into
&gt; /usr/local, then everything is OK. The thorny part is 'make check'
&gt; before install. The test runners need &lt;nettle dir&gt;/.lib on-path to
&gt; find the new libraries before install.
&gt; 
&gt; And if you already have Nettle installed, then you probably won't
&gt; encounter the issue because the system will find the *.dylibs in
&gt; /usr/local instead of using the ones at &lt;nettle dir&gt;/.lib.

I forgot to mention... DYLD_FALLBACK_LIBRARY_PATH may work. Apple used
to have a man page on it, but I can't find it anymore.

The man page used to say, don't use DYLD_LIBRARY_PATH . Instead, use
DYLD_FALLBACK_LIBRARY_PATH . The problem is, the fallback path is
checked after other paths (iirc). That means an old Nettle in
/usr/local might be loaded instead of the new Nettle in .lib/

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200331115138</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2020-03-31 11:51:38-0400</timestampReceived><subject>Re: Nettle 3.5.1 and OS X 10.12 patch</subject><body>

Hi Jeff,

On Tue, Mar 31, 2020 at 06:51:37AM -0400, Jeffrey Walton wrote:

&gt; &gt; I believe the reason the patch works is, the environment is scrubbed
&gt; &gt; before run-tests.sh is run. run-tests.sh then sets DYLD_LIBRARY_PATH
&gt; &gt; (and friends). Since the test runner is calling programs outside the
&gt; &gt; SIP boundary, the variables persist.
I verified as much by copying /bin/bash to ~/bash and running it from
there. Indeed, exported DYLD-variables propagate to ~/bash.

&gt; &gt; &gt; 1. Disable SIP as @theronic suggests.
&gt; &gt; &gt; 2. Set DYLD_LIBRARY_PATH in main via setenv()
&gt; &gt; &gt; 3. Link statically
&gt; &gt; &gt; 4. Use otool to fix up the paths
&gt; &gt; &gt; 5. Link with runtime path.
&gt; &gt; &gt; 6. Link with @origin or @executable relative paths.
&gt; &gt; (2) may work, but it is not needed (based on my experience). Just set
&gt; &gt; LD_LIBRARY_PATH and DYLD_LIBRARY_PATH in the test runner.
&gt; I forgot to mention... DYLD_FALLBACK_LIBRARY_PATH may work. Apple used
&gt; to have a man page on it, but I can't find it anymore.

It's in dyld(1).

&gt; The man page used to say, don't use DYLD_LIBRARY_PATH . Instead, use
&gt; DYLD_FALLBACK_LIBRARY_PATH . The problem is, the fallback path is
&gt; checked after other paths (iirc). That means an old Nettle in
&gt; /usr/local might be loaded instead of the new Nettle in .lib/

Indeed, DYLD_FALLBACK_LIBRARY_PATH is not stripped but will also not
prevent an already installed libnettle from being used for the tests.
-- 
Thanks,
Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200331180835</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-03-31 18:08:35-0400</timestampReceived><subject>Re: Nettle 3.5.1 and OS X 10.12 patch</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; I think a reasonable way is to add 
&gt;
&gt; abs_top_builddir = @abs_top_builddir@
&gt;
&gt; TEST_SHLIB_DIR = "${abs_top_builddir}/.lib"
&gt;
&gt; to config.make.in, and use that to set LD_LIBRARY_PATH. And possibly
&gt; only pass TEST_SHLIB_DIR to the run-tests script, and move the logic to
&gt; setup the environment.

I've pushed a change like that to the branch test-shlib-dir. Please try
it out.

This also makes tests with a shared-library build work in termux on my
android phone. It used to fail, in part because termux depends on
LD_LIBRARY_PATH being set, and possibly with additional trouble from
using an LD_LIBRARY_PATH with relative file names.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200401060613</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-01 06:06:13-0400</timestampReceived><subject>Re: Nettle 3.5.1 and OS X 10.12 patch</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; Tested mostly OK on my mac-mini:

Thanks for testing.

&gt; dyld: Library not loaded: /Users/jwalton/tmp/nettle/lib/libnettle.7.dylib

Is this the expected location after install, from 

  -install_name ${libdir}/$(LIBNETTLE_SONAME)

on the command linking libnettle.dylib?

Then maybe using DYLD_FALLBACK_LIBRARY_PATH could work a bit better, if
the runtime linker only looks for libnettle.7.dylib in the given install
location, and not in system directories. Will still not be correct if
you install into a location where you have an older version but with the
same soname, but at least will be correct in some more cases?

&gt;   Referenced from:
&gt; /Users/jwalton/Build-Scripts/nettle-master/testsuite/../tools/sexp-conv
&gt;   Reason: image not found
&gt; cmp: EOF on test1.out
&gt; FAIL: sexp-conv
&gt; FAIL: pkcs1-conv
&gt; FAIL: nettle-pbkdf2

The three failing tests are /bin/sh scripts running the binaries in
tools/. I guess those still have DYLD_LIBRARY_PATH dropped from the
environment, can you confirm?

To me, "system integrity protection", dropping DYLD_LIBRARY_PATH, seems
a bit pointless in a setting where we're running code of our choice
anyway. 

Do you see any clean workaround? One could maybe delegate it further,
similar to how $EMULATOR is handled.

Otherwise, we may just have to recommend disabling this "protection" on
macs used for development (according to the linked comments, boot in
"recovery mode", run csrutil disable).

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200401063547</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-04-01 06:35:47-0400</timestampReceived><subject>Re: Nettle 3.5.1 and OS X 10.12 patch</subject><body>

On Wed, Apr 1, 2020 at 2:06 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; Jeffrey Walton &lt;noloader@gmail.com&gt; writes:
&gt;
&gt; &gt; Tested mostly OK on my mac-mini:
&gt;
&gt; Thanks for testing.
&gt;
&gt; &gt; dyld: Library not loaded: /Users/jwalton/tmp/nettle/lib/libnettle.7.dylib
&gt;
&gt; Is this the expected location after install, from
&gt;
&gt;   -install_name ${libdir}/$(LIBNETTLE_SONAME)
&gt;
&gt; on the command linking libnettle.dylib?

I think that is a red herring that will take you down a rabbit hole.
On OS X I build with -Wl,-rpath,@loader_path/../lib. Eventually, when
the library is installed, it will be a good path.

But I don't think it is the problem here. The problem here seems to be
DYLD_LIBRARY_PATH is empty, so the loader is falling back to the
rpath.

&gt; Then maybe using DYLD_FALLBACK_LIBRARY_PATH could work a bit better, if
&gt; the runtime linker only looks for libnettle.7.dylib in the given install
&gt; location, and not in system directories. Will still not be correct if
&gt; you install into a location where you have an older version but with the
&gt; same soname, but at least will be correct in some more cases?
&gt;
&gt; &gt;   Referenced from:
&gt; &gt; /Users/jwalton/Build-Scripts/nettle-master/testsuite/../tools/sexp-conv
&gt; &gt;   Reason: image not found
&gt; &gt; cmp: EOF on test1.out
&gt; &gt; FAIL: sexp-conv
&gt; &gt; FAIL: pkcs1-conv
&gt; &gt; FAIL: nettle-pbkdf2
&gt;
&gt; The three failing tests are /bin/sh scripts running the binaries in
&gt; tools/. I guess those still have DYLD_LIBRARY_PATH dropped from the
&gt; environment, can you confirm?
&gt;
&gt; To me, "system integrity protection", dropping DYLD_LIBRARY_PATH, seems
&gt; a bit pointless in a setting where we're running code of our choice
&gt; anyway.
&gt;
&gt; Do you see any clean workaround? One could maybe delegate it further,
&gt; similar to how $EMULATOR is handled.

Well, you patched run-tests, but you did not patch the other scripts.
Maybe patch the other scripts?

I patch the other scripts and don't have a problem. I think the other
scripts include testsuite/nettle-pbkdf2-test,
testsuite/sexp-conv-test, testsuite/pkcs1-conv-test,
examples/rsa-encrypt-test, examples/rsa-verify-test and
examples/rsa-sign-test.

I believe some of the other scripts need patching because a call chain
looks sometimes like the following.

    run-tests =&gt; testsuite/sexp-conv-test =&gt; sexp-conv
    run-tests =&gt; testsuite/pkcs1-conv-test =&gt; pkcs1-conv
    run-tests =&gt; testsuite/nettle-pbkdf2-test =&gt; nettle-pbkdf2

(I did not study it in great detail, so I may be wrong about it. But
some of the tests seemed to go outside of run-tests. The place to
patch seems to be the last script before [compiled] test program is
called).

Another workaround may be, provide a run-tests.in,
testsuite/sexp-conv-test.in and friends. And then let Autotools patch
the path into the scripts with a variable like @nettle_testlibdir@.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200522150212</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-05-22 15:02:12-0400</timestampReceived><subject>[PATCH 1/2] Implement GOST R 34.11-2012 (Streebog) hash function</subject><body>

From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;

Signed-off-by: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;
---
 Makefile.in                 |    7 +-
 examples/nettle-benchmark.c |    3 +-
 hmac-streebog-meta.c        |   56 ++
 hmac-streebog.c             |   73 ++
 hmac.h                      |   33 +
 nettle-meta-hashes.c        |    2 +
 nettle-meta-macs.c          |    2 +
 nettle-meta.h               |    4 +
 nettle.texinfo              |   72 ++
 streebog-meta.c             |   44 ++
 streebog.c                  | 1334 +++++++++++++++++++++++++++++++++++
 streebog.h                  |   99 +++
 testsuite/.gitignore        |    1 +
 testsuite/Makefile.in       |    2 +-
 testsuite/hmac-test.c       |   17 +
 testsuite/meta-hash-test.c  |    2 +
 testsuite/meta-mac-test.c   |    2 +
 testsuite/pbkdf2-test.c     |   30 +-
 testsuite/streebog-test.c   |   81 +++
 19 files changed, 1858 insertions(+), 6 deletions(-)
 create mode 100644 hmac-streebog-meta.c
 create mode 100644 hmac-streebog.c
 create mode 100644 streebog-meta.c
 create mode 100644 streebog.c
 create mode 100644 streebog.h
 create mode 100644 testsuite/streebog-test.c

diff --git a/Makefile.in b/Makefile.in
index e5ccfc76b901..64ff10018af0 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -107,10 +107,10 @@ nettle_SOURCES = aes-decrypt-internal.c aes-decrypt.c \
 		 gost28147.c gosthash94.c gosthash94-meta.c \
 		 hmac.c hmac-gosthash94.c hmac-md5.c hmac-ripemd160.c \
 		 hmac-sha1.c hmac-sha224.c hmac-sha256.c hmac-sha384.c \
-		 hmac-sha512.c \
+		 hmac-sha512.c hmac-streebog.c \
 		 hmac-md5-meta.c hmac-ripemd160-meta.c hmac-sha1-meta.c \
 		 hmac-sha224-meta.c hmac-sha256-meta.c hmac-sha384-meta.c \
-		 hmac-sha512-meta.c \
+		 hmac-sha512-meta.c hmac-streebog-meta.c \
 		 knuth-lfib.c hkdf.c \
 		 md2.c md2-meta.c md4.c md4-meta.c \
 		 md5.c md5-compress.c md5-compat.c md5-meta.c \
@@ -137,6 +137,7 @@ nettle_SOURCES = aes-decrypt-internal.c aes-decrypt.c \
 		 shake256.c \
 		 serpent-set-key.c serpent-encrypt.c serpent-decrypt.c \
 		 serpent-meta.c \
+		 streebog.c streebog-meta.c \
 		 twofish.c twofish-meta.c \
 		 umac-nh.c umac-nh-n.c umac-l2.c umac-l3.c \
 		 umac-poly64.c umac-poly128.c umac-set-key.c \
@@ -222,7 +223,7 @@ HEADERS = aes.h arcfour.h arctwo.h asn1.h blowfish.h \
 	  pbkdf2.h \
 	  pgp.h pkcs1.h pss.h pss-mgf1.h realloc.h ripemd160.h rsa.h \
 	  salsa20.h sexp.h \
-	  serpent.h sha.h sha1.h sha2.h sha3.h twofish.h \
+	  serpent.h sha.h sha1.h sha2.h sha3.h streebog.h twofish.h \
 	  umac.h yarrow.h xts.h poly1305.h
 
 INSTALL_HEADERS = $(HEADERS) version.h @IF_MINI_GMP@ mini-gmp.h
diff --git a/examples/nettle-benchmark.c b/examples/nettle-benchmark.c
index 5d0e649ea726..ea52cb44becf 100644
--- a/examples/nettle-benchmark.c
+++ b/examples/nettle-benchmark.c
@@ -918,7 +918,8 @@ main(int argc, char **argv)
       &amp;nettle_sha3_224, &amp;nettle_sha3_256,
       &amp;nettle_sha3_384, &amp;nettle_sha3_512,
       &amp;nettle_ripemd160, &amp;nettle_gosthash94,
-      &amp;nettle_gosthash94cp,
+      &amp;nettle_gosthash94cp, &amp;nettle_streebog256,
+      &amp;nettle_streebog512,
       NULL
     };
 
diff --git a/hmac-streebog-meta.c b/hmac-streebog-meta.c
new file mode 100644
index 000000000000..d6028307aa5a
--- /dev/null
+++ b/hmac-streebog-meta.c
@@ -0,0 +1,56 @@
+/* hmac-streebog-meta.c
+
+   Copyright (C) 2020 Dmitry Baryshkov
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include "nettle-meta.h"
+
+#include "hmac.h"
+
+static void
+hmac_streebog256_set_key_wrapper (void *ctx, const uint8_t *key)
+{
+  hmac_streebog256_set_key (ctx, STREEBOG256_DIGEST_SIZE, key);
+}
+
+const struct nettle_mac nettle_hmac_streebog256
+= _NETTLE_HMAC(hmac_streebog256, STREEBOG256);
+
+static void
+hmac_streebog512_set_key_wrapper (void *ctx, const uint8_t *key)
+{
+  hmac_streebog512_set_key (ctx, STREEBOG512_DIGEST_SIZE, key);
+}
+
+const struct nettle_mac nettle_hmac_streebog512
+= _NETTLE_HMAC(hmac_streebog512, STREEBOG512);
diff --git a/hmac-streebog.c b/hmac-streebog.c
new file mode 100644
index 000000000000..3b07b95da936
--- /dev/null
+++ b/hmac-streebog.c
@@ -0,0 +1,73 @@
+/* hmac-streebog.c
+
+   HMAC-Streebog message authentication code.
+
+   Copyright (C) 2016 Dmitry Eremin-Solenikov
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include "hmac.h"
+
+void
+hmac_streebog512_set_key(struct hmac_streebog512_ctx *ctx,
+			 size_t key_length, const uint8_t *key)
+{
+  HMAC_SET_KEY(ctx, &amp;nettle_streebog512, key_length, key);
+}
+
+void
+hmac_streebog512_update(struct hmac_streebog512_ctx *ctx,
+			size_t length, const uint8_t *data)
+{
+  streebog512_update(&amp;ctx-&gt;state, length, data);
+}
+
+void
+hmac_streebog512_digest(struct hmac_streebog512_ctx *ctx,
+			size_t length, uint8_t *digest)
+{
+  HMAC_DIGEST(ctx, &amp;nettle_streebog512, length, digest);
+}
+
+void
+hmac_streebog256_set_key(struct hmac_streebog256_ctx *ctx,
+			 size_t key_length, const uint8_t *key)
+{
+  HMAC_SET_KEY(ctx, &amp;nettle_streebog256, key_length, key);
+}
+
+void
+hmac_streebog256_digest(struct hmac_streebog256_ctx *ctx,
+			size_t length, uint8_t *digest)
+{
+  HMAC_DIGEST(ctx, &amp;nettle_streebog256, length, digest);
+}
diff --git a/hmac.h b/hmac.h
index d9ee3400108d..72c8fd5768c4 100644
--- a/hmac.h
+++ b/hmac.h
@@ -41,6 +41,7 @@
 #include "ripemd160.h"
 #include "sha1.h"
 #include "sha2.h"
+#include "streebog.h"
 
 #ifdef __cplusplus
 extern "C" {
@@ -75,6 +76,11 @@ extern "C" {
 #define hmac_gosthash94cp_set_key nettle_hmac_gosthash94cp_set_key
 #define hmac_gosthash94cp_update nettle_hmac_gosthash94cp_update
 #define hmac_gosthash94cp_digest nettle_hmac_gosthash94cp_digest
+#define hmac_streebog256_set_key nettle_hmac_streebog256_set_key
+#define hmac_streebog256_digest nettle_hmac_streebog256_digest
+#define hmac_streebog512_set_key nettle_hmac_streebog512_set_key
+#define hmac_streebog512_update nettle_hmac_streebog512_update
+#define hmac_streebog512_digest nettle_hmac_streebog512_digest
 
 void
 hmac_set_key(void *outer, void *inner, void *state,
@@ -240,6 +246,33 @@ hmac_gosthash94cp_digest(struct hmac_gosthash94cp_ctx *ctx,
 			 size_t length, uint8_t *digest);
 
 
+/* hmac-streebog */
+struct hmac_streebog512_ctx HMAC_CTX(struct streebog512_ctx);
+
+void
+hmac_streebog512_set_key(struct hmac_streebog512_ctx *ctx,
+		    size_t key_length, const uint8_t *key);
+
+void
+hmac_streebog512_update(struct hmac_streebog512_ctx *ctx,
+		   size_t length, const uint8_t *data);
+
+void
+hmac_streebog512_digest(struct hmac_streebog512_ctx *ctx,
+		   size_t length, uint8_t *digest);
+
+#define hmac_streebog256_ctx hmac_streebog512_ctx
+
+void
+hmac_streebog256_set_key(struct hmac_streebog256_ctx *ctx,
+		    size_t key_length, const uint8_t *key);
+
+#define hmac_streebog256_update hmac_streebog512_update
+
+void
+hmac_streebog256_digest(struct hmac_streebog256_ctx *ctx,
+		   size_t length, uint8_t *digest);
+
 #ifdef __cplusplus
 }
 #endif
diff --git a/nettle-meta-hashes.c b/nettle-meta-hashes.c
index 27b576cdc58c..8e96dd414d23 100644
--- a/nettle-meta-hashes.c
+++ b/nettle-meta-hashes.c
@@ -53,6 +53,8 @@ const struct nettle_hash * const _nettle_hashes[] = {
   &amp;nettle_sha3_256,
   &amp;nettle_sha3_384,
   &amp;nettle_sha3_512,
+  &amp;nettle_streebog256,
+  &amp;nettle_streebog512,
   NULL
 };
 
diff --git a/nettle-meta-macs.c b/nettle-meta-macs.c
index a658ee39e230..5e8f871329bb 100644
--- a/nettle-meta-macs.c
+++ b/nettle-meta-macs.c
@@ -48,6 +48,8 @@ const struct nettle_mac * const _nettle_macs[] = {
   &amp;nettle_hmac_sha256,
   &amp;nettle_hmac_sha384,
   &amp;nettle_hmac_sha512,
+  &amp;nettle_hmac_streebog256,
+  &amp;nettle_hmac_streebog512,
   NULL
 };
 
diff --git a/nettle-meta.h b/nettle-meta.h
index 7a6af363426b..6a62b653efa6 100644
--- a/nettle-meta.h
+++ b/nettle-meta.h
@@ -143,6 +143,8 @@ extern const struct nettle_hash nettle_sha3_224;
 extern const struct nettle_hash nettle_sha3_256;
 extern const struct nettle_hash nettle_sha3_384;
 extern const struct nettle_hash nettle_sha3_512;
+extern const struct nettle_hash nettle_streebog256;
+extern const struct nettle_hash nettle_streebog512;
 
 struct nettle_mac
 {
@@ -286,6 +288,8 @@ extern const struct nettle_mac nettle_hmac_sha224;
 extern const struct nettle_mac nettle_hmac_sha256;
 extern const struct nettle_mac nettle_hmac_sha384;
 extern const struct nettle_mac nettle_hmac_sha512;
+extern const struct nettle_mac nettle_hmac_streebog256;
+extern const struct nettle_mac nettle_hmac_streebog512;
 
 #ifdef __cplusplus
 }
diff --git a/nettle.texinfo b/nettle.texinfo
index 995d5de80813..2425b4f9d331 100644
--- a/nettle.texinfo
+++ b/nettle.texinfo
@@ -857,6 +857,78 @@ to @var{digest}. @var{length} can be of arbitrary size.
 This function also resets the context.
 @end deftypefun
 
+@subsubsection @acronym{STREEBOG512}
+
+STREEBOG512 is a member of the Streebog (GOST R 34.11-2012) family.  It outputs
+hash values of 512 bits, or 64 octets. Nettle defines STREEBOG512 in
+@file{&lt;nettle/streebog.h&gt;}.
+
+@deftp {Context struct} {struct streebog512_ctx}
+@end deftp
+
+@defvr Constant STREEBOG512_DIGEST_SIZE
+The size of a STREEBOG512 digest, i.e. 64.
+@end defvr
+
+@defvr Constant STREEBOG512_BLOCK_SIZE
+The internal block size of STREEBOG512. Useful for some special constructions,
+in particular HMAC-STREEBOG512.
+@end defvr
+
+@deftypefun void streebog512_init (struct streebog512_ctx *@var{ctx})
+Initialize the STREEBOG512 state.
+@end deftypefun
+
+@deftypefun void streebog512_update (struct streebog512_ctx *@var{ctx}, size_t \
@var{length}, const uint8_t *@var{data}) +Hash some more data.
+@end deftypefun
+
+@deftypefun void streebog512_digest (struct streebog512_ctx *@var{ctx}, size_t \
@var{length}, uint8_t *@var{digest}) +Performs final processing and extracts the \
message digest, writing it +to @var{digest}. @var{length} may be smaller than
+@code{STREEBOG512_DIGEST_SIZE}, in which case only the first @var{length}
+octets of the digest are written.
+
+This function also resets the context in the same way as
+@code{streebog512_init}.
+@end deftypefun
+
+@subsubsection @acronym{STREEBOG256}
+
+STREEBOG256 is a variant of STREEBOG512, with a different initial state, and with
+the output truncated to 256 bits, or 32 octets. Nettle defines STREEBOG256 in
+@file{&lt;nettle/streebog.h&gt;}.
+
+@deftp {Context struct} {struct streebog256_ctx}
+@end deftp
+
+@defvr Constant STREEBOG256_DIGEST_SIZE
+The size of a STREEBOG256 digest, i.e. 32.
+@end defvr
+
+@defvr Constant STREEBOG256_BLOCK_SIZE
+The internal block size of STREEBOG256. Useful for some special constructions,
+in particular HMAC-STREEBOG256.
+@end defvr
+
+@deftypefun void streebog256_init (struct streebog256_ctx *@var{ctx})
+Initialize the STREEBOG256 state.
+@end deftypefun
+
+@deftypefun void streebog256_update (struct streebog256_ctx *@var{ctx}, size_t \
@var{length}, const uint8_t *@var{data}) +Hash some more data.
+@end deftypefun
+
+@deftypefun void streebog256_digest (struct streebog256_ctx *@var{ctx}, size_t \
@var{length}, uint8_t *@var{digest}) +Performs final processing and extracts the \
message digest, writing it +to @var{digest}. @var{length} may be smaller than
+@code{STREEBOG256_DIGEST_SIZE}, in which case only the first @var{length}
+octets of the digest are written.
+
+This function also resets the context in the same way as
+@code{streebog256_init}.
+@end deftypefun
+
 @node Legacy hash functions, nettle_hash abstraction, Recommended hash functions, \
Hash functions  @comment  node-name,  next,  previous,  up
 @subsection Legacy hash functions
diff --git a/streebog-meta.c b/streebog-meta.c
new file mode 100644
index 000000000000..b8284d5c2b0d
--- /dev/null
+++ b/streebog-meta.c
@@ -0,0 +1,44 @@
+/* streebog-meta.c
+
+   Copyright (C) 2012 Nikos Mavrogiannopoulos, Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include "nettle-meta.h"
+
+#include "streebog.h"
+
+const struct nettle_hash nettle_streebog512
+= _NETTLE_HASH(streebog512, STREEBOG512);
+
+const struct nettle_hash nettle_streebog256
+= _NETTLE_HASH(streebog256, STREEBOG256);
diff --git a/streebog.c b/streebog.c
new file mode 100644
index 000000000000..bcbf5dbd8a65
--- /dev/null
+++ b/streebog.c
@@ -0,0 +1,1334 @@
+/* streebog.c - GOST R 34.11-2012 (Streebog) hash function
+
+   Copyright (C) 2013-2015 Dmitry Eremin-Solenikov
+
+   Based on my code in libgcrypt.
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+ */
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;stdlib.h&gt;
+#include &lt;string.h&gt;
+
+#include "streebog.h"
+
+#include "macros.h"
+#include "nettle-write.h"
+
+
+/* Pre-computed results of multiplication of bytes on A and reordered with
+   Pi[]. */
+static const uint64_t streebog_table[8][256] =
+{
+  /* 0 */
+  { 0xd01f715b5c7ef8e6ULL, 0x16fa240980778325ULL,
+    0xa8a42e857ee049c8ULL, 0x6ac1068fa186465bULL,
+    0x6e417bd7a2e9320bULL, 0x665c8167a437daabULL,
+    0x7666681aa89617f6ULL, 0x4b959163700bdcf5ULL,
+    0xf14be6b78df36248ULL, 0xc585bd689a625cffULL,
+    0x9557d7fca67d82cbULL, 0x89f0b969af6dd366ULL,
+    0xb0833d48749f6c35ULL, 0xa1998c23b1ecbc7cULL,
+    0x8d70c431ac02a736ULL, 0xd6dfbc2fd0a8b69eULL,
+    0x37aeb3e551fa198bULL, 0x0b7d128a40b5cf9cULL,
+    0x5a8f2008b5780cbcULL, 0xedec882284e333e5ULL,
+    0xd25fc177d3c7c2ceULL, 0x5e0f5d50b61778ecULL,
+    0x1d873683c0c24cb9ULL, 0xad040bcbb45d208cULL,
+    0x2f89a0285b853c76ULL, 0x5732fff6791b8d58ULL,
+    0x3e9311439ef6ec3fULL, 0xc9183a809fd3c00fULL,
+    0x83adf3f5260a01eeULL, 0xa6791941f4e8ef10ULL,
+    0x103ae97d0ca1cd5dULL, 0x2ce948121dee1b4aULL,
+    0x39738421dbf2bf53ULL, 0x093da2a6cf0cf5b4ULL,
+    0xcd9847d89cbcb45fULL, 0xf9561c078b2d8ae8ULL,
+    0x9c6a755a6971777fULL, 0xbc1ebaa0712ef0c5ULL,
+    0x72e61542abf963a6ULL, 0x78bb5fde229eb12eULL,
+    0x14ba94250fceb90dULL, 0x844d6697630e5282ULL,
+    0x98ea08026a1e032fULL, 0xf06bbea144217f5cULL,
+    0xdb6263d11ccb377aULL, 0x641c314b2b8ee083ULL,
+    0x320e96ab9b4770cfULL, 0x1ee7deb986a96b85ULL,
+    0xe96cf57a878c47b5ULL, 0xfdd6615f8842feb8ULL,
+    0xc83862965601dd1bULL, 0x2ea9f83e92572162ULL,
+    0xf876441142ff97fcULL, 0xeb2c455608357d9dULL,
+    0x5612a7e0b0c9904cULL, 0x6c01cbfb2d500823ULL,
+    0x4548a6a7fa037a2dULL, 0xabc4c6bf388b6ef4ULL,
+    0xbade77d4fdf8bebdULL, 0x799b07c8eb4cac3aULL,
+    0x0c9d87e805b19cf0ULL, 0xcb588aac106afa27ULL,
+    0xea0c1d40c1e76089ULL, 0x2869354a1e816f1aULL,
+    0xff96d17307fbc490ULL, 0x9f0a9d602f1a5043ULL,
+    0x96373fc6e016a5f7ULL, 0x5292dab8b3a6e41cULL,
+    0x9b8ae0382c752413ULL, 0x4f15ec3b7364a8a5ULL,
+    0x3fb349555724f12bULL, 0xc7c50d4415db66d7ULL,
+    0x92b7429ee379d1a7ULL, 0xd37f99611a15dfdaULL,
+    0x231427c05e34a086ULL, 0xa439a96d7b51d538ULL,
+    0xb403401077f01865ULL, 0xdda2aea5901d7902ULL,
+    0x0a5d4a9c8967d288ULL, 0xc265280adf660f93ULL,
+    0x8bb0094520d4e94eULL, 0x2a29856691385532ULL,
+    0x42a833c5bf072941ULL, 0x73c64d54622b7eb2ULL,
+    0x07e095624504536cULL, 0x8a905153e906f45aULL,
+    0x6f6123c16b3b2f1fULL, 0xc6e55552dc097bc3ULL,
+    0x4468feb133d16739ULL, 0xe211e7f0c7398829ULL,
+    0xa2f96419f7879b40ULL, 0x19074bdbc3ad38e9ULL,
+    0xf4ebc3f9474e0b0cULL, 0x43886bd376d53455ULL,
+    0xd8028beb5aa01046ULL, 0x51f23282f5cdc320ULL,
+    0xe7b1c2be0d84e16dULL, 0x081dfab006dee8a0ULL,
+    0x3b33340d544b857bULL, 0x7f5bcabc679ae242ULL,
+    0x0edd37c48a08a6d8ULL, 0x81ed43d9a9b33bc6ULL,
+    0xb1a3655ebd4d7121ULL, 0x69a1eeb5e7ed6167ULL,
+    0xf6ab73d5c8f73124ULL, 0x1a67a3e185c61fd5ULL,
+    0x2dc91004d43c065eULL, 0x0240b02c8fb93a28ULL,
+    0x90f7f2b26cc0eb8fULL, 0x3cd3a16f114fd617ULL,
+    0xaae49ea9f15973e0ULL, 0x06c0cd748cd64e78ULL,
+    0xda423bc7d5192a6eULL, 0xc345701c16b41287ULL,
+    0x6d2193ede4821537ULL, 0xfcf639494190e3acULL,
+    0x7c3b228621f1c57eULL, 0xfb16ac2b0494b0c0ULL,
+    0xbf7e529a3745d7f9ULL, 0x6881b6a32e3f7c73ULL,
+    0xca78d2bad9b8e733ULL, 0xbbfe2fc2342aa3a9ULL,
+    0x0dbddffecc6381e4ULL, 0x70a6a56e2440598eULL,
+    0xe4d12a844befc651ULL, 0x8c509c2765d0ba22ULL,
+    0xee8c6018c28814d9ULL, 0x17da7c1f49a59e31ULL,
+    0x609c4c1328e194d3ULL, 0xb3e3d57232f44b09ULL,
+    0x91d7aaa4a512f69bULL, 0x0ffd6fd243dabbccULL,
+    0x50d26a943c1fde34ULL, 0x6be15e9968545b4fULL,
+    0x94778fea6faf9fdfULL, 0x2b09dd7058ea4826ULL,
+    0x677cd9716de5c7bfULL, 0x49d5214fffb2e6ddULL,
+    0x0360e83a466b273cULL, 0x1fc786af4f7b7691ULL,
+    0xa0b9d435783ea168ULL, 0xd49f0c035f118cb6ULL,
+    0x01205816c9d21d14ULL, 0xac2453dd7d8f3d98ULL,
+    0x545217cc3f70aa64ULL, 0x26b4028e9489c9c2ULL,
+    0xdec2469fd6765e3eULL, 0x04807d58036f7450ULL,
+    0xe5f17292823ddb45ULL, 0xf30b569b024a5860ULL,
+    0x62dcfc3fa758aefbULL, 0xe84cad6c4e5e5aa1ULL,
+    0xccb81fce556ea94bULL, 0x53b282ae7a74f908ULL,
+    0x1b47fbf74c1402c1ULL, 0x368eebf39828049fULL,
+    0x7afbeff2ad278b06ULL, 0xbe5e0a8cfe97caedULL,
+    0xcfd8f7f413058e77ULL, 0xf78b2bc301252c30ULL,
+    0x4d555c17fcdd928dULL, 0x5f2f05467fc565f8ULL,
+    0x24f4b2a21b30f3eaULL, 0x860dd6bbecb768aaULL,
+    0x4c750401350f8f99ULL, 0x0000000000000000ULL,
+    0xecccd0344d312ef1ULL, 0xb5231806be220571ULL,
+    0xc105c030990d28afULL, 0x653c695de25cfd97ULL,
+    0x159acc33c61ca419ULL, 0xb89ec7f872418495ULL,
+    0xa9847693b73254dcULL, 0x58cf90243ac13694ULL,
+    0x59efc832f3132b80ULL, 0x5c4fed7c39ae42c4ULL,
+    0x828dabe3efd81cfaULL, 0xd13f294d95ace5f2ULL,
+    0x7d1b7a90e823d86aULL, 0xb643f03cf849224dULL,
+    0x3df3f979d89dcb03ULL, 0x7426d836272f2ddeULL,
+    0xdfe21e891fa4432aULL, 0x3a136c1b9d99986fULL,
+    0xfa36f43dcd46add4ULL, 0xc025982650df35bbULL,
+    0x856d3e81aadc4f96ULL, 0xc4a5e57e53b041ebULL,
+    0x4708168b75ba4005ULL, 0xaf44bbe73be41aa4ULL,
+    0x971767d029c4b8e3ULL, 0xb9be9feebb939981ULL,
+    0x215497ecd18d9aaeULL, 0x316e7e91dd2c57f3ULL,
+    0xcef8afe2dad79363ULL, 0x3853dc371220a247ULL,
+    0x35ee03c9de4323a3ULL, 0xe6919aa8c456fc79ULL,
+    0xe05157dc4880b201ULL, 0x7bdbb7e464f59612ULL,
+    0x127a59518318f775ULL, 0x332ecebd52956ddbULL,
+    0x8f30741d23bb9d1eULL, 0xd922d3fd93720d52ULL,
+    0x7746300c61440ae2ULL, 0x25d4eab4d2e2eefeULL,
+    0x75068020eefd30caULL, 0x135a01474acaea61ULL,
+    0x304e268714fe4ae7ULL, 0xa519f17bb283c82cULL,
+    0xdc82f6b359cf6416ULL, 0x5baf781e7caa11a8ULL,
+    0xb2c38d64fb26561dULL, 0x34ce5bdf17913eb7ULL,
+    0x5d6fb56af07c5fd0ULL, 0x182713cd0a7f25fdULL,
+    0x9e2ac576e6c84d57ULL, 0x9aaab82ee5a73907ULL,
+    0xa3d93c0f3e558654ULL, 0x7e7b92aaae48ff56ULL,
+    0x872d8ead256575beULL, 0x41c8dbfff96c0e7dULL,
+    0x99ca5014a3cc1e3bULL, 0x40e883e930be1369ULL,
+    0x1ca76e95091051adULL, 0x4e35b42dbab6b5b1ULL,
+    0x05a0254ecabd6944ULL, 0xe1710fca8152af15ULL,
+    0xf22b0e8dcb984574ULL, 0xb763a82a319b3f59ULL,
+    0x63fca4296e8ab3efULL, 0x9d4a2d4ca0a36a6bULL,
+    0xe331bfe60eeb953dULL, 0xd5bf541596c391a2ULL,
+    0xf5cb9bef8e9c1618ULL, 0x46284e9dbc685d11ULL,
+    0x2074cffa185f87baULL, 0xbd3ee2b6b8fcedd1ULL,
+    0xae64e3f1f23607b0ULL, 0xfeb68965ce29d984ULL,
+    0x55724fdaf6a2b770ULL, 0x29496d5cd753720eULL,
+    0xa75941573d3af204ULL, 0x8e102c0bea69800aULL,
+    0x111ab16bc573d049ULL, 0xd7ffe439197aab8aULL,
+    0xefac380e0b5a09cdULL, 0x48f579593660fbc9ULL,
+    0x22347fd697e6bd92ULL, 0x61bc1405e13389c7ULL,
+    0x4ab5c975b9d9c1e1ULL, 0x80cd1bcf606126d2ULL,
+    0x7186fd78ed92449aULL, 0x93971a882aabccb3ULL,
+    0x88d0e17f66bfce72ULL, 0x27945a985d5bd4d6ULL },
+  /* 1 */
+  { 0xde553f8c05a811c8ULL, 0x1906b59631b4f565ULL,
+    0x436e70d6b1964ff7ULL, 0x36d343cb8b1e9d85ULL,
+    0x843dfacc858aab5aULL, 0xfdfc95c299bfc7f9ULL,
+    0x0f634bdea1d51fa2ULL, 0x6d458b3b76efb3cdULL,
+    0x85c3f77cf8593f80ULL, 0x3c91315fbe737cb2ULL,
+    0x2148b03366ace398ULL, 0x18f8b8264c6761bfULL,
+    0xc830c1c495c9fb0fULL, 0x981a76102086a0aaULL,
+    0xaa16012142f35760ULL, 0x35cc54060c763cf6ULL,
+    0x42907d66cc45db2dULL, 0x8203d44b965af4bcULL,
+    0x3d6f3cefc3a0e868ULL, 0xbc73ff69d292bda7ULL,
+    0x8722ed0102e20a29ULL, 0x8f8185e8cd34deb7ULL,
+    0x9b0561dda7ee01d9ULL, 0x5335a0193227fad6ULL,
+    0xc9cecc74e81a6fd5ULL, 0x54f5832e5c2431eaULL,
+    0x99e47ba05d553470ULL, 0xf7bee756acd226ceULL,
+    0x384e05a5571816fdULL, 0xd1367452a47d0e6aULL,
+    0xf29fde1c386ad85bULL, 0x320c77316275f7caULL,
+    0xd0c879e2d9ae9ab0ULL, 0xdb7406c69110ef5dULL,
+    0x45505e51a2461011ULL, 0xfc029872e46c5323ULL,
+    0xfa3cb6f5f7bc0cc5ULL, 0x031f17cd8768a173ULL,
+    0xbd8df2d9af41297dULL, 0x9d3b4f5ab43e5e3fULL,
+    0x4071671b36feee84ULL, 0x716207e7d3e3b83dULL,
+    0x48d20ff2f9283a1aULL, 0x27769eb4757cbc7eULL,
+    0x5c56ebc793f2e574ULL, 0xa48b474f9ef5dc18ULL,
+    0x52cbada94ff46e0cULL, 0x60c7da982d8199c6ULL,
+    0x0e9d466edc068b78ULL, 0x4eec2175eaf865fcULL,
+    0x550b8e9e21f7a530ULL, 0x6b7ba5bc653fec2bULL,
+    0x5eb7f1ba6949d0ddULL, 0x57ea94e3db4c9099ULL,
+    0xf640eae6d101b214ULL, 0xdd4a284182c0b0bbULL,
+    0xff1d8fbf6304f250ULL, 0xb8accb933bf9d7e8ULL,
+    0xe8867c478eb68c4dULL, 0x3f8e2692391bddc1ULL,
+    0xcb2fd60912a15a7cULL, 0xaec935dbab983d2fULL,
+    0xf55ffd2b56691367ULL, 0x80e2ce366ce1c115ULL,
+    0x179bf3f8edb27e1dULL, 0x01fe0db07dd394daULL,
+    0xda8a0b76ecc37b87ULL, 0x44ae53e1df9584cbULL,
+    0xb310b4b77347a205ULL, 0xdfab323c787b8512ULL,
+    0x3b511268d070b78eULL, 0x65e6e3d2b9396753ULL,
+    0x6864b271e2574d58ULL, 0x259784c98fc789d7ULL,
+    0x02e11a7dfabb35a9ULL, 0x8841a6dfa337158bULL,
+    0x7ade78c39b5dcdd0ULL, 0xb7cf804d9a2cc84aULL,
+    0x20b6bd831b7f7742ULL, 0x75bd331d3a88d272ULL,
+    0x418f6aab4b2d7a5eULL, 0xd9951cbb6babdaf4ULL,
+    0xb6318dfde7ff5c90ULL, 0x1f389b112264aa83ULL,
+    0x492c024284fbaec0ULL, 0xe33a0363c608f9a0ULL,
+    0x2688930408af28a4ULL, 0xc7538a1a341ce4adULL,
+    0x5da8e677ee2171aeULL, 0x8c9e92254a5c7fc4ULL,
+    0x63d8cd55aae938b5ULL, 0x29ebd8daa97a3706ULL,
+    0x959827b37be88aa1ULL, 0x1484e4356adadf6eULL,
+    0xa7945082199d7d6bULL, 0xbf6ce8a455fa1cd4ULL,
+    0x9cc542eac9edcae5ULL, 0x79c16f0e1c356ca3ULL,
+    0x89bfab6fdee48151ULL, 0xd4174d1830c5f0ffULL,
+    0x9258048415eb419dULL, 0x6139d72850520d1cULL,
+    0x6a85a80c18ec78f1ULL, 0xcd11f88e0171059aULL,
+    0xcceff53e7ca29140ULL, 0xd229639f2315af19ULL,
+    0x90b91ef9ef507434ULL, 0x5977d28d074a1be1ULL,
+    0x311360fce51d56b9ULL, 0xc093a92d5a1f2f91ULL,
+    0x1a19a25bb6dc5416ULL, 0xeb996b8a09de2d3eULL,
+    0xfee3820f1ed7668aULL, 0xd7085ad5b7ad518cULL,
+    0x7fff41890fe53345ULL, 0xec5948bd67dde602ULL,
+    0x2fd5f65dbaaa68e0ULL, 0xa5754affe32648c2ULL,
+    0xf8ddac880d07396cULL, 0x6fa491468c548664ULL,
+    0x0c7c5c1326bdbed1ULL, 0x4a33158f03930fb3ULL,
+    0x699abfc19f84d982ULL, 0xe4fa2054a80b329cULL,
+    0x6707f9af438252faULL, 0x08a368e9cfd6d49eULL,
+    0x47b1442c58fd25b8ULL, 0xbbb3dc5ebc91769bULL,
+    0x1665fe489061eac7ULL, 0x33f27a811fa66310ULL,
+    0x93a609346838d547ULL, 0x30ed6d4c98cec263ULL,
+    0x1dd9816cd8df9f2aULL, 0x94662a03063b1e7bULL,
+    0x83fdd9fbeb896066ULL, 0x7b207573e68e590aULL,
+    0x5f49fc0a149a4407ULL, 0x343259b671a5a82cULL,
+    0xfbc2bb458a6f981fULL, 0xc272b350a0a41a38ULL,
+    0x3aaf1fd8ada32354ULL, 0x6cbb868b0b3c2717ULL,
+    0xa2b569c88d2583feULL, 0xf180c9d1bf027928ULL,
+    0xaf37386bd64ba9f5ULL, 0x12bacab2790a8088ULL,
+    0x4c0d3b0810435055ULL, 0xb2eeb9070e9436dfULL,
+    0xc5b29067cea7d104ULL, 0xdcb425f1ff132461ULL,
+    0x4f122cc5972bf126ULL, 0xac282fa651230886ULL,
+    0xe7e537992f6393efULL, 0xe61b3a2952b00735ULL,
+    0x709c0a57ae302ce7ULL, 0xe02514ae416058d3ULL,
+    0xc44c9dd7b37445deULL, 0x5a68c5408022ba92ULL,
+    0x1c278cdca50c0bf0ULL, 0x6e5a9cf6f18712beULL,
+    0x86dce0b17f319ef3ULL, 0x2d34ec2040115d49ULL,
+    0x4bcd183f7e409b69ULL, 0x2815d56ad4a9a3dcULL,
+    0x24698979f2141d0dULL, 0x0000000000000000ULL,
+    0x1ec696a15fb73e59ULL, 0xd86b110b16784e2eULL,
+    0x8e7f8858b0e74a6dULL, 0x063e2e8713d05fe6ULL,
+    0xe2c40ed3bbdb6d7aULL, 0xb1f1aeca89fc97acULL,
+    0xe1db191e3cb3cc09ULL, 0x6418ee62c4eaf389ULL,
+    0xc6ad87aa49cf7077ULL, 0xd6f65765ca7ec556ULL,
+    0x9afb6c6dda3d9503ULL, 0x7ce05644888d9236ULL,
+    0x8d609f95378feb1eULL, 0x23a9aa4e9c17d631ULL,
+    0x6226c0e5d73aac6fULL, 0x56149953a69f0443ULL,
+    0xeeb852c09d66d3abULL, 0x2b0ac2a753c102afULL,
+    0x07c023376e03cb3cULL, 0x2ccae1903dc2c993ULL,
+    0xd3d76e2f5ec63bc3ULL, 0x9e2458973356ff4cULL,
+    0xa66a5d32644ee9b1ULL, 0x0a427294356de137ULL,
+    0x783f62be61e6f879ULL, 0x1344c70204d91452ULL,
+    0x5b96c8f0fdf12e48ULL, 0xa90916ecc59bf613ULL,
+    0xbe92e5142829880eULL, 0x727d102a548b194eULL,
+    0x1be7afebcb0fc0ccULL, 0x3e702b2244c8491bULL,
+    0xd5e940a84d166425ULL, 0x66f9f41f3e51c620ULL,
+    0xabe80c913f20c3baULL, 0xf07ec461c2d1edf2ULL,
+    0xf361d3ac45b94c81ULL, 0x0521394a94b8fe95ULL,
+    0xadd622162cf09c5cULL, 0xe97871f7f3651897ULL,
+    0xf4a1f09b2bba87bdULL, 0x095d6559b2054044ULL,
+    0x0bbc7f2448be75edULL, 0x2af4cf172e129675ULL,
+    0x157ae98517094bb4ULL, 0x9fda55274e856b96ULL,
+    0x914713499283e0eeULL, 0xb952c623462a4332ULL,
+    0x74433ead475b46a8ULL, 0x8b5eb112245fb4f8ULL,
+    0xa34b6478f0f61724ULL, 0x11a5dd7ffe6221fbULL,
+    0xc16da49d27ccbb4bULL, 0x76a224d0bde07301ULL,
+    0x8aa0bca2598c2022ULL, 0x4df336b86d90c48fULL,
+    0xea67663a740db9e4ULL, 0xef465f70e0b54771ULL,
+    0x39b008152acb8227ULL, 0x7d1e5bf4f55e06ecULL,
+    0x105bd0cf83b1b521ULL, 0x775c2960c033e7dbULL,
+    0x7e014c397236a79fULL, 0x811cc386113255cfULL,
+    0xeda7450d1a0e72d8ULL, 0x5889df3d7a998f3bULL,
+    0x2e2bfbedc779fc3aULL, 0xce0eef438619a4e9ULL,
+    0x372d4e7bf6cd095fULL, 0x04df34fae96b6a4fULL,
+    0xf923a13870d4adb6ULL, 0xa1aa7e050a4d228dULL,
+    0xa8f71b5cb84862c9ULL, 0xb52e9a306097fde3ULL,
+    0x0d8251a35b6e2a0bULL, 0x2257a7fee1c442ebULL,
+    0x73831d9a29588d94ULL, 0x51d4ba64c89ccf7fULL,
+    0x502ab7d4b54f5ba5ULL, 0x97793dce8153bf08ULL,
+    0xe5042de4d5d8a646ULL, 0x9687307efc802bd2ULL,
+    0xa05473b5779eb657ULL, 0xb4d097801d446939ULL,
+    0xcff0e2f3fbca3033ULL, 0xc38cbee0dd778ee2ULL,
+    0x464f499c252eb162ULL, 0xcad1dbb96f72cea6ULL,
+    0xba4dd1eec142e241ULL, 0xb00fa37af42f0376ULL },
+  /* 2 */
+  { 0xcce4cd3aa968b245ULL, 0x089d5484e80b7fafULL,
+    0x638246c1b3548304ULL, 0xd2fe0ec8c2355492ULL,
+    0xa7fbdf7ff2374eeeULL, 0x4df1600c92337a16ULL,
+    0x84e503ea523b12fbULL, 0x0790bbfd53ab0c4aULL,
+    0x198a780f38f6ea9dULL, 0x2ab30c8f55ec48cbULL,
+    0xe0f7fed6b2c49db5ULL, 0xb6ecf3f422cadbdcULL,
+    0x409c9a541358df11ULL, 0xd3ce8a56dfde3fe3ULL,
+    0xc3e9224312c8c1a0ULL, 0x0d6dfa58816ba507ULL,
+    0xddf3e1b179952777ULL, 0x04c02a42748bb1d9ULL,
+    0x94c2abff9f2decb8ULL, 0x4f91752da8f8acf4ULL,
+    0x78682befb169bf7bULL, 0xe1c77a48af2ff6c4ULL,
+    0x0c5d7ec69c80ce76ULL, 0x4cc1e4928fd81167ULL,
+    0xfeed3d24d9997b62ULL, 0x518bb6dfc3a54a23ULL,
+    0x6dbf2d26151f9b90ULL, 0xb5bc624b05ea664fULL,
+    0xe86aaa525acfe21aULL, 0x4801ced0fb53a0beULL,
+    0xc91463e6c00868edULL, 0x1027a815cd16fe43ULL,
+    0xf67069a0319204cdULL, 0xb04ccc976c8abce7ULL,
+    0xc0b9b3fc35e87c33ULL, 0xf380c77c58f2de65ULL,
+    0x50bb3241de4e2152ULL, 0xdf93f490435ef195ULL,
+    0xf1e0d25d62390887ULL, 0xaf668bfb1a3c3141ULL,
+    0xbc11b251f00a7291ULL, 0x73a5eed47e427d47ULL,
+    0x25bee3f6ee4c3b2eULL, 0x43cc0beb34786282ULL,
+    0xc824e778dde3039cULL, 0xf97d86d98a327728ULL,
+    0xf2b043e24519b514ULL, 0xe297ebf7880f4b57ULL,
+    0x3a94a49a98fab688ULL, 0x868516cb68f0c419ULL,
+    0xeffa11af0964ee50ULL, 0xa4ab4ec0d517f37dULL,
+    0xa9c6b498547c567aULL, 0x8e18424f80fbbbb6ULL,
+    0x0bcdc53bcf2bc23cULL, 0x137739aaea3643d0ULL,
+    0x2c1333ec1bac2ff0ULL, 0x8d48d3f0a7db0625ULL,
+    0x1e1ac3f26b5de6d7ULL, 0xf520f81f16b2b95eULL,
+    0x9f0f6ec450062e84ULL, 0x0130849e1deb6b71ULL,
+    0xd45e31ab8c7533a9ULL, 0x652279a2fd14e43fULL,
+    0x3209f01e70f1c927ULL, 0xbe71a770cac1a473ULL,
+    0x0e3d6be7a64b1894ULL, 0x7ec8148cff29d840ULL,
+    0xcb7476c7fac3be0fULL, 0x72956a4a63a91636ULL,
+    0x37f95ec21991138fULL, 0x9e3fea5a4ded45f5ULL,
+    0x7b38ba50964902e8ULL, 0x222e580bbde73764ULL,
+    0x61e253e0899f55e6ULL, 0xfc8d2805e352ad80ULL,
+    0x35994be3235ac56dULL, 0x09add01af5e014deULL,
+    0x5e8659a6780539c6ULL, 0xb17c48097161d796ULL,
+    0x026015213acbd6e2ULL, 0xd1ae9f77e515e901ULL,
+    0xb7dc776a3f21b0adULL, 0xaba6a1b96eb78098ULL,
+    0x9bcf4486248d9f5dULL, 0x582666c536455efdULL,
+    0xfdbdac9bfeb9c6f1ULL, 0xc47999be4163cdeaULL,
+    0x765540081722a7efULL, 0x3e548ed8ec710751ULL,
+    0x3d041f67cb51bac2ULL, 0x7958af71ac82d40aULL,
+    0x36c9da5c047a78feULL, 0xed9a048e33af38b2ULL,
+    0x26ee7249c96c86bdULL, 0x900281bdeba65d61ULL,
+    0x11172c8bd0fd9532ULL, 0xea0abf73600434f8ULL,
+    0x42fc8f75299309f3ULL, 0x34a9cf7d3eb1ae1cULL,
+    0x2b838811480723baULL, 0x5ce64c8742ceef24ULL,
+    0x1adae9b01fd6570eULL, 0x3c349bf9d6bad1b3ULL,
+    0x82453c891c7b75c0ULL, 0x97923a40b80d512bULL,
+    0x4a61dbf1c198765cULL, 0xb48ce6d518010d3eULL,
+    0xcfb45c858e480fd6ULL, 0xd933cbf30d1e96aeULL,
+    0xd70ea014ab558e3aULL, 0xc189376228031742ULL,
+    0x9262949cd16d8b83ULL, 0xeb3a3bed7def5f89ULL,
+    0x49314a4ee6b8cbcfULL, 0xdcc3652f647e4c06ULL,
+    0xda635a4c2a3e2b3dULL, 0x470c21a940f3d35bULL,
+    0x315961a157d174b4ULL, 0x6672e81dda3459acULL,
+    0x5b76f77a1165e36eULL, 0x445cb01667d36ec8ULL,
+    0xc5491d205c88a69bULL, 0x456c34887a3805b9ULL,
+    0xffddb9bac4721013ULL, 0x99af51a71e4649bfULL,
+    0xa15be01cbc7729d5ULL, 0x52db2760e485f7b0ULL,
+    0x8c78576eba306d54ULL, 0xae560f6507d75a30ULL,
+    0x95f22f6182c687c9ULL, 0x71c5fbf54489aba5ULL,
+    0xca44f259e728d57eULL, 0x88b87d2ccebbdc8dULL,
+    0xbab18d32be4a15aaULL, 0x8be8ec93e99b611eULL,
+    0x17b713e89ebdf209ULL, 0xb31c5d284baa0174ULL,
+    0xeeca9531148f8521ULL, 0xb8d198138481c348ULL,
+    0x8988f9b2d350b7fcULL, 0xb9e11c8d996aa839ULL,
+    0x5a4673e40c8e881fULL, 0x1687977683569978ULL,
+    0xbf4123eed72acf02ULL, 0x4ea1f1b3b513c785ULL,
+    0xe767452be16f91ffULL, 0x7505d1b730021a7cULL,
+    0xa59bca5ec8fc980cULL, 0xad069eda20f7e7a3ULL,
+    0x38f4b1bba231606aULL, 0x60d2d77e94743e97ULL,
+    0x9affc0183966f42cULL, 0x248e6768f3a7505fULL,
+    0xcdd449a4b483d934ULL, 0x87b59255751baf68ULL,
+    0x1bea6d2e023d3c7fULL, 0x6b1f12455b5ffcabULL,
+    0x743555292de9710dULL, 0xd8034f6d10f5fddfULL,
+    0xc6198c9f7ba81b08ULL, 0xbb8109aca3a17edbULL,
+    0xfa2d1766ad12cabbULL, 0xc729080166437079ULL,
+    0x9c5fff7b77269317ULL, 0x0000000000000000ULL,
+    0x15d706c9a47624ebULL, 0x6fdf38072fd44d72ULL,
+    0x5fb6dd3865ee52b7ULL, 0xa33bf53d86bcff37ULL,
+    0xe657c1b5fc84fa8eULL, 0xaa962527735cebe9ULL,
+    0x39c43525bfda0b1bULL, 0x204e4d2a872ce186ULL,
+    0x7a083ece8ba26999ULL, 0x554b9c9db72efbfaULL,
+    0xb22cd9b656416a05ULL, 0x96a2bedea5e63a5aULL,
+    0x802529a826b0a322ULL, 0x8115ad363b5bc853ULL,
+    0x8375b81701901eb1ULL, 0x3069e53f4a3a1fc5ULL,
+    0xbd2136cfede119e0ULL, 0x18bafc91251d81ecULL,
+    0x1d4a524d4c7d5b44ULL, 0x05f0aedc6960daa8ULL,
+    0x29e39d3072ccf558ULL, 0x70f57f6b5962c0d4ULL,
+    0x989fd53903ad22ceULL, 0xf84d024797d91c59ULL,
+    0x547b1803aac5908bULL, 0xf0d056c37fd263f6ULL,
+    0xd56eb535919e58d8ULL, 0x1c7ad6d351963035ULL,
+    0x2e7326cd2167f912ULL, 0xac361a443d1c8cd2ULL,
+    0x697f076461942a49ULL, 0x4b515f6fdc731d2dULL,
+    0x8ad8680df4700a6fULL, 0x41ac1eca0eb3b460ULL,
+    0x7d988533d80965d3ULL, 0xa8f6300649973d0bULL,
+    0x7765c4960ac9cc9eULL, 0x7ca801adc5e20ea2ULL,
+    0xdea3700e5eb59ae4ULL, 0xa06b6482a19c42a4ULL,
+    0x6a2f96db46b497daULL, 0x27def6d7d487edccULL,
+    0x463ca5375d18b82aULL, 0xa6cb5be1efdc259fULL,
+    0x53eba3fef96e9cc1ULL, 0xce84d81b93a364a7ULL,
+    0xf4107c810b59d22fULL, 0x333974806d1aa256ULL,
+    0x0f0def79bba073e5ULL, 0x231edc95a00c5c15ULL,
+    0xe437d494c64f2c6cULL, 0x91320523f64d3610ULL,
+    0x67426c83c7df32ddULL, 0x6eefbc99323f2603ULL,
+    0x9d6f7be56acdf866ULL, 0x5916e25b2bae358cULL,
+    0x7ff89012e2c2b331ULL, 0x035091bf2720bd93ULL,
+    0x561b0d22900e4669ULL, 0x28d319ae6f279e29ULL,
+    0x2f43a2533c8c9263ULL, 0xd09e1be9f8fe8270ULL,
+    0xf740ed3e2c796fbcULL, 0xdb53ded237d5404cULL,
+    0x62b2c25faebfe875ULL, 0x0afd41a5d2c0a94dULL,
+    0x6412fd3ce0ff8f4eULL, 0xe3a76f6995e42026ULL,
+    0x6c8fa9b808f4f0e1ULL, 0xc2d9a6dd0f23aad1ULL,
+    0x8f28c6d19d10d0c7ULL, 0x85d587744fd0798aULL,
+    0xa20b71a39b579446ULL, 0x684f83fa7c7f4138ULL,
+    0xe507500adba4471dULL, 0x3f640a46f19a6c20ULL,
+    0x1247bd34f7dd28a1ULL, 0x2d23b77206474481ULL,
+    0x93521002cc86e0f2ULL, 0x572b89bc8de52d18ULL,
+    0xfb1d93f8b0f9a1caULL, 0xe95a2ecc4724896bULL,
+    0x3ba420048511ddf9ULL, 0xd63e248ab6bee54bULL,
+    0x5dd6c8195f258455ULL, 0x06a03f634e40673bULL,
+    0x1f2a476c76b68da6ULL, 0x217ec9b49ac78af7ULL,
+    0xecaa80102e4453c3ULL, 0x14e78257b99d4f9aULL },
+  /* 3 */
+  { 0x20329b2cc87bba05ULL, 0x4f5eb6f86546a531ULL,
+    0xd4f44775f751b6b1ULL, 0x8266a47b850dfa8bULL,
+    0xbb986aa15a6ca985ULL, 0xc979eb08f9ae0f99ULL,
+    0x2da6f447a2375ea1ULL, 0x1e74275dcd7d8576ULL,
+    0xbc20180a800bc5f8ULL, 0xb4a2f701b2dc65beULL,
+    0xe726946f981b6d66ULL, 0x48e6c453bf21c94cULL,
+    0x42cad9930f0a4195ULL, 0xefa47b64aacccd20ULL,
+    0x71180a8960409a42ULL, 0x8bb3329bf6a44e0cULL,
+    0xd34c35de2d36daccULL, 0xa92f5b7cbc23dc96ULL,
+    0xb31a85aa68bb09c3ULL, 0x13e04836a73161d2ULL,
+    0xb24dfc4129c51d02ULL, 0x8ae44b70b7da5acdULL,
+    0xe671ed84d96579a7ULL, 0xa4bb3417d66f3832ULL,
+    0x4572ab38d56d2de8ULL, 0xb1b47761ea47215cULL,
+    0xe81c09cf70aba15dULL, 0xffbdb872ce7f90acULL,
+    0xa8782297fd5dc857ULL, 0x0d946f6b6a4ce4a4ULL,
+    0xe4df1f4f5b995138ULL, 0x9ebc71edca8c5762ULL,
+    0x0a2c1dc0b02b88d9ULL, 0x3b503c115d9d7b91ULL,
+    0xc64376a8111ec3a2ULL, 0xcec199a323c963e4ULL,
+    0xdc76a87ec58616f7ULL, 0x09d596e073a9b487ULL,
+    0x14583a9d7d560dafULL, 0xf4c6dc593f2a0cb4ULL,
+    0xdd21d19584f80236ULL, 0x4a4836983ddde1d3ULL,
+    0xe58866a41ae745f9ULL, 0xf591a5b27e541875ULL,
+    0x891dc05074586693ULL, 0x5b068c651810a89eULL,
+    0xa30346bc0c08544fULL, 0x3dbf3751c684032dULL,
+    0x2a1e86ec785032dcULL, 0xf73f5779fca830eaULL,
+    0xb60c05ca30204d21ULL, 0x0cc316802b32f065ULL,
+    0x8770241bdd96be69ULL, 0xb861e18199ee95dbULL,
+    0xf805cad91418fcd1ULL, 0x29e70dccbbd20e82ULL,
+    0xc7140f435060d763ULL, 0x0f3a9da0e8b0cc3bULL,
+    0xa2543f574d76408eULL, 0xbd7761e1c175d139ULL,
+    0x4b1f4f737ca3f512ULL, 0x6dc2df1f2fc137abULL,
+    0xf1d05c3967b14856ULL, 0xa742bf3715ed046cULL,
+    0x654030141d1697edULL, 0x07b872abda676c7dULL,
+    0x3ce84eba87fa17ecULL, 0xc1fb0403cb79afdfULL,
+    0x3e46bc7105063f73ULL, 0x278ae987121cd678ULL,
+    0xa1adb4778ef47cd0ULL, 0x26dd906c5362c2b9ULL,
+    0x05168060589b44e2ULL, 0xfbfc41f9d79ac08fULL,
+    0x0e6de44ba9ced8faULL, 0x9feb08068bf243a3ULL,
+    0x7b341749d06b129bULL, 0x229c69e74a87929aULL,
+    0xe09ee6c4427c011bULL, 0x5692e30e725c4c3aULL,
+    0xda99a33e5e9f6e4bULL, 0x353dd85af453a36bULL,
+    0x25241b4c90e0fee7ULL, 0x5de987258309d022ULL,
+    0xe230140fc0802984ULL, 0x93281e86a0c0b3c6ULL,
+    0xf229d719a4337408ULL, 0x6f6c2dd4ad3d1f34ULL,
+    0x8ea5b2fbae3f0aeeULL, 0x8331dd90c473ee4aULL,
+    0x346aa1b1b52db7aaULL, 0xdf8f235e06042aa9ULL,
+    0xcc6f6b68a1354b7bULL, 0x6c95a6f46ebf236aULL,
+    0x52d31a856bb91c19ULL, 0x1a35ded6d498d555ULL,
+    0xf37eaef2e54d60c9ULL, 0x72e181a9a3c2a61cULL,
+    0x98537aad51952fdeULL, 0x16f6c856ffaa2530ULL,
+    0xd960281e9d1d5215ULL, 0x3a0745fa1ce36f50ULL,
+    0x0b7b642bf1559c18ULL, 0x59a87eae9aec8001ULL,
+    0x5e100c05408bec7cULL, 0x0441f98b19e55023ULL,
+    0xd70dcc5534d38aefULL, 0x927f676de1bea707ULL,
+    0x9769e70db925e3e5ULL, 0x7a636ea29115065aULL,
+    0x468b201816ef11b6ULL, 0xab81a9b73edff409ULL,
+    0xc0ac7de88a07bb1eULL, 0x1f235eb68c0391b7ULL,
+    0x6056b074458dd30fULL, 0xbe8eeac102f7ed67ULL,
+    0xcd381283e04b5fbaULL, 0x5cbefecec277c4e3ULL,
+    0xd21b4c356c48ce0dULL, 0x1019c31664b35d8cULL,
+    0x247362a7d19eea26ULL, 0xebe582efb3299d03ULL,
+    0x02aef2cb82fc289fULL, 0x86275df09ce8aaa8ULL,
+    0x28b07427faac1a43ULL, 0x38a9b7319e1f47cfULL,
+    0xc82e92e3b8d01b58ULL, 0x06ef0b409b1978bcULL,
+    0x62f842bfc771fb90ULL, 0x9904034610eb3b1fULL,
+    0xded85ab5477a3e68ULL, 0x90d195a663428f98ULL,
+    0x5384636e2ac708d8ULL, 0xcbd719c37b522706ULL,
+    0xae9729d76644b0ebULL, 0x7c8c65e20a0c7ee6ULL,
+    0x80c856b007f1d214ULL, 0x8c0b40302cc32271ULL,
+    0xdbcedad51fe17a8aULL, 0x740e8ae938dbdea0ULL,
+    0xa615c6dc549310adULL, 0x19cc55f6171ae90bULL,
+    0x49b1bdb8fe5fdd8dULL, 0xed0a89af2830e5bfULL,
+    0x6a7aadb4f5a65bd6ULL, 0x7e22972988f05679ULL,
+    0xf952b3325566e810ULL, 0x39fecedadf61530eULL,
+    0x6101c99f04f3c7ceULL, 0x2e5f7f6761b562ffULL,
+    0xf08725d226cf5c97ULL, 0x63af3b54860fef51ULL,
+    0x8ff2cb10ef411e2fULL, 0x884ab9bb35267252ULL,
+    0x4df04433e7ba8daeULL, 0x9afd8866d3690741ULL,
+    0x66b9bb34de94abb3ULL, 0x9baaf18d92171380ULL,
+    0x543c11c5f0a064a5ULL, 0x17a1b1bdbed431f1ULL,
+    0xb5f58eeaf3a2717fULL, 0xc355f6c849858740ULL,
+    0xec5df044694ef17eULL, 0xd83751f5dc6346d4ULL,
+    0xfc4433520dfdacf2ULL, 0x0000000000000000ULL,
+    0x5a51f58e596ebc5fULL, 0x3285aaf12e34cf16ULL,
+    0x8d5c39db6dbd36b0ULL, 0x12b731dde64f7513ULL,
+    0x94906c2d7aa7dfbbULL, 0x302b583aacc8e789ULL,
+    0x9d45facd090e6b3cULL, 0x2165e2c78905aec4ULL,
+    0x68d45f7f775a7349ULL, 0x189b2c1d5664fdcaULL,
+    0xe1c99f2f030215daULL, 0x6983269436246788ULL,
+    0x8489af3b1e148237ULL, 0xe94b702431d5b59cULL,
+    0x33d2d31a6f4adbd7ULL, 0xbfd9932a4389f9a6ULL,
+    0xb0e30e8aab39359dULL, 0xd1e2c715afcaf253ULL,
+    0x150f43763c28196eULL, 0xc4ed846393e2eb3dULL,
+    0x03f98b20c3823c5eULL, 0xfd134ab94c83b833ULL,
+    0x556b682eb1de7064ULL, 0x36c4537a37d19f35ULL,
+    0x7559f30279a5ca61ULL, 0x799ae58252973a04ULL,
+    0x9c12832648707ffdULL, 0x78cd9c6913e92ec5ULL,
+    0x1d8dac7d0effb928ULL, 0x439da0784e745554ULL,
+    0x413352b3cc887dcbULL, 0xbacf134a1b12bd44ULL,
+    0x114ebafd25cd494dULL, 0x2f08068c20cb763eULL,
+    0x76a07822ba27f63fULL, 0xeab2fb04f25789c2ULL,
+    0xe3676de481fe3d45ULL, 0x1b62a73d95e6c194ULL,
+    0x641749ff5c68832cULL, 0xa5ec4dfc97112cf3ULL,
+    0xf6682e92bdd6242bULL, 0x3f11c59a44782bb2ULL,
+    0x317c21d1edb6f348ULL, 0xd65ab5be75ad9e2eULL,
+    0x6b2dd45fb4d84f17ULL, 0xfaab381296e4d44eULL,
+    0xd0b5befeeeb4e692ULL, 0x0882ef0b32d7a046ULL,
+    0x512a91a5a83b2047ULL, 0x963e9ee6f85bf724ULL,
+    0x4e09cf132438b1f0ULL, 0x77f701c9fb59e2feULL,
+    0x7ddb1c094b726a27ULL, 0x5f4775ee01f5f8bdULL,
+    0x9186ec4d223c9b59ULL, 0xfeeac1998f01846dULL,
+    0xac39db1ce4b89874ULL, 0xb75b7c21715e59e0ULL,
+    0xafc0503c273aa42aULL, 0x6e3b543fec430bf5ULL,
+    0x704f7362213e8e83ULL, 0x58ff0745db9294c0ULL,
+    0x67eec2df9feabf72ULL, 0xa0facd9ccf8a6811ULL,
+    0xb936986ad890811aULL, 0x95c715c63bd9cb7aULL,
+    0xca8060283a2c33c7ULL, 0x507de84ee9453486ULL,
+    0x85ded6d05f6a96f6ULL, 0x1cdad5964f81ade9ULL,
+    0xd5a33e9eb62fa270ULL, 0x40642b588df6690aULL,
+    0x7f75eec2c98e42b8ULL, 0x2cf18dace3494a60ULL,
+    0x23cb100c0bf9865bULL, 0xeef3028febb2d9e1ULL,
+    0x4425d2d394133929ULL, 0xaad6d05c7fa1e0c8ULL,
+    0xad6ea2f7a5c68cb5ULL, 0xc2028f2308fb9381ULL,
+    0x819f2f5b468fc6d5ULL, 0xc5bafd88d29cfffcULL,
+    0x47dc59f357910577ULL, 0x2b49ff07392e261dULL,
+    0x57c59ae5332258fbULL, 0x73b6f842e2bcb2ddULL,
+    0xcf96e04862b77725ULL, 0x4ca73dd8a6c4996fULL,
+    0x015779eb417e14c1ULL, 0x37932a9176af8bf4ULL },
+  /* 4 */
+  { 0x190a2c9b249df23eULL, 0x2f62f8b62263e1e9ULL,
+    0x7a7f754740993655ULL, 0x330b7ba4d5564d9fULL,
+    0x4c17a16a46672582ULL, 0xb22f08eb7d05f5b8ULL,
+    0x535f47f40bc148ccULL, 0x3aec5d27d4883037ULL,
+    0x10ed0a1825438f96ULL, 0x516101f72c233d17ULL,
+    0x13cc6f949fd04eaeULL, 0x739853c441474bfdULL,
+    0x653793d90d3f5b1bULL, 0x5240647b96b0fc2fULL,
+    0x0c84890ad27623e0ULL, 0xd7189b32703aaea3ULL,
+    0x2685de3523bd9c41ULL, 0x99317c5b11bffefaULL,
+    0x0d9baa854f079703ULL, 0x70b93648fbd48ac5ULL,
+    0xa80441fce30bc6beULL, 0x7287704bdc36ff1eULL,
+    0xb65384ed33dc1f13ULL, 0xd36417343ee34408ULL,
+    0x39cd38ab6e1bf10fULL, 0x5ab861770a1f3564ULL,
+    0x0ebacf09f594563bULL, 0xd04572b884708530ULL,
+    0x3cae9722bdb3af47ULL, 0x4a556b6f2f5cbaf2ULL,
+    0xe1704f1f76c4bd74ULL, 0x5ec4ed7144c6dfcfULL,
+    0x16afc01d4c7810e6ULL, 0x283f113cd629ca7aULL,
+    0xaf59a8761741ed2dULL, 0xeed5a3991e215facULL,
+    0x3bf37ea849f984d4ULL, 0xe413e096a56ce33cULL,
+    0x2c439d3a98f020d1ULL, 0x637559dc6404c46bULL,
+    0x9e6c95d1e5f5d569ULL, 0x24bb9836045fe99aULL,
+    0x44efa466dac8ecc9ULL, 0xc6eab2a5c80895d6ULL,
+    0x803b50c035220cc4ULL, 0x0321658cba93c138ULL,
+    0x8f9ebc465dc7ee1cULL, 0xd15a5137190131d3ULL,
+    0x0fa5ec8668e5e2d8ULL, 0x91c979578d1037b1ULL,
+    0x0642ca05693b9f70ULL, 0xefca80168350eb4fULL,
+    0x38d21b24f36a45ecULL, 0xbeab81e1af73d658ULL,
+    0x8cbfd9cae7542f24ULL, 0xfd19cc0d81f11102ULL,
+    0x0ac6430fbb4dbc90ULL, 0x1d76a09d6a441895ULL,
+    0x2a01573ff1cbbfa1ULL, 0xb572e161894fde2bULL,
+    0x8124734fa853b827ULL, 0x614b1fdf43e6b1b0ULL,
+    0x68ac395c4238cc18ULL, 0x21d837bfd7f7b7d2ULL,
+    0x20c714304a860331ULL, 0x5cfaab726324aa14ULL,
+    0x74c5ba4eb50d606eULL, 0xf3a3030474654739ULL,
+    0x23e671bcf015c209ULL, 0x45f087e947b9582aULL,
+    0xd8bd77b418df4c7bULL, 0xe06f6c90ebb50997ULL,
+    0x0bd96080263c0873ULL, 0x7e03f9410e40dcfeULL,
+    0xb8e94be4c6484928ULL, 0xfb5b0608e8ca8e72ULL,
+    0x1a2b49179e0e3306ULL, 0x4e29e76961855059ULL,
+    0x4f36c4e6fcf4e4baULL, 0x49740ee395cf7bcaULL,
+    0xc2963ea386d17f7dULL, 0x90d65ad810618352ULL,
+    0x12d34c1b02a1fa4dULL, 0xfa44258775bb3a91ULL,
+    0x18150f14b9ec46ddULL, 0x1491861e6b9a653dULL,
+    0x9a1019d7ab2c3fc2ULL, 0x3668d42d06fe13d7ULL,
+    0xdcc1fbb25606a6d0ULL, 0x969490dd795a1c22ULL,
+    0x3549b1a1bc6dd2efULL, 0xc94f5e23a0ed770eULL,
+    0xb9f6686b5b39fdcbULL, 0xc4d4f4a6efeae00dULL,
+    0xe732851a1fff2204ULL, 0x94aad6de5eb869f9ULL,
+    0x3f8ff2ae07206e7fULL, 0xfe38a9813b62d03aULL,
+    0xa7a1ad7a8bee2466ULL, 0x7b6056c8dde882b6ULL,
+    0x302a1e286fc58ca7ULL, 0x8da0fa457a259bc7ULL,
+    0xb3302b64e074415bULL, 0x5402ae7eff8b635fULL,
+    0x08f8050c9cafc94bULL, 0xae468bf98a3059ceULL,
+    0x88c355cca98dc58fULL, 0xb10e6d67c7963480ULL,
+    0xbad70de7e1aa3cf3ULL, 0xbfb4a26e320262bbULL,
+    0xcb711820870f02d5ULL, 0xce12b7a954a75c9dULL,
+    0x563ce87dd8691684ULL, 0x9f73b65e7884618aULL,
+    0x2b1e74b06cba0b42ULL, 0x47cec1ea605b2df1ULL,
+    0x1c698312f735ac76ULL, 0x5fdbcefed9b76b2cULL,
+    0x831a354c8fb1cdfcULL, 0x820516c312c0791fULL,
+    0xb74ca762aeadabf0ULL, 0xfc06ef821c80a5e1ULL,
+    0x5723cbf24518a267ULL, 0x9d4df05d5f661451ULL,
+    0x588627742dfd40bfULL, 0xda8331b73f3d39a0ULL,
+    0x17b0e392d109a405ULL, 0xf965400bcf28fba9ULL,
+    0x7c3dbf4229a2a925ULL, 0x023e460327e275dbULL,
+    0x6cd0b55a0ce126b3ULL, 0xe62da695828e96e7ULL,
+    0x42ad6e63b3f373b9ULL, 0xe50cc319381d57dfULL,
+    0xc5cbd729729b54eeULL, 0x46d1e265fd2a9912ULL,
+    0x6428b056904eeff8ULL, 0x8be23040131e04b7ULL,
+    0x6709d5da2add2ec0ULL, 0x075de98af44a2b93ULL,
+    0x8447dcc67bfbe66fULL, 0x6616f655b7ac9a23ULL,
+    0xd607b8bded4b1a40ULL, 0x0563af89d3a85e48ULL,
+    0x3db1b4ad20c21ba4ULL, 0x11f22997b8323b75ULL,
+    0x292032b34b587e99ULL, 0x7f1cdace9331681dULL,
+    0x8e819fc9c0b65affULL, 0xa1e3677fe2d5bb16ULL,
+    0xcd33d225ee349da5ULL, 0xd9a2543b85aef898ULL,
+    0x795e10cbfa0af76dULL, 0x25a4bbb9992e5d79ULL,
+    0x78413344677b438eULL, 0xf0826688cef68601ULL,
+    0xd27b34bba392f0ebULL, 0x551d8df162fad7bcULL,
+    0x1e57c511d0d7d9adULL, 0xdeffbdb171e4d30bULL,
+    0xf4feea8e802f6caaULL, 0xa480c8f6317de55eULL,
+    0xa0fc44f07fa40ff5ULL, 0x95b5f551c3c9dd1aULL,
+    0x22f952336d6476eaULL, 0x0000000000000000ULL,
+    0xa6be8ef5169f9085ULL, 0xcc2cf1aa73452946ULL,
+    0x2e7ddb39bf12550aULL, 0xd526dd3157d8db78ULL,
+    0x486b2d6c08becf29ULL, 0x9b0f3a58365d8b21ULL,
+    0xac78cdfaadd22c15ULL, 0xbc95c7e28891a383ULL,
+    0x6a927f5f65dab9c3ULL, 0xc3891d2c1ba0cb9eULL,
+    0xeaa92f9f50f8b507ULL, 0xcf0d9426c9d6e87eULL,
+    0xca6e3baf1a7eb636ULL, 0xab25247059980786ULL,
+    0x69b31ad3df4978fbULL, 0xe2512a93cc577c4cULL,
+    0xff278a0ea61364d9ULL, 0x71a615c766a53e26ULL,
+    0x89dc764334fc716cULL, 0xf87a638452594f4aULL,
+    0xf2bc208be914f3daULL, 0x8766b94ac1682757ULL,
+    0xbbc82e687cdb8810ULL, 0x626a7a53f9757088ULL,
+    0xa2c202f358467a2eULL, 0x4d0882e5db169161ULL,
+    0x09e7268301de7da8ULL, 0xe897699c771ac0dcULL,
+    0xc8507dac3d9cc3edULL, 0xc0a878a0a1330aa6ULL,
+    0x978bb352e42ba8c1ULL, 0xe9884a13ea6b743fULL,
+    0x279afdbabecc28a2ULL, 0x047c8c064ed9eaabULL,
+    0x507e2278b15289f4ULL, 0x599904fbb08cf45cULL,
+    0xbd8ae46d15e01760ULL, 0x31353da7f2b43844ULL,
+    0x8558ff49e68a528cULL, 0x76fbfc4d92ef15b5ULL,
+    0x3456922e211c660cULL, 0x86799ac55c1993b4ULL,
+    0x3e90d1219a51da9cULL, 0x2d5cbeb505819432ULL,
+    0x982e5fd48cce4a19ULL, 0xdb9c1238a24c8d43ULL,
+    0xd439febecaa96f9bULL, 0x418c0bef0960b281ULL,
+    0x158ea591f6ebd1deULL, 0x1f48e69e4da66d4eULL,
+    0x8afd13cf8e6fb054ULL, 0xf5e1c9011d5ed849ULL,
+    0xe34e091c5126c8afULL, 0xad67ee7530a398f6ULL,
+    0x43b24dec2e82c75aULL, 0x75da99c1287cd48dULL,
+    0x92e81cdb3783f689ULL, 0xa3dd217cc537cecdULL,
+    0x60543c50de970553ULL, 0x93f73f54aaf2426aULL,
+    0xa91b62737e7a725dULL, 0xf19d4507538732e2ULL,
+    0x77e4dfc20f9ea156ULL, 0x7d229ccdb4d31dc6ULL,
+    0x1b346a98037f87e5ULL, 0xedf4c615a4b29e94ULL,
+    0x4093286094110662ULL, 0xb0114ee85ae78063ULL,
+    0x6ff1d0d6b672e78bULL, 0x6dcf96d591909250ULL,
+    0xdfe09e3eec9567e8ULL, 0x3214582b4827f97cULL,
+    0xb46dc2ee143e6ac8ULL, 0xf6c0ac8da7cd1971ULL,
+    0xebb60c10cd8901e4ULL, 0xf7df8f023abcad92ULL,
+    0x9c52d3d2c217a0b2ULL, 0x6b8d5cd0f8ab0d20ULL,
+    0x3777f7a29b8fa734ULL, 0x011f238f9d71b4e3ULL,
+    0xc1b75b2f3c42be45ULL, 0x5de588fdfe551ef7ULL,
+    0x6eeef3592b035368ULL, 0xaa3a07ffc4e9b365ULL,
+    0xecebe59a39c32a77ULL, 0x5ba742f8976e8187ULL,
+    0x4b4a48e0b22d0e11ULL, 0xddded83dcb771233ULL,
+    0xa59feb79ac0c51bdULL, 0xc7f5912a55792135ULL },
+  /* 5 */
+  { 0x6d6ae04668a9b08aULL, 0x3ab3f04b0be8c743ULL,
+    0xe51e166b54b3c908ULL, 0xbe90a9eb35c2f139ULL,
+    0xb2c7066637f2bec1ULL, 0xaa6945613392202cULL,
+    0x9a28c36f3b5201ebULL, 0xddce5a93ab536994ULL,
+    0x0e34133ef6382827ULL, 0x52a02ba1ec55048bULL,
+    0xa2f88f97c4b2a177ULL, 0x8640e513ca2251a5ULL,
+    0xcdf1d36258137622ULL, 0xfe6cb708dedf8ddbULL,
+    0x8a174a9ec8121e5dULL, 0x679896036b81560eULL,
+    0x59ed033395795feeULL, 0x1dd778ab8b74edafULL,
+    0xee533ef92d9f926dULL, 0x2a8c79baf8a8d8f5ULL,
+    0x6bcf398e69b119f6ULL, 0xe20491742fafdd95ULL,
+    0x276488e0809c2aecULL, 0xea955b82d88f5cceULL,
+    0x7102c63a99d9e0c4ULL, 0xf9763017a5c39946ULL,
+    0x429fa2501f151b3dULL, 0x4659c72bea05d59eULL,
+    0x984b7fdccf5a6634ULL, 0xf742232953fbb161ULL,
+    0x3041860e08c021c7ULL, 0x747bfd9616cd9386ULL,
+    0x4bb1367192312787ULL, 0x1b72a1638a6c44d3ULL,
+    0x4a0e68a6e8359a66ULL, 0x169a5039f258b6caULL,
+    0xb98a2ef44edee5a4ULL, 0xd9083fe85e43a737ULL,
+    0x967f6ce239624e13ULL, 0x8874f62d3c1a7982ULL,
+    0x3c1629830af06e3fULL, 0x9165ebfd427e5a8eULL,
+    0xb5dd81794ceeaa5cULL, 0x0de8f15a7834f219ULL,
+    0x70bd98ede3dd5d25ULL, 0xaccc9ca9328a8950ULL,
+    0x56664eda1945ca28ULL, 0x221db34c0f8859aeULL,
+    0x26dbd637fa98970dULL, 0x1acdffb4f068f932ULL,
+    0x4585254f64090fa0ULL, 0x72de245e17d53afaULL,
+    0x1546b25d7c546cf4ULL, 0x207e0ffffb803e71ULL,
+    0xfaaad2732bcf4378ULL, 0xb462dfae36ea17bdULL,
+    0xcf926fd1ac1b11fdULL, 0xe0672dc7dba7ba4aULL,
+    0xd3fa49ad5d6b41b3ULL, 0x8ba81449b216a3bcULL,
+    0x14f9ec8a0650d115ULL, 0x40fc1ee3eb1d7ce2ULL,
+    0x23a2ed9b758ce44fULL, 0x782c521b14fddc7eULL,
+    0x1c68267cf170504eULL, 0xbcf31558c1ca96e6ULL,
+    0xa781b43b4ba6d235ULL, 0xf6fd7dfe29ff0c80ULL,
+    0xb0a4bad5c3fad91eULL, 0xd199f51ea963266cULL,
+    0x414340349119c103ULL, 0x5405f269ed4dadf7ULL,
+    0xabd61bb649969dcdULL, 0x6813dbeae7bdc3c8ULL,
+    0x65fb2ab09f8931d1ULL, 0xf1e7fae152e3181dULL,
+    0xc1a67cef5a2339daULL, 0x7a4feea8e0f5bba1ULL,
+    0x1e0b9acf05783791ULL, 0x5b8ebf8061713831ULL,
+    0x80e53cdbcb3af8d9ULL, 0x7e898bd315e57502ULL,
+    0xc6bcfbf0213f2d47ULL, 0x95a38e86b76e942dULL,
+    0x092e94218d243cbaULL, 0x8339debf453622e7ULL,
+    0xb11be402b9fe64ffULL, 0x57d9100d634177c9ULL,
+    0xcc4e8db52217cbc3ULL, 0x3b0cae9c71ec7aa2ULL,
+    0xfb158ca451cbfe99ULL, 0x2b33276d82ac6514ULL,
+    0x01bf5ed77a04bde1ULL, 0xc5601994af33f779ULL,
+    0x75c4a3416cc92e67ULL, 0xf3844652a6eb7fc2ULL,
+    0x3487e375fdd0ef64ULL, 0x18ae430704609eedULL,
+    0x4d14efb993298efbULL, 0x815a620cb13e4538ULL,
+    0x125c354207487869ULL, 0x9eeea614ce42cf48ULL,
+    0xce2d3106d61fac1cULL, 0xbbe99247bad6827bULL,
+    0x071a871f7b1c149dULL, 0x2e4a1cc10db81656ULL,
+    0x77a71ff298c149b8ULL, 0x06a5d9c80118a97cULL,
+    0xad73c27e488e34b1ULL, 0x443a7b981e0db241ULL,
+    0xe3bbcfa355ab6074ULL, 0x0af276450328e684ULL,
+    0x73617a896dd1871bULL, 0x58525de4ef7de20fULL,
+    0xb7be3dcab8e6cd83ULL, 0x19111dd07e64230cULL,
+    0x842359a03e2a367aULL, 0x103f89f1f3401fb6ULL,
+    0xdc710444d157d475ULL, 0xb835702334da5845ULL,
+    0x4320fc876511a6dcULL, 0xd026abc9d3679b8dULL,
+    0x17250eee885c0b2bULL, 0x90dab52a387ae76fULL,
+    0x31fed8d972c49c26ULL, 0x89cba8fa461ec463ULL,
+    0x2ff5421677bcabb7ULL, 0x396f122f85e41d7dULL,
+    0xa09b332430bac6a8ULL, 0xc888e8ced7070560ULL,
+    0xaeaf201ac682ee8fULL, 0x1180d7268944a257ULL,
+    0xf058a43628e7a5fcULL, 0xbd4c4b8fbbce2b07ULL,
+    0xa1246df34abe7b49ULL, 0x7d5569b79be9af3cULL,
+    0xa9b5a705bd9efa12ULL, 0xdb6b835baa4bc0e8ULL,
+    0x05793bac8f147342ULL, 0x21c1512881848390ULL,
+    0xfdb0556c50d357e5ULL, 0x613d4fcb6a99ff72ULL,
+    0x03dce2648e0cda3eULL, 0xe949b9e6568386f0ULL,
+    0xfc0f0bbb2ad7ea04ULL, 0x6a70675913b5a417ULL,
+    0x7f36d5046fe1c8e3ULL, 0x0c57af8d02304ff8ULL,
+    0x32223abdfcc84618ULL, 0x0891caf6f720815bULL,
+    0xa63eeaec31a26fd4ULL, 0x2507345374944d33ULL,
+    0x49d28ac266394058ULL, 0xf5219f9aa7f3d6beULL,
+    0x2d96fea583b4cc68ULL, 0x5a31e1571b7585d0ULL,
+    0x8ed12fe53d02d0feULL, 0xdfade6205f5b0e4bULL,
+    0x4cabb16ee92d331aULL, 0x04c6657bf510cea3ULL,
+    0xd73c2cd6a87b8f10ULL, 0xe1d87310a1a307abULL,
+    0x6cd5be9112ad0d6bULL, 0x97c032354366f3f2ULL,
+    0xd4e0ceb22677552eULL, 0x0000000000000000ULL,
+    0x29509bde76a402cbULL, 0xc27a9e8bd42fe3e4ULL,
+    0x5ef7842cee654b73ULL, 0xaf107ecdbc86536eULL,
+    0x3fcacbe784fcb401ULL, 0xd55f90655c73e8cfULL,
+    0xe6c2f40fdabf1336ULL, 0xe8f6e7312c873b11ULL,
+    0xeb2a0555a28be12fULL, 0xe4a148bc2eb774e9ULL,
+    0x9b979db84156bc0aULL, 0x6eb60222e6a56ab4ULL,
+    0x87ffbbc4b026ec44ULL, 0xc703a5275b3b90a6ULL,
+    0x47e699fc9001687fULL, 0x9c8d1aa73a4aa897ULL,
+    0x7cea3760e1ed12ddULL, 0x4ec80ddd1d2554c5ULL,
+    0x13e36b957d4cc588ULL, 0x5d2b66486069914dULL,
+    0x92b90999cc7280b0ULL, 0x517cc9c56259deb5ULL,
+    0xc937b619ad03b881ULL, 0xec30824ad997f5b2ULL,
+    0xa45d565fc5aa080bULL, 0xd6837201d27f32f1ULL,
+    0x635ef3789e9198adULL, 0x531f75769651b96aULL,
+    0x4f77530a6721e924ULL, 0x486dd4151c3dfdb9ULL,
+    0x5f48dafb9461f692ULL, 0x375b011173dc355aULL,
+    0x3da9775470f4d3deULL, 0x8d0dcd81b30e0ac0ULL,
+    0x36e45fc609d888bbULL, 0x55baacbe97491016ULL,
+    0x8cb29356c90ab721ULL, 0x76184125e2c5f459ULL,
+    0x99f4210bb55edbd5ULL, 0x6f095cf59ca1d755ULL,
+    0x9f51f8c3b44672a9ULL, 0x3538bda287d45285ULL,
+    0x50c39712185d6354ULL, 0xf23b1885dcefc223ULL,
+    0x79930ccc6ef9619fULL, 0xed8fdc9da3934853ULL,
+    0xcb540aaa590bdf5eULL, 0x5c94389f1a6d2cacULL,
+    0xe77daad8a0bbaed7ULL, 0x28efc5090ca0bf2aULL,
+    0xbf2ff73c4fc64cd8ULL, 0xb37858b14df60320ULL,
+    0xf8c96ec0dfc724a7ULL, 0x828680683f329f06ULL,
+    0x941cd051cd6a29ccULL, 0xc3c5c05cae2b5e05ULL,
+    0xb601631dc2e27062ULL, 0xc01922382027843bULL,
+    0x24b86a840e90f0d2ULL, 0xd245177a276ffc52ULL,
+    0x0f8b4de98c3c95c6ULL, 0x3e759530fef809e0ULL,
+    0x0b4d2892792c5b65ULL, 0xc4df4743d5374a98ULL,
+    0xa5e20888bfaeb5eaULL, 0xba56cc90c0d23f9aULL,
+    0x38d04cf8ffe0a09cULL, 0x62e1adafe495254cULL,
+    0x0263bcb3f40867dfULL, 0xcaeb547d230f62bfULL,
+    0x6082111c109d4293ULL, 0xdad4dd8cd04f7d09ULL,
+    0xefec602e579b2f8cULL, 0x1fb4c4187f7c8a70ULL,
+    0xffd3e9dfa4db303aULL, 0x7bf0b07f9af10640ULL,
+    0xf49ec14dddf76b5fULL, 0x8f6e713247066d1fULL,
+    0x339d646a86ccfbf9ULL, 0x64447467e58d8c30ULL,
+    0x2c29a072f9b07189ULL, 0xd8b7613f24471ad6ULL,
+    0x6627c8d41185ebefULL, 0xa347d140beb61c96ULL,
+    0xde12b8f7255fb3aaULL, 0x9d324470404e1576ULL,
+    0x9306574eb6763d51ULL, 0xa80af9d2c79a47f3ULL,
+    0x859c0777442e8b9bULL, 0x69ac853d9db97e29ULL },
+  /* 6 */
+  { 0xc3407dfc2de6377eULL, 0x5b9e93eea4256f77ULL,
+    0xadb58fdd50c845e0ULL, 0x5219ff11a75bed86ULL,
+    0x356b61cfd90b1de9ULL, 0xfb8f406e25abe037ULL,
+    0x7a5a0231c0f60796ULL, 0x9d3cd216e1f5020bULL,
+    0x0c6550fb6b48d8f3ULL, 0xf57508c427ff1c62ULL,
+    0x4ad35ffa71cb407dULL, 0x6290a2da1666aa6dULL,
+    0xe284ec2349355f9fULL, 0xb3c307c53d7c84ecULL,
+    0x05e23c0468365a02ULL, 0x190bac4d6c9ebfa8ULL,
+    0x94bbbee9e28b80faULL, 0xa34fc777529cb9b5ULL,
+    0xcc7b39f095bcd978ULL, 0x2426addb0ce532e3ULL,
+    0x7e79329312ce4fc7ULL, 0xab09a72eebec2917ULL,
+    0xf8d15499f6b9d6c2ULL, 0x1a55b8babf8c895dULL,
+    0xdb8add17fb769a85ULL, 0xb57f2f368658e81bULL,
+    0x8acd36f18f3f41f6ULL, 0x5ce3b7bba50f11d3ULL,
+    0x114dcc14d5ee2f0aULL, 0xb91a7fcded1030e8ULL,
+    0x81d5425fe55de7a1ULL, 0xb6213bc1554adeeeULL,
+    0x80144ef95f53f5f2ULL, 0x1e7688186db4c10cULL,
+    0x3b912965db5fe1bcULL, 0xc281715a97e8252dULL,
+    0x54a5d7e21c7f8171ULL, 0x4b12535ccbc5522eULL,
+    0x1d289cefbea6f7f9ULL, 0x6ef5f2217d2e729eULL,
+    0xe6a7dc819b0d17ceULL, 0x1b94b41c05829b0eULL,
+    0x33d7493c622f711eULL, 0xdcf7f942fa5ce421ULL,
+    0x600fba8b7f7a8ecbULL, 0x46b60f011a83988eULL,
+    0x235b898e0dcf4c47ULL, 0x957ab24f588592a9ULL,
+    0x4354330572b5c28cULL, 0xa5f3ef84e9b8d542ULL,
+    0x8c711e02341b2d01ULL, 0x0b1874ae6a62a657ULL,
+    0x1213d8e306fc19ffULL, 0xfe6d7c6a4d9dba35ULL,
+    0x65ed868f174cd4c9ULL, 0x88522ea0e6236550ULL,
+    0x899322065c2d7703ULL, 0xc01e690bfef4018bULL,
+    0x915982ed8abddaf8ULL, 0xbe675b98ec3a4e4cULL,
+    0xa996bf7f82f00db1ULL, 0xe1daf8d49a27696aULL,
+    0x2effd5d3dc8986e7ULL, 0xd153a51f2b1a2e81ULL,
+    0x18caa0ebd690adfbULL, 0x390e3134b243c51aULL,
+    0x2778b92cdff70416ULL, 0x029f1851691c24a6ULL,
+    0x5e7cafeacc133575ULL, 0xfa4e4cc89fa5f264ULL,
+    0x5a5f9f481e2b7d24ULL, 0x484c47ab18d764dbULL,
+    0x400a27f2a1a7f479ULL, 0xaeeb9b2a83da7315ULL,
+    0x721c626879869734ULL, 0x042330a2d2384851ULL,
+    0x85f672fd3765aff0ULL, 0xba446b3a3e02061dULL,
+    0x73dd6ecec3888567ULL, 0xffac70ccf793a866ULL,
+    0xdfa9edb5294ed2d4ULL, 0x6c6aea7014325638ULL,
+    0x834a5a0e8c41c307ULL, 0xcdba35562fb2cb2bULL,
+    0x0ad97808d06cb404ULL, 0x0f3b440cb85aee06ULL,
+    0xe5f9c876481f213bULL, 0x98deee1289c35809ULL,
+    0x59018bbfcd394bd1ULL, 0xe01bf47220297b39ULL,
+    0xde68e1139340c087ULL, 0x9fa3ca4788e926adULL,
+    0xbb85679c840c144eULL, 0x53d8f3b71d55ffd5ULL,
+    0x0da45c5dd146caa0ULL, 0x6f34fe87c72060cdULL,
+    0x57fbc315cf6db784ULL, 0xcee421a1fca0fddeULL,
+    0x3d2d0196607b8d4bULL, 0x642c8a29ad42c69aULL,
+    0x14aff010bdd87508ULL, 0xac74837beac657b3ULL,
+    0x3216459ad821634dULL, 0x3fb219c70967a9edULL,
+    0x06bc28f3bb246cf7ULL, 0xf2082c9126d562c6ULL,
+    0x66b39278c45ee23cULL, 0xbd394f6f3f2878b9ULL,
+    0xfd33689d9e8f8cc0ULL, 0x37f4799eb017394fULL,
+    0x108cc0b26fe03d59ULL, 0xda4bd1b1417888d6ULL,
+    0xb09d1332ee6eb219ULL, 0x2f3ed975668794b4ULL,
+    0x58c0871977375982ULL, 0x7561463d78ace990ULL,
+    0x09876cff037e82f1ULL, 0x7fb83e35a8c05d94ULL,
+    0x26b9b58a65f91645ULL, 0xef20b07e9873953fULL,
+    0x3148516d0b3355b8ULL, 0x41cb2b541ba9e62aULL,
+    0x790416c613e43163ULL, 0xa011d380818e8f40ULL,
+    0x3a5025c36151f3efULL, 0xd57095bdf92266d0ULL,
+    0x498d4b0da2d97688ULL, 0x8b0c3a57353153a5ULL,
+    0x21c491df64d368e1ULL, 0x8f2f0af5e7091bf4ULL,
+    0x2da1c1240f9bb012ULL, 0xc43d59a92ccc49daULL,
+    0xbfa6573e56345c1fULL, 0x828b56a8364fd154ULL,
+    0x9a41f643e0df7cafULL, 0xbcf843c985266aeaULL,
+    0x2b1de9d7b4bfdce5ULL, 0x20059d79dedd7ab2ULL,
+    0x6dabe6d6ae3c446bULL, 0x45e81bf6c991ae7bULL,
+    0x6351ae7cac68b83eULL, 0xa432e32253b6c711ULL,
+    0xd092a9b991143cd2ULL, 0xcac711032e98b58fULL,
+    0xd8d4c9e02864ac70ULL, 0xc5fc550f96c25b89ULL,
+    0xd7ef8dec903e4276ULL, 0x67729ede7e50f06fULL,
+    0xeac28c7af045cf3dULL, 0xb15c1f945460a04aULL,
+    0x9cfddeb05bfb1058ULL, 0x93c69abce3a1fe5eULL,
+    0xeb0380dc4a4bdd6eULL, 0xd20db1e8f8081874ULL,
+    0x229a8528b7c15e14ULL, 0x44291750739fbc28ULL,
+    0xd3ccbd4e42060a27ULL, 0xf62b1c33f4ed2a97ULL,
+    0x86a8660ae4779905ULL, 0xd62e814a2a305025ULL,
+    0x477703a7a08d8addULL, 0x7b9b0e977af815c5ULL,
+    0x78c51a60a9ea2330ULL, 0xa6adfb733aaae3b7ULL,
+    0x97e5aa1e3199b60fULL, 0x0000000000000000ULL,
+    0xf4b404629df10e31ULL, 0x5564db44a6719322ULL,
+    0x9207961a59afec0dULL, 0x9624a6b88b97a45cULL,
+    0x363575380a192b1cULL, 0x2c60cd82b595a241ULL,
+    0x7d272664c1dc7932ULL, 0x7142769faa94a1c1ULL,
+    0xa1d0df263b809d13ULL, 0x1630e841d4c451aeULL,
+    0xc1df65ad44fa13d8ULL, 0x13d2d445bcf20bacULL,
+    0xd915c546926abe23ULL, 0x38cf3d92084dd749ULL,
+    0xe766d0272103059dULL, 0xc7634d5effde7f2fULL,
+    0x077d2455012a7ea4ULL, 0xedbfa82ff16fb199ULL,
+    0xaf2a978c39d46146ULL, 0x42953fa3c8bbd0dfULL,
+    0xcb061da59496a7dcULL, 0x25e7a17db6eb20b0ULL,
+    0x34aa6d6963050fbaULL, 0xa76cf7d580a4f1e4ULL,
+    0xf7ea10954ee338c4ULL, 0xfcf2643b24819e93ULL,
+    0xcf252d0746aeef8dULL, 0x4ef06f58a3f3082cULL,
+    0x563acfb37563a5d7ULL, 0x5086e740ce47c920ULL,
+    0x2982f186dda3f843ULL, 0x87696aac5e798b56ULL,
+    0x5d22bb1d1f010380ULL, 0x035e14f7d31236f5ULL,
+    0x3cec0d30da759f18ULL, 0xf3c920379cdb7095ULL,
+    0xb8db736b571e22bbULL, 0xdd36f5e44052f672ULL,
+    0xaac8ab8851e23b44ULL, 0xa857b3d938fe1fe2ULL,
+    0x17f1e4e76eca43fdULL, 0xec7ea4894b61a3caULL,
+    0x9e62c6e132e734feULL, 0xd4b1991b432c7483ULL,
+    0x6ad6c283af163acfULL, 0x1ce9904904a8e5aaULL,
+    0x5fbda34c761d2726ULL, 0xf910583f4cb7c491ULL,
+    0xc6a241f845d06d7cULL, 0x4f3163fe19fd1a7fULL,
+    0xe99c988d2357f9c8ULL, 0x8eee06535d0709a7ULL,
+    0x0efa48aa0254fc55ULL, 0xb4be23903c56fa48ULL,
+    0x763f52caabbedf65ULL, 0xeee1bcd8227d876cULL,
+    0xe345e085f33b4dccULL, 0x3e731561b369bbbeULL,
+    0x2843fd2067adea10ULL, 0x2adce5710eb1ceb6ULL,
+    0xb7e03767ef44ccbdULL, 0x8db012a48e153f52ULL,
+    0x61ceb62dc5749c98ULL, 0xe85d942b9959eb9bULL,
+    0x4c6f7709caef2c8aULL, 0x84377e5b8d6bbda3ULL,
+    0x30895dcbb13d47ebULL, 0x74a04a9bc2a2fbc3ULL,
+    0x6b17ce251518289cULL, 0xe438c4d0f2113368ULL,
+    0x1fb784bed7bad35fULL, 0x9b80fae55ad16efcULL,
+    0x77fe5e6c11b0cd36ULL, 0xc858095247849129ULL,
+    0x08466059b97090a2ULL, 0x01c10ca6ba0e1253ULL,
+    0x6988d6747c040c3aULL, 0x6849dad2c60a1e69ULL,
+    0x5147ebe67449db73ULL, 0xc99905f4fd8a837aULL,
+    0x991fe2b433cd4a5aULL, 0xf09734c04fc94660ULL,
+    0xa28ecbd1e892abe6ULL, 0xf1563866f5c75433ULL,
+    0x4dae7baf70e13ed9ULL, 0x7ce62ac27bd26b61ULL,
+    0x70837a39109ab392ULL, 0x90988e4b30b3c8abULL,
+    0xb2020b63877296bfULL, 0x156efcb607d6675bULL },
+  /* 7 */
+  { 0xe63f55ce97c331d0ULL, 0x25b506b0015bba16ULL,
+    0xc8706e29e6ad9ba8ULL, 0x5b43d3775d521f6aULL,
+    0x0bfa3d577035106eULL, 0xab95fc172afb0e66ULL,
+    0xf64b63979e7a3276ULL, 0xf58b4562649dad4bULL,
+    0x48f7c3dbae0c83f1ULL, 0xff31916642f5c8c5ULL,
+    0xcbb048dc1c4a0495ULL, 0x66b8f83cdf622989ULL,
+    0x35c130e908e2b9b0ULL, 0x7c761a61f0b34fa1ULL,
+    0x3601161cf205268dULL, 0x9e54ccfe2219b7d6ULL,
+    0x8b7d90a538940837ULL, 0x9cd403588ea35d0bULL,
+    0xbc3c6fea9ccc5b5aULL, 0xe5ff733b6d24aeedULL,
+    0xceed22de0f7eb8d2ULL, 0xec8581cab1ab545eULL,
+    0xb96105e88ff8e71dULL, 0x8ca03501871a5eadULL,
+    0x76ccce65d6db2a2fULL, 0x5883f582a7b58057ULL,
+    0x3f7be4ed2e8adc3eULL, 0x0fe7be06355cd9c9ULL,
+    0xee054e6c1d11be83ULL, 0x1074365909b903a6ULL,
+    0x5dde9f80b4813c10ULL, 0x4a770c7d02b6692cULL,
+    0x5379c8d5d7809039ULL, 0xb4067448161ed409ULL,
+    0x5f5e5026183bd6cdULL, 0xe898029bf4c29df9ULL,
+    0x7fb63c940a54d09cULL, 0xc5171f897f4ba8bcULL,
+    0xa6f28db7b31d3d72ULL, 0x2e4f3be7716eaa78ULL,
+    0x0d6771a099e63314ULL, 0x82076254e41bf284ULL,
+    0x2f0fd2b42733df98ULL, 0x5c9e76d3e2dc49f0ULL,
+    0x7aeb569619606cdbULL, 0x83478b07b2468764ULL,
+    0xcfadcb8d5923cd32ULL, 0x85dac7f05b95a41eULL,
+    0xb5469d1b4043a1e9ULL, 0xb821ecbbd9a592fdULL,
+    0x1b8e0b0e798c13c8ULL, 0x62a57b6d9a0be02eULL,
+    0xfcf1b793b81257f8ULL, 0x9d94ea0bd8fe28ebULL,
+    0x4cea408aeb654a56ULL, 0x23284a47e888996cULL,
+    0x2d8f1d128b893545ULL, 0xf4cbac3132c0d8abULL,
+    0xbd7c86b9ca912ebaULL, 0x3a268eef3dbe6079ULL,
+    0xf0d62f6077a9110cULL, 0x2735c916ade150cbULL,
+    0x89fd5f03942ee2eaULL, 0x1acee25d2fd16628ULL,
+    0x90f39bab41181bffULL, 0x430dfe8cde39939fULL,
+    0xf70b8ac4c8274796ULL, 0x1c53aeaac6024552ULL,
+    0x13b410acf35e9c9bULL, 0xa532ab4249faa24fULL,
+    0x2b1251e5625a163fULL, 0xd7e3e676da4841c7ULL,
+    0xa7b264e4e5404892ULL, 0xda8497d643ae72d3ULL,
+    0x861ae105a1723b23ULL, 0x38a6414991048aa4ULL,
+    0x6578dec92585b6b4ULL, 0x0280cfa6acbaeaddULL,
+    0x88bdb650c273970aULL, 0x9333bd5ebbff84c2ULL,
+    0x4e6a8f2c47dfa08bULL, 0x321c954db76cef2aULL,
+    0x418d312a72837942ULL, 0xb29b38bfffcdf773ULL,
+    0x6c022c38f90a4c07ULL, 0x5a033a240b0f6a8aULL,
+    0x1f93885f3ce5da6fULL, 0xc38a537e96988bc6ULL,
+    0x39e6a81ac759ff44ULL, 0x29929e43cee0fce2ULL,
+    0x40cdd87924de0ca2ULL, 0xe9d8ebc8a29fe819ULL,
+    0x0c2798f3cfbb46f4ULL, 0x55e484223e53b343ULL,
+    0x4650948ecd0d2fd8ULL, 0x20e86cb2126f0651ULL,
+    0x6d42c56baf5739e7ULL, 0xa06fc1405ace1e08ULL,
+    0x7babbfc54f3d193bULL, 0x424d17df8864e67fULL,
+    0xd8045870ef14980eULL, 0xc6d7397c85ac3781ULL,
+    0x21a885e1443273b1ULL, 0x67f8116f893f5c69ULL,
+    0x24f5efe35706cff6ULL, 0xd56329d076f2ab1aULL,
+    0x5e1eb9754e66a32dULL, 0x28d2771098bd8902ULL,
+    0x8f6013f47dfdc190ULL, 0x17a993fdb637553cULL,
+    0xe0a219397e1012aaULL, 0x786b9930b5da8606ULL,
+    0x6e82e39e55b0a6daULL, 0x875a0856f72f4ec3ULL,
+    0x3741ff4fa458536dULL, 0xac4859b3957558fcULL,
+    0x7ef6d5c75c09a57cULL, 0xc04a758b6c7f14fbULL,
+    0xf9acdd91ab26ebbfULL, 0x7391a467c5ef9668ULL,
+    0x335c7c1ee1319acaULL, 0xa91533b18641e4bbULL,
+    0xe4bf9a683b79db0dULL, 0x8e20faa72ba0b470ULL,
+    0x51f907737b3a7ae4ULL, 0x2268a314bed5ec8cULL,
+    0xd944b123b949edeeULL, 0x31dcb3b84d8b7017ULL,
+    0xd3fe65279f218860ULL, 0x097af2f1dc8ffab3ULL,
+    0x9b09a6fc312d0b91ULL, 0xcc6ded78a3c4520fULL,
+    0x3481d9ba5ebfcc50ULL, 0x4f2a667f1182d56bULL,
+    0xdfd9fdd4509ace94ULL, 0x26752045fbbc252bULL,
+    0xbffc491f662bc467ULL, 0xdd593272fc202449ULL,
+    0x3cbbc218d46d4303ULL, 0x91b372f817456e1fULL,
+    0x681faf69bc6385a0ULL, 0xb686bbeebaa43ed4ULL,
+    0x1469b5084cd0ca01ULL, 0x98c98009cbca94acULL,
+    0x6438379a73d8c354ULL, 0xc2caba2dc0c5fe26ULL,
+    0x3e3b0dbe78d7a9deULL, 0x50b9ee202d670f04ULL,
+    0x4590b27b37eab0e5ULL, 0x6025b4cb36b10af3ULL,
+    0xfb2c1237079c0162ULL, 0xa12f28130c936be8ULL,
+    0x4b37e52e54eb1cccULL, 0x083a1ba28ad28f53ULL,
+    0xc10a9cd83a22611bULL, 0x9f1425ad7444c236ULL,
+    0x069d4cf7e9d3237aULL, 0xedc56899e7f621beULL,
+    0x778c273680865fcfULL, 0x309c5aeb1bd605f7ULL,
+    0x8de0dc52d1472b4dULL, 0xf8ec34c2fd7b9e5fULL,
+    0xea18cd3d58787724ULL, 0xaad515447ca67b86ULL,
+    0x9989695a9d97e14cULL, 0x0000000000000000ULL,
+    0xf196c63321f464ecULL, 0x71116bc169557cb5ULL,
+    0xaf887f466f92c7c1ULL, 0x972e3e0ffe964d65ULL,
+    0x190ec4a8d536f915ULL, 0x95aef1a9522ca7b8ULL,
+    0xdc19db21aa7d51a9ULL, 0x94ee18fa0471d258ULL,
+    0x8087adf248a11859ULL, 0xc457f6da2916dd5cULL,
+    0xfa6cfb6451c17482ULL, 0xf256e0c6db13fbd1ULL,
+    0x6a9f60cf10d96f7dULL, 0x4daaa9d9bd383fb6ULL,
+    0x03c026f5fae79f3dULL, 0xde99148706c7bb74ULL,
+    0x2a52b8b6340763dfULL, 0x6fc20acd03edd33aULL,
+    0xd423c08320afdefaULL, 0xbbe1ca4e23420dc0ULL,
+    0x966ed75ca8cb3885ULL, 0xeb58246e0e2502c4ULL,
+    0x055d6a021334bc47ULL, 0xa47242111fa7d7afULL,
+    0xe3623fcc84f78d97ULL, 0x81c744a11efc6db9ULL,
+    0xaec8961539cfb221ULL, 0xf31609958d4e8e31ULL,
+    0x63e5923ecc5695ceULL, 0x47107ddd9b505a38ULL,
+    0xa3afe7b5a0298135ULL, 0x792b7063e387f3e6ULL,
+    0x0140e953565d75e0ULL, 0x12f4f9ffa503e97bULL,
+    0x750ce8902c3cb512ULL, 0xdbc47e8515f30733ULL,
+    0x1ed3610c6ab8af8fULL, 0x5239218681dde5d9ULL,
+    0xe222d69fd2aaf877ULL, 0xfe71783514a8bd25ULL,
+    0xcaf0a18f4a177175ULL, 0x61655d9860ec7f13ULL,
+    0xe77fbc9dc19e4430ULL, 0x2ccff441ddd440a5ULL,
+    0x16e97aaee06a20dcULL, 0xa855dae2d01c915bULL,
+    0x1d1347f9905f30b2ULL, 0xb7c652bdecf94b34ULL,
+    0xd03e43d265c6175dULL, 0xfdb15ec0ee4f2218ULL,
+    0x57644b8492e9599eULL, 0x07dda5a4bf8e569aULL,
+    0x54a46d71680ec6a3ULL, 0x5624a2d7c4b42c7eULL,
+    0xbebca04c3076b187ULL, 0x7d36f332a6ee3a41ULL,
+    0x3b6667bc6be31599ULL, 0x695f463aea3ef040ULL,
+    0xad08b0e0c3282d1cULL, 0xb15b1e4a052a684eULL,
+    0x44d05b2861b7c505ULL, 0x15295c5b1a8dbfe1ULL,
+    0x744c01c37a61c0f2ULL, 0x59c31cd1f1e8f5b7ULL,
+    0xef45a73f4b4ccb63ULL, 0x6bdf899c46841a9dULL,
+    0x3dfb2b4b823036e3ULL, 0xa2ef0ee6f674f4d5ULL,
+    0x184e2dfb836b8cf5ULL, 0x1134df0a5fe47646ULL,
+    0xbaa1231d751f7820ULL, 0xd17eaa81339b62bdULL,
+    0xb01bf71953771daeULL, 0x849a2ea30dc8d1feULL,
+    0x705182923f080955ULL, 0x0ea757556301ac29ULL,
+    0x041d83514569c9a7ULL, 0x0abad4042668658eULL,
+    0x49b72a88f851f611ULL, 0x8a3d79f66ec97dd7ULL,
+    0xcd2d042bf59927efULL, 0xc930877ab0f0ee48ULL,
+    0x9273540deda2f122ULL, 0xc797d02fd3f14261ULL,
+    0xe1e2f06a284d674aULL, 0xd2be8c74c97cfd80ULL,
+    0x9a494faf67707e71ULL, 0xb3dbd1eca9908293ULL,
+    0x72d14d3493b2e388ULL, 0xd6a30f258c153427ULL },
+};
+
+static const uint64_t C16[12][8] =
+{
+  { 0xdd806559f2a64507ULL, 0x05767436cc744d23ULL,
+    0xa2422a08a460d315ULL, 0x4b7ce09192676901ULL,
+    0x714eb88d7585c4fcULL, 0x2f6a76432e45d016ULL,
+    0xebcb2f81c0657c1fULL, 0xb1085bda1ecadae9ULL },
+  { 0xe679047021b19bb7ULL, 0x55dda21bd7cbcd56ULL,
+    0x5cb561c2db0aa7caULL, 0x9ab5176b12d69958ULL,
+    0x61d55e0f16b50131ULL, 0xf3feea720a232b98ULL,
+    0x4fe39d460f70b5d7ULL, 0x6fa3b58aa99d2f1aULL },
+  { 0x991e96f50aba0ab2ULL, 0xc2b6f443867adb31ULL,
+    0xc1c93a376062db09ULL, 0xd3e20fe490359eb1ULL,
+    0xf2ea7514b1297b7bULL, 0x06f15e5f529c1f8bULL,
+    0x0a39fc286a3d8435ULL, 0xf574dcac2bce2fc7ULL },
+  { 0x220cbebc84e3d12eULL, 0x3453eaa193e837f1ULL,
+    0xd8b71333935203beULL, 0xa9d72c82ed03d675ULL,
+    0x9d721cad685e353fULL, 0x488e857e335c3c7dULL,
+    0xf948e1a05d71e4ddULL, 0xef1fdfb3e81566d2ULL },
+  { 0x601758fd7c6cfe57ULL, 0x7a56a27ea9ea63f5ULL,
+    0xdfff00b723271a16ULL, 0xbfcd1747253af5a3ULL,
+    0x359e35d7800fffbdULL, 0x7f151c1f1686104aULL,
+    0x9a3f410c6ca92363ULL, 0x4bea6bacad474799ULL },
+  { 0xfa68407a46647d6eULL, 0xbf71c57236904f35ULL,
+    0x0af21f66c2bec6b6ULL, 0xcffaa6b71c9ab7b4ULL,
+    0x187f9ab49af08ec6ULL, 0x2d66c4f95142a46cULL,
+    0x6fa4c33b7a3039c0ULL, 0xae4faeae1d3ad3d9ULL },
+  { 0x8886564d3a14d493ULL, 0x3517454ca23c4af3ULL,
+    0x06476983284a0504ULL, 0x0992abc52d822c37ULL,
+    0xd3473e33197a93c9ULL, 0x399ec6c7e6bf87c9ULL,
+    0x51ac86febf240954ULL, 0xf4c70e16eeaac5ecULL },
+  { 0xa47f0dd4bf02e71eULL, 0x36acc2355951a8d9ULL,
+    0x69d18d2bd1a5c42fULL, 0xf4892bcb929b0690ULL,
+    0x89b4443b4ddbc49aULL, 0x4eb7f8719c36de1eULL,
+    0x03e7aa020c6e4141ULL, 0x9b1f5b424d93c9a7ULL },
+  { 0x7261445183235adbULL, 0x0e38dc92cb1f2a60ULL,
+    0x7b2b8a9aa6079c54ULL, 0x800a440bdbb2ceb1ULL,
+    0x3cd955b7e00d0984ULL, 0x3a7d3a1b25894224ULL,
+    0x944c9ad8ec165fdeULL, 0x378f5a541631229bULL },
+  { 0x74b4c7fb98459cedULL, 0x3698fad1153bb6c3ULL,
+    0x7a1e6c303b7652f4ULL, 0x9fe76702af69334bULL,
+    0x1fffe18a1b336103ULL, 0x8941e71cff8a78dbULL,
+    0x382ae548b2e4f3f3ULL, 0xabbedea680056f52ULL },
+  { 0x6bcaa4cd81f32d1bULL, 0xdea2594ac06fd85dULL,
+    0xefbacd1d7d476e98ULL, 0x8a1d71efea48b9caULL,
+    0x2001802114846679ULL, 0xd8fa6bbbebab0761ULL,
+    0x3002c6cd635afe94ULL, 0x7bcd9ed0efc889fbULL },
+  { 0x48bc924af11bd720ULL, 0xfaf417d5d9b21b99ULL,
+    0xe71da4aa88e12852ULL, 0x5d80ef9d1891cc86ULL,
+    0xf82012d430219f9bULL, 0xcda43c32bcdf1d77ULL,
+    0xd21380b00449b17aULL, 0x378ee767f11631baULL },
+};
+
+#define strido(out, temp, i) do { \
+	uint64_t t; \
+	t  = streebog_table[0][(temp[0] &gt;&gt; (i * 8)) &amp; 0xff]; \
+	t ^= streebog_table[1][(temp[1] &gt;&gt; (i * 8)) &amp; 0xff]; \
+	t ^= streebog_table[2][(temp[2] &gt;&gt; (i * 8)) &amp; 0xff]; \
+	t ^= streebog_table[3][(temp[3] &gt;&gt; (i * 8)) &amp; 0xff]; \
+	t ^= streebog_table[4][(temp[4] &gt;&gt; (i * 8)) &amp; 0xff]; \
+	t ^= streebog_table[5][(temp[5] &gt;&gt; (i * 8)) &amp; 0xff]; \
+	t ^= streebog_table[6][(temp[6] &gt;&gt; (i * 8)) &amp; 0xff]; \
+	t ^= streebog_table[7][(temp[7] &gt;&gt; (i * 8)) &amp; 0xff]; \
+	out[i] = t; } while(0)
+
+static void LPSX (uint64_t *out, const uint64_t *a, const uint64_t *b)
+{
+  uint64_t temp[8];
+  temp[0] = a[0] ^ b[0];
+  temp[1] = a[1] ^ b[1];
+  temp[2] = a[2] ^ b[2];
+  temp[3] = a[3] ^ b[3];
+  temp[4] = a[4] ^ b[4];
+  temp[5] = a[5] ^ b[5];
+  temp[6] = a[6] ^ b[6];
+  temp[7] = a[7] ^ b[7];
+  strido (out, temp, 0);
+  strido (out, temp, 1);
+  strido (out, temp, 2);
+  strido (out, temp, 3);
+  strido (out, temp, 4);
+  strido (out, temp, 5);
+  strido (out, temp, 6);
+  strido (out, temp, 7);
+}
+
+static inline void g (uint64_t *h, uint64_t *m, uint64_t *N)
+{
+  uint64_t K[8];
+  uint64_t T[8];
+  int i;
+
+  LPSX (K, h, N);
+
+  LPSX (T, K, m);
+  LPSX (K, K, C16[0]);
+  for (i = 1; i &lt; 12; i++)
+    {
+      LPSX (T, K, T);
+      LPSX (K, K, C16[i]);
+    }
+
+  h[0] ^= T[0] ^ K[0] ^ m[0];
+  h[1] ^= T[1] ^ K[1] ^ m[1];
+  h[2] ^= T[2] ^ K[2] ^ m[2];
+  h[3] ^= T[3] ^ K[3] ^ m[3];
+  h[4] ^= T[4] ^ K[4] ^ m[4];
+  h[5] ^= T[5] ^ K[5] ^ m[5];
+  h[6] ^= T[6] ^ K[6] ^ m[6];
+  h[7] ^= T[7] ^ K[7] ^ m[7];
+}
+
+
+static void
+streebog512_compress (struct streebog512_ctx *ctx, const uint8_t *input, size_t \
count) +{
+  uint64_t M[8];
+  uint64_t l, cf;
+  int i;
+
+  for (i = 0; i &lt; 8; i++, input += 8)
+    M[i] = LE_READ_UINT64(input);
+
+  g (ctx-&gt;state, M, ctx-&gt;count);
+  l = ctx-&gt;count[0];
+  ctx-&gt;count[0] += count;
+  if (ctx-&gt;count[0] &lt; l)
+    { /* overflow */
+      for (i = 1; i &lt; 8; i++)
+        {
+          ctx-&gt;count[i]++;
+          if (ctx-&gt;count[i] != 0)
+            break;
+        }
+    }
+
+  cf = 0;
+  ctx-&gt;sigma[0] += M[0];
+  for (i = 1; i &lt; 8; i++)
+    {
+      if (ctx-&gt;sigma[i-1] != M[i-1])
+	cf = (ctx-&gt;sigma[i-1] &lt; M[i-1]);
+      ctx-&gt;sigma[i] += M[i] + cf;
+    }
+}
+
+static void
+streebog_final (struct streebog512_ctx *ctx)
+{
+  uint64_t Z[8] = {};
+  unsigned int i;
+
+  /* PAD. It does not count towards message length */
+  i = ctx-&gt;index;
+  /* We have at least one byte free) */
+  ctx-&gt;block[i++] = 1;
+  while (i &lt; 64)
+    ctx-&gt;block[i++] = 0;
+  streebog512_compress (ctx, ctx-&gt;block, ctx-&gt;index * 8);
+
+  g (ctx-&gt;state, ctx-&gt;count, Z);
+  g (ctx-&gt;state, ctx-&gt;sigma, Z);
+}
+
+#define COMPRESS(ctx, data) (streebog512_compress((ctx), (data), 64 * 8))
+
+void
+streebog512_init(struct streebog512_ctx *ctx)
+{
+  memset(ctx-&gt;state, 0, sizeof(ctx-&gt;state));
+  memset(ctx-&gt;count, 0, sizeof(ctx-&gt;count));
+  memset(ctx-&gt;sigma, 0, sizeof(ctx-&gt;sigma));
+
+  /* Initialize buffer */
+  ctx-&gt;index = 0;
+}
+
+void
+streebog512_update(struct streebog512_ctx *ctx,
+                   size_t length, const uint8_t *data)
+{
+  MD_UPDATE (ctx, length, data, COMPRESS, (void)0);
+}
+
+static void
+streebog512_write_digest(struct streebog512_ctx *ctx,
+                         size_t offset, size_t length,
+                         uint8_t *digest)
+{
+  unsigned i;
+  unsigned words;
+  unsigned leftover;
+
+  assert(offset + length &lt;= STREEBOG512_DIGEST_SIZE);
+
+  streebog_final(ctx);
+
+  words = length / 8;
+  leftover = length % 8;
+
+  for (i = 0; i &lt; words; i++, digest += 8)
+    LE_WRITE_UINT64(digest, ctx-&gt;state[offset + i]);
+
+  if (leftover)
+    {
+      /* Truncate to the right size */
+      uint64_t word = ctx-&gt;state[offset + i] &lt;&lt; (8*(8 - leftover));
+
+      do {
+	digest[--leftover] = (word &gt;&gt; 56) &amp; 0xff;
+	word &lt;&lt;= 8;
+      } while (leftover);
+    }
+}
+
+void
+streebog512_digest(struct streebog512_ctx *ctx,
+		   size_t length,
+		   uint8_t *digest)
+{
+  assert(length &lt;= STREEBOG512_DIGEST_SIZE);
+
+  streebog512_write_digest(ctx, 0, length, digest);
+  streebog512_init(ctx);
+}
+
+void
+streebog256_init(struct streebog256_ctx *ctx)
+{
+  memset(ctx-&gt;state, 1, sizeof(ctx-&gt;state));
+  memset(ctx-&gt;count, 0, sizeof(ctx-&gt;count));
+  memset(ctx-&gt;sigma, 0, sizeof(ctx-&gt;sigma));
+
+  /* Initialize buffer */
+  ctx-&gt;index = 0;
+}
+
+void
+streebog256_digest(struct streebog256_ctx *ctx,
+                   size_t length,
+                   uint8_t *digest)
+{
+  assert(length &lt;= STREEBOG256_DIGEST_SIZE);
+
+  streebog512_write_digest(ctx,
+      4,
+      length,
+      digest);
+  streebog256_init(ctx);
+}
diff --git a/streebog.h b/streebog.h
new file mode 100644
index 000000000000..3408224e0240
--- /dev/null
+++ b/streebog.h
@@ -0,0 +1,99 @@
+/* streebog.h
+
+   The Streebog family of hash functions.
+
+   Copyright (C) 2015 Dmitry Eremin-Solenikov
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+ 
+#ifndef NETTLE_STREEBOG_H_INCLUDED
+#define NETTLE_STREEBOG_H_INCLUDED
+
+#include "nettle-types.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/* Name mangling */
+#define streebog256_init nettle_streebog256_init
+#define streebog256_digest nettle_streebog256_digest
+#define streebog512_init nettle_streebog512_init
+#define streebog512_update nettle_streebog512_update
+#define streebog512_digest nettle_streebog512_digest
+
+/* STREEBOG512 */
+
+#define STREEBOG512_DIGEST_SIZE 64
+#define STREEBOG512_BLOCK_SIZE 64
+
+/* Digest is kept internally as 8 64-bit words. */
+#define _STREEBOG512_DIGEST_LENGTH 8
+
+struct streebog512_ctx
+{
+  uint64_t state[_STREEBOG512_DIGEST_LENGTH];    /* State variables */
+  uint64_t count[_STREEBOG512_DIGEST_LENGTH];
+  uint64_t sigma[_STREEBOG512_DIGEST_LENGTH];
+  unsigned int index;                       /* index into buffer */
+  uint8_t block[STREEBOG512_BLOCK_SIZE];          /* STREEBOG512 data buffer */
+};
+
+void
+streebog512_init(struct streebog512_ctx *ctx);
+
+void
+streebog512_update(struct streebog512_ctx *ctx,
+	      size_t length,
+	      const uint8_t *data);
+
+void
+streebog512_digest(struct streebog512_ctx *ctx,
+	      size_t length,
+	      uint8_t *digest);
+
+
+#define STREEBOG256_DIGEST_SIZE 32
+#define STREEBOG256_BLOCK_SIZE STREEBOG512_BLOCK_SIZE
+#define streebog256_ctx streebog512_ctx
+
+void
+streebog256_init(struct streebog256_ctx *ctx);
+
+#define streebog256_update nettle_streebog512_update
+
+void
+streebog256_digest(struct streebog256_ctx *ctx,
+		  size_t length,
+		  uint8_t *digest);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* NETTLE_STREEBOG_H_INCLUDED */
diff --git a/testsuite/.gitignore b/testsuite/.gitignore
index a2b3d52312cd..280ee45b0dee 100644
--- a/testsuite/.gitignore
+++ b/testsuite/.gitignore
@@ -96,6 +96,7 @@
 /sha512-224-test
 /sha512-256-test
 /sha512-test
+/streebog-test
 /twofish-test
 /umac-test
 /version-test
diff --git a/testsuite/Makefile.in b/testsuite/Makefile.in
index 3f5e5f6b995c..c66e139eee62 100644
--- a/testsuite/Makefile.in
+++ b/testsuite/Makefile.in
@@ -24,7 +24,7 @@ TS_NETTLE_SOURCES = aes-test.c arcfour-test.c arctwo-test.c \
 		    sha384-test.c sha512-test.c sha512-224-test.c sha512-256-test.c \
 		    sha3-permute-test.c sha3-224-test.c sha3-256-test.c \
 		    sha3-384-test.c sha3-512-test.c \
-		    shake256-test.c \
+		    shake256-test.c streebog-test.c \
 		    serpent-test.c twofish-test.c version-test.c \
 		    knuth-lfib-test.c \
 		    cbc-test.c cfb-test.c ctr-test.c gcm-test.c eax-test.c ccm-test.c \
diff --git a/testsuite/hmac-test.c b/testsuite/hmac-test.c
index de1b6bfe057c..348f7920add9 100644
--- a/testsuite/hmac-test.c
+++ b/testsuite/hmac-test.c
@@ -866,4 +866,21 @@ test_main(void)
 	    SHEX("0126bdb87800af214341456563780100"),
 	    SHEX("bad70b61c41095bc47e1141cfaed4272"
 		 "6a5ceebd62ce75dbbb9ad76cda9f72f7"));
+
+  /* RFC 7836 */
+  HMAC_TEST(streebog512,
+	    SHEX("000102030405060708090a0b0c0d0e0f"
+		 "101112131415161718191a1b1c1d1e1f"),
+	    SHEX("0126bdb87800af214341456563780100"),
+	    SHEX("a59bab22ecae19c65fbde6e5f4e9f5d8"
+	         "549d31f037f9df9b905500e171923a77"
+		 "3d5f1530f2ed7e964cb2eedc29e9ad2f"
+		 "3afe93b2814f79f5000ffc0366c251e6"));
+
+  HMAC_TEST(streebog256,
+	    SHEX("000102030405060708090a0b0c0d0e0f"
+		 "101112131415161718191a1b1c1d1e1f"),
+	    SHEX("0126bdb87800af214341456563780100"),
+	    SHEX("a1aa5f7de402d7b3d323f2991c8d4534"
+	         "013137010a83754fd0af6d7cd4922ed9"));
 }
diff --git a/testsuite/meta-hash-test.c b/testsuite/meta-hash-test.c
index 7d863a7c386d..eb9f3698e353 100644
--- a/testsuite/meta-hash-test.c
+++ b/testsuite/meta-hash-test.c
@@ -20,6 +20,8 @@ const char* hashes[] = {
   "sha3_256",
   "sha3_384",
   "sha3_512",
+  "streebog256",
+  "streebog512"
 };
 
 void
diff --git a/testsuite/meta-mac-test.c b/testsuite/meta-mac-test.c
index 55339441c99f..adbd43263801 100644
--- a/testsuite/meta-mac-test.c
+++ b/testsuite/meta-mac-test.c
@@ -12,6 +12,8 @@ const char* macs[] = {
   "hmac_sha256",
   "hmac_sha384",
   "hmac_sha512",
+  "hmac_streebog256",
+  "hmac_streebog512",
 };
 
 void
diff --git a/testsuite/pbkdf2-test.c b/testsuite/pbkdf2-test.c
index e64a20d09dea..9e024e57b7f5 100644
--- a/testsuite/pbkdf2-test.c
+++ b/testsuite/pbkdf2-test.c
@@ -19,7 +19,8 @@
     ASSERT(dk[expect-&gt;length] == 17);					\
   } while (0)
 
-#define MAX_DKLEN SHA512_DIGEST_SIZE
+/* Streebog test has particularly long testcase */
+#define MAX_DKLEN 100
 
 void
 test_main (void)
@@ -29,6 +30,8 @@ test_main (void)
   struct hmac_sha256_ctx sha256ctx;
   struct hmac_sha512_ctx sha512ctx;
   struct hmac_gosthash94cp_ctx gosthash94cpctx;
+  struct hmac_streebog512_ctx streebog512ctx;
+  struct hmac_streebog256_ctx streebog256ctx;
 
   /* Test vectors for PBKDF2 from RFC 6070. */
 
@@ -134,4 +137,29 @@ test_main (void)
 
   PBKDF2_HMAC_TEST (pbkdf2_hmac_gosthash94cp, LDATA("password"), 1, LDATA("salt"),
 	       SHEX("7314e7c04fb2e662c543674253f68bd0b73445d07f241bed872882da21662d58"));
+
+  hmac_streebog512_set_key (&amp;streebog512ctx, LDATA("password"));
+  PBKDF2_TEST (&amp;streebog512ctx, hmac_streebog512_update, hmac_streebog512_digest,
+	       STREEBOG512_DIGEST_SIZE, 1, LDATA("salt"),
+	       SHEX("64770af7f748c3b1c9ac831dbcfd85c26111b30a8a657ddc3056b80ca73e040d2854fd36811f6d825cc4ab66ec0a68a490a9e5cf5156b3a2b7eecddbf9a16b47"));
 +  PBKDF2_TEST (&amp;streebog512ctx, hmac_streebog512_update, hmac_streebog512_digest,
+	       STREEBOG512_DIGEST_SIZE, 4096, LDATA("salt"),
+	       SHEX("e52deb9a2d2aaff4e2ac9d47a41f34c20376591c67807f0477e32549dc341bc7867c09841b6d58e29d0347c996301d55df0d34e47cf68f4e3c2cdaf1d9ab86c3"));
 +
+  hmac_streebog512_set_key (&amp;streebog512ctx, LDATA("passwordPASSWORDpassword"));
+  PBKDF2_TEST (&amp;streebog512ctx, hmac_streebog512_update, hmac_streebog512_digest,
+	       STREEBOG512_DIGEST_SIZE, 4096, \
LDATA("saltSALTsaltSALTsaltSALTsaltSALTsalt"), +	       \
SHEX("b2d8f1245fc4d29274802057e4b54e0a0753aa22fc53760b301cf008679e58fe4bee9addcae99ba2b0b20f431a9c5e50f395"
 +		    "c89387d0945aedeca6eb4015dfc2bd2421ee9bb71183ba882ceebfef259f33f9e27dc6178cb89dc37428cf9cc52a2baa2d3a"));
 +
+  hmac_streebog512_set_key (&amp;streebog512ctx, LDATA("pass\0word"));
+  PBKDF2_TEST (&amp;streebog512ctx, hmac_streebog512_update, hmac_streebog512_digest,
+	       STREEBOG512_DIGEST_SIZE, 4096, LDATA("sa\0lt"),
+	       SHEX("50df062885b69801a3c10248eb0a27ab6e522ffeb20c991c660f001475d73a4e167f782c18e97e92976d9c1d970831ea78ccb879f67068cdac1910740844e830"));
 +
+  /* Generated */
+  hmac_streebog256_set_key (&amp;streebog256ctx, LDATA("password"));
+  PBKDF2_TEST (&amp;streebog256ctx, hmac_streebog256_update, hmac_streebog256_digest,
+	       STREEBOG256_DIGEST_SIZE, 1, LDATA("salt"),
+	       SHEX("d789458d143b9abebc4ef63ca8e576c72b13c7d4289db23fc1e946f84cd605bc"));
 }
diff --git a/testsuite/streebog-test.c b/testsuite/streebog-test.c
new file mode 100644
index 000000000000..f3532e73a7ee
--- /dev/null
+++ b/testsuite/streebog-test.c
@@ -0,0 +1,81 @@
+#include "testutils.h"
+#include "streebog.h"
+
+/* Using test vectors from the standard itself */
+
+void
+test_main(void)
+{
+  test_hash(&amp;nettle_streebog512,
+            SDATA("012345678901234567890123456789012345678901234567890123456789012"),
 +            SHEX("1b54d01a4af5b9d5 cc3d86d68d285462"
+                 "b19abc2475222f35 c085122be4ba1ffa"
+                 "00ad30f8767b3a82 384c6574f024c311"
+                 "e2a481332b08ef7f 41797891c1646f48"));
+
+  test_hash(&amp;nettle_streebog256,
+            SDATA("012345678901234567890123456789012345678901234567890123456789012"),
 +            SHEX("9d151eefd8590b89 daa6ba6cb74af927"
+                 "5dd051026bb149a4 52fd84e5e57b5500"));
+
+  test_hash(&amp;nettle_streebog512,
+            SHEX("d1e520e2e5f2f0e82c20d1f2f0e8e1ee"
+                 "e6e820e2edf3f6e82c20e2e5fef2fa20"
+                 "f120eceef0ff20f1f2f0e5ebe0ece820"
+                 "ede020f5f0e0e1f0fbff20efebfaeafb"
+                 "20c8e3eef0e5e2fb"),
+            SHEX("1e88e62226bfca6f 9994f1f2d51569e0"
+                 "daf8475a3b0fe61a 5300eee46d961376"
+                 "035fe83549ada2b8 620fcd7c496ce5b3"
+                 "3f0cb9dddc2b6460 143b03dabac9fb28"));
+
+  test_hash(&amp;nettle_streebog256,
+            SHEX("d1e520e2e5f2f0e82c20d1f2f0e8e1ee"
+                 "e6e820e2edf3f6e82c20e2e5fef2fa20"
+                 "f120eceef0ff20f1f2f0e5ebe0ece820"
+                 "ede020f5f0e0e1f0fbff20efebfaeafb"
+                 "20c8e3eef0e5e2fb"),
+            SHEX("9dd2fe4e90409e5d a87f53976d7405b0"
+                 "c0cac628fc669a74 1d50063c557e8f50"));
+
+  test_hash(&amp;nettle_streebog512,
+	    SHEX("eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"
+		 "eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"
+		 "eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"
+		 "eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"
+		 "16111111111111111111111111111111"
+		 "11111111111111111111111111111111"
+		 "11111111111111111111111111111111"
+		 "11111111111111111111111111111116"),
+	    SHEX("8b06f41e59907d9636e892caf5942fcd"
+		 "fb71fa31169a5e70f0edb873664df41c"
+		 "2cce6e06dc6755d15a61cdeb92bd607c"
+		 "c4aaca6732bf3568a23a210dd520fd41"));
+
+  test_hash(&amp;nettle_streebog256,
+	    SHEX("eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"
+		 "eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"
+		 "eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"
+		 "eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"
+		 "16111111111111111111111111111111"
+		 "11111111111111111111111111111111"
+		 "11111111111111111111111111111111"
+		 "11111111111111111111111111111116"),
+	    SHEX("81bb632fa31fcc38b4c379a662dbc58b"
+		 "9bed83f50d3a1b2ce7271ab02d25babb"));
+
+  test_hash(&amp;nettle_streebog512,
+	    SHEX("ffffffffffffffffffffffffffffffff"
+		 "ffffffffffffffffffffffffffffffff"
+		 "ffffffffffffffffffffffffffffffff"
+		 "ffffffffffffffffffffffffffffffff"
+		 "ffffffffffffffffffffffffffffffff"
+		 "ffffffffffffffffffffffffffffffff"
+		 "ffffffffffffffffffffffffffffffff"
+		 "ffffffffffffffffffffffffffffffff"),
+	    SHEX("90a161d12ad309498d3fe5d48202d8a4"
+		 "e9c406d6a264aeab258ac5ecc37a7962"
+		 "aaf9587a5abb09b6bb81ec4b3752a3ff"
+		 "5a838ef175be5772056bc5fe54fcfc7e"));
+
+}
-- 
2.26.2

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200106220156</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-06 22:01:56-0400</timestampReceived><subject>Re: update CI to latest fedora image</subject><body>

Nikos Mavrogiannopoulos &lt;nmav@redhat.com&gt; writes:

&gt;  This patch updates the CI to the latest fedora image. It also includes
&gt; some minor changes to tools, to pass the new clang analyser. 

Pushed now.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200106221642</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-01-06 22:16:42-0400</timestampReceived><subject>[PATCH v3 0/3] ecc: rename to contain full curve name</subject><body>

Next iteration of renaming patchset. The only change since v2 is
rebasing on top of current master to fix conflicts due to ed448
addition.

-- 
With best wishes
Dmitry


_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200908180450</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-09-08 18:04:50-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" AES improve syntax</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; If these registers are used explicitly, GAS will yield a bunch of errors
&gt; like "Error: unsupported relocation against r1" unless "-mregnames" is
&gt; passed to the assembler. I can add "-Wa,-mregnames" to CFLAGS in
&gt; configure.ac and modify the assembly files to improve the syntax.

I think I'll adopt the configure check and related m4 things from GMP. It's
documented like this:

dnl  GMP_ASM_POWERPC_R_REGISTERS
dnl  ---------------------------
dnl  Determine whether the assembler takes powerpc registers with an "r" as
dnl  in "r6", or as plain "6".  The latter is standard, but NeXT, Rhapsody,
dnl  and MacOS-X require the "r" forms.
dnl
dnl  See also mpn/powerpc32/powerpc-defs.m4 which uses the result of this
dnl  test.

I'd like to also try out -Wa,-mregnames, if that's needed for register
names on more mainstream ppc systems.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200918054409</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-09-18 05:44:09-0400</timestampReceived><subject>Re: The m4 quote characters</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; I apologize for the late reply. I just saw this post.
&gt; I'm a little confused here, are these changes conflict with the patch I
&gt; just posted?

I don't think so, it looks like your patch is against the code after the
conversion from &lt;&gt; to `'.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200918083534</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-09-18 08:35:34-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" Use register names explicitly</subject><body>

&gt;
&gt; I'm not sure it's a good idea to unconditionally use these gcc specific
&gt; flags. Are they supported by all relevant compilers?


 It seems that Clang doesn't support that flag.


&gt; I'm considering instead adding the attached patch.
&gt;

This is a better solution. I'll consider this patch for upcoming editing.


&gt; &gt; diff --git a/powerpc64/machine.m4 b/powerpc64/machine.m4
&gt; &gt; index 221fa523..cefabc9b 100644
&gt; &gt; --- a/powerpc64/machine.m4
&gt; &gt; +++ b/powerpc64/machine.m4
&gt; &gt; @@ -24,7 +24,7 @@ define(`EPILOGUE',
&gt; &gt;
&gt; &gt;  C Get vector-scalar register from vector register
&gt; &gt;  C VSR(VR)
&gt; &gt; -define(`VSR',`32+$1')
&gt; &gt; +define(`VSR',``vs'eval(32+substr($1,1,len($1)))')
&gt;
&gt; May be less brittle with an explicit ifelse chain, like the similar
&gt; macros in arm/machine.m4. Should work better with the above approach,
&gt; where r1 may expand to 1, depending on a configure check.


I got it, I'll consider this too.

Thank you,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200919060217</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-09-19 06:02:17-0400</timestampReceived><subject>[PATCH] "PowerPC64" Use same register convention in VSR macro</subject><body>

---
 powerpc64/machine.m4 | 7 +++----
 1 file changed, 3 insertions(+), 4 deletions(-)

diff --git a/powerpc64/machine.m4 b/powerpc64/machine.m4
index f867ec01..e2383201 100644
--- a/powerpc64/machine.m4
+++ b/powerpc64/machine.m4
@@ -24,10 +24,9 @@ define(`EPILOGUE',

 C Get vector-scalar register from vector register
 C VSR(VR)
-define(`VSR',`ifelse(ASM_PPC_WANT_R_REGISTERS,no,
-`eval(32+$1)',
-``vs'eval(32+substr($1,1,len($1)))'
-)')
+define(`VSR',`ifelse(substr($1,0,1),`v',
+``vs'eval(32+substr($1,1,len($1)))',
+`eval(32+$1)')')

 C Load the quadword in DATA_SRC storage into
 C VEC_DST. GPR is general-purpose register

-- 
2.17.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200921113838</emailId><senderName>Jaak Ristioja</senderName><senderEmail>jaak.ristioja@cyber.ee</senderEmail><timestampReceived>2020-09-21 11:38:38-0400</timestampReceived><subject>Re: NAPLES standup</subject><body>

Hello,

I apologize for spamming the mailing list with internal communication. 
Apparently KMail/Akonadi has a some bug which causes the nettle-bugs mailing 
list to be automatically added to the list of recipients when using "Reply to 
All..." on an unrelated e-mail.

Best regards,
Jaak Ristioja
Cybernetica AS


_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200923172923</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-09-23 17:29:23-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" Use explicit register names</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; This patch is built upon ppc-m4-macrology.patch. Using explicit register
&gt; names is working as expected now.

Thanks. This and the next patch now merged to master-updates.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200925205302</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-09-25 20:53:02-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

Writing .align explicitly instead of defining FUNC_ALIGN has no negative
effects except the function won't get alignment for big-endian mode.
It looks like there are some additional operations are needed for
big-endian mode before storing the results to 'dst' buffer, in
chacha-core-internal.c:

#ifdef WORDS_BIGENDIAN
#define LE_SWAP32(v) \
  ((ROTL32(8,  v) &amp; 0x00FF00FFUL) | \
   (ROTL32(24, v) &amp; 0xFF00FF00UL))
#else
#define LE_SWAP32(v) (v)
#endif

for (i = 0; i &lt; _CHACHA_STATE_LENGTH; i++)
    {
      uint32_t t = x[i] + src[i];
      dst[i] = LE_SWAP32 (t);
    }

On Fri, Sep 25, 2020 at 10:58 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt; Great work. The implementation looks fine, I like the idea of using -16
&gt; &gt; instead of 16 for rotating because vspltisw is limited to (-16 to 15)
&gt; &gt; and vrlw picks the low-order 5 bits which is the same for both -16 and
&gt; &gt; 16.
&gt;
&gt; I picked up that trick from Torbjörn Granlund's code.
&gt;
&gt; &gt; BTW this implementation should work as is on big-endian mode without any
&gt; &gt; hassle because lxvw4x/stxvw4x are endianness aware of loading/storing
&gt; word
&gt; &gt; values.
&gt;
&gt; I've pushed it to a branch ppc-chacha-core. But it fails on big-endian
&gt; powerpc64, see https://gitlab.com/gnutls/nettle/-/jobs/758348866.
&gt;
&gt; And it looks like the error message from the first failing chacha test
&gt; is truncated, which makes me suspect some error in function prologue or
&gt; register usage, resulting in some invalid state when the function returns.
&gt;
&gt; Comparing to your assembly code, I don't set FUNC_ALIGN, is that a
&gt; problem?
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200928180721</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-09-28 18:07:21-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" GCM support</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

Thanks for the update. This is quite complex for me. I have not yet read
the code very carefully. I think I'd like to focus on the main function,
gcm_hash, first. Some questions and suggestions, to make it easier:

1. Take out the fat support to it's own patch.

2. You could consider doing the init_key in C, if nothing else as
   documentation. It could be either under some #ifdef in gcm.c, or a
   separate .c file under powerpc64/p8/, next to gcm-hash.asm. Maybe
   it's still a good idea to have it in assembly, that's a tradeoff that
   depends a bit on the complexity of both the C and assembly, and the
   speedup from doing it in assembly. And I don't have a very strong
   opinion on this point now.

   Even with asm, it might be a bit clearer to move it to its own .asm
   file, so each file can use define only for the relevant registers for
   that function.

3. What's TableElemAlign? Assuming GCM_TABLE_BITS is 8 (current Nettle
   ABI), you can treat struct gcm_key as a blob of size 4096 bytes, with
   alignment corresponding to what the C compiler uses for uint64_t. Are
   you using some padding at the start (depending on address) to ensure
   you get stronger alignment? And 256 byte alignment sounds a bit more
   than needed?

4. Please document the layout used for the precomputed values stored in
   struct gcm_key.

5. It would help with comments explaining the naming convention used for
   the named registers, and the instruction sequence used for a single
   Karatsuba multiplication, with any needed comments.

6. Is 8-way unrolling really necessary to get full utilization of the
   execution units? And it's also not yet clear to me what 8-way means,
   is that 8 blocks of 16 bytes each (i.e., 128 bytes input), or 8 input
   bytes?

7. Do you need any bit reversal? As you have mentioned, the
   multiplication operation is symmetric under bit reversal, so ideally
   bit reversal should be needed at most when setting the key and
   extracting the digest, but not by the main workhorse, gcm_hash.

I know you have referenced articles for the used algorithm, but it would
be helpful to have the main ideas in comments close to the code.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200928181456</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-09-28 18:14:56-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" chacha-core big-endian support "Shorter version"</subject><body>

Sure. According to Power ISA 2.07:
The lvsl and lvsr instructions can be used to create the permute control
vector to be used by a subsequent vperm instruction.

So the lvsl and lvsr instructions check 'sh' value in order to fill the
vector register, if 'sh' is 0 the vector register will be populated as
follow
0x000102030405060708090A0B0C0D0E0F
this can be done using the following instructions
li       r9, 0
lvsl     LE_MASK, r9, r9
Now we xor each byte with 3 using these instructions
vspltisb LE_TEMP, 0x03
vxor     LE_MASK, LE_MASK, LE_TEMP
The value of the vector register is now
0x03020100070605040B0A09080F0E0D0C
If this mask has been used in vperm instruction, that means each word in
the source vector will be byte reversed so in the big-endian mode every
word of the result will be stored in the destination buffer in
little-endian order and that what LE_SWAP32 is meant to do.

On Mon, Sep 28, 2020 at 8:32 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt; The last patch follows the C implementation but I just figured out a
&gt; decent
&gt; &gt; way to do it.
&gt;
&gt; Thanks! Applied, and pushed on the ppc-chacha-core branch for testing.
&gt; (Had apply it semi-manually, since the file to patch indents using TAB
&gt; and those were replaced by spaces in the emailed patch).
&gt;
&gt; &gt; +IF_BE(`
&gt; &gt; + li       r9, 0
&gt; &gt; + lvsl     LE_MASK, r9, r9
&gt; &gt; + vspltisb LE_TEMP, 0x03
&gt; &gt; + vxor     LE_MASK, LE_MASK, LE_TEMP
&gt; &gt; +')
&gt;
&gt; I think this deserves some comments, on what goes into the register in
&gt; each step. Clever that the endian conversion corresponds to xoring the
&gt; byte indices with 3.
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200103091332</emailId><senderName>Nikos Mavrogiannopoulos</senderName><senderEmail>nmav@redhat.com</senderEmail><timestampReceived>2020-01-03 09:13:32-0400</timestampReceived><subject>update CI to latest fedora image</subject><body>

Hi,
 This patch updates the CI to the latest fedora image. It also includes
some minor changes to tools, to pass the new clang analyser. I will
remove the f29 image once this is applied. A test run passes:
https://gitlab.com/nmav/nettle/pipelines/106785682

regards,
Nikos


["0002-sexp-conv-ensure-non-null-input-to-strcmp-and-strtol.patch" (0002-sexp-conv-ensure-non-null-input-to-strcmp-and-strtol.patch)]

From 859d819ddbdbb7cef176ec2c1ed40049b942a55a Mon Sep 17 00:00:00 2001
From: Nikos Mavrogiannopoulos &lt;nmav@redhat.com&gt;
Date: Fri, 3 Jan 2020 09:57:38 +0100
Subject: [PATCH 2/2] sexp-conv: ensure non-null input to strcmp() and strtol()

Signed-off-by: Nikos Mavrogiannopoulos &lt;nmav@redhat.com&gt;
---
 tools/sexp-conv.c | 6 +++++-
 1 file changed, 5 insertions(+), 1 deletion(-)

diff --git a/tools/sexp-conv.c b/tools/sexp-conv.c
index 557b8bd7..e7357052 100644
--- a/tools/sexp-conv.c
+++ b/tools/sexp-conv.c
@@ -217,6 +217,7 @@ static int
 match_argument(const char *given, const char *name)
 {
   /* FIXME: Allow abbreviations */
+  assert(given != NULL &amp;&amp; name != NULL);
   return !strcmp(given, name);
 }
 
@@ -279,7 +280,10 @@ parse_options(struct conv_options *o,
 	case 'w':
 	  {
 	    char *end;
-	    int width = strtol(optarg, &amp;end , 0);
+	    int width;
+	    assert(optarg != NULL);
+
+	    width = strtol(optarg, &amp;end , 0);
 	    if (!*optarg || *end || width &lt; 0)
 	      die("sexp-conv: Invalid width `%s'.\n", optarg);
 
-- 
2.24.1


[Attachment #4 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200103095122</emailId><senderName>Nikos Mavrogiannopoulos</senderName><senderEmail>nmav@redhat.com</senderEmail><timestampReceived>2020-01-03 09:51:22-0400</timestampReceived><subject>Re: update CI to latest fedora image</subject><body>

I seem to have attached the wrong file. Let me try again.

On Fri, Jan 3, 2020 at 10:13 AM Nikos Mavrogiannopoulos &lt;nmav@redhat.com&gt; w=
rote:
&gt;
&gt; Hi,
&gt;  This patch updates the CI to the latest fedora image. It also includes
&gt; some minor changes to tools, to pass the new clang analyser. I will
&gt; remove the f29 image once this is applied. A test run passes:
&gt; https://gitlab.com/nmav/nettle/pipelines/106785682
&gt;
&gt; regards,
&gt; Nikos
&gt;

["0002-sexp-conv-ensure-non-null-input-to-strcmp-and-strtol.patch" (text/x-patch)]

From 859d819ddbdbb7cef176ec2c1ed40049b942a55a Mon Sep 17 00:00:00 2001
From: Nikos Mavrogiannopoulos &lt;nmav@redhat.com&gt;
Date: Fri, 3 Jan 2020 09:57:38 +0100
Subject: [PATCH 2/2] sexp-conv: ensure non-null input to strcmp() and strtol()

Signed-off-by: Nikos Mavrogiannopoulos &lt;nmav@redhat.com&gt;
---
 tools/sexp-conv.c | 6 +++++-
 1 file changed, 5 insertions(+), 1 deletion(-)

diff --git a/tools/sexp-conv.c b/tools/sexp-conv.c
index 557b8bd7..e7357052 100644
--- a/tools/sexp-conv.c
+++ b/tools/sexp-conv.c
@@ -217,6 +217,7 @@ static int
 match_argument(const char *given, const char *name)
 {
   /* FIXME: Allow abbreviations */
+  assert(given != NULL &amp;&amp; name != NULL);
   return !strcmp(given, name);
 }
 
@@ -279,7 +280,10 @@ parse_options(struct conv_options *o,
 	case 'w':
 	  {
 	    char *end;
-	    int width = strtol(optarg, &amp;end , 0);
+	    int width;
+	    assert(optarg != NULL);
+
+	    width = strtol(optarg, &amp;end , 0);
 	    if (!*optarg || *end || width &lt; 0)
 	      die("sexp-conv: Invalid width `%s'.\n", optarg);
 
-- 
2.24.1


["0001-.gitlab-ci.yml-use-fedora31-image.patch" (text/x-patch)]

From b3690f02166b07bb9e4be6f3af13e21163f62e40 Mon Sep 17 00:00:00 2001
From: Nikos Mavrogiannopoulos &lt;nmav@redhat.com&gt;
Date: Fri, 3 Jan 2020 09:48:59 +0100
Subject: [PATCH 1/2] .gitlab-ci.yml: use fedora31 image

Signed-off-by: Nikos Mavrogiannopoulos &lt;nmav@redhat.com&gt;
---
 .gitlab-ci.yml | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/.gitlab-ci.yml b/.gitlab-ci.yml
index c857eacc..85acdf14 100644
--- a/.gitlab-ci.yml
+++ b/.gitlab-ci.yml
@@ -1,7 +1,7 @@
 variables:
   BUILD_IMAGES_PROJECT: gnutls/build-images
   DEBIAN_CROSS_BUILD: buildenv-debian-cross
-  FEDORA_BUILD: buildenv-f29
+  FEDORA_BUILD: buildenv-fedora31
   DEBIAN_X86_CROSS_BUILD: buildenv-debian-x86-cross
   GET_SOURCES_ATTEMPTS: "3"
 
-- 
2.24.1


[Attachment #5 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200103231136</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-03 23:11:36-0400</timestampReceived><subject>Re: update CI to latest fedora image</subject><body>

Nikos Mavrogiannopoulos &lt;nmav@redhat.com&gt; writes:

&gt; On Fri, Jan 3, 2020 at 10:13 AM Nikos Mavrogiannopoulos &lt;nmav@redhat.com&gt; wrote:
&gt;&gt;
&gt;&gt; Hi,
&gt;&gt;  This patch updates the CI to the latest fedora image. It also includes
&gt;&gt; some minor changes to tools, to pass the new clang analyser. I will
&gt;&gt; remove the f29 image once this is applied. A test run passes:
&gt;&gt; https://gitlab.com/nmav/nettle/pipelines/106785682
&gt;&gt;
&gt;&gt; regards,
&gt;&gt; Nikos

Thanks. Not applied yet, but I hope to get to it in a few days.

I noticed that some of todays builds have failed. It seems the find
command is no longer available (used by config.status). If I understand
the log correctly, it's using
registry.gitlab.com/gnutls/build-images:buildenv-f29. See
https://gitlab.com/gnutls/nettle/-/jobs/393683657

Is that easy to fix, or is it better to leave as is and just switch to
the fedora31 images?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200911192207</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-09-11 19:22:07-0400</timestampReceived><subject>The m4 quote characters</subject><body>

To adopt the m4 macrology used in GMP, for optionally substituting
r0--&gt;0, r1--&gt;1, etc, I tried to copy the m4 macros, including an m4
forloop.

But that didn't work out of the box, and it seems that one complication
is that Nettle's uses &lt;&gt; as m4 quote characters. I've used them since I
introduced m4 preprocessing back in 2002, and I honestly don't remember
why I thought that was a good idea at the time. I guess I found `' ugly,
and the autoconf choice of [] didn't work well with assembly syntax (in
particular on sparc).

In a few places nettle needs to use &lt; as an operator in m4 eval, and
there are workarounds for that using local changequote, with the curious
hack

define(&lt;W64_ENTRY&gt;, &lt;
  changequote([,])dnl
  ifelse(&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; ignored; only for balancing)
  ifelse(W64_ABI,yes,[
    dnl unconditionally push %rdi, making %rsp 16-byte aligned
    push %rdi
    dnl Save %xmm6, ..., if needed
    ifelse(eval($2 &gt; 6), 1, [
      sub [$]eval(16*($2 - 6)), %rsp
      movdqa %xmm6, 0(%rsp)
    ])
    ifelse(eval($2 &gt; 7), 1, [
      movdqa %xmm7, 16(%rsp)
    ])
  ...

So I'm considering changing that, and instead stick to m4 default
quotes. Opinions?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200914183813</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-09-14 18:38:13-0400</timestampReceived><subject>Re: The m4 quote characters</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; So I'm considering changing that, and instead stick to m4 default
&gt; quotes. Opinions?

Pushed changes to do that to a branch, default-m4-quote-char. Seems to
pass the ci tests, as well as manual testing on sparc. I'll likely merge
in a day or two, if I don't become aware of any problems.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200916115159</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-09-16 11:51:59-0400</timestampReceived><subject>[PATCH] "PowerPC64" Use register names explicitly</subject><body>

Use explicit register names to improve the syntax of assembly files and
pass -mregnames to the assembler to allow building the assembly files. I
will make a stand-alone patch for GCM which brings all the accumulated
modifications so it can be directly merged.
---
 configure.ac                          |   4 +-
 powerpc64/machine.m4                  |   4 +-
 powerpc64/p8/aes-decrypt-internal.asm | 194
+++++++++++++++++-----------------
 powerpc64/p8/aes-encrypt-internal.asm | 192
++++++++++++++++-----------------
 4 files changed, 198 insertions(+), 196 deletions(-)

diff --git a/configure.ac b/configure.ac
index 666b2f4a..6ab32f03 100644
--- a/configure.ac
+++ b/configure.ac
@@ -458,10 +458,12 @@ if test "x$enable_assembler" = xyes ; then
       if test "$ABI" = 64 ; then
  asm_path="powerpc64"
  if test "x$enable_fat" = xyes ; then
-  asm_path="powerpc64/fat $asm_path"
+  CFLAGS="$CFLAGS -Wa,-mregnames"
+    asm_path="powerpc64/fat $asm_path"
   OPT_NETTLE_SOURCES="fat-ppc.c $OPT_NETTLE_SOURCES"
   FAT_TEST_LIST="none crypto_ext"
  elif test "x$enable_power_crypto_ext" = xyes ; then
+          CFLAGS="$CFLAGS -Wa,-mregnames"
           asm_path="powerpc64/p8 $asm_path"
  fi
       fi
diff --git a/powerpc64/machine.m4 b/powerpc64/machine.m4
index 221fa523..cefabc9b 100644
--- a/powerpc64/machine.m4
+++ b/powerpc64/machine.m4
@@ -24,7 +24,7 @@ define(`EPILOGUE',

 C Get vector-scalar register from vector register
 C VSR(VR)
-define(`VSR',`32+$1')
+define(`VSR',``vs'eval(32+substr($1,1,len($1)))')

 C Load the quadword in DATA_SRC storage into
 C VEC_DST. GPR is general-purpose register
@@ -32,5 +32,5 @@ C used to obtain the effective address of
 C DATA_SRC storage.
 C DATA_LOAD_VEC(VEC_DST, DATA_SRC, GPR)
 define(`DATA_LOAD_VEC',
-`ld $3,$2@got(2)
+`ld $3,$2@got(r2)
 lvx $1,0,$3')
diff --git a/powerpc64/p8/aes-decrypt-internal.asm
b/powerpc64/p8/aes-decrypt-internal.asm
index acdbc1bd..7c79ffcb 100644
--- a/powerpc64/p8/aes-decrypt-internal.asm
+++ b/powerpc64/p8/aes-decrypt-internal.asm
@@ -31,32 +31,32 @@ ifelse(`

 C Register usage:

-define(`SP', `1')
-define(`TOCP', `2')
-
-define(`ROUNDS', `3')
-define(`KEYS', `4')
-define(`LENGTH', `6')
-define(`DST', `7')
-define(`SRC', `8')
-
-define(`swap_mask', `0')
-
-define(`K', `1')
-define(`S0', `2')
-define(`S1', `3')
-define(`S2', `4')
-define(`S3', `5')
-define(`S4', `6')
-define(`S5', `7')
-define(`S6', `8')
-define(`S7', `9')
+define(`SP', `r1')
+define(`TOCP', `r2')
+
+define(`ROUNDS', `r3')
+define(`KEYS', `r4')
+define(`LENGTH', `r6')
+define(`DST', `r7')
+define(`SRC', `r8')
+
+define(`swap_mask', `v0')
+
+define(`K', `v1')
+define(`S0', `v2')
+define(`S1', `v3')
+define(`S2', `v4')
+define(`S3', `v5')
+define(`S4', `v6')
+define(`S5', `v7')
+define(`S6', `v8')
+define(`S7', `v9')

 C ZERO vector register is used in place of RoundKey
 C for vncipher instruction because the order of InvMixColumns
 C and Xor processes are flipped in that instruction.
 C The Xor process with RoundKey is executed afterward.
-define(`ZERO', `10')
+define(`ZERO', `v10')

 .file "aes-decrypt-internal.asm"

@@ -71,30 +71,30 @@ define(`FUNC_ALIGN', `5')
 PROLOGUE(_nettle_aes_decrypt)
  vxor ZERO,ZERO,ZERO

- DATA_LOAD_VEC(swap_mask,.swap_mask,5)
+ DATA_LOAD_VEC(swap_mask,.swap_mask,r5)

  subi ROUNDS,ROUNDS,1
  srdi LENGTH,LENGTH,4

- srdi 5,LENGTH,3 #8x loop count
- cmpldi 5,0
+ srdi r5,LENGTH,3 #8x loop count
+ cmpldi r5,0
  beq L4x

- std 25,-56(SP);
- std 26,-48(SP);
- std 27,-40(SP);
- std 28,-32(SP);
- std 29,-24(SP);
- std 30,-16(SP);
- std 31,-8(SP);
-
- li 25,0x10
- li 26,0x20
- li 27,0x30
- li 28,0x40
- li 29,0x50
- li 30,0x60
- li 31,0x70
+ std r25,-56(SP);
+ std r26,-48(SP);
+ std r27,-40(SP);
+ std r28,-32(SP);
+ std r29,-24(SP);
+ std r30,-16(SP);
+ std r31,-8(SP);
+
+ li r25,0x10
+ li r26,0x20
+ li r27,0x30
+ li r28,0x40
+ li r29,0x50
+ li r30,0x60
+ li r31,0x70

 .align 5
 Lx8_loop:
@@ -102,13 +102,13 @@ Lx8_loop:
  vperm   K,K,K,swap_mask

  lxvd2x VSR(S0),0,SRC
- lxvd2x VSR(S1),25,SRC
- lxvd2x VSR(S2),26,SRC
- lxvd2x VSR(S3),27,SRC
- lxvd2x VSR(S4),28,SRC
- lxvd2x VSR(S5),29,SRC
- lxvd2x VSR(S6),30,SRC
- lxvd2x VSR(S7),31,SRC
+ lxvd2x VSR(S1),r25,SRC
+ lxvd2x VSR(S2),r26,SRC
+ lxvd2x VSR(S3),r27,SRC
+ lxvd2x VSR(S4),r28,SRC
+ lxvd2x VSR(S5),r29,SRC
+ lxvd2x VSR(S6),r30,SRC
+ lxvd2x VSR(S7),r31,SRC

 IF_LE(`vperm S0,S0,S0,swap_mask
  vperm S1,S1,S1,swap_mask
@@ -129,10 +129,10 @@ IF_LE(`vperm S0,S0,S0,swap_mask
  vxor S7,S7,K

  mtctr ROUNDS
- li 10,0x10
+ li r10,0x10
 .align 5
 L8x_round_loop:
- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm   K,K,K,swap_mask
  vncipher S0,S0,ZERO
  vncipher S1,S1,ZERO
@@ -150,10 +150,10 @@ L8x_round_loop:
  vxor S5,S5,K
  vxor S6,S6,K
  vxor S7,S7,K
- addi 10,10,0x10
+ addi r10,r10,0x10
  bdnz L8x_round_loop

- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm   K,K,K,swap_mask
  vncipherlast S0,S0,K
  vncipherlast S1,S1,K
@@ -174,44 +174,44 @@ IF_LE(`vperm S0,S0,S0,swap_mask
  vperm S7,S7,S7,swap_mask')

  stxvd2x VSR(S0),0,DST
- stxvd2x VSR(S1),25,DST
- stxvd2x VSR(S2),26,DST
- stxvd2x VSR(S3),27,DST
- stxvd2x VSR(S4),28,DST
- stxvd2x VSR(S5),29,DST
- stxvd2x VSR(S6),30,DST
- stxvd2x VSR(S7),31,DST
+ stxvd2x VSR(S1),r25,DST
+ stxvd2x VSR(S2),r26,DST
+ stxvd2x VSR(S3),r27,DST
+ stxvd2x VSR(S4),r28,DST
+ stxvd2x VSR(S5),r29,DST
+ stxvd2x VSR(S6),r30,DST
+ stxvd2x VSR(S7),r31,DST

  addi SRC,SRC,0x80
  addi DST,DST,0x80
- subic. 5,5,1
+ subic. r5,r5,1
  bne Lx8_loop

- ld 25,-56(SP);
- ld 26,-48(SP);
- ld 27,-40(SP);
- ld 28,-32(SP);
- ld 29,-24(SP);
- ld 30,-16(SP);
- ld 31,-8(SP);
+ ld r25,-56(SP);
+ ld r26,-48(SP);
+ ld r27,-40(SP);
+ ld r28,-32(SP);
+ ld r29,-24(SP);
+ ld r30,-16(SP);
+ ld r31,-8(SP);

  clrldi LENGTH,LENGTH,61

 L4x:
- srdi   5,LENGTH,2
- cmpldi   5,0
+ srdi   r5,LENGTH,2
+ cmpldi   r5,0
  beq   L2x

  lxvd2x   VSR(K),0,KEYS
  vperm   K,K,K,swap_mask

  lxvd2x VSR(S0),0,SRC
- li  9,0x10
- lxvd2x VSR(S1),9,SRC
- addi   9,9,0x10
- lxvd2x VSR(S2),9,SRC
- addi   9,9,0x10
- lxvd2x VSR(S3),9,SRC
+ li  r9,0x10
+ lxvd2x VSR(S1),r9,SRC
+ addi   r9,r9,0x10
+ lxvd2x VSR(S2),r9,SRC
+ addi   r9,r9,0x10
+ lxvd2x VSR(S3),r9,SRC

 IF_LE(`vperm S0,S0,S0,swap_mask
  vperm S1,S1,S1,swap_mask
@@ -224,10 +224,10 @@ IF_LE(`vperm S0,S0,S0,swap_mask
  vxor S3,S3,K

  mtctr ROUNDS
- li 10,0x10
+ li r10,0x10
 .align 5
 L4x_round_loop:
- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm  K,K,K,swap_mask
  vncipher S0,S0,ZERO
  vncipher S1,S1,ZERO
@@ -237,10 +237,10 @@ L4x_round_loop:
  vxor  S1,S1,K
  vxor   S2,S2,K
  vxor   S3,S3,K
- addi   10,10,0x10
+ addi   r10,r10,0x10
  bdnz  L4x_round_loop

- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm   K,K,K,swap_mask
  vncipherlast S0,S0,K
  vncipherlast S1,S1,K
@@ -253,12 +253,12 @@ IF_LE(`vperm S0,S0,S0,swap_mask
  vperm S3,S3,S3,swap_mask')

  stxvd2x VSR(S0),0,DST
- li  9,0x10
- stxvd2x VSR(S1),9,DST
- addi   9,9,0x10
- stxvd2x VSR(S2),9,DST
- addi  9,9,0x10
- stxvd2x VSR(S3),9,DST
+ li  r9,0x10
+ stxvd2x VSR(S1),r9,DST
+ addi   r9,r9,0x10
+ stxvd2x VSR(S2),r9,DST
+ addi  r9,r9,0x10
+ stxvd2x VSR(S3),r9,DST

  addi   SRC,SRC,0x40
  addi   DST,DST,0x40
@@ -266,16 +266,16 @@ IF_LE(`vperm S0,S0,S0,swap_mask
  clrldi LENGTH,LENGTH,62

 L2x:
- srdi  5,LENGTH,1
- cmpldi  5,0
+ srdi  r5,LENGTH,1
+ cmpldi  r5,0
  beq   L1x

  lxvd2x VSR(K),0,KEYS
  vperm K,K,K,swap_mask

  lxvd2x VSR(S0),0,SRC
- li   9,0x10
- lxvd2x VSR(S1),9,SRC
+ li   r9,0x10
+ lxvd2x VSR(S1),r9,SRC

 IF_LE(`vperm S0,S0,S0,swap_mask
  vperm S1,S1,S1,swap_mask')
@@ -284,19 +284,19 @@ IF_LE(`vperm S0,S0,S0,swap_mask
  vxor   S1,S1,K

  mtctr   ROUNDS
- li  10,0x10
+ li  r10,0x10
 .align 5
 L2x_round_loop:
- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm  K,K,K,swap_mask
  vncipher S0,S0,ZERO
  vncipher S1,S1,ZERO
  vxor  S0,S0,K
  vxor  S1,S1,K
- addi   10,10,0x10
+ addi   r10,r10,0x10
  bdnz   L2x_round_loop

- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm  K,K,K,swap_mask
  vncipherlast S0,S0,K
  vncipherlast S1,S1,K
@@ -305,8 +305,8 @@ IF_LE(`vperm S0,S0,S0,swap_mask
  vperm S1,S1,S1,swap_mask')

  stxvd2x VSR(S0),0,DST
- li  9,0x10
- stxvd2x VSR(S1),9,DST
+ li  r9,0x10
+ stxvd2x VSR(S1),r9,DST

  addi   SRC,SRC,0x20
  addi   DST,DST,0x20
@@ -327,17 +327,17 @@ IF_LE(`vperm S0,S0,S0,swap_mask')
  vxor   S0,S0,K

  mtctr   ROUNDS
- li   10,0x10
+ li   r10,0x10
 .align 5
 L1x_round_loop:
- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm  K,K,K,swap_mask
  vncipher S0,S0,ZERO
  vxor   S0,S0,K
- addi   10,10,0x10
+ addi   r10,r10,0x10
  bdnz   L1x_round_loop

- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm  K,K,K,swap_mask
  vncipherlast S0,S0,K

diff --git a/powerpc64/p8/aes-encrypt-internal.asm
b/powerpc64/p8/aes-encrypt-internal.asm
index 482dff25..3dd6e7b5 100644
--- a/powerpc64/p8/aes-encrypt-internal.asm
+++ b/powerpc64/p8/aes-encrypt-internal.asm
@@ -31,26 +31,26 @@ ifelse(`

 C Register usage:

-define(`SP', `1')
-define(`TOCP', `2')
-
-define(`ROUNDS', `3')
-define(`KEYS', `4')
-define(`LENGTH', `6')
-define(`DST', `7')
-define(`SRC', `8')
-
-define(`swap_mask', `0')
-
-define(`K', `1')
-define(`S0', `2')
-define(`S1', `3')
-define(`S2', `4')
-define(`S3', `5')
-define(`S4', `6')
-define(`S5', `7')
-define(`S6', `8')
-define(`S7', `9')
+define(`SP', `r1')
+define(`TOCP', `r2')
+
+define(`ROUNDS', `r3')
+define(`KEYS', `r4')
+define(`LENGTH', `r6')
+define(`DST', `r7')
+define(`SRC', `r8')
+
+define(`swap_mask', `v0')
+
+define(`K', `v1')
+define(`S0', `v2')
+define(`S1', `v3')
+define(`S2', `v4')
+define(`S3', `v5')
+define(`S4', `v6')
+define(`S5', `v7')
+define(`S6', `v8')
+define(`S7', `v9')

 .file "aes-encrypt-internal.asm"

@@ -63,30 +63,30 @@ define(`S7', `9')

 define(`FUNC_ALIGN', `5')
 PROLOGUE(_nettle_aes_encrypt)
- DATA_LOAD_VEC(swap_mask,.swap_mask,5)
+ DATA_LOAD_VEC(swap_mask,.swap_mask,r5)

  subi ROUNDS,ROUNDS,1
  srdi LENGTH,LENGTH,4

- srdi 5,LENGTH,3 #8x loop count
- cmpldi 5,0
+ srdi r5,LENGTH,3 #8x loop count
+ cmpldi r5,0
  beq L4x

- std 25,-56(SP);
- std 26,-48(SP);
- std 27,-40(SP);
- std 28,-32(SP);
- std 29,-24(SP);
- std 30,-16(SP);
- std 31,-8(SP);
-
- li 25,0x10
- li 26,0x20
- li 27,0x30
- li 28,0x40
- li 29,0x50
- li 30,0x60
- li 31,0x70
+ std r25,-56(SP);
+ std r26,-48(SP);
+ std r27,-40(SP);
+ std r28,-32(SP);
+ std r29,-24(SP);
+ std r30,-16(SP);
+ std r31,-8(SP);
+
+ li r25,0x10
+ li r26,0x20
+ li r27,0x30
+ li r28,0x40
+ li r29,0x50
+ li r30,0x60
+ li r31,0x70

 .align 5
 Lx8_loop:
@@ -94,13 +94,13 @@ Lx8_loop:
  vperm   K,K,K,swap_mask

  lxvd2x VSR(S0),0,SRC
- lxvd2x VSR(S1),25,SRC
- lxvd2x VSR(S2),26,SRC
- lxvd2x VSR(S3),27,SRC
- lxvd2x VSR(S4),28,SRC
- lxvd2x VSR(S5),29,SRC
- lxvd2x VSR(S6),30,SRC
- lxvd2x VSR(S7),31,SRC
+ lxvd2x VSR(S1),r25,SRC
+ lxvd2x VSR(S2),r26,SRC
+ lxvd2x VSR(S3),r27,SRC
+ lxvd2x VSR(S4),r28,SRC
+ lxvd2x VSR(S5),r29,SRC
+ lxvd2x VSR(S6),r30,SRC
+ lxvd2x VSR(S7),r31,SRC

 IF_LE(`vperm S0,S0,S0,swap_mask
  vperm S1,S1,S1,swap_mask
@@ -121,10 +121,10 @@ IF_LE(`vperm S0,S0,S0,swap_mask
  vxor S7,S7,K

  mtctr ROUNDS
- li 10,0x10
+ li r10,0x10
 .align 5
 L8x_round_loop:
- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm   K,K,K,swap_mask
  vcipher S0,S0,K
  vcipher S1,S1,K
@@ -134,10 +134,10 @@ L8x_round_loop:
  vcipher S5,S5,K
  vcipher S6,S6,K
  vcipher S7,S7,K
- addi 10,10,0x10
+ addi r10,r10,0x10
  bdnz L8x_round_loop

- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm   K,K,K,swap_mask
  vcipherlast S0,S0,K
  vcipherlast S1,S1,K
@@ -158,44 +158,44 @@ IF_LE(`vperm S0,S0,S0,swap_mask
  vperm S7,S7,S7,swap_mask')

  stxvd2x VSR(S0),0,DST
- stxvd2x VSR(S1),25,DST
- stxvd2x VSR(S2),26,DST
- stxvd2x VSR(S3),27,DST
- stxvd2x VSR(S4),28,DST
- stxvd2x VSR(S5),29,DST
- stxvd2x VSR(S6),30,DST
- stxvd2x VSR(S7),31,DST
+ stxvd2x VSR(S1),r25,DST
+ stxvd2x VSR(S2),r26,DST
+ stxvd2x VSR(S3),r27,DST
+ stxvd2x VSR(S4),r28,DST
+ stxvd2x VSR(S5),r29,DST
+ stxvd2x VSR(S6),r30,DST
+ stxvd2x VSR(S7),r31,DST

  addi SRC,SRC,0x80
  addi DST,DST,0x80
- subic. 5,5,1
+ subic. r5,r5,1
  bne Lx8_loop

- ld 25,-56(SP);
- ld 26,-48(SP);
- ld 27,-40(SP);
- ld 28,-32(SP);
- ld 29,-24(SP);
- ld 30,-16(SP);
- ld 31,-8(SP);
+ ld r25,-56(SP);
+ ld r26,-48(SP);
+ ld r27,-40(SP);
+ ld r28,-32(SP);
+ ld r29,-24(SP);
+ ld r30,-16(SP);
+ ld r31,-8(SP);

  clrldi LENGTH,LENGTH,61

 L4x:
- srdi   5,LENGTH,2
- cmpldi   5,0
+ srdi   r5,LENGTH,2
+ cmpldi   r5,0
  beq   L2x

  lxvd2x   VSR(K),0,KEYS
  vperm   K,K,K,swap_mask

  lxvd2x VSR(S0),0,SRC
- li  9,0x10
- lxvd2x VSR(S1),9,SRC
- addi   9,9,0x10
- lxvd2x VSR(S2),9,SRC
- addi   9,9,0x10
- lxvd2x VSR(S3),9,SRC
+ li  r9,0x10
+ lxvd2x VSR(S1),r9,SRC
+ addi   r9,r9,0x10
+ lxvd2x VSR(S2),r9,SRC
+ addi   r9,r9,0x10
+ lxvd2x VSR(S3),r9,SRC

 IF_LE(`vperm S0,S0,S0,swap_mask
  vperm S1,S1,S1,swap_mask
@@ -208,19 +208,19 @@ IF_LE(`vperm S0,S0,S0,swap_mask
  vxor S3,S3,K

  mtctr ROUNDS
- li 10,0x10
+ li r10,0x10
 .align 5
 L4x_round_loop:
- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm  K,K,K,swap_mask
  vcipher S0,S0,K
  vcipher S1,S1,K
  vcipher S2,S2,K
  vcipher S3,S3,K
- addi   10,10,0x10
+ addi   r10,r10,0x10
  bdnz  L4x_round_loop

- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm   K,K,K,swap_mask
  vcipherlast S0,S0,K
  vcipherlast S1,S1,K
@@ -233,12 +233,12 @@ IF_LE(`vperm S0,S0,S0,swap_mask
  vperm S3,S3,S3,swap_mask')

  stxvd2x VSR(S0),0,DST
- li  9,0x10
- stxvd2x VSR(S1),9,DST
- addi   9,9,0x10
- stxvd2x VSR(S2),9,DST
- addi  9,9,0x10
- stxvd2x VSR(S3),9,DST
+ li  r9,0x10
+ stxvd2x VSR(S1),r9,DST
+ addi   r9,r9,0x10
+ stxvd2x VSR(S2),r9,DST
+ addi  r9,r9,0x10
+ stxvd2x VSR(S3),r9,DST

  addi   SRC,SRC,0x40
  addi   DST,DST,0x40
@@ -246,16 +246,16 @@ IF_LE(`vperm S0,S0,S0,swap_mask
  clrldi LENGTH,LENGTH,62

 L2x:
- srdi  5,LENGTH,1
- cmpldi  5,0
+ srdi  r5,LENGTH,1
+ cmpldi  r5,0
  beq   L1x

  lxvd2x VSR(K),0,KEYS
  vperm K,K,K,swap_mask

  lxvd2x VSR(S0),0,SRC
- li   9,0x10
- lxvd2x VSR(S1),9,SRC
+ li   r9,0x10
+ lxvd2x VSR(S1),r9,SRC

 IF_LE(`vperm S0,S0,S0,swap_mask
  vperm S1,S1,S1,swap_mask')
@@ -264,17 +264,17 @@ IF_LE(`vperm S0,S0,S0,swap_mask
  vxor   S1,S1,K

  mtctr   ROUNDS
- li  10,0x10
+ li  r10,0x10
 .align 5
 L2x_round_loop:
- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm  K,K,K,swap_mask
  vcipher S0,S0,K
  vcipher S1,S1,K
- addi   10,10,0x10
+ addi   r10,r10,0x10
  bdnz   L2x_round_loop

- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm  K,K,K,swap_mask
  vcipherlast S0,S0,K
  vcipherlast S1,S1,K
@@ -283,8 +283,8 @@ IF_LE(`vperm S0,S0,S0,swap_mask
  vperm S1,S1,S1,swap_mask')

  stxvd2x VSR(S0),0,DST
- li  9,0x10
- stxvd2x VSR(S1),9,DST
+ li  r9,0x10
+ stxvd2x VSR(S1),r9,DST

  addi   SRC,SRC,0x20
  addi   DST,DST,0x20
@@ -305,16 +305,16 @@ IF_LE(`vperm S0,S0,S0,swap_mask')
  vxor   S0,S0,K

  mtctr   ROUNDS
- li   10,0x10
+ li   r10,0x10
 .align 5
 L1x_round_loop:
- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm  K,K,K,swap_mask
  vcipher S0,S0,K
- addi   10,10,0x10
+ addi   r10,r10,0x10
  bdnz   L1x_round_loop

- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm  K,K,K,swap_mask
  vcipherlast S0,S0,K


-- 
2.17.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200921103407</emailId><senderName>Jaak Ristioja</senderName><senderEmail>jaak.ristioja@cyber.ee</senderEmail><timestampReceived>2020-09-21 10:34:07-0400</timestampReceived><subject>Re: NAPLES standup</subject><body>

On esmaspäev, 21. september 2020 13:33:10 EEST Angela Sahk wrote:
&gt; Ma olen hetkel Zoomi VMRis...
&gt; 
&gt; &gt; On September 21, 2020 at 1:32 PM Angela Sahk &lt;angela.sahk@cyber.ee&gt; wrote:
&gt; &gt;     Hei,
&gt; &gt;     
&gt; &gt;     
&gt; &gt;     Kuna meie vahel Matrix ei toimi, siis kirjutan siia... kas sa liitud
&gt; &gt;     täna?
&gt; &gt;     
&gt; &gt;     
&gt; &gt;     Angela

Meanwhile in matrix:

[13:32:01] &lt;J&gt; hei! Naples-vormsi standup ikka toimub? ma ei näe VMR02-s 
kedagi
[13:33:19] &lt;J&gt; muidugi seal taskis on hoopis mingi muu pexipi link, mis annab 
HTTP 404: https://pexip.me/meet/53256948/

J


_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200919053229</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-09-19 05:32:29-0400</timestampReceived><subject>[PATCH] "PowerPC64" Use explicit register names</subject><body>

This patch is built upon ppc-m4-macrology.patch. Using explicit register
names is working as expected now.
---
 powerpc64/machine.m4                  |  11 +-
 powerpc64/p8/aes-decrypt-internal.asm | 194
+++++++++++++++++-----------------
 powerpc64/p8/aes-encrypt-internal.asm | 192
++++++++++++++++-----------------
 3 files changed, 200 insertions(+), 197 deletions(-)

diff --git a/powerpc64/machine.m4 b/powerpc64/machine.m4
index ae161d79..f867ec01 100644
--- a/powerpc64/machine.m4
+++ b/powerpc64/machine.m4
@@ -24,7 +24,10 @@ define(`EPILOGUE',

 C Get vector-scalar register from vector register
 C VSR(VR)
-define(`VSR',`32+$1')
+define(`VSR',`ifelse(ASM_PPC_WANT_R_REGISTERS,no,
+`eval(32+$1)',
+``vs'eval(32+substr($1,1,len($1)))'
+)')

 C Load the quadword in DATA_SRC storage into
 C VEC_DST. GPR is general-purpose register
@@ -32,19 +35,19 @@ C used to obtain the effective address of
 C DATA_SRC storage.
 C DATA_LOAD_VEC(VEC_DST, DATA_SRC, GPR)
 define(`DATA_LOAD_VEC',
-`ld $3,$2@got(2)
+`ld $3,$2@got(r2)
 lvx $1,0,$3')

 dnl  Usage: r0 ... r31, cr0 ... cr7
 dnl
 dnl  Registers names, either left as "r0" etc or mapped to plain 0 etc,
-dnl  according to the result of the GMP_ASM_POWERPC_REGISTERS configure
+dnl  according to the result of the ASM_PPC_WANT_R_REGISTERS configure
 dnl  test.

 ifelse(ASM_PPC_WANT_R_REGISTERS,no,`
 forloop(i,0,31,`deflit(`r'i,i)')
 forloop(i,0,31,`deflit(`v'i,i)')
+forloop(i,0,63,`deflit(`vs'i,i)')
 forloop(i,0,31,`deflit(`f'i,i)')
 forloop(i,0,7, `deflit(`cr'i,i)')
 ')
-
diff --git a/powerpc64/p8/aes-decrypt-internal.asm
b/powerpc64/p8/aes-decrypt-internal.asm
index acdbc1bd..7c79ffcb 100644
--- a/powerpc64/p8/aes-decrypt-internal.asm
+++ b/powerpc64/p8/aes-decrypt-internal.asm
@@ -31,32 +31,32 @@ ifelse(`

 C Register usage:

-define(`SP', `1')
-define(`TOCP', `2')
-
-define(`ROUNDS', `3')
-define(`KEYS', `4')
-define(`LENGTH', `6')
-define(`DST', `7')
-define(`SRC', `8')
-
-define(`swap_mask', `0')
-
-define(`K', `1')
-define(`S0', `2')
-define(`S1', `3')
-define(`S2', `4')
-define(`S3', `5')
-define(`S4', `6')
-define(`S5', `7')
-define(`S6', `8')
-define(`S7', `9')
+define(`SP', `r1')
+define(`TOCP', `r2')
+
+define(`ROUNDS', `r3')
+define(`KEYS', `r4')
+define(`LENGTH', `r6')
+define(`DST', `r7')
+define(`SRC', `r8')
+
+define(`swap_mask', `v0')
+
+define(`K', `v1')
+define(`S0', `v2')
+define(`S1', `v3')
+define(`S2', `v4')
+define(`S3', `v5')
+define(`S4', `v6')
+define(`S5', `v7')
+define(`S6', `v8')
+define(`S7', `v9')

 C ZERO vector register is used in place of RoundKey
 C for vncipher instruction because the order of InvMixColumns
 C and Xor processes are flipped in that instruction.
 C The Xor process with RoundKey is executed afterward.
-define(`ZERO', `10')
+define(`ZERO', `v10')

 .file "aes-decrypt-internal.asm"

@@ -71,30 +71,30 @@ define(`FUNC_ALIGN', `5')
 PROLOGUE(_nettle_aes_decrypt)
  vxor ZERO,ZERO,ZERO

- DATA_LOAD_VEC(swap_mask,.swap_mask,5)
+ DATA_LOAD_VEC(swap_mask,.swap_mask,r5)

  subi ROUNDS,ROUNDS,1
  srdi LENGTH,LENGTH,4

- srdi 5,LENGTH,3 #8x loop count
- cmpldi 5,0
+ srdi r5,LENGTH,3 #8x loop count
+ cmpldi r5,0
  beq L4x

- std 25,-56(SP);
- std 26,-48(SP);
- std 27,-40(SP);
- std 28,-32(SP);
- std 29,-24(SP);
- std 30,-16(SP);
- std 31,-8(SP);
-
- li 25,0x10
- li 26,0x20
- li 27,0x30
- li 28,0x40
- li 29,0x50
- li 30,0x60
- li 31,0x70
+ std r25,-56(SP);
+ std r26,-48(SP);
+ std r27,-40(SP);
+ std r28,-32(SP);
+ std r29,-24(SP);
+ std r30,-16(SP);
+ std r31,-8(SP);
+
+ li r25,0x10
+ li r26,0x20
+ li r27,0x30
+ li r28,0x40
+ li r29,0x50
+ li r30,0x60
+ li r31,0x70

 .align 5
 Lx8_loop:
@@ -102,13 +102,13 @@ Lx8_loop:
  vperm   K,K,K,swap_mask

  lxvd2x VSR(S0),0,SRC
- lxvd2x VSR(S1),25,SRC
- lxvd2x VSR(S2),26,SRC
- lxvd2x VSR(S3),27,SRC
- lxvd2x VSR(S4),28,SRC
- lxvd2x VSR(S5),29,SRC
- lxvd2x VSR(S6),30,SRC
- lxvd2x VSR(S7),31,SRC
+ lxvd2x VSR(S1),r25,SRC
+ lxvd2x VSR(S2),r26,SRC
+ lxvd2x VSR(S3),r27,SRC
+ lxvd2x VSR(S4),r28,SRC
+ lxvd2x VSR(S5),r29,SRC
+ lxvd2x VSR(S6),r30,SRC
+ lxvd2x VSR(S7),r31,SRC

 IF_LE(`vperm S0,S0,S0,swap_mask
  vperm S1,S1,S1,swap_mask
@@ -129,10 +129,10 @@ IF_LE(`vperm S0,S0,S0,swap_mask
  vxor S7,S7,K

  mtctr ROUNDS
- li 10,0x10
+ li r10,0x10
 .align 5
 L8x_round_loop:
- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm   K,K,K,swap_mask
  vncipher S0,S0,ZERO
  vncipher S1,S1,ZERO
@@ -150,10 +150,10 @@ L8x_round_loop:
  vxor S5,S5,K
  vxor S6,S6,K
  vxor S7,S7,K
- addi 10,10,0x10
+ addi r10,r10,0x10
  bdnz L8x_round_loop

- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm   K,K,K,swap_mask
  vncipherlast S0,S0,K
  vncipherlast S1,S1,K
@@ -174,44 +174,44 @@ IF_LE(`vperm S0,S0,S0,swap_mask
  vperm S7,S7,S7,swap_mask')

  stxvd2x VSR(S0),0,DST
- stxvd2x VSR(S1),25,DST
- stxvd2x VSR(S2),26,DST
- stxvd2x VSR(S3),27,DST
- stxvd2x VSR(S4),28,DST
- stxvd2x VSR(S5),29,DST
- stxvd2x VSR(S6),30,DST
- stxvd2x VSR(S7),31,DST
+ stxvd2x VSR(S1),r25,DST
+ stxvd2x VSR(S2),r26,DST
+ stxvd2x VSR(S3),r27,DST
+ stxvd2x VSR(S4),r28,DST
+ stxvd2x VSR(S5),r29,DST
+ stxvd2x VSR(S6),r30,DST
+ stxvd2x VSR(S7),r31,DST

  addi SRC,SRC,0x80
  addi DST,DST,0x80
- subic. 5,5,1
+ subic. r5,r5,1
  bne Lx8_loop

- ld 25,-56(SP);
- ld 26,-48(SP);
- ld 27,-40(SP);
- ld 28,-32(SP);
- ld 29,-24(SP);
- ld 30,-16(SP);
- ld 31,-8(SP);
+ ld r25,-56(SP);
+ ld r26,-48(SP);
+ ld r27,-40(SP);
+ ld r28,-32(SP);
+ ld r29,-24(SP);
+ ld r30,-16(SP);
+ ld r31,-8(SP);

  clrldi LENGTH,LENGTH,61

 L4x:
- srdi   5,LENGTH,2
- cmpldi   5,0
+ srdi   r5,LENGTH,2
+ cmpldi   r5,0
  beq   L2x

  lxvd2x   VSR(K),0,KEYS
  vperm   K,K,K,swap_mask

  lxvd2x VSR(S0),0,SRC
- li  9,0x10
- lxvd2x VSR(S1),9,SRC
- addi   9,9,0x10
- lxvd2x VSR(S2),9,SRC
- addi   9,9,0x10
- lxvd2x VSR(S3),9,SRC
+ li  r9,0x10
+ lxvd2x VSR(S1),r9,SRC
+ addi   r9,r9,0x10
+ lxvd2x VSR(S2),r9,SRC
+ addi   r9,r9,0x10
+ lxvd2x VSR(S3),r9,SRC

 IF_LE(`vperm S0,S0,S0,swap_mask
  vperm S1,S1,S1,swap_mask
@@ -224,10 +224,10 @@ IF_LE(`vperm S0,S0,S0,swap_mask
  vxor S3,S3,K

  mtctr ROUNDS
- li 10,0x10
+ li r10,0x10
 .align 5
 L4x_round_loop:
- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm  K,K,K,swap_mask
  vncipher S0,S0,ZERO
  vncipher S1,S1,ZERO
@@ -237,10 +237,10 @@ L4x_round_loop:
  vxor  S1,S1,K
  vxor   S2,S2,K
  vxor   S3,S3,K
- addi   10,10,0x10
+ addi   r10,r10,0x10
  bdnz  L4x_round_loop

- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm   K,K,K,swap_mask
  vncipherlast S0,S0,K
  vncipherlast S1,S1,K
@@ -253,12 +253,12 @@ IF_LE(`vperm S0,S0,S0,swap_mask
  vperm S3,S3,S3,swap_mask')

  stxvd2x VSR(S0),0,DST
- li  9,0x10
- stxvd2x VSR(S1),9,DST
- addi   9,9,0x10
- stxvd2x VSR(S2),9,DST
- addi  9,9,0x10
- stxvd2x VSR(S3),9,DST
+ li  r9,0x10
+ stxvd2x VSR(S1),r9,DST
+ addi   r9,r9,0x10
+ stxvd2x VSR(S2),r9,DST
+ addi  r9,r9,0x10
+ stxvd2x VSR(S3),r9,DST

  addi   SRC,SRC,0x40
  addi   DST,DST,0x40
@@ -266,16 +266,16 @@ IF_LE(`vperm S0,S0,S0,swap_mask
  clrldi LENGTH,LENGTH,62

 L2x:
- srdi  5,LENGTH,1
- cmpldi  5,0
+ srdi  r5,LENGTH,1
+ cmpldi  r5,0
  beq   L1x

  lxvd2x VSR(K),0,KEYS
  vperm K,K,K,swap_mask

  lxvd2x VSR(S0),0,SRC
- li   9,0x10
- lxvd2x VSR(S1),9,SRC
+ li   r9,0x10
+ lxvd2x VSR(S1),r9,SRC

 IF_LE(`vperm S0,S0,S0,swap_mask
  vperm S1,S1,S1,swap_mask')
@@ -284,19 +284,19 @@ IF_LE(`vperm S0,S0,S0,swap_mask
  vxor   S1,S1,K

  mtctr   ROUNDS
- li  10,0x10
+ li  r10,0x10
 .align 5
 L2x_round_loop:
- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm  K,K,K,swap_mask
  vncipher S0,S0,ZERO
  vncipher S1,S1,ZERO
  vxor  S0,S0,K
  vxor  S1,S1,K
- addi   10,10,0x10
+ addi   r10,r10,0x10
  bdnz   L2x_round_loop

- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm  K,K,K,swap_mask
  vncipherlast S0,S0,K
  vncipherlast S1,S1,K
@@ -305,8 +305,8 @@ IF_LE(`vperm S0,S0,S0,swap_mask
  vperm S1,S1,S1,swap_mask')

  stxvd2x VSR(S0),0,DST
- li  9,0x10
- stxvd2x VSR(S1),9,DST
+ li  r9,0x10
+ stxvd2x VSR(S1),r9,DST

  addi   SRC,SRC,0x20
  addi   DST,DST,0x20
@@ -327,17 +327,17 @@ IF_LE(`vperm S0,S0,S0,swap_mask')
  vxor   S0,S0,K

  mtctr   ROUNDS
- li   10,0x10
+ li   r10,0x10
 .align 5
 L1x_round_loop:
- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm  K,K,K,swap_mask
  vncipher S0,S0,ZERO
  vxor   S0,S0,K
- addi   10,10,0x10
+ addi   r10,r10,0x10
  bdnz   L1x_round_loop

- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm  K,K,K,swap_mask
  vncipherlast S0,S0,K

diff --git a/powerpc64/p8/aes-encrypt-internal.asm
b/powerpc64/p8/aes-encrypt-internal.asm
index 482dff25..3dd6e7b5 100644
--- a/powerpc64/p8/aes-encrypt-internal.asm
+++ b/powerpc64/p8/aes-encrypt-internal.asm
@@ -31,26 +31,26 @@ ifelse(`

 C Register usage:

-define(`SP', `1')
-define(`TOCP', `2')
-
-define(`ROUNDS', `3')
-define(`KEYS', `4')
-define(`LENGTH', `6')
-define(`DST', `7')
-define(`SRC', `8')
-
-define(`swap_mask', `0')
-
-define(`K', `1')
-define(`S0', `2')
-define(`S1', `3')
-define(`S2', `4')
-define(`S3', `5')
-define(`S4', `6')
-define(`S5', `7')
-define(`S6', `8')
-define(`S7', `9')
+define(`SP', `r1')
+define(`TOCP', `r2')
+
+define(`ROUNDS', `r3')
+define(`KEYS', `r4')
+define(`LENGTH', `r6')
+define(`DST', `r7')
+define(`SRC', `r8')
+
+define(`swap_mask', `v0')
+
+define(`K', `v1')
+define(`S0', `v2')
+define(`S1', `v3')
+define(`S2', `v4')
+define(`S3', `v5')
+define(`S4', `v6')
+define(`S5', `v7')
+define(`S6', `v8')
+define(`S7', `v9')

 .file "aes-encrypt-internal.asm"

@@ -63,30 +63,30 @@ define(`S7', `9')

 define(`FUNC_ALIGN', `5')
 PROLOGUE(_nettle_aes_encrypt)
- DATA_LOAD_VEC(swap_mask,.swap_mask,5)
+ DATA_LOAD_VEC(swap_mask,.swap_mask,r5)

  subi ROUNDS,ROUNDS,1
  srdi LENGTH,LENGTH,4

- srdi 5,LENGTH,3 #8x loop count
- cmpldi 5,0
+ srdi r5,LENGTH,3 #8x loop count
+ cmpldi r5,0
  beq L4x

- std 25,-56(SP);
- std 26,-48(SP);
- std 27,-40(SP);
- std 28,-32(SP);
- std 29,-24(SP);
- std 30,-16(SP);
- std 31,-8(SP);
-
- li 25,0x10
- li 26,0x20
- li 27,0x30
- li 28,0x40
- li 29,0x50
- li 30,0x60
- li 31,0x70
+ std r25,-56(SP);
+ std r26,-48(SP);
+ std r27,-40(SP);
+ std r28,-32(SP);
+ std r29,-24(SP);
+ std r30,-16(SP);
+ std r31,-8(SP);
+
+ li r25,0x10
+ li r26,0x20
+ li r27,0x30
+ li r28,0x40
+ li r29,0x50
+ li r30,0x60
+ li r31,0x70

 .align 5
 Lx8_loop:
@@ -94,13 +94,13 @@ Lx8_loop:
  vperm   K,K,K,swap_mask

  lxvd2x VSR(S0),0,SRC
- lxvd2x VSR(S1),25,SRC
- lxvd2x VSR(S2),26,SRC
- lxvd2x VSR(S3),27,SRC
- lxvd2x VSR(S4),28,SRC
- lxvd2x VSR(S5),29,SRC
- lxvd2x VSR(S6),30,SRC
- lxvd2x VSR(S7),31,SRC
+ lxvd2x VSR(S1),r25,SRC
+ lxvd2x VSR(S2),r26,SRC
+ lxvd2x VSR(S3),r27,SRC
+ lxvd2x VSR(S4),r28,SRC
+ lxvd2x VSR(S5),r29,SRC
+ lxvd2x VSR(S6),r30,SRC
+ lxvd2x VSR(S7),r31,SRC

 IF_LE(`vperm S0,S0,S0,swap_mask
  vperm S1,S1,S1,swap_mask
@@ -121,10 +121,10 @@ IF_LE(`vperm S0,S0,S0,swap_mask
  vxor S7,S7,K

  mtctr ROUNDS
- li 10,0x10
+ li r10,0x10
 .align 5
 L8x_round_loop:
- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm   K,K,K,swap_mask
  vcipher S0,S0,K
  vcipher S1,S1,K
@@ -134,10 +134,10 @@ L8x_round_loop:
  vcipher S5,S5,K
  vcipher S6,S6,K
  vcipher S7,S7,K
- addi 10,10,0x10
+ addi r10,r10,0x10
  bdnz L8x_round_loop

- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm   K,K,K,swap_mask
  vcipherlast S0,S0,K
  vcipherlast S1,S1,K
@@ -158,44 +158,44 @@ IF_LE(`vperm S0,S0,S0,swap_mask
  vperm S7,S7,S7,swap_mask')

  stxvd2x VSR(S0),0,DST
- stxvd2x VSR(S1),25,DST
- stxvd2x VSR(S2),26,DST
- stxvd2x VSR(S3),27,DST
- stxvd2x VSR(S4),28,DST
- stxvd2x VSR(S5),29,DST
- stxvd2x VSR(S6),30,DST
- stxvd2x VSR(S7),31,DST
+ stxvd2x VSR(S1),r25,DST
+ stxvd2x VSR(S2),r26,DST
+ stxvd2x VSR(S3),r27,DST
+ stxvd2x VSR(S4),r28,DST
+ stxvd2x VSR(S5),r29,DST
+ stxvd2x VSR(S6),r30,DST
+ stxvd2x VSR(S7),r31,DST

  addi SRC,SRC,0x80
  addi DST,DST,0x80
- subic. 5,5,1
+ subic. r5,r5,1
  bne Lx8_loop

- ld 25,-56(SP);
- ld 26,-48(SP);
- ld 27,-40(SP);
- ld 28,-32(SP);
- ld 29,-24(SP);
- ld 30,-16(SP);
- ld 31,-8(SP);
+ ld r25,-56(SP);
+ ld r26,-48(SP);
+ ld r27,-40(SP);
+ ld r28,-32(SP);
+ ld r29,-24(SP);
+ ld r30,-16(SP);
+ ld r31,-8(SP);

  clrldi LENGTH,LENGTH,61

 L4x:
- srdi   5,LENGTH,2
- cmpldi   5,0
+ srdi   r5,LENGTH,2
+ cmpldi   r5,0
  beq   L2x

  lxvd2x   VSR(K),0,KEYS
  vperm   K,K,K,swap_mask

  lxvd2x VSR(S0),0,SRC
- li  9,0x10
- lxvd2x VSR(S1),9,SRC
- addi   9,9,0x10
- lxvd2x VSR(S2),9,SRC
- addi   9,9,0x10
- lxvd2x VSR(S3),9,SRC
+ li  r9,0x10
+ lxvd2x VSR(S1),r9,SRC
+ addi   r9,r9,0x10
+ lxvd2x VSR(S2),r9,SRC
+ addi   r9,r9,0x10
+ lxvd2x VSR(S3),r9,SRC

 IF_LE(`vperm S0,S0,S0,swap_mask
  vperm S1,S1,S1,swap_mask
@@ -208,19 +208,19 @@ IF_LE(`vperm S0,S0,S0,swap_mask
  vxor S3,S3,K

  mtctr ROUNDS
- li 10,0x10
+ li r10,0x10
 .align 5
 L4x_round_loop:
- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm  K,K,K,swap_mask
  vcipher S0,S0,K
  vcipher S1,S1,K
  vcipher S2,S2,K
  vcipher S3,S3,K
- addi   10,10,0x10
+ addi   r10,r10,0x10
  bdnz  L4x_round_loop

- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm   K,K,K,swap_mask
  vcipherlast S0,S0,K
  vcipherlast S1,S1,K
@@ -233,12 +233,12 @@ IF_LE(`vperm S0,S0,S0,swap_mask
  vperm S3,S3,S3,swap_mask')

  stxvd2x VSR(S0),0,DST
- li  9,0x10
- stxvd2x VSR(S1),9,DST
- addi   9,9,0x10
- stxvd2x VSR(S2),9,DST
- addi  9,9,0x10
- stxvd2x VSR(S3),9,DST
+ li  r9,0x10
+ stxvd2x VSR(S1),r9,DST
+ addi   r9,r9,0x10
+ stxvd2x VSR(S2),r9,DST
+ addi  r9,r9,0x10
+ stxvd2x VSR(S3),r9,DST

  addi   SRC,SRC,0x40
  addi   DST,DST,0x40
@@ -246,16 +246,16 @@ IF_LE(`vperm S0,S0,S0,swap_mask
  clrldi LENGTH,LENGTH,62

 L2x:
- srdi  5,LENGTH,1
- cmpldi  5,0
+ srdi  r5,LENGTH,1
+ cmpldi  r5,0
  beq   L1x

  lxvd2x VSR(K),0,KEYS
  vperm K,K,K,swap_mask

  lxvd2x VSR(S0),0,SRC
- li   9,0x10
- lxvd2x VSR(S1),9,SRC
+ li   r9,0x10
+ lxvd2x VSR(S1),r9,SRC

 IF_LE(`vperm S0,S0,S0,swap_mask
  vperm S1,S1,S1,swap_mask')
@@ -264,17 +264,17 @@ IF_LE(`vperm S0,S0,S0,swap_mask
  vxor   S1,S1,K

  mtctr   ROUNDS
- li  10,0x10
+ li  r10,0x10
 .align 5
 L2x_round_loop:
- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm  K,K,K,swap_mask
  vcipher S0,S0,K
  vcipher S1,S1,K
- addi   10,10,0x10
+ addi   r10,r10,0x10
  bdnz   L2x_round_loop

- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm  K,K,K,swap_mask
  vcipherlast S0,S0,K
  vcipherlast S1,S1,K
@@ -283,8 +283,8 @@ IF_LE(`vperm S0,S0,S0,swap_mask
  vperm S1,S1,S1,swap_mask')

  stxvd2x VSR(S0),0,DST
- li  9,0x10
- stxvd2x VSR(S1),9,DST
+ li  r9,0x10
+ stxvd2x VSR(S1),r9,DST

  addi   SRC,SRC,0x20
  addi   DST,DST,0x20
@@ -305,16 +305,16 @@ IF_LE(`vperm S0,S0,S0,swap_mask')
  vxor   S0,S0,K

  mtctr   ROUNDS
- li   10,0x10
+ li   r10,0x10
 .align 5
 L1x_round_loop:
- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm  K,K,K,swap_mask
  vcipher S0,S0,K
- addi   10,10,0x10
+ addi   r10,r10,0x10
  bdnz   L1x_round_loop

- lxvd2x VSR(K),10,KEYS
+ lxvd2x VSR(K),r10,KEYS
  vperm  K,K,K,swap_mask
  vcipherlast S0,S0,K


-- 
2.17.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200924182343</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-09-24 18:23:43-0400</timestampReceived><subject>[PATCH] "PowerPC64" GCM support</subject><body>

This is a stand-alone patch that applies all the previous patches to the
optimized GCM implementation. This patch is based on the master upstream so
it can be merged directly.
It passes the testsuite and yields the expected performance.
---
 configure.ac               |   5 +-
 fat-ppc.c                  |  44 +++
 fat-setup.h                |   9 +
 gcm.c                      |  82 +++-
 powerpc64/README           |   2 +-
 powerpc64/fat/gcm-hash.asm |  40 ++
 powerpc64/p8/gcm-hash.asm  | 956
+++++++++++++++++++++++++++++++++++++++++++++
 7 files changed, 1121 insertions(+), 17 deletions(-)
 create mode 100644 powerpc64/fat/gcm-hash.asm
 create mode 100644 powerpc64/p8/gcm-hash.asm

diff --git a/configure.ac b/configure.ac
index e9983697..13cfe33a 100644
--- a/configure.ac
+++ b/configure.ac
@@ -488,7 +488,7 @@ asm_replace_list="aes-encrypt-internal.asm
aes-decrypt-internal.asm \
  sha3-permute.asm umac-nh.asm umac-nh-n.asm machine.m4"

 # Assembler files which generate additional object files if they are used.
-asm_nettle_optional_list="gcm-hash8.asm cpuid.asm \
+asm_nettle_optional_list="gcm-hash.asm gcm-hash8.asm cpuid.asm \
   aes-encrypt-internal-2.asm aes-decrypt-internal-2.asm memxor-2.asm \
   chacha-3core.asm chacha-core-internal-2.asm salsa20-2core.asm \
   salsa20-core-internal-2.asm sha1-compress-2.asm sha256-compress-2.asm \
@@ -612,7 +612,8 @@ AH_VERBATIM([HAVE_NATIVE],
 #undef HAVE_NATIVE_ecc_secp384r1_redc
 #undef HAVE_NATIVE_ecc_secp521r1_modp
 #undef HAVE_NATIVE_ecc_secp521r1_redc
-#undef HAVE_NATIVE_gcm_init_key8
+#undef HAVE_NATIVE_gcm_init_key
+#undef HAVE_NATIVE_gcm_hash
 #undef HAVE_NATIVE_gcm_hash8
 #undef HAVE_NATIVE_gcm_fill
 #undef HAVE_NATIVE_salsa20_core
diff --git a/fat-ppc.c b/fat-ppc.c
index 2bc50481..e69dff95 100644
--- a/fat-ppc.c
+++ b/fat-ppc.c
@@ -120,6 +120,20 @@ DECLARE_FAT_FUNC(_nettle_aes_decrypt,
aes_crypt_internal_func)
 DECLARE_FAT_FUNC_VAR(aes_decrypt, aes_crypt_internal_func, c)
 DECLARE_FAT_FUNC_VAR(aes_decrypt, aes_crypt_internal_func, ppc64)

+#if GCM_TABLE_BITS == 8
+DECLARE_FAT_FUNC(_nettle_gcm_init_key, gcm_init_key_func)
+DECLARE_FAT_FUNC_VAR(gcm_init_key, gcm_init_key_func, c)
+DECLARE_FAT_FUNC_VAR(gcm_init_key, gcm_init_key_func, ppc64)
+
+DECLARE_FAT_FUNC(_nettle_gcm_hash, gcm_hash_func)
+DECLARE_FAT_FUNC_VAR(gcm_hash, gcm_hash_func, c)
+DECLARE_FAT_FUNC_VAR(gcm_hash, gcm_hash_func, ppc64)
+#endif /* GCM_TABLE_BITS == 8 */
+
+DECLARE_FAT_FUNC(_nettle_gcm_fill, gcm_fill_func)
+DECLARE_FAT_FUNC_VAR(gcm_fill, gcm_fill_func, c)
+DECLARE_FAT_FUNC_VAR(gcm_fill, gcm_fill_func, ppc64)
+
 static void CONSTRUCTOR
 fat_init (void)
 {
@@ -139,11 +153,25 @@ fat_init (void)
  fprintf (stderr, "libnettle: enabling arch 2.07 code.\n");
       _nettle_aes_encrypt_vec = _nettle_aes_encrypt_ppc64;
       _nettle_aes_decrypt_vec = _nettle_aes_decrypt_ppc64;
+#if GCM_TABLE_BITS == 8
+     /* Make sure _nettle_gcm_init_key_vec function is compatible
+        with _nettle_gcm_hash_vec function e.g. _nettle_gcm_init_key_c()
+        fills gcm_key table with values that are incompatible with
+        _nettle_gcm_hash_ppc64() */
+     _nettle_gcm_init_key_vec = _nettle_gcm_init_key_ppc64;
+     _nettle_gcm_hash_vec = _nettle_gcm_hash_ppc64;
+#endif /* GCM_TABLE_BITS == 8 */
+     _nettle_gcm_fill_vec = _nettle_gcm_fill_ppc64;
     }
   else
     {
       _nettle_aes_encrypt_vec = _nettle_aes_encrypt_c;
       _nettle_aes_decrypt_vec = _nettle_aes_decrypt_c;
+#if GCM_TABLE_BITS == 8
+     _nettle_gcm_init_key_vec = _nettle_gcm_init_key_c;
+     _nettle_gcm_hash_vec = _nettle_gcm_hash_c;
+#endif /* GCM_TABLE_BITS == 8 */
+     _nettle_gcm_fill_vec = _nettle_gcm_fill_c;
     }
 }

@@ -160,3 +188,19 @@ DEFINE_FAT_FUNC(_nettle_aes_decrypt, void,
  size_t length, uint8_t *dst,
  const uint8_t *src),
  (rounds, keys, T, length, dst, src))
+
+ #if GCM_TABLE_BITS == 8
+DEFINE_FAT_FUNC(_nettle_gcm_init_key, void,
+ (union nettle_block16 *table),
+ (table))
+
+DEFINE_FAT_FUNC(_nettle_gcm_hash, void,
+ (const struct gcm_key *key, union nettle_block16 *x,
+ size_t length, const uint8_t *data),
+ (key, x, length, data))
+#endif /* GCM_TABLE_BITS == 8 */
+
+DEFINE_FAT_FUNC(_nettle_gcm_fill, void,
+ (uint8_t *ctr, size_t blocks,
+ union nettle_block16 *buffer),
+ (ctr, blocks, buffer))
diff --git a/fat-setup.h b/fat-setup.h
index 99f1ea67..623f9579 100644
--- a/fat-setup.h
+++ b/fat-setup.h
@@ -162,6 +162,15 @@ typedef void aes_crypt_internal_func (unsigned rounds,
const uint32_t *keys,
       size_t length, uint8_t *dst,
       const uint8_t *src);

+#if GCM_TABLE_BITS == 8
+typedef void gcm_init_key_func (union nettle_block16 *table);
+
+typedef void gcm_hash_func (const struct gcm_key *key, union
nettle_block16 *x,
+      size_t length, const uint8_t *data);
+#endif /* GCM_TABLE_BITS == 8 */
+
+typedef void gcm_fill_func (uint8_t *ctr, size_t blocks, union
nettle_block16 *buffer);
+
 typedef void *(memxor_func)(void *dst, const void *src, size_t n);

 typedef void salsa20_core_func (uint32_t *dst, const uint32_t *src,
unsigned rounds);
diff --git a/gcm.c b/gcm.c
index cf615daf..935d4420 100644
--- a/gcm.c
+++ b/gcm.c
@@ -140,6 +140,26 @@ gcm_gf_mul (union nettle_block16 *x, const union
nettle_block16 *table)
   memcpy (x-&gt;b, Z.b, sizeof(Z));
 }
 # elif GCM_TABLE_BITS == 8
+#  if HAVE_NATIVE_gcm_init_key
+
+#define gcm_init_key _nettle_gcm_init_key
+void
+_nettle_gcm_init_key (union nettle_block16 *table);
+/* For fat builds */
+void
+_nettle_gcm_init_key_c (union nettle_block16 *table);
+#  endif /* HAVE_NATIVE_gcm_init_key */
+#  if HAVE_NATIVE_gcm_hash
+
+#define gcm_hash _nettle_gcm_hash
+void
+_nettle_gcm_hash (const struct gcm_key *key, union nettle_block16 *x,
+   size_t length, const uint8_t *data);
+/* For fat builds */
+void
+_nettle_gcm_hash_c (const struct gcm_key *key, union nettle_block16 *x,
+   size_t length, const uint8_t *data);
+#  endif /* HAVE_NATIVE_gcm_hash */
 #  if HAVE_NATIVE_gcm_hash8

 #define gcm_hash _nettle_gcm_hash8
@@ -225,9 +245,45 @@ gcm_gf_mul (union nettle_block16 *x, const union
nettle_block16 *table)

 #endif /* GCM_TABLE_BITS */

+#if HAVE_NATIVE_gcm_fill
+
+#define gcm_fill _nettle_gcm_fill
+void
+_nettle_gcm_fill (uint8_t *ctr, size_t blocks, union nettle_block16
*buffer);
+/* For fat builds */
+void
+_nettle_gcm_fill_c (uint8_t *ctr, size_t blocks, union nettle_block16
*buffer);
+#endif /* HAVE_NATIVE_gcm_fill */
+
 /* Increment the rightmost 32 bits. */
 #define INC32(block) INCREMENT(4, (block.b) + GCM_BLOCK_SIZE - 4)

+#ifdef gcm_init_key
+void
+_nettle_gcm_init_key_c(union nettle_block16 *table)
+#else
+static void
+gcm_init_key(union nettle_block16 *table)
+#endif /* !gcm_init_key */
+{
+#if GCM_TABLE_BITS
+  /* Middle element if GCM_TABLE_BITS &gt; 0, otherwise the first
+     element */
+  unsigned i = (1&lt;&lt;GCM_TABLE_BITS)/2;
+
+  /* Algorithm 3 from the gcm paper. First do powers of two, then do
+     the rest by adding. */
+  while (i /= 2)
+    block16_mulx_ghash(&amp;table[i], &amp;table[2*i]);
+  for (i = 2; i &lt; 1&lt;&lt;GCM_TABLE_BITS; i *= 2)
+    {
+      unsigned j;
+      for (j = 1; j &lt; i; j++)
+ block16_xor3(&amp;table[i+j], &amp;table[i], &amp;table[j]);
+    }
+#endif
+}
+
 /* Initialization of GCM.
  * @ctx: The context of GCM
  * @cipher: The context of the underlying block cipher
@@ -245,24 +301,18 @@ gcm_set_key(struct gcm_key *key,
   memset(key-&gt;h[0].b, 0, GCM_BLOCK_SIZE);
   f (cipher, GCM_BLOCK_SIZE, key-&gt;h[i].b, key-&gt;h[0].b);

-#if GCM_TABLE_BITS
-  /* Algorithm 3 from the gcm paper. First do powers of two, then do
-     the rest by adding. */
-  while (i /= 2)
-    block16_mulx_ghash(&amp;key-&gt;h[i], &amp;key-&gt;h[2*i]);
-  for (i = 2; i &lt; 1&lt;&lt;GCM_TABLE_BITS; i *= 2)
-    {
-      unsigned j;
-      for (j = 1; j &lt; i; j++)
- block16_xor3(&amp;key-&gt;h[i+j], &amp;key-&gt;h[i],&amp;key-&gt;h[j]);
-    }
-#endif
+  gcm_init_key(key-&gt;h);
 }

-#ifndef gcm_hash
+#ifdef gcm_hash
+void
+_nettle_gcm_hash_c(const struct gcm_key *key, union nettle_block16 *x,
+ size_t length, const uint8_t *data)
+#else
 static void
 gcm_hash(const struct gcm_key *key, union nettle_block16 *x,
  size_t length, const uint8_t *data)
+#endif /* !gcm_hash */
 {
   for (; length &gt;= GCM_BLOCK_SIZE;
        length -= GCM_BLOCK_SIZE, data += GCM_BLOCK_SIZE)
@@ -276,7 +326,6 @@ gcm_hash(const struct gcm_key *key, union
nettle_block16 *x,
       gcm_gf_mul (x, key-&gt;h);
     }
 }
-#endif /* !gcm_hash */

 static void
 gcm_hash_sizes(const struct gcm_key *key, union nettle_block16 *x,
@@ -333,9 +382,14 @@ gcm_update(struct gcm_ctx *ctx, const struct gcm_key
*key,
   ctx-&gt;auth_size += length;
 }

+#ifdef gcm_fill
+void
+_nettle_gcm_fill_c(uint8_t *ctr, size_t blocks, union nettle_block16
*buffer)
+#else
 static nettle_fill16_func gcm_fill;
 static void
 gcm_fill(uint8_t *ctr, size_t blocks, union nettle_block16 *buffer)
+#endif /* !gcm_fill */
 {
   uint32_t c;

diff --git a/powerpc64/README b/powerpc64/README
index 7301953b..fac1108b 100644
--- a/powerpc64/README
+++ b/powerpc64/README
@@ -52,7 +52,7 @@ storage operands, refer to "6.4.1 Accessing Unaligned
Storage Operands"
 in [3] to see an example of accessing unaligned storage operands.
 "lxvd2x/stxvd2x" can be used to load/store data into unaligned storage
 operands but permuting is needed for loading and storing data in
-little-endian mode VSX registers are defined with "X" suffix
+little-endian mode

 Function Prologue

diff --git a/powerpc64/fat/gcm-hash.asm b/powerpc64/fat/gcm-hash.asm
new file mode 100644
index 00000000..2d9f281e
--- /dev/null
+++ b/powerpc64/fat/gcm-hash.asm
@@ -0,0 +1,40 @@
+C powerpc64/fat/gcm-hash.asm
+
+
+ifelse(`
+   Copyright (C) 2020 Mamone Tarsha
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+')
+
+dnl picked up by configure
+dnl PROLOGUE(_nettle_gcm_init_key)
+dnl PROLOGUE(_nettle_gcm_hash)
+dnl PROLOGUE(_nettle_gcm_fill)
+
+define(`fat_transform', `$1_ppc64')
+include_src(`powerpc64/p8/gcm-hash.asm')
diff --git a/powerpc64/p8/gcm-hash.asm b/powerpc64/p8/gcm-hash.asm
new file mode 100644
index 00000000..f57cbfe4
--- /dev/null
+++ b/powerpc64/p8/gcm-hash.asm
@@ -0,0 +1,956 @@
+C powerpc64/p8/gcm-hash.asm
+
+ifelse(`
+   Copyright (C) 2020 Mamone Tarsha
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+')
+
+C Alignment of gcm_key table elements, which is declared in gcm.h
+define(`TableElemAlign', `0x100')
+
+C Register usage:
+
+define(`SP', `r1')
+define(`TOCP', `r2')
+
+define(`TABLE', `r3')
+define(`X', `r4')
+define(`LENGTH', `r5')
+define(`DATA', `r6')
+
+define(`zero', `v0')
+define(`swap_mask', `v1')
+define(`hidw_mask', `v2')
+define(`lodw_mask', `v3')
+define(`poly', `v4')
+define(`poly_h', `v4')
+define(`poly_l', `v5')
+define(`RP', `v6')
+define(`Mh', `v7')
+define(`Ml', `v8')
+define(`H', `v9')
+define(`Hh', `v10')
+define(`Hl', `v11')
+define(`RP2', `v9')
+define(`M2h', `v10')
+define(`M2l', `v11')
+
+define(`sl1', `v1')
+define(`msb', `v5')
+define(`H2', `v6')
+define(`H2h', `v7')
+define(`H2l', `v8')
+define(`H_h', `v12')
+define(`H_m', `v13')
+define(`H_l', `v14')
+define(`H_Hh', `v12')
+define(`H_H', `v13')
+define(`H_Hl', `v14')
+define(`H_t', `v15')
+define(`H2_h', `v16')
+define(`H2_m', `v17')
+define(`H2_l', `v18')
+define(`H2_t', `v19')
+
+define(`C0', `v6')
+define(`C1', `v7')
+define(`C2', `v8')
+define(`C3', `v12')
+define(`C4', `v6')
+define(`C5', `v7')
+define(`C6', `v8')
+define(`C7', `v12')
+
+define(`C', `v13')
+
+define(`Ch', `v14')
+define(`Cl', `v15')
+define(`Cm', `v16')
+
+define(`C01h', `v14')
+define(`C01l', `v15')
+define(`C01', `v16')
+define(`C23h', `v17')
+define(`C23l', `v18')
+define(`C23', `v19')
+define(`C45h', `v20')
+define(`C45l', `v21')
+define(`C45', `v22')
+define(`C67h', `v6')
+define(`C67l', `v7')
+define(`C67', `v8')
+
+define(`H21', `v9')
+define(`H21h', `v10')
+define(`H21l', `v11')
+define(`H43', `v23')
+define(`H43h', `v24')
+define(`H43l', `v25')
+define(`H65', `v26')
+define(`H65h', `v27')
+define(`H65l', `v28')
+define(`H87', `v29')
+define(`H87h', `v30')
+define(`H87l', `v31')
+
+# gcm_fill registers:
+
+define(`CTR', `r3')
+define(`BLOCKS', `r4')
+define(`BUFFER', `r5')
+
+define(`CTR0', `v2')
+define(`CTR0S', `v3')
+define(`CTR1', `v4')
+define(`CTR2', `v5')
+define(`CTR3', `v6')
+define(`CTR4', `v7')
+define(`CTR5', `v8')
+define(`CTR6', `v9')
+define(`CTR7', `v10')
+
+define(`I1', `v11')
+define(`I2', `v12')
+define(`I3', `v13')
+define(`I4', `v14')
+define(`I5', `v15')
+define(`I6', `v16')
+define(`I7', `v17')
+define(`I8', `v18')
+
+.file "gcm-hash.asm"
+
+.text
+
+ # void gcm_init_key (union gcm_block *table)
+
+define(`FUNC_ALIGN', `5')
+PROLOGUE(_nettle_gcm_init_key)
+ DATA_LOAD_VEC(poly,.polynomial,r7)
+IF_LE(`DATA_LOAD_VEC(swap_mask,.swap_mask,r7)')
+ DATA_LOAD_VEC(hidw_mask,.hidw_mask,r7)
+ DATA_LOAD_VEC(lodw_mask,.lodw_mask,r7)
+
+ li    r10,8*TableElemAlign
+ lxvd2x VSR(H),r10,TABLE # load H
+IF_LE(`vperm H,H,H,swap_mask')
+
+ # --- calculate H = H shift left 1 modulo polynomial ---
+
+ vupkhsw    msb,H # most significant bit word-extend
+ vspltisb sl1,1 # splat 1 for shift left
+ vspltw      msb,msb,0 # most significant bit extend
+ vsl    H,H,sl1 # H shift left 1
+ vand msb,msb,poly
+ vxor zero,zero,zero
+ vxor H_t,H,msb
+
+ vsldoi H,H_t,H_t,8 # doubleword swap
+ vsldoi Hh,H,zero,8
+ vsldoi Hl,zero,H,8
+
+ # --- calculate H^2 = H*H ---
+
+ # reduction pre-processing
+ vsldoi poly_h,zero,poly,8
+ vsldoi poly_l,poly_h,poly_h,8
+
+ # polynomial multiplication "classical"
+ vpmsumd H_h,H_t,Hh # H^1h*H^1h
+ vpmsumd H_l,H_t,Hl # H^1l*H^1l
+ vpmsumd H_m,H_t,H # H^1h*H^1l⊕H^1l*H^1h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h   # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8   # [2]
+ vsldoi Ml,H_m,zero,8 # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor H_h,H_h,Mh       # [2]
+ vxor H_l,H_l,Ml       # [2]
+ vxor H_l,H_l,RP       # [1]
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l
+ vxor H_h,H_l,H_h
+ vxor H2_t,H_h,RP
+
+ vsldoi H2,H2_t,H2_t,8
+ vsldoi H2h,H2,zero,8
+ vsldoi H2l,zero,H2,8
+
+ # --- calculate [H^2.Hi⊕H^2.Lo:H^1.Hi⊕H^1.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store H,[H^2.Hi⊕H^2.Lo:H^1.Hi⊕H^1.Lo] ---
+
+ li    r8,0*TableElemAlign
+ li    r9,1*TableElemAlign
+ li    r10,2*TableElemAlign
+ stxvd2x VSR(Hl),r8,TABLE
+ stxvd2x VSR(H),r9,TABLE
+ stxvd2x VSR(Hh),r10,TABLE
+
+ li    r8,3*TableElemAlign
+ li    r9,4*TableElemAlign
+ li    r10,5*TableElemAlign
+ stxvd2x VSR(H_Hh),r8,TABLE
+ stxvd2x VSR(H_H),r9,TABLE
+ stxvd2x VSR(H_Hl),r10,TABLE
+
+ # --- calculate H^3,H^4 ---
+
+ # polynomial multiplication "classical"
+ vpmsumd H_l,H_t,H2l # H^1l*H^2l
+ vpmsumd H_m,H_t,H2 # H^1h*H^2l⊕H^1l*H^2h
+ vpmsumd H_h,H_t,H2h # H^1h*H^2h
+ vpmsumd H2_l,H2_t,H2l # H^2l*H^2l
+ vpmsumd H2_m,H2_t,H2 # H^2h*H^2l⊕H^2l*H^2h
+ vpmsumd H2_h,H2_t,H2h # H^2h*H^2h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h # [1] H^3
+ vpmsumd    RP2,H2_l,poly_h # [1] H^4
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8 # [2] H^3
+ vsldoi M2h,zero,H2_m,8 # [2] H^4
+ vsldoi Ml,H_m,zero,8 # [2] H^3
+ vsldoi M2l,H2_m,zero,8 # [2] H^4
+ vsldoi RP,RP,RP,8 # [1] H^3
+ vsldoi RP2,RP2,RP2,8 # [1] H^4
+ vxor H_h,H_h,Mh # [2] H^3
+ vxor H2_h,H2_h,M2h # [2] H^4
+ vxor H_l,H_l,Ml # [2] H^3
+ vxor H2_l,H2_l,M2l # [2] H^4
+ vxor H_l,H_l,RP # [1] H^3
+ vxor H2_l,H2_l,RP2 # [1] H^4
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l # H^3
+ vpmsumd RP2,H2_l,poly_l # H^4
+ vxor H_h,H_l,H_h # H^3
+ vxor H2_h,H2_l,H2_h # H^4
+ vxor H_h,H_h,RP # H^3
+ vxor H2_h,H2_h,RP2 # H^4
+
+ vsldoi H2,H2_h,H2_h,8 # H^4
+ vsldoi H,H_h,H_h,8 # H^3
+ vsldoi H2l,zero,H2,8 # H^4
+ vsldoi H2h,H2,zero,8 # H^4
+
+ # --- calculate [H^4.Hi⊕H^4.Lo:H^3.Hi⊕H^3.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store [H^4.Hi⊕H^4.Lo:H^3.Hi⊕H^3.Lo] ---
+
+ li    r8,6*TableElemAlign
+ li    r9,7*TableElemAlign
+ li    r10,8*TableElemAlign
+ stxvd2x VSR(H_Hh),r8,TABLE
+ stxvd2x VSR(H_H),r9,TABLE
+ stxvd2x VSR(H_Hl),r10,TABLE
+
+ # --- calculate H^5,H^6 ---
+
+ # polynomial multiplication "classical"
+ vpmsumd H_l,H_t,H2l # H^1l*H^4l
+ vpmsumd H_m,H_t,H2 # H^1h*H^4l⊕H^1l*H^4h
+ vpmsumd H_h,H_t,H2h # H^1h*H^4h
+ vpmsumd H2_l,H2_t,H2l # H^2l*H^4l
+ vpmsumd H2_m,H2_t,H2 # H^2h*H^4l⊕H^2l*H^4h
+ vpmsumd H2_h,H2_t,H2h # H^2h*H^4h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h # [1] H^5
+ vpmsumd    RP2,H2_l,poly_h # [1] H^6
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8 # [2] H^5
+ vsldoi M2h,zero,H2_m,8 # [2] H^6
+ vsldoi Ml,H_m,zero,8 # [2] H^5
+ vsldoi M2l,H2_m,zero,8 # [2] H^6
+ vsldoi RP,RP,RP,8 # [1] H^5
+ vsldoi RP2,RP2,RP2,8 # [1] H^6
+ vxor H_h,H_h,Mh # [2] H^5
+ vxor H2_h,H2_h,M2h # [2] H^6
+ vxor H_l,H_l,Ml # [2] H^5
+ vxor H2_l,H2_l,M2l # [2] H^6
+ vxor H_l,H_l,RP # [1] H^5
+ vxor H2_l,H2_l,RP2 # [1] H^6
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l # H^5
+ vpmsumd RP2,H2_l,poly_l # H^6
+ vxor H_h,H_l,H_h # H^5
+ vxor H2_h,H2_l,H2_h # H^6
+ vxor H_h,H_h,RP # H^5
+ vxor H2_h,H2_h,RP2 # H^6
+
+ vsldoi H2,H2_h,H2_h,8 # H^6
+ vsldoi H,H_h,H_h,8 # H^5
+ vsldoi H2l,zero,H2,8 # H^6
+ vsldoi H2h,H2,zero,8 # H^6
+
+ # --- calculate [H^6.Hi⊕H^6.Lo:H^5.Hi⊕H^5.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store [H^6.Hi⊕H^6.Lo:H^5.Hi⊕H^5.Lo] ---
+
+ li    r8,9*TableElemAlign
+ li    r9,10*TableElemAlign
+ li    r10,11*TableElemAlign
+ stxvd2x VSR(H_Hh),r8,TABLE
+ stxvd2x VSR(H_H),r9,TABLE
+ stxvd2x VSR(H_Hl),r10,TABLE
+
+ # --- calculate H^7,H^8 ---
+
+ # polynomial multiplication "classical"
+ vpmsumd H_l,H_t,H2l # H^1l*H^6l
+ vpmsumd H_m,H_t,H2 # H^1h*H^6l⊕H^1l*H^6h
+ vpmsumd H_h,H_t,H2h # H^1h*H^6h
+ vpmsumd H2_l,H2_t,H2l # H^2l*H^6l
+ vpmsumd H2_m,H2_t,H2 # H^2h*H^6l⊕H^2l*H^6h
+ vpmsumd H2_h,H2_t,H2h # H^2h*H^6h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h # [1] H^7
+ vpmsumd    RP2,H2_l,poly_h # [1] H^8
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8 # [2] H^7
+ vsldoi M2h,zero,H2_m,8 # [2] H^8
+ vsldoi Ml,H_m,zero,8 # [2] H^7
+ vsldoi M2l,H2_m,zero,8 # [2] H^8
+ vsldoi RP,RP,RP,8 # [1] H^7
+ vsldoi RP2,RP2,RP2,8 # [1] H^8
+ vxor H_h,H_h,Mh # [2] H^7
+ vxor H2_h,H2_h,M2h # [2] H^8
+ vxor H_l,H_l,Ml # [2] H^7
+ vxor H2_l,H2_l,M2l # [2] H^8
+ vxor H_l,H_l,RP # [1] H^7
+ vxor H2_l,H2_l,RP2 # [1] H^8
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l # H^7
+ vpmsumd RP2,H2_l,poly_l # H^8
+ vxor H_h,H_l,H_h # H^7
+ vxor H2_h,H2_l,H2_h # H^8
+ vxor H_h,H_h,RP # H^7
+ vxor H2_h,H2_h,RP2 # H^8
+
+ vsldoi H,H_h,H_h,8 # H^7
+ vsldoi H2,H2_h,H2_h,8 # H^8
+
+ # --- calculate [H^8.Hi⊕H^8.Lo:H^7.Hi⊕H^7.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store [H^8.Hi⊕H^8.Lo:H^7.Hi⊕H^7.Lo] ---
+
+ li    r8,12*TableElemAlign
+ li    r9,13*TableElemAlign
+ li    r10,14*TableElemAlign
+ stxvd2x VSR(H_Hh),r8,TABLE
+ stxvd2x VSR(H_H),r9,TABLE
+ stxvd2x VSR(H_Hl),r10,TABLE
+
+  blr
+EPILOGUE(_nettle_gcm_init_key)
+
+ # void gcm_hash (const struct gcm_key *key, union gcm_block *x,
+ #                size_t length, const uint8_t *data)
+
+define(`FUNC_ALIGN', `5')
+PROLOGUE(_nettle_gcm_hash)
+ vxor zero,zero,zero
+
+ DATA_LOAD_VEC(poly,.polynomial,r7)
+IF_LE(`DATA_LOAD_VEC(swap_mask,.swap_mask,r7)')
+ DATA_LOAD_VEC(hidw_mask,.hidw_mask,r7)
+ DATA_LOAD_VEC(lodw_mask,.lodw_mask,r7)
+
+ vsldoi poly_h,zero,poly,8
+ vsldoi poly_l,poly_h,poly_h,8
+
+ lxvd2x VSR(C),0,X # load X
+IF_LE(`vperm C,C,C,swap_mask')
+
+ srdi r7,LENGTH,7 # 8x loop count
+ cmpldi r7,0
+ beq L2x
+
+ # backup registers
+ stdu SP,-224(SP)
+ std r28,216(SP)
+ std r29,208(SP)
+ std r30,200(SP)
+ std r31,192(SP)
+    li 8,176
+    stvx 20,8,SP
+    subi 8,8,16
+    stvx 21,8,SP
+    subi 8,8,16
+    stvx 22,8,SP
+    subi 8,8,16
+    stvx 23,8,SP
+    subi 8,8,16
+    stvx 24,8,SP
+    subi 8,8,16
+    stvx 25,8,SP
+    subi 8,8,16
+    stvx 26,8,SP
+    subi 8,8,16
+    stvx 27,8,SP
+    subi 8,8,16
+    stvx 28,8,SP
+    subi 8,8,16
+    stvx 29,8,SP
+    subi 8,8,16
+    stvx 30,8,SP
+    subi 8,8,16
+    stvx 31,8,SP
+
+ # table loading
+ li r8,3*TableElemAlign
+ li r9,4*TableElemAlign
+ li r10,5*TableElemAlign
+ lxvd2x VSR(H21h),r8,TABLE
+ lxvd2x VSR(H21),r9,TABLE
+ lxvd2x VSR(H21l),r10,TABLE
+ li r8,6*TableElemAlign
+ li r9,7*TableElemAlign
+ li r10,8*TableElemAlign
+ lxvd2x VSR(H43h),r8,TABLE
+ lxvd2x VSR(H43),r9,TABLE
+ lxvd2x VSR(H43l),r10,TABLE
+ li r8,9*TableElemAlign
+ li r9,10*TableElemAlign
+ li r10,11*TableElemAlign
+ lxvd2x VSR(H65h),r8,TABLE
+ lxvd2x VSR(H65),r9,TABLE
+ lxvd2x VSR(H65l),r10,TABLE
+ li r8,12*TableElemAlign
+ li r9,13*TableElemAlign
+ li r10,14*TableElemAlign
+ lxvd2x VSR(H87h),r8,TABLE
+ lxvd2x VSR(H87),r9,TABLE
+ lxvd2x VSR(H87l),r10,TABLE
+
+ li r8,0x10
+ li r9,0x20
+ li r10,0x30
+ li r28,0x40
+ li r29,0x50
+ li r30,0x60
+ li r31,0x70
+
+ mtctr     r7
+.align 5
+L8x_loop:
+ # input loading
+ lxvd2x VSR(C0),0,DATA # load C0
+ lxvd2x VSR(C1),r8,DATA # load C1
+ lxvd2x VSR(C2),r9,DATA # load C2
+ lxvd2x VSR(C3),r10,DATA # load C3
+
+ # swap permuting
+IF_LE(`vperm C0,C0,C0,swap_mask
+ vperm C1,C1,C1,swap_mask
+ vperm C2,C2,C2,swap_mask
+ vperm C3,C3,C3,swap_mask')
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ # polynomial multiplication "karatsuba" pre-processing
+ vperm C23h,C2,C3,hidw_mask
+ vperm C23l,C2,C3,lodw_mask
+ vperm C01h,C0,C1,hidw_mask
+ vperm C01l,C0,C1,lodw_mask
+
+ # input loading
+ lxvd2x VSR(C4),r28,DATA # load C4
+ lxvd2x VSR(C5),r29,DATA # load C5
+ lxvd2x VSR(C6),r30,DATA # load C6
+ lxvd2x VSR(C7),r31,DATA # load C7
+
+ # swap permuting
+IF_LE(`vperm C4,C4,C4,swap_mask
+ vperm C5,C5,C5,swap_mask
+ vperm C6,C6,C6,swap_mask
+ vperm C7,C7,C7,swap_mask')
+
+ # polynomial multiplication "karatsuba" pre-processing
+ vperm C45h,C4,C5,hidw_mask
+ vperm C45l,C4,C5,lodw_mask
+ vperm C67h,C6,C7,hidw_mask
+ vperm C67l,C6,C7,lodw_mask
+ vxor C23,C23h,C23l
+ vxor C01,C01h,C01l
+ vxor C45,C45h,C45l
+ vxor C67,C67h,C67l
+
+ # polynomial multiplication "karatsuba"
+ vpmsumd C23h,C23h,H65h # H23 = H^6h*C2h⊕H^5h*C3h
+ vpmsumd C23l,C23l,H65l # L23 = H^6l*C2l⊕H^5l*C3l
+ vpmsumd C01h,C01h,H87h # H01 = H^8h*C0h⊕H^7h*C1h
+ vpmsumd C01l,C01l,H87l # L01 = H^8l*C0l⊕H^7l*C1l
+ vpmsumd C67h,C67h,H21h # H67 = H^2h*C6h⊕H^1h*C7h
+ vpmsumd C67l,C67l,H21l # L67 = H^2l*C6l⊕H^1l*C7l
+ vpmsumd C45h,C45h,H43h # H45 = H^4h*C4h⊕H^3h*C5h
+ vpmsumd C45l,C45l,H43l # L45 = H^4l*C4l⊕H^3l*C5l
+ vpmsumd C23,C23,H65 # M23 = (H^6h⊕H^5h)*(C2h⊕C3h)⊕(H^6l⊕H^5l)*(C2l⊕C3l)
+ vpmsumd C01,C01,H87 # M01 = (H^8h⊕H^7h)*(C0h⊕C1h)⊕(H^8l⊕H^7l)*(C0l⊕C1l)
+ vpmsumd C45,C45,H43 # M45 = (H^4h⊕H^3h)*(C4h⊕C5h)⊕(H^4l⊕H^3l)*(C4l⊕C5l)
+ vpmsumd C67,C67,H21 # M67 = (H^2h⊕H^1h)*(C6h⊕C7h)⊕(H^2l⊕H^1l)*(C6l⊕C7l)
+
+ # polynomial multiplication "karatsuba" post-processing
+ vxor C23,C23,C23h
+ vxor C01,C01,C01h
+ vxor C45,C45,C45h
+ vxor C67,C67,C67h
+ vxor C23,C23,C23l
+ vxor C01,C01,C01l
+ vxor C45,C45,C45l
+ vxor C67,C67,C67l
+
+ # deferred recombination of partial products
+ vxor C01h,C01h,C23h # H0 = H01⊕H23
+ vxor C45h,C45h,C67h # H1 = H45⊕H67
+ vxor C01l,C01l,C23l # L0 = L01⊕L23
+ vxor C45l,C45l,C67l # L1 = L45⊕L45
+ vxor C01,C01,C23 # M0 = M01⊕M23
+ vxor C45,C45,C67 # M1 = M45⊕M45
+ vxor C01h,C01h,C45h # H = H0⊕H1
+ vxor C01l,C01l,C45l # L = L0⊕L1
+ vxor C01,C01,C45 # M = M0⊕M1
+
+ # reduction first phase # [1]
+ vpmsumd RP,C01l,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,C01,8   # [2]
+ vsldoi Ml,C01,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor C01h,C01h,Mh     # [2]
+ vxor C01l,C01l,Ml     # [2]
+ vxor C01l,C01l,RP     # [1]
+
+ # reduction second phase
+ vpmsumd RP,C01l,poly_l
+ vxor C01h,C01l,C01h
+ vxor C,C01h,RP
+
+ addi DATA,DATA,0x80
+ bdnz L8x_loop
+
+    # restore registers
+ li 8,0
+    lvx 31,8,SP
+    addi 8,8,16
+    lvx 30,8,SP
+    addi 8,8,16
+    lvx 29,8,SP
+    addi 8,8,16
+    lvx 28,8,SP
+    addi 8,8,16
+    lvx 27,8,SP
+    addi 8,8,16
+    lvx 26,8,SP
+    addi 8,8,16
+    lvx 25,8,SP
+    addi 8,8,16
+    lvx 24,8,SP
+    addi 8,8,16
+    lvx 23,8,SP
+    addi 8,8,16
+    lvx 22,8,SP
+    addi 8,8,16
+    lvx 21,8,SP
+    addi 8,8,16
+    lvx 20,8,SP
+ ld r31,192(SP)
+ ld r30,200(SP)
+ ld r29,208(SP)
+ ld r28,216(SP)
+ addi SP,SP,224
+
+ clrldi   LENGTH,LENGTH,57
+L2x:
+ srdi r7,LENGTH,5
+ cmpldi r7,0
+ beq L1x
+
+ # table loading
+ li r8,3*TableElemAlign
+ li r9,4*TableElemAlign
+ li r10,5*TableElemAlign
+ lxvd2x VSR(H21h),r8,TABLE
+ lxvd2x VSR(H21),r9,TABLE
+ lxvd2x VSR(H21l),r10,TABLE
+
+ li r10,0x10
+
+ mtctr     r7
+.align 5
+L2x_loop:
+ # input loading
+ lxvd2x VSR(C0),0,DATA # load C0
+ lxvd2x VSR(C1),r10,DATA # load C1
+
+ # swap permuting
+IF_LE(`vperm C0,C0,C0,swap_mask
+ vperm C1,C1,C1,swap_mask')
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ # polynomial multiplication "karatsuba" pre-processing
+ vperm C01h,C0,C1,hidw_mask
+ vperm C01l,C0,C1,lodw_mask
+ vxor C01,C01h,C01l
+
+ # polynomial multiplication "karatsuba"
+ vpmsumd C01h,C01h,H21h # H01 = H^2h*C0h⊕H^1h*C1h
+ vpmsumd C01l,C01l,H21l # L01 = H^2l*C0l⊕H^1l*C1l
+ vpmsumd C01,C01,H21 # M01 = (H^2h⊕H^1h)*(C0h⊕C1h)⊕(H^2l⊕H^1l)*(C0l⊕C1l)
+
+ # polynomial multiplication "karatsuba" post-processing
+ vxor C01,C01,C01h
+ vxor C01,C01,C01l
+
+ # reduction first phase # [1]
+ vpmsumd RP,C01l,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,C01,8   # [2]
+ vsldoi Ml,C01,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor C01h,C01h,Mh     # [2]
+ vxor C01l,C01l,Ml     # [2]
+ vxor C01l,C01l,RP     # [1]
+
+ # reduction second phase
+ vpmsumd RP,C01l,poly_l
+ vxor C01h,C01l,C01h
+ vxor C,C01h,RP
+
+ addi DATA,DATA,0x20
+ bdnz L2x_loop
+
+ clrldi   LENGTH,LENGTH,59
+L1x:
+ srdi r7,LENGTH,4
+ cmpldi r7,0
+ beq Lrem
+
+ # table loading
+ li r9,1*TableElemAlign
+ li r10,2*TableElemAlign
+ lxvd2x VSR(Hl),0,TABLE
+ lxvd2x VSR(H), r9,TABLE
+ lxvd2x VSR(Hh),r10,TABLE
+
+ # input loading
+ lxvd2x VSR(C0),0,DATA # load C0
+
+ # swap permuting
+IF_LE(`vperm C0,C0,C0,swap_mask')
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ vpmsumd Cl,C0,Hl # L = Hl*Cl
+ vpmsumd Cm,C0,H # M = Hh*Cl⊕Hl*Ch
+ vpmsumd Ch,C0,Hh # H = Hh*Ch
+
+ # reduction first phase # [1]
+ vpmsumd RP,Cl,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,Cm,8   # [2]
+ vsldoi Ml,Cm,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor Ch,Ch,Mh   # [2]
+ vxor Cl,Cl,Ml       # [2]
+ vxor Cl,Cl,RP   # [1]
+
+ # reduction second phase
+ vpmsumd RP,Cl,poly_l
+ vxor Ch,Cl,Ch
+ vxor C,Ch,RP
+
+ addi DATA,DATA,0x10
+ clrldi   LENGTH,LENGTH,60
+Lrem:
+ cmpldi LENGTH,0
+ beq Ldone
+
+ # table loading
+ li r9,1*TableElemAlign
+ li r10,2*TableElemAlign
+ lxvd2x VSR(Hl),0,TABLE
+ lxvd2x VSR(H), r9,TABLE
+ lxvd2x VSR(Hh),r10,TABLE
+
+ # input loading
+ stdu SP,-16(SP)
+ stvx zero,0,SP
+Lst_loop:
+ subic.      LENGTH,LENGTH,1
+ lbzx r7,LENGTH,DATA
+ stbx r7,LENGTH,SP
+ bne Lst_loop
+ lxvd2x   VSR(C0),0,SP
+ addi SP,SP,16
+
+ # swap permuting
+IF_LE(`vperm C0,C0,C0,swap_mask')
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ vpmsumd Cl,C0,Hl # L = Hl*Cl
+ vpmsumd Cm,C0,H # M = Hh*Cl⊕Hl*Ch
+ vpmsumd Ch,C0,Hh # H = Hh*Ch
+
+ # reduction first phase # [1]
+ vpmsumd RP,Cl,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,Cm,8   # [2]
+ vsldoi Ml,Cm,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor Ch,Ch,Mh   # [2]
+ vxor Cl,Cl,Ml     # [2]
+ vxor Cl,Cl,RP   # [1]
+
+ # reduction second phase
+ vpmsumd RP,Cl,poly_l
+ vxor Ch,Cl,Ch
+ vxor C,Ch,RP
+
+Ldone:
+IF_LE(`vperm C,C,C,swap_mask')
+ stxvd2x VSR(C),0,X # store C
+ blr
+EPILOGUE(_nettle_gcm_hash)
+
+ # gcm_fill (uint8_t *ctr, size_t blocks, union gcm_block *buffer)
+
+define(`FUNC_ALIGN', `5')
+PROLOGUE(_nettle_gcm_fill)
+IF_LE(`DATA_LOAD_VEC(swap_mask,.swap_mask,r6)')
+
+ vxor zero,zero,zero
+ vspltisb I1,1
+ vspltisb I2,2
+ vspltisb I3,3
+ vspltisb I4,4
+ vspltisb I5,5
+ vspltisb I6,6
+ vspltisb I7,7
+ vspltisb I8,8
+ vsldoi I1,zero,I1,1
+ vsldoi I2,zero,I2,1
+ vsldoi I3,zero,I3,1
+ vsldoi I4,zero,I4,1
+ vsldoi I5,zero,I5,1
+ vsldoi I6,zero,I6,1
+ vsldoi I7,zero,I7,1
+ vsldoi I8,zero,I8,1
+
+ lxvd2x VSR(CTR0),0,CTR
+ IF_LE(`vperm CTR0,CTR0,CTR0,swap_mask')
+
+ srdi r6,BLOCKS,3 # 8x loop count
+ cmpldi r6,0
+ beq Lfill_4x
+
+ std r25,-56(SP);
+ std r26,-48(SP);
+ std r27,-40(SP);
+ std r28,-32(SP);
+ std r29,-24(SP);
+ std r30,-16(SP);
+ std r31,-8(SP);
+
+ li r25,0x10
+ li r26,0x20
+ li r27,0x30
+ li r28,0x40
+ li r29,0x50
+ li r30,0x60
+ li r31,0x70
+
+ mtctr r6
+ L8x_fill_loop:
+ vadduwm CTR1,CTR0,I1
+ vadduwm CTR2,CTR0,I2
+ vadduwm CTR3,CTR0,I3
+ vadduwm CTR4,CTR0,I4
+ vadduwm CTR5,CTR0,I5
+ vadduwm CTR6,CTR0,I6
+ vadduwm CTR7,CTR0,I7
+
+ IF_LE(`vperm CTR0S,CTR0,CTR0,swap_mask
+ vperm CTR1,CTR1,CTR1,swap_mask
+ vperm CTR2,CTR2,CTR2,swap_mask
+ vperm CTR3,CTR3,CTR3,swap_mask
+ vperm CTR4,CTR4,CTR4,swap_mask
+ vperm CTR5,CTR5,CTR5,swap_mask
+ vperm CTR6,CTR6,CTR6,swap_mask
+ vperm CTR7,CTR7,CTR7,swap_mask')
+
+ IF_LE(`stxvd2x VSR(CTR0S),0,BUFFER')
+ IF_BE(`stxvd2x VSR(CTR0),0,BUFFER')
+ stxvd2x VSR(CTR1),r25,BUFFER
+ stxvd2x VSR(CTR2),r26,BUFFER
+ stxvd2x VSR(CTR3),r27,BUFFER
+ stxvd2x VSR(CTR4),r28,BUFFER
+ stxvd2x VSR(CTR5),r29,BUFFER
+ stxvd2x VSR(CTR6),r30,BUFFER
+ stxvd2x VSR(CTR7),r31,BUFFER
+
+ vadduwm CTR0,CTR0,I8
+ addi BUFFER,BUFFER,0x80
+ bdnz L8x_fill_loop
+
+ ld r25,-56(SP);
+ ld r26,-48(SP);
+ ld r27,-40(SP);
+ ld r28,-32(SP);
+ ld r29,-24(SP);
+ ld r30,-16(SP);
+ ld r31,-8(SP);
+
+ clrldi BLOCKS,BLOCKS,61
+
+ Lfill_4x:
+ srdi r6,BLOCKS,2
+ cmpldi r6,0
+ beq Lfill_2x
+
+ li r8,0x10
+ li r9,0x20
+ li r10,0x30
+
+ vadduwm CTR1,CTR0,I1
+ vadduwm CTR2,CTR0,I2
+ vadduwm CTR3,CTR0,I3
+
+ IF_LE(`vperm CTR0S,CTR0,CTR0,swap_mask
+ vperm CTR1,CTR1,CTR1,swap_mask
+ vperm CTR2,CTR2,CTR2,swap_mask
+ vperm CTR3,CTR3,CTR3,swap_mask')
+
+ IF_LE(`stxvd2x VSR(CTR0S),0,BUFFER')
+ IF_BE(`stxvd2x VSR(CTR0),0,BUFFER')
+ stxvd2x VSR(CTR1),r8,BUFFER
+ stxvd2x VSR(CTR2),r9,BUFFER
+ stxvd2x VSR(CTR3),r10,BUFFER
+
+ vadduwm CTR0,CTR0,I4
+ addi BUFFER,BUFFER,0x40
+
+ clrldi BLOCKS,BLOCKS,62
+
+ Lfill_2x:
+ srdi r6,BLOCKS,1
+ cmpldi r6,0
+ beq Lfill_1x
+
+ li r10,0x10
+
+ vadduwm CTR1,CTR0,I1
+
+ IF_LE(`vperm CTR0S,CTR0,CTR0,swap_mask
+ vperm CTR1,CTR1,CTR1,swap_mask')
+
+ IF_LE(`stxvd2x VSR(CTR0S),0,BUFFER')
+ IF_BE(`stxvd2x VSR(CTR0),0,BUFFER')
+ stxvd2x VSR(CTR1),r10,BUFFER
+
+ vadduwm CTR0,CTR0,I2
+ addi BUFFER,BUFFER,0x20
+
+ clrldi BLOCKS,BLOCKS,63
+
+ Lfill_1x:
+ cmpldi BLOCKS,0
+ beq Lfill_done
+
+ IF_LE(`vperm CTR0S,CTR0,CTR0,swap_mask')
+
+ IF_LE(`stxvd2x VSR(CTR0S),0,BUFFER')
+ IF_BE(`stxvd2x VSR(CTR0),0,BUFFER')
+
+ vadduwm CTR0,CTR0,I1
+
+ Lfill_done:
+ IF_LE(`vperm CTR0,CTR0,CTR0,swap_mask')
+ stxvd2x VSR(CTR0),0,CTR
+
+ blr
+EPILOGUE(_nettle_gcm_fill)
+
+    .data
+IF_LE(`.align 4
+.polynomial:
+ .byte 1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0xc2
+    .align 4
+.swap_mask:
+ .byte 8,9,10,11,12,13,14,15,0,1,2,3,4,5,6,7
+    .align 4
+.hidw_mask:
+ .byte 23,22,21,20,19,18,17,16,7,6,5,4,3,2,1,0
+    .align 4
+.lodw_mask:
+ .byte 31,30,29,28,27,26,25,24,15,14,13,12,11,10,9,8')
+IF_BE(`.align 4
+.polynomial:
+ .byte 0xc2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
+    .align 4
+.hidw_mask:
+ .byte 0,1,2,3,4,5,6,7,16,17,18,19,20,21,22,23
+    .align 4
+.lodw_mask:
+ .byte 8,9,10,11,12,13,14,15,24,25,26,27,28,29,30,31')

-- 
2.17.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200925215255</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-09-25 21:52:55-0400</timestampReceived><subject>[PATCH] "PowerPC64" chacha-core big-endian support</subject><body>

---
 powerpc64/p7/chacha-core-internal.asm | 55
++++++++++++++++++++++++++++++++++-
 1 file changed, 54 insertions(+), 1 deletion(-)

diff --git a/powerpc64/p7/chacha-core-internal.asm
b/powerpc64/p7/chacha-core-internal.asm
index 33c721c1..922050ff 100644
--- a/powerpc64/p7/chacha-core-internal.asm
+++ b/powerpc64/p7/chacha-core-internal.asm
@@ -53,6 +53,18 @@ define(`S1', `v9')
 define(`S2', `v10')
 define(`S3', `v11')

+C Big-endian working state
+define(`ROT24', `v12')
+define(`ODD',   `v13')
+define(`EVEN',  `v14')
+define(`ZERO',  `v15')
+define(`NEG',   `v16')
+
+define(`XR0', `v15')
+define(`XR1', `v16')
+define(`XR2', `v17')
+define(`XR3', `v18')
+
 C QROUND(X0, X1, X2, X3)
 define(`QROUND', `
  C x0 += x1, x3 ^= x0, x3 lrot 16
@@ -77,10 +89,42 @@ define(`QROUND', `
  vrlw $2, $2, ROT7
 ')

+C LE_SWAP32(X0, X1, X2, X3)
+define(`LE_SWAP32', `IF_BE(`
+ C xr = x lrot 8, xr &amp;= 0x00FF00FF
+ C x = x lrot 24, x &amp;= 0xFF00FF00
+ C x |= xr
+
+ vrlw XR0, X0, ROT8
+ vrlw XR1, X1, ROT8
+ vrlw XR2, X2, ROT8
+ vrlw XR3, X3, ROT8
+
+ vand XR0, XR0, ODD
+ vand XR1, XR1, ODD
+ vand XR2, XR2, ODD
+ vand XR3, XR3, ODD
+
+ vrlw X0, X0, ROT24
+ vrlw X1, X1, ROT24
+ vrlw X2, X2, ROT24
+ vrlw X3, X3, ROT24
+
+ vand X0, X0, EVEN
+ vand X1, X1, EVEN
+ vand X2, X2, EVEN
+ vand X3, X3, EVEN
+
+ vor  X0, X0, XR0
+ vor  X1, X1, XR1
+ vor  X2, X2, XR2
+ vor  X3, X3, XR3
+')')
+
  .text
- .align 4
  C _chacha_core(uint32_t *dst, const uint32_t *src, unsigned rounds)

+define(`FUNC_ALIGN', `5')
 PROLOGUE(_nettle_chacha_core)

  li r6, 0x10 C set up some...
@@ -91,6 +135,13 @@ PROLOGUE(_nettle_chacha_core)
  vspltisw ROT12, 12
  vspltisw ROT8, 8
  vspltisw ROT7, 7
+IF_BE(`
+ vspltisw ZERO, 0
+ vspltisw NEG, -1
+ vmrghb   ODD, ZERO, NEG
+ vmrghb   EVEN, NEG, ZERO
+ vadduwm  ROT24, ROT12, ROT12
+')

  lxvw4x VSR(X0), 0, SRC
  lxvw4x VSR(X1), r6, SRC
@@ -131,6 +182,8 @@ PROLOGUE(_nettle_chacha_core)
  vadduwm X2, X2, S2
  vadduwm X3, X3, S3

+ LE_SWAP32(X0, X1, X2, X3)
+
  stxvw4x VSR(X0), 0, DST
  stxvw4x VSR(X1), r6, DST
  stxvw4x VSR(X2), r7, DST

-- 
2.17.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200925223732</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-09-25 22:37:32-0400</timestampReceived><subject>[PATCH] "PowerPC64" chacha-core big-endian support "Shorter version"</subject><body>

The last patch follows the C implementation but I just figured out a decent
way to do it.
---
 powerpc64/p7/chacha-core-internal.asm | 22 +++++++++++++++++++++-
 1 file changed, 21 insertions(+), 1 deletion(-)

diff --git a/powerpc64/p7/chacha-core-internal.asm
b/powerpc64/p7/chacha-core-internal.asm
index 33c721c1..76ca0d45 100644
--- a/powerpc64/p7/chacha-core-internal.asm
+++ b/powerpc64/p7/chacha-core-internal.asm
@@ -53,6 +53,10 @@ define(`S1', `v9')
 define(`S2', `v10')
 define(`S3', `v11')

+C Big-endian working state
+define(`LE_MASK',  `v12')
+define(`LE_TEMP', `v13')
+
 C QROUND(X0, X1, X2, X3)
 define(`QROUND', `
  C x0 += x1, x3 ^= x0, x3 lrot 16
@@ -77,10 +81,18 @@ define(`QROUND', `
  vrlw $2, $2, ROT7
 ')

+C LE_SWAP32(X0, X1, X2, X3)
+define(`LE_SWAP32', `IF_BE(`
+ vperm   X0, X0, X0, LE_MASK
+ vperm   X1, X1, X1, LE_MASK
+ vperm   X2, X2, X2, LE_MASK
+ vperm   X3, X3, X3, LE_MASK
+')')
+
  .text
- .align 4
  C _chacha_core(uint32_t *dst, const uint32_t *src, unsigned rounds)

+define(`FUNC_ALIGN', `5')
 PROLOGUE(_nettle_chacha_core)

  li r6, 0x10 C set up some...
@@ -91,6 +103,12 @@ PROLOGUE(_nettle_chacha_core)
  vspltisw ROT12, 12
  vspltisw ROT8, 8
  vspltisw ROT7, 7
+IF_BE(`
+ li       r9, 0
+ lvsl     LE_MASK, r9, r9
+ vspltisb LE_TEMP, 0x03
+ vxor     LE_MASK, LE_MASK, LE_TEMP
+')

  lxvw4x VSR(X0), 0, SRC
  lxvw4x VSR(X1), r6, SRC
@@ -131,6 +149,8 @@ PROLOGUE(_nettle_chacha_core)
  vadduwm X2, X2, S2
  vadduwm X3, X3, S3

+ LE_SWAP32(X0, X1, X2, X3)
+
  stxvw4x VSR(X0), 0, DST
  stxvw4x VSR(X1), r6, DST
  stxvw4x VSR(X2), r7, DST

-- 
2.17.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200928173204</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-09-28 17:32:04-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" chacha-core big-endian support "Shorter version"</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; The last patch follows the C implementation but I just figured out a decent
&gt; way to do it.

Thanks! Applied, and pushed on the ppc-chacha-core branch for testing.
(Had apply it semi-manually, since the file to patch indents using TAB
and those were replaced by spaces in the emailed patch).

&gt; +IF_BE(`
&gt; + li       r9, 0
&gt; + lvsl     LE_MASK, r9, r9
&gt; + vspltisb LE_TEMP, 0x03
&gt; + vxor     LE_MASK, LE_MASK, LE_TEMP
&gt; +')

I think this deserves some comments, on what goes into the register in
each step. Clever that the endian conversion corresponds to xoring the
byte indices with 3.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200928180858</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-09-28 18:08:58-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" chacha-core big-endian support "Shorter version"</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt;&gt; The last patch follows the C implementation but I just figured out a decent
&gt;&gt; way to do it.
&gt;
&gt; Thanks! Applied, and pushed on the ppc-chacha-core branch for testing.
&gt; (Had apply it semi-manually, since the file to patch indents using TAB
&gt; and those were replaced by spaces in the emailed patch).

And tests seems to pass also on big-endian. Nice!

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201107102455</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-11-07 10:24:55-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" chacha-core big-endian support "Shorter version"</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; Sure. According to Power ISA 2.07:
&gt; The lvsl and lvsr instructions can be used to create the permute control
&gt; vector to be used by a subsequent vperm instruction.
&gt;
&gt; So the lvsl and lvsr instructions check 'sh' value in order to fill the
&gt; vector register, if 'sh' is 0 the vector register will be populated as
&gt; follow
&gt; 0x000102030405060708090A0B0C0D0E0F
&gt; this can be done using the following instructions
&gt; li       r9, 0
&gt; lvsl     LE_MASK, r9, r9
&gt; Now we xor each byte with 3 using these instructions
&gt; vspltisb LE_TEMP, 0x03
&gt; vxor     LE_MASK, LE_MASK, LE_TEMP
&gt; The value of the vector register is now
&gt; 0x03020100070605040B0A09080F0E0D0C

Thanks. I've added some comments about this.

I've also extended the fat setup to check for altivec, using the logic 

      hwcap = getauxval(AT_HWCAP);
      ...
      /* We also need VSX instructions, mainly for load and store. */
      features-&gt;have_altivec
	 = ((hwcap &amp; (PPC_FEATURE_HAS_ALTIVEC | PPC_FEATURE_HAS_VSX))
    	    == (PPC_FEATURE_HAS_ALTIVEC | PPC_FEATURE_HAS_VSX));

For now, gnu/linux only, patches to get detection working also on
freebsd and aix welcome (I think needed fixes will be close to trivial,
but I have no easy way to test, and I don't want to commit untested code).

For non-fat builds, the new code is disabled by default, with a
configure option --enable-power-altivec.

And I've merged the changes to the master branch. I have some work-in
progress code to do 2 or 4 chacha blocks in parallel, but not sure when
I will get that into working shape.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200924192803</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-09-24 19:28:03-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" GCM support</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; This is a stand-alone patch that applies all the previous patches to the
&gt; optimized GCM implementation. This patch is based on the master upstream so
&gt; it can be merged directly.

Some questions on the overall structure:

What's the speedup you get from assembly gcm_fill? I see the C
implementation uses memcpy and WRITE_UINT32, and is likely significantly
slower than the ctr_fill16 in ctr.c. But it could be improved using
portable means. If done well, it should be a very small fraction of the
cpu time spent for gcm encryption.

What table layout is used by the assembly gcm_init_key? I would have
expected not much tables to be needed when using the special multiply
instructions. And Nettle generally doesn't try very hard to optimize key
setup, under the theory that applications that need high performance
also do a lot of work with each key. E.g., we use C code for AES key
setup even when it could be sped up by assembly using special
instructions.

So it would be easier for me to start with a patch for gcm_hash only
(possibly with supporting C code for key setup).

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200924225145</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-09-24 22:51:45-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" GCM support</subject><body>

&gt; 
&gt; What's the speedup you get from assembly gcm_fill? I see the C
&gt; implementation uses memcpy and WRITE_UINT32, and is likely significantly
&gt; slower than the ctr_fill16 in ctr.c. But it could be improved using
&gt; portable means. If done well, it should be a very small fraction of the
&gt; cpu time spent for gcm encryption.


Actually, there is a counter involved along with writing operations, the
idea here is that the width of a single block is 16 bytes which can fit in
a vector register so one writing operation is needed plus executing e.g. 6
addition operations per cycle would boost the function performance. I
measured the execution time of both C and altivec implementations on POWER8
for 32,768 blocks (512 KB), repeated 10000 times and compiled with -O3
gcm_fill_c() took 0.000073 seconds to execute
gcm_fill_altivec() took 0.000019 seconds to execute
As you can see, the function itself isn't time consuming at all and maybe
optimizing it is not worth it, but gcm_fill is part of AES_CTR and what
other libraries usually do is optimizing AES_CTR as a whole so I considered
optimizing it to stay on the same track.

What table layout is used by the assembly gcm_init_key? I would have
&gt; expected not much tables to be needed when using the special multiply
&gt; instructions. And Nettle generally doesn't try very hard to optimize key
&gt; setup, under the theory that applications that need high performance
&gt; also do a lot of work with each key. E.g., we use C code for AES key
&gt; setup even when it could be sped up by assembly using special
&gt; instructions.
&gt; 
&gt; So it would be easier for me to start with a patch for gcm_hash only
&gt; (possibly with supporting C code for key setup).


It's a little bit more complicated than just special multiply instructions,
let me explain that
From reference [1]:
To compute the GHASH digest of 4 consecutive blocks, we use a method of
parallelization as described in References [3]. The method can be described
by the following equations:
Ciphertext inputs: C0, C1, C2, C3.
Digest input/output: Digest.
Digest = (((((((Digest ⊕C0)*H)⊕C1)*H)⊕C2)*H)⊕C3)*H
       = ((Digest⊕C0)*H^4)⊕(C1*H^3)⊕(C2*H^2)⊕(C3*H)

As you can see, there is a pre-computed constants here "H,H^2,H^3,H^3"
which should settle in a table to be used in upcoming hash operations,
furthermore to handle bit-reflection of the multiplication product, we
precompute "H &lt;&lt; 1 modulo polynomial g(x)" then to pre-compute
"H^2,H^3,H^3" we use the operation:
reflected (A)*reflected (H&lt;&lt;1 mod g(x)) = reflected (A*H) mod g(x)
so we got H = H &lt;&lt; 1 modulo polynomial g(x) then H^2 = H * H and so on. we
can use these values as 128-bit constants and avoid shifting the product.
Also in the init function we have to precompute inputs to the Karatsuba
Algorithm, so we adapt the previous constants to be compatible with the
Karatsuba Algorithm.
In summary, The table layout varies according to the techniques used in the
different implementations, it's unreasonable to fill certain table using C
as standard key setup, for example there are several x86 GCM
implementations in OpenSSL library and the table layouts of SSE and AVX
implementations are different from each other.

[1] https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/communications-ia-galois-counter-mode-paper.pdf
 _______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200925065958</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-09-25 06:59:58-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" GCM support</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt;&gt; What's the speedup you get from assembly gcm_fill? I see the C
&gt;&gt; implementation uses memcpy and WRITE_UINT32, and is likely significantly
&gt;&gt; slower than the ctr_fill16 in ctr.c. But it could be improved using
&gt;&gt; portable means. If done well, it should be a very small fraction of the
&gt;&gt; cpu time spent for gcm encryption.

&gt; I measured the execution time of both C and altivec implementations on
&gt; POWER8 for 32,768 blocks (512 KB), repeated 10000 times and compiled
&gt; with -O3 gcm_fill_c() took 0.000073 seconds to execute
&gt; gcm_fill_altivec() took 0.000019 seconds to execute As you can see,
&gt; the function itself isn't time consuming at all and maybe optimizing
&gt; it is not worth it,

Can you try below patch? For now, tested on little endian (x86_64) only,
and there the loop compiles to

  50:   89 c8                   mov    %ecx,%eax
  52:   4c 89 0a                mov    %r9,(%rdx)
  55:   48 83 c2 10             add    $0x10,%rdx
  59:   83 c1 01                add    $0x1,%ecx
  5c:   0f c8                   bswap  %eax
  5e:   48 c1 e0 20             shl    $0x20,%rax
  62:   4c 01 d0                add    %r10,%rax
  65:   48 89 42 f8             mov    %rax,-0x8(%rdx)
  69:   4c 39 c2                cmp    %r8,%rdx
  6c:   75 e2                   jne    50 &lt;gcm_fill+0x20&gt;

Should run in a few cycles per block (6 cycles assuming dual-issue,
decent out-of-order capabilities per block). I would expect unrolling,
to do multiple blocks in parallel, to give a large performance
improvement only on strict in-order processors.

&gt; but gcm_fill is part of AES_CTR and what other
&gt; libraries usually do is optimizing AES_CTR as a whole so I considered
&gt; optimizing it to stay on the same track.

In Nettle, I strive to go to the extra complexity of assembler
implementation only when there's a significant performance benefit.

Regards,
/Niels

diff --git a/gcm.c b/gcm.c
index cf615daf..71e9f365 100644
--- a/gcm.c
+++ b/gcm.c
@@ -334,6 +334,46 @@ gcm_update(struct gcm_ctx *ctx, const struct gcm_key *key,
 }
 
 static nettle_fill16_func gcm_fill;
+#if WORDS_BIGENDIAN
+static void
+gcm_fill(uint8_t *ctr, size_t blocks, union nettle_block16 *buffer)
+{
+  uint64_t hi, lo;
+  uint32_t lo;
+  size_t i;
+  hi = READ_UINT64(ctr);
+  mid = (uint64_t)READ_UINT32(ctr + 8) &lt;&lt; 32;
+  lo = READ_UINT32(ctr + 12);
+
+  for (i = 0; i &lt; blocks; i++)
+    {
+      buffer[i].u64[0] = hi;
+      buffer[i].u64[1] = mid + lo++;
+    }
+  WRITE_UINT32(ctr + 12, lo);
+
+}
+#elif HAVE_BUILTIN_BSWAP64
+/* Assume __builtin_bswap32 is also available */
+static void
+gcm_fill(uint8_t *ctr, size_t blocks, union nettle_block16 *buffer)
+{
+  uint64_t hi, mid;
+  uint32_t lo;
+  size_t i;
+  hi = LE_READ_UINT64(ctr);
+  mid = LE_READ_UINT32(ctr + 8);
+  lo = READ_UINT32(ctr + 12);
+
+  for (i = 0; i &lt; blocks; i++)
+    {
+      buffer[i].u64[0] = hi;
+      buffer[i].u64[1] = mid + ((uint64_t)__builtin_bswap32(lo) &lt;&lt; 32);
+      lo++;
+    }
+  WRITE_UINT32(ctr + 12, lo);
+}
+#else
 static void
 gcm_fill(uint8_t *ctr, size_t blocks, union nettle_block16 *buffer)
 {
@@ -349,6 +389,7 @@ gcm_fill(uint8_t *ctr, size_t blocks, union nettle_block16 *buffer)
 
   WRITE_UINT32(ctr + GCM_BLOCK_SIZE - 4, c);
 }
+#endif
 
 void
 gcm_encrypt (struct gcm_ctx *ctx, const struct gcm_key *key,


-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200925085743</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-09-25 08:57:43-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" GCM support</subject><body>

It's gotten better with this patch, now it takes 0.000049 seconds to
execute under the same circumstances.

On Fri, Sep 25, 2020 at 9:59 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt;&gt; What's the speedup you get from assembly gcm_fill? I see the C
&gt; &gt;&gt; implementation uses memcpy and WRITE_UINT32, and is likely significantly
&gt; &gt;&gt; slower than the ctr_fill16 in ctr.c. But it could be improved using
&gt; &gt;&gt; portable means. If done well, it should be a very small fraction of the
&gt; &gt;&gt; cpu time spent for gcm encryption.
&gt;
&gt; &gt; I measured the execution time of both C and altivec implementations on
&gt; &gt; POWER8 for 32,768 blocks (512 KB), repeated 10000 times and compiled
&gt; &gt; with -O3 gcm_fill_c() took 0.000073 seconds to execute
&gt; &gt; gcm_fill_altivec() took 0.000019 seconds to execute As you can see,
&gt; &gt; the function itself isn't time consuming at all and maybe optimizing
&gt; &gt; it is not worth it,
&gt;
&gt; Can you try below patch? For now, tested on little endian (x86_64) only,
&gt; and there the loop compiles to
&gt;
&gt;   50:   89 c8                   mov    %ecx,%eax
&gt;   52:   4c 89 0a                mov    %r9,(%rdx)
&gt;   55:   48 83 c2 10             add    $0x10,%rdx
&gt;   59:   83 c1 01                add    $0x1,%ecx
&gt;   5c:   0f c8                   bswap  %eax
&gt;   5e:   48 c1 e0 20             shl    $0x20,%rax
&gt;   62:   4c 01 d0                add    %r10,%rax
&gt;   65:   48 89 42 f8             mov    %rax,-0x8(%rdx)
&gt;   69:   4c 39 c2                cmp    %r8,%rdx
&gt;   6c:   75 e2                   jne    50 &lt;gcm_fill+0x20&gt;
&gt;
&gt; Should run in a few cycles per block (6 cycles assuming dual-issue,
&gt; decent out-of-order capabilities per block). I would expect unrolling,
&gt; to do multiple blocks in parallel, to give a large performance
&gt; improvement only on strict in-order processors.
&gt;
&gt; &gt; but gcm_fill is part of AES_CTR and what other
&gt; &gt; libraries usually do is optimizing AES_CTR as a whole so I considered
&gt; &gt; optimizing it to stay on the same track.
&gt;
&gt; In Nettle, I strive to go to the extra complexity of assembler
&gt; implementation only when there's a significant performance benefit.
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; diff --git a/gcm.c b/gcm.c
&gt; index cf615daf..71e9f365 100644
&gt; --- a/gcm.c
&gt; +++ b/gcm.c
&gt; @@ -334,6 +334,46 @@ gcm_update(struct gcm_ctx *ctx, const struct gcm_key
&gt; *key,
&gt;  }
&gt;
&gt;  static nettle_fill16_func gcm_fill;
&gt; +#if WORDS_BIGENDIAN
&gt; +static void
&gt; +gcm_fill(uint8_t *ctr, size_t blocks, union nettle_block16 *buffer)
&gt; +{
&gt; +  uint64_t hi, lo;
&gt; +  uint32_t lo;
&gt; +  size_t i;
&gt; +  hi = READ_UINT64(ctr);
&gt; +  mid = (uint64_t)READ_UINT32(ctr + 8) &lt;&lt; 32;
&gt; +  lo = READ_UINT32(ctr + 12);
&gt; +
&gt; +  for (i = 0; i &lt; blocks; i++)
&gt; +    {
&gt; +      buffer[i].u64[0] = hi;
&gt; +      buffer[i].u64[1] = mid + lo++;
&gt; +    }
&gt; +  WRITE_UINT32(ctr + 12, lo);
&gt; +
&gt; +}
&gt; +#elif HAVE_BUILTIN_BSWAP64
&gt; +/* Assume __builtin_bswap32 is also available */
&gt; +static void
&gt; +gcm_fill(uint8_t *ctr, size_t blocks, union nettle_block16 *buffer)
&gt; +{
&gt; +  uint64_t hi, mid;
&gt; +  uint32_t lo;
&gt; +  size_t i;
&gt; +  hi = LE_READ_UINT64(ctr);
&gt; +  mid = LE_READ_UINT32(ctr + 8);
&gt; +  lo = READ_UINT32(ctr + 12);
&gt; +
&gt; +  for (i = 0; i &lt; blocks; i++)
&gt; +    {
&gt; +      buffer[i].u64[0] = hi;
&gt; +      buffer[i].u64[1] = mid + ((uint64_t)__builtin_bswap32(lo) &lt;&lt; 32);
&gt; +      lo++;
&gt; +    }
&gt; +  WRITE_UINT32(ctr + 12, lo);
&gt; +}
&gt; +#else
&gt;  static void
&gt;  gcm_fill(uint8_t *ctr, size_t blocks, union nettle_block16 *buffer)
&gt;  {
&gt; @@ -349,6 +389,7 @@ gcm_fill(uint8_t *ctr, size_t blocks, union
&gt; nettle_block16 *buffer)
&gt;
&gt;    WRITE_UINT32(ctr + GCM_BLOCK_SIZE - 4, c);
&gt;  }
&gt; +#endif
&gt;
&gt;  void
&gt;  gcm_encrypt (struct gcm_ctx *ctx, const struct gcm_key *key,
&gt;
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200927192336</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-09-27 19:23:36-0400</timestampReceived><subject>[PATCH] "PowerPC64" GCM support</subject><body>

---
 configure.ac               |   6 +-
 fat-ppc.c                  |  33 ++
 fat-setup.h                |   7 +
 gcm.c                      |  69 +++-
 powerpc64/fat/gcm-hash.asm |  39 +++
 powerpc64/p8/gcm-hash.asm  | 773
+++++++++++++++++++++++++++++++++++++++++++++
 6 files changed, 909 insertions(+), 18 deletions(-)
 create mode 100644 powerpc64/fat/gcm-hash.asm
 create mode 100644 powerpc64/p8/gcm-hash.asm

diff --git a/configure.ac b/configure.ac
index e9983697..0129f950 100644
--- a/configure.ac
+++ b/configure.ac
@@ -488,7 +488,7 @@ asm_replace_list="aes-encrypt-internal.asm
aes-decrypt-internal.asm \
  sha3-permute.asm umac-nh.asm umac-nh-n.asm machine.m4"

 # Assembler files which generate additional object files if they are used.
-asm_nettle_optional_list="gcm-hash8.asm cpuid.asm \
+asm_nettle_optional_list="gcm-hash.asm gcm-hash8.asm cpuid.asm \
   aes-encrypt-internal-2.asm aes-decrypt-internal-2.asm memxor-2.asm \
   chacha-3core.asm chacha-core-internal-2.asm salsa20-2core.asm \
   salsa20-core-internal-2.asm sha1-compress-2.asm sha256-compress-2.asm \
@@ -612,9 +612,9 @@ AH_VERBATIM([HAVE_NATIVE],
 #undef HAVE_NATIVE_ecc_secp384r1_redc
 #undef HAVE_NATIVE_ecc_secp521r1_modp
 #undef HAVE_NATIVE_ecc_secp521r1_redc
-#undef HAVE_NATIVE_gcm_init_key8
+#undef HAVE_NATIVE_gcm_init_key
+#undef HAVE_NATIVE_gcm_hash
 #undef HAVE_NATIVE_gcm_hash8
-#undef HAVE_NATIVE_gcm_fill
 #undef HAVE_NATIVE_salsa20_core
 #undef HAVE_NATIVE_salsa20_2core
 #undef HAVE_NATIVE_fat_salsa20_2core
diff --git a/fat-ppc.c b/fat-ppc.c
index 2bc50481..d73b45b0 100644
--- a/fat-ppc.c
+++ b/fat-ppc.c
@@ -120,6 +120,16 @@ DECLARE_FAT_FUNC(_nettle_aes_decrypt,
aes_crypt_internal_func)
 DECLARE_FAT_FUNC_VAR(aes_decrypt, aes_crypt_internal_func, c)
 DECLARE_FAT_FUNC_VAR(aes_decrypt, aes_crypt_internal_func, ppc64)

+#if GCM_TABLE_BITS == 8
+DECLARE_FAT_FUNC(_nettle_gcm_init_key, gcm_init_key_func)
+DECLARE_FAT_FUNC_VAR(gcm_init_key, gcm_init_key_func, c)
+DECLARE_FAT_FUNC_VAR(gcm_init_key, gcm_init_key_func, ppc64)
+
+DECLARE_FAT_FUNC(_nettle_gcm_hash, gcm_hash_func)
+DECLARE_FAT_FUNC_VAR(gcm_hash, gcm_hash_func, c)
+DECLARE_FAT_FUNC_VAR(gcm_hash, gcm_hash_func, ppc64)
+#endif /* GCM_TABLE_BITS == 8 */
+
 static void CONSTRUCTOR
 fat_init (void)
 {
@@ -139,11 +149,23 @@ fat_init (void)
  fprintf (stderr, "libnettle: enabling arch 2.07 code.\n");
       _nettle_aes_encrypt_vec = _nettle_aes_encrypt_ppc64;
       _nettle_aes_decrypt_vec = _nettle_aes_decrypt_ppc64;
+#if GCM_TABLE_BITS == 8
+     /* Make sure _nettle_gcm_init_key_vec function is compatible
+        with _nettle_gcm_hash_vec function e.g. _nettle_gcm_init_key_c()
+        fills gcm_key table with values that are incompatible with
+        _nettle_gcm_hash_ppc64() */
+     _nettle_gcm_init_key_vec = _nettle_gcm_init_key_ppc64;
+     _nettle_gcm_hash_vec = _nettle_gcm_hash_ppc64;
+#endif /* GCM_TABLE_BITS == 8 */
     }
   else
     {
       _nettle_aes_encrypt_vec = _nettle_aes_encrypt_c;
       _nettle_aes_decrypt_vec = _nettle_aes_decrypt_c;
+#if GCM_TABLE_BITS == 8
+     _nettle_gcm_init_key_vec = _nettle_gcm_init_key_c;
+     _nettle_gcm_hash_vec = _nettle_gcm_hash_c;
+#endif /* GCM_TABLE_BITS == 8 */
     }
 }

@@ -160,3 +182,14 @@ DEFINE_FAT_FUNC(_nettle_aes_decrypt, void,
  size_t length, uint8_t *dst,
  const uint8_t *src),
  (rounds, keys, T, length, dst, src))
+
+#if GCM_TABLE_BITS == 8
+DEFINE_FAT_FUNC(_nettle_gcm_init_key, void,
+ (union nettle_block16 *table),
+ (table))
+
+DEFINE_FAT_FUNC(_nettle_gcm_hash, void,
+ (const struct gcm_key *key, union nettle_block16 *x,
+ size_t length, const uint8_t *data),
+ (key, x, length, data))
+#endif /* GCM_TABLE_BITS == 8 */
diff --git a/fat-setup.h b/fat-setup.h
index 99f1ea67..4a9f7969 100644
--- a/fat-setup.h
+++ b/fat-setup.h
@@ -162,6 +162,13 @@ typedef void aes_crypt_internal_func (unsigned rounds,
const uint32_t *keys,
       size_t length, uint8_t *dst,
       const uint8_t *src);

+#if GCM_TABLE_BITS == 8
+typedef void gcm_init_key_func (union nettle_block16 *table);
+
+typedef void gcm_hash_func (const struct gcm_key *key, union
nettle_block16 *x,
+      size_t length, const uint8_t *data);
+#endif /* GCM_TABLE_BITS == 8 */
+
 typedef void *(memxor_func)(void *dst, const void *src, size_t n);

 typedef void salsa20_core_func (uint32_t *dst, const uint32_t *src,
unsigned rounds);
diff --git a/gcm.c b/gcm.c
index 48b3e75a..787c303e 100644
--- a/gcm.c
+++ b/gcm.c
@@ -140,6 +140,26 @@ gcm_gf_mul (union nettle_block16 *x, const union
nettle_block16 *table)
   memcpy (x-&gt;b, Z.b, sizeof(Z));
 }
 # elif GCM_TABLE_BITS == 8
+#  if HAVE_NATIVE_gcm_init_key
+
+#define gcm_init_key _nettle_gcm_init_key
+void
+_nettle_gcm_init_key (union nettle_block16 *table);
+/* For fat builds */
+void
+_nettle_gcm_init_key_c (union nettle_block16 *table);
+#  endif /* HAVE_NATIVE_gcm_init_key */
+#  if HAVE_NATIVE_gcm_hash
+
+#define gcm_hash _nettle_gcm_hash
+void
+_nettle_gcm_hash (const struct gcm_key *key, union nettle_block16 *x,
+   size_t length, const uint8_t *data);
+/* For fat builds */
+void
+_nettle_gcm_hash_c (const struct gcm_key *key, union nettle_block16 *x,
+   size_t length, const uint8_t *data);
+#  endif /* HAVE_NATIVE_gcm_hash */
 #  if HAVE_NATIVE_gcm_hash8

 #define gcm_hash _nettle_gcm_hash8
@@ -228,6 +248,32 @@ gcm_gf_mul (union nettle_block16 *x, const union
nettle_block16 *table)
 /* Increment the rightmost 32 bits. */
 #define INC32(block) INCREMENT(4, (block.b) + GCM_BLOCK_SIZE - 4)

+#ifdef gcm_init_key
+void
+_nettle_gcm_init_key_c(union nettle_block16 *table)
+#else
+static void
+gcm_init_key(union nettle_block16 *table)
+#endif /* !gcm_init_key */
+{
+#if GCM_TABLE_BITS
+  /* Middle element if GCM_TABLE_BITS &gt; 0, otherwise the first
+     element */
+  unsigned i = (1&lt;&lt;GCM_TABLE_BITS)/2;
+
+  /* Algorithm 3 from the gcm paper. First do powers of two, then do
+     the rest by adding. */
+  while (i /= 2)
+    block16_mulx_ghash(&amp;table[i], &amp;table[2*i]);
+  for (i = 2; i &lt; 1&lt;&lt;GCM_TABLE_BITS; i *= 2)
+    {
+      unsigned j;
+      for (j = 1; j &lt; i; j++)
+ block16_xor3(&amp;table[i+j], &amp;table[i], &amp;table[j]);
+    }
+#endif
+}
+
 /* Initialization of GCM.
  * @ctx: The context of GCM
  * @cipher: The context of the underlying block cipher
@@ -244,25 +290,19 @@ gcm_set_key(struct gcm_key *key,
   /* H */
   memset(key-&gt;h[0].b, 0, GCM_BLOCK_SIZE);
   f (cipher, GCM_BLOCK_SIZE, key-&gt;h[i].b, key-&gt;h[0].b);
-
-#if GCM_TABLE_BITS
-  /* Algorithm 3 from the gcm paper. First do powers of two, then do
-     the rest by adding. */
-  while (i /= 2)
-    block16_mulx_ghash(&amp;key-&gt;h[i], &amp;key-&gt;h[2*i]);
-  for (i = 2; i &lt; 1&lt;&lt;GCM_TABLE_BITS; i *= 2)
-    {
-      unsigned j;
-      for (j = 1; j &lt; i; j++)
- block16_xor3(&amp;key-&gt;h[i+j], &amp;key-&gt;h[i],&amp;key-&gt;h[j]);
-    }
-#endif
+
+  gcm_init_key(key-&gt;h);
 }

-#ifndef gcm_hash
+#ifdef gcm_hash
+void
+_nettle_gcm_hash_c(const struct gcm_key *key, union nettle_block16 *x,
+ size_t length, const uint8_t *data)
+#else
 static void
 gcm_hash(const struct gcm_key *key, union nettle_block16 *x,
  size_t length, const uint8_t *data)
+#endif /* !gcm_hash */
 {
   for (; length &gt;= GCM_BLOCK_SIZE;
        length -= GCM_BLOCK_SIZE, data += GCM_BLOCK_SIZE)
@@ -276,7 +316,6 @@ gcm_hash(const struct gcm_key *key, union
nettle_block16 *x,
       gcm_gf_mul (x, key-&gt;h);
     }
 }
-#endif /* !gcm_hash */

 static void
 gcm_hash_sizes(const struct gcm_key *key, union nettle_block16 *x,
diff --git a/powerpc64/fat/gcm-hash.asm b/powerpc64/fat/gcm-hash.asm
new file mode 100644
index 00000000..7fd77223
--- /dev/null
+++ b/powerpc64/fat/gcm-hash.asm
@@ -0,0 +1,39 @@
+C powerpc64/fat/gcm-hash.asm
+
+
+ifelse(`
+   Copyright (C) 2020 Mamone Tarsha
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+')
+
+dnl picked up by configure
+dnl PROLOGUE(_nettle_gcm_init_key)
+dnl PROLOGUE(_nettle_gcm_hash)
+
+define(`fat_transform', `$1_ppc64')
+include_src(`powerpc64/p8/gcm-hash.asm')
diff --git a/powerpc64/p8/gcm-hash.asm b/powerpc64/p8/gcm-hash.asm
new file mode 100644
index 00000000..f987f2ca
--- /dev/null
+++ b/powerpc64/p8/gcm-hash.asm
@@ -0,0 +1,773 @@
+C powerpc64/p8/gcm-hash.asm
+
+ifelse(`
+   Copyright (C) 2020 Mamone Tarsha
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+')
+
+C Alignment of gcm_key table elements, which is declared in gcm.h
+define(`TableElemAlign', `0x100')
+
+C Register usage:
+
+define(`SP', `r1')
+define(`TOCP', `r2')
+
+define(`TABLE', `r3')
+define(`X', `r4')
+define(`LENGTH', `r5')
+define(`DATA', `r6')
+
+define(`zero', `v0')
+define(`swap_mask', `v1')
+define(`hidw_mask', `v2')
+define(`lodw_mask', `v3')
+define(`poly', `v4')
+define(`poly_h', `v4')
+define(`poly_l', `v5')
+define(`RP', `v6')
+define(`Mh', `v7')
+define(`Ml', `v8')
+define(`H', `v9')
+define(`Hh', `v10')
+define(`Hl', `v11')
+define(`RP2', `v9')
+define(`M2h', `v10')
+define(`M2l', `v11')
+
+define(`sl1', `v1')
+define(`msb', `v5')
+define(`H2', `v6')
+define(`H2h', `v7')
+define(`H2l', `v8')
+define(`H_h', `v12')
+define(`H_m', `v13')
+define(`H_l', `v14')
+define(`H_Hh', `v12')
+define(`H_H', `v13')
+define(`H_Hl', `v14')
+define(`H_t', `v15')
+define(`H2_h', `v16')
+define(`H2_m', `v17')
+define(`H2_l', `v18')
+define(`H2_t', `v19')
+
+define(`C0', `v6')
+define(`C1', `v7')
+define(`C2', `v8')
+define(`C3', `v12')
+define(`C4', `v6')
+define(`C5', `v7')
+define(`C6', `v8')
+define(`C7', `v12')
+
+define(`C', `v13')
+
+define(`Ch', `v14')
+define(`Cl', `v15')
+define(`Cm', `v16')
+
+define(`C01h', `v14')
+define(`C01l', `v15')
+define(`C01', `v16')
+define(`C23h', `v17')
+define(`C23l', `v18')
+define(`C23', `v19')
+define(`C45h', `v20')
+define(`C45l', `v21')
+define(`C45', `v22')
+define(`C67h', `v6')
+define(`C67l', `v7')
+define(`C67', `v8')
+
+define(`H21', `v9')
+define(`H21h', `v10')
+define(`H21l', `v11')
+define(`H43', `v23')
+define(`H43h', `v24')
+define(`H43l', `v25')
+define(`H65', `v26')
+define(`H65h', `v27')
+define(`H65l', `v28')
+define(`H87', `v29')
+define(`H87h', `v30')
+define(`H87l', `v31')
+
+.file "gcm-hash.asm"
+
+.text
+
+ # void gcm_init_key (union gcm_block *table)
+
+define(`FUNC_ALIGN', `5')
+PROLOGUE(_nettle_gcm_init_key)
+ DATA_LOAD_VEC(poly,.polynomial,r7)
+IF_LE(`DATA_LOAD_VEC(swap_mask,.swap_mask,r7)')
+ DATA_LOAD_VEC(hidw_mask,.hidw_mask,r7)
+ DATA_LOAD_VEC(lodw_mask,.lodw_mask,r7)
+
+ li    r10,8*TableElemAlign
+ lxvd2x VSR(H),r10,TABLE # load H
+IF_LE(`vperm H,H,H,swap_mask')
+
+ # --- calculate H = H shift left 1 modulo polynomial ---
+
+ vupkhsw    msb,H # most significant bit word-extend
+ vspltisb sl1,1 # splat 1 for shift left
+ vspltw      msb,msb,0 # most significant bit extend
+ vsl    H,H,sl1 # H shift left 1
+ vand msb,msb,poly
+ vxor zero,zero,zero
+ vxor H_t,H,msb
+
+ vsldoi H,H_t,H_t,8 # doubleword swap
+ vsldoi Hh,H,zero,8
+ vsldoi Hl,zero,H,8
+
+ # --- calculate H^2 = H*H ---
+
+ # reduction pre-processing
+ vsldoi poly_h,zero,poly,8
+ vsldoi poly_l,poly_h,poly_h,8
+
+ # polynomial multiplication "classical"
+ vpmsumd H_h,H_t,Hh # H^1h*H^1h
+ vpmsumd H_l,H_t,Hl # H^1l*H^1l
+ vpmsumd H_m,H_t,H # H^1h*H^1l⊕H^1l*H^1h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h   # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8   # [2]
+ vsldoi Ml,H_m,zero,8 # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor H_h,H_h,Mh       # [2]
+ vxor H_l,H_l,Ml       # [2]
+ vxor H_l,H_l,RP       # [1]
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l
+ vxor H_h,H_l,H_h
+ vxor H2_t,H_h,RP
+
+ vsldoi H2,H2_t,H2_t,8
+ vsldoi H2h,H2,zero,8
+ vsldoi H2l,zero,H2,8
+
+ # --- calculate [H^2.Hi⊕H^2.Lo:H^1.Hi⊕H^1.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store H,[H^2.Hi⊕H^2.Lo:H^1.Hi⊕H^1.Lo] ---
+
+ li    r8,0*TableElemAlign
+ li    r9,1*TableElemAlign
+ li    r10,2*TableElemAlign
+ stxvd2x VSR(Hl),r8,TABLE
+ stxvd2x VSR(H),r9,TABLE
+ stxvd2x VSR(Hh),r10,TABLE
+
+ li    r8,3*TableElemAlign
+ li    r9,4*TableElemAlign
+ li    r10,5*TableElemAlign
+ stxvd2x VSR(H_Hh),r8,TABLE
+ stxvd2x VSR(H_H),r9,TABLE
+ stxvd2x VSR(H_Hl),r10,TABLE
+
+ # --- calculate H^3,H^4 ---
+
+ # polynomial multiplication "classical"
+ vpmsumd H_l,H_t,H2l # H^1l*H^2l
+ vpmsumd H_m,H_t,H2 # H^1h*H^2l⊕H^1l*H^2h
+ vpmsumd H_h,H_t,H2h # H^1h*H^2h
+ vpmsumd H2_l,H2_t,H2l # H^2l*H^2l
+ vpmsumd H2_m,H2_t,H2 # H^2h*H^2l⊕H^2l*H^2h
+ vpmsumd H2_h,H2_t,H2h # H^2h*H^2h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h # [1] H^3
+ vpmsumd    RP2,H2_l,poly_h # [1] H^4
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8 # [2] H^3
+ vsldoi M2h,zero,H2_m,8 # [2] H^4
+ vsldoi Ml,H_m,zero,8 # [2] H^3
+ vsldoi M2l,H2_m,zero,8 # [2] H^4
+ vsldoi RP,RP,RP,8 # [1] H^3
+ vsldoi RP2,RP2,RP2,8 # [1] H^4
+ vxor H_h,H_h,Mh # [2] H^3
+ vxor H2_h,H2_h,M2h # [2] H^4
+ vxor H_l,H_l,Ml # [2] H^3
+ vxor H2_l,H2_l,M2l # [2] H^4
+ vxor H_l,H_l,RP # [1] H^3
+ vxor H2_l,H2_l,RP2 # [1] H^4
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l # H^3
+ vpmsumd RP2,H2_l,poly_l # H^4
+ vxor H_h,H_l,H_h # H^3
+ vxor H2_h,H2_l,H2_h # H^4
+ vxor H_h,H_h,RP # H^3
+ vxor H2_h,H2_h,RP2 # H^4
+
+ vsldoi H2,H2_h,H2_h,8 # H^4
+ vsldoi H,H_h,H_h,8 # H^3
+ vsldoi H2l,zero,H2,8 # H^4
+ vsldoi H2h,H2,zero,8 # H^4
+
+ # --- calculate [H^4.Hi⊕H^4.Lo:H^3.Hi⊕H^3.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store [H^4.Hi⊕H^4.Lo:H^3.Hi⊕H^3.Lo] ---
+
+ li    r8,6*TableElemAlign
+ li    r9,7*TableElemAlign
+ li    r10,8*TableElemAlign
+ stxvd2x VSR(H_Hh),r8,TABLE
+ stxvd2x VSR(H_H),r9,TABLE
+ stxvd2x VSR(H_Hl),r10,TABLE
+
+ # --- calculate H^5,H^6 ---
+
+ # polynomial multiplication "classical"
+ vpmsumd H_l,H_t,H2l # H^1l*H^4l
+ vpmsumd H_m,H_t,H2 # H^1h*H^4l⊕H^1l*H^4h
+ vpmsumd H_h,H_t,H2h # H^1h*H^4h
+ vpmsumd H2_l,H2_t,H2l # H^2l*H^4l
+ vpmsumd H2_m,H2_t,H2 # H^2h*H^4l⊕H^2l*H^4h
+ vpmsumd H2_h,H2_t,H2h # H^2h*H^4h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h # [1] H^5
+ vpmsumd    RP2,H2_l,poly_h # [1] H^6
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8 # [2] H^5
+ vsldoi M2h,zero,H2_m,8 # [2] H^6
+ vsldoi Ml,H_m,zero,8 # [2] H^5
+ vsldoi M2l,H2_m,zero,8 # [2] H^6
+ vsldoi RP,RP,RP,8 # [1] H^5
+ vsldoi RP2,RP2,RP2,8 # [1] H^6
+ vxor H_h,H_h,Mh # [2] H^5
+ vxor H2_h,H2_h,M2h # [2] H^6
+ vxor H_l,H_l,Ml # [2] H^5
+ vxor H2_l,H2_l,M2l # [2] H^6
+ vxor H_l,H_l,RP # [1] H^5
+ vxor H2_l,H2_l,RP2 # [1] H^6
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l # H^5
+ vpmsumd RP2,H2_l,poly_l # H^6
+ vxor H_h,H_l,H_h # H^5
+ vxor H2_h,H2_l,H2_h # H^6
+ vxor H_h,H_h,RP # H^5
+ vxor H2_h,H2_h,RP2 # H^6
+
+ vsldoi H2,H2_h,H2_h,8 # H^6
+ vsldoi H,H_h,H_h,8 # H^5
+ vsldoi H2l,zero,H2,8 # H^6
+ vsldoi H2h,H2,zero,8 # H^6
+
+ # --- calculate [H^6.Hi⊕H^6.Lo:H^5.Hi⊕H^5.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store [H^6.Hi⊕H^6.Lo:H^5.Hi⊕H^5.Lo] ---
+
+ li    r8,9*TableElemAlign
+ li    r9,10*TableElemAlign
+ li    r10,11*TableElemAlign
+ stxvd2x VSR(H_Hh),r8,TABLE
+ stxvd2x VSR(H_H),r9,TABLE
+ stxvd2x VSR(H_Hl),r10,TABLE
+
+ # --- calculate H^7,H^8 ---
+
+ # polynomial multiplication "classical"
+ vpmsumd H_l,H_t,H2l # H^1l*H^6l
+ vpmsumd H_m,H_t,H2 # H^1h*H^6l⊕H^1l*H^6h
+ vpmsumd H_h,H_t,H2h # H^1h*H^6h
+ vpmsumd H2_l,H2_t,H2l # H^2l*H^6l
+ vpmsumd H2_m,H2_t,H2 # H^2h*H^6l⊕H^2l*H^6h
+ vpmsumd H2_h,H2_t,H2h # H^2h*H^6h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h # [1] H^7
+ vpmsumd    RP2,H2_l,poly_h # [1] H^8
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8 # [2] H^7
+ vsldoi M2h,zero,H2_m,8 # [2] H^8
+ vsldoi Ml,H_m,zero,8 # [2] H^7
+ vsldoi M2l,H2_m,zero,8 # [2] H^8
+ vsldoi RP,RP,RP,8 # [1] H^7
+ vsldoi RP2,RP2,RP2,8 # [1] H^8
+ vxor H_h,H_h,Mh # [2] H^7
+ vxor H2_h,H2_h,M2h # [2] H^8
+ vxor H_l,H_l,Ml # [2] H^7
+ vxor H2_l,H2_l,M2l # [2] H^8
+ vxor H_l,H_l,RP # [1] H^7
+ vxor H2_l,H2_l,RP2 # [1] H^8
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l # H^7
+ vpmsumd RP2,H2_l,poly_l # H^8
+ vxor H_h,H_l,H_h # H^7
+ vxor H2_h,H2_l,H2_h # H^8
+ vxor H_h,H_h,RP # H^7
+ vxor H2_h,H2_h,RP2 # H^8
+
+ vsldoi H,H_h,H_h,8 # H^7
+ vsldoi H2,H2_h,H2_h,8 # H^8
+
+ # --- calculate [H^8.Hi⊕H^8.Lo:H^7.Hi⊕H^7.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store [H^8.Hi⊕H^8.Lo:H^7.Hi⊕H^7.Lo] ---
+
+ li    r8,12*TableElemAlign
+ li    r9,13*TableElemAlign
+ li    r10,14*TableElemAlign
+ stxvd2x VSR(H_Hh),r8,TABLE
+ stxvd2x VSR(H_H),r9,TABLE
+ stxvd2x VSR(H_Hl),r10,TABLE
+
+  blr
+EPILOGUE(_nettle_gcm_init_key)
+
+ # void gcm_hash (const struct gcm_key *key, union gcm_block *x,
+ #                size_t length, const uint8_t *data)
+
+define(`FUNC_ALIGN', `5')
+PROLOGUE(_nettle_gcm_hash)
+ vxor zero,zero,zero
+
+ DATA_LOAD_VEC(poly,.polynomial,r7)
+IF_LE(`DATA_LOAD_VEC(swap_mask,.swap_mask,r7)')
+ DATA_LOAD_VEC(hidw_mask,.hidw_mask,r7)
+ DATA_LOAD_VEC(lodw_mask,.lodw_mask,r7)
+
+ vsldoi poly_h,zero,poly,8
+ vsldoi poly_l,poly_h,poly_h,8
+
+ lxvd2x VSR(C),0,X # load X
+IF_LE(`vperm C,C,C,swap_mask')
+
+ srdi r7,LENGTH,7 # 8x loop count
+ cmpldi r7,0
+ beq L2x
+
+ # backup registers
+ stdu SP,-224(SP)
+ std r28,216(SP)
+ std r29,208(SP)
+ std r30,200(SP)
+ std r31,192(SP)
+    li 8,176
+    stvx 20,8,SP
+    subi 8,8,16
+    stvx 21,8,SP
+    subi 8,8,16
+    stvx 22,8,SP
+    subi 8,8,16
+    stvx 23,8,SP
+    subi 8,8,16
+    stvx 24,8,SP
+    subi 8,8,16
+    stvx 25,8,SP
+    subi 8,8,16
+    stvx 26,8,SP
+    subi 8,8,16
+    stvx 27,8,SP
+    subi 8,8,16
+    stvx 28,8,SP
+    subi 8,8,16
+    stvx 29,8,SP
+    subi 8,8,16
+    stvx 30,8,SP
+    subi 8,8,16
+    stvx 31,8,SP
+
+ # table loading
+ li r8,3*TableElemAlign
+ li r9,4*TableElemAlign
+ li r10,5*TableElemAlign
+ lxvd2x VSR(H21h),r8,TABLE
+ lxvd2x VSR(H21),r9,TABLE
+ lxvd2x VSR(H21l),r10,TABLE
+ li r8,6*TableElemAlign
+ li r9,7*TableElemAlign
+ li r10,8*TableElemAlign
+ lxvd2x VSR(H43h),r8,TABLE
+ lxvd2x VSR(H43),r9,TABLE
+ lxvd2x VSR(H43l),r10,TABLE
+ li r8,9*TableElemAlign
+ li r9,10*TableElemAlign
+ li r10,11*TableElemAlign
+ lxvd2x VSR(H65h),r8,TABLE
+ lxvd2x VSR(H65),r9,TABLE
+ lxvd2x VSR(H65l),r10,TABLE
+ li r8,12*TableElemAlign
+ li r9,13*TableElemAlign
+ li r10,14*TableElemAlign
+ lxvd2x VSR(H87h),r8,TABLE
+ lxvd2x VSR(H87),r9,TABLE
+ lxvd2x VSR(H87l),r10,TABLE
+
+ li r8,0x10
+ li r9,0x20
+ li r10,0x30
+ li r28,0x40
+ li r29,0x50
+ li r30,0x60
+ li r31,0x70
+
+ mtctr     r7
+.align 5
+L8x_loop:
+ # input loading
+ lxvd2x VSR(C0),0,DATA # load C0
+ lxvd2x VSR(C1),r8,DATA # load C1
+ lxvd2x VSR(C2),r9,DATA # load C2
+ lxvd2x VSR(C3),r10,DATA # load C3
+
+ # swap permuting
+IF_LE(`vperm C0,C0,C0,swap_mask
+ vperm C1,C1,C1,swap_mask
+ vperm C2,C2,C2,swap_mask
+ vperm C3,C3,C3,swap_mask')
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ # polynomial multiplication "karatsuba" pre-processing
+ vperm C23h,C2,C3,hidw_mask
+ vperm C23l,C2,C3,lodw_mask
+ vperm C01h,C0,C1,hidw_mask
+ vperm C01l,C0,C1,lodw_mask
+
+ # input loading
+ lxvd2x VSR(C4),r28,DATA # load C4
+ lxvd2x VSR(C5),r29,DATA # load C5
+ lxvd2x VSR(C6),r30,DATA # load C6
+ lxvd2x VSR(C7),r31,DATA # load C7
+
+ # swap permuting
+IF_LE(`vperm C4,C4,C4,swap_mask
+ vperm C5,C5,C5,swap_mask
+ vperm C6,C6,C6,swap_mask
+ vperm C7,C7,C7,swap_mask')
+
+ # polynomial multiplication "karatsuba" pre-processing
+ vperm C45h,C4,C5,hidw_mask
+ vperm C45l,C4,C5,lodw_mask
+ vperm C67h,C6,C7,hidw_mask
+ vperm C67l,C6,C7,lodw_mask
+ vxor C23,C23h,C23l
+ vxor C01,C01h,C01l
+ vxor C45,C45h,C45l
+ vxor C67,C67h,C67l
+
+ # polynomial multiplication "karatsuba"
+ vpmsumd C23h,C23h,H65h # H23 = H^6h*C2h⊕H^5h*C3h
+ vpmsumd C23l,C23l,H65l # L23 = H^6l*C2l⊕H^5l*C3l
+ vpmsumd C01h,C01h,H87h # H01 = H^8h*C0h⊕H^7h*C1h
+ vpmsumd C01l,C01l,H87l # L01 = H^8l*C0l⊕H^7l*C1l
+ vpmsumd C67h,C67h,H21h # H67 = H^2h*C6h⊕H^1h*C7h
+ vpmsumd C67l,C67l,H21l # L67 = H^2l*C6l⊕H^1l*C7l
+ vpmsumd C45h,C45h,H43h # H45 = H^4h*C4h⊕H^3h*C5h
+ vpmsumd C45l,C45l,H43l # L45 = H^4l*C4l⊕H^3l*C5l
+ vpmsumd C23,C23,H65 # M23 = (H^6h⊕H^5h)*(C2h⊕C3h)⊕(H^6l⊕H^5l)*(C2l⊕C3l)
+ vpmsumd C01,C01,H87 # M01 = (H^8h⊕H^7h)*(C0h⊕C1h)⊕(H^8l⊕H^7l)*(C0l⊕C1l)
+ vpmsumd C45,C45,H43 # M45 = (H^4h⊕H^3h)*(C4h⊕C5h)⊕(H^4l⊕H^3l)*(C4l⊕C5l)
+ vpmsumd C67,C67,H21 # M67 = (H^2h⊕H^1h)*(C6h⊕C7h)⊕(H^2l⊕H^1l)*(C6l⊕C7l)
+
+ # polynomial multiplication "karatsuba" post-processing
+ vxor C23,C23,C23h
+ vxor C01,C01,C01h
+ vxor C45,C45,C45h
+ vxor C67,C67,C67h
+ vxor C23,C23,C23l
+ vxor C01,C01,C01l
+ vxor C45,C45,C45l
+ vxor C67,C67,C67l
+
+ # deferred recombination of partial products
+ vxor C01h,C01h,C23h # H0 = H01⊕H23
+ vxor C45h,C45h,C67h # H1 = H45⊕H67
+ vxor C01l,C01l,C23l # L0 = L01⊕L23
+ vxor C45l,C45l,C67l # L1 = L45⊕L45
+ vxor C01,C01,C23 # M0 = M01⊕M23
+ vxor C45,C45,C67 # M1 = M45⊕M45
+ vxor C01h,C01h,C45h # H = H0⊕H1
+ vxor C01l,C01l,C45l # L = L0⊕L1
+ vxor C01,C01,C45 # M = M0⊕M1
+
+ # reduction first phase # [1]
+ vpmsumd RP,C01l,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,C01,8   # [2]
+ vsldoi Ml,C01,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor C01h,C01h,Mh     # [2]
+ vxor C01l,C01l,Ml     # [2]
+ vxor C01l,C01l,RP     # [1]
+
+ # reduction second phase
+ vpmsumd RP,C01l,poly_l
+ vxor C01h,C01l,C01h
+ vxor C,C01h,RP
+
+ addi DATA,DATA,0x80
+ bdnz L8x_loop
+
+    # restore registers
+ li 8,0
+    lvx 31,8,SP
+    addi 8,8,16
+    lvx 30,8,SP
+    addi 8,8,16
+    lvx 29,8,SP
+    addi 8,8,16
+    lvx 28,8,SP
+    addi 8,8,16
+    lvx 27,8,SP
+    addi 8,8,16
+    lvx 26,8,SP
+    addi 8,8,16
+    lvx 25,8,SP
+    addi 8,8,16
+    lvx 24,8,SP
+    addi 8,8,16
+    lvx 23,8,SP
+    addi 8,8,16
+    lvx 22,8,SP
+    addi 8,8,16
+    lvx 21,8,SP
+    addi 8,8,16
+    lvx 20,8,SP
+ ld r31,192(SP)
+ ld r30,200(SP)
+ ld r29,208(SP)
+ ld r28,216(SP)
+ addi SP,SP,224
+
+ clrldi   LENGTH,LENGTH,57
+L2x:
+ srdi r7,LENGTH,5
+ cmpldi r7,0
+ beq L1x
+
+ # table loading
+ li r8,3*TableElemAlign
+ li r9,4*TableElemAlign
+ li r10,5*TableElemAlign
+ lxvd2x VSR(H21h),r8,TABLE
+ lxvd2x VSR(H21),r9,TABLE
+ lxvd2x VSR(H21l),r10,TABLE
+
+ li r10,0x10
+
+ mtctr     r7
+.align 5
+L2x_loop:
+ # input loading
+ lxvd2x VSR(C0),0,DATA # load C0
+ lxvd2x VSR(C1),r10,DATA # load C1
+
+ # swap permuting
+IF_LE(`vperm C0,C0,C0,swap_mask
+ vperm C1,C1,C1,swap_mask')
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ # polynomial multiplication "karatsuba" pre-processing
+ vperm C01h,C0,C1,hidw_mask
+ vperm C01l,C0,C1,lodw_mask
+ vxor C01,C01h,C01l
+
+ # polynomial multiplication "karatsuba"
+ vpmsumd C01h,C01h,H21h # H01 = H^2h*C0h⊕H^1h*C1h
+ vpmsumd C01l,C01l,H21l # L01 = H^2l*C0l⊕H^1l*C1l
+ vpmsumd C01,C01,H21 # M01 = (H^2h⊕H^1h)*(C0h⊕C1h)⊕(H^2l⊕H^1l)*(C0l⊕C1l)
+
+ # polynomial multiplication "karatsuba" post-processing
+ vxor C01,C01,C01h
+ vxor C01,C01,C01l
+
+ # reduction first phase # [1]
+ vpmsumd RP,C01l,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,C01,8   # [2]
+ vsldoi Ml,C01,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor C01h,C01h,Mh     # [2]
+ vxor C01l,C01l,Ml     # [2]
+ vxor C01l,C01l,RP     # [1]
+
+ # reduction second phase
+ vpmsumd RP,C01l,poly_l
+ vxor C01h,C01l,C01h
+ vxor C,C01h,RP
+
+ addi DATA,DATA,0x20
+ bdnz L2x_loop
+
+ clrldi   LENGTH,LENGTH,59
+L1x:
+ srdi r7,LENGTH,4
+ cmpldi r7,0
+ beq Lrem
+
+ # table loading
+ li r9,1*TableElemAlign
+ li r10,2*TableElemAlign
+ lxvd2x VSR(Hl),0,TABLE
+ lxvd2x VSR(H), r9,TABLE
+ lxvd2x VSR(Hh),r10,TABLE
+
+ # input loading
+ lxvd2x VSR(C0),0,DATA # load C0
+
+ # swap permuting
+IF_LE(`vperm C0,C0,C0,swap_mask')
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ vpmsumd Cl,C0,Hl # L = Hl*Cl
+ vpmsumd Cm,C0,H # M = Hh*Cl⊕Hl*Ch
+ vpmsumd Ch,C0,Hh # H = Hh*Ch
+
+ # reduction first phase # [1]
+ vpmsumd RP,Cl,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,Cm,8   # [2]
+ vsldoi Ml,Cm,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor Ch,Ch,Mh   # [2]
+ vxor Cl,Cl,Ml       # [2]
+ vxor Cl,Cl,RP   # [1]
+
+ # reduction second phase
+ vpmsumd RP,Cl,poly_l
+ vxor Ch,Cl,Ch
+ vxor C,Ch,RP
+
+ addi DATA,DATA,0x10
+ clrldi   LENGTH,LENGTH,60
+Lrem:
+ cmpldi LENGTH,0
+ beq Ldone
+
+ # table loading
+ li r9,1*TableElemAlign
+ li r10,2*TableElemAlign
+ lxvd2x VSR(Hl),0,TABLE
+ lxvd2x VSR(H), r9,TABLE
+ lxvd2x VSR(Hh),r10,TABLE
+
+ # input loading
+ stdu SP,-16(SP)
+ stvx zero,0,SP
+Lst_loop:
+ subic.      LENGTH,LENGTH,1
+ lbzx r7,LENGTH,DATA
+ stbx r7,LENGTH,SP
+ bne Lst_loop
+ lxvd2x   VSR(C0),0,SP
+ addi SP,SP,16
+
+ # swap permuting
+IF_LE(`vperm C0,C0,C0,swap_mask')
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ vpmsumd Cl,C0,Hl # L = Hl*Cl
+ vpmsumd Cm,C0,H # M = Hh*Cl⊕Hl*Ch
+ vpmsumd Ch,C0,Hh # H = Hh*Ch
+
+ # reduction first phase # [1]
+ vpmsumd RP,Cl,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,Cm,8   # [2]
+ vsldoi Ml,Cm,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor Ch,Ch,Mh   # [2]
+ vxor Cl,Cl,Ml     # [2]
+ vxor Cl,Cl,RP   # [1]
+
+ # reduction second phase
+ vpmsumd RP,Cl,poly_l
+ vxor Ch,Cl,Ch
+ vxor C,Ch,RP
+
+Ldone:
+IF_LE(`vperm C,C,C,swap_mask')
+ stxvd2x VSR(C),0,X # store C
+ blr
+EPILOGUE(_nettle_gcm_hash)
+
+    .data
+IF_LE(`.align 4
+.polynomial:
+ .byte 1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0xc2
+    .align 4
+.swap_mask:
+ .byte 8,9,10,11,12,13,14,15,0,1,2,3,4,5,6,7
+    .align 4
+.hidw_mask:
+ .byte 23,22,21,20,19,18,17,16,7,6,5,4,3,2,1,0
+    .align 4
+.lodw_mask:
+ .byte 31,30,29,28,27,26,25,24,15,14,13,12,11,10,9,8')
+IF_BE(`.align 4
+.polynomial:
+ .byte 0xc2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
+    .align 4
+.hidw_mask:
+ .byte 0,1,2,3,4,5,6,7,16,17,18,19,20,21,22,23
+    .align 4
+.lodw_mask:
+ .byte 8,9,10,11,12,13,14,15,24,25,26,27,28,29,30,31')

-- 
2.17.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200927192532</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-09-27 19:25:32-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" GCM support</subject><body>

  gcm_fill() got C optimization which performs close to the one I
implemented using altivec, the altivec version of gcm_fill has been wiped
now.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200928052432</emailId><senderName>Amos Jeffries</senderName><senderEmail>squid3@treenet.co.nz</senderEmail><timestampReceived>2020-09-28 05:24:32-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" GCM support</subject><body>

On 28/09/20 8:25 am, Maamoun TK wrote:
&gt;   gcm_fill() got C optimization which performs close to the one I

What do you mean by "close"?
  faster or slower?
  and it that difference consistent?

If the other implementation is slower (even by a few nanosec) it can be
useful keeping this fast code around for builds where high-performance
is critical.


AYJ
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200928133326</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-09-28 13:33:26-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" GCM support</subject><body>

I posted a performance test here
https://lists.lysator.liu.se/pipermail/nettle-bugs/2020/009169.html
Personally, I prefer keeping the altivec version in nettle library since
it's faster than C implementation but I'm not sure whether the performance
margin fits with the library's convention of optimizing such functions.

On Mon, Sep 28, 2020 at 8:40 AM Amos Jeffries &lt;squid3@treenet.co.nz&gt; wrote:

&gt; On 28/09/20 8:25 am, Maamoun TK wrote:
&gt; &gt;   gcm_fill() got C optimization which performs close to the one I
&gt;
&gt; What do you mean by "close"?
&gt;   faster or slower?
&gt;   and it that difference consistent?
&gt;
&gt; If the other implementation is slower (even by a few nanosec) it can be
&gt; useful keeping this fast code around for builds where high-performance
&gt; is critical.
&gt;
&gt;
&gt; AYJ
&gt; _______________________________________________
&gt; nettle-bugs mailing list
&gt; nettle-bugs@lists.lysator.liu.se
&gt; http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200924194618</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-09-24 19:46:18-0400</timestampReceived><subject>PPC chacha</subject><body>

I'm trying to learn a bit of ppc assembly. Below is an implementation of
_chacha_core. Seems to work, when tested on gcc112.fsffrance.org (just
put the file in the powerpc64 directory and reconfigure). This machine
is little-endian, I haven't yet tested on big-endian.

Unfortunately I don't get any accurate benchmark numbers on that
machine, but I think speedup may be on the order of 50%. It could likely
be speedup further by processing 2, 3 or 4 blocks in parallel, similar to
recent improvements for arm and x86_64. I'd like to do that after the
simpler single-block function is properly merged.

I'm not sure where it fits under powerpc64. The code doesn't need any
cryptographic extensions, but it depends on vector instructions as well
as VSX registers (for the unaligned load and store instructions). So I'd
need advice both on the directory hierarchy and compile time
configuration, and appropriate runtime tests for fat builds.

Comments on the code highly appreciated! It's the first ppc code I've
written, and the reference manual isn't that easy to navigate. The
vector instructions seem very nice to work with, and makes for a shorter
QROUND than both x86_64 SSE and ARM Neon (these suffer a bit from
missing vector rotate instruction).

Help with additional benchmarking would also be useful.

Regards,
/Niels

C powerpc64/chacha-core-internal.asm

ifelse(`
   Copyright (C) 2020 Niels Möller and Torbjörn Granlund
   This file is part of GNU Nettle.

   GNU Nettle is free software: you can redistribute it and/or
   modify it under the terms of either:

     * the GNU Lesser General Public License as published by the Free
       Software Foundation; either version 3 of the License, or (at your
       option) any later version.

   or

     * the GNU General Public License as published by the Free
       Software Foundation; either version 2 of the License, or (at your
       option) any later version.

   or both in parallel, as here.

   GNU Nettle is distributed in the hope that it will be useful,
   but WITHOUT ANY WARRANTY; without even the implied warranty of
   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
   General Public License for more details.

   You should have received copies of the GNU General Public License and
   the GNU Lesser General Public License along with this program.  If
   not, see http://www.gnu.org/licenses/.
')

C Register usage:

C Argments
define(`DST', `r3')
define(`SRC', `r4')
define(`ROUNDS', `r5')

C Working state
define(`X0', `v0')
define(`X1', `v1')
define(`X2', `v2')
define(`X3', `v3')
	
define(`ROT16', `v4')
define(`ROT12', `v5')
define(`ROT8',  `v6')
define(`ROT7',  `v7')

C Original input state
define(`S0', `v8')
define(`S1', `v9')
define(`S2', `v10')
define(`S3', `v11')

C QROUND(X0, X1, X2, X3)
define(`QROUND', `
	C x0 += x1, x3 ^= x0, x3 lrot 16
	C x2 += x3, x1 ^= x2, x1 lrot 12
	C x0 += x1, x3 ^= x0, x3 lrot 8
	C x2 += x3, x1 ^= x2, x1 lrot 7

	vadduwm $1, $1, $2
	vxor	$4, $4, $1
	vrlw	$4, $4, ROT16

	vadduwm $3, $3, $4
	vxor	$2, $2, $3
	vrlw	$2, $2, ROT12

	vadduwm $1, $1, $2
	vxor	$4, $4, $1
	vrlw	$4, $4, ROT8

	vadduwm $3, $3, $4
	vxor	$2, $2, $3
	vrlw	$2, $2, ROT7
')

	.text
	.align 4
	C _chacha_core(uint32_t *dst, const uint32_t *src, unsigned rounds)

PROLOGUE(_nettle_chacha_core)

	li	r6, 0x10	C set up some...
	li	r7, 0x20	C ...useful...
	li	r8, 0x30	C ...offsets

	vspltisw ROT16, -16	C -16 instead of 16 actually works!
	vspltisw ROT12, 12
	vspltisw ROT8, 8
	vspltisw ROT7, 7

	lxvw4x	VSR(X0), 0, SRC
	lxvw4x	VSR(X1), r6, SRC
	lxvw4x	VSR(X2), r7, SRC
	lxvw4x	VSR(X3), r8, SRC

	vor	S0, X0, X0
	vor	S1, X1, X1
	vor	S2, X2, X2
	vor	S3, X3, X3

	srdi	ROUNDS, ROUNDS, 1
	mtctr	ROUNDS

.Loop:
	QROUND(X0, X1, X2, X3)
	C Rotate rows, to get
	C	 0  1  2  3
	C	 5  6  7  4  &lt;&lt;&lt; 1
	C	10 11  8  9  &lt;&lt;&lt; 2
	C	15 12 13 14  &lt;&lt;&lt; 3

	vsldoi	X1, X1, X1, 4
	vsldoi	X2, X2, X2, 8
	vsldoi	X3, X3, X3, 12

	QROUND(X0, X1, X2, X3)

	C Inverse rotation	
	vsldoi	X1, X1, X1, 12
	vsldoi	X2, X2, X2, 8
	vsldoi	X3, X3, X3, 4

        bdnz    .Loop

	vadduwm	X0, X0, S0
	vadduwm	X1, X1, S1
	vadduwm	X2, X2, S2
	vadduwm	X3, X3, S3

	stxvw4x	VSR(X0), 0, DST
	stxvw4x	VSR(X1), r6, DST
	stxvw4x	VSR(X2), r7, DST
	stxvw4x	VSR(X3), r8, DST

	blr
EPILOGUE(_nettle_chacha_core)

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200924204135</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-09-24 20:41:35-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

On Thu, Sep 24, 2020 at 3:46 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; I'm trying to learn a bit of ppc assembly. Below is an implementation of
&gt; _chacha_core. Seems to work, when tested on gcc112.fsffrance.org (just
&gt; put the file in the powerpc64 directory and reconfigure). This machine
&gt; is little-endian, I haven't yet tested on big-endian.
&gt;
&gt; Unfortunately I don't get any accurate benchmark numbers on that
&gt; machine, but I think speedup may be on the order of 50%...

Yeah, getting accurate benchmark results is difficult on the compile
farm. First, you need to moves the machines into performance mode but
you can't because you're not an admin. (A script like
https://github.com/weidai11/cryptopp/blob/master/TestScripts/governor.sh
will do if you are admin).

Second, the ISA seems to produce random looking benchmark results.
I've never been able to identify good access patterns to produce
consistent results. Part of this problem may be powersave mode. Part
of it may be mistakes on my part.

Third, to develop somewhat consistent benchmark statistics, repeat the
benchmark several times and discard the outliers. I discard both low-
and high-outliers. (The low- outliers may be valid, but I discard them
anyway).

Also see "GCC135/Power9 performance?",
https://lists.tetaneutral.net/pipermail/cfarm-users/2020-April/000556.html.
Andy Polyakov joins the conversation and provides his insights.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200819194652</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-08-19 19:46:52-0400</timestampReceived><subject>Re: [PATCH 4/6] "PowerPC64" Add fat build</subject><body>

Hi, I've been busy and silent for a while. 

I was thinking, that I don't want to merge to master with
--enable-power-crypto-ext enabled by default. And then we really need
fat builds to have easy ci testing.

So I'm applying the AES-parts of this patch, to try to get fat builds
working as soon as possible.

Another question: When looking at the powerpc64 things in configure.ac,
I wonder if powerpc64 supports 32-bit binaries, which would be built
with something like CC='gcc -m32' ? 

If 32-bit builds are possible, and are incompatible with the assembly
files, we need to add an ABI check similar to the one for x86_64 and
sparc, and add powerpc64 to asm_path only for ABI=64.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200819214204</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-08-19 21:42:04-0400</timestampReceived><subject>Re: [PATCH 4/6] "PowerPC64" Add fat build</subject><body>

On Wed, Aug 19, 2020 at 10:46 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Hi, I've been busy and silent for a while.
&gt;
&gt; I was thinking, that I don't want to merge to master with
&gt; --enable-power-crypto-ext enabled by default. And then we really need
&gt; fat builds to have easy ci testing.
&gt;
&gt; So I'm applying the AES-parts of this patch, to try to get fat builds
&gt; working as soon as possible.
&gt;
&gt;
Great. Thank you for your work.


&gt; Another question: When looking at the powerpc64 things in configure.ac,
&gt; I wonder if powerpc64 supports 32-bit binaries, which would be built
&gt; with something like CC='gcc -m32' ?
&gt;
&gt; If 32-bit builds are possible, and are incompatible with the assembly
&gt; files, we need to add an ABI check similar to the one for x86_64 and
&gt; sparc, and add powerpc64 to asm_path only for ABI=64.
&gt;

Right, I missed the '-m32' thing. I will add the ABI check to configure.ac

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200801114339</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-08-01 11:43:39-0400</timestampReceived><subject>[Patch] "PowerPC64" Add README (Reformatted)</subject><body>

---
 powerpc64/README | 73
++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 73 insertions(+)
 create mode 100644 powerpc64/README

diff --git a/powerpc64/README b/powerpc64/README
new file mode 100644
index 00000000..19351be8
--- /dev/null
+++ b/powerpc64/README
@@ -0,0 +1,73 @@
+General-Purpose Register Conventions
+
+Register Status Use
+
+GPR0 volatile In function prologs.
+GPR1 dedicated Stack pointer.
+GPR2 dedicated Table of Contents (TOC) pointer.
+GPR3 volatile First word of a function's argument list;
+ first word of a scalar function return.
+GPR4 volatile Second word of a function's argument list;
+ second word of a scalar function return.
+GPR5 volatile Third word of a function's argument list.
+GPR6 volatile Fourth word of a function's argument list.
+GPR7 volatile Fifth word of a function's argument list.
+GPR8 volatile Sixth word of a function's argument list.
+GPR9 volatile Seventh word of a function's argument list.
+GPR10 volatile Eighth word of a function's argument list.
+GPR11 volatile In calls by pointer and as an environment pointer
+ for languages that require it (for example, PASCAL).
+GPR12 volatile For special exception handling required by certain
+ languages and in glink code.
+GPR13 reserved Reserved under 64-bit environment;
+ not restored across system calls.
+GPR14:GPR31 nonvolatile These registers must be preserved across
+ a function call.
+
+Vector Register Conventions
+
+Register Status
+
+VR0:V19 Volatile
+VR20:VR31 Nonvolatile (extended ABI mode) their values are preserved
+ across function calls
+
+Addressing memory
+
+There are many ways to reference data, in the sake of writing
+position-independent code the current implementation uses GOT-indirect
+addressing (Accessing data through the global offset table):
+1. Define data in .data section
+2. Load the address of data into register from the global offset table
+   e.g. ld 7, my_var@got(2)
+3. Use the address to load the value of data into register
+   e.g. ld 3, 0(7)
+Refer to [2] for more information about referencing data
+
+VSX instructions "lxvd2x/stxvd2x" are used to load and store data to
+memory instead of VR instructions "lvx/stvx" as it produces a fewer
+instructions "lvx/stvx" can be used to load/store data into storage
+operands but additional instructions are needed to access unaligned
+storage operands, refer to "6.4.1 Accessing Unaligned Storage Operands"
+in [3] to see an example of accessing unaligned storage operands.
+"lxvd2x/stxvd2x" can be used to load/store data into unaligned storage
+operands but permuting is needed for loading and storing data in
+little-endian mode VSX registers are defined with "X" suffix
+TODO: use architecture 3.0 instructions "lxv/stxv" instead for POWER9
+      and newer
+
+Function Prologue
+
+Big-endian systems only support ELFv1 ABI which requires the following
+steps in the function prologue:
+1. Write the "official procedure descriptor" in ".opd","aw" section
+2. Write procedure description for .my_func in my_func label
+3. Switch back to ".text" section for program code
+4. Label the beginning of the code .my_func
+Refer to [1] for more information
+Little-endian systems are compatible with ELFv2 ABI, an example of
+function prologue for ELFv2 ABI can be seen in [2]
+
+[1] http://www.ibm.com/developerworks/linux/library/l-powasm1.html
+[2]
https://openpowerfoundation.org/?resource_lib=64-bit-elf-v2-abi-specification-power-architecture
+[3]
https://openpowerfoundation.org/?resource_lib=ibm-power-isa-version-2-07-b
-- 
2.17.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200802181203</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-08-02 18:12:03-0400</timestampReceived><subject>Re: [Patch] "PowerPC64" Add README (Reformatted)</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; ---
&gt;  powerpc64/README | 73
&gt; ++++++++++++++++++++++++++++++++++++++++++++++++++++++++
&gt;  1 file changed, 73 insertions(+)
&gt;  create mode 100644 powerpc64/README

Merged to the power-asm-wip branch (there were still some improper line
breaks on the url-lines at the end; I had to edit a little before git am
was happy with it). And I did the P8 -&gt; p8 rename. If the ci tests work
out fine, I'll merge to the master branch, and we can continue from
there.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200802182643</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-08-02 18:26:43-0400</timestampReceived><subject>Re: [Patch] "PowerPC64" Add README (Reformatted)</subject><body>

On Sun, Aug 2, 2020 at 2:12 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt; ---
&gt; &gt;  powerpc64/README | 73
&gt; &gt; ++++++++++++++++++++++++++++++++++++++++++++++++++++++++
&gt; &gt;  1 file changed, 73 insertions(+)
&gt; &gt;  create mode 100644 powerpc64/README
&gt;
&gt; Merged to the power-asm-wip branch (there were still some improper line
&gt; breaks on the url-lines at the end; I had to edit a little before git am
&gt; was happy with it). And I did the P8 -&gt; p8 rename. If the ci tests work
&gt; out fine, I'll merge to the master branch, and we can continue from
&gt; there.

I'm not sure what you plan on doing with POWER9, but the POWER8 AES
sources will be fine for POWER9.

POWER9 adds the DARN random number generator. DARN is like RDRAND or
RDSEED. You can ask for a conditioned or unconditioned word. The rng
is not available on POWER8.

See the POWER ISA 3.0 specification, p. 78.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200802185321</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-08-02 18:53:21-0400</timestampReceived><subject>Re: [Patch] "PowerPC64" Add README (Reformatted)</subject><body>

Thanks for the info, I'll take a look.

Regards,
Mamone

On Sun, Aug 2, 2020 at 9:27 PM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:

&gt; On Sun, Aug 2, 2020 at 2:12 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt; &gt;
&gt; &gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt; &gt;
&gt; &gt; &gt; ---
&gt; &gt; &gt;  powerpc64/README | 73
&gt; &gt; &gt; ++++++++++++++++++++++++++++++++++++++++++++++++++++++++
&gt; &gt; &gt;  1 file changed, 73 insertions(+)
&gt; &gt; &gt;  create mode 100644 powerpc64/README
&gt; &gt;
&gt; &gt; Merged to the power-asm-wip branch (there were still some improper line
&gt; &gt; breaks on the url-lines at the end; I had to edit a little before git am
&gt; &gt; was happy with it). And I did the P8 -&gt; p8 rename. If the ci tests work
&gt; &gt; out fine, I'll merge to the master branch, and we can continue from
&gt; &gt; there.
&gt;
&gt; I'm not sure what you plan on doing with POWER9, but the POWER8 AES
&gt; sources will be fine for POWER9.
&gt;
&gt; POWER9 adds the DARN random number generator. DARN is like RDRAND or
&gt; RDSEED. You can ask for a conditioned or unconditioned word. The rng
&gt; is not available on POWER8.
&gt;
&gt; See the POWER ISA 3.0 specification, p. 78.
&gt;
&gt; Jeff
&gt; _______________________________________________
&gt; nettle-bugs mailing list
&gt; nettle-bugs@lists.lysator.liu.se
&gt; http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200829131418</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-08-29 13:14:18-0400</timestampReceived><subject>Re: [Patch] "PowerPC64" Add README (Reformatted)</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; Merged to the power-asm-wip branch (there were still some improper line
&gt; breaks on the url-lines at the end; I had to edit a little before git am
&gt; was happy with it). And I did the P8 -&gt; p8 rename. If the ci tests work
&gt; out fine, I'll merge to the master branch, and we can continue from
&gt; there.

Merged to master now. So this branch now includes fat setup and the AES
implementation. I'm also testing the ABI fix (I did it slightly
differently, applying only to powerpc64) on the master-updates branch.

Please try it out, in particular, check that it still gives the expected
performance improvement.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200819220649</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-08-19 22:06:49-0400</timestampReceived><subject>Re: [PATCH 4/6] "PowerPC64" Add fat build</subject><body>

On Wed, Aug 19, 2020 at 5:42 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt; wrote:
&gt; ...
&gt; &gt; Another question: When looking at the powerpc64 things in configure.ac,
&gt; &gt; I wonder if powerpc64 supports 32-bit binaries, which would be built
&gt; &gt; with something like CC='gcc -m32' ?
&gt; &gt;
&gt; &gt; If 32-bit builds are possible, and are incompatible with the assembly
&gt; &gt; files, we need to add an ABI check similar to the one for x86_64 and
&gt; &gt; sparc, and add powerpc64 to asm_path only for ABI=64.
&gt; &gt;
&gt;
&gt; Right, I missed the '-m32' thing. I will add the ABI check to configure.ac

You might want to check this. In practice I don't believe 32-bit ABIs
are supported on the 64-bit iron.

I don't recall if the Linux ABI supports 32-bit on these machines. I
thought Steven Monroe said something about this (i.e., not supported),
but I cannot find it in my inbox.

If the ABI does specify a 32-bit interface, then GCC does not support
it. Here's from GCC112 on the compile farm. GCC112 offers GCC 4.8 and
GCC 8.3.

# GCC 4.8
$ gcc -m32 test.c -o test
In file included from /usr/include/features.h:399:0,
                 from /usr/include/stdint.h:25,
                 from
/usr/lib/gcc/ppc64le-redhat-linux/4.8.5/include/stdint.h:9,
                 from test.c:1:
/usr/include/gnu/stubs.h:8:27: fatal error: gnu/stubs-32.h: No such
file or directory
 # include &lt;gnu/stubs-32.h&gt;

# GCC 8.3
gcc112:~$ /opt/at12.0/bin/gcc -m32 test.c -o test
cc1: error: ‘-m32' not supported in this configuration

I don't know what Clang offers.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200820054449</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-08-20 05:44:49-0400</timestampReceived><subject>Re: [PATCH 4/6] "PowerPC64" Add fat build</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; If the ABI does specify a 32-bit interface, then GCC does not support
&gt; it. Here's from GCC112 on the compile farm. GCC112 offers GCC 4.8 and
&gt; GCC 8.3.
&gt;
&gt; # GCC 4.8
&gt; $ gcc -m32 test.c -o test
&gt; In file included from /usr/include/features.h:399:0,
&gt;                  from /usr/include/stdint.h:25,
&gt;                  from
&gt; /usr/lib/gcc/ppc64le-redhat-linux/4.8.5/include/stdint.h:9,
&gt;                  from test.c:1:
&gt; /usr/include/gnu/stubs.h:8:27: fatal error: gnu/stubs-32.h: No such
&gt; file or directory
&gt;  # include &lt;gnu/stubs-32.h&gt;
&gt;
&gt; # GCC 8.3
&gt; gcc112:~$ /opt/at12.0/bin/gcc -m32 test.c -o test
&gt; cc1: error: ‘-m32' not supported in this configuration

I'm not familiar with how redhat packages gcc, but on debian, the plain
gcc package supports only the default (64-bit abi), and one has to
install a separate gcc-multilib package to get headers and libraries
needed for building 32-bit (and x32, on x86_64) binaries.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200925114314</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-09-25 11:43:14-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

&gt;
&gt;
&gt; I'm trying to learn a bit of ppc assembly. Below is an implementation of
&gt; _chacha_core. Seems to work, when tested on gcc112.fsffrance.org (just
&gt; put the file in the powerpc64 directory and reconfigure). This machine
&gt; is little-endian, I haven't yet tested on big-endian.
&gt;

Great work. The implementation looks fine, I like the idea of using -16
instead of 16 for rotating because vspltisw is limited to (-16 to 15)
and vrlw picks the low-order 5 bits which is the same for both -16 and 16.
BTW this implementation should work as is on big-endian mode without any
hassle because lxvw4x/stxvw4x are endianness aware of loading/storing word
values.


&gt; Unfortunately I don't get any accurate benchmark numbers on that
&gt; machine, but I think speedup may be on the order of 50%. It could likely
&gt; be speedup further by processing 2, 3 or 4 blocks in parallel, similar to
&gt; recent improvements for arm and x86_64. I'd like to do that after the
&gt; simpler single-block function is properly merged.
&gt;

I can benchmark the optimized core but it could take me a few days to get
it done, you may want to try Unicamp Minicloud
https://openpower.ic.unicamp.br/minicloud or POWER Cloud at OSU
http://osuosl.org/services/powerdev
Unicamp Minicloud offer good POWER instances and would approve your request
in two days.


&gt;
&gt; I'm not sure where it fits under powerpc64. The code doesn't need any
&gt; cryptographic extensions, but it depends on vector instructions as well
&gt; as VSX registers (for the unaligned load and store instructions). So I'd
&gt; need advice both on the directory hierarchy and compile time
&gt; configuration, and appropriate runtime tests for fat builds.


The VSX instructions are introduced in Power ISA v.2.06 so since you have
used VSX instructions lxvw4x/stxvw4x the minimum processor you are
targeting is POWER7
We can add new config option like "--enable-power-vsx" that enable this
optimization.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200925115704</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-09-25 11:57:04-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

On Fri, Sep 25, 2020 at 7:43 AM Maamoun TK &lt;maamoun.tk@googlemail.com&gt; wrote:
&gt; ...
&gt; &gt; I'm not sure where it fits under powerpc64. The code doesn't need any
&gt; &gt; cryptographic extensions, but it depends on vector instructions as well
&gt; &gt; as VSX registers (for the unaligned load and store instructions). So I'd
&gt; &gt; need advice both on the directory hierarchy and compile time
&gt; &gt; configuration, and appropriate runtime tests for fat builds.
&gt;
&gt; The VSX instructions are introduced in Power ISA v.2.06 so since you have
&gt; used VSX instructions lxvw4x/stxvw4x the minimum processor you are
&gt; targeting is POWER7
&gt; We can add new config option like "--enable-power-vsx" that enable this
&gt; optimization.

I believe the 64-bit adds (addudm) and subtracts (subudm) require
POWER8. POWER7 provides vector unsigned long long (and friends) and
the 64-bit loads, but you need POWER8 to do something useful with
them.

Or, the 64-bit adds can be performed manually using vector unsigned
int with code to manage carry or borrow. It allows you to drop back to
POWER4. ChaCha20 is still profitable.

typedef vector unsigned int uint32x4_p;

inline uint32x4_p VecAdd64(const uint32x4_p vec1, const uint32x4_p vec2)
{
    // The carry mask selects carrys for elements 1 and 3 and sets
    // remaining elements to 0. The results is then shifted so the
    // carried values are added to elements 0 and 2.
#if defined(NETTLE_BIG_ENDIAN)
    const uint32x4_p zero = {0, 0, 0, 0};
    const uint32x4_p mask = {0, 1, 0, 1};
#else
    const uint32x4_p zero = {0, 0, 0, 0};
    const uint32x4_p mask = {1, 0, 1, 0};
#endif

    uint32x4_p cy = vec_addc(vec1, vec2);
    uint32x4_p res = vec_add(vec1, vec2);
    cy = vec_and(mask, cy);
    cy = vec_sld (cy, zero, 4);
    return vec_add(res, cy);
#endif
}

Here's the core of a subtract:

    uint32x4_p bw = vec_subc(vec1, vec2);
    uint32x4_p res = vec_sub(vec1, vec2);
    bw = vec_andc(mask, bw);
    bw = vec_sld (bw, zero, 4);
    return vec_sub(res, bw);

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200925142458</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-09-25 14:24:58-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; I believe the 64-bit adds (addudm) and subtracts (subudm) require
&gt; POWER8.

I don't think there are any 64-bit adds in my chacha code, only 32-bit,
vadduwm. The chacha state is fundamentally 16 32-bit words, with
operations very friendly to 4-way simd.

Using 64-bit adds might be useful for later code doing multiple blocks,
for updating the counter (for the original 64-bit counter variant of
chacha). Might make sense to do manual carry handling to keep it working
on power7.

So it would make sense to add the code to a new directory powerpc64/p7/ ?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200925143155</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-09-25 14:31:55-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

Yes, it would make sense.

On Fri, Sep 25, 2020 at 5:25 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Jeffrey Walton &lt;noloader@gmail.com&gt; writes:
&gt;
&gt; &gt; I believe the 64-bit adds (addudm) and subtracts (subudm) require
&gt; &gt; POWER8.
&gt;
&gt; I don't think there are any 64-bit adds in my chacha code, only 32-bit,
&gt; vadduwm. The chacha state is fundamentally 16 32-bit words, with
&gt; operations very friendly to 4-way simd.
&gt;
&gt; Using 64-bit adds might be useful for later code doing multiple blocks,
&gt; for updating the counter (for the original 64-bit counter variant of
&gt; chacha). Might make sense to do manual carry handling to keep it working
&gt; on power7.
&gt;
&gt; So it would make sense to add the code to a new directory powerpc64/p7/ ?
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt; _______________________________________________
&gt; nettle-bugs mailing list
&gt; nettle-bugs@lists.lysator.liu.se
&gt; http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200925150414</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-09-25 15:04:14-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

On Fri, Sep 25, 2020 at 10:25 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; Jeffrey Walton &lt;noloader@gmail.com&gt; writes:
&gt;
&gt; &gt; I believe the 64-bit adds (addudm) and subtracts (subudm) require
&gt; &gt; POWER8.
&gt;
&gt; I don't think there are any 64-bit adds in my chacha code, only 32-bit,
&gt; vadduwm. The chacha state is fundamentally 16 32-bit words, with
&gt; operations very friendly to 4-way simd.
&gt;
&gt; Using 64-bit adds might be useful for later code doing multiple blocks,
&gt; for updating the counter (for the original 64-bit counter variant of
&gt; chacha). Might make sense to do manual carry handling to keep it working
&gt; on power7.

I hope I'm not crossing my wires, but doesn't ChaCha core require a
counter addition? That's where a 32-bit wrap can occur, and you need a
64-bit add to handle it correctly. That happens at x[12] and x[13] in
Berstein's source code.[1]

Track the use of the PLUSONE macro in Bernstein's code. The
'!x-&gt;input[12]' is the test for wrap on a 32-bit unsigned integer.

    x-&gt;input[12] = PLUSONE(x-&gt;input[12]);
    if (!x-&gt;input[12]) {
      x-&gt;input[13] = PLUSONE(x-&gt;input[13]);
      /* stopping at 2^70 bytes per nonce is user's responsibility */
    }

It should be easy enough to test. Start with a counter of 0xfffffff8
and encrypt a couple of [64-byte] blocks. You can use Bernstein's
reference implementation to generate test vectors.[1]

Here's a hacked version of Bernstein's code that allows you to set the
counter to something other than 0's:
https://github.com/noloader/cryptopp-test/blob/master/ChaCha20/chacha.c.
See the XXX_ctr_setup function.

There are some fundamental differences between Bernstein's ChaCha and
the IETF's ChaCha used in TLS. Bernstein's ChaCha uses a 64-bit
counter. The IETF's version uses a 32-bit counter, and the IETF fails
to specify what happens when their 32-bit version wraps. Be sure to
specify which version Nettle is providing in the docs because it leads
to confusion for users.

[1] https://cr.yp.to/chacha.html and
https://cr.yp.to/streamciphers/timings/estreambench/submissions/salsa20/chacha8/regs/chacha.c.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200925155524</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-09-25 15:55:24-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

On Fri, Sep 25, 2020 at 11:04 AM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:
&gt;
&gt; On Fri, Sep 25, 2020 at 10:25 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt; &gt;
&gt; &gt; Jeffrey Walton &lt;noloader@gmail.com&gt; writes:
&gt; &gt; ...
&gt; It should be easy enough to test. Start with a counter of 0xfffffff8
&gt; and encrypt a couple of [64-byte] blocks. You can use Bernstein's
&gt; reference implementation to generate test vectors.[1]

My bad. Start with a counter of 0xfffffff8 and encrypt or decrypt
16*64 bytes. That will get you into the corner case.

&gt; Here's a hacked version of Bernstein's code that allows you to set the
&gt; counter to something other than 0's:
&gt; https://github.com/noloader/cryptopp-test/blob/master/ChaCha20/chacha.c.
&gt; See the XXX_ctr_setup function.

While not obvious, setting the counter is how you seek in the ChaCha
stream. It allows you to encrypt or decrypt an arbitrary block of
64-bytes.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200925171433</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-09-25 17:14:33-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; I hope I'm not crossing my wires, but doesn't ChaCha core require a
&gt; counter addition? 

Sure, but nettle's _chacha_core function (what I've implemented so far
for ppc) does a single block, and doesn't modify the counter. Variants
like _chacha_3core (currently implemented for ARM Neon only) need to
update the counter.

&gt; There are some fundamental differences between Bernstein's ChaCha and
&gt; the IETF's ChaCha used in TLS. Bernstein's ChaCha uses a 64-bit
&gt; counter.

That's a bit messy, but nettle supports both variants. To use the ietf
version, either use the the chacha_poly1305_* aead functions, or, for
chacha only, the functions chacha_set_nonce96 and chacha_crypt32.

And there are tests for 32-bit wraparound in both cases.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200925195850</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-09-25 19:58:50-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; Great work. The implementation looks fine, I like the idea of using -16
&gt; instead of 16 for rotating because vspltisw is limited to (-16 to 15)
&gt; and vrlw picks the low-order 5 bits which is the same for both -16 and
&gt; 16.

I picked up that trick from Torbjörn Granlund's code.

&gt; BTW this implementation should work as is on big-endian mode without any
&gt; hassle because lxvw4x/stxvw4x are endianness aware of loading/storing word
&gt; values.

I've pushed it to a branch ppc-chacha-core. But it fails on big-endian
powerpc64, see https://gitlab.com/gnutls/nettle/-/jobs/758348866.

And it looks like the error message from the first failing chacha test
is truncated, which makes me suspect some error in function prologue or
register usage, resulting in some invalid state when the function returns.

Comparing to your assembly code, I don't set FUNC_ALIGN, is that a
problem?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201115103901</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-11-15 10:39:01-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; It could likely be speedup further by processing 2, 3 or 4 blocks in
&gt; parallel.

I've given 2 blocks in parallel a try, but not quite working yet. My
work-in-progress code below.

When I test it on the gcc112 machine, it fails with an illegal
instruction (SIGILL) on this line, close to function entry:

  .globl _nettle_chacha_2core
  .type _nettle_chacha_2core,%function
  .align 5
  _nettle_chacha_2core:
  addis 2,12,(.TOC.-_nettle_chacha_2core)@ha
  addi 2,2,(.TOC.-_nettle_chacha_2core)@l
  .localentry _nettle_chacha_2core, .-_nettle_chacha_2core
  
  
          li      r8, 0x30
          vspltisw v1, 1
  =&gt;      vextractuw v1, v1, 0

I don't understand, from the manual, what's wrong with this. The
intention of this piece of code is just to construct the value {1, 0, 0,
0} in one of the vector registers. Maybe there's a better way to do
that?

Regards,
/Niels

C powerpc64/p7/chacha-core-internal.asm

ifelse(`
   Copyright (C) 2020 Niels Möller and Torbjörn Granlund
   This file is part of GNU Nettle.

   GNU Nettle is free software: you can redistribute it and/or
   modify it under the terms of either:

     * the GNU Lesser General Public License as published by the Free
       Software Foundation; either version 3 of the License, or (at your
       option) any later version.

   or

     * the GNU General Public License as published by the Free
       Software Foundation; either version 2 of the License, or (at your
       option) any later version.

   or both in parallel, as here.

   GNU Nettle is distributed in the hope that it will be useful,
   but WITHOUT ANY WARRANTY; without even the implied warranty of
   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
   General Public License for more details.

   You should have received copies of the GNU General Public License and
   the GNU Lesser General Public License along with this program.  If
   not, see http://www.gnu.org/licenses/.
')

C Register usage:

C Argments
define(`DST', `r3')
define(`SRC', `r4')
define(`ROUNDS', `r5')

C State, even elements in X, odd elements in Y
define(`X0', `v0')
define(`X1', `v1')
define(`X2', `v2')
define(`X3', `v3')
define(`Y0', `v4')
define(`Y1', `v5')
define(`Y2', `v6')
define(`Y3', `v7')

define(`ROT16', `v8')
define(`ROT12', `v9')
define(`ROT8',  `v10')
define(`ROT7',  `v11')

C Original input state
define(`S0', `v12')
define(`S1', `v13')
define(`S2', `v14')
define(`S3', `v15')
define(`S3p1', `v16')
define(`T0', `v17')

	.text
	C _chacha_2core(uint32_t *dst, const uint32_t *src, unsigned rounds)

define(`FUNC_ALIGN', `5')
PROLOGUE(_nettle_chacha_2core)

	li	r8, 0x30	C offset for x3
	vspltisw X1, 1		C {1,1,...,1}
	vextractuw X1, X1, 0	C {1,0,...,0}

	lxvw4x	VSR(X3), r8, SRC

	vnegw	X0, X1
	vcmpequw Y3, X3, X0
	vand	Y3, Y3, X1	C Counter carry out
	vsldoi	Y3, Y3, Y3, 4
	vor	Y3, Y3, X1

.Lshared_entry:
	vadduwm	Y3, Y3, X3

	li	r6, 0x10	C set up some...
	li	r7, 0x20	C ...useful...
	lxvw4x	VSR(X0), 0, SRC
	lxvw4x	VSR(X1), r6, SRC
	lxvw4x	VSR(X2), r7, SRC

	vor	S0, X0, X0
	vor	S1, X1, X1
	vor	S2, X2, X2
	vor	S3, S3, X3
	vor	S3p1, Y3, Y3

	vmrgow	Y0, X0, X0	C  1  1  3  3
	vmrgew	X0, X0, X0	C  0  0  2  2
	vmrgow	Y1, X1, X1	C  5  5  7  7
	vmrgew	X1, X1, X1	C  4  4  6  6
	vmrgow	Y2, X2, X2	C  9  9 11 11
	vmrgew	X2, X2, X2	C  8  8 10 10
	vmrgow	Y3, X3, X3	C 13 13 15 15
	vmrgew	X3, X3, X3	C 12 12 14 14

	vspltisw ROT16, -16	C -16 instead of 16 actually works!
	vspltisw ROT12, 12
	vspltisw ROT8, 8
	vspltisw ROT7, 7

	srdi	ROUNDS, ROUNDS, 1
	mtctr	ROUNDS
.Loop:
C Register layout (A is first block, B is second block)
C
C X0:  A0  B0  A2  B2  Y0:  A1  B1  A3  B3
C X1:  A4  B4  A6  B6  Y1:  A5  B5  A7  B7
C X2:  A8  B8 A10 B10  Y2:  A9  B9 A11 B11
C X3: A12 B12 A14 B14  Y3: A13 B13 A15 B15
	vadduwm X0, X0, X1
	 vadduwm Y0, Y0, Y1
	vxor	X3, X3, X0
	 vxor	Y3, Y3, Y0
	vrlw	X3, X3, ROT16
	 vrlw	Y3, Y3, ROT16

	vadduwm X2, X2, X3
	 vadduwm Y2, Y2, Y3
	vxor	X1, X1, X2
	 vxor	Y1, Y1, Y2
	vrlw	X1, X1, ROT12
	 vrlw	Y1, Y1, ROT12

	vadduwm X0, X0, X1
	 vadduwm Y0, Y0, Y1
	vxor	X3, X3, X0
	 vxor	Y3, Y3, Y0
	vrlw	X3, X3, ROT8
	 vrlw	Y3, Y3, ROT8

	vadduwm X2, X2, X3
	 vadduwm Y2, Y2, Y3
	vxor	X1, X1, X2
	 vxor	Y1, Y1, Y2
	vrlw	X1, X1, ROT7
	 vrlw	Y1, Y1, ROT7

	vsldoi	X1, X1, X1, 8
	vsldoi	X2, X2, X2, 8
	vsldoi	Y2, Y2, Y2, 8
	vsldoi	X3, X3, X3, 8

C Register layout:
C X0:  A0  B0  A2  B2  Y0:  A1  B1  A3  B3
C Y1:  A5  B5  A7  B7  X1:  A6  B6  A4  B4 (X1 swapped)
C X2: A10 B10  A8  B8  Y2: A11 A11  A9  B9 (X2, Y2 swapped)
C Y3  A15 B15 A13 B13  X3  A12 B12 A14 B14 (X3 swapped)

	vadduwm X0, X0, Y1
	 vadduwm Y0, Y0, X1
	vxor	Y3, Y3, X0
	 vxor	X3, X3, Y0
	vrlw	Y3, Y3, ROT16
	 vrlw	X3, X3, ROT16

	vadduwm X2, X2, Y3
	 vadduwm Y2, Y2, X3
	vxor	Y1, Y1, X2
	 vxor	X1, X1, Y2
	vrlw	Y1, Y1, ROT12
	 vrlw	X1, X1, ROT12

	vadduwm X0, X0, Y1
	 vadduwm Y0, Y0, Y1
	vxor	Y3, Y3, X0
	 vxor	X3, X3, Y0
	vrlw	Y3, Y3, ROT8
	 vrlw	X3, X3, ROT8

	vadduwm X2, X2, Y3
	 vadduwm Y2, Y2, X3
	vxor	Y1, Y1, X2
	 vxor	X1, X1, Y2
	vrlw	Y1, Y1, ROT7
	 vrlw	X1, X1, ROT7

	vsldoi	X1, X1, X1, 8
	vsldoi	X2, X2, X2, 8
	vsldoi	Y2, Y2, Y2, 8
	vsldoi	X3, X3, X3, 8

	bdnz	.Loop

	vmrghw	T0, X0, Y0
	vmrglw	Y0, X0, Y0

	vmrghw	X0, X1, Y1
	vmrglw	Y1, X1, Y1

	vmrghw	X1, X2, Y2
	vmrglw	Y2, X2, Y2

	vmrghw	X2, X3, Y3
	vmrglw	Y3, X3, Y3

	vadduwm T0, T0, S0
	vadduwm Y0, Y0, S0
	vadduwm X0, X0, S1
	vadduwm Y1, Y1, S1
	vadduwm X1, X1, S2
	vadduwm Y2, Y2, S2
	vadduwm X2, X2, S3
	vadduwm Y3, Y3, S3p1

	stxvw4x	VSR(T0), 0, DST
	stxvw4x	VSR(X0), r6, DST
	stxvw4x	VSR(X1), r7, DST
	stxvw4x	VSR(X2), r8, DST

	addi	DST, DST, 64

	stxvw4x	VSR(T0), 0, DST
	stxvw4x	VSR(X0), r6, DST
	stxvw4x	VSR(X1), r7, DST
	stxvw4x	VSR(X2), r8, DST
	blr

define(`FUNC_ALIGN', `5')
PROLOGUE(_nettle_chacha_2core32)
	li	r8, 0x30	C offset for x3
	vspltisw Y3, 1		C {1,1,...,1}
	vextractuw Y3, Y3, 0	C {1,0,...,0}
	lxvw4x	VSR(X3), r8, SRC
	b	.Lshared_entry
EPILOGUE(_nettle_chacha_2core32)

	.data
	.align 4
.Lcount1:
	.int 1,0,0,0

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201120205122</emailId><senderName>David Edelsohn</senderName><senderEmail>dje.gcc@gmail.com</senderEmail><timestampReceived>2020-11-20 20:51:22-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

On Fri, Nov 20, 2020 at 3:40 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; nisse@lysator.liu.se (Niels Möller) writes:
&gt;
&gt; &gt; It could likely be speedup further by processing 2, 3 or 4 blocks in
&gt; &gt; parallel.
&gt;
&gt; I've given 2 blocks in parallel a try, but not quite working yet. My
&gt; work-in-progress code below.
&gt;
&gt; When I test it on the gcc112 machine, it fails with an illegal
&gt; instruction (SIGILL) on this line, close to function entry:
&gt;
&gt;   .globl _nettle_chacha_2core
&gt;   .type _nettle_chacha_2core,%function
&gt;   .align 5
&gt;   _nettle_chacha_2core:
&gt;   addis 2,12,(.TOC.-_nettle_chacha_2core)@ha
&gt;   addi 2,2,(.TOC.-_nettle_chacha_2core)@l
&gt;   .localentry _nettle_chacha_2core, .-_nettle_chacha_2core
&gt;
&gt;
&gt;           li      r8, 0x30
&gt;           vspltisw v1, 1
&gt;   =&gt;      vextractuw v1, v1, 0
&gt;
&gt; I don't understand, from the manual, what's wrong with this. The
&gt; intention of this piece of code is just to construct the value {1, 0, 0,
&gt; 0} in one of the vector registers. Maybe there's a better way to do
&gt; that?

vextractuw is a Power9 instruction and gcc112 is a Power8 system.  The
processor does not support the instruction.

gcc135 is a Power9 system.

Thanks, David
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201120205341</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-11-20 20:53:41-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

On Fri, Nov 20, 2020 at 3:40 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; nisse@lysator.liu.se (Niels Möller) writes:
&gt;
&gt; &gt; It could likely be speedup further by processing 2, 3 or 4 blocks in
&gt; &gt; parallel.
&gt;
&gt; I've given 2 blocks in parallel a try, but not quite working yet. My
&gt; work-in-progress code below.
&gt;
&gt; When I test it on the gcc112 machine, it fails with an illegal
&gt; instruction (SIGILL) on this line, close to function entry:
&gt;
&gt;   .globl _nettle_chacha_2core
&gt;   .type _nettle_chacha_2core,%function
&gt;   .align 5
&gt;   _nettle_chacha_2core:
&gt;   addis 2,12,(.TOC.-_nettle_chacha_2core)@ha
&gt;   addi 2,2,(.TOC.-_nettle_chacha_2core)@l
&gt;   .localentry _nettle_chacha_2core, .-_nettle_chacha_2core
&gt;
&gt;
&gt;           li      r8, 0x30
&gt;           vspltisw v1, 1
&gt;   =&gt;      vextractuw v1, v1, 0
&gt;
&gt; I don't understand, from the manual, what's wrong with this. The
&gt; intention of this piece of code is just to construct the value {1, 0, 0,
&gt; 0} in one of the vector registers. Maybe there's a better way to do
&gt; that?

GCC112 is a POWER8 machine. According to the POWER manual, vextractuw
is a POWER9 instruction.

POWER8 manual: https://openpowerfoundation.org/?resource_lib=power8-processor-users-manual
POWER9 manual: https://openpowerfoundation.org/?resource_lib=power9-processor-users-manual

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200928173332</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-09-28 17:33:32-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" GCM support</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; I posted a performance test here
&gt; https://lists.lysator.liu.se/pipermail/nettle-bugs/2020/009169.html
&gt; Personally, I prefer keeping the altivec version in nettle library since
&gt; it's faster than C implementation but I'm not sure whether the performance
&gt; margin fits with the library's convention of optimizing such functions.

We can revisit it later, but lets go for the low-hanging fruit first.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201003225957</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-10-03 22:59:57-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" GCM support</subject><body>

&gt;
&gt; 1. Take out the fat support to it's own patch.
&gt;
 Done! I will post the assembly part first so you can review it.

2. You could consider doing the init_key in C, if nothing else as
&gt;    documentation. It could be either under some #ifdef in gcm.c, or a
&gt;    separate .c file under powerpc64/p8/, next to gcm-hash.asm. Maybe
&gt;    it's still a good idea to have it in assembly, that's a tradeoff that
&gt;    depends a bit on the complexity of both the C and assembly, and the
&gt;    speedup from doing it in assembly. And I don't have a very strong
&gt;    opinion on this point now.
&gt;
&gt;    Even with asm, it might be a bit clearer to move it to its own .asm
&gt;    file, so each file can use define only for the relevant registers for
&gt;    that function.

Writing init_key() in C for PowerPC implementation has a couple of
disadvantages:
1. init_key() and gcm_hash() functions are connected to each other through
a shared table, it makes it easier to modify the implementation if both are
written in the same way.
2. we have to use intrinsics for certain operations like 'vpmsumd',
furthermore '__builtin_crypto_vpmsumd' is buggy on certain versions of GCC
https://gcc.gnu.org/bugzilla/show_bug.cgi?id=91275 and has different name
on CLANG '__builtin_altivec_crypto_vpmsumd' so we will end up using a lot
of conditions to check the variant of compiler plus writing inline assembly
code for 'vpmsumd' in case the variant has intrinsic issue with it.
I still prefer to have both functions in the same file, I separated the
'define' macros for each function so each function has its own define
section above its prologue.

3. What's TableElemAlign? Assuming GCM_TABLE_BITS is 8 (current Nettle
&gt;    ABI), you can treat struct gcm_key as a blob of size 4096 bytes, with
&gt;    alignment corresponding to what the C compiler uses for uint64_t. Are
&gt;    you using some padding at the start (depending on address) to ensure
&gt;    you get stronger alignment? And 256 byte alignment sounds a bit more
&gt;    than needed?

The compiler aligns each element of gcm_key array at 0x100 perhaps because
the struct is declared as union so for example if I want to get the 'H'
value that is assigned into the 9th index, I have to add 0x800 to the array
address to get that value.


&gt; 4. Please document the layout used for the precomputed values stored in
&gt;    struct gcm_key.

Done!

5. It would help with comments explaining the naming convention used for
&gt;    the named registers, and the instruction sequence used for a single
&gt;    Karatsuba multiplication, with any needed comments.

I tried to make a reader-friendly version of the implementation to make it
clearer with appropriate comments. Let me know if the documentation still
looks sketchy.

6. Is 8-way unrolling really necessary to get full utilization of the
&gt;    execution units? And it's also not yet clear to me what 8-way means,
&gt;    is that 8 blocks of 16 bytes each (i.e., 128 bytes input), or 8 input
&gt;    bytes?
&gt;
processing 4 blocks is enough to saturate the execution units but
processing 8 blocks (each block is 128-bit) cut the times of reduction
procedure execution by half compared to processing 4 blocks per loop so it
performs better, however in order to facilitate a review of implementation
I downed the loop to process 4 blocks to make it more clear.


&gt; 7. Do you need any bit reversal? As you have mentioned, the
&gt;    multiplication operation is symmetric under bit reversal, so ideally
&gt;    bit reversal should be needed at most when setting the key and
&gt;    extracting the digest, but not by the main workhorse, gcm_hash.
&gt;
You got it. If the bit-reflection of the key is handled, there is no need
to handle the bit-reflection of the multiplication product with that key.
So any upcoming multiplication will be bit-reversal-free.

I would like to explain more about 'vpmsumd' instruction, in x86 arch the
'pclmulqdq' instruction is used for carry-less operations. To use
'pclmulqdq' an immediate value should be passed to the third parameter of
the instruction to specify which doublewords will be multiplied. However,
'vpmsumd' do the following operation:
(High-order doubleword of the second parameter * High-order doubleword of
the third parameter) XOR (Low-order doubleword of the second parameter *
Low-order doubleword of the third parameter)
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201003230046</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-10-03 23:00:46-0400</timestampReceived><subject>[PATCH] "PowerPC64" GCM support</subject><body>

---
 configure.ac              |   6 +-
 gcm.c                     |  49 +++-
 powerpc64/p8/gcm-hash.asm | 607
++++++++++++++++++++++++++++++++++++++++++++++
 3 files changed, 647 insertions(+), 15 deletions(-)
 create mode 100644 powerpc64/p8/gcm-hash.asm

diff --git a/configure.ac b/configure.ac
index e9983697..0129f950 100644
--- a/configure.ac
+++ b/configure.ac
@@ -488,7 +488,7 @@ asm_replace_list="aes-encrypt-internal.asm
aes-decrypt-internal.asm \
  sha3-permute.asm umac-nh.asm umac-nh-n.asm machine.m4"

 # Assembler files which generate additional object files if they are used.
-asm_nettle_optional_list="gcm-hash8.asm cpuid.asm \
+asm_nettle_optional_list="gcm-hash.asm gcm-hash8.asm cpuid.asm \
   aes-encrypt-internal-2.asm aes-decrypt-internal-2.asm memxor-2.asm \
   chacha-3core.asm chacha-core-internal-2.asm salsa20-2core.asm \
   salsa20-core-internal-2.asm sha1-compress-2.asm sha256-compress-2.asm \
@@ -612,9 +612,9 @@ AH_VERBATIM([HAVE_NATIVE],
 #undef HAVE_NATIVE_ecc_secp384r1_redc
 #undef HAVE_NATIVE_ecc_secp521r1_modp
 #undef HAVE_NATIVE_ecc_secp521r1_redc
-#undef HAVE_NATIVE_gcm_init_key8
+#undef HAVE_NATIVE_gcm_init_key
+#undef HAVE_NATIVE_gcm_hash
 #undef HAVE_NATIVE_gcm_hash8
-#undef HAVE_NATIVE_gcm_fill
 #undef HAVE_NATIVE_salsa20_core
 #undef HAVE_NATIVE_salsa20_2core
 #undef HAVE_NATIVE_fat_salsa20_2core
diff --git a/gcm.c b/gcm.c
index 48b3e75a..81981c1c 100644
--- a/gcm.c
+++ b/gcm.c
@@ -140,6 +140,19 @@ gcm_gf_mul (union nettle_block16 *x, const union
nettle_block16 *table)
   memcpy (x-&gt;b, Z.b, sizeof(Z));
 }
 # elif GCM_TABLE_BITS == 8
+#  if HAVE_NATIVE_gcm_init_key
+
+#define gcm_init_key _nettle_gcm_init_key
+void
+_nettle_gcm_init_key (union nettle_block16 *table);
+#  endif /* HAVE_NATIVE_gcm_init_key */
+#  if HAVE_NATIVE_gcm_hash
+
+#define gcm_hash _nettle_gcm_hash
+void
+_nettle_gcm_hash (const struct gcm_key *key, union nettle_block16 *x,
+   size_t length, const uint8_t *data);
+#  endif /* HAVE_NATIVE_gcm_hash */
 #  if HAVE_NATIVE_gcm_hash8

 #define gcm_hash _nettle_gcm_hash8
@@ -228,6 +241,29 @@ gcm_gf_mul (union nettle_block16 *x, const union
nettle_block16 *table)
 /* Increment the rightmost 32 bits. */
 #define INC32(block) INCREMENT(4, (block.b) + GCM_BLOCK_SIZE - 4)

+#ifndef gcm_init_key
+static void
+gcm_init_key(union nettle_block16 *table)
+{
+#if GCM_TABLE_BITS
+  /* Middle element if GCM_TABLE_BITS &gt; 0, otherwise the first
+     element */
+  unsigned i = (1&lt;&lt;GCM_TABLE_BITS)/2;
+
+  /* Algorithm 3 from the gcm paper. First do powers of two, then do
+     the rest by adding. */
+  while (i /= 2)
+    block16_mulx_ghash(&amp;table[i], &amp;table[2*i]);
+  for (i = 2; i &lt; 1&lt;&lt;GCM_TABLE_BITS; i *= 2)
+    {
+      unsigned j;
+      for (j = 1; j &lt; i; j++)
+ block16_xor3(&amp;table[i+j], &amp;table[i], &amp;table[j]);
+    }
+#endif
+}
+#endif /* !gcm_init_key */
+
 /* Initialization of GCM.
  * @ctx: The context of GCM
  * @cipher: The context of the underlying block cipher
@@ -245,18 +281,7 @@ gcm_set_key(struct gcm_key *key,
   memset(key-&gt;h[0].b, 0, GCM_BLOCK_SIZE);
   f (cipher, GCM_BLOCK_SIZE, key-&gt;h[i].b, key-&gt;h[0].b);

-#if GCM_TABLE_BITS
-  /* Algorithm 3 from the gcm paper. First do powers of two, then do
-     the rest by adding. */
-  while (i /= 2)
-    block16_mulx_ghash(&amp;key-&gt;h[i], &amp;key-&gt;h[2*i]);
-  for (i = 2; i &lt; 1&lt;&lt;GCM_TABLE_BITS; i *= 2)
-    {
-      unsigned j;
-      for (j = 1; j &lt; i; j++)
- block16_xor3(&amp;key-&gt;h[i+j], &amp;key-&gt;h[i],&amp;key-&gt;h[j]);
-    }
-#endif
+  gcm_init_key(key-&gt;h);
 }

 #ifndef gcm_hash
diff --git a/powerpc64/p8/gcm-hash.asm b/powerpc64/p8/gcm-hash.asm
new file mode 100644
index 00000000..540c9f97
--- /dev/null
+++ b/powerpc64/p8/gcm-hash.asm
@@ -0,0 +1,607 @@
+C powerpc64/p8/gcm-hash.asm
+
+ifelse(`
+   Copyright (D) 2020 Mamone Tarsha
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+')
+
+C Alignment of gcm_key table elements, which is declared in gcm.h
+define(`TableElemAlign', `0x100')
+
+C Register usage:
+
+define(`SP', `r1')
+define(`TOCP', `r2')
+
+define(`TABLE', `r3')
+
+define(`ZERO', `v0')
+define(`B1', `v1')
+define(`EMSB', `v2')
+define(`POLY', `v7')
+define(`POLY_L', `v1')
+define(`POLY_H', `v2')
+
+define(`H', `v3')
+define(`H3', `v3')
+define(`Hl', `v4')
+define(`Hm', `v5')
+define(`Hh', `v6')
+define(`RP', `v7')
+define(`Mh', `v8')
+define(`Ml', `v9')
+define(`H2', `v7')
+define(`H4', `v7')
+define(`H2m', `v8')
+define(`H2l', `v9')
+define(`H2h', `v10')
+define(`RP2', `v11')
+define(`M2h', `v12')
+define(`M2l', `v13')
+
+define(`H2_l', `v14')
+define(`H2_m', `v15')
+define(`H2_h', `v16')
+define(`H3_l', `v14')
+define(`H3_m', `v15')
+define(`H3_h', `v16')
+define(`H4_l', `v17')
+define(`H4_m', `v18')
+define(`H4_h', `v19')
+
+define(`H21l', `v16')
+define(`H21h', `v17')
+define(`H3m', `v16')
+define(`H4m', `v17')
+define(`H43l', `v18')
+define(`H43h', `v19')
+
+define(`LE_TEMP', `v18')
+define(`LE_MASK', `v19')
+
+.file "gcm-hash.asm"
+
+.text
+
+    C void gcm_init_key (union gcm_block *table)
+
+C This function populates the gcm table as the following layout
+C ********************************************************************
+C | Hm = low-order doubleword of H^1:high-order doubleword of H^1    |
+C | Hl = 64-bits zeros:low-order doubleword of H^1                   |
+C | Hh = high-order doubleword of H^1:64-bits zeros                  |
+C |                                                                  |
+C | H2m = low-order doubleword of H^2:high-order doubleword of H^2   |
+C | H21l = low-order doubleword of H^2:low-order doubleword of H^1   |
+C | H21h = high-order doubleword of H^2:high-order doubleword of H^1 |
+C |                                                                  |
+C | H3m = low-order doubleword of H^3:high-order doubleword of H^3   |
+C | H4m = low-order doubleword of H^4:high-order doubleword of H^4   |
+C | H43l = low-order doubleword of H^4:low-order doubleword of H^3   |
+C | H43h = high-order doubleword of H^4:high-order doubleword of H^3 |
+C ********************************************************************
+
+define(`FUNC_ALIGN', `5')
+PROLOGUE(_nettle_gcm_init_key)
+    DATA_LOAD_VEC(POLY,.polynomial,r7)           C
0xC2000000000000000000000000000001
+IF_LE(`
+    li             r8,0
+    lvsl           LE_MASK,0,r8                  C
0x000102030405060708090A0B0C0D0E0F
+    vspltisb       LE_TEMP,0x07                  C
0x07070707070707070707070707070707
+    vxor           LE_MASK,LE_MASK,LE_TEMP       C
0x07060504030201000F0E0D0C0B0A0908
+')
+
+    C 'H' is assigned by gcm_set_key() to the middle element of the table
+    li             r10,8*TableElemAlign
+    lxvd2x         VSR(H),r10,TABLE              C load 'H'
+    C byte-reverse of each doubleword permuting on little-endian mode
+IF_LE(`
+    vperm          H,H,H,LE_MASK
+')
+
+    C --- calculate [H = H &lt;&lt; 1 modulo polynomial] ---
+
+    vupkhsb        EMSB,H                        C extend most significant
bit to first byte
+    vspltisb       B1,1                          C
0x01010101010101010101010101010101
+    vspltb         EMSB,EMSB,0                   C first byte
quadword-extend
+    vsl            H,H,B1                        C H = H &lt;&lt; 1
+    vand           EMSB,EMSB,POLY                C EMSB &amp;=
0xC2000000000000000000000000000001
+    vxor           ZERO,ZERO,ZERO                C
0x00000000000000000000000000000000
+    vxor           H,H,EMSB                      C H ^= EMSB
+
+    C calculate [Hl = 0:H^1l, Hm = H^1l:H^1h, Hh = H^1h:0]
+    xxmrgld        VSR(Hl),VSR(ZERO),VSR(H)
+    xxswapd        VSR(Hm),VSR(H)
+    xxmrghd        VSR(Hh),VSR(H),VSR(ZERO)
+
+    C --- calculate H^2 = H*H ---
+
+    C reduction pre-processing
+    xxmrghd        VSR(POLY_H),VSR(POLY),VSR(ZERO) C
0xC2000000000000000000000000000000
+    xxmrghd        VSR(POLY_L),VSR(ZERO),VSR(POLY) C
0x0000000000000000C200000000000000
+
+    C polynomial multiplication "classical"
+    vpmsumd        H2_l,H,Hl                     C H^1l*H^1l
+    vpmsumd        H2_m,H,Hm                     C H^1h*H^1l⊕H^1l*H^1h
+    vpmsumd        H2_h,H,Hh                     C H^1h*H^1h
+
+    C reduction first phase                        [1]
+    vpmsumd        RP,H2_l,POLY_L                C [1]
+
+    C polynomial multiplication post-processing    [2]
+    xxmrghd        VSR(Mh),VSR(ZERO),VSR(H2_m)   C [2]
+    xxmrgld        VSR(Ml),VSR(H2_m),VSR(ZERO)   C [2]
+    xxswapd        VSR(RP),VSR(RP)               C [1]
+    vxor           H2_h,H2_h,Mh                  C [2]
+    vxor           H2_l,H2_l,Ml                  C [2]
+    vxor           H2_l,H2_l,RP                  C [1]
+
+    C reduction second phase
+    vpmsumd        RP,H2_l,POLY_H
+    vxor           H2_h,H2_h,H2_l
+    vxor           H2,H2_h,RP
+
+    C store [H2m = H^2l:H^2h, H2l = 0:H^2l, H2h = H^2h:0]
+    xxswapd        VSR(H2m),VSR(H2)
+    xxmrgld        VSR(H2l),VSR(ZERO),VSR(H2)
+    xxmrghd        VSR(H2h),VSR(H2),VSR(ZERO)
+
+    C calculate [H21l = H^2l:H^1l, H21h = H^2h:H^1h]
+    xxmrgld        VSR(H21l),VSR(H2),VSR(H)
+    xxmrghd        VSR(H21h),VSR(H2),VSR(H)
+
+    C store [Hm, Hl, Hh]
+    li             r9,1*TableElemAlign
+    li             r10,2*TableElemAlign
+    stxvd2x        VSR(Hm),0,TABLE
+    stxvd2x        VSR(Hl),r9,TABLE
+    stxvd2x        VSR(Hh),r10,TABLE
+
+    C store [H2m, H21l, H21h]
+    li             r8,3*TableElemAlign
+    li             r9,4*TableElemAlign
+    li             r10,5*TableElemAlign
+    stxvd2x        VSR(H2m),r8,TABLE
+    stxvd2x        VSR(H21l),r9,TABLE
+    stxvd2x        VSR(H21h),r10,TABLE
+
+    C --- calculate H^3 = H^1*H^2, H^4 = H^2*H^2 ---
+
+    C polynomial multiplication "classical"
+    vpmsumd        H3_l,H,H2l                    C H^1l*H^2l
+    vpmsumd        H4_l,H2,H2l                   C H^2l*H^2l
+    vpmsumd        H3_m,H,H2m                    C H^1h*H^2l⊕H^1l*H^2h
+    vpmsumd        H4_m,H2,H2m                   C H^2h*H^2l⊕H^2l*H^2h
+    vpmsumd        H3_h,H,H2h                    C H^1h*H^2h
+    vpmsumd        H4_h,H2,H2h                   C H^2h*H^2h
+
+    C reduction first phase                        [1]
+    vpmsumd        RP,H3_l,POLY_L                C [1] H^3
+    vpmsumd        RP2,H4_l,POLY_L               C [1] H^4
+
+    C polynomial multiplication post-processing    [2]
+    xxmrghd        VSR(Mh),VSR(ZERO),VSR(H3_m)   C [2] H^3
+    xxmrghd        VSR(M2h),VSR(ZERO),VSR(H4_m)  C [2] H^4
+    xxmrgld        VSR(Ml),VSR(H3_m),VSR(ZERO)   C [2] H^3
+    xxmrgld        VSR(M2l),VSR(H4_m),VSR(ZERO)  C [2] H^4
+    xxswapd        VSR(RP),VSR(RP)               C [1] H^3
+    xxswapd        VSR(RP2),VSR(RP2)             C [1] H^4
+    vxor           H3_h,H3_h,Mh                  C [2] H^3
+    vxor           H4_h,H4_h,M2h                 C [2] H^4
+    vxor           H3_l,H3_l,Ml                  C [2] H^3
+    vxor           H4_l,H4_l,M2l                 C [2] H^4
+    vxor           H3_l,H3_l,RP                  C [1] H^3
+    vxor           H4_l,H4_l,RP2                 C [1] H^4
+
+    C reduction second phase
+    vpmsumd        RP,H3_l,POLY_H                C H^3
+    vpmsumd        RP2,H4_l,POLY_H               C H^4
+    vxor           H3_h,H3_h,H3_l                C H^3
+    vxor           H4_h,H4_h,H4_l                C H^4
+    vxor           H3,H3_h,RP                    C H^3
+    vxor           H4,H4_h,RP2                   C H^4
+
+    C calculate [H3m = H^3l:H^3h, H4m = H^4l:H^4h, H43l = H^4l:H^3l, H43h
= H^4h:H^3h]
+    xxswapd        VSR(H3m),VSR(H3)
+    xxswapd        VSR(H4m),VSR(H4)
+    xxmrgld        VSR(H43l),VSR(H4),VSR(H3)
+    xxmrghd        VSR(H43h),VSR(H4),VSR(H3)
+
+    C store [H3m, H4m, H43l, H43h]
+    li             r7,6*TableElemAlign
+    li             r8,7*TableElemAlign
+    li             r9,8*TableElemAlign
+    li             r10,9*TableElemAlign
+    stxvd2x        VSR(H3m),r7,TABLE
+    stxvd2x        VSR(H4m),r8,TABLE
+    stxvd2x        VSR(H43l),r9,TABLE
+    stxvd2x        VSR(H43h),r10,TABLE
+
+    blr
+EPILOGUE(_nettle_gcm_init_key)
+
+define(`TABLE', `r3')
+define(`X', `r4')
+define(`LENGTH', `r5')
+define(`DATA', `r6')
+
+define(`ZERO', `v0')
+define(`POLY', `v3')
+define(`POLY_L', `v1')
+define(`POLY_H', `v2')
+
+define(`D', `v3')
+define(`C0', `v4')
+define(`C1', `v5')
+define(`C2', `v6')
+define(`C3', `v7')
+define(`Mh', `v8')
+define(`Ml', `v9')
+define(`RP', `v10')
+define(`C01h', `v11')
+define(`C01l', `v12')
+define(`C23h', `v13')
+define(`C23l', `v14')
+
+define(`H1', `v15')
+define(`H2', `v16')
+define(`H21l', `v17')
+define(`H21h', `v18')
+define(`H3', `v20')
+define(`H4', `v21')
+define(`H43l', `v22')
+define(`H43h', `v23')
+
+define(`Cl', `v5')
+define(`Cm', `v6')
+define(`Ch', `v7')
+define(`Hl', `v15')
+define(`H', `v16')
+define(`Hh', `v17')
+
+define(`LE_TEMP', `v18')
+define(`LE_MASK', `v19')
+
+    C void gcm_hash (const struct gcm_key *key, union gcm_block *x,
+    C                size_t length, const uint8_t *data)
+
+define(`FUNC_ALIGN', `5')
+PROLOGUE(_nettle_gcm_hash)
+    DATA_LOAD_VEC(POLY,.polynomial,r7)
+IF_LE(`
+    li             r8,0
+    lvsl           LE_MASK,0,r8
+    vspltisb       LE_TEMP,0x07
+    vxor           LE_MASK,LE_MASK,LE_TEMP
+')
+    vxor           ZERO,ZERO,ZERO
+
+    xxmrghd        VSR(POLY_L),VSR(ZERO),VSR(POLY)
+    xxmrghd        VSR(POLY_H),VSR(POLY),VSR(ZERO)
+
+    lxvd2x         VSR(D),0,X                    C load 'X' pointer
+    C byte-reverse of each doubleword permuting on little-endian mode
+IF_LE(`
+    vperm          D,D,D,LE_MASK
+')
+
+    C --- process 4 blocks '128-bit each' per one loop ---
+
+    srdi           r7,LENGTH,6                   C 4-blocks loop count
'LENGTH / (4 * 16)'
+    cmpldi         r7,0
+    beq            L2x
+
+    mtctr          r7                            C assign counter register
to loop count
+
+    C backup non-volatile vector registers
+    addi           r8,SP,-64
+    stvx           20,0,r8
+    addi           r8,r8,16
+    stvx           21,0,r8
+    addi           r8,r8,16
+    stvx           22,0,r8
+    addi           r8,r8,16
+    stvx           23,0,r8
+
+    C load table elements
+    li             r8,3*TableElemAlign
+    li             r9,4*TableElemAlign
+    li             r10,5*TableElemAlign
+    lxvd2x         VSR(H1),0,TABLE
+    lxvd2x         VSR(H2),r8,TABLE
+    lxvd2x         VSR(H21l),r9,TABLE
+    lxvd2x         VSR(H21h),r10,TABLE
+    li             r7,6*TableElemAlign
+    li             r8,7*TableElemAlign
+    li             r9,8*TableElemAlign
+    li             r10,9*TableElemAlign
+    lxvd2x         VSR(H3),r7,TABLE
+    lxvd2x         VSR(H4),r8,TABLE
+    lxvd2x         VSR(H43l),r9,TABLE
+    lxvd2x         VSR(H43h),r10,TABLE
+
+    li             r8,0x10
+    li             r9,0x20
+    li             r10,0x30
+.align 5
+L4x_loop:
+    C input loading
+    lxvd2x         VSR(C0),0,DATA                C load C0
+    lxvd2x         VSR(C1),r8,DATA               C load C1
+    lxvd2x         VSR(C2),r9,DATA               C load C2
+    lxvd2x         VSR(C3),r10,DATA              C load C3
+
+IF_LE(`
+    vperm          C0,C0,C0,LE_MASK
+    vperm          C1,C1,C1,LE_MASK
+    vperm          C2,C2,C2,LE_MASK
+    vperm          C3,C3,C3,LE_MASK
+')
+
+    C previous digest combining
+    vxor           C0,C0,D
+
+    C polynomial multiplication "classical" pre-processing
+    xxmrghd        VSR(C23h),VSR(C2),VSR(C3)
+    xxmrgld        VSR(C23l),VSR(C2),VSR(C3)
+    xxmrghd        VSR(C01h),VSR(C0),VSR(C1)
+    xxmrgld        VSR(C01l),VSR(C0),VSR(C1)
+
+    C polynomial multiplication "classical"
+    vpmsumd        C3,C3,H1                      C M3 = H^1l*C3h⊕H^1h*C3l
+    vpmsumd        C2,C2,H2                      C M2 = H^2l*C2h⊕H^2h*C2l
+    vpmsumd        C1,C1,H3                      C M1 = H^3l*C1h⊕H^3h*C1l
+    vpmsumd        C0,C0,H4                      C M0 = H^4l*C0h⊕H^4h*C0l
+    vpmsumd        C23h,C23h,H21h                C H23 = H^2h*C2h⊕H^1h*C3h
+    vpmsumd        C23l,C23l,H21l                C L23 = H^2l*C2l⊕H^1l*C3l
+    vpmsumd        C01h,C01h,H43h                C H01 = H^4h*C0h⊕H^4h*C1h
+    vpmsumd        C01l,C01l,H43l                C L01 = H^4l*C0l⊕H^4l*C1l
+
+    C polynomial multiplication "classical" post-processing
+    vxor           C2,C2,C3                      C M2 = M2⊕M3
+    vxor           C0,C0,C1                      C M0 = M0⊕M1
+
+    C deferred recombination of partial products
+    vxor           C01h,C01h,C23h                C H0 = H01⊕H23
+    vxor           C01l,C01l,C23l                C L0 = L01⊕L23
+    vxor           C0,C0,C2                      C M0 = M0⊕M2
+
+    C reduction first phase                        [1]
+    vpmsumd        RP,C01l,POLY_L                C [1]
+
+    C polynomial multiplication post-processing    [2]
+    xxmrghd        VSR(Mh),VSR(ZERO),VSR(C0)     C [2]
+    xxmrgld        VSR(Ml),VSR(C0),VSR(ZERO)     C [2]
+    xxswapd        VSR(RP),VSR(RP)               C [1]
+    vxor           C01h,C01h,Mh                  C [2]
+    vxor           C01l,C01l,Ml                  C [2]
+    vxor           C01l,C01l,RP                  C [1]
+
+    C reduction second phase
+    vpmsumd        RP,C01l,POLY_H
+    vxor           C01h,C01l,C01h
+    vxor           D,C01h,RP
+
+    addi           DATA,DATA,0x40
+    bdnz           L4x_loop
+
+    C restore non-volatile vector registers
+    addi           r8,SP,-64
+    lvx            20,0,r8
+    addi           r8,r8,16
+    lvx            21,0,r8
+    addi           r8,r8,16
+    lvx            22,0,r8
+    addi           r8,r8,16
+    lvx            23,0,r8
+
+    clrldi         LENGTH,LENGTH,58              C 'set the high-order 58
bits to zeros'
+L2x:
+    C --- process 2 blocks ---
+
+    srdi           r7,LENGTH,5                   C 'LENGTH / (2 * 16)'
+    cmpldi         r7,0
+    beq            L1x
+
+    C load table elements
+    li             r8,3*TableElemAlign
+    li             r9,4*TableElemAlign
+    li             r10,5*TableElemAlign
+    lxvd2x         VSR(H1),0,TABLE
+    lxvd2x         VSR(H2),r8,TABLE
+    lxvd2x         VSR(H21l),r9,TABLE
+    lxvd2x         VSR(H21h),r10,TABLE
+
+    C input loading
+    li             r10,0x10
+    lxvd2x         VSR(C0),0,DATA                C load C0
+    lxvd2x         VSR(C1),r10,DATA              C load C1
+
+IF_LE(`
+    vperm          C0,C0,C0,LE_MASK
+    vperm          C1,C1,C1,LE_MASK
+')
+
+    C previous digest combining
+    vxor           C0,C0,D
+
+    C polynomial multiplication "classical" pre-processing
+    xxmrghd        VSR(C01h),VSR(C0),VSR(C1)
+    xxmrgld        VSR(C01l),VSR(C0),VSR(C1)
+
+    C polynomial multiplication "classical"
+    vpmsumd        C1,C1,H1                      C M1 = H^1l*C1h⊕H^1h*C1l
+    vpmsumd        C0,C0,H2                      C M0 = H^2l*C0h⊕H^2h*C0l
+    vpmsumd        C01h,C01h,H21h                C H01 = H^2h*C0h⊕H^1h*C1h
+    vpmsumd        C01l,C01l,H21l                C L01 = H^2l*C0l⊕H^1l*C1l
+
+    C deferred recombination of partial products
+    vxor           C0,C0,C1                      C M0 = M0⊕M1
+
+    C reduction first phase                        [1]
+    vpmsumd        RP,C01l,POLY_L                C [1]
+
+    C polynomial multiplication post-processing    [2]
+    xxmrghd        VSR(Mh),VSR(ZERO),VSR(C0)     C [2]
+    xxmrgld        VSR(Ml),VSR(C0),VSR(ZERO)     C [2]
+    xxswapd        VSR(RP),VSR(RP)               C [1]
+    vxor           C01h,C01h,Mh                  C [2]
+    vxor           C01l,C01l,Ml                  C [2]
+    vxor           C01l,C01l,RP                  C [1]
+
+    C reduction second phase
+    vpmsumd        RP,C01l,POLY_H
+    vxor           C01h,C01l,C01h
+    vxor           D,C01h,RP
+
+    addi           DATA,DATA,0x20
+    clrldi         LENGTH,LENGTH,59              C 'set the high-order 59
bits to zeros'
+L1x:
+    C --- process 1 block ---
+
+    srdi           r7,LENGTH,4                   C 'LENGTH / (1 * 16)'
+    cmpldi         r7,0
+    beq            Lmod
+
+    C load table elements
+    li             r9,1*TableElemAlign
+    li             r10,2*TableElemAlign
+    lxvd2x         VSR(H),0,TABLE
+    lxvd2x         VSR(Hl),r9,TABLE
+    lxvd2x         VSR(Hh),r10,TABLE
+
+    C input loading
+    lxvd2x         VSR(C0),0,DATA                C load C0
+
+IF_LE(`
+    vperm          C0,C0,C0,LE_MASK
+')
+
+    C previous digest combining
+    vxor           C0,C0,D
+
+    C polynomial multiplication "classical"
+    vpmsumd        Cl,C0,Hl                      C L = Hl*Cl
+    vpmsumd        Cm,C0,H                       C M = Hh*Cl⊕Hl*Ch
+    vpmsumd        Ch,C0,Hh                      C H = Hh*Ch
+
+    C reduction first phase                      C [1]
+    vpmsumd        RP,Cl,POLY_L                  C [1]
+
+    C polynomial multiplication post-processing    [2]
+    xxmrghd        VSR(Mh),VSR(ZERO),VSR(Cm)     C [2]
+    xxmrgld        VSR(Ml),VSR(Cm),VSR(ZERO)     C [2]
+    xxswapd        VSR(RP),VSR(RP)               C [1]
+    vxor           Ch,Ch,Mh                      C [2]
+    vxor           Cl,Cl,Ml                      C [2]
+    vxor           Cl,Cl,RP                      C [1]
+
+    C reduction second phase
+    vpmsumd        RP,Cl,POLY_H
+    vxor           Ch,Cl,Ch
+    vxor           D,Ch,RP
+
+    addi           DATA,DATA,0x10
+    clrldi         LENGTH,LENGTH,60              C 'set the high-order 60
bits to zeros'
+Lmod:
+    C --- process the modulo bytes, padding the low-order bytes with zeros
---
+
+    cmpldi         LENGTH,0
+    beq            Ldone
+
+    C load table elements
+    li             r9,1*TableElemAlign
+    li             r10,2*TableElemAlign
+    lxvd2x         VSR(H),0,TABLE
+    lxvd2x         VSR(Hl),r9,TABLE
+    lxvd2x         VSR(Hh),r10,TABLE
+
+    C push every modulo byte to the stack and load them with padding into
vector register
+    addi           r8,SP,-16
+    stvx           ZERO,0,r8
+Lstb_loop:
+    subic.         LENGTH,LENGTH,1
+    lbzx           r7,LENGTH,DATA
+    stbx           r7,LENGTH,r8
+    bne            Lstb_loop
+    lxvd2x         VSR(C0),0,r8
+
+IF_LE(`
+    vperm          C0,C0,C0,LE_MASK
+')
+
+    C previous digest combining
+    vxor           C0,C0,D
+
+    C polynomial multiplication "classical"
+    vpmsumd        Cl,C0,Hl                      C L = Hl*Cl
+    vpmsumd        Cm,C0,H                       C M = Hh*Cl⊕Hl*Ch
+    vpmsumd        Ch,C0,Hh                      C H = Hh*Ch
+
+    C reduction first phase                        [1]
+    vpmsumd        RP,Cl,POLY_L                  C [1]
+
+    C polynomial multiplication post-processing    [2]
+    xxmrghd        VSR(Mh),VSR(ZERO),VSR(Cm)     C [2]
+    xxmrgld        VSR(Ml),VSR(Cm),VSR(ZERO)     C [2]
+    xxswapd        VSR(RP),VSR(RP)               C [1]
+    vxor           Ch,Ch,Mh                      C [2]
+    vxor           Cl,Cl,Ml                      C [2]
+    vxor           Cl,Cl,RP                      C [1]
+
+    C reduction second phase
+    vpmsumd        RP,Cl,POLY_H
+    vxor           Ch,Cl,Ch
+    vxor           D,Ch,RP
+
+Ldone:
+    C byte-reverse of each doubleword permuting on little-endian mode
+IF_LE(`
+    vperm          D,D,D,LE_MASK
+')
+    stxvd2x        VSR(D),0,X                    C store digest 'D'
+
+    blr
+EPILOGUE(_nettle_gcm_hash)
+
+.data
+    C 0xC2000000000000000000000000000001
+.polynomial:
+.align 4
+IF_BE(`
+.byte 0xC2
+.rept 14
+.byte 0x00
+.endr
+.byte 0x01
+',`
+.byte 0x01
+.rept 14
+.byte 0x00
+.endr
+.byte 0xC2
+')

-- 
2.17.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201003231856</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-10-03 23:18:56-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" GCM support</subject><body>

On Sat, Oct 3, 2020 at 7:00 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt; wrote:
&gt; ...
&gt; 2. ... has different name
&gt; on CLANG '__builtin_altivec_crypto_vpmsumd' so we will end up using a lot
&gt; of conditions to check the variant of compiler plus writing inline assembly
&gt; code for 'vpmsumd' in case the variant has intrinsic issue with it.

And __vpmsumd for IBM's XL C/C++ compiler.

Clang plays games with the preprocessor macros. It pretends to be GCC,
Clang and XLC all at once, but it can't handle the other compiler's
intrinsics.

Here's how to setup the preprocessor macro tests:

#if defined(__ibmxl__) || (defined(_AIX) &amp;&amp; defined(__xlC__))
    // IBM XL C/C++
#elif defined(__clang__)
    // Clang
#else
    // GCC
#endif

I believe all the PowerPC machines on the GCC compile farm have IBM XL
C/C++ installed.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201004194633</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-10-04 19:46:33-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" GCM support</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt;  Done! I will post the assembly part first so you can review it.

Thanks. I hope to get the time to read it carefully soon.

&gt; 1. init_key() and gcm_hash() functions are connected to each other through
&gt; a shared table, it makes it easier to modify the implementation if both are
&gt; written in the same way.
&gt; 2. we have to use intrinsics for certain operations like 'vpmsumd',
&gt; furthermore '__builtin_crypto_vpmsumd' is buggy on certain versions of GCC
&gt; https://gcc.gnu.org/bugzilla/show_bug.cgi?id=91275 and has different name
&gt; on CLANG '__builtin_altivec_crypto_vpmsumd' so we will end up using a lot
&gt; of conditions to check the variant of compiler plus writing inline assembly
&gt; code for 'vpmsumd' in case the variant has intrinsic issue with it.
&gt; I still prefer to have both functions in the same file, I separated the
&gt; 'define' macros for each function so each function has its own define
&gt; section above its prologue.

I see. And I wouldn't want C code with machine-specific or
compiler-specific intrinsics. If there's no reasonable way to do it in
portable C, let's stick to assembly.

&gt; 3. What's TableElemAlign? Assuming GCM_TABLE_BITS is 8 (current Nettle
&gt;&gt;    ABI), you can treat struct gcm_key as a blob of size 4096 bytes, with
&gt;&gt;    alignment corresponding to what the C compiler uses for uint64_t. Are
&gt;&gt;    you using some padding at the start (depending on address) to ensure
&gt;&gt;    you get stronger alignment? And 256 byte alignment sounds a bit more
&gt;&gt;    than needed?
&gt;
&gt; The compiler aligns each element of gcm_key array at 0x100 perhaps because
&gt; the struct is declared as union so for example if I want to get the 'H'
&gt; value that is assigned into the 9th index, I have to add 0x800 to the array
&gt; address to get that value.

That's highly unexpected! It makes struct gcm_key 16 times larger than
intended, 64 KByte rather than 4KByte, which seems pretty bad. I would
expect more or less any C compiler to use size 16 and 8 byte minimum
alignment for the elements (and I'd wish there were a nice and portable
way to enforce minimum 16 byte alignment). Can you double check, and try
to find an explanation for this?

&gt; I would like to explain more about 'vpmsumd' instruction, in x86 arch the
&gt; 'pclmulqdq' instruction is used for carry-less operations. To use
&gt; 'pclmulqdq' an immediate value should be passed to the third parameter of
&gt; the instruction to specify which doublewords will be multiplied. However,
&gt; 'vpmsumd' do the following operation:
&gt; (High-order doubleword of the second parameter * High-order doubleword of
&gt; the third parameter) XOR (Low-order doubleword of the second parameter *
&gt; Low-order doubleword of the third parameter)

Interesting! Do you use inputs where one doubleword is zero, making one
or the other of the xored values be zero, or is there some clever way to
take advantage of the buiiltin wraparound? I guess one can also do some
interesting things of other selected parts of the inputs zero, for
example, the middle word of one of the operands, or all odd-numbered
bits, or...

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201004211017</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-10-04 21:10:17-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" GCM support</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt;&gt; I would like to explain more about 'vpmsumd' instruction, in x86 arch the
&gt;&gt; 'pclmulqdq' instruction is used for carry-less operations. To use
&gt;&gt; 'pclmulqdq' an immediate value should be passed to the third parameter of
&gt;&gt; the instruction to specify which doublewords will be multiplied. However,
&gt;&gt; 'vpmsumd' do the following operation:
&gt;&gt; (High-order doubleword of the second parameter * High-order doubleword of
&gt;&gt; the third parameter) XOR (Low-order doubleword of the second parameter *
&gt;&gt; Low-order doubleword of the third parameter)
&gt;
&gt; Interesting! Do you use inputs where one doubleword is zero, making one
&gt; or the other of the xored values be zero, or is there some clever way to
&gt; take advantage of the buiiltin wraparound? I guess one can also do some
&gt; interesting things of other selected parts of the inputs zero, for
&gt; example, the middle word of one of the operands, or all odd-numbered
&gt; bits, or...

Ok, let me see if I can get the math right first (and ignore the issues
if bit order and reversal). Thanks a lot for this the explanation of
this curious instruction, I hope I have understood it corectly, because
it seems really useful.

We have the polynomial p(x) = x^128 + x^7 + x^2 + x + 1 over Z_2. Which
implies that

  x^128 = x^2 + x + 1 (mod p(x))

so let's call this simpler polynomial p'(x) = x^2 + x + 1.

As input we have two polynomials, one depending on the key (i.e.,
invariant when processing a large message), represented as 128 bits
each. Split them in 64-bit pieces we can reason about,

  A = a_1(x) x^64 + a_0(x), B = b_1(x) x^64 + b_0(x), 

with (unreduced) product C(x) = A(x) B(x), split in 64-bit pieces as

  C(x) = c_3(x) x^192 + c_2(x) x^128 + c_1(x) x^64 + c_0 (x)

(where c_3 actually is only 63 bits). To reduce, we use x^128 = p'(x)
(mod p(x)). We'd then need to multiply the high half with p'(x), say 

  D = (c_3(x) x^64 + c_2(x) ) p'(x) = d_2(x) x^128 + d_1(x) 2^64 + d_0(x)

where we get the high few bits in d_2(x). So we'd need to compute d_2
p'(x) again. And finally, we get the result C(x) mod p by summing/xoring

  c_1(x) x^64 +     c_0(x)
  d_1(x) x^64 +     d_0(x)
                d2(x) p'(x)
--------------------------

Now, let's look closer at the initial multiplication, A(x) B(x), which
can be expanded as 

  a_1(x) b_1(x) x^128 + (a_1(x) b_0(x) + a_0(x) b_1(x)) x^64 + a_0(x) b_0(x)

I see two tricks: First, we can precompute a'_2(x) x^64 + a'_1(x) = a_1(x) x^128 (mod
(p(x)), and replace the first term with

  (a'_2(x) x^64 + a'_1(x)) b_1(x)

That should eliminate the annoying high bits d_2 in the reduction, at
the cost one one more 64x64 multiply. I would expect that's the same
number of operations, but more shallow dependency path. We get a 192-bit
partially reduced result, instad of the full 256-bit result. Let's
denote this product as

  h_2(x) x^128 + h_1(x) x^64 + h_0(x) = (a'_2(x) x^64) + a'_1(x)) b_1(x)

Second, if we also prepare a register with the swapped A, a_0(x) x^64 +
a_1(x), then the vpmsumd instruction, if I understand you correctly, can
compute the middle term (a_1(x) b_0(x) + a_0(x) b_1(x)) in one
operation. So we get down to 3 64x64 multiplies for free, without tghe
reconstruction needed for standard Karatsuba multiplication. So if we
compute the middle term like this,

 m_1(x) x^64 + m_0(x) = a_1(x) b_0(x) + a_0(x) b_1(x)

The part we need to fold is m_1(x) + h_2(x)
then we get the fully reduced result by summing

  a_0(x) b_0(x)         (127 bits, one vpmsumd with one input half zero)
  m_0(x)                (64 bits)
  h_1(x) h_0(x)         (128 bits)
  (m_1(x) + h_2(x))p'(x) (70 or so bits)

If I count it correctly, we get the fully reduced result with 5 vpmsumd
multiplicatiions, one for a_0 b_0, one for the midle terms, two for the
miltiplication with a', and one for the only explicit multiplication
with p'(x). And if we do multiple blocks in parallel, they can share
share this final multiply.

There are sure further tricks, e.g., it seems the a_0(x) b_0(x) multiply
can share an vpmsumd instruction with the a'_1(x) b_1(x) multiply,
if we just prepare a register with a'_1(x) x^64 + a_0(x); then the
replacement of a_1 with the twice as large a' values seems for free. One
could also attempt to let operations corresponding to separate input
blocks share vpmsumd instructions.


Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201005072700</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-10-05 07:27:00-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" GCM support</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; +L4x_loop:
[...]
&gt; +    C polynomial multiplication "classical" pre-processing
&gt; +    xxmrghd        VSR(C23h),VSR(C2),VSR(C3)
&gt; +    xxmrgld        VSR(C23l),VSR(C2),VSR(C3)
&gt; +    xxmrghd        VSR(C01h),VSR(C0),VSR(C1)
&gt; +    xxmrgld        VSR(C01l),VSR(C0),VSR(C1)
&gt; +
&gt; +    C polynomial multiplication "classical"
&gt; +    vpmsumd        C3,C3,H1                      C M3 = H^1l*C3h⊕H^1h*C3l
&gt; +    vpmsumd        C2,C2,H2                      C M2 = H^2l*C2h⊕H^2h*C2l
&gt; +    vpmsumd        C1,C1,H3                      C M1 = H^3l*C1h⊕H^3h*C1l
&gt; +    vpmsumd        C0,C0,H4                      C M0 = H^4l*C0h⊕H^4h*C0l
&gt; +    vpmsumd        C23h,C23h,H21h                C H23 = H^2h*C2h⊕H^1h*C3h
&gt; +    vpmsumd        C23l,C23l,H21l                C L23 = H^2l*C2l⊕H^1l*C3l
&gt; +    vpmsumd        C01h,C01h,H43h                C H01 = H^4h*C0h⊕H^4h*C1h
&gt; +    vpmsumd        C01l,C01l,H43l                C L01 = H^4l*C0l⊕H^4l*C1l

So you do 4 blocks with only 10 vpmsumd instructions (the 8 above, and 2
more below for the reduction). That's nice! It would be even nicer if
the H terms could be rearranged to eliminate the pre-processing of the C
values.

And it is all with polynomials bits reversed compared to the spec? I
find the spec,
https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-38d.pdf,
not crystal clear, but as I understand it, the bit that is least
significant when interpreted as a plain integer corresponds to the
highest power of x, while instructions like vpmsumd use the opposite
(and more natural, imo) convention.

This is how I understand bit reversal. We want

  c(x) = a(x) b(x) mod p(x) = a(x) b(x) + q(x) p(x)

where a, b and c all are 128 bits, p is 129 bits, and q is 127 bits
(chosen so the high 127 bits of the 255 bit product cancel). Reverse as

  c'(x) = x^127 c(1/x), similarly for a', b',

  q'(x) = x^126 q(1/x), p'(x) = x^128 p(1/x)

Then we get

  c'(x) = [a'(x) b'(x) + q'(x) p'(x)] / x^127

i.e., q' now cancels the *low* 127 bits of the product. Which can also be
written as

  c'(x) = a'(x) b'(x) / x^127 (mod p'(x))

So in this way, bit reversal is a bit similar to montgomery
representation for modular arithmetic on integers. And if 128 and
corresponding bit boundary is more convenient than 127, one can either
shift the product one bit left, or premultiply one of the factors with x
mod p'(x).

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201005181853</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-10-05 18:18:53-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" GCM support</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt;&gt; +L4x_loop:
&gt; [...]
&gt;&gt; +    C polynomial multiplication "classical" pre-processing
&gt;&gt; +    xxmrghd        VSR(C23h),VSR(C2),VSR(C3)
&gt;&gt; +    xxmrgld        VSR(C23l),VSR(C2),VSR(C3)
&gt;&gt; +    xxmrghd        VSR(C01h),VSR(C0),VSR(C1)
&gt;&gt; +    xxmrgld        VSR(C01l),VSR(C0),VSR(C1)
&gt;&gt; +
&gt;&gt; +    C polynomial multiplication "classical"
&gt;&gt; +    vpmsumd        C3,C3,H1                      C M3 = H^1l*C3h⊕H^1h*C3l
&gt;&gt; +    vpmsumd        C2,C2,H2                      C M2 = H^2l*C2h⊕H^2h*C2l
&gt;&gt; +    vpmsumd        C1,C1,H3                      C M1 = H^3l*C1h⊕H^3h*C1l
&gt;&gt; +    vpmsumd        C0,C0,H4                      C M0 = H^4l*C0h⊕H^4h*C0l
&gt;&gt; +    vpmsumd        C23h,C23h,H21h                C H23 = H^2h*C2h⊕H^1h*C3h
&gt;&gt; +    vpmsumd        C23l,C23l,H21l                C L23 = H^2l*C2l⊕H^1l*C3l
&gt;&gt; +    vpmsumd        C01h,C01h,H43h                C H01 = H^4h*C0h⊕H^4h*C1h
&gt;&gt; +    vpmsumd        C01l,C01l,H43l                C L01 = H^4l*C0l⊕H^4l*C1l
&gt;
&gt; So you do 4 blocks with only 10 vpmsumd instructions (the 8 above, and 2
&gt; more below for the reduction). That's nice! It would be even nicer if
&gt; the H terms could be rearranged to eliminate the pre-processing of the C
&gt; values.

I think I've found a slightly better way to organize it. I'm assuming
bit reversal and that we have pre-multiplied the key factor by x, so
that we need to compute

  A(x) B(x) / x^128 (mod P(x))

where P(x) is the reversed polynomial P(x) = x^128 + x^127 + x^126 +
x^121 + 1. Denote the 64-bit pieces as

  A(x) = a_1(x) x^64 + a_0(x), B(x) = b_1(x) x^64 + b_0(x)

We do precomputations on B (the key, invariant when processing a message
of multiple blocks).

First, compute b_0(x) / x^64 (mod P(x)), which expands it from 64 bits to
128,

  c_1(x) x^64 + c_0(x) = b_0(x) / x^64 (mod P(x))

Next, add together d_1 = b_1 + c_0. We can then write (to simplify
notation, everything below is (mod P(x)), + means xor, and we also omit
the (x) arguments).

  A B / x^128 = a_1 b_1 + (a_0 b_1 + a_1 b_0) / x^64 + a_0 b_0 / x^128
              = a_1 b_1 + (a_0 b_1 + a_1 b_0) / x^64 + a_0 (c_1 x^64 + c_0) / x^64
              = a_1 b_1 + a_0 c_1 + (a_0 b_1 + a_1 b_0 + a_0 c_0) / 2^64
              = a_1 b_1 + a_0 c_1 + (a_0 d_1 + a_1 b_0) / x^64
                `------R--------'    `------F--------'

So if we have the input in register A (loaded from memory with no
processing besides ensuring proper *byte* order), and precompute two
values, M representing b_1(x) x^64 + c_1(x), and L representing b_0(x)
x^64 + d_1(x)), then we get the two halves above with two vpmsumd,

  vpmsumd R, M, A
  vpmsumd F, L, A

When doing more than one block at a time, I think it's easiest to
accumulate the R and F values separately.

After accumulation, we have the pieces

  R = r_1 x^64 + r_0, F = f_1 x^64 + f_0
 
To do the division with x^64 (mod P), and reduce to a 128-bit result. we
need to cancel f_0, and we do that by adding multiplyign f_0 P and
adding in:
  
  (f_1 x^64 + f_0 + f_0 P) / 2^64 = f_1 + f_0 (x^64 + x^63 + x^62 + x^57)

If we prepare a register G representing the constant polynomial (x^63 +
x^62 + x^57), i.e, all zero high part, we can do that as

  vpmsumd T, F, G

and then to get the final result, we need to xor together the three
values

   r_1 x^64 + r_0
   f_0 x^64 + f_1   (F swapped)
   t_1 x^64 + t_0

It may be worth noting that both r_1 and t_1 are only 63 bits, so it's
only the contribution of f_0 in the high half position that increases
the size of the result from 127 bits to 128.

There are some possible variations of the final reduction, e.g, one
could use G' = x^63 + x^62 + x^61 + x^56 (i.e., one more term), but then
left shift the result of f_0 G'. With some different and really clever
handling of the extra x factor (here, assumed premultiplied into b),
maybe one could use a single vpmsumd to multiply f_0 G' and add in f_1
at the right place before shifting.

So to sum up, with this method, there's no preprocessing of the input,
two vpmsumd per block to produce the values to be accumulated (same as
in your patch), and a single vpmsumd (one less than in your patch) for
the final reduction.

Furthermore, there's actually no need to do the final reduction until
the end of the message. If we can keep the accumulated R and M values
separately in the gcm_ctx struct (an ABI change, though), the final
reduction can be postponed until gcm_digest is called.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201011141702</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-10-11 14:17:02-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" GCM support</subject><body>

Hi Niels,

I tried to apply your method but can't get it work, while applying it one
question came to my mind.


&gt; First, compute b_0(x) / x^64 (mod P(x)), which expands it from 64 bits to
&gt; 128,
&gt;
&gt;   c_1(x) x^64 + c_0(x) = b_0(x) / x^64 (mod P(x))
&gt;

Here you are trying to get partially reduced product by computing b_0(x) /
x^64 (mod P(x)) but since the degree of input is 127,  we can use the
polynomial defining the finite field with x^64 elements, in this case P(x)
= X^64+X^4+X^3+X+1 and P' = P^-1 (mod X^64) = X^63+X^61+X^60+1 which is the
same constant 0xB0 and the function now: c_1(x) x^64 + c_0(x) = ((b_0 mod
X^64) * p') mod X^64
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201011142037</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-10-11 14:20:37-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" GCM support</subject><body>

Forgot to mention that P(x) = X^64+X^63+X^61+X^60+1 after being reflected.

Regards,
Mamone

On Sun, Oct 11, 2020 at 5:17 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
wrote:

&gt; Hi Niels,
&gt;
&gt; I tried to apply your method but can't get it work, while applying it one
&gt; question came to my mind.
&gt;
&gt;
&gt;&gt; First, compute b_0(x) / x^64 (mod P(x)), which expands it from 64 bits to
&gt;&gt; 128,
&gt;&gt;
&gt;&gt;   c_1(x) x^64 + c_0(x) = b_0(x) / x^64 (mod P(x))
&gt;&gt;
&gt;
&gt; Here you are trying to get partially reduced product by computing b_0(x) /
&gt; x^64 (mod P(x)) but since the degree of input is 127,  we can use the
&gt; polynomial defining the finite field with x^64 elements, in this case P(x)
&gt; = X^64+X^4+X^3+X+1 and P' = P^-1 (mod X^64) = X^63+X^61+X^60+1 which is the
&gt; same constant 0xB0 and the function now: c_1(x) x^64 + c_0(x) = ((b_0 mod
&gt; X^64) * p') mod X^64
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201011171437</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-10-11 17:14:37-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" GCM support</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; Hi Niels,
&gt;
&gt; I tried to apply your method but can't get it work,

Hmm, do you think I've missed something in the math, or are there other
difficulties?

&gt; while applying it one
&gt; question came to my mind.
&gt;
&gt;
&gt;&gt; First, compute b_0(x) / x^64 (mod P(x)), which expands it from 64 bits to
&gt;&gt; 128,
&gt;&gt;
&gt;&gt;   c_1(x) x^64 + c_0(x) = b_0(x) / x^64 (mod P(x))
&gt;&gt;
&gt;
&gt; Here you are trying to get partially reduced product by computing b_0(x) /
&gt; x^64 (mod P(x)) but since the degree of input is 127,  we can use the
&gt; polynomial defining the finite field with x^64 elements, in this case P(x)
&gt; = X^64+X^4+X^3+X+1 and P' = P^-1 (mod X^64) = X^63+X^61+X^60+1 which is the
&gt; same constant 0xB0 and the function now: c_1(x) x^64 + c_0(x) = ((b_0 mod
&gt; X^64) * p') mod X^64

For correctness, I think it is important that the computation b_0(x) /
x^64 is done modulo the gcm polynomial (originally, x^128 + x^7 + x^2 +
x + 1, but after bit reflection, P(x) = x^128 + x^127 + x^126 + x^125 +
1).

I don't see how one can do part of the computation in GF(2^64), or how
your degree-64 polynomial relates the the original degree-128
polynomial. If there's some useful embedding of GF(2^64) as a subfield
of GF(2^128), please explain?

That said, division by x^64 is fairly cheap, since P(x) = 1 (mod x^64).
I think we get

  b_0(x) / x^64 (mod P(x)) = b_0(x) (1 + P(x)) / x^64 (mod P(x)

where we can simplify (P(x) + 1) / x^64 to x^64 + x^63 + x^62 + x^58, or

  b_0(x) / x^64 (mod P(x)) = b_0(x) (x^64 to x^64 + x^63 + x^62 + x^58)

So no reduction needed, just split the product in high and low part to
get c_1 and c_0.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201011184721</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-10-11 18:47:21-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" GCM support</subject><body>

Thanks for the clarification, I just misunderstanded the division with the
partial reduction in a previous reply.

Ok, so you mean a polynomial division of  b_0(x) by P(x) where P(x) = X^128
+  X^127 +  X^126 +  X^121 + 1
b_0(x)/P(x) = (b_0(x)*(p^-1 mod P(x))) mod P(x)
b_0(x)/P(x) = (b_0(x)*(p')) mod P(x)
P(x) = X^64 +  X^63 +  X^62 +  X^57
P' = p^-1 mod P(x) = X^63 +  X^62 +  X^57
so the constant 0xC2

let me show you part of the new implementation of _nettle_gcm_init_key in
PPC

    C --- calculate [H = H &lt;&lt; 1 modulo polynomial] ---

    vupkhsb        EMSB,H                        C extend most significant
bit to first byte
    vspltisb       B1,1                          C
0x01010101010101010101010101010101
    vspltb         EMSB,EMSB,0                   C first byte
quadword-extend
    vsl            H,H,B1                        C H = H &lt;&lt; 1
    vand           EMSB,EMSB,POLY                C EMSB &amp;=
0xC2000000000000000000000000000001
    vxor           ZERO,ZERO,ZERO                C
0x00000000000000000000000000000000
    vxor           H,H,EMSB                      C H ^= EMSB

    xxmrghd        VSR(POLY_L),VSR(ZERO),VSR(POLY) C
0x0000000000000000C200000000000000
    xxmrghd        VSR(POLY_H),VSR(POLY),VSR(ZERO) C
0xC2000000000000000000000000000000

    C --- calculate [H^2 = H*H] ---

    xxswapd        VSR(Hm),VSR(H)
    vpmsumd        HP,H,POLY_L
    vxor           L,HP,Hm
    xxmrghd        VSR(M),VSR(H),VSR(HP)
    xxmrgld        VSR(L),VSR(H),VSR(L)

    vpmsumd        R,M,H
    vpmsumd        F,L,H

    vpmsumd        T,F,POLY_H
    xxswapd        VSR(F),VSR(F)
    vxor           R,R,T
    vxor           R,R,F

R still yields the wrong value of H^2, did I miss something in the
implementation or did it wrong?

On Sun, Oct 11, 2020 at 8:14 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt; Hi Niels,
&gt; &gt;
&gt; &gt; I tried to apply your method but can't get it work,
&gt;
&gt; Hmm, do you think I've missed something in the math, or are there other
&gt; difficulties?
&gt;
&gt; &gt; while applying it one
&gt; &gt; question came to my mind.
&gt; &gt;
&gt; &gt;
&gt; &gt;&gt; First, compute b_0(x) / x^64 (mod P(x)), which expands it from 64 bits
&gt; to
&gt; &gt;&gt; 128,
&gt; &gt;&gt;
&gt; &gt;&gt;   c_1(x) x^64 + c_0(x) = b_0(x) / x^64 (mod P(x))
&gt; &gt;&gt;
&gt; &gt;
&gt; &gt; Here you are trying to get partially reduced product by computing b_0(x)
&gt; /
&gt; &gt; x^64 (mod P(x)) but since the degree of input is 127,  we can use the
&gt; &gt; polynomial defining the finite field with x^64 elements, in this case
&gt; P(x)
&gt; &gt; = X^64+X^4+X^3+X+1 and P' = P^-1 (mod X^64) = X^63+X^61+X^60+1 which is
&gt; the
&gt; &gt; same constant 0xB0 and the function now: c_1(x) x^64 + c_0(x) = ((b_0 mod
&gt; &gt; X^64) * p') mod X^64
&gt;
&gt; For correctness, I think it is important that the computation b_0(x) /
&gt; x^64 is done modulo the gcm polynomial (originally, x^128 + x^7 + x^2 +
&gt; x + 1, but after bit reflection, P(x) = x^128 + x^127 + x^126 + x^125 +
&gt; 1).
&gt;
&gt; I don't see how one can do part of the computation in GF(2^64), or how
&gt; your degree-64 polynomial relates the the original degree-128
&gt; polynomial. If there's some useful embedding of GF(2^64) as a subfield
&gt; of GF(2^128), please explain?
&gt;
&gt; That said, division by x^64 is fairly cheap, since P(x) = 1 (mod x^64).
&gt; I think we get
&gt;
&gt;   b_0(x) / x^64 (mod P(x)) = b_0(x) (1 + P(x)) / x^64 (mod P(x)
&gt;
&gt; where we can simplify (P(x) + 1) / x^64 to x^64 + x^63 + x^62 + x^58, or
&gt;
&gt;   b_0(x) / x^64 (mod P(x)) = b_0(x) (x^64 to x^64 + x^63 + x^62 + x^58)
&gt;
&gt; So no reduction needed, just split the product in high and low part to
&gt; get c_1 and c_0.
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201011195631</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-10-11 19:56:31-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" GCM support</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; Thanks for the clarification, I just misunderstanded the division with the
&gt; partial reduction in a previous reply.
&gt;
&gt; Ok, so you mean a polynomial division of  b_0(x) by P(x) where P(x) = X^128
&gt; +  X^127 +  X^126 +  X^121 + 1
&gt; b_0(x)/P(x) = (b_0(x)*(p^-1 mod P(x))) mod P(x)
&gt; b_0(x)/P(x) = (b_0(x)*(p')) mod P(x)
&gt; P(x) = X^64 +  X^63 +  X^62 +  X^57
&gt; P' = p^-1 mod P(x) = X^63 +  X^62 +  X^57
&gt; so the constant 0xC2

Hmm, I'm not following you (and it seems you are using P(x) to refer to
two different polynomials). The operation is a bit similar to Montgomery
redc, and it has taken me some time to get used to the initially strange
mix of operations mod P(x) and mod x^k (or in the integer case, it's a
mix of mod m, with m odd, and mod 2^k).

  b_0(x) / x^64 (mod P(x)) 

can be computed in two different ways, giving the same result: 

   (i) Compute the inverse u(x) = (x^64){-1} mod P(x), then multiply
       b_0(x) u(x) (mod P(x))

       We get u(x) = x^64 + x^63 + x^62 + x^57, with degree only 64.
       (This is thanks to the special structure of P(x); an inverse of
       some arbitrary element mod a 128-degree polynomial would be
       expected to be larger).
       

  (ii) Add a multiple of P(x) to b_0(x) to make the the lowest 64
       coefficients all cancel, then divide by x^64 by simply shifting /
       subtracting 64 from exponents of remaining terms. And because of
       the special structure of P(x), P(x) = 1 mod x^64, the right
       multiple is b_0(x) P(x). So

       b_0(x) + P(x) b_0(x)

       is a degree 191 polynomial, with the least 64 coefficients all
       zero. When simplified, it boils down to the same b_0(x) u(x), no
       additional reduction needed.

I tend to think about reductions (from either end) in terms of
cancelling bits, so to me, (ii) is a familiar way to think about it.

&gt; let me show you part of the new implementation of _nettle_gcm_init_key in
&gt; PPC
&gt;
&gt;     C --- calculate [H = H &lt;&lt; 1 modulo polynomial] ---
&gt;
&gt;     vupkhsb        EMSB,H                        C extend most significant
&gt; bit to first byte
&gt;     vspltisb       B1,1                          C
&gt; 0x01010101010101010101010101010101
&gt;     vspltb         EMSB,EMSB,0                   C first byte
&gt; quadword-extend
&gt;     vsl            H,H,B1                        C H = H &lt;&lt; 1
&gt;     vand           EMSB,EMSB,POLY                C EMSB &amp;=
&gt; 0xC2000000000000000000000000000001
&gt;     vxor           ZERO,ZERO,ZERO                C
&gt; 0x00000000000000000000000000000000
&gt;     vxor           H,H,EMSB                      C H ^= EMSB
&gt;
&gt;     xxmrghd        VSR(POLY_L),VSR(ZERO),VSR(POLY) C
&gt; 0x0000000000000000C200000000000000
&gt;     xxmrghd        VSR(POLY_H),VSR(POLY),VSR(ZERO) C
&gt; 0xC2000000000000000000000000000000
&gt;
&gt;     C --- calculate [H^2 = H*H] ---
&gt;
&gt;     xxswapd        VSR(Hm),VSR(H)
&gt;     vpmsumd        HP,H,POLY_L
&gt;     vxor           L,HP,Hm
&gt;     xxmrghd        VSR(M),VSR(H),VSR(HP)
&gt;     xxmrgld        VSR(L),VSR(H),VSR(L)
&gt;
&gt;     vpmsumd        R,M,H
&gt;     vpmsumd        F,L,H
&gt;
&gt;     vpmsumd        T,F,POLY_H
&gt;     xxswapd        VSR(F),VSR(F)
&gt;     vxor           R,R,T
&gt;     vxor           R,R,F
&gt;
&gt; R still yields the wrong value of H^2, did I miss something in the
&gt; implementation or did it wrong?

I'm afraid I don't follow all details (and I would suggest trying to get
the most basic variant working first, doing only a single block at a
time). But one potential issue is the powers of x. If H(x) is the
original key, then I think you need to precompute values corresponding
to

  x H(x) (mod P(x))
  x H(x)^2 (mod P(x))

But it looks like you may be computing

  (x H(x))^2 / x^128 =  x^2 H(x)^2 / x^128

which is different. It's easy to get confused, but I think the
precomputation needs a standard mod P(x), i.e., adding a multiple of
P(x) cancelling the most significant coefficients, rather than the more
efficient reduction cancelling the least significant coefficients.

If you're familiar with montgomery multiplication of integers, there
it's possible to consistently use the operation a,b -&gt; ab / 2^k
everywhere, but that requires that all inputs are transformed to
montgomery form, a --&gt; 2^k a mod m. And in this case, it's desirable to
scale the precomputed values appropriately, so no such transformation is
needed for the inputs corresponding to message blocks.

To compute more powers of H, one could do the standard reduction only
once, essentially transforming H to montgomery form,

  H' = H(x) x^128 (mod P(x)),

then further powers of H can use the reduction of least significant
coefficients,

  (x H(x)) H' / x^128 = x H(x)^2

  (x H(x)^2) H' / x^128 = x H(x)^3

etc.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201120211314</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-11-20 21:13:14-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

On Fri, Nov 20, 2020 at 10:40 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; nisse@lysator.liu.se (Niels Möller) writes:
&gt; The
&gt; intention of this piece of code is just to construct the value {1, 0, 0,
&gt; 0} in one of the vector registers. Maybe there's a better way to do
&gt; that?
&gt;

The cheapest replacement I can think of:

vspltisw   ZERO,0                            C
0x00000000000000000000000000000000
vspltisw   ONE,1                              C
0x00000001000000010000000100000001
vsldoi       ONE, ONE, ZERO,12      C  0x00000001000000000000000000000000

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201121151149</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-11-21 15:11:49-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; GCC112 is a POWER8 machine. According to the POWER manual, vextractuw
&gt; is a POWER9 instruction.
&gt;
&gt; POWER8 manual: https://openpowerfoundation.org/?resource_lib=power8-processor-users-manual
&gt; POWER9 manual: https://openpowerfoundation.org/?resource_lib=power9-processor-users-manual

Ooops. I was reading a document titled "Power ISA(tm) Version 3.1".
There are changebars indicating changes from version 3.0, which I
weren't paying much attention to. Which POWER version does ISA Version
3.0 correspond to?

I would like to target Power 7 for the chacha code.

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; The cheapest replacement I can think of:
&gt;
&gt; vspltisw   ZERO,0                            C
&gt; 0x00000000000000000000000000000000
&gt; vspltisw   ONE,1                              C
&gt; 0x00000001000000010000000100000001
&gt; vsldoi       ONE, ONE, ZERO,12      C  0x00000001000000000000000000000000

Thanks, I'll try that.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201121152041</emailId><senderName>David Edelsohn</senderName><senderEmail>dje.gcc@gmail.com</senderEmail><timestampReceived>2020-11-21 15:20:41-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

Please don't target Power7.  Please target Power9, or at least Power8.

The PPC64LE Linux ABI specifies Power8 as the minimum ISA.

Power ISA 2.07 is Power8.  ISA 3.0 is Power9.  ISA 3.1 is Power10.

Thanks, David

On Sat, Nov 21, 2020 at 10:11 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; Jeffrey Walton &lt;noloader@gmail.com&gt; writes:
&gt;
&gt; &gt; GCC112 is a POWER8 machine. According to the POWER manual, vextractuw
&gt; &gt; is a POWER9 instruction.
&gt; &gt;
&gt; &gt; POWER8 manual: https://openpowerfoundation.org/?resource_lib=power8-processor-users-manual
&gt; &gt; POWER9 manual: https://openpowerfoundation.org/?resource_lib=power9-processor-users-manual
&gt;
&gt; Ooops. I was reading a document titled "Power ISA(tm) Version 3.1".
&gt; There are changebars indicating changes from version 3.0, which I
&gt; weren't paying much attention to. Which POWER version does ISA Version
&gt; 3.0 correspond to?
&gt;
&gt; I would like to target Power 7 for the chacha code.
&gt;
&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt; The cheapest replacement I can think of:
&gt; &gt;
&gt; &gt; vspltisw   ZERO,0                            C
&gt; &gt; 0x00000000000000000000000000000000
&gt; &gt; vspltisw   ONE,1                              C
&gt; &gt; 0x00000001000000010000000100000001
&gt; &gt; vsldoi       ONE, ONE, ZERO,12      C  0x00000001000000000000000000000000
&gt;
&gt; Thanks, I'll try that.
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt; _______________________________________________
&gt; nettle-bugs mailing list
&gt; nettle-bugs@lists.lysator.liu.se
&gt; http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201121155711</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-11-21 15:57:11-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

On Sat, Nov 21, 2020 at 10:20 AM David Edelsohn &lt;dje.gcc@gmail.com&gt; wrote:
&gt;
&gt; Please don't target Power7.  Please target Power9, or at least Power8.
&gt;
&gt; The PPC64LE Linux ABI specifies Power8 as the minimum ISA.
&gt;
&gt; Power ISA 2.07 is Power8.  ISA 3.0 is Power9.  ISA 3.1 is Power10.

Small nit... PowerMac G4's and G5's still have a strong following.
There's a lot of activity on Debian's PowerPC list.

The G4's and G5's provide Altivec acceleration and the old gcc
compiler even accepts -mcpu=power4.

ChaCha is a simple algorithm that benefits from Altivec, even when you
manage the 64-bit additions/carries in a 32x4 vector arrangement.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201121162333</emailId><senderName>David Edelsohn</senderName><senderEmail>dje.gcc@gmail.com</senderEmail><timestampReceived>2020-11-21 16:23:33-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

On Sat, Nov 21, 2020 at 10:57 AM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:
&gt;
&gt; On Sat, Nov 21, 2020 at 10:20 AM David Edelsohn &lt;dje.gcc@gmail.com&gt; wrote:
&gt; &gt;
&gt; &gt; Please don't target Power7.  Please target Power9, or at least Power8.
&gt; &gt;
&gt; &gt; The PPC64LE Linux ABI specifies Power8 as the minimum ISA.
&gt; &gt;
&gt; &gt; Power ISA 2.07 is Power8.  ISA 3.0 is Power9.  ISA 3.1 is Power10.
&gt;
&gt; Small nit... PowerMac G4's and G5's still have a strong following.
&gt; There's a lot of activity on Debian's PowerPC list.
&gt;
&gt; The G4's and G5's provide Altivec acceleration and the old gcc
&gt; compiler even accepts -mcpu=power4.
&gt;
&gt; ChaCha is a simple algorithm that benefits from Altivec, even when you
&gt; manage the 64-bit additions/carries in a 32x4 vector arrangement.

Small nit: G4 and G5 Macs are not Power7.  If an implementation of a
cipher targets Power7, it still can use ISA instructions not supported
by PowerMacs.  If you want to provide an additional implementation for
pure Altivec, that's fine.

There is a vocal group of Debian PowerPC users.  I greatly appreciate
support and advocacy.  But the number of actual users is very small.
And it's highly unlikely that those users will run ChaCha cipher in
production.  The ChaCha implementation is new, not maintaining
existing support.

If Niels wants to implement an optimized version of a cipher on Power
that will be useful in production environments and applied in global
businesses, I would recommend that he target Power9.  A new,
high-performance implementation will be deployed on new systems for
new applications or new versions of applications.

Thanks, David
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201121163153</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-11-21 16:31:53-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

On Sat, Nov 21, 2020 at 11:23 AM David Edelsohn &lt;dje.gcc@gmail.com&gt; wrote:
&gt;
&gt; On Sat, Nov 21, 2020 at 10:57 AM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:
&gt; &gt;
&gt; &gt; On Sat, Nov 21, 2020 at 10:20 AM David Edelsohn &lt;dje.gcc@gmail.com&gt; wrote:
&gt; &gt; &gt;
&gt; &gt; &gt; Please don't target Power7.  Please target Power9, or at least Power8.
&gt; &gt; &gt;
&gt; &gt; &gt; The PPC64LE Linux ABI specifies Power8 as the minimum ISA.
&gt; &gt; &gt;
&gt; &gt; &gt; Power ISA 2.07 is Power8.  ISA 3.0 is Power9.  ISA 3.1 is Power10.
&gt; &gt;
&gt; &gt; Small nit... PowerMac G4's and G5's still have a strong following.
&gt; &gt; There's a lot of activity on Debian's PowerPC list.
&gt; &gt;
&gt; &gt; The G4's and G5's provide Altivec acceleration and the old gcc
&gt; &gt; compiler even accepts -mcpu=power4.
&gt; &gt;
&gt; &gt; ChaCha is a simple algorithm that benefits from Altivec, even when you
&gt; &gt; manage the 64-bit additions/carries in a 32x4 vector arrangement.
&gt;
&gt; Small nit: G4 and G5 Macs are not Power7.  If an implementation of a
&gt; cipher targets Power7, it still can use ISA instructions not supported
&gt; by PowerMacs.  If you want to provide an additional implementation for
&gt; pure Altivec, that's fine.

Correct.

&gt; There is a vocal group of Debian PowerPC users.  I greatly appreciate
&gt; support and advocacy.  But the number of actual users is very small.
&gt; And it's highly unlikely that those users will run ChaCha cipher in
&gt; production.  The ChaCha implementation is new, not maintaining
&gt; existing support.
&gt;
&gt; If Niels wants to implement an optimized version of a cipher on Power
&gt; that will be useful in production environments and applied in global
&gt; businesses, I would recommend that he target Power9.  A new,
&gt; high-performance implementation will be deployed on new systems for
&gt; new applications or new versions of applications.

When you said the library should not target POWER7, and only target
POWER8 and POWER9, I took that to mean the library should not target
POWER7 and below.

Altivec and POWER4 is a fine target given the user base. It will even
run on POWER7.

An Altivec version of ChaCha is an easy implementation. There are no
pain points in implementing it.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201121164120</emailId><senderName>David Edelsohn</senderName><senderEmail>dje.gcc@gmail.com</senderEmail><timestampReceived>2020-11-21 16:41:20-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

On Sat, Nov 21, 2020 at 11:32 AM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:
&gt;
&gt; On Sat, Nov 21, 2020 at 11:23 AM David Edelsohn &lt;dje.gcc@gmail.com&gt; wrote:
&gt; &gt;
&gt; &gt; On Sat, Nov 21, 2020 at 10:57 AM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:
&gt; &gt; &gt;
&gt; &gt; &gt; On Sat, Nov 21, 2020 at 10:20 AM David Edelsohn &lt;dje.gcc@gmail.com&gt; wrote:
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; Please don't target Power7.  Please target Power9, or at least Power8.
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; The PPC64LE Linux ABI specifies Power8 as the minimum ISA.
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; Power ISA 2.07 is Power8.  ISA 3.0 is Power9.  ISA 3.1 is Power10.
&gt; &gt; &gt;
&gt; &gt; &gt; Small nit... PowerMac G4's and G5's still have a strong following.
&gt; &gt; &gt; There's a lot of activity on Debian's PowerPC list.
&gt; &gt; &gt;
&gt; &gt; &gt; The G4's and G5's provide Altivec acceleration and the old gcc
&gt; &gt; &gt; compiler even accepts -mcpu=power4.
&gt; &gt; &gt;
&gt; &gt; &gt; ChaCha is a simple algorithm that benefits from Altivec, even when you
&gt; &gt; &gt; manage the 64-bit additions/carries in a 32x4 vector arrangement.
&gt; &gt;
&gt; &gt; Small nit: G4 and G5 Macs are not Power7.  If an implementation of a
&gt; &gt; cipher targets Power7, it still can use ISA instructions not supported
&gt; &gt; by PowerMacs.  If you want to provide an additional implementation for
&gt; &gt; pure Altivec, that's fine.
&gt;
&gt; Correct.
&gt;
&gt; &gt; There is a vocal group of Debian PowerPC users.  I greatly appreciate
&gt; &gt; support and advocacy.  But the number of actual users is very small.
&gt; &gt; And it's highly unlikely that those users will run ChaCha cipher in
&gt; &gt; production.  The ChaCha implementation is new, not maintaining
&gt; &gt; existing support.
&gt; &gt;
&gt; &gt; If Niels wants to implement an optimized version of a cipher on Power
&gt; &gt; that will be useful in production environments and applied in global
&gt; &gt; businesses, I would recommend that he target Power9.  A new,
&gt; &gt; high-performance implementation will be deployed on new systems for
&gt; &gt; new applications or new versions of applications.
&gt;
&gt; When you said the library should not target POWER7, and only target
&gt; POWER8 and POWER9, I took that to mean the library should not target
&gt; POWER7 and below.
&gt;
&gt; Altivec and POWER4 is a fine target given the user base. It will even
&gt; run on POWER7.
&gt;
&gt; An Altivec version of ChaCha is an easy implementation. There are no
&gt; pain points in implementing it.

Nettle can target any processors and ISA levels that it wishes.  Niels wrote:

&gt; I would like to target Power 7 for the chacha code.

I responded that Power9 (or at least Power8) would be preferred. If
Niels wants the implementation to impact production deployments and
increase the use of Nettle for cryptography on Power systems, I
recommend that he target a more recent level of the ISA.  He can
target Power7, and Power4, and pure Altivec as well.

Thanks, David
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201121205247</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-11-21 20:52:47-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

David Edelsohn &lt;dje.gcc@gmail.com&gt; writes:

&gt; I responded that Power9 (or at least Power8) would be preferred. If
&gt; Niels wants the implementation to impact production deployments and
&gt; increase the use of Nettle for cryptography on Power systems, I
&gt; recommend that he target a more recent level of the ISA.  He can
&gt; target Power7, and Power4, and pure Altivec as well.

The basic chacha code I added some month ago uses altivec instructions,
and the instructions lxvw4x and stxvw4x (with vsr registers) for load and
store, to make it easier to work with data that is only 32-bit aligned.

I put that code under the powerpc64/p7/ directory, under the belief that
the code should work fine for all Power7 and later (with the caveat that
I don't know to which degree altivec is an optional feature).

It may also be relavant to note that with the current configure script,
no power assembly is used unconditionally by default, it has to be
enabled either explicitly with configure arguments, or based on runtine
checks, if configured with --enable-fat.

That means that the name of powerpc64/p7/ directory doesn't matter much
technically (I would be fine to rename it to, e.g., altivec/).
But I got the impression from the list discussion that p7/ was
reasonable.

And my intention is that improved chacha code should target the same
processor flavors as the existing more basic implementation. So I need
to replace the use of the vextractuw (which isn't used in the most
performance critical part of the function).

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201123165012</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-11-23 16:50:12-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

Niels Möller &lt;nisse@lysator.liu.se&gt; writes:

&gt;&gt; It could likely be speedup further by processing 2, 3 or 4 blocks in
&gt;&gt; parallel.
&gt;
&gt; I've given 2 blocks in parallel a try, but not quite working yet. My
&gt; work-in-progress code below.

I've got it into working shape now, at least for little-endian. See
https://git.lysator.liu.se/nettle/nettle/-/blob/ppc-chacha-2core/powerpc64/p7/chacha-2core.asm

Next steps:

1. Fix it to work also for big-endian, 

2. Wire it up for fat builds.

3. Try out if 4-way gives additional speedup.

Benchmarking is appreciated. Compare the master branch to the
ppc-chacha-2core branch, configured with --enable-power-altivec, and run
./examples/nettle-benchmark chacha.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201125070044</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-11-25 07:00:44-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

Thank you for your work.

On POWER9 I got the following benchmark result:

./configured:
chacha      encrypt  308.58
chacha      decrypt  325.87
./configured --enable-power-altivec "master branch":
chacha      encrypt  342.15
chacha      decrypt  356.24
./configured --enable-power-altivec "ppc-chacha-2core":
chacha      encrypt  648.97
chacha      decrypt  648.00

It's gotten better with every further optimization on the core, great work.

regards,
Mamone

On Mon, Nov 23, 2020 at 6:50 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Niels Möller &lt;nisse@lysator.liu.se&gt; writes:
&gt;
&gt; &gt;&gt; It could likely be speedup further by processing 2, 3 or 4 blocks in
&gt; &gt;&gt; parallel.
&gt; &gt;
&gt; &gt; I've given 2 blocks in parallel a try, but not quite working yet. My
&gt; &gt; work-in-progress code below.
&gt;
&gt; I've got it into working shape now, at least for little-endian. See
&gt;
&gt; https://git.lysator.liu.se/nettle/nettle/-/blob/ppc-chacha-2core/powerpc64/p7/chacha-2core.asm
&gt;
&gt; Next steps:
&gt;
&gt; 1. Fix it to work also for big-endian,
&gt;
&gt; 2. Wire it up for fat builds.
&gt;
&gt; 3. Try out if 4-way gives additional speedup.
&gt;
&gt; Benchmarking is appreciated. Compare the master branch to the
&gt; ppc-chacha-2core branch, configured with --enable-power-altivec, and run
&gt; ./examples/nettle-benchmark chacha.
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt; _______________________________________________
&gt; nettle-bugs mailing list
&gt; nettle-bugs@lists.lysator.liu.se
&gt; http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201125082252</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-11-25 08:22:52-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; On POWER9 I got the following benchmark result:
&gt;
&gt; ./configured:
&gt; chacha      encrypt  308.58
&gt; chacha      decrypt  325.87
&gt; ./configured --enable-power-altivec "master branch":
&gt; chacha      encrypt  342.15
&gt; chacha      decrypt  356.24
&gt; ./configured --enable-power-altivec "ppc-chacha-2core":
&gt; chacha      encrypt  648.97
&gt; chacha      decrypt  648.00
&gt;
&gt; It's gotten better with every further optimization on the core, great work.

Nice. So almost a factor 2 speedup from doing 2 blocks in parallel. I
wonder if one can get close to another factor of two by going to 4
blocks. I hope to get the time to try that out, it should be fairly
easy. (And if that does work out fine, maybe the code to do only 2 blocks
could be removed).

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201125145701</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-11-25 14:57:01-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

Niels Möller &lt;nisse@lysator.liu.se&gt; writes:

&gt; I've got it into working shape now, at least for little-endian. See
&gt; https://git.lysator.liu.se/nettle/nettle/-/blob/ppc-chacha-2core/powerpc64/p7/chacha-2core.asm
&gt;
&gt; Next steps:
&gt;
&gt; 1. Fix it to work also for big-endian, 
&gt;
&gt; 2. Wire it up for fat builds.

Done, pushed to the ppc-chacha-2core branch. (I see no obstacles to
merging it to the master branch).

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201125160036</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-11-25 16:00:36-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

On Wed, Nov 25, 2020 at 3:22 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt; On POWER9 I got the following benchmark result:
&gt; &gt;
&gt; &gt; ./configured:
&gt; &gt; chacha      encrypt  308.58
&gt; &gt; chacha      decrypt  325.87
&gt; &gt; ./configured --enable-power-altivec "master branch":
&gt; &gt; chacha      encrypt  342.15
&gt; &gt; chacha      decrypt  356.24
&gt; &gt; ./configured --enable-power-altivec "ppc-chacha-2core":
&gt; &gt; chacha      encrypt  648.97
&gt; &gt; chacha      decrypt  648.00
&gt; &gt;
&gt; &gt; It's gotten better with every further optimization on the core, great work.
&gt;
&gt; Nice. So almost a factor 2 speedup from doing 2 blocks in parallel. I
&gt; wonder if one can get close to another factor of two by going to 4
&gt; blocks. I hope to get the time to try that out, it should be fairly
&gt; easy. (And if that does work out fine, maybe the code to do only 2 blocks
&gt; could be removed).

Botan and Crypto++ uses 4x blocks. They usually hit about the same
benchmark numbers.

For Crypto++ on GCC112, mixed message sizes:

  * ChaCha20: 1200 MB/s, 2.9 cpb
  * ChaCha8: 2370 MB/s, 1.5 cpb

On an antique PowerMac G5:

  * ChaCha20: 400 MB/s, 4.9 cpb
  * ChaCha8: 725 MB/s, 2.6 cpb

Bernstein's results are at https://bench.cr.yp.to/results-stream.html.
He's showing 9 cpb on a 2006 IBM PowerPC. His implementation has a lot
of opportunities for improvement. Also see
https://cr.yp.to/streamciphers/timings/estreambench/submissions/salsa20/chacha8/ppc-altivec/chacha.c.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201130103706</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-11-30 10:37:06-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

Niels Möller &lt;nisse@lysator.liu.se&gt; writes:

&gt; 3. Try out if 4-way gives additional speedup.

Below code seems to work (but is not yet a drop-in replacement, since it
needs some wireup in chacha.crypt.c, and 32-bit counter variant and BE
swapping not yet implemented). Seems to give almost a factor of 2
speedup over chacha_2core. In theory, it could give slightly more than a
factor 2, since all datashuffling between qrounds (the vsldoi
instructinos in the chacha_2core.asm main loop) has been eliminated.

Questions: 

1. Does the save and restore of registers look correct? I checked the
   abi spec, and the intention is to use the part of the 288 byte
   "Protected zone" below the stack pointer.

2. The use of the QR macro means that there's no careful
   instruction-level interleaving of independent instructions. Do you
   think it's beneficial to do manual interleaving (like in
   chacha_2core.asm), or can it be left to the out-of-order execution
   logic run sort it out and execute instructions in parallel?

3. Is there any clever way to construct the vector {0,1,2,3} in a
   register, instead of loading it from memory?

Regards,
/Niels

C powerpc64/chacha-4core.asm

ifelse(`
   Copyright (C) 2020 Niels Möller and Torbjörn Granlund
   This file is part of GNU Nettle.

   GNU Nettle is free software: you can redistribute it and/or
   modify it under the terms of either:

     * the GNU Lesser General Public License as published by the Free
       Software Foundation; either version 3 of the License, or (at your
       option) any later version.

   or

     * the GNU General Public License as published by the Free
       Software Foundation; either version 2 of the License, or (at your
       option) any later version.

   or both in parallel, as here.

   GNU Nettle is distributed in the hope that it will be useful,
   but WITHOUT ANY WARRANTY; without even the implied warranty of
   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
   General Public License for more details.

   You should have received copies of the GNU General Public License and
   the GNU Lesser General Public License along with this program.  If
   not, see http://www.gnu.org/licenses/.
')

C Register usage:

define(`SP', `r1')
define(`TOCP', `r2')

C Argments
define(`DST', `r3')
define(`SRC', `r4')
define(`ROUNDS', `r5')

C Working state in v0,...,v15

define(`ROT16', v16)
define(`ROT12', v17)
define(`ROT8',	v18)
define(`ROT7',	v19)

C During the loop, used to save the original values for last 4 words
C of each block. Also used as temporaries for transpose-
define(`T0', `v20')
define(`T1', `v21')
define(`T2', `v22')
define(`T3', `v23')

C Main loop for round
define(`QR',`
	vadduwm $1, $1, $2
	vxor	$4, $4, $1
	vrlw	$4, $4, ROT16
	vadduwm $3, $3, $4
	vxor	$2, $2, $3
	vrlw	$2, $2, ROT12
	vadduwm $1, $1, $2
	vxor	$4, $4, $1
	vrlw	$4, $4, ROT8
	vadduwm $3, $3, $4
	vxor	$2, $2, $3
	vrlw	$2, $2, ROT7
 ')

define(`TRANSPOSE',`
	vmrghw	T0, $1, $3	C A0 A2 B0 B2
	vmrghw	T1, $2, $4	C A1 A3 B1 B3
	vmrglw	T2, $1, $3	C C0 C2 D0 D2
	vmrglw	T3, $2, $4	C C1 C3 D1 D3

	vmrghw	$1, T0, T1	C A0 A1 A2 A3
	vmrglw	$2, T0, T1	C B0 B1 B2 B3
	vmrghw	$3, T2, T3	C C0 C2 C1 C3
	vmrglw	$4, T2, T3	C D0 D1 D2 D3
')

	C _chacha_4core(uint32_t *dst, const uint32_t *src, unsigned rounds)
define(`FUNC_ALIGN', `5')
PROLOGUE(_nettle_chacha_4core)	

	li	r6, 0x10	C set up some...
	li	r7, 0x20	C ...useful...
	li	r8, 0x30	C ...offsets

	addi	r1, r1, -0x40	C Save callee-save registers
	stvx	v20, 0, r1
	stvx	v21, r6, r1
	stvx	v22, r7, r1
	stvx	v23, r8, r1

	vspltisw ROT16, -16	C -16 instead of 16 actually works!
	vspltisw ROT12, 12
	vspltisw ROT8, 8
	vspltisw ROT7, 7

C Load state while splating it, incrementing "pos" fields as we go
	lxvw4x	VSR(v0),  0, SRC	C "expa ..."
	lxvw4x	VSR(v4),  r6, SRC	C key
	lxvw4x	VSR(v8),  r7, SRC	C key
	lxvw4x	VSR(v12), r8, SRC	C cnt and nonce

	vspltw	v1, v0, 1
	vspltw	v2, v0, 2
	vspltw	v3, v0, 3
	vspltw	v0, v0, 0
	vspltw	v5, v4, 1
	vspltw	v6, v4, 2
	vspltw	v7, v4, 3
	vspltw	v4, v4, 0
	vspltw	v9,  v8, 1
	vspltw	v10, v8, 2
	vspltw	v11, v8, 3
	vspltw	v8,  v8, 0
	vspltw	v13, v12, 1
	vspltw	v14, v12, 2
	vspltw	v15, v12, 3
	vspltw	v12, v12, 0

	ld	r9, .Lcnts@got(r2)
	lxvw4x	VSR(T0), 0, r9	C increments
	vaddcuw	T1, v12, T0	C compute carry-out
	vadduwm	v12, v12, T0	C low adds
	vadduwm	v13, v13, T1	C apply carries

	C Save all 4x4 of the last words.
	vor	T0, v12, v12	C save pos field until...
	vor	T1, v13, v13	C ...after rounds
	vor	T2, v14, v14
	vor	T3, v15, v15

	srdi	ROUNDS, ROUNDS, 1
	mtctr	ROUNDS
.Loop:
	QR(v0, v4,  v8, v12)
	QR(v1, v5,  v9, v13)
	QR(v2, v6, v10, v14)
	QR(v3, v7, v11, v15)
	QR(v0, v5, v10, v15)
	QR(v1, v6, v11, v12)
	QR(v2, v7,  v8, v13)
	QR(v3, v4,  v9, v14)
	bdnz	.Loop

	C Add in saved original words, including counters, before
	C transpose.
	vadduwm	v12, v12, T0
	vadduwm	v13, v13, T1
	vadduwm v14, v14, T2
	vadduwm	v15, v15, T3

	TRANSPOSE(v0, v1,v2, v3)
	TRANSPOSE(v4, v5, v6, v7)
	TRANSPOSE(v8, v9, v10, v11)
	TRANSPOSE(v12, v13, v14, v15)

	lxvw4x	VSR(T0),  0, SRC
	lxvw4x	VSR(T1), r6, SRC
	lxvw4x	VSR(T2), r7, SRC

	vadduwm	v0, v0, T0
	vadduwm	v1, v1, T0
	vadduwm	v2, v2, T0
	vadduwm	v3, v3, T0

	vadduwm	v4, v4, T1
	vadduwm	v5, v5, T1
	vadduwm	v6, v6, T1
	vadduwm	v7, v7, T1

	vadduwm	v8, v8, T2
	vadduwm	v9, v9, T2
	vadduwm	v10, v10, T2
	vadduwm	v11, v11, T2

	stxvw4x	VSR(v0), 0, DST
	stxvw4x	VSR(v4), r6, DST
	stxvw4x	VSR(v8), r7, DST
	stxvw4x	VSR(v12), r8, DST

	addi	DST, DST, 64

	stxvw4x	VSR(v1), 0, DST
	stxvw4x	VSR(v5), r6, DST
	stxvw4x	VSR(v9), r7, DST
	stxvw4x	VSR(v13), r8, DST

	addi	DST, DST, 64

	stxvw4x	VSR(v2), 0, DST
	stxvw4x	VSR(v6), r6, DST
	stxvw4x	VSR(v10), r7, DST
	stxvw4x	VSR(v14), r8, DST

	addi	DST, DST, 64

	stxvw4x	VSR(v3), 0, DST
	stxvw4x	VSR(v7), r6, DST
	stxvw4x	VSR(v11), r7, DST
	stxvw4x	VSR(v15), r8, DST

	C Restore callee-save registers
	lvx	v20, 0, r1
	lvx	v21, r6, r1
	lvx	v22, r7, r1
	lvx	v23, r8, r1
	addi	r1, r1, 0x40

	blr
EPILOGUE(_nettle_chacha_4core)

	.section .rodata
	ALIGN(16)
.Lcnts: .long	0,1,2,3		C increments

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201130200708</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-11-30 20:07:08-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

On Mon, Nov 30, 2020 at 12:37 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Niels Möller &lt;nisse@lysator.liu.se&gt; writes:
&gt; 1. Does the save and restore of registers look correct? I checked the
&gt;    abi spec, and the intention is to use the part of the 288 byte
&gt;    "Protected zone" below the stack pointer.


There are requirements should be applied when modifying the stack pointer
register, I will add the needed rules from
https://refspecs.linuxfoundation.org/ELF/ppc64/PPC-elf64abi-1.9.html

- The stack pointer shall maintain quadword alignment.
- The stack pointer shall point to the first word of the lowest allocated
stack frame, the "back chain" word. The stack shall grow downward, that is,
toward lower addresses. The first word of the stack frame shall always
point to the previously allocated stack frame (toward higher addresses),
except for the first stack frame, which shall have a back chain of 0 (NULL).
- The stack pointer shall be decremented and the back chain updated
atomically using one of the "Store Double Word with Update" instructions,
so that the stack pointer always points to the beginning of a linked list
of stack frames.

so to modify r1 you have to allocate additional 8 bytes in the stack to
store the old value of r1. The register store sequence will look like:

        li      r6, 0x10        C set up some...
        li      r7, 0x20        C ...useful...
        li      r8, 0x30        C ...offsets
        li      r9, 0x40        C ...offsets

        stdu    r1, -0x50(r1)   C Save callee-save registers
        stvx    v20, r6, r1
        stvx    v21, r7, r1
        stvx    v22, r8, r1
        stvx    v23, r9, r1

note that the allocated size is rounded up to a multiple of 16 bytes, so
that quadword stack alignment is maintained.

and the register restore sequence will look like:

        lvx     v20, r6, r1
        lvx     v21, r7, r1
        lvx     v22, r8, r1
        lvx     v23, r9, r1
        addi    r1, r1, 0x50

BTW since there is no function called while the register of the stack frame
is modified, I think it's fine to not follow the rules and keep the store
and restore sequences as are without any modification.

2. The use of the QR macro means that there's no careful
&gt;    instruction-level interleaving of independent instructions. Do you
&gt;    think it's beneficial to do manual interleaving (like in
&gt;    chacha_2core.asm), or can it be left to the out-of-order execution
&gt;    logic run sort it out and execute instructions in parallel?
&gt;

You'll get performance benefits by interleaving the independent
instructions in this case, I can estimate the increase of performance
around 20%-30%.


&gt; 3. Is there any clever way to construct the vector {0,1,2,3} in a
&gt;    register, instead of loading it from memory?
&gt;

I can think of this method:

li               r10,0
lvsl           T0,0,r10      C 0x000102030405060708090A0B0C0D0E0F
vupkhsb   T0,T0          C 0x00000001000200030004000500060007
vupkhsh   T0,T0          C 0x00000000000000010000000200000003

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201130202408</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-11-30 20:24:08-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

On Mon, Nov 30, 2020 at 10:07 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
wrote:

&gt; BTW since there is no function called while the register of the stack
&gt; frame is modified, I think it's fine to not follow the rules and keep the
&gt; store and restore sequences as are without any modification.
&gt;

I'm thinking what could happen if an exception raised while the stack frame
is modified incorrectly, the exception handler will try to look at the
calling function but it can't get the previous state of stack pointer
because the stack pointer doesn't point to it and that will mess the
exception handling procedure. So we can't ignore the rules whatsoever and
we have to modify the stack frame correctly.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201130205602</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-11-30 20:56:02-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; I'm thinking what could happen if an exception raised while the stack frame
&gt; is modified incorrectly, the exception handler will try to look at the
&gt; calling function but it can't get the previous state of stack pointer
&gt; because the stack pointer doesn't point to it and that will mess the
&gt; exception handling procedure. So we can't ignore the rules whatsoever and
&gt; we have to modify the stack frame correctly.

Hmm. I agree just lowering the stack pointer sounds a bit questionable.
But if we use some other register to point into the protected zone, we
should be fine? E.g.,

	addi	r10, r1, -0x40 C Save callee-save registers
	stvx	v20, 0, r10
	stvx	v21, r6, r10
	stvx	v22, r7, r10
	stvx	v23, r8, r10

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201130210159</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-11-30 21:01:59-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

On Mon, Nov 30, 2020 at 10:56 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Hmm. I agree just lowering the stack pointer sounds a bit questionable.
&gt; But if we use some other register to point into the protected zone, we
&gt; should be fine? E.g.,
&gt;
&gt;         addi    r10, r1, -0x40 C Save callee-save registers
&gt;         stvx    v20, 0, r10
&gt;         stvx    v21, r6, r10
&gt;         stvx    v22, r7, r10
&gt;         stvx    v23, r8, r10
&gt;

This is totally fine.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201130210829</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-11-30 21:08:29-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

Niels Möller &lt;nisse@lysator.liu.se&gt; writes:

&gt; Below code seems to work (but is not yet a drop-in replacement, since it
&gt; needs some wireup in chacha.crypt.c, and 32-bit counter variant and BE
&gt; swapping not yet implemented).

I fixed these issues, as well as fat build support. Pushed to the branch
ppc-chacha-4core. Seems to work fine (but the issue with a possibly bad
use of the stackpointer not yet fixed). Plese try it out.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201130211838</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-11-30 21:18:38-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

on POWER9 I get the following benchmark with ". /configure
--enable-power-altivec":

chacha      encrypt  763.57
chacha      decrypt  780.64

regards,
Mamone

On Mon, Nov 30, 2020 at 11:08 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Niels Möller &lt;nisse@lysator.liu.se&gt; writes:
&gt;
&gt; &gt; Below code seems to work (but is not yet a drop-in replacement, since it
&gt; &gt; needs some wireup in chacha.crypt.c, and 32-bit counter variant and BE
&gt; &gt; swapping not yet implemented).
&gt;
&gt; I fixed these issues, as well as fat build support. Pushed to the branch
&gt; ppc-chacha-4core. Seems to work fine (but the issue with a possibly bad
&gt; use of the stackpointer not yet fixed). Plese try it out.
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt; _______________________________________________
&gt; nettle-bugs mailing list
&gt; nettle-bugs@lists.lysator.liu.se
&gt; http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201130212320</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-11-30 21:23:20-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

On Mon, Nov 30, 2020 at 11:18 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
wrote:

&gt; on POWER9 I get the following benchmark with ". /configure
&gt; --enable-power-altivec":
&gt;
&gt; chacha      encrypt  763.57
&gt; chacha      decrypt  780.64
&gt;
&gt; regards,
&gt; Mamone
&gt;

I got this result using ppc-chacha-2core branch on same machine:

chacha      encrypt  565.79
chacha      decrypt  582.10
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201130213301</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-11-30 21:33:01-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; On Mon, Nov 30, 2020 at 11:18 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
&gt; wrote:
&gt;
&gt;&gt; on POWER9 I get the following benchmark with ". /configure
&gt;&gt; --enable-power-altivec":
&gt;&gt;
&gt;&gt; chacha      encrypt  763.57
&gt;&gt; chacha      decrypt  780.64
&gt;&gt;
&gt;&gt; regards,
&gt;&gt; Mamone
&gt;&gt;
&gt;
&gt; I got this result using ppc-chacha-2core branch on same machine:
&gt;
&gt; chacha      encrypt  565.79
&gt; chacha      decrypt  582.10

Thanks for testing! That's a nice speedup, but a bit less then the
factor two I was hoping for. Maybe better interleaving can help.

BTW, the chacha_2core code is merged to the master branch now.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201201180239</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-12-01 18:02:39-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; On Mon, Nov 30, 2020 at 10:56 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt;&gt; Hmm. I agree just lowering the stack pointer sounds a bit questionable.
&gt;&gt; But if we use some other register to point into the protected zone, we
&gt;&gt; should be fine? E.g.,
&gt;&gt;
&gt;&gt;         addi    r10, r1, -0x40 C Save callee-save registers
&gt;&gt;         stvx    v20, 0, r10
&gt;&gt;         stvx    v21, r6, r10
&gt;&gt;         stvx    v22, r7, r10
&gt;&gt;         stvx    v23, r8, r10
&gt;&gt;
&gt;
&gt; This is totally fine.

I changed it to do this (and it looks like you use the protected zone
as a save area also in the new aes code).

How portable is this, do all relevant operating systems support storing
data below the stack pointer?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201201184832</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-12-01 18:48:32-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; On Mon, Nov 30, 2020 at 11:18 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
&gt; wrote:
&gt;
&gt;&gt; on POWER9 I get the following benchmark with ". /configure
&gt;&gt; --enable-power-altivec":
&gt;&gt;
&gt;&gt; chacha      encrypt  763.57
&gt;&gt; chacha      decrypt  780.64
&gt;&gt;
&gt;&gt; regards,
&gt;&gt; Mamone
&gt;&gt;
&gt;
&gt; I got this result using ppc-chacha-2core branch on same machine:
&gt;
&gt; chacha      encrypt  565.79
&gt; chacha      decrypt  582.10

I've tried running the benchmark on gcc135, and that gives me much more
consistent values than gcc112. The 2-way code (currently on master
branch) gives 686 Mbyte/2. The 4-way code you tried gives 958 MByte/s. I
then replaced the innerloop with a versino with better interleaving,
written by Torbjörn Granlund (just pushed to the branch). That gives
1225 Mbyte/s.

And for reference, the plain C implementation gives 363 MByte/s.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201202144059</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-12-02 14:40:59-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

On Tue, Dec 1, 2020 at 8:02 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; How portable is this, do all relevant operating systems support storing
&gt; data below the stack pointer?
&gt;

I need to investigate this.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201202173104</emailId><senderName>David Edelsohn</senderName><senderEmail>dje.gcc@gmail.com</senderEmail><timestampReceived>2020-12-02 17:31:04-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

On Wed, Dec 2, 2020 at 9:41 AM Maamoun TK &lt;maamoun.tk@googlemail.com&gt; wrote:
&gt;
&gt; On Tue, Dec 1, 2020 at 8:02 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; &gt; How portable is this, do all relevant operating systems support storing
&gt; &gt; data below the stack pointer?
&gt; &gt;
&gt;
&gt; I need to investigate this.

It's dependent upon the ABI.

Thanks, David
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201202175713</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-12-02 17:57:13-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

I can't find a document other than 64-bit elf v2 abi specification
https://openpowerfoundation.org/?resource_lib=64-bit-elf-v2-abi-specification-power-architecture
which say it's safe to use the 288-byte volatile storage below the stack
pointer to hold saved registers and local variables.
However, I wrote a C file for the test and disassembled the compiled binary
on ELFv1, ELFv2, and AIX. All of them hold the saved registers right below
the stack pointer. Furthermore same as we did, the compiler try to avoid
modifying the stack pointer register when possible, the prologue of tested
binary looks like this:
std     r30,-16(r1)
std     r31,-8(r1)
li      r0,-80
stvx    v28,r1,r0
li      r0,-64
stvx    v29,r1,r0
li      r0,-48
stvx    v30,r1,r0
li      r0,-32
stvx    v31,r1,r0

regards,
Mamone

On Wed, Dec 2, 2020 at 7:31 PM David Edelsohn &lt;dje.gcc@gmail.com&gt; wrote:

&gt; On Wed, Dec 2, 2020 at 9:41 AM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
&gt; wrote:
&gt; &gt;
&gt; &gt; On Tue, Dec 1, 2020 at 8:02 PM Niels Möller &lt;nisse@lysator.liu.se&gt;
&gt; wrote:
&gt; &gt;
&gt; &gt; &gt; How portable is this, do all relevant operating systems support storing
&gt; &gt; &gt; data below the stack pointer?
&gt; &gt; &gt;
&gt; &gt;
&gt; &gt; I need to investigate this.
&gt;
&gt; It's dependent upon the ABI.
&gt;
&gt; Thanks, David
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201202180233</emailId><senderName>David Edelsohn</senderName><senderEmail>dje.gcc@gmail.com</senderEmail><timestampReceived>2020-12-02 18:02:33-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

Hi, Maamoun

I thought that you were asking in general. All PowerPC ABI, except the
original 32 bit ELF ABI, allow a red zone below the stack pointer.
For other architectures, one needs to check each ABI.

Thanks, David

On Wed, Dec 2, 2020 at 12:57 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt; wrote:
&gt; 
&gt; I can't find a document other than 64-bit elf v2 abi specification \
&gt; https://openpowerfoundation.org/?resource_lib=64-bit-elf-v2-abi-specification-power-architecture \
&gt; which say it's safe to use the 288-byte volatile storage below the stack pointer to \
&gt; hold saved registers and local variables. However, I wrote a C file for the test \
&gt; and disassembled the compiled binary on ELFv1, ELFv2, and AIX. All of them hold the \
&gt; saved registers right below the stack pointer. Furthermore same as we did, the \
&gt; compiler try to avoid modifying the stack pointer register when possible, the \
&gt; prologue of tested binary looks like this: std     r30,-16(r1)
&gt; std     r31,-8(r1)
&gt; li      r0,-80
&gt; stvx    v28,r1,r0
&gt; li      r0,-64
&gt; stvx    v29,r1,r0
&gt; li      r0,-48
&gt; stvx    v30,r1,r0
&gt; li      r0,-32
&gt; stvx    v31,r1,r0
&gt; 
&gt; regards,
&gt; Mamone
&gt; 
&gt; On Wed, Dec 2, 2020 at 7:31 PM David Edelsohn &lt;dje.gcc@gmail.com&gt; wrote:
&gt; &gt; 
&gt; &gt; On Wed, Dec 2, 2020 at 9:41 AM Maamoun TK &lt;maamoun.tk@googlemail.com&gt; wrote:
&gt; &gt; &gt; 
&gt; &gt; &gt; On Tue, Dec 1, 2020 at 8:02 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt; &gt; &gt; 
&gt; &gt; &gt; &gt; How portable is this, do all relevant operating systems support storing
&gt; &gt; &gt; &gt; data below the stack pointer?
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; 
&gt; &gt; &gt; I need to investigate this.
&gt; &gt; 
&gt; &gt; It's dependent upon the ABI.
&gt; &gt; 
&gt; &gt; Thanks, David
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20201202184715</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-12-02 18:47:15-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

David Edelsohn &lt;dje.gcc@gmail.com&gt; writes:

&gt; I thought that you were asking in general. All PowerPC ABI, except the
&gt; original 32 bit ELF ABI, allow a red zone below the stack pointer.
&gt; For other architectures, one needs to check each ABI.

Do any of you know what ABI was used on Macs with 64-bit powerpc
processors (starting from https://en.wikipedia.org/wiki/Power_Mac_G5, if
I understand it correctly?). Probably not worth much effort to support
these, but it would be good to at least know if the new assembly files
are compatible with that ABI or not.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201202190826</emailId><senderName>David Edelsohn</senderName><senderEmail>dje.gcc@gmail.com</senderEmail><timestampReceived>2020-12-02 19:08:26-0400</timestampReceived><subject>Re: PPC chacha</subject><body>

Apple Darwin on PPC has its own ABI.

The Power Mac G5 processor (PPC970) supported the initial Altivec ISA.

Thanks, David

On Wed, Dec 2, 2020 at 1:47 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; David Edelsohn &lt;dje.gcc@gmail.com&gt; writes:
&gt;
&gt; &gt; I thought that you were asking in general. All PowerPC ABI, except the
&gt; &gt; original 32 bit ELF ABI, allow a red zone below the stack pointer.
&gt; &gt; For other architectures, one needs to check each ABI.
&gt;
&gt; Do any of you know what ABI was used on Macs with 64-bit powerpc
&gt; processors (starting from https://en.wikipedia.org/wiki/Power_Mac_G5, if
&gt; I understand it correctly?). Probably not worth much effort to support
&gt; these, but it would be good to at least know if the new assembly files
&gt; are compatible with that ABI or not.
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200918063729</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-09-18 06:37:29-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" Use register names explicitly</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; Use explicit register names to improve the syntax of assembly files and
&gt; pass -mregnames to the assembler to allow building the assembly files. I
&gt; will make a stand-alone patch for GCM which brings all the accumulated
&gt; modifications so it can be directly merged.
&gt; ---
&gt;  configure.ac                          |   4 +-
&gt;  powerpc64/machine.m4                  |   4 +-
&gt;  powerpc64/p8/aes-decrypt-internal.asm | 194
&gt; +++++++++++++++++-----------------
&gt;  powerpc64/p8/aes-encrypt-internal.asm | 192
&gt; ++++++++++++++++-----------------
&gt;  4 files changed, 198 insertions(+), 196 deletions(-)
&gt;
&gt; diff --git a/configure.ac b/configure.ac
&gt; index 666b2f4a..6ab32f03 100644
&gt; --- a/configure.ac
&gt; +++ b/configure.ac
&gt; @@ -458,10 +458,12 @@ if test "x$enable_assembler" = xyes ; then
&gt;        if test "$ABI" = 64 ; then
&gt;   asm_path="powerpc64"
&gt;   if test "x$enable_fat" = xyes ; then
&gt; -  asm_path="powerpc64/fat $asm_path"
&gt; +  CFLAGS="$CFLAGS -Wa,-mregnames"
&gt; +    asm_path="powerpc64/fat $asm_path"

I'm not sure it's a good idea to unconditionally use these gcc specific
flags. Are they supported by all relevant compilers? I'm considering
instead adding the attached patch. It's a pretty large file with various m4
utilities plus an autoconf test to determine if the assembler accepts
register names (copied from gmp), and then conditionally doing

  forloop(i,0,31,`deflit(`r'i,i)')

to define register names as macros expanding to corresponding integers.

This could be extended with a configure check to try adding
-Wa,-mregnames.

&gt; diff --git a/powerpc64/machine.m4 b/powerpc64/machine.m4
&gt; index 221fa523..cefabc9b 100644
&gt; --- a/powerpc64/machine.m4
&gt; +++ b/powerpc64/machine.m4
&gt; @@ -24,7 +24,7 @@ define(`EPILOGUE',
&gt;
&gt;  C Get vector-scalar register from vector register
&gt;  C VSR(VR)
&gt; -define(`VSR',`32+$1')
&gt; +define(`VSR',``vs'eval(32+substr($1,1,len($1)))')

May be less brittle with an explicit ifelse chain, like the similar
macros in arm/machine.m4. Should work better with the above approach,
where r1 may expand to 1, depending on a configure check.


["ppc-m4-macrology.patch" (text/x-diff)]

diff --git a/ChangeLog b/ChangeLog
index 1d42f701..abaaa3cb 100644
--- a/ChangeLog
+++ b/ChangeLog
@@ -1,3 +1,19 @@
+2020-09-08  Niels Möller  &lt;nisse@obsidian&gt;
+
+	* Makefile.in: Read m4-utils.m4 when preprocessing .asm files.
+	(DISTFILES): Add m4-utils.m4.
+	* m4-utils.m4: New file with m4 utilities, in particular forloop.
+	Copied from GMP's asm-defs.m4.
+
+	* aclocal.m4 (GMP_ASM_POWERPC_R_REGISTERS): New configure test,
+	adapted from corresponding test in GMP's acinlude.m4.
+	* configure.ac (ASM_PPC_WANT_R_REGISTERS): New substituted
+	variable. Set using GMP_ASM_POWERPC_R_REGISTERS, when powerpc64
+	assembly code is enabled.
+	* config.m4.in: Substituted here.
+	* powerpc64/machine.m4: Check ASM_PPC_WANT_R_REGISTERS, and
+	if needed, replace register names like r0, r1, ... with integers.
+
 2020-09-15  Niels Möller  &lt;nisse@obsidian&gt;
 
 	* Makefile.in (DISTFILES): Add missing file blowfish-internal.h.
diff --git a/Makefile.in b/Makefile.in
index 4260b724..c10f3e9d 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -267,7 +267,7 @@ DISTFILES = $(SOURCES) $(HEADERS) getopt.h getopt_int.h \
 	salsa20-internal.h umac-internal.h hogweed-internal.h \
 	rsa-internal.h pkcs1-internal.h dsa-internal.h eddsa-internal.h \
 	gmp-glue.h ecc-internal.h fat-setup.h \
-	mini-gmp.h asm.m4 \
+	mini-gmp.h asm.m4 m4-utils.m4 \
 	nettle.texinfo nettle.info nettle.html nettle.pdf sha-example.c
 
 # Rules building static libraries
@@ -289,8 +289,8 @@ libhogweed.a: $(hogweed_OBJS)
 	$(RANLIB) $@
 	echo hogweed &gt; libhogweed.stamp
 
-%.$(OBJEXT): %.asm $(srcdir)/asm.m4 machine.m4 config.m4
-	$(M4) $(srcdir)/asm.m4 machine.m4 config.m4 $&lt; &gt;$*.s
+%.$(OBJEXT): %.asm $(srcdir)/m4-utils.m4 $(srcdir)/asm.m4 config.m4 machine.m4
+	$(M4) $(srcdir)/m4-utils.m4 $(srcdir)/asm.m4 config.m4 machine.m4 $&lt; &gt;$*.s
 	$(COMPILE) -c $*.s
 
 %.$(OBJEXT): %.c
diff --git a/aclocal.m4 b/aclocal.m4
index 513b2df4..29aa5c3e 100644
--- a/aclocal.m4
+++ b/aclocal.m4
@@ -555,3 +555,27 @@ EOF
 	AC_SUBST(EXTRA_HOGWEED_LINKER_FLAGS)
   fi
 ])
+
+dnl  GMP_ASM_POWERPC_R_REGISTERS
+dnl  ---------------------------
+dnl  Determine whether the assembler takes powerpc registers with an "r" as
+dnl  in "r6", or as plain "6".  The latter is standard, but NeXT, Rhapsody,
+dnl  and MacOS-X require the "r" forms.
+dnl
+dnl  See also mpn/powerpc32/powerpc-defs.m4 which uses the result of this
+dnl  test.
+
+AC_DEFUN([GMP_ASM_POWERPC_R_REGISTERS],
+[AC_CACHE_CHECK([if the assembler needs r on registers],
+               gmp_cv_asm_powerpc_r_registers,
+[GMP_TRY_ASSEMBLE(
+[	$gmp_cv_asm_text
+	mtctr	6],
+[gmp_cv_asm_powerpc_r_registers=no],
+[GMP_TRY_ASSEMBLE(
+[	.text
+	mtctr	r6],
+[gmp_cv_asm_powerpc_r_registers=yes],
+[AC_MSG_ERROR([neither "mtctr 6" nor "mtctr r6" works])])])])
+ASM_PPC_WANT_R_REGISTERS="$gmp_cv_asm_powerpc_r_registers"
+])
diff --git a/config.m4.in b/config.m4.in
index f9b7ece4..d89325b8 100644
--- a/config.m4.in
+++ b/config.m4.in
@@ -10,6 +10,7 @@ define(`RODATA', `@ASM_RODATA@')dnl
 define(`WORDS_BIGENDIAN', `@ASM_WORDS_BIGENDIAN@')dnl
 define(`ASM_X86_ENDBR',`@ASM_X86_ENDBR@')dnl
 define(`ASM_X86_MARK_CET_ALIGN',`@ASM_X86_MARK_CET_ALIGN@')dnl
+define(`ASM_PPC_WANT_R_REGISTERS',`@ASM_PPC_WANT_R_REGISTERS@')dnl
 divert(1)
 @ASM_X86_MARK_CET@
 @ASM_MARK_NOEXEC_STACK@
diff --git a/configure.ac b/configure.ac
index 666b2f4a..e9983697 100644
--- a/configure.ac
+++ b/configure.ac
@@ -399,6 +399,7 @@ fi
 
 OPT_NETTLE_SOURCES=""
 FAT_TEST_LIST=""
+ASM_PPC_WANT_R_REGISTERS="n/a"
 
 # Select assembler code
 asm_path=
@@ -456,6 +457,7 @@ if test "x$enable_assembler" = xyes ; then
       ;;
     *powerpc64*)
       if test "$ABI" = 64 ; then
+	GMP_ASM_POWERPC_R_REGISTERS
 	asm_path="powerpc64"
 	if test "x$enable_fat" = xyes ; then
 	  asm_path="powerpc64/fat $asm_path"
@@ -588,6 +590,7 @@ else
   IF_ASM='#'
 fi
 AC_SUBST([IF_ASM])
+AC_SUBST([ASM_PPC_WANT_R_REGISTERS])
 
 AH_VERBATIM([HAVE_NATIVE],
 [/* Define to 1 each of the following for which a native (ie. CPU specific)
diff --git a/m4-utils.m4 b/m4-utils.m4
new file mode 100644
index 00000000..3ead365a
--- /dev/null
+++ b/m4-utils.m4
@@ -0,0 +1,436 @@
+divert(-1)
+
+dnl
+dnl  m4 macros for gmp assembly code, shared by all CPUs. From gmp/mpn/asm-defs.m4
+
+dnl  Copyright 1999-2006, 2011 Free Software Foundation, Inc.
+
+dnl  This file is part of the GNU MP Library.
+dnl
+dnl  The GNU MP Library is free software; you can redistribute it and/or modify
+dnl  it under the terms of either:
+dnl
+dnl    * the GNU Lesser General Public License as published by the Free
+dnl      Software Foundation; either version 3 of the License, or (at your
+dnl      option) any later version.
+dnl
+dnl  or
+dnl
+dnl    * the GNU General Public License as published by the Free Software
+dnl      Foundation; either version 2 of the License, or (at your option) any
+dnl      later version.
+dnl
+dnl  or both in parallel, as here.
+dnl
+dnl  The GNU MP Library is distributed in the hope that it will be useful, but
+dnl  WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+dnl  or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+dnl  for more details.
+dnl
+dnl  You should have received copies of the GNU General Public License and the
+dnl  GNU Lesser General Public License along with the GNU MP Library.  If not,
+dnl  see https://www.gnu.org/licenses/.
+
+
+dnl  These macros are designed for use with any m4 and have been used on
+dnl  GNU, FreeBSD, NetBSD, OpenBSD and SysV.
+dnl
+dnl  GNU m4 and OpenBSD 2.7 m4 will give filenames and line numbers in error
+dnl  messages.
+dnl
+dnl
+dnl  Macros:
+dnl
+dnl  Most new m4 specific macros have an "m4_" prefix to emphasise they're
+dnl  m4 expansions.  But new defining things like deflit() and defreg() are
+dnl  named like the builtin define(), and forloop() is named following the
+dnl  GNU m4 example on which it's based.
+dnl
+dnl  GNU m4 with the -P option uses "m4_" as a prefix for builtins, but that
+dnl  option isn't going to be used, so there's no conflict or confusion.
+dnl
+dnl
+dnl  Comments in output:
+dnl
+dnl  The m4 comment delimiters are left at # and \n, the normal assembler
+dnl  commenting for most CPUs.  m4 passes comment text through without
+dnl  expanding macros in it, which is generally a good thing since it stops
+dnl  unexpected expansions and possible resultant errors.
+dnl
+dnl  But note that when a quoted string is being read, a # isn't special, so
+dnl  apostrophes in comments in quoted strings must be avoided or they'll be
+dnl  interpreted as a closing quote mark.  But when the quoted text is
+dnl  re-read # will still act like a normal comment, suppressing macro
+dnl  expansion.
+dnl
+dnl  For example,
+dnl
+dnl          # apostrophes in comments that're outside quotes are ok
+dnl          # and using macro names like PROLOGUE is ok too
+dnl          ...
+dnl          ifdef(`PIC',`
+dnl                  # but apostrophes aren't ok inside quotes
+dnl                  #                     ^--wrong
+dnl                  ...
+dnl                  # though macro names like PROLOGUE are still ok
+dnl                  ...
+dnl          ')
+dnl
+dnl  If macro expansion in a comment is wanted, use `#' in the .asm (ie. a
+dnl  quoted hash symbol), which will turn into # in the .s but get
+dnl  expansions done on that line.  This can make the .s more readable to
+dnl  humans, but it won't make a blind bit of difference to the assembler.
+dnl
+dnl  All the above applies, mutatis mutandis, when changecom() is used to
+dnl  select @ ! ; or whatever other commenting.
+dnl
+dnl
+dnl  Variations in m4 affecting gmp:
+dnl
+dnl  $# - When a macro is called as "foo" with no brackets, BSD m4 sets $#
+dnl       to 1, whereas GNU or SysV m4 set it to 0.  In all cases though
+dnl       "foo()" sets $# to 1.  This is worked around in various places.
+dnl
+dnl  len() - When "len()" is given an empty argument, BSD m4 evaluates to
+dnl       nothing, whereas GNU, SysV, and the new OpenBSD, evaluate to 0.
+dnl       See m4_length() below which works around this.
+dnl
+dnl  translit() - GNU m4 accepts character ranges like A-Z, and the new
+dnl       OpenBSD m4 does under option -g, but basic BSD and SysV don't.
+dnl
+dnl  popdef() - in BSD and SysV m4 popdef() takes multiple arguments and
+dnl       pops each, but GNU m4 only takes one argument.
+dnl
+dnl  push back - BSD m4 has some limits on the amount of text that can be
+dnl       pushed back.  The limit is reasonably big and so long as macros
+dnl       don't gratuitously duplicate big arguments it isn't a problem.
+dnl       Normally an error message is given, but sometimes it just hangs.
+dnl
+dnl  eval() &amp;,|,^ - GNU and SysV m4 have bitwise operators &amp;,|,^ available,
+dnl       but BSD m4 doesn't (contrary to what the man page suggests) and
+dnl       instead ^ is exponentiation.
+dnl
+dnl  eval() ?: - The C ternary operator "?:" is available in BSD m4, but not
+dnl       in SysV or GNU m4 (as of GNU m4 1.4 and betas of 1.5).
+dnl
+dnl  eval() -2^31 - BSD m4 has a bug where an eval() resulting in -2^31
+dnl       (ie. -2147483648) gives "-(".  Using -2147483648 within an
+dnl       expression is ok, it just can't be a final result.  "-(" will of
+dnl       course upset parsing, with all sorts of strange effects.
+dnl
+dnl  eval() &lt;&lt;,&gt;&gt; - SysV m4 doesn't support shift operators in eval() (on
+dnl       Solaris 7 /usr/xpg4/m4 has them but /usr/ccs/m4 doesn't).  See
+dnl       m4_lshift() and m4_rshift() below for workarounds.
+dnl
+dnl  ifdef() - OSF 4.0 m4 considers a macro defined to a zero value `0' or
+dnl       `00' etc as not defined.  See m4_ifdef below for a workaround.
+dnl
+dnl  m4wrap() sequence - in BSD m4, m4wrap() replaces any previous m4wrap()
+dnl       string, in SysV m4 it appends to it, and in GNU m4 it prepends.
+dnl       See m4wrap_prepend() below which brings uniformity to this.
+dnl
+dnl  m4wrap() 0xFF - old versions of BSD m4 store EOF in a C "char" under an
+dnl       m4wrap() and on systems where char is unsigned by default a
+dnl       spurious 0xFF is output.  This has been observed on recent Cray
+dnl       Unicos Alpha, Apple MacOS X, and HPUX 11 systems.  An autoconf
+dnl       test is used to check for this, see the m4wrap handling below.  It
+dnl       might work to end the m4wrap string with a dnl to consume the
+dnl       0xFF, but that probably induces the offending m4's to read from an
+dnl       already closed "FILE *", which could be bad on a glibc style
+dnl       stdio.
+dnl
+dnl  __file__,__line__ - GNU m4 and OpenBSD 2.7 m4 provide these, and
+dnl       they're used here to make error messages more informative.  GNU m4
+dnl       gives an unhelpful "NONE 0" in an m4wrap(), but that's worked
+dnl       around.
+dnl
+dnl  __file__ quoting - OpenBSD m4, unlike GNU m4, doesn't quote the
+dnl       filename in __file__, so care should be taken that no macro has
+dnl       the same name as a file, or an unwanted expansion will occur when
+dnl       printing an error or warning.
+dnl
+dnl  changecom() - BSD m4 changecom doesn't quite work like the man page
+dnl       suggests, in particular "changecom" or "changecom()" doesn't
+dnl       disable the comment feature, and multi-character comment sequences
+dnl       don't seem to work.  If the default `#' and newline aren't
+dnl       suitable it's necessary to change it to something else,
+dnl       eg. changecom(;).
+dnl
+dnl  OpenBSD 2.6 m4 - in this m4, eval() rejects decimal constants containing
+dnl       an 8 or 9, making it pretty much unusable.  The bug is confined to
+dnl       version 2.6 (it's not in 2.5, and was fixed in 2.7).
+dnl
+dnl  SunOS /usr/bin/m4 - this m4 lacks a number of desired features,
+dnl       including $# and $@, defn(), m4exit(), m4wrap(), pushdef(),
+dnl       popdef().  /usr/5bin/m4 is a SysV style m4 which should always be
+dnl       available, and "configure" will reject /usr/bin/m4 in favour of
+dnl       /usr/5bin/m4 (if necessary).
+dnl
+dnl       The sparc code actually has modest m4 requirements currently and
+dnl       could manage with /usr/bin/m4, but there's no reason to put our
+dnl       macros through contortions when /usr/5bin/m4 is available or GNU
+dnl       m4 can be installed.
+
+
+
+
+dnl  --------------------------------------------------------------------------
+dnl  Basic error handling things.
+
+
+dnl  Usage: m4_dollarhash_1_if_noparen_p
+dnl
+dnl  Expand to 1 if a call "foo" gives $# set to 1 (as opposed to 0 like GNU
+dnl  and SysV m4 give).
+
+define(m4_dollarhash_1_if_noparen_test,`$#')
+define(m4_dollarhash_1_if_noparen_p,
+eval(m4_dollarhash_1_if_noparen_test==1))
+undefine(`m4_dollarhash_1_if_noparen_test')
+
+define(m4_error,
+`errprint($@
+)m4exit(1)')
+
+dnl  Usage: m4_assert_numargs(num)
+dnl
+dnl  Put this unquoted on a line on its own at the start of a macro
+dnl  definition to add some code to check that num many arguments get passed
+dnl  to the macro.  For example,
+dnl
+dnl         define(foo,
+dnl         m4_assert_numargs(2)
+dnl         `something `$1' and `$2' blah blah')
+dnl
+dnl  Then a call like foo(one,two,three) will provoke an error like
+dnl
+dnl         file:10: foo expected 2 arguments, got 3 arguments
+dnl
+dnl  Here are some calls and how many arguments they're interpreted as passing.
+dnl
+dnl         foo(abc,def)  2
+dnl         foo(xyz)      1
+dnl         foo()         0
+dnl         foo          -1
+dnl
+dnl  The -1 for no parentheses at all means a macro that's meant to be used
+dnl  that way can be checked with m4_assert_numargs(-1).  For example,
+dnl
+dnl         define(SPECIAL_SUFFIX,
+dnl         m4_assert_numargs(-1)
+dnl         `ifdef(`FOO',`_foo',`_bar')')
+dnl
+dnl  But as an alternative see also deflit() below where parenthesized
+dnl  expressions following a macro are passed through to the output.
+dnl
+dnl  Note that in BSD m4 there's no way to differentiate calls "foo" and
+dnl  "foo()", so in BSD m4 the distinction between the two isn't enforced.
+dnl  (In GNU and SysV m4 it can be checked, and is.)
+
+
+dnl  m4_assert_numargs is able to check its own arguments by calling
+dnl  assert_numargs_internal directly.
+dnl
+dnl  m4_doublequote($`'0) expands to ``$0'', whereas ``$`'0'' would expand
+dnl  to `$`'0' and do the wrong thing, and likewise for $1.  The same is
+dnl  done in other assert macros.
+dnl
+dnl  $`#' leaves $# in the new macro being defined, and stops # being
+dnl  interpreted as a comment character.
+dnl
+dnl  `dnl ' means an explicit dnl isn't necessary when m4_assert_numargs is
+dnl  used.  The space means that if there is a dnl it'll still work.
+
+dnl  Usage: m4_doublequote(x) expands to ``x''
+define(m4_doublequote,
+`m4_assert_numargs_internal(`$0',1,$#,len(`$1'))``$1''')
+
+define(m4_assert_numargs,
+`m4_assert_numargs_internal(`$0',1,$#,len(`$1'))dnl
+`m4_assert_numargs_internal'(m4_doublequote($`'0),$1,$`#',`len'(m4_doublequote($`'1)))`dnl \
'') +
+dnl  Called: m4_assert_numargs_internal(`macroname',wantargs,$#,len(`$1'))
+define(m4_assert_numargs_internal,
+`m4_assert_numargs_internal_check(`$1',`$2',m4_numargs_count(`$3',`$4'))')
+
+dnl  Called: m4_assert_numargs_internal_check(`macroname',wantargs,gotargs)
+dnl
+dnl  If m4_dollarhash_1_if_noparen_p (BSD m4) then gotargs can be 0 when it
+dnl  should be -1.  If wantargs is -1 but gotargs is 0 and the two can't be
+dnl  distinguished then it's allowed to pass.
+dnl
+define(m4_assert_numargs_internal_check,
+`ifelse(eval($2 == $3
+             || ($2==-1 &amp;&amp; $3==0 &amp;&amp; m4_dollarhash_1_if_noparen_p)),0,
+`m4_error(`$1 expected 'm4_Narguments(`$2')`, got 'm4_Narguments(`$3')
+)')')
+
+dnl  Called: m4_numargs_count($#,len(`$1'))
+dnl  If $#==0 then -1 args, if $#==1 but len(`$1')==0 then 0 args, otherwise
+dnl  $# args.
+define(m4_numargs_count,
+`ifelse($1,0, -1,
+`ifelse(eval($1==1 &amp;&amp; $2-0==0),1, 0, $1)')')
+
+dnl  Usage: m4_Narguments(N)
+dnl  "$1 argument" or "$1 arguments" with the plural according to $1.
+define(m4_Narguments,
+`$1 argument`'ifelse(`$1',1,,s)')
+
+
+dnl  --------------------------------------------------------------------------
+dnl  Additional error checking things.
+
+
+dnl  Usage: m4_assert_onearg()
+dnl
+dnl  Put this, unquoted, at the start of a macro definition to add some code
+dnl  to check that one argument is passed to the macro, but with that
+dnl  argument allowed to be empty.  For example,
+dnl
+dnl          define(foo,
+dnl          m4_assert_onearg()
+dnl          `blah blah $1 blah blah')
+dnl
+dnl  Calls "foo(xyz)" or "foo()" are accepted.  A call "foo(xyz,abc)" fails.
+dnl  A call "foo" fails too, but BSD m4 can't detect this case (GNU and SysV
+dnl  m4 can).
+
+define(m4_assert_onearg,
+m4_assert_numargs(0)
+`m4_assert_onearg_internal'(m4_doublequote($`'0),$`#')`dnl ')
+
+dnl  Called: m4_assert_onearg(`macroname',$#)
+define(m4_assert_onearg_internal,
+`ifelse($2,1,,
+`m4_error(`$1 expected 1 argument, got 'm4_Narguments(`$2')
+)')')
+
+
+
+dnl  --------------------------------------------------------------------------
+dnl  Various generic m4 things.
+
+
+
+dnl  Usage: m4_length(string)
+dnl
+dnl  Determine the length of a string.  This is the same as len(), but
+dnl  always expands to a number, working around the BSD len() which
+dnl  evaluates to nothing given an empty argument.
+
+define(m4_length,
+m4_assert_onearg()
+`eval(len(`$1')-0)')
+
+
+
+dnl  Usage: m4_incr_or_decr(n,last)
+dnl
+dnl  Do an incr(n) or decr(n), whichever is in the direction of "last".
+dnl  Both n and last must be numbers of course.
+
+define(m4_incr_or_decr,
+m4_assert_numargs(2)
+`ifelse(eval($1&lt;$2),1,incr($1),decr($1))')
+
+
+dnl  Usage: forloop(i, first, last, statement)
+dnl
+dnl  Based on GNU m4 examples/forloop.m4, but extended.
+dnl
+dnl  statement is expanded repeatedly, with i successively defined as
+dnl
+dnl         first, first+1, ..., last-1, last
+dnl
+dnl  Or if first &gt; last, then it's
+dnl
+dnl         first, first-1, ..., last+1, last
+dnl
+dnl  If first == last, then one expansion is done.
+dnl
+dnl  A pushdef/popdef of i is done to preserve any previous definition (or
+dnl  lack of definition).  first and last are eval()ed and so can be
+dnl  expressions.
+dnl
+dnl  forloop_first is defined to 1 on the first iteration, 0 on the rest.
+dnl  forloop_last is defined to 1 on the last iteration, 0 on the others.
+dnl  Nested forloops are allowed, in which case forloop_first and
+dnl  forloop_last apply to the innermost loop that's open.
+dnl
+dnl  A simple example,
+dnl
+dnl         forloop(i, 1, 2*2+1, `dnl
+dnl         iteration number i ... ifelse(forloop_first,1,FIRST)
+dnl         ')
+
+
+dnl  "i" and "statement" are carefully quoted, but "first" and "last" are
+dnl  just plain numbers once eval()ed.
+
+define(`forloop',
+m4_assert_numargs(4)
+`pushdef(`$1',eval(`$2'))dnl
+pushdef(`forloop_first',1)dnl
+pushdef(`forloop_last',0)dnl
+forloop_internal(`$1',eval(`$3'),`$4')`'dnl
+popdef(`forloop_first')dnl
+popdef(`forloop_last')dnl
+popdef(`$1')')
+
+dnl  Called: forloop_internal(`var',last,statement)
+define(`forloop_internal',
+m4_assert_numargs(3)
+`ifelse($1,$2,
+`define(`forloop_last',1)$3',
+`$3`'dnl
+define(`forloop_first',0)dnl
+define(`$1',m4_incr_or_decr($1,$2))dnl
+forloop_internal(`$1',$2,`$3')')')
+
+dnl  Usage: deflit(name,value)
+dnl
+dnl  Like define(), but "name" expands like a literal, rather than taking
+dnl  arguments.  For example "name(%eax)" expands to "value(%eax)".
+dnl
+dnl  Limitations:
+dnl
+dnl  $ characters in the value part must have quotes to stop them looking
+dnl  like macro parameters.  For example, deflit(reg,`123+$`'4+567').  See
+dnl  defreg() below for handling simple register definitions like $7 etc.
+dnl
+dnl  "name()" is turned into "name", unfortunately.  In GNU and SysV m4 an
+dnl  error is generated when this happens, but in BSD m4 it will happen
+dnl  silently.  The problem is that in BSD m4 $# is 1 in both "name" or
+dnl  "name()", so there's no way to differentiate them.  Because we want
+dnl  plain "name" to turn into plain "value", we end up with "name()"
+dnl  turning into plain "value" too.
+dnl
+dnl  "name(foo)" will lose any whitespace after commas in "foo", for example
+dnl  "disp(%eax, %ecx)" would become "128(%eax,%ecx)".
+dnl
+dnl  These parentheses oddities shouldn't matter in assembler text, but if
+dnl  they do the suggested workaround is to write "name ()" or "name (foo)"
+dnl  to stop the parentheses looking like a macro argument list.  If a space
+dnl  isn't acceptable in the output, then write "name`'()" or "name`'(foo)".
+dnl  The `' is stripped when read, but again stops the parentheses looking
+dnl  like parameters.
+
+dnl  Quoting for deflit_emptyargcheck is similar to m4_assert_numargs.  The
+dnl  stuff in the ifelse gives a $#, $1 and $@ evaluated in the new macro
+dnl  created, not in deflit.
+define(deflit,
+m4_assert_numargs(2)
+`define(`$1',
+`deflit_emptyargcheck'(``$1'',$`#',m4_doublequote($`'1))`dnl
+$2`'dnl
+ifelse(eval($'`#&gt;1 || m4_length('m4_doublequote($`'1)`)!=0),1,($'`@))')')
+
+dnl  Called: deflit_emptyargcheck(macroname,$#,`$1')
+define(deflit_emptyargcheck,
+`ifelse(eval($2==1 &amp;&amp; !m4_dollarhash_1_if_noparen_p &amp;&amp; m4_length(`$3')==0),1,
+`m4_error(`dont use a deflit as $1() because it loses the brackets (see deflit in \
asm-defs.m4 for more information) +')')')
+
+
+divert`'dnl
diff --git a/powerpc64/machine.m4 b/powerpc64/machine.m4
index 221fa523..ae161d79 100644
--- a/powerpc64/machine.m4
+++ b/powerpc64/machine.m4
@@ -34,3 +34,17 @@ C DATA_LOAD_VEC(VEC_DST, DATA_SRC, GPR)
 define(`DATA_LOAD_VEC',
 `ld $3,$2@got(2)
 lvx $1,0,$3')
+
+dnl  Usage: r0 ... r31, cr0 ... cr7
+dnl
+dnl  Registers names, either left as "r0" etc or mapped to plain 0 etc,
+dnl  according to the result of the GMP_ASM_POWERPC_REGISTERS configure
+dnl  test.
+
+ifelse(ASM_PPC_WANT_R_REGISTERS,no,`
+forloop(i,0,31,`deflit(`r'i,i)')
+forloop(i,0,31,`deflit(`v'i,i)')
+forloop(i,0,31,`deflit(`f'i,i)')
+forloop(i,0,7, `deflit(`cr'i,i)')
+')
+



-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.

[Attachment #5 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200916115948</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-09-16 11:59:48-0400</timestampReceived><subject>Re: The m4 quote characters</subject><body>

I apologize for the late reply. I just saw this post.
I'm a little confused here, are these changes conflict with the patch I
just posted?

On Mon, Sep 14, 2020 at 9:38 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; nisse@lysator.liu.se (Niels Möller) writes:
&gt;
&gt; &gt; So I'm considering changing that, and instead stick to m4 default
&gt; &gt; quotes. Opinions?
&gt;
&gt; Pushed changes to do that to a branch, default-m4-quote-char. Seems to
&gt; pass the ci tests, as well as manual testing on sparc. I'll likely merge
&gt; in a day or two, if I don't become aware of any problems.
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt; _______________________________________________
&gt; nettle-bugs mailing list
&gt; nettle-bugs@lists.lysator.liu.se
&gt; http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200105054614</emailId><senderName>Nikos Mavrogiannopoulos</senderName><senderEmail>n.mavrogiannopoulos@gmail.com</senderEmail><timestampReceived>2020-01-05 05:46:14-0400</timestampReceived><subject>Re: update CI to latest fedora image</subject><body>

On Sat, Jan 4, 2020 at 12:11 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; Nikos Mavrogiannopoulos &lt;nmav@redhat.com&gt; writes:
&gt;
&gt; &gt; On Fri, Jan 3, 2020 at 10:13 AM Nikos Mavrogiannopoulos &lt;nmav@redhat.com&gt; wrote:
&gt; &gt;&gt;
&gt; &gt;&gt; Hi,
&gt; &gt;&gt;  This patch updates the CI to the latest fedora image. It also includes
&gt; &gt;&gt; some minor changes to tools, to pass the new clang analyser. I will
&gt; &gt;&gt; remove the f29 image once this is applied. A test run passes:
&gt; &gt;&gt; https://gitlab.com/nmav/nettle/pipelines/106785682
&gt; &gt;&gt;
&gt; &gt;&gt; regards,
&gt; &gt;&gt; Nikos
&gt;
&gt; Thanks. Not applied yet, but I hope to get to it in a few days.
&gt;
&gt; I noticed that some of todays builds have failed. It seems the find
&gt; command is no longer available (used by config.status). If I understand
&gt; the log correctly, it's using
&gt; registry.gitlab.com/gnutls/build-images:buildenv-f29. See
&gt; https://gitlab.com/gnutls/nettle/-/jobs/393683657
&gt;
&gt; Is that easy to fix, or is it better to leave as is and just switch to
&gt; the fedora31 images?

Images stop generating because CI runners were out of disk space so I
made them all smaller. This seems like a side effect. I've added
findutils to this image, but if you move to the newer version it would
be great help as I will have less images to take care of.

regards,
Nikos
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200801114629</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-08-01 11:46:29-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" Add README</subject><body>

Hi,

I reformatted the README as you suggested and re-wrote line breaks to avoid
the invalid ones.

Regards,
Mamone

On Fri, Jul 31, 2020 at 9:40 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt;  powerpc64/README | 86
&gt;
&gt; Hi, this patch still has lien break problems, e.g.,
&gt;
&gt; &gt; +GPR11   volatile    In calls by pointer and as an environment pointer
&gt; for
&gt; &gt; languages
&gt; &gt; +    that require it (for example, PASCAL).
&gt;
&gt; this line break makes it invalid patch syntax. Unclear to me where and
&gt; why that happens; the mail was sent using
&gt;
&gt; Content-Type: text/plain; charset="utf-8"
&gt; Content-Transfer-Encoding: base64
&gt;
&gt; so MTAs on the way won't care about line length. I could fix it manually
&gt; and apply, but maybe it's better to reformat the README file to keep
&gt; line length limited to 72 or so characters.
&gt;
&gt; You could also have a look at the x86_64/README and arm/README files, to
&gt; use the same table style, e.g.,
&gt;
&gt; Registers       May be          Argument
&gt;                 clobbered       number
&gt;
&gt; r0              Y               1
&gt; r1              Y               2
&gt; r2              Y               3
&gt; r3              Y               4
&gt; r4              N
&gt;
&gt; (Not essential, but consistency would make it a bit easier for readers).
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200801115547</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-08-01 11:55:47-0400</timestampReceived><subject>Re: [PATCH 2/6] "PowerPC64" Add optimized AES [Enc|Dec]</subject><body>

I will add PPC to this check.

Thank you,
Mamone

On Fri, Jul 31, 2020 at 8:56 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; nisse@lysator.liu.se (Niels Möller) writes:
&gt;
&gt; &gt; BTW, about fat tests, I'm considering adding a make target "check-fat"
&gt; &gt; which will run make check with some different settings of
&gt; &gt; NETTLE_FAT_OVERRIDE (platform specific, and determined by configure).
&gt;
&gt; I've added this now, with fairly solid coverage for ARM and less
&gt; coverage for x86_64.
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200802143032</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-08-02 14:30:32-0400</timestampReceived><subject>[PATCH] Check for ENV_OVERRIDE in get_ppc_features()</subject><body>

This patch doesn't add FAT_TEST_LIST to ppc in configure.ac because the
check-fat patch hasn't merged to the power-asm-wip branch. It can be
enabled easily by adding FAT_TEST_LIST="crypto_ext" to the ppc condition in
configure.ac once both patches are merged together.

Regards,
Mamone

---
 fat-ppc.c | 38 ++++++++++++++++++++++++++++++--------
 1 file changed, 30 insertions(+), 8 deletions(-)

diff --git a/fat-ppc.c b/fat-ppc.c
index eca689fe..e0b50199 100644
--- a/fat-ppc.c
+++ b/fat-ppc.c
@@ -68,26 +68,48 @@ struct ppc_features
   int have_crypto_ext;
 };

+#define MATCH(s, slen, literal, llen) \
+  ((slen) == (llen) &amp;&amp; memcmp ((s), (literal), llen) == 0)
+
 static void
 get_ppc_features (struct ppc_features *features)
 {
+  const char *s;
+  features-&gt;have_crypto_ext = 0;
+
+  s = secure_getenv (ENV_OVERRIDE);
+  if (s)
+    for (;;)
+      {
+ const char *sep = strchr (s, ',');
+ size_t length = sep ? (size_t) (sep - s) : strlen(s);
+
+ if (MATCH (s, length, "crypto_ext", 10))
+  features-&gt;have_crypto_ext = 1;
+ if (!sep)
+  break;
+ s = sep + 1;
+      }
+  else
+  {
 #if defined(_AIX) &amp;&amp; defined(__power_8_andup)
-  features-&gt;have_crypto_ext = __power_8_andup() != 0 ? 1 : 0;
+    features-&gt;have_crypto_ext = __power_8_andup() != 0 ? 1 : 0;
 #else
-  unsigned long hwcap2 = 0;
+    unsigned long hwcap2 = 0;
 #if defined(__linux__)
-  hwcap2 = getauxval(AT_HWCAP2);
+    hwcap2 = getauxval(AT_HWCAP2);
 #elif defined(__FreeBSD__)
 #if __FreeBSD__ &gt;= 12
-  elf_aux_info(AT_HWCAP2, &amp;hwcap2, sizeof(hwcap2));
+    elf_aux_info(AT_HWCAP2, &amp;hwcap2, sizeof(hwcap2));
 #else
-  size_t len = sizeof(hwcap2);
-  sysctlbyname("hw.cpu_features2", &amp;hwcap2, &amp;len, NULL, 0);
+    size_t len = sizeof(hwcap2);
+    sysctlbyname("hw.cpu_features2", &amp;hwcap2, &amp;len, NULL, 0);
 #endif
 #endif
-  features-&gt;have_crypto_ext =
-   (hwcap2 &amp; PPC_FEATURE2_VEC_CRYPTO) == PPC_FEATURE2_VEC_CRYPTO ? 1 : 0;
+    features-&gt;have_crypto_ext =
+     (hwcap2 &amp; PPC_FEATURE2_VEC_CRYPTO) == PPC_FEATURE2_VEC_CRYPTO ? 1 : 0;
 #endif
+  }
 }

 DECLARE_FAT_FUNC(_nettle_aes_encrypt, aes_crypt_internal_func)
-- 
2.17.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200820134731</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-08-20 13:47:31-0400</timestampReceived><subject>[PATCH] "PowerPC64" Detect and check ABI</subject><body>

---
 configure.ac | 27 ++++++++++++++++++++-------
 1 file changed, 20 insertions(+), 7 deletions(-)

diff --git a/configure.ac b/configure.ac
index 49db7af1..6db3fc42 100644
--- a/configure.ac
+++ b/configure.ac
@@ -322,6 +322,17 @@ case "$host_cpu" in
     AC_TRY_COMPILE([
 #if defined(__sgi) &amp;&amp; defined(__LP64__)
 #error 64-bit mips
+#endif
+    ], [], [
+      ABI=32
+    ], [
+      ABI=64
+    ])
+    ;;
+  powerpc*)
+    AC_TRY_COMPILE([
+#if defined(__PPC64__)
+#error 64-bit powerpc
 #endif
     ], [], [
       ABI=32
@@ -438,13 +449,15 @@ if test "x$enable_assembler" = xyes ; then
  fi
       fi
       ;;
-    *powerpc64*)
-      if test "x$enable_fat" = xyes ; then
-        asm_path="powerpc64/fat powerpc64"
-        OPT_NETTLE_SOURCES="fat-ppc.c $OPT_NETTLE_SOURCES"
-     else
-        if test "x$enable_power_crypto_ext" = xyes ; then
-          asm_path="powerpc64/P8 powerpc64"
+    powerpc*)
+      if test "$ABI" = 64 ; then
+        if test "x$enable_fat" = xyes ; then
+          asm_path="powerpc64/fat powerpc64"
+          OPT_NETTLE_SOURCES="fat-ppc.c $OPT_NETTLE_SOURCES"
+      else
+          if test "x$enable_power_crypto_ext" = xyes ; then
+            asm_path="powerpc64/p8 powerpc64"
+          fi
         fi
       fi
       ;;

-- 
2.17.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200820140440</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-08-20 14:04:40-0400</timestampReceived><subject>Re: [PATCH 4/6] "PowerPC64" Add fat build</subject><body>

On Thu, Aug 20, 2020 at 1:07 AM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:

&gt; You might want to check this. In practice I don't believe 32-bit ABIs
&gt; are supported on the 64-bit iron.
&gt;
&gt; I don't recall if the Linux ABI supports 32-bit on these machines. I
&gt; thought Steven Monroe said something about this (i.e., not supported),
&gt; but I cannot find it in my inbox.
&gt;
&gt; If the ABI does specify a 32-bit interface, then GCC does not support
&gt; it. Here's from GCC112 on the compile farm. GCC112 offers GCC 4.8 and
&gt; GCC 8.3.
&gt;
&gt; # GCC 4.8
&gt; $ gcc -m32 test.c -o test
&gt; In file included from /usr/include/features.h:399:0,
&gt;                  from /usr/include/stdint.h:25,
&gt;                  from
&gt; /usr/lib/gcc/ppc64le-redhat-linux/4.8.5/include/stdint.h:9,
&gt;                  from test.c:1:
&gt; /usr/include/gnu/stubs.h:8:27: fatal error: gnu/stubs-32.h: No such
&gt; file or directory
&gt;  # include &lt;gnu/stubs-32.h&gt;
&gt;
&gt; # GCC 8.3
&gt; gcc112:~$ /opt/at12.0/bin/gcc -m32 test.c -o test
&gt; cc1: error: ‘-m32' not supported in this configuration
&gt;
&gt; I don't know what Clang offers.
&gt;
&gt; Jeff
&gt;

 Hi,

As Niels said, maybe a missing package is what stops the compilation
process. I tested it on  GCC119 which has AIX 7.2, gcc builds 32 bit binary
by default when -maix64 is enabled it builds 64 bit binary and both are
executed successfully.

I posted a patch that adds ABI check, thank you both.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200829142714</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-08-29 14:27:14-0400</timestampReceived><subject>Re: [Patch] "PowerPC64" Add README (Reformatted)</subject><body>

Great. I can confirm the testsuite is passed and the performance of AES is
as expected for both fat and explicit crypto configurations.

On Sat, Aug 29, 2020 at 4:14 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; nisse@lysator.liu.se (Niels Möller) writes:
&gt;
&gt; &gt; Merged to the power-asm-wip branch (there were still some improper line
&gt; &gt; breaks on the url-lines at the end; I had to edit a little before git am
&gt; &gt; was happy with it). And I did the P8 -&gt; p8 rename. If the ci tests work
&gt; &gt; out fine, I'll merge to the master branch, and we can continue from
&gt; &gt; there.
&gt;
&gt; Merged to master now. So this branch now includes fat setup and the AES
&gt; implementation. I'm also testing the ABI fix (I did it slightly
&gt; differently, applying only to powerpc64) on the master-updates branch.
&gt;
&gt; Please try it out, in particular, check that it still gives the expected
&gt; performance improvement.
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200829144654</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-08-29 14:46:54-0400</timestampReceived><subject>[PATCH] "PowerPC64" AES improve syntax</subject><body>

This patch adds "VSR" macro to improve the syntax of assembly code, I will
create a separate patch for gcm-hash since it hasn't merged yet to the
master. I also removed the TODO from README because I tried to use
"lxv/stxv" in POWER9 instead of  "lxvd2x/stxvd2x" but gcc produced
"lxvd2x/stxvd2x" in the binary. I'm not sure if it's variant issue of gcc
but this will be problematic since "lxvd2x/stxvd2x" need  permuting in
little-endian mode while "lxv/stxv" is endianness aware.

---
 powerpc64/README                      |  2 -
 powerpc64/machine.m4                  |  4 ++
 powerpc64/p8/aes-decrypt-internal.asm | 97
++++++++++++++++-------------------
 powerpc64/p8/aes-encrypt-internal.asm | 97
++++++++++++++++-------------------
 4 files changed, 90 insertions(+), 110 deletions(-)

diff --git a/powerpc64/README b/powerpc64/README
index 5410791f..7301953b 100644
--- a/powerpc64/README
+++ b/powerpc64/README
@@ -53,8 +53,6 @@ in [3] to see an example of accessing unaligned storage
operands.
 "lxvd2x/stxvd2x" can be used to load/store data into unaligned storage
 operands but permuting is needed for loading and storing data in
 little-endian mode VSX registers are defined with "X" suffix
-TODO: use architecture 3.0 instructions "lxv/stxv" instead for POWER9
-      and newer

 Function Prologue

diff --git a/powerpc64/machine.m4 b/powerpc64/machine.m4
index 2f91adec..b76bb8b1 100644
--- a/powerpc64/machine.m4
+++ b/powerpc64/machine.m4
@@ -22,6 +22,10 @@ define(&lt;EPILOGUE&gt;,
 &lt;.size .C_NAME($1), . - .C_NAME($1)
 .size C_NAME($1), . - .C_NAME($1)&gt;)&gt;)

+C Get vector-scalar register from vector register
+C VSR(VR)
+define(&lt;VSR&gt;,&lt;32+$1&gt;)
+
 C Load the quadword in DATA_SRC storage into
 C VEC_DST. GPR is general-purpose register
 C used to obtain the effective address of
diff --git a/powerpc64/p8/aes-decrypt-internal.asm
b/powerpc64/p8/aes-decrypt-internal.asm
index 7d518cd9..bfedb32b 100644
--- a/powerpc64/p8/aes-decrypt-internal.asm
+++ b/powerpc64/p8/aes-decrypt-internal.asm
@@ -1,4 +1,4 @@
-C powerpc64/P8/aes-decrypt-internal.asm
+C powerpc64/p8/aes-decrypt-internal.asm

 ifelse(&lt;
    Copyright (C) 2020 Mamone Tarsha
@@ -52,16 +52,6 @@ define(&lt;S5&gt;, &lt;7&gt;)
 define(&lt;S6&gt;, &lt;8&gt;)
 define(&lt;S7&gt;, &lt;9&gt;)

-define(&lt;KX&gt;, &lt;33&gt;)
-define(&lt;S0X&gt;, &lt;34&gt;)
-define(&lt;S1X&gt;, &lt;35&gt;)
-define(&lt;S2X&gt;, &lt;36&gt;)
-define(&lt;S3X&gt;, &lt;37&gt;)
-define(&lt;S4X&gt;, &lt;38&gt;)
-define(&lt;S5X&gt;, &lt;39&gt;)
-define(&lt;S6X&gt;, &lt;40&gt;)
-define(&lt;S7X&gt;, &lt;41&gt;)
-
 C ZERO vector register is used in place of RoundKey
 C for vncipher instruction because the order of InvMixColumns
 C and Xor processes are flipped in that instruction.
@@ -70,7 +60,6 @@ define(&lt;ZERO&gt;, &lt;10&gt;)

 .file "aes-decrypt-internal.asm"

-IF_LE(&lt;.abiversion 2&gt;)
 .text

  C _aes_decrypt(unsigned rounds, const uint32_t *keys,
@@ -109,17 +98,17 @@ PROLOGUE(_nettle_aes_decrypt)

 .align 5
 Lx8_loop:
- lxvd2x KX,0,KEYS
+ lxvd2x VSR(K),0,KEYS
  vperm   K,K,K,swap_mask

- lxvd2x S0X,0,SRC
- lxvd2x S1X,25,SRC
- lxvd2x S2X,26,SRC
- lxvd2x S3X,27,SRC
- lxvd2x S4X,28,SRC
- lxvd2x S5X,29,SRC
- lxvd2x S6X,30,SRC
- lxvd2x S7X,31,SRC
+ lxvd2x VSR(S0),0,SRC
+ lxvd2x VSR(S1),25,SRC
+ lxvd2x VSR(S2),26,SRC
+ lxvd2x VSR(S3),27,SRC
+ lxvd2x VSR(S4),28,SRC
+ lxvd2x VSR(S5),29,SRC
+ lxvd2x VSR(S6),30,SRC
+ lxvd2x VSR(S7),31,SRC

 IF_LE(&lt;vperm S0,S0,S0,swap_mask
  vperm S1,S1,S1,swap_mask
@@ -143,7 +132,7 @@ IF_LE(&lt;vperm S0,S0,S0,swap_mask
  li 10,0x10
 .align 5
 L8x_round_loop:
- lxvd2x KX,10,KEYS
+ lxvd2x VSR(K),10,KEYS
  vperm   K,K,K,swap_mask
  vncipher S0,S0,ZERO
  vncipher S1,S1,ZERO
@@ -164,7 +153,7 @@ L8x_round_loop:
  addi 10,10,0x10
  bdnz L8x_round_loop

- lxvd2x KX,10,KEYS
+ lxvd2x VSR(K),10,KEYS
  vperm   K,K,K,swap_mask
  vncipherlast S0,S0,K
  vncipherlast S1,S1,K
@@ -184,14 +173,14 @@ IF_LE(&lt;vperm S0,S0,S0,swap_mask
  vperm S6,S6,S6,swap_mask
  vperm S7,S7,S7,swap_mask&gt;)

- stxvd2x S0X,0,DST
- stxvd2x S1X,25,DST
- stxvd2x S2X,26,DST
- stxvd2x S3X,27,DST
- stxvd2x S4X,28,DST
- stxvd2x S5X,29,DST
- stxvd2x S6X,30,DST
- stxvd2x S7X,31,DST
+ stxvd2x VSR(S0),0,DST
+ stxvd2x VSR(S1),25,DST
+ stxvd2x VSR(S2),26,DST
+ stxvd2x VSR(S3),27,DST
+ stxvd2x VSR(S4),28,DST
+ stxvd2x VSR(S5),29,DST
+ stxvd2x VSR(S6),30,DST
+ stxvd2x VSR(S7),31,DST

  addi SRC,SRC,0x80
  addi DST,DST,0x80
@@ -213,16 +202,16 @@ L4x:
  cmpldi   5,0
  beq   L2x

- lxvd2x   KX,0,KEYS
+ lxvd2x   VSR(K),0,KEYS
  vperm   K,K,K,swap_mask

- lxvd2x S0X,0,SRC
+ lxvd2x VSR(S0),0,SRC
  li  9,0x10
- lxvd2x S1X,9,SRC
+ lxvd2x VSR(S1),9,SRC
  addi   9,9,0x10
- lxvd2x S2X,9,SRC
+ lxvd2x VSR(S2),9,SRC
  addi   9,9,0x10
- lxvd2x S3X,9,SRC
+ lxvd2x VSR(S3),9,SRC

 IF_LE(&lt;vperm S0,S0,S0,swap_mask
  vperm S1,S1,S1,swap_mask
@@ -238,7 +227,7 @@ IF_LE(&lt;vperm S0,S0,S0,swap_mask
  li 10,0x10
 .align 5
 L4x_round_loop:
- lxvd2x KX,10,KEYS
+ lxvd2x VSR(K),10,KEYS
  vperm  K,K,K,swap_mask
  vncipher S0,S0,ZERO
  vncipher S1,S1,ZERO
@@ -251,7 +240,7 @@ L4x_round_loop:
  addi   10,10,0x10
  bdnz  L4x_round_loop

- lxvd2x KX,10,KEYS
+ lxvd2x VSR(K),10,KEYS
  vperm   K,K,K,swap_mask
  vncipherlast S0,S0,K
  vncipherlast S1,S1,K
@@ -263,13 +252,13 @@ IF_LE(&lt;vperm S0,S0,S0,swap_mask
  vperm S2,S2,S2,swap_mask
  vperm S3,S3,S3,swap_mask&gt;)

- stxvd2x S0X,0,DST
+ stxvd2x VSR(S0),0,DST
  li  9,0x10
- stxvd2x S1X,9,DST
+ stxvd2x VSR(S1),9,DST
  addi   9,9,0x10
- stxvd2x S2X,9,DST
+ stxvd2x VSR(S2),9,DST
  addi  9,9,0x10
- stxvd2x S3X,9,DST
+ stxvd2x VSR(S3),9,DST

  addi   SRC,SRC,0x40
  addi   DST,DST,0x40
@@ -281,12 +270,12 @@ L2x:
  cmpldi  5,0
  beq   L1x

- lxvd2x KX,0,KEYS
+ lxvd2x VSR(K),0,KEYS
  vperm K,K,K,swap_mask

- lxvd2x S0X,0,SRC
+ lxvd2x VSR(S0),0,SRC
  li   9,0x10
- lxvd2x S1X,9,SRC
+ lxvd2x VSR(S1),9,SRC

 IF_LE(&lt;vperm S0,S0,S0,swap_mask
  vperm S1,S1,S1,swap_mask&gt;)
@@ -298,7 +287,7 @@ IF_LE(&lt;vperm S0,S0,S0,swap_mask
  li  10,0x10
 .align 5
 L2x_round_loop:
- lxvd2x KX,10,KEYS
+ lxvd2x VSR(K),10,KEYS
  vperm  K,K,K,swap_mask
  vncipher S0,S0,ZERO
  vncipher S1,S1,ZERO
@@ -307,7 +296,7 @@ L2x_round_loop:
  addi   10,10,0x10
  bdnz   L2x_round_loop

- lxvd2x KX,10,KEYS
+ lxvd2x VSR(K),10,KEYS
  vperm  K,K,K,swap_mask
  vncipherlast S0,S0,K
  vncipherlast S1,S1,K
@@ -315,9 +304,9 @@ L2x_round_loop:
 IF_LE(&lt;vperm S0,S0,S0,swap_mask
  vperm S1,S1,S1,swap_mask&gt;)

- stxvd2x S0X,0,DST
+ stxvd2x VSR(S0),0,DST
  li  9,0x10
- stxvd2x S1X,9,DST
+ stxvd2x VSR(S1),9,DST

  addi   SRC,SRC,0x20
  addi   DST,DST,0x20
@@ -328,10 +317,10 @@ L1x:
  cmpldi LENGTH,0
  beq   Ldone

- lxvd2x KX,0,KEYS
+ lxvd2x VSR(K),0,KEYS
  vperm   K,K,K,swap_mask

- lxvd2x S0X,0,SRC
+ lxvd2x VSR(S0),0,SRC

 IF_LE(&lt;vperm S0,S0,S0,swap_mask&gt;)

@@ -341,20 +330,20 @@ IF_LE(&lt;vperm S0,S0,S0,swap_mask&gt;)
  li   10,0x10
 .align 5
 L1x_round_loop:
- lxvd2x KX,10,KEYS
+ lxvd2x VSR(K),10,KEYS
  vperm  K,K,K,swap_mask
  vncipher S0,S0,ZERO
  vxor   S0,S0,K
  addi   10,10,0x10
  bdnz   L1x_round_loop

- lxvd2x KX,10,KEYS
+ lxvd2x VSR(K),10,KEYS
  vperm  K,K,K,swap_mask
  vncipherlast S0,S0,K

 IF_LE(&lt;vperm S0,S0,S0,swap_mask&gt;)

- stxvd2x S0X,0,DST
+ stxvd2x VSR(S0),0,DST

 Ldone:
  blr
diff --git a/powerpc64/p8/aes-encrypt-internal.asm
b/powerpc64/p8/aes-encrypt-internal.asm
index c696a4a3..67c7e597 100644
--- a/powerpc64/p8/aes-encrypt-internal.asm
+++ b/powerpc64/p8/aes-encrypt-internal.asm
@@ -1,4 +1,4 @@
-C powerpc64/P8/aes-encrypt-internal.asm
+C powerpc64/p8/aes-encrypt-internal.asm

 ifelse(&lt;
    Copyright (C) 2020 Mamone Tarsha
@@ -52,19 +52,8 @@ define(&lt;S5&gt;, &lt;7&gt;)
 define(&lt;S6&gt;, &lt;8&gt;)
 define(&lt;S7&gt;, &lt;9&gt;)

-define(&lt;KX&gt;, &lt;33&gt;)
-define(&lt;S0X&gt;, &lt;34&gt;)
-define(&lt;S1X&gt;, &lt;35&gt;)
-define(&lt;S2X&gt;, &lt;36&gt;)
-define(&lt;S3X&gt;, &lt;37&gt;)
-define(&lt;S4X&gt;, &lt;38&gt;)
-define(&lt;S5X&gt;, &lt;39&gt;)
-define(&lt;S6X&gt;, &lt;40&gt;)
-define(&lt;S7X&gt;, &lt;41&gt;)
-
 .file "aes-encrypt-internal.asm"

-IF_LE(&lt;.abiversion 2&gt;)
 .text

  C _aes_encrypt(unsigned rounds, const uint32_t *keys,
@@ -101,17 +90,17 @@ PROLOGUE(_nettle_aes_encrypt)

 .align 5
 Lx8_loop:
- lxvd2x KX,0,KEYS
+ lxvd2x VSR(K),0,KEYS
  vperm   K,K,K,swap_mask

- lxvd2x S0X,0,SRC
- lxvd2x S1X,25,SRC
- lxvd2x S2X,26,SRC
- lxvd2x S3X,27,SRC
- lxvd2x S4X,28,SRC
- lxvd2x S5X,29,SRC
- lxvd2x S6X,30,SRC
- lxvd2x S7X,31,SRC
+ lxvd2x VSR(S0),0,SRC
+ lxvd2x VSR(S1),25,SRC
+ lxvd2x VSR(S2),26,SRC
+ lxvd2x VSR(S3),27,SRC
+ lxvd2x VSR(S4),28,SRC
+ lxvd2x VSR(S5),29,SRC
+ lxvd2x VSR(S6),30,SRC
+ lxvd2x VSR(S7),31,SRC

 IF_LE(&lt;vperm S0,S0,S0,swap_mask
  vperm S1,S1,S1,swap_mask
@@ -135,7 +124,7 @@ IF_LE(&lt;vperm S0,S0,S0,swap_mask
  li 10,0x10
 .align 5
 L8x_round_loop:
- lxvd2x KX,10,KEYS
+ lxvd2x VSR(K),10,KEYS
  vperm   K,K,K,swap_mask
  vcipher S0,S0,K
  vcipher S1,S1,K
@@ -148,7 +137,7 @@ L8x_round_loop:
  addi 10,10,0x10
  bdnz L8x_round_loop

- lxvd2x KX,10,KEYS
+ lxvd2x VSR(K),10,KEYS
  vperm   K,K,K,swap_mask
  vcipherlast S0,S0,K
  vcipherlast S1,S1,K
@@ -168,14 +157,14 @@ IF_LE(&lt;vperm S0,S0,S0,swap_mask
  vperm S6,S6,S6,swap_mask
  vperm S7,S7,S7,swap_mask&gt;)

- stxvd2x S0X,0,DST
- stxvd2x S1X,25,DST
- stxvd2x S2X,26,DST
- stxvd2x S3X,27,DST
- stxvd2x S4X,28,DST
- stxvd2x S5X,29,DST
- stxvd2x S6X,30,DST
- stxvd2x S7X,31,DST
+ stxvd2x VSR(S0),0,DST
+ stxvd2x VSR(S1),25,DST
+ stxvd2x VSR(S2),26,DST
+ stxvd2x VSR(S3),27,DST
+ stxvd2x VSR(S4),28,DST
+ stxvd2x VSR(S5),29,DST
+ stxvd2x VSR(S6),30,DST
+ stxvd2x VSR(S7),31,DST

  addi SRC,SRC,0x80
  addi DST,DST,0x80
@@ -197,16 +186,16 @@ L4x:
  cmpldi   5,0
  beq   L2x

- lxvd2x   KX,0,KEYS
+ lxvd2x   VSR(K),0,KEYS
  vperm   K,K,K,swap_mask

- lxvd2x S0X,0,SRC
+ lxvd2x VSR(S0),0,SRC
  li  9,0x10
- lxvd2x S1X,9,SRC
+ lxvd2x VSR(S1),9,SRC
  addi   9,9,0x10
- lxvd2x S2X,9,SRC
+ lxvd2x VSR(S2),9,SRC
  addi   9,9,0x10
- lxvd2x S3X,9,SRC
+ lxvd2x VSR(S3),9,SRC

 IF_LE(&lt;vperm S0,S0,S0,swap_mask
  vperm S1,S1,S1,swap_mask
@@ -222,7 +211,7 @@ IF_LE(&lt;vperm S0,S0,S0,swap_mask
  li 10,0x10
 .align 5
 L4x_round_loop:
- lxvd2x KX,10,KEYS
+ lxvd2x VSR(K),10,KEYS
  vperm  K,K,K,swap_mask
  vcipher S0,S0,K
  vcipher S1,S1,K
@@ -231,7 +220,7 @@ L4x_round_loop:
  addi   10,10,0x10
  bdnz  L4x_round_loop

- lxvd2x KX,10,KEYS
+ lxvd2x VSR(K),10,KEYS
  vperm   K,K,K,swap_mask
  vcipherlast S0,S0,K
  vcipherlast S1,S1,K
@@ -243,13 +232,13 @@ IF_LE(&lt;vperm S0,S0,S0,swap_mask
  vperm S2,S2,S2,swap_mask
  vperm S3,S3,S3,swap_mask&gt;)

- stxvd2x S0X,0,DST
+ stxvd2x VSR(S0),0,DST
  li  9,0x10
- stxvd2x S1X,9,DST
+ stxvd2x VSR(S1),9,DST
  addi   9,9,0x10
- stxvd2x S2X,9,DST
+ stxvd2x VSR(S2),9,DST
  addi  9,9,0x10
- stxvd2x S3X,9,DST
+ stxvd2x VSR(S3),9,DST

  addi   SRC,SRC,0x40
  addi   DST,DST,0x40
@@ -261,12 +250,12 @@ L2x:
  cmpldi  5,0
  beq   L1x

- lxvd2x KX,0,KEYS
+ lxvd2x VSR(K),0,KEYS
  vperm K,K,K,swap_mask

- lxvd2x S0X,0,SRC
+ lxvd2x VSR(S0),0,SRC
  li   9,0x10
- lxvd2x S1X,9,SRC
+ lxvd2x VSR(S1),9,SRC

 IF_LE(&lt;vperm S0,S0,S0,swap_mask
  vperm S1,S1,S1,swap_mask&gt;)
@@ -278,14 +267,14 @@ IF_LE(&lt;vperm S0,S0,S0,swap_mask
  li  10,0x10
 .align 5
 L2x_round_loop:
- lxvd2x KX,10,KEYS
+ lxvd2x VSR(K),10,KEYS
  vperm  K,K,K,swap_mask
  vcipher S0,S0,K
  vcipher S1,S1,K
  addi   10,10,0x10
  bdnz   L2x_round_loop

- lxvd2x KX,10,KEYS
+ lxvd2x VSR(K),10,KEYS
  vperm  K,K,K,swap_mask
  vcipherlast S0,S0,K
  vcipherlast S1,S1,K
@@ -293,9 +282,9 @@ L2x_round_loop:
 IF_LE(&lt;vperm S0,S0,S0,swap_mask
  vperm S1,S1,S1,swap_mask&gt;)

- stxvd2x S0X,0,DST
+ stxvd2x VSR(S0),0,DST
  li  9,0x10
- stxvd2x S1X,9,DST
+ stxvd2x VSR(S1),9,DST

  addi   SRC,SRC,0x20
  addi   DST,DST,0x20
@@ -306,10 +295,10 @@ L1x:
  cmpldi LENGTH,0
  beq   Ldone

- lxvd2x KX,0,KEYS
+ lxvd2x VSR(K),0,KEYS
  vperm   K,K,K,swap_mask

- lxvd2x S0X,0,SRC
+ lxvd2x VSR(S0),0,SRC

 IF_LE(&lt;vperm S0,S0,S0,swap_mask&gt;)

@@ -319,19 +308,19 @@ IF_LE(&lt;vperm S0,S0,S0,swap_mask&gt;)
  li   10,0x10
 .align 5
 L1x_round_loop:
- lxvd2x KX,10,KEYS
+ lxvd2x VSR(K),10,KEYS
  vperm  K,K,K,swap_mask
  vcipher S0,S0,K
  addi   10,10,0x10
  bdnz   L1x_round_loop

- lxvd2x KX,10,KEYS
+ lxvd2x VSR(K),10,KEYS
  vperm  K,K,K,swap_mask
  vcipherlast S0,S0,K

 IF_LE(&lt;vperm S0,S0,S0,swap_mask&gt;)

- stxvd2x S0X,0,DST
+ stxvd2x VSR(S0),0,DST

 Ldone:
  blr

-- 
2.17.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200701075543</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-07-01 07:55:43-0400</timestampReceived><subject>Re: [Patch] Optimize AES and GHASH for PowerPC64 (support little-endian and big-endian)</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; Is it possible to override the PROLOGUE definition in powerpc64/machine.m4?

The m4 files are processed in the order asm.m4, machine.m4, config.m4
(not sure why config.m4 is last).

So machine.m4 can override definitions in asm.m4. Or if you don't want
to override all of PROLOGUE, you could define some helper macros which
expand to empty by default, and override them instead. A bit like the
ASM_X86_ENDBR, which is used unconditionally in the definition of
PROLOGUE, but expands to the empty string where not enabled by cnfigure.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200701093931</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-07-01 09:39:31-0400</timestampReceived><subject>Re: [PATCH 3/3] v4.3 Blowfish: Supply lengths instead of C-strings.</subject><body>

On Tue, Jun 30, 2020 at 9:56 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; I've now merged this (squashed together with part 2/3) to the bcrypt
&gt; branch in the repository.


Thanks.


&gt; Before merging to master, I'd need some basic
&gt; tests for the testsuite, preferably based on authoritative test vectors.
&gt;
&gt; For tests of the _verify function, it's important to include tests also
&gt; for inputs that should be rejected.
&gt;

I added some tests, commit has been submitted separately.
-- 
Stephen.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200706090945</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-07-06 09:09:45-0400</timestampReceived><subject>Re: [PATCH] Add bcrypt tests to testsuite.</subject><body>

"Stephen R. van den Berg" &lt;srb@cuci.nl&gt; writes:

&gt; True, but I fail to see how separating it into a different headerfile will
&gt; make this easier or more efficient.
&gt; In general, if you ask me, I'd say the more headerfiles you provide, the
&gt; more complicated it becomes to program to the API.

Ok. I've merged the bcrypt support to the master branch now.

Thanks!
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200709061515</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-07-09 06:15:15-0400</timestampReceived><subject>[PATCH 2/4] Add GHASH optimized implementation for PowerPC64</subject><body>

---
 gcm.c                   |   19 +-
 powerpc64/gcm-hash8.asm | 1004
+++++++++++++++++++++++++++++++++++++++++++++++
 2 files changed, 1022 insertions(+), 1 deletion(-)
 create mode 100644 powerpc64/gcm-hash8.asm

diff --git a/gcm.c b/gcm.c
index cf615daf..809c03bc 100644
--- a/gcm.c
+++ b/gcm.c
@@ -140,6 +140,12 @@ gcm_gf_mul (union nettle_block16 *x, const union
nettle_block16 *table)
   memcpy (x-&gt;b, Z.b, sizeof(Z));
 }
 # elif GCM_TABLE_BITS == 8
+#  if HAVE_NATIVE_gcm_init_key8
+
+#define gcm_init_key _nettle_gcm_init_key8
+void
+_nettle_gcm_init_key8 (union nettle_block16 *table);
+#  endif /* HAVE_NATIVE_gcm_init_key8 */
 #  if HAVE_NATIVE_gcm_hash8

 #define gcm_hash _nettle_gcm_hash8
@@ -225,6 +231,13 @@ gcm_gf_mul (union nettle_block16 *x, const union
nettle_block16 *table)

 #endif /* GCM_TABLE_BITS */

+#if HAVE_NATIVE_gcm_fill
+
+#define gcm_fill _nettle_gcm_fill
+void
+_nettle_gcm_fill (uint8_t *ctr, size_t blocks, union nettle_block16
*buffer);
+#endif /* HAVE_NATIVE_gcm_fill */
+
 /* Increment the rightmost 32 bits. */
 #define INC32(block) INCREMENT(4, (block.b) + GCM_BLOCK_SIZE - 4)

@@ -245,7 +258,9 @@ gcm_set_key(struct gcm_key *key,
   memset(key-&gt;h[0].b, 0, GCM_BLOCK_SIZE);
   f (cipher, GCM_BLOCK_SIZE, key-&gt;h[i].b, key-&gt;h[0].b);

-#if GCM_TABLE_BITS
+#ifdef gcm_init_key
+  gcm_init_key(key-&gt;h);
+#elif GCM_TABLE_BITS
   /* Algorithm 3 from the gcm paper. First do powers of two, then do
      the rest by adding. */
   while (i /= 2)
@@ -333,6 +348,7 @@ gcm_update(struct gcm_ctx *ctx, const struct gcm_key
*key,
   ctx-&gt;auth_size += length;
 }

+#ifndef gcm_fill
 static nettle_fill16_func gcm_fill;
 static void
 gcm_fill(uint8_t *ctr, size_t blocks, union nettle_block16 *buffer)
@@ -349,6 +365,7 @@ gcm_fill(uint8_t *ctr, size_t blocks, union
nettle_block16 *buffer)

   WRITE_UINT32(ctr + GCM_BLOCK_SIZE - 4, c);
 }
+#endif /* !gcm_fill */

 void
 gcm_encrypt (struct gcm_ctx *ctx, const struct gcm_key *key,
diff --git a/powerpc64/gcm-hash8.asm b/powerpc64/gcm-hash8.asm
new file mode 100644
index 00000000..7d5d3ec9
--- /dev/null
+++ b/powerpc64/gcm-hash8.asm
@@ -0,0 +1,1004 @@
+C powerpc64/gcm-hash8.asm
+
+ifelse(&lt;
+   Copyright (C) 2020 Mamone Tarsha
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+&gt;)
+
+C Alignment of gcm_key table elements, which is declared in gcm.h
+define(&lt;TableElemAlign&gt;, &lt;0x100&gt;)
+
+C Register usage:
+
+define(&lt;SP&gt;, &lt;1&gt;)
+define(&lt;TOCP&gt;, &lt;2&gt;)
+
+define(&lt;TABLE&gt;, &lt;3&gt;)
+define(&lt;X&gt;, &lt;4&gt;)
+define(&lt;LENGTH&gt;, &lt;5&gt;)
+define(&lt;DATA&gt;, &lt;6&gt;)
+
+define(&lt;zero&gt;, &lt;0&gt;)
+define(&lt;swap_mask&gt;, &lt;1&gt;)
+define(&lt;hidw_mask&gt;, &lt;2&gt;)
+define(&lt;lodw_mask&gt;, &lt;3&gt;)
+define(&lt;poly&gt;, &lt;4&gt;)
+define(&lt;poly_h&gt;, &lt;4&gt;)
+define(&lt;poly_l&gt;, &lt;5&gt;)
+define(&lt;RP&gt;, &lt;6&gt;)
+define(&lt;Mh&gt;, &lt;7&gt;)
+define(&lt;Ml&gt;, &lt;8&gt;)
+define(&lt;H&gt;, &lt;9&gt;)
+define(&lt;Hh&gt;, &lt;10&gt;)
+define(&lt;Hl&gt;, &lt;11&gt;)
+define(&lt;RP2&gt;, &lt;9&gt;)
+define(&lt;M2h&gt;, &lt;10&gt;)
+define(&lt;M2l&gt;, &lt;11&gt;)
+
+define(&lt;HX&gt;, &lt;41&gt;)
+define(&lt;HhX&gt;, &lt;42&gt;)
+define(&lt;HlX&gt;, &lt;43&gt;)
+define(&lt;H_HhX&gt;, &lt;44&gt;)
+define(&lt;H_HX&gt;, &lt;45&gt;)
+define(&lt;H_HlX&gt;, &lt;46&gt;)
+
+define(&lt;sl1&gt;, &lt;1&gt;)
+define(&lt;msb&gt;, &lt;5&gt;)
+define(&lt;H2&gt;, &lt;6&gt;)
+define(&lt;H2h&gt;, &lt;7&gt;)
+define(&lt;H2l&gt;, &lt;8&gt;)
+define(&lt;H_h&gt;, &lt;12&gt;)
+define(&lt;H_m&gt;, &lt;13&gt;)
+define(&lt;H_l&gt;, &lt;14&gt;)
+define(&lt;H_Hh&gt;, &lt;12&gt;)
+define(&lt;H_H&gt;, &lt;13&gt;)
+define(&lt;H_Hl&gt;, &lt;14&gt;)
+define(&lt;H_t&gt;, &lt;15&gt;)
+define(&lt;H2_h&gt;, &lt;16&gt;)
+define(&lt;H2_m&gt;, &lt;17&gt;)
+define(&lt;H2_l&gt;, &lt;18&gt;)
+define(&lt;H2_t&gt;, &lt;19&gt;)
+
+define(&lt;C0X&gt;, &lt;38&gt;)
+define(&lt;C1X&gt;, &lt;39&gt;)
+define(&lt;C2X&gt;, &lt;40&gt;)
+define(&lt;C3X&gt;, &lt;44&gt;)
+define(&lt;C4X&gt;, &lt;38&gt;)
+define(&lt;C5X&gt;, &lt;39&gt;)
+define(&lt;C6X&gt;, &lt;40&gt;)
+define(&lt;C7X&gt;, &lt;44&gt;)
+
+define(&lt;CX&gt;, &lt;45&gt;)
+
+define(&lt;C0&gt;, &lt;6&gt;)
+define(&lt;C1&gt;, &lt;7&gt;)
+define(&lt;C2&gt;, &lt;8&gt;)
+define(&lt;C3&gt;, &lt;12&gt;)
+define(&lt;C4&gt;, &lt;6&gt;)
+define(&lt;C5&gt;, &lt;7&gt;)
+define(&lt;C6&gt;, &lt;8&gt;)
+define(&lt;C7&gt;, &lt;12&gt;)
+
+define(&lt;C&gt;, &lt;13&gt;)
+
+define(&lt;Ch&gt;, &lt;14&gt;)
+define(&lt;Cl&gt;, &lt;15&gt;)
+define(&lt;Cm&gt;, &lt;16&gt;)
+
+define(&lt;C01h&gt;, &lt;14&gt;)
+define(&lt;C01l&gt;, &lt;15&gt;)
+define(&lt;C01&gt;, &lt;16&gt;)
+define(&lt;C23h&gt;, &lt;17&gt;)
+define(&lt;C23l&gt;, &lt;18&gt;)
+define(&lt;C23&gt;, &lt;19&gt;)
+define(&lt;C45h&gt;, &lt;20&gt;)
+define(&lt;C45l&gt;, &lt;21&gt;)
+define(&lt;C45&gt;, &lt;22&gt;)
+define(&lt;C67h&gt;, &lt;6&gt;)
+define(&lt;C67l&gt;, &lt;7&gt;)
+define(&lt;C67&gt;, &lt;8&gt;)
+
+define(&lt;H21&gt;, &lt;9&gt;)
+define(&lt;H21h&gt;, &lt;10&gt;)
+define(&lt;H21l&gt;, &lt;11&gt;)
+define(&lt;H43&gt;, &lt;23&gt;)
+define(&lt;H43h&gt;, &lt;24&gt;)
+define(&lt;H43l&gt;, &lt;25&gt;)
+define(&lt;H65&gt;, &lt;26&gt;)
+define(&lt;H65h&gt;, &lt;27&gt;)
+define(&lt;H65l&gt;, &lt;28&gt;)
+define(&lt;H87&gt;, &lt;29&gt;)
+define(&lt;H87h&gt;, &lt;30&gt;)
+define(&lt;H87l&gt;, &lt;31&gt;)
+
+define(&lt;H21X&gt;, &lt;41&gt;)
+define(&lt;H21hX&gt;, &lt;42&gt;)
+define(&lt;H21lX&gt;, &lt;43&gt;)
+define(&lt;H43X&gt;, &lt;55&gt;)
+define(&lt;H43hX&gt;, &lt;56&gt;)
+define(&lt;H43lX&gt;, &lt;57&gt;)
+define(&lt;H65X&gt;, &lt;58&gt;)
+define(&lt;H65hX&gt;, &lt;59&gt;)
+define(&lt;H65lX&gt;, &lt;60&gt;)
+define(&lt;H87X&gt;, &lt;61&gt;)
+define(&lt;H87hX&gt;, &lt;62&gt;)
+define(&lt;H87lX&gt;, &lt;63&gt;)
+
+# gcm_fill registers:
+
+define(&lt;CTR&gt;, &lt;3&gt;)
+define(&lt;BLOCKS&gt;, &lt;4&gt;)
+define(&lt;BUFFER&gt;, &lt;5&gt;)
+
+define(&lt;CTR0&gt;, &lt;2&gt;)
+define(&lt;CTR0S&gt;, &lt;3&gt;)
+define(&lt;CTR1&gt;, &lt;4&gt;)
+define(&lt;CTR2&gt;, &lt;5&gt;)
+define(&lt;CTR3&gt;, &lt;6&gt;)
+define(&lt;CTR4&gt;, &lt;7&gt;)
+define(&lt;CTR5&gt;, &lt;8&gt;)
+define(&lt;CTR6&gt;, &lt;9&gt;)
+define(&lt;CTR7&gt;, &lt;10&gt;)
+
+define(&lt;CTR0X&gt;, &lt;34&gt;)
+define(&lt;CTR0SX&gt;, &lt;35&gt;)
+define(&lt;CTR1X&gt;, &lt;36&gt;)
+define(&lt;CTR2X&gt;, &lt;37&gt;)
+define(&lt;CTR3X&gt;, &lt;38&gt;)
+define(&lt;CTR4X&gt;, &lt;39&gt;)
+define(&lt;CTR5X&gt;, &lt;40&gt;)
+define(&lt;CTR6X&gt;, &lt;41&gt;)
+define(&lt;CTR7X&gt;, &lt;42&gt;)
+
+define(&lt;I1&gt;, &lt;11&gt;)
+define(&lt;I2&gt;, &lt;12&gt;)
+define(&lt;I3&gt;, &lt;13&gt;)
+define(&lt;I4&gt;, &lt;14&gt;)
+define(&lt;I5&gt;, &lt;15&gt;)
+define(&lt;I6&gt;, &lt;16&gt;)
+define(&lt;I7&gt;, &lt;17&gt;)
+define(&lt;I8&gt;, &lt;18&gt;)
+
+.file "gcm-hash8.asm"
+
+IF_LE(&lt;.abiversion 2&gt;)
+.text
+
+ # void gcm_init_key (union gcm_block *table)
+
+PROLOGUE(_nettle_gcm_init_key8)
+ ld     7,.polynomial@got(TOCP)
+ lvx   poly,0,7
+IF_LE(&lt;ld 7,.swap_mask@got(TOCP)
+ lvx   swap_mask,0,7&gt;)
+ ld     7,.hidw_mask@got(TOCP)
+ lvx     hidw_mask,0,7
+ ld     7,.lodw_mask@got(TOCP)
+ lvx   lodw_mask,0,7
+
+ li    10,8*TableElemAlign
+  lxvd2x HX,10,TABLE # load H
+IF_LE(&lt;vperm H,H,H,swap_mask&gt;)
+
+ # --- calculate H = H shift left 1 modulo polynomial ---
+
+ vupkhsw    msb,H # most significant bit word-extend
+ vspltisb sl1,1 # splat 1 for shift left
+ vspltw      msb,msb,0 # most significant bit extend
+ vsl    H,H,sl1 # H shift left 1
+ vand msb,msb,poly
+ vxor zero,zero,zero
+ vxor H_t,H,msb
+
+ vsldoi H,H_t,H_t,8 # doubleword swap
+ vsldoi Hh,H,zero,8
+ vsldoi Hl,zero,H,8
+
+ # --- calculate H^2 = H*H ---
+
+ # reduction pre-processing
+ vsldoi poly_h,zero,poly,8
+ vsldoi poly_l,poly_h,poly_h,8
+
+ # polynomial multiplication "classical"
+ vpmsumd H_h,H_t,Hh # H^1h*H^1h
+ vpmsumd H_l,H_t,Hl # H^1l*H^1l
+ vpmsumd H_m,H_t,H # H^1h*H^1l⊕H^1l*H^1h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h   # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8   # [2]
+ vsldoi Ml,H_m,zero,8 # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor H_h,H_h,Mh       # [2]
+ vxor H_l,H_l,Ml       # [2]
+ vxor H_l,H_l,RP       # [1]
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l
+ vxor H_h,H_l,H_h
+ vxor H2_t,H_h,RP
+
+ vsldoi H2,H2_t,H2_t,8
+ vsldoi H2h,H2,zero,8
+ vsldoi H2l,zero,H2,8
+
+ # --- calculate [H^2.Hi⊕H^2.Lo:H^1.Hi⊕H^1.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store H,[H^2.Hi⊕H^2.Lo:H^1.Hi⊕H^1.Lo] ---
+
+ li    8,0*TableElemAlign
+ li    9,1*TableElemAlign
+ li    10,2*TableElemAlign
+ stxvd2x HlX,8,TABLE
+ stxvd2x HX,9,TABLE
+ stxvd2x HhX,10,TABLE
+
+ li    8,3*TableElemAlign
+ li    9,4*TableElemAlign
+ li    10,5*TableElemAlign
+ stxvd2x H_HhX,8,TABLE
+ stxvd2x H_HX,9,TABLE
+ stxvd2x H_HlX,10,TABLE
+
+ # --- calculate H^3,H^4 ---
+
+ # polynomial multiplication "classical"
+ vpmsumd H_l,H_t,H2l # H^1l*H^2l
+ vpmsumd H_m,H_t,H2 # H^1h*H^2l⊕H^1l*H^2h
+ vpmsumd H_h,H_t,H2h # H^1h*H^2h
+ vpmsumd H2_l,H2_t,H2l # H^2l*H^2l
+ vpmsumd H2_m,H2_t,H2 # H^2h*H^2l⊕H^2l*H^2h
+ vpmsumd H2_h,H2_t,H2h # H^2h*H^2h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h # [1] H^3
+ vpmsumd    RP2,H2_l,poly_h # [1] H^4
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8 # [2] H^3
+ vsldoi M2h,zero,H2_m,8 # [2] H^4
+ vsldoi Ml,H_m,zero,8 # [2] H^3
+ vsldoi M2l,H2_m,zero,8 # [2] H^4
+ vsldoi RP,RP,RP,8 # [1] H^3
+ vsldoi RP2,RP2,RP2,8 # [1] H^4
+ vxor H_h,H_h,Mh # [2] H^3
+ vxor H2_h,H2_h,M2h # [2] H^4
+ vxor H_l,H_l,Ml # [2] H^3
+ vxor H2_l,H2_l,M2l # [2] H^4
+ vxor H_l,H_l,RP # [1] H^3
+ vxor H2_l,H2_l,RP2 # [1] H^4
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l # H^3
+ vpmsumd RP2,H2_l,poly_l # H^4
+ vxor H_h,H_l,H_h # H^3
+ vxor H2_h,H2_l,H2_h # H^4
+ vxor H_h,H_h,RP # H^3
+ vxor H2_h,H2_h,RP2 # H^4
+
+ vsldoi H2,H2_h,H2_h,8 # H^4
+ vsldoi H,H_h,H_h,8 # H^3
+ vsldoi H2l,zero,H2,8 # H^4
+ vsldoi H2h,H2,zero,8 # H^4
+
+ # --- calculate [H^4.Hi⊕H^4.Lo:H^3.Hi⊕H^3.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store [H^4.Hi⊕H^4.Lo:H^3.Hi⊕H^3.Lo] ---
+
+ li    8,6*TableElemAlign
+ li    9,7*TableElemAlign
+ li    10,8*TableElemAlign
+ stxvd2x H_HhX,8,TABLE
+ stxvd2x H_HX,9,TABLE
+ stxvd2x H_HlX,10,TABLE
+
+ # --- calculate H^5,H^6 ---
+
+ # polynomial multiplication "classical"
+ vpmsumd H_l,H_t,H2l # H^1l*H^4l
+ vpmsumd H_m,H_t,H2 # H^1h*H^4l⊕H^1l*H^4h
+ vpmsumd H_h,H_t,H2h # H^1h*H^4h
+ vpmsumd H2_l,H2_t,H2l # H^2l*H^4l
+ vpmsumd H2_m,H2_t,H2 # H^2h*H^4l⊕H^2l*H^4h
+ vpmsumd H2_h,H2_t,H2h # H^2h*H^4h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h # [1] H^5
+ vpmsumd    RP2,H2_l,poly_h # [1] H^6
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8 # [2] H^5
+ vsldoi M2h,zero,H2_m,8 # [2] H^6
+ vsldoi Ml,H_m,zero,8 # [2] H^5
+ vsldoi M2l,H2_m,zero,8 # [2] H^6
+ vsldoi RP,RP,RP,8 # [1] H^5
+ vsldoi RP2,RP2,RP2,8 # [1] H^6
+ vxor H_h,H_h,Mh # [2] H^5
+ vxor H2_h,H2_h,M2h # [2] H^6
+ vxor H_l,H_l,Ml # [2] H^5
+ vxor H2_l,H2_l,M2l # [2] H^6
+ vxor H_l,H_l,RP # [1] H^5
+ vxor H2_l,H2_l,RP2 # [1] H^6
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l # H^5
+ vpmsumd RP2,H2_l,poly_l # H^6
+ vxor H_h,H_l,H_h # H^5
+ vxor H2_h,H2_l,H2_h # H^6
+ vxor H_h,H_h,RP # H^5
+ vxor H2_h,H2_h,RP2 # H^6
+
+ vsldoi H2,H2_h,H2_h,8 # H^6
+ vsldoi H,H_h,H_h,8 # H^5
+ vsldoi H2l,zero,H2,8 # H^6
+ vsldoi H2h,H2,zero,8 # H^6
+
+ # --- calculate [H^6.Hi⊕H^6.Lo:H^5.Hi⊕H^5.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store [H^6.Hi⊕H^6.Lo:H^5.Hi⊕H^5.Lo] ---
+
+ li    8,9*TableElemAlign
+ li    9,10*TableElemAlign
+ li    10,11*TableElemAlign
+ stxvd2x H_HhX,8,TABLE
+ stxvd2x H_HX,9,TABLE
+ stxvd2x H_HlX,10,TABLE
+
+ # --- calculate H^7,H^8 ---
+
+ # polynomial multiplication "classical"
+ vpmsumd H_l,H_t,H2l # H^1l*H^6l
+ vpmsumd H_m,H_t,H2 # H^1h*H^6l⊕H^1l*H^6h
+ vpmsumd H_h,H_t,H2h # H^1h*H^6h
+ vpmsumd H2_l,H2_t,H2l # H^2l*H^6l
+ vpmsumd H2_m,H2_t,H2 # H^2h*H^6l⊕H^2l*H^6h
+ vpmsumd H2_h,H2_t,H2h # H^2h*H^6h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h # [1] H^7
+ vpmsumd    RP2,H2_l,poly_h # [1] H^8
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8 # [2] H^7
+ vsldoi M2h,zero,H2_m,8 # [2] H^8
+ vsldoi Ml,H_m,zero,8 # [2] H^7
+ vsldoi M2l,H2_m,zero,8 # [2] H^8
+ vsldoi RP,RP,RP,8 # [1] H^7
+ vsldoi RP2,RP2,RP2,8 # [1] H^8
+ vxor H_h,H_h,Mh # [2] H^7
+ vxor H2_h,H2_h,M2h # [2] H^8
+ vxor H_l,H_l,Ml # [2] H^7
+ vxor H2_l,H2_l,M2l # [2] H^8
+ vxor H_l,H_l,RP # [1] H^7
+ vxor H2_l,H2_l,RP2 # [1] H^8
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l # H^7
+ vpmsumd RP2,H2_l,poly_l # H^8
+ vxor H_h,H_l,H_h # H^7
+ vxor H2_h,H2_l,H2_h # H^8
+ vxor H_h,H_h,RP # H^7
+ vxor H2_h,H2_h,RP2 # H^8
+
+ vsldoi H,H_h,H_h,8 # H^7
+ vsldoi H2,H2_h,H2_h,8 # H^8
+
+ # --- calculate [H^8.Hi⊕H^8.Lo:H^7.Hi⊕H^7.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store [H^8.Hi⊕H^8.Lo:H^7.Hi⊕H^7.Lo] ---
+
+ li    8,12*TableElemAlign
+ li    9,13*TableElemAlign
+ li    10,14*TableElemAlign
+ stxvd2x H_HhX,8,TABLE
+ stxvd2x H_HX,9,TABLE
+ stxvd2x H_HlX,10,TABLE
+
+  blr
+EPILOGUE(_nettle_gcm_init_key8)
+
+ # void gcm_hash (const struct gcm_key *key, union gcm_block *x,
+ #                size_t length, const uint8_t *data)
+
+PROLOGUE(_nettle_gcm_hash8)
+ vxor zero,zero,zero
+
+ ld     7,.polynomial@got(TOCP)
+ lvx   poly,0,7
+IF_LE(&lt;ld 7,.swap_mask@got(TOCP)
+ lvx   swap_mask,0,7&gt;)
+ ld      7,.hidw_mask@got(TOCP)
+ lvx     hidw_mask,0,7
+ ld     7,.lodw_mask@got(TOCP)
+ lvx   lodw_mask,0,7
+
+ vsldoi poly_h,zero,poly,8
+ vsldoi poly_l,poly_h,poly_h,8
+
+ lxvd2x CX,0,X # load X
+IF_LE(&lt;vperm C,C,C,swap_mask&gt;)
+
+ srdi 7,LENGTH,7 # 8x loop count
+ cmpldi 7,0
+ beq L2x
+
+ # backup registers
+ stdu SP,-224(SP)
+ std 28,216(SP)
+ std 29,208(SP)
+ std 30,200(SP)
+ std 31,192(SP)
+    li 8,176
+    stvx 20,8,SP
+    subi 8,8,16
+    stvx 21,8,SP
+    subi 8,8,16
+    stvx 22,8,SP
+    subi 8,8,16
+    stvx 23,8,SP
+    subi 8,8,16
+    stvx 24,8,SP
+    subi 8,8,16
+    stvx 25,8,SP
+    subi 8,8,16
+    stvx 26,8,SP
+    subi 8,8,16
+    stvx 27,8,SP
+    subi 8,8,16
+    stvx 28,8,SP
+    subi 8,8,16
+    stvx 29,8,SP
+    subi 8,8,16
+    stvx 30,8,SP
+    subi 8,8,16
+    stvx 31,8,SP
+
+ # table loading
+ li 8,3*TableElemAlign
+ li 9,4*TableElemAlign
+ li 10,5*TableElemAlign
+ lxvd2x H21hX,8,TABLE
+ lxvd2x H21X,9,TABLE
+ lxvd2x H21lX,10,TABLE
+ li 8,6*TableElemAlign
+ li 9,7*TableElemAlign
+ li 10,8*TableElemAlign
+ lxvd2x H43hX,8,TABLE
+ lxvd2x H43X,9,TABLE
+ lxvd2x H43lX,10,TABLE
+ li 8,9*TableElemAlign
+ li 9,10*TableElemAlign
+ li 10,11*TableElemAlign
+ lxvd2x H65hX,8,TABLE
+ lxvd2x H65X,9,TABLE
+ lxvd2x H65lX,10,TABLE
+ li 8,12*TableElemAlign
+ li 9,13*TableElemAlign
+ li 10,14*TableElemAlign
+ lxvd2x H87hX,8,TABLE
+ lxvd2x H87X,9,TABLE
+ lxvd2x H87lX,10,TABLE
+
+ li 8,0x10
+ li 9,0x20
+ li 10,0x30
+ li 28,0x40
+ li 29,0x50
+ li 30,0x60
+ li 31,0x70
+
+ mtctr     7
+.align 5
+L8x_loop:
+ # input loading
+ lxvd2x C0X,0,DATA # load C0
+ lxvd2x C1X,8,DATA # load C1
+ lxvd2x C2X,9,DATA # load C2
+ lxvd2x C3X,10,DATA # load C3
+
+ # swap permuting
+IF_LE(&lt;vperm C0,C0,C0,swap_mask
+ vperm C1,C1,C1,swap_mask
+ vperm C2,C2,C2,swap_mask
+ vperm C3,C3,C3,swap_mask&gt;)
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ # polynomial multiplication "karatsuba" pre-processing
+ vperm C23h,C2,C3,hidw_mask
+ vperm C23l,C2,C3,lodw_mask
+ vperm C01h,C0,C1,hidw_mask
+ vperm C01l,C0,C1,lodw_mask
+
+ # input loading
+ lxvd2x C4X,28,DATA # load C4
+ lxvd2x C5X,29,DATA # load C5
+ lxvd2x C6X,30,DATA # load C6
+ lxvd2x C7X,31,DATA # load C7
+
+ # swap permuting
+IF_LE(&lt;vperm C4,C4,C4,swap_mask
+ vperm C5,C5,C5,swap_mask
+ vperm C6,C6,C6,swap_mask
+ vperm C7,C7,C7,swap_mask&gt;)
+
+ # polynomial multiplication "karatsuba" pre-processing
+ vperm C45h,C4,C5,hidw_mask
+ vperm C45l,C4,C5,lodw_mask
+ vperm C67h,C6,C7,hidw_mask
+ vperm C67l,C6,C7,lodw_mask
+ vxor C23,C23h,C23l
+ vxor C01,C01h,C01l
+ vxor C45,C45h,C45l
+ vxor C67,C67h,C67l
+
+ # polynomial multiplication "karatsuba"
+ vpmsumd C23h,C23h,H65h # H23 = H^6h*C2h⊕H^5h*C3h
+ vpmsumd C23l,C23l,H65l # L23 = H^6l*C2l⊕H^5l*C3l
+ vpmsumd C01h,C01h,H87h # H01 = H^8h*C0h⊕H^7h*C1h
+ vpmsumd C01l,C01l,H87l # L01 = H^8l*C0l⊕H^7l*C1l
+ vpmsumd C67h,C67h,H21h # H67 = H^2h*C6h⊕H^1h*C7h
+ vpmsumd C67l,C67l,H21l # L67 = H^2l*C6l⊕H^1l*C7l
+ vpmsumd C45h,C45h,H43h # H45 = H^4h*C4h⊕H^3h*C5h
+ vpmsumd C45l,C45l,H43l # L45 = H^4l*C4l⊕H^3l*C5l
+ vpmsumd C23,C23,H65 # M23 = (H^6h⊕H^5h)*(C2h⊕C3h)⊕(H^6l⊕H^5l)*(C2l⊕C3l)
+ vpmsumd C01,C01,H87 # M01 = (H^8h⊕H^7h)*(C0h⊕C1h)⊕(H^8l⊕H^7l)*(C0l⊕C1l)
+ vpmsumd C45,C45,H43 # M45 = (H^4h⊕H^3h)*(C4h⊕C5h)⊕(H^4l⊕H^3l)*(C4l⊕C5l)
+ vpmsumd C67,C67,H21 # M67 = (H^2h⊕H^1h)*(C6h⊕C7h)⊕(H^2l⊕H^1l)*(C6l⊕C7l)
+
+ # polynomial multiplication "karatsuba" post-processing
+ vxor C23,C23,C23h
+ vxor C01,C01,C01h
+ vxor C45,C45,C45h
+ vxor C67,C67,C67h
+ vxor C23,C23,C23l
+ vxor C01,C01,C01l
+ vxor C45,C45,C45l
+ vxor C67,C67,C67l
+
+ # deferred recombination of partial products
+ vxor C01h,C01h,C23h # H0 = H01⊕H23
+ vxor C45h,C45h,C67h # H1 = H45⊕H67
+ vxor C01l,C01l,C23l # L0 = L01⊕L23
+ vxor C45l,C45l,C67l # L1 = L45⊕L45
+ vxor C01,C01,C23 # M0 = M01⊕M23
+ vxor C45,C45,C67 # M1 = M45⊕M45
+ vxor C01h,C01h,C45h # H = H0⊕H1
+ vxor C01l,C01l,C45l # L = L0⊕L1
+ vxor C01,C01,C45 # M = M0⊕M1
+
+ # reduction first phase # [1]
+ vpmsumd RP,C01l,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,C01,8   # [2]
+ vsldoi Ml,C01,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor C01h,C01h,Mh     # [2]
+ vxor C01l,C01l,Ml     # [2]
+ vxor C01l,C01l,RP     # [1]
+
+ # reduction second phase
+ vpmsumd RP,C01l,poly_l
+ vxor C01h,C01l,C01h
+ vxor C,C01h,RP
+
+ addi DATA,DATA,0x80
+ bdnz L8x_loop
+
+    # restore registers
+ li 8,0
+    lvx 31,8,SP
+    addi 8,8,16
+    lvx 30,8,SP
+    addi 8,8,16
+    lvx 29,8,SP
+    addi 8,8,16
+    lvx 28,8,SP
+    addi 8,8,16
+    lvx 27,8,SP
+    addi 8,8,16
+    lvx 26,8,SP
+    addi 8,8,16
+    lvx 25,8,SP
+    addi 8,8,16
+    lvx 24,8,SP
+    addi 8,8,16
+    lvx 23,8,SP
+    addi 8,8,16
+    lvx 22,8,SP
+    addi 8,8,16
+    lvx 21,8,SP
+    addi 8,8,16
+    lvx 20,8,SP
+ ld 31,192(SP)
+ ld 30,200(SP)
+ ld 29,208(SP)
+ ld 28,216(SP)
+ addi SP,SP,224
+
+ clrldi   LENGTH,LENGTH,57
+L2x:
+ srdi 7,LENGTH,5
+ cmpldi 7,0
+ beq L1x
+
+ # table loading
+ li 8,3*TableElemAlign
+ li 9,4*TableElemAlign
+ li 10,5*TableElemAlign
+ lxvd2x H21hX,8,TABLE
+ lxvd2x H21X,9,TABLE
+ lxvd2x H21lX,10,TABLE
+
+ li 10,0x10
+
+ mtctr     7
+.align 5
+L2x_loop:
+ # input loading
+ lxvd2x C0X,0,DATA # load C0
+ lxvd2x C1X,10,DATA # load C1
+
+ # swap permuting
+IF_LE(&lt;vperm C0,C0,C0,swap_mask
+ vperm C1,C1,C1,swap_mask&gt;)
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ # polynomial multiplication "karatsuba" pre-processing
+ vperm C01h,C0,C1,hidw_mask
+ vperm C01l,C0,C1,lodw_mask
+ vxor C01,C01h,C01l
+
+ # polynomial multiplication "karatsuba"
+ vpmsumd C01h,C01h,H21h # H01 = H^2h*C0h⊕H^1h*C1h
+ vpmsumd C01l,C01l,H21l # L01 = H^2l*C0l⊕H^1l*C1l
+ vpmsumd C01,C01,H21 # M01 = (H^2h⊕H^1h)*(C0h⊕C1h)⊕(H^2l⊕H^1l)*(C0l⊕C1l)
+
+ # polynomial multiplication "karatsuba" post-processing
+ vxor C01,C01,C01h
+ vxor C01,C01,C01l
+
+ # reduction first phase # [1]
+ vpmsumd RP,C01l,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,C01,8   # [2]
+ vsldoi Ml,C01,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor C01h,C01h,Mh     # [2]
+ vxor C01l,C01l,Ml     # [2]
+ vxor C01l,C01l,RP     # [1]
+
+ # reduction second phase
+ vpmsumd RP,C01l,poly_l
+ vxor C01h,C01l,C01h
+ vxor C,C01h,RP
+
+ addi DATA,DATA,0x20
+ bdnz L2x_loop
+
+ clrldi   LENGTH,LENGTH,59
+L1x:
+ srdi 7,LENGTH,4
+ cmpldi 7,0
+ beq Lrem
+
+ # table loading
+ li 9,1*TableElemAlign
+ li 10,2*TableElemAlign
+ lxvd2x HlX,0,TABLE
+ lxvd2x HX, 9,TABLE
+ lxvd2x HhX,10,TABLE
+
+ # input loading
+ lxvd2x C0X,0,DATA # load C0
+
+ # swap permuting
+IF_LE(&lt;vperm C0,C0,C0,swap_mask&gt;)
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ vpmsumd Cl,C0,Hl # L = Hl*Cl
+ vpmsumd Cm,C0,H # M = Hh*Cl⊕Hl*Ch
+ vpmsumd Ch,C0,Hh # H = Hh*Ch
+
+ # reduction first phase # [1]
+ vpmsumd RP,Cl,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,Cm,8   # [2]
+ vsldoi Ml,Cm,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor Ch,Ch,Mh   # [2]
+ vxor Cl,Cl,Ml       # [2]
+ vxor Cl,Cl,RP   # [1]
+
+ # reduction second phase
+ vpmsumd RP,Cl,poly_l
+ vxor Ch,Cl,Ch
+ vxor C,Ch,RP
+
+ addi DATA,DATA,0x10
+ clrldi   LENGTH,LENGTH,60
+Lrem:
+ cmpldi LENGTH,0
+ beq Ldone
+
+ # table loading
+ li 9,1*TableElemAlign
+ li 10,2*TableElemAlign
+ lxvd2x HlX,0,TABLE
+ lxvd2x HX, 9,TABLE
+ lxvd2x HhX,10,TABLE
+
+ # input loading
+ stdu SP,-16(SP)
+ stvx zero,0,SP
+Lst_loop:
+ subic.      LENGTH,LENGTH,1
+ lbzx 7,LENGTH,DATA
+ stbx 7,LENGTH,SP
+ bne Lst_loop
+ lxvd2x   C0X,0,SP
+ addi SP,SP,16
+
+ # swap permuting
+IF_LE(&lt;vperm C0,C0,C0,swap_mask&gt;)
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ vpmsumd Cl,C0,Hl # L = Hl*Cl
+ vpmsumd Cm,C0,H # M = Hh*Cl⊕Hl*Ch
+ vpmsumd Ch,C0,Hh # H = Hh*Ch
+
+ # reduction first phase # [1]
+ vpmsumd RP,Cl,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,Cm,8   # [2]
+ vsldoi Ml,Cm,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor Ch,Ch,Mh   # [2]
+ vxor Cl,Cl,Ml     # [2]
+ vxor Cl,Cl,RP   # [1]
+
+ # reduction second phase
+ vpmsumd RP,Cl,poly_l
+ vxor Ch,Cl,Ch
+ vxor C,Ch,RP
+
+Ldone:
+IF_LE(&lt;vperm C,C,C,swap_mask&gt;)
+ stxvd2x CX,0,X # store C
+ blr
+EPILOGUE(_nettle_gcm_hash8)
+
+ # gcm_fill (uint8_t *ctr, size_t blocks, union gcm_block *buffer)
+
+PROLOGUE(_nettle_gcm_fill)
+IF_LE(&lt;ld 6,.swap_mask@got(TOCP)
+ lvx swap_mask,0,6&gt;)
+
+ vxor zero,zero,zero
+ vspltisb I1,1
+ vspltisb I2,2
+ vspltisb I3,3
+ vspltisb I4,4
+ vspltisb I5,5
+ vspltisb I6,6
+ vspltisb I7,7
+ vspltisb I8,8
+ vsldoi I1,zero,I1,1
+ vsldoi I2,zero,I2,1
+ vsldoi I3,zero,I3,1
+ vsldoi I4,zero,I4,1
+ vsldoi I5,zero,I5,1
+ vsldoi I6,zero,I6,1
+ vsldoi I7,zero,I7,1
+ vsldoi I8,zero,I8,1
+
+ lxvd2x CTR0X,0,CTR
+ IF_LE(&lt;vperm CTR0,CTR0,CTR0,swap_mask&gt;)
+
+ srdi 6,BLOCKS,3 # 8x loop count
+ cmpldi 6,0
+ beq Lfill_4x
+
+ std 25,-56(SP);
+ std 26,-48(SP);
+ std 27,-40(SP);
+ std 28,-32(SP);
+ std 29,-24(SP);
+ std 30,-16(SP);
+ std 31,-8(SP);
+
+ li 25,0x10
+ li 26,0x20
+ li 27,0x30
+ li 28,0x40
+ li 29,0x50
+ li 30,0x60
+ li 31,0x70
+
+ mtctr 6
+ L8x_fill_loop:
+ vadduwm CTR1,CTR0,I1
+ vadduwm CTR2,CTR0,I2
+ vadduwm CTR3,CTR0,I3
+ vadduwm CTR4,CTR0,I4
+ vadduwm CTR5,CTR0,I5
+ vadduwm CTR6,CTR0,I6
+ vadduwm CTR7,CTR0,I7
+
+ IF_LE(&lt;vperm CTR0S,CTR0,CTR0,swap_mask
+ vperm CTR1,CTR1,CTR1,swap_mask
+ vperm CTR2,CTR2,CTR2,swap_mask
+ vperm CTR3,CTR3,CTR3,swap_mask
+ vperm CTR4,CTR4,CTR4,swap_mask
+ vperm CTR5,CTR5,CTR5,swap_mask
+ vperm CTR6,CTR6,CTR6,swap_mask
+ vperm CTR7,CTR7,CTR7,swap_mask&gt;)
+
+ IF_LE(&lt;stxvd2x CTR0SX,0,BUFFER&gt;)
+ IF_BE(&lt;stxvd2x CTR0X,0,BUFFER&gt;)
+ stxvd2x CTR1X,25,BUFFER
+ stxvd2x CTR2X,26,BUFFER
+ stxvd2x CTR3X,27,BUFFER
+ stxvd2x CTR4X,28,BUFFER
+ stxvd2x CTR5X,29,BUFFER
+ stxvd2x CTR6X,30,BUFFER
+ stxvd2x CTR7X,31,BUFFER
+
+ vadduwm CTR0,CTR0,I8
+ addi BUFFER,BUFFER,0x80
+ bdnz L8x_fill_loop
+
+ ld 25,-56(SP);
+ ld 26,-48(SP);
+ ld 27,-40(SP);
+ ld 28,-32(SP);
+ ld 29,-24(SP);
+ ld 30,-16(SP);
+ ld 31,-8(SP);
+
+ clrldi BLOCKS,BLOCKS,61
+
+ Lfill_4x:
+ srdi 6,BLOCKS,2
+ cmpldi 6,0
+ beq Lfill_2x
+
+ li 8,0x10
+ li 9,0x20
+ li 10,0x30
+
+ vadduwm CTR1,CTR0,I1
+ vadduwm CTR2,CTR0,I2
+ vadduwm CTR3,CTR0,I3
+
+ IF_LE(&lt;vperm CTR0S,CTR0,CTR0,swap_mask
+ vperm CTR1,CTR1,CTR1,swap_mask
+ vperm CTR2,CTR2,CTR2,swap_mask
+ vperm CTR3,CTR3,CTR3,swap_mask&gt;)
+
+ IF_LE(&lt;stxvd2x CTR0SX,0,BUFFER&gt;)
+ IF_BE(&lt;stxvd2x CTR0X,0,BUFFER&gt;)
+ stxvd2x CTR1X,8,BUFFER
+ stxvd2x CTR2X,9,BUFFER
+ stxvd2x CTR3X,10,BUFFER
+
+ vadduwm CTR0,CTR0,I4
+ addi BUFFER,BUFFER,0x40
+
+ clrldi BLOCKS,BLOCKS,62
+
+ Lfill_2x:
+ srdi 6,BLOCKS,1
+ cmpldi 6,0
+ beq Lfill_1x
+
+ li 10,0x10
+
+ vadduwm CTR1,CTR0,I1
+
+ IF_LE(&lt;vperm CTR0S,CTR0,CTR0,swap_mask
+ vperm CTR1,CTR1,CTR1,swap_mask&gt;)
+
+ IF_LE(&lt;stxvd2x CTR0SX,0,BUFFER&gt;)
+ IF_BE(&lt;stxvd2x CTR0X,0,BUFFER&gt;)
+ stxvd2x CTR1X,10,BUFFER
+
+ vadduwm CTR0,CTR0,I2
+ addi BUFFER,BUFFER,0x20
+
+ clrldi BLOCKS,BLOCKS,63
+
+ Lfill_1x:
+ cmpldi BLOCKS,0
+ beq Lfill_done
+
+ IF_LE(&lt;vperm CTR0S,CTR0,CTR0,swap_mask&gt;)
+
+ IF_LE(&lt;stxvd2x CTR0SX,0,BUFFER&gt;)
+ IF_BE(&lt;stxvd2x CTR0X,0,BUFFER&gt;)
+
+ vadduwm CTR0,CTR0,I1
+
+ Lfill_done:
+ IF_LE(&lt;vperm CTR0,CTR0,CTR0,swap_mask&gt;)
+ stxvd2x CTR0X,0,CTR
+
+ blr
+EPILOGUE(_nettle_gcm_fill)
+
+    .data
+IF_LE(&lt;.align 4
+.polynomial:
+ .byte 1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0xc2
+    .align 4
+.swap_mask:
+ .byte 8,9,10,11,12,13,14,15,0,1,2,3,4,5,6,7
+    .align 4
+.hidw_mask:
+ .byte 23,22,21,20,19,18,17,16,7,6,5,4,3,2,1,0
+    .align 4
+.lodw_mask:
+ .byte 31,30,29,28,27,26,25,24,15,14,13,12,11,10,9,8&gt;)
+IF_BE(&lt;.align 4
+.polynomial:
+ .byte 0xc2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
+    .align 4
+.hidw_mask:
+ .byte 0,1,2,3,4,5,6,7,16,17,18,19,20,21,22,23
+    .align 4
+.lodw_mask:
+ .byte 8,9,10,11,12,13,14,15,24,25,26,27,28,29,30,31&gt;)
-- 
2.17.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200709144451</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-07-09 14:44:51-0400</timestampReceived><subject>Re: [PATCH] Add missing undef directives in configure.ac"</subject><body>

Applied.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200709144516</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-07-09 14:45:16-0400</timestampReceived><subject>Re: [PATCH 3/4] Add test 128 bytes to gcm-test</subject><body>

Applied.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200714113614</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-07-14 11:36:14-0400</timestampReceived><subject>[PATCH 1/6] "PowerPC64" Add machine.m4</subject><body>

---
 powerpc64/machine.m4 | 32 ++++++++++++++++++++++++++++++++
 1 file changed, 32 insertions(+)
 create mode 100644 powerpc64/machine.m4

diff --git a/powerpc64/machine.m4 b/powerpc64/machine.m4
new file mode 100644
index 00000000..3a121260
--- /dev/null
+++ b/powerpc64/machine.m4
@@ -0,0 +1,32 @@
+define(&lt;PROLOGUE&gt;,
+&lt;.globl C_NAME($1)
+DECLARE_FUNC(C_NAME($1))
+ifelse(WORDS_BIGENDIAN,no,
+&lt;ifdef(&lt;FUNC_ALIGN&gt;,&lt;.align FUNC_ALIGN&gt;)
+C_NAME($1):
+addis 2,12,(.TOC.-C_NAME($1))@ha
+addi 2,2,(.TOC.-C_NAME($1))@l
+.localentry C_NAME($1), .-C_NAME($1)&gt;,
+&lt;.section ".opd","aw"
+.align 3
+C_NAME($1):
+.quad .C_NAME($1),.TOC.@tocbase,0
+.previous
+ifdef(&lt;FUNC_ALIGN&gt;,&lt;.align FUNC_ALIGN&gt;)
+.C_NAME($1):&gt;)
+undefine(&lt;FUNC_ALIGN&gt;)&gt;)
+
+define(&lt;EPILOGUE&gt;,
+&lt;ifelse(WORDS_BIGENDIAN,no,
+&lt;.size C_NAME($1), . - C_NAME($1)&gt;,
+&lt;.size .C_NAME($1), . - .C_NAME($1)
+.size C_NAME($1), . - .C_NAME($1)&gt;)&gt;)
+
+C Load the quadword in DATA_SRC storage into
+C VEC_DST. GPR is general-purpose register
+C used to obtain the effective address of
+C DATA_SRC storage.
+C DATA_LOAD_VEC(VEC_DST, DATA_SRC, GPR)
+define(&lt;DATA_LOAD_VEC&gt;,
+&lt;ld $3,$2@got(2)
+lvx $1,0,$3&gt;)
-- 
2.17.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200714114344</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-07-14 11:43:44-0400</timestampReceived><subject>[PATCH 3/6] "PowerPC64" Add optimized GHASH</subject><body>

---
 gcm.c                     |  82 +++-
 powerpc64/P8/gcm-hash.asm | 998
++++++++++++++++++++++++++++++++++++++++++++++
 2 files changed, 1066 insertions(+), 14 deletions(-)
 create mode 100644 powerpc64/P8/gcm-hash.asm

diff --git a/gcm.c b/gcm.c
index cf615daf..935d4420 100644
--- a/gcm.c
+++ b/gcm.c
@@ -140,6 +140,26 @@ gcm_gf_mul (union nettle_block16 *x, const union
nettle_block16 *table)
   memcpy (x-&gt;b, Z.b, sizeof(Z));
 }
 # elif GCM_TABLE_BITS == 8
+#  if HAVE_NATIVE_gcm_init_key
+
+#define gcm_init_key _nettle_gcm_init_key
+void
+_nettle_gcm_init_key (union nettle_block16 *table);
+/* For fat builds */
+void
+_nettle_gcm_init_key_c (union nettle_block16 *table);
+#  endif /* HAVE_NATIVE_gcm_init_key */
+#  if HAVE_NATIVE_gcm_hash
+
+#define gcm_hash _nettle_gcm_hash
+void
+_nettle_gcm_hash (const struct gcm_key *key, union nettle_block16 *x,
+   size_t length, const uint8_t *data);
+/* For fat builds */
+void
+_nettle_gcm_hash_c (const struct gcm_key *key, union nettle_block16 *x,
+   size_t length, const uint8_t *data);
+#  endif /* HAVE_NATIVE_gcm_hash */
 #  if HAVE_NATIVE_gcm_hash8

 #define gcm_hash _nettle_gcm_hash8
@@ -225,9 +245,45 @@ gcm_gf_mul (union nettle_block16 *x, const union
nettle_block16 *table)

 #endif /* GCM_TABLE_BITS */

+#if HAVE_NATIVE_gcm_fill
+
+#define gcm_fill _nettle_gcm_fill
+void
+_nettle_gcm_fill (uint8_t *ctr, size_t blocks, union nettle_block16
*buffer);
+/* For fat builds */
+void
+_nettle_gcm_fill_c (uint8_t *ctr, size_t blocks, union nettle_block16
*buffer);
+#endif /* HAVE_NATIVE_gcm_fill */
+
 /* Increment the rightmost 32 bits. */
 #define INC32(block) INCREMENT(4, (block.b) + GCM_BLOCK_SIZE - 4)

+#ifdef gcm_init_key
+void
+_nettle_gcm_init_key_c(union nettle_block16 *table)
+#else
+static void
+gcm_init_key(union nettle_block16 *table)
+#endif /* !gcm_init_key */
+{
+#if GCM_TABLE_BITS
+  /* Middle element if GCM_TABLE_BITS &gt; 0, otherwise the first
+     element */
+  unsigned i = (1&lt;&lt;GCM_TABLE_BITS)/2;
+
+  /* Algorithm 3 from the gcm paper. First do powers of two, then do
+     the rest by adding. */
+  while (i /= 2)
+    block16_mulx_ghash(&amp;table[i], &amp;table[2*i]);
+  for (i = 2; i &lt; 1&lt;&lt;GCM_TABLE_BITS; i *= 2)
+    {
+      unsigned j;
+      for (j = 1; j &lt; i; j++)
+ block16_xor3(&amp;table[i+j], &amp;table[i], &amp;table[j]);
+    }
+#endif
+}
+
 /* Initialization of GCM.
  * @ctx: The context of GCM
  * @cipher: The context of the underlying block cipher
@@ -245,24 +301,18 @@ gcm_set_key(struct gcm_key *key,
   memset(key-&gt;h[0].b, 0, GCM_BLOCK_SIZE);
   f (cipher, GCM_BLOCK_SIZE, key-&gt;h[i].b, key-&gt;h[0].b);

-#if GCM_TABLE_BITS
-  /* Algorithm 3 from the gcm paper. First do powers of two, then do
-     the rest by adding. */
-  while (i /= 2)
-    block16_mulx_ghash(&amp;key-&gt;h[i], &amp;key-&gt;h[2*i]);
-  for (i = 2; i &lt; 1&lt;&lt;GCM_TABLE_BITS; i *= 2)
-    {
-      unsigned j;
-      for (j = 1; j &lt; i; j++)
- block16_xor3(&amp;key-&gt;h[i+j], &amp;key-&gt;h[i],&amp;key-&gt;h[j]);
-    }
-#endif
+  gcm_init_key(key-&gt;h);
 }

-#ifndef gcm_hash
+#ifdef gcm_hash
+void
+_nettle_gcm_hash_c(const struct gcm_key *key, union nettle_block16 *x,
+ size_t length, const uint8_t *data)
+#else
 static void
 gcm_hash(const struct gcm_key *key, union nettle_block16 *x,
  size_t length, const uint8_t *data)
+#endif /* !gcm_hash */
 {
   for (; length &gt;= GCM_BLOCK_SIZE;
        length -= GCM_BLOCK_SIZE, data += GCM_BLOCK_SIZE)
@@ -276,7 +326,6 @@ gcm_hash(const struct gcm_key *key, union
nettle_block16 *x,
       gcm_gf_mul (x, key-&gt;h);
     }
 }
-#endif /* !gcm_hash */

 static void
 gcm_hash_sizes(const struct gcm_key *key, union nettle_block16 *x,
@@ -333,9 +382,14 @@ gcm_update(struct gcm_ctx *ctx, const struct gcm_key
*key,
   ctx-&gt;auth_size += length;
 }

+#ifdef gcm_fill
+void
+_nettle_gcm_fill_c(uint8_t *ctr, size_t blocks, union nettle_block16
*buffer)
+#else
 static nettle_fill16_func gcm_fill;
 static void
 gcm_fill(uint8_t *ctr, size_t blocks, union nettle_block16 *buffer)
+#endif /* !gcm_fill */
 {
   uint32_t c;

diff --git a/powerpc64/P8/gcm-hash.asm b/powerpc64/P8/gcm-hash.asm
new file mode 100644
index 00000000..b8f2178e
--- /dev/null
+++ b/powerpc64/P8/gcm-hash.asm
@@ -0,0 +1,998 @@
+C powerpc64/P8/gcm-hash.asm
+
+ifelse(&lt;
+   Copyright (C) 2020 Mamone Tarsha
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+&gt;)
+
+C Alignment of gcm_key table elements, which is declared in gcm.h
+define(&lt;TableElemAlign&gt;, &lt;0x100&gt;)
+
+C Register usage:
+
+define(&lt;SP&gt;, &lt;1&gt;)
+define(&lt;TOCP&gt;, &lt;2&gt;)
+
+define(&lt;TABLE&gt;, &lt;3&gt;)
+define(&lt;X&gt;, &lt;4&gt;)
+define(&lt;LENGTH&gt;, &lt;5&gt;)
+define(&lt;DATA&gt;, &lt;6&gt;)
+
+define(&lt;zero&gt;, &lt;0&gt;)
+define(&lt;swap_mask&gt;, &lt;1&gt;)
+define(&lt;hidw_mask&gt;, &lt;2&gt;)
+define(&lt;lodw_mask&gt;, &lt;3&gt;)
+define(&lt;poly&gt;, &lt;4&gt;)
+define(&lt;poly_h&gt;, &lt;4&gt;)
+define(&lt;poly_l&gt;, &lt;5&gt;)
+define(&lt;RP&gt;, &lt;6&gt;)
+define(&lt;Mh&gt;, &lt;7&gt;)
+define(&lt;Ml&gt;, &lt;8&gt;)
+define(&lt;H&gt;, &lt;9&gt;)
+define(&lt;Hh&gt;, &lt;10&gt;)
+define(&lt;Hl&gt;, &lt;11&gt;)
+define(&lt;RP2&gt;, &lt;9&gt;)
+define(&lt;M2h&gt;, &lt;10&gt;)
+define(&lt;M2l&gt;, &lt;11&gt;)
+
+define(&lt;HX&gt;, &lt;41&gt;)
+define(&lt;HhX&gt;, &lt;42&gt;)
+define(&lt;HlX&gt;, &lt;43&gt;)
+define(&lt;H_HhX&gt;, &lt;44&gt;)
+define(&lt;H_HX&gt;, &lt;45&gt;)
+define(&lt;H_HlX&gt;, &lt;46&gt;)
+
+define(&lt;sl1&gt;, &lt;1&gt;)
+define(&lt;msb&gt;, &lt;5&gt;)
+define(&lt;H2&gt;, &lt;6&gt;)
+define(&lt;H2h&gt;, &lt;7&gt;)
+define(&lt;H2l&gt;, &lt;8&gt;)
+define(&lt;H_h&gt;, &lt;12&gt;)
+define(&lt;H_m&gt;, &lt;13&gt;)
+define(&lt;H_l&gt;, &lt;14&gt;)
+define(&lt;H_Hh&gt;, &lt;12&gt;)
+define(&lt;H_H&gt;, &lt;13&gt;)
+define(&lt;H_Hl&gt;, &lt;14&gt;)
+define(&lt;H_t&gt;, &lt;15&gt;)
+define(&lt;H2_h&gt;, &lt;16&gt;)
+define(&lt;H2_m&gt;, &lt;17&gt;)
+define(&lt;H2_l&gt;, &lt;18&gt;)
+define(&lt;H2_t&gt;, &lt;19&gt;)
+
+define(&lt;C0X&gt;, &lt;38&gt;)
+define(&lt;C1X&gt;, &lt;39&gt;)
+define(&lt;C2X&gt;, &lt;40&gt;)
+define(&lt;C3X&gt;, &lt;44&gt;)
+define(&lt;C4X&gt;, &lt;38&gt;)
+define(&lt;C5X&gt;, &lt;39&gt;)
+define(&lt;C6X&gt;, &lt;40&gt;)
+define(&lt;C7X&gt;, &lt;44&gt;)
+
+define(&lt;CX&gt;, &lt;45&gt;)
+
+define(&lt;C0&gt;, &lt;6&gt;)
+define(&lt;C1&gt;, &lt;7&gt;)
+define(&lt;C2&gt;, &lt;8&gt;)
+define(&lt;C3&gt;, &lt;12&gt;)
+define(&lt;C4&gt;, &lt;6&gt;)
+define(&lt;C5&gt;, &lt;7&gt;)
+define(&lt;C6&gt;, &lt;8&gt;)
+define(&lt;C7&gt;, &lt;12&gt;)
+
+define(&lt;C&gt;, &lt;13&gt;)
+
+define(&lt;Ch&gt;, &lt;14&gt;)
+define(&lt;Cl&gt;, &lt;15&gt;)
+define(&lt;Cm&gt;, &lt;16&gt;)
+
+define(&lt;C01h&gt;, &lt;14&gt;)
+define(&lt;C01l&gt;, &lt;15&gt;)
+define(&lt;C01&gt;, &lt;16&gt;)
+define(&lt;C23h&gt;, &lt;17&gt;)
+define(&lt;C23l&gt;, &lt;18&gt;)
+define(&lt;C23&gt;, &lt;19&gt;)
+define(&lt;C45h&gt;, &lt;20&gt;)
+define(&lt;C45l&gt;, &lt;21&gt;)
+define(&lt;C45&gt;, &lt;22&gt;)
+define(&lt;C67h&gt;, &lt;6&gt;)
+define(&lt;C67l&gt;, &lt;7&gt;)
+define(&lt;C67&gt;, &lt;8&gt;)
+
+define(&lt;H21&gt;, &lt;9&gt;)
+define(&lt;H21h&gt;, &lt;10&gt;)
+define(&lt;H21l&gt;, &lt;11&gt;)
+define(&lt;H43&gt;, &lt;23&gt;)
+define(&lt;H43h&gt;, &lt;24&gt;)
+define(&lt;H43l&gt;, &lt;25&gt;)
+define(&lt;H65&gt;, &lt;26&gt;)
+define(&lt;H65h&gt;, &lt;27&gt;)
+define(&lt;H65l&gt;, &lt;28&gt;)
+define(&lt;H87&gt;, &lt;29&gt;)
+define(&lt;H87h&gt;, &lt;30&gt;)
+define(&lt;H87l&gt;, &lt;31&gt;)
+
+define(&lt;H21X&gt;, &lt;41&gt;)
+define(&lt;H21hX&gt;, &lt;42&gt;)
+define(&lt;H21lX&gt;, &lt;43&gt;)
+define(&lt;H43X&gt;, &lt;55&gt;)
+define(&lt;H43hX&gt;, &lt;56&gt;)
+define(&lt;H43lX&gt;, &lt;57&gt;)
+define(&lt;H65X&gt;, &lt;58&gt;)
+define(&lt;H65hX&gt;, &lt;59&gt;)
+define(&lt;H65lX&gt;, &lt;60&gt;)
+define(&lt;H87X&gt;, &lt;61&gt;)
+define(&lt;H87hX&gt;, &lt;62&gt;)
+define(&lt;H87lX&gt;, &lt;63&gt;)
+
+# gcm_fill registers:
+
+define(&lt;CTR&gt;, &lt;3&gt;)
+define(&lt;BLOCKS&gt;, &lt;4&gt;)
+define(&lt;BUFFER&gt;, &lt;5&gt;)
+
+define(&lt;CTR0&gt;, &lt;2&gt;)
+define(&lt;CTR0S&gt;, &lt;3&gt;)
+define(&lt;CTR1&gt;, &lt;4&gt;)
+define(&lt;CTR2&gt;, &lt;5&gt;)
+define(&lt;CTR3&gt;, &lt;6&gt;)
+define(&lt;CTR4&gt;, &lt;7&gt;)
+define(&lt;CTR5&gt;, &lt;8&gt;)
+define(&lt;CTR6&gt;, &lt;9&gt;)
+define(&lt;CTR7&gt;, &lt;10&gt;)
+
+define(&lt;CTR0X&gt;, &lt;34&gt;)
+define(&lt;CTR0SX&gt;, &lt;35&gt;)
+define(&lt;CTR1X&gt;, &lt;36&gt;)
+define(&lt;CTR2X&gt;, &lt;37&gt;)
+define(&lt;CTR3X&gt;, &lt;38&gt;)
+define(&lt;CTR4X&gt;, &lt;39&gt;)
+define(&lt;CTR5X&gt;, &lt;40&gt;)
+define(&lt;CTR6X&gt;, &lt;41&gt;)
+define(&lt;CTR7X&gt;, &lt;42&gt;)
+
+define(&lt;I1&gt;, &lt;11&gt;)
+define(&lt;I2&gt;, &lt;12&gt;)
+define(&lt;I3&gt;, &lt;13&gt;)
+define(&lt;I4&gt;, &lt;14&gt;)
+define(&lt;I5&gt;, &lt;15&gt;)
+define(&lt;I6&gt;, &lt;16&gt;)
+define(&lt;I7&gt;, &lt;17&gt;)
+define(&lt;I8&gt;, &lt;18&gt;)
+
+.file "gcm-hash.asm"
+
+IF_LE(&lt;.abiversion 2&gt;)
+.text
+
+ # void gcm_init_key (union gcm_block *table)
+
+define(&lt;FUNC_ALIGN&gt;, &lt;5&gt;)
+PROLOGUE(_nettle_gcm_init_key)
+ DATA_LOAD_VEC(poly,.polynomial,7)
+IF_LE(&lt;DATA_LOAD_VEC(swap_mask,.swap_mask,7)&gt;)
+ DATA_LOAD_VEC(hidw_mask,.hidw_mask,7)
+ DATA_LOAD_VEC(lodw_mask,.lodw_mask,7)
+
+ li    10,8*TableElemAlign
+  lxvd2x HX,10,TABLE # load H
+IF_LE(&lt;vperm H,H,H,swap_mask&gt;)
+
+ # --- calculate H = H shift left 1 modulo polynomial ---
+
+ vupkhsw    msb,H # most significant bit word-extend
+ vspltisb sl1,1 # splat 1 for shift left
+ vspltw      msb,msb,0 # most significant bit extend
+ vsl    H,H,sl1 # H shift left 1
+ vand msb,msb,poly
+ vxor zero,zero,zero
+ vxor H_t,H,msb
+
+ vsldoi H,H_t,H_t,8 # doubleword swap
+ vsldoi Hh,H,zero,8
+ vsldoi Hl,zero,H,8
+
+ # --- calculate H^2 = H*H ---
+
+ # reduction pre-processing
+ vsldoi poly_h,zero,poly,8
+ vsldoi poly_l,poly_h,poly_h,8
+
+ # polynomial multiplication "classical"
+ vpmsumd H_h,H_t,Hh # H^1h*H^1h
+ vpmsumd H_l,H_t,Hl # H^1l*H^1l
+ vpmsumd H_m,H_t,H # H^1h*H^1l⊕H^1l*H^1h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h   # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8   # [2]
+ vsldoi Ml,H_m,zero,8 # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor H_h,H_h,Mh       # [2]
+ vxor H_l,H_l,Ml       # [2]
+ vxor H_l,H_l,RP       # [1]
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l
+ vxor H_h,H_l,H_h
+ vxor H2_t,H_h,RP
+
+ vsldoi H2,H2_t,H2_t,8
+ vsldoi H2h,H2,zero,8
+ vsldoi H2l,zero,H2,8
+
+ # --- calculate [H^2.Hi⊕H^2.Lo:H^1.Hi⊕H^1.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store H,[H^2.Hi⊕H^2.Lo:H^1.Hi⊕H^1.Lo] ---
+
+ li    8,0*TableElemAlign
+ li    9,1*TableElemAlign
+ li    10,2*TableElemAlign
+ stxvd2x HlX,8,TABLE
+ stxvd2x HX,9,TABLE
+ stxvd2x HhX,10,TABLE
+
+ li    8,3*TableElemAlign
+ li    9,4*TableElemAlign
+ li    10,5*TableElemAlign
+ stxvd2x H_HhX,8,TABLE
+ stxvd2x H_HX,9,TABLE
+ stxvd2x H_HlX,10,TABLE
+
+ # --- calculate H^3,H^4 ---
+
+ # polynomial multiplication "classical"
+ vpmsumd H_l,H_t,H2l # H^1l*H^2l
+ vpmsumd H_m,H_t,H2 # H^1h*H^2l⊕H^1l*H^2h
+ vpmsumd H_h,H_t,H2h # H^1h*H^2h
+ vpmsumd H2_l,H2_t,H2l # H^2l*H^2l
+ vpmsumd H2_m,H2_t,H2 # H^2h*H^2l⊕H^2l*H^2h
+ vpmsumd H2_h,H2_t,H2h # H^2h*H^2h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h # [1] H^3
+ vpmsumd    RP2,H2_l,poly_h # [1] H^4
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8 # [2] H^3
+ vsldoi M2h,zero,H2_m,8 # [2] H^4
+ vsldoi Ml,H_m,zero,8 # [2] H^3
+ vsldoi M2l,H2_m,zero,8 # [2] H^4
+ vsldoi RP,RP,RP,8 # [1] H^3
+ vsldoi RP2,RP2,RP2,8 # [1] H^4
+ vxor H_h,H_h,Mh # [2] H^3
+ vxor H2_h,H2_h,M2h # [2] H^4
+ vxor H_l,H_l,Ml # [2] H^3
+ vxor H2_l,H2_l,M2l # [2] H^4
+ vxor H_l,H_l,RP # [1] H^3
+ vxor H2_l,H2_l,RP2 # [1] H^4
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l # H^3
+ vpmsumd RP2,H2_l,poly_l # H^4
+ vxor H_h,H_l,H_h # H^3
+ vxor H2_h,H2_l,H2_h # H^4
+ vxor H_h,H_h,RP # H^3
+ vxor H2_h,H2_h,RP2 # H^4
+
+ vsldoi H2,H2_h,H2_h,8 # H^4
+ vsldoi H,H_h,H_h,8 # H^3
+ vsldoi H2l,zero,H2,8 # H^4
+ vsldoi H2h,H2,zero,8 # H^4
+
+ # --- calculate [H^4.Hi⊕H^4.Lo:H^3.Hi⊕H^3.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store [H^4.Hi⊕H^4.Lo:H^3.Hi⊕H^3.Lo] ---
+
+ li    8,6*TableElemAlign
+ li    9,7*TableElemAlign
+ li    10,8*TableElemAlign
+ stxvd2x H_HhX,8,TABLE
+ stxvd2x H_HX,9,TABLE
+ stxvd2x H_HlX,10,TABLE
+
+ # --- calculate H^5,H^6 ---
+
+ # polynomial multiplication "classical"
+ vpmsumd H_l,H_t,H2l # H^1l*H^4l
+ vpmsumd H_m,H_t,H2 # H^1h*H^4l⊕H^1l*H^4h
+ vpmsumd H_h,H_t,H2h # H^1h*H^4h
+ vpmsumd H2_l,H2_t,H2l # H^2l*H^4l
+ vpmsumd H2_m,H2_t,H2 # H^2h*H^4l⊕H^2l*H^4h
+ vpmsumd H2_h,H2_t,H2h # H^2h*H^4h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h # [1] H^5
+ vpmsumd    RP2,H2_l,poly_h # [1] H^6
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8 # [2] H^5
+ vsldoi M2h,zero,H2_m,8 # [2] H^6
+ vsldoi Ml,H_m,zero,8 # [2] H^5
+ vsldoi M2l,H2_m,zero,8 # [2] H^6
+ vsldoi RP,RP,RP,8 # [1] H^5
+ vsldoi RP2,RP2,RP2,8 # [1] H^6
+ vxor H_h,H_h,Mh # [2] H^5
+ vxor H2_h,H2_h,M2h # [2] H^6
+ vxor H_l,H_l,Ml # [2] H^5
+ vxor H2_l,H2_l,M2l # [2] H^6
+ vxor H_l,H_l,RP # [1] H^5
+ vxor H2_l,H2_l,RP2 # [1] H^6
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l # H^5
+ vpmsumd RP2,H2_l,poly_l # H^6
+ vxor H_h,H_l,H_h # H^5
+ vxor H2_h,H2_l,H2_h # H^6
+ vxor H_h,H_h,RP # H^5
+ vxor H2_h,H2_h,RP2 # H^6
+
+ vsldoi H2,H2_h,H2_h,8 # H^6
+ vsldoi H,H_h,H_h,8 # H^5
+ vsldoi H2l,zero,H2,8 # H^6
+ vsldoi H2h,H2,zero,8 # H^6
+
+ # --- calculate [H^6.Hi⊕H^6.Lo:H^5.Hi⊕H^5.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store [H^6.Hi⊕H^6.Lo:H^5.Hi⊕H^5.Lo] ---
+
+ li    8,9*TableElemAlign
+ li    9,10*TableElemAlign
+ li    10,11*TableElemAlign
+ stxvd2x H_HhX,8,TABLE
+ stxvd2x H_HX,9,TABLE
+ stxvd2x H_HlX,10,TABLE
+
+ # --- calculate H^7,H^8 ---
+
+ # polynomial multiplication "classical"
+ vpmsumd H_l,H_t,H2l # H^1l*H^6l
+ vpmsumd H_m,H_t,H2 # H^1h*H^6l⊕H^1l*H^6h
+ vpmsumd H_h,H_t,H2h # H^1h*H^6h
+ vpmsumd H2_l,H2_t,H2l # H^2l*H^6l
+ vpmsumd H2_m,H2_t,H2 # H^2h*H^6l⊕H^2l*H^6h
+ vpmsumd H2_h,H2_t,H2h # H^2h*H^6h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h # [1] H^7
+ vpmsumd    RP2,H2_l,poly_h # [1] H^8
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8 # [2] H^7
+ vsldoi M2h,zero,H2_m,8 # [2] H^8
+ vsldoi Ml,H_m,zero,8 # [2] H^7
+ vsldoi M2l,H2_m,zero,8 # [2] H^8
+ vsldoi RP,RP,RP,8 # [1] H^7
+ vsldoi RP2,RP2,RP2,8 # [1] H^8
+ vxor H_h,H_h,Mh # [2] H^7
+ vxor H2_h,H2_h,M2h # [2] H^8
+ vxor H_l,H_l,Ml # [2] H^7
+ vxor H2_l,H2_l,M2l # [2] H^8
+ vxor H_l,H_l,RP # [1] H^7
+ vxor H2_l,H2_l,RP2 # [1] H^8
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l # H^7
+ vpmsumd RP2,H2_l,poly_l # H^8
+ vxor H_h,H_l,H_h # H^7
+ vxor H2_h,H2_l,H2_h # H^8
+ vxor H_h,H_h,RP # H^7
+ vxor H2_h,H2_h,RP2 # H^8
+
+ vsldoi H,H_h,H_h,8 # H^7
+ vsldoi H2,H2_h,H2_h,8 # H^8
+
+ # --- calculate [H^8.Hi⊕H^8.Lo:H^7.Hi⊕H^7.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store [H^8.Hi⊕H^8.Lo:H^7.Hi⊕H^7.Lo] ---
+
+ li    8,12*TableElemAlign
+ li    9,13*TableElemAlign
+ li    10,14*TableElemAlign
+ stxvd2x H_HhX,8,TABLE
+ stxvd2x H_HX,9,TABLE
+ stxvd2x H_HlX,10,TABLE
+
+  blr
+EPILOGUE(_nettle_gcm_init_key)
+
+ # void gcm_hash (const struct gcm_key *key, union gcm_block *x,
+ #                size_t length, const uint8_t *data)
+
+define(&lt;FUNC_ALIGN&gt;, &lt;5&gt;)
+PROLOGUE(_nettle_gcm_hash)
+ vxor zero,zero,zero
+
+ DATA_LOAD_VEC(poly,.polynomial,7)
+IF_LE(&lt;DATA_LOAD_VEC(swap_mask,.swap_mask,7)&gt;)
+ DATA_LOAD_VEC(hidw_mask,.hidw_mask,7)
+ DATA_LOAD_VEC(lodw_mask,.lodw_mask,7)
+
+ vsldoi poly_h,zero,poly,8
+ vsldoi poly_l,poly_h,poly_h,8
+
+ lxvd2x CX,0,X # load X
+IF_LE(&lt;vperm C,C,C,swap_mask&gt;)
+
+ srdi 7,LENGTH,7 # 8x loop count
+ cmpldi 7,0
+ beq L2x
+
+ # backup registers
+ stdu SP,-224(SP)
+ std 28,216(SP)
+ std 29,208(SP)
+ std 30,200(SP)
+ std 31,192(SP)
+    li 8,176
+    stvx 20,8,SP
+    subi 8,8,16
+    stvx 21,8,SP
+    subi 8,8,16
+    stvx 22,8,SP
+    subi 8,8,16
+    stvx 23,8,SP
+    subi 8,8,16
+    stvx 24,8,SP
+    subi 8,8,16
+    stvx 25,8,SP
+    subi 8,8,16
+    stvx 26,8,SP
+    subi 8,8,16
+    stvx 27,8,SP
+    subi 8,8,16
+    stvx 28,8,SP
+    subi 8,8,16
+    stvx 29,8,SP
+    subi 8,8,16
+    stvx 30,8,SP
+    subi 8,8,16
+    stvx 31,8,SP
+
+ # table loading
+ li 8,3*TableElemAlign
+ li 9,4*TableElemAlign
+ li 10,5*TableElemAlign
+ lxvd2x H21hX,8,TABLE
+ lxvd2x H21X,9,TABLE
+ lxvd2x H21lX,10,TABLE
+ li 8,6*TableElemAlign
+ li 9,7*TableElemAlign
+ li 10,8*TableElemAlign
+ lxvd2x H43hX,8,TABLE
+ lxvd2x H43X,9,TABLE
+ lxvd2x H43lX,10,TABLE
+ li 8,9*TableElemAlign
+ li 9,10*TableElemAlign
+ li 10,11*TableElemAlign
+ lxvd2x H65hX,8,TABLE
+ lxvd2x H65X,9,TABLE
+ lxvd2x H65lX,10,TABLE
+ li 8,12*TableElemAlign
+ li 9,13*TableElemAlign
+ li 10,14*TableElemAlign
+ lxvd2x H87hX,8,TABLE
+ lxvd2x H87X,9,TABLE
+ lxvd2x H87lX,10,TABLE
+
+ li 8,0x10
+ li 9,0x20
+ li 10,0x30
+ li 28,0x40
+ li 29,0x50
+ li 30,0x60
+ li 31,0x70
+
+ mtctr     7
+.align 5
+L8x_loop:
+ # input loading
+ lxvd2x C0X,0,DATA # load C0
+ lxvd2x C1X,8,DATA # load C1
+ lxvd2x C2X,9,DATA # load C2
+ lxvd2x C3X,10,DATA # load C3
+
+ # swap permuting
+IF_LE(&lt;vperm C0,C0,C0,swap_mask
+ vperm C1,C1,C1,swap_mask
+ vperm C2,C2,C2,swap_mask
+ vperm C3,C3,C3,swap_mask&gt;)
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ # polynomial multiplication "karatsuba" pre-processing
+ vperm C23h,C2,C3,hidw_mask
+ vperm C23l,C2,C3,lodw_mask
+ vperm C01h,C0,C1,hidw_mask
+ vperm C01l,C0,C1,lodw_mask
+
+ # input loading
+ lxvd2x C4X,28,DATA # load C4
+ lxvd2x C5X,29,DATA # load C5
+ lxvd2x C6X,30,DATA # load C6
+ lxvd2x C7X,31,DATA # load C7
+
+ # swap permuting
+IF_LE(&lt;vperm C4,C4,C4,swap_mask
+ vperm C5,C5,C5,swap_mask
+ vperm C6,C6,C6,swap_mask
+ vperm C7,C7,C7,swap_mask&gt;)
+
+ # polynomial multiplication "karatsuba" pre-processing
+ vperm C45h,C4,C5,hidw_mask
+ vperm C45l,C4,C5,lodw_mask
+ vperm C67h,C6,C7,hidw_mask
+ vperm C67l,C6,C7,lodw_mask
+ vxor C23,C23h,C23l
+ vxor C01,C01h,C01l
+ vxor C45,C45h,C45l
+ vxor C67,C67h,C67l
+
+ # polynomial multiplication "karatsuba"
+ vpmsumd C23h,C23h,H65h # H23 = H^6h*C2h⊕H^5h*C3h
+ vpmsumd C23l,C23l,H65l # L23 = H^6l*C2l⊕H^5l*C3l
+ vpmsumd C01h,C01h,H87h # H01 = H^8h*C0h⊕H^7h*C1h
+ vpmsumd C01l,C01l,H87l # L01 = H^8l*C0l⊕H^7l*C1l
+ vpmsumd C67h,C67h,H21h # H67 = H^2h*C6h⊕H^1h*C7h
+ vpmsumd C67l,C67l,H21l # L67 = H^2l*C6l⊕H^1l*C7l
+ vpmsumd C45h,C45h,H43h # H45 = H^4h*C4h⊕H^3h*C5h
+ vpmsumd C45l,C45l,H43l # L45 = H^4l*C4l⊕H^3l*C5l
+ vpmsumd C23,C23,H65 # M23 = (H^6h⊕H^5h)*(C2h⊕C3h)⊕(H^6l⊕H^5l)*(C2l⊕C3l)
+ vpmsumd C01,C01,H87 # M01 = (H^8h⊕H^7h)*(C0h⊕C1h)⊕(H^8l⊕H^7l)*(C0l⊕C1l)
+ vpmsumd C45,C45,H43 # M45 = (H^4h⊕H^3h)*(C4h⊕C5h)⊕(H^4l⊕H^3l)*(C4l⊕C5l)
+ vpmsumd C67,C67,H21 # M67 = (H^2h⊕H^1h)*(C6h⊕C7h)⊕(H^2l⊕H^1l)*(C6l⊕C7l)
+
+ # polynomial multiplication "karatsuba" post-processing
+ vxor C23,C23,C23h
+ vxor C01,C01,C01h
+ vxor C45,C45,C45h
+ vxor C67,C67,C67h
+ vxor C23,C23,C23l
+ vxor C01,C01,C01l
+ vxor C45,C45,C45l
+ vxor C67,C67,C67l
+
+ # deferred recombination of partial products
+ vxor C01h,C01h,C23h # H0 = H01⊕H23
+ vxor C45h,C45h,C67h # H1 = H45⊕H67
+ vxor C01l,C01l,C23l # L0 = L01⊕L23
+ vxor C45l,C45l,C67l # L1 = L45⊕L45
+ vxor C01,C01,C23 # M0 = M01⊕M23
+ vxor C45,C45,C67 # M1 = M45⊕M45
+ vxor C01h,C01h,C45h # H = H0⊕H1
+ vxor C01l,C01l,C45l # L = L0⊕L1
+ vxor C01,C01,C45 # M = M0⊕M1
+
+ # reduction first phase # [1]
+ vpmsumd RP,C01l,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,C01,8   # [2]
+ vsldoi Ml,C01,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor C01h,C01h,Mh     # [2]
+ vxor C01l,C01l,Ml     # [2]
+ vxor C01l,C01l,RP     # [1]
+
+ # reduction second phase
+ vpmsumd RP,C01l,poly_l
+ vxor C01h,C01l,C01h
+ vxor C,C01h,RP
+
+ addi DATA,DATA,0x80
+ bdnz L8x_loop
+
+    # restore registers
+ li 8,0
+    lvx 31,8,SP
+    addi 8,8,16
+    lvx 30,8,SP
+    addi 8,8,16
+    lvx 29,8,SP
+    addi 8,8,16
+    lvx 28,8,SP
+    addi 8,8,16
+    lvx 27,8,SP
+    addi 8,8,16
+    lvx 26,8,SP
+    addi 8,8,16
+    lvx 25,8,SP
+    addi 8,8,16
+    lvx 24,8,SP
+    addi 8,8,16
+    lvx 23,8,SP
+    addi 8,8,16
+    lvx 22,8,SP
+    addi 8,8,16
+    lvx 21,8,SP
+    addi 8,8,16
+    lvx 20,8,SP
+ ld 31,192(SP)
+ ld 30,200(SP)
+ ld 29,208(SP)
+ ld 28,216(SP)
+ addi SP,SP,224
+
+ clrldi   LENGTH,LENGTH,57
+L2x:
+ srdi 7,LENGTH,5
+ cmpldi 7,0
+ beq L1x
+
+ # table loading
+ li 8,3*TableElemAlign
+ li 9,4*TableElemAlign
+ li 10,5*TableElemAlign
+ lxvd2x H21hX,8,TABLE
+ lxvd2x H21X,9,TABLE
+ lxvd2x H21lX,10,TABLE
+
+ li 10,0x10
+
+ mtctr     7
+.align 5
+L2x_loop:
+ # input loading
+ lxvd2x C0X,0,DATA # load C0
+ lxvd2x C1X,10,DATA # load C1
+
+ # swap permuting
+IF_LE(&lt;vperm C0,C0,C0,swap_mask
+ vperm C1,C1,C1,swap_mask&gt;)
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ # polynomial multiplication "karatsuba" pre-processing
+ vperm C01h,C0,C1,hidw_mask
+ vperm C01l,C0,C1,lodw_mask
+ vxor C01,C01h,C01l
+
+ # polynomial multiplication "karatsuba"
+ vpmsumd C01h,C01h,H21h # H01 = H^2h*C0h⊕H^1h*C1h
+ vpmsumd C01l,C01l,H21l # L01 = H^2l*C0l⊕H^1l*C1l
+ vpmsumd C01,C01,H21 # M01 = (H^2h⊕H^1h)*(C0h⊕C1h)⊕(H^2l⊕H^1l)*(C0l⊕C1l)
+
+ # polynomial multiplication "karatsuba" post-processing
+ vxor C01,C01,C01h
+ vxor C01,C01,C01l
+
+ # reduction first phase # [1]
+ vpmsumd RP,C01l,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,C01,8   # [2]
+ vsldoi Ml,C01,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor C01h,C01h,Mh     # [2]
+ vxor C01l,C01l,Ml     # [2]
+ vxor C01l,C01l,RP     # [1]
+
+ # reduction second phase
+ vpmsumd RP,C01l,poly_l
+ vxor C01h,C01l,C01h
+ vxor C,C01h,RP
+
+ addi DATA,DATA,0x20
+ bdnz L2x_loop
+
+ clrldi   LENGTH,LENGTH,59
+L1x:
+ srdi 7,LENGTH,4
+ cmpldi 7,0
+ beq Lrem
+
+ # table loading
+ li 9,1*TableElemAlign
+ li 10,2*TableElemAlign
+ lxvd2x HlX,0,TABLE
+ lxvd2x HX, 9,TABLE
+ lxvd2x HhX,10,TABLE
+
+ # input loading
+ lxvd2x C0X,0,DATA # load C0
+
+ # swap permuting
+IF_LE(&lt;vperm C0,C0,C0,swap_mask&gt;)
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ vpmsumd Cl,C0,Hl # L = Hl*Cl
+ vpmsumd Cm,C0,H # M = Hh*Cl⊕Hl*Ch
+ vpmsumd Ch,C0,Hh # H = Hh*Ch
+
+ # reduction first phase # [1]
+ vpmsumd RP,Cl,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,Cm,8   # [2]
+ vsldoi Ml,Cm,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor Ch,Ch,Mh   # [2]
+ vxor Cl,Cl,Ml       # [2]
+ vxor Cl,Cl,RP   # [1]
+
+ # reduction second phase
+ vpmsumd RP,Cl,poly_l
+ vxor Ch,Cl,Ch
+ vxor C,Ch,RP
+
+ addi DATA,DATA,0x10
+ clrldi   LENGTH,LENGTH,60
+Lrem:
+ cmpldi LENGTH,0
+ beq Ldone
+
+ # table loading
+ li 9,1*TableElemAlign
+ li 10,2*TableElemAlign
+ lxvd2x HlX,0,TABLE
+ lxvd2x HX, 9,TABLE
+ lxvd2x HhX,10,TABLE
+
+ # input loading
+ stdu SP,-16(SP)
+ stvx zero,0,SP
+Lst_loop:
+ subic.      LENGTH,LENGTH,1
+ lbzx 7,LENGTH,DATA
+ stbx 7,LENGTH,SP
+ bne Lst_loop
+ lxvd2x   C0X,0,SP
+ addi SP,SP,16
+
+ # swap permuting
+IF_LE(&lt;vperm C0,C0,C0,swap_mask&gt;)
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ vpmsumd Cl,C0,Hl # L = Hl*Cl
+ vpmsumd Cm,C0,H # M = Hh*Cl⊕Hl*Ch
+ vpmsumd Ch,C0,Hh # H = Hh*Ch
+
+ # reduction first phase # [1]
+ vpmsumd RP,Cl,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,Cm,8   # [2]
+ vsldoi Ml,Cm,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor Ch,Ch,Mh   # [2]
+ vxor Cl,Cl,Ml     # [2]
+ vxor Cl,Cl,RP   # [1]
+
+ # reduction second phase
+ vpmsumd RP,Cl,poly_l
+ vxor Ch,Cl,Ch
+ vxor C,Ch,RP
+
+Ldone:
+IF_LE(&lt;vperm C,C,C,swap_mask&gt;)
+ stxvd2x CX,0,X # store C
+ blr
+EPILOGUE(_nettle_gcm_hash)
+
+ # gcm_fill (uint8_t *ctr, size_t blocks, union gcm_block *buffer)
+
+define(&lt;FUNC_ALIGN&gt;, &lt;5&gt;)
+PROLOGUE(_nettle_gcm_fill)
+IF_LE(&lt;DATA_LOAD_VEC(swap_mask,.swap_mask,6)&gt;)
+
+ vxor zero,zero,zero
+ vspltisb I1,1
+ vspltisb I2,2
+ vspltisb I3,3
+ vspltisb I4,4
+ vspltisb I5,5
+ vspltisb I6,6
+ vspltisb I7,7
+ vspltisb I8,8
+ vsldoi I1,zero,I1,1
+ vsldoi I2,zero,I2,1
+ vsldoi I3,zero,I3,1
+ vsldoi I4,zero,I4,1
+ vsldoi I5,zero,I5,1
+ vsldoi I6,zero,I6,1
+ vsldoi I7,zero,I7,1
+ vsldoi I8,zero,I8,1
+
+ lxvd2x CTR0X,0,CTR
+ IF_LE(&lt;vperm CTR0,CTR0,CTR0,swap_mask&gt;)
+
+ srdi 6,BLOCKS,3 # 8x loop count
+ cmpldi 6,0
+ beq Lfill_4x
+
+ std 25,-56(SP);
+ std 26,-48(SP);
+ std 27,-40(SP);
+ std 28,-32(SP);
+ std 29,-24(SP);
+ std 30,-16(SP);
+ std 31,-8(SP);
+
+ li 25,0x10
+ li 26,0x20
+ li 27,0x30
+ li 28,0x40
+ li 29,0x50
+ li 30,0x60
+ li 31,0x70
+
+ mtctr 6
+ L8x_fill_loop:
+ vadduwm CTR1,CTR0,I1
+ vadduwm CTR2,CTR0,I2
+ vadduwm CTR3,CTR0,I3
+ vadduwm CTR4,CTR0,I4
+ vadduwm CTR5,CTR0,I5
+ vadduwm CTR6,CTR0,I6
+ vadduwm CTR7,CTR0,I7
+
+ IF_LE(&lt;vperm CTR0S,CTR0,CTR0,swap_mask
+ vperm CTR1,CTR1,CTR1,swap_mask
+ vperm CTR2,CTR2,CTR2,swap_mask
+ vperm CTR3,CTR3,CTR3,swap_mask
+ vperm CTR4,CTR4,CTR4,swap_mask
+ vperm CTR5,CTR5,CTR5,swap_mask
+ vperm CTR6,CTR6,CTR6,swap_mask
+ vperm CTR7,CTR7,CTR7,swap_mask&gt;)
+
+ IF_LE(&lt;stxvd2x CTR0SX,0,BUFFER&gt;)
+ IF_BE(&lt;stxvd2x CTR0X,0,BUFFER&gt;)
+ stxvd2x CTR1X,25,BUFFER
+ stxvd2x CTR2X,26,BUFFER
+ stxvd2x CTR3X,27,BUFFER
+ stxvd2x CTR4X,28,BUFFER
+ stxvd2x CTR5X,29,BUFFER
+ stxvd2x CTR6X,30,BUFFER
+ stxvd2x CTR7X,31,BUFFER
+
+ vadduwm CTR0,CTR0,I8
+ addi BUFFER,BUFFER,0x80
+ bdnz L8x_fill_loop
+
+ ld 25,-56(SP);
+ ld 26,-48(SP);
+ ld 27,-40(SP);
+ ld 28,-32(SP);
+ ld 29,-24(SP);
+ ld 30,-16(SP);
+ ld 31,-8(SP);
+
+ clrldi BLOCKS,BLOCKS,61
+
+ Lfill_4x:
+ srdi 6,BLOCKS,2
+ cmpldi 6,0
+ beq Lfill_2x
+
+ li 8,0x10
+ li 9,0x20
+ li 10,0x30
+
+ vadduwm CTR1,CTR0,I1
+ vadduwm CTR2,CTR0,I2
+ vadduwm CTR3,CTR0,I3
+
+ IF_LE(&lt;vperm CTR0S,CTR0,CTR0,swap_mask
+ vperm CTR1,CTR1,CTR1,swap_mask
+ vperm CTR2,CTR2,CTR2,swap_mask
+ vperm CTR3,CTR3,CTR3,swap_mask&gt;)
+
+ IF_LE(&lt;stxvd2x CTR0SX,0,BUFFER&gt;)
+ IF_BE(&lt;stxvd2x CTR0X,0,BUFFER&gt;)
+ stxvd2x CTR1X,8,BUFFER
+ stxvd2x CTR2X,9,BUFFER
+ stxvd2x CTR3X,10,BUFFER
+
+ vadduwm CTR0,CTR0,I4
+ addi BUFFER,BUFFER,0x40
+
+ clrldi BLOCKS,BLOCKS,62
+
+ Lfill_2x:
+ srdi 6,BLOCKS,1
+ cmpldi 6,0
+ beq Lfill_1x
+
+ li 10,0x10
+
+ vadduwm CTR1,CTR0,I1
+
+ IF_LE(&lt;vperm CTR0S,CTR0,CTR0,swap_mask
+ vperm CTR1,CTR1,CTR1,swap_mask&gt;)
+
+ IF_LE(&lt;stxvd2x CTR0SX,0,BUFFER&gt;)
+ IF_BE(&lt;stxvd2x CTR0X,0,BUFFER&gt;)
+ stxvd2x CTR1X,10,BUFFER
+
+ vadduwm CTR0,CTR0,I2
+ addi BUFFER,BUFFER,0x20
+
+ clrldi BLOCKS,BLOCKS,63
+
+ Lfill_1x:
+ cmpldi BLOCKS,0
+ beq Lfill_done
+
+ IF_LE(&lt;vperm CTR0S,CTR0,CTR0,swap_mask&gt;)
+
+ IF_LE(&lt;stxvd2x CTR0SX,0,BUFFER&gt;)
+ IF_BE(&lt;stxvd2x CTR0X,0,BUFFER&gt;)
+
+ vadduwm CTR0,CTR0,I1
+
+ Lfill_done:
+ IF_LE(&lt;vperm CTR0,CTR0,CTR0,swap_mask&gt;)
+ stxvd2x CTR0X,0,CTR
+
+ blr
+EPILOGUE(_nettle_gcm_fill)
+
+    .data
+IF_LE(&lt;.align 4
+.polynomial:
+ .byte 1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0xc2
+    .align 4
+.swap_mask:
+ .byte 8,9,10,11,12,13,14,15,0,1,2,3,4,5,6,7
+    .align 4
+.hidw_mask:
+ .byte 23,22,21,20,19,18,17,16,7,6,5,4,3,2,1,0
+    .align 4
+.lodw_mask:
+ .byte 31,30,29,28,27,26,25,24,15,14,13,12,11,10,9,8&gt;)
+IF_BE(&lt;.align 4
+.polynomial:
+ .byte 0xc2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
+    .align 4
+.hidw_mask:
+ .byte 0,1,2,3,4,5,6,7,16,17,18,19,20,21,22,23
+    .align 4
+.lodw_mask:
+ .byte 8,9,10,11,12,13,14,15,24,25,26,27,28,29,30,31&gt;)
-- 
2.17.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200714114408</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-07-14 11:44:08-0400</timestampReceived><subject>[PATCH 4/6] "PowerPC64" Add fat build</subject><body>

---
 aes-decrypt-internal.c                   |  10 ++
 aes-encrypt-internal.c                   |  10 ++
 fat-ppc.c                                | 173
+++++++++++++++++++++++++++++++
 fat-setup.h                              |   9 ++
 powerpc64/fat/aes-decrypt-internal-2.asm |  37 +++++++
 powerpc64/fat/aes-encrypt-internal-2.asm |  37 +++++++
 powerpc64/fat/gcm-hash.asm               |  40 +++++++
 7 files changed, 316 insertions(+)
 create mode 100644 fat-ppc.c
 create mode 100644 powerpc64/fat/aes-decrypt-internal-2.asm
 create mode 100644 powerpc64/fat/aes-encrypt-internal-2.asm
 create mode 100644 powerpc64/fat/gcm-hash.asm

diff --git a/aes-decrypt-internal.c b/aes-decrypt-internal.c
index 709c52f9..6326befb 100644
--- a/aes-decrypt-internal.c
+++ b/aes-decrypt-internal.c
@@ -40,6 +40,16 @@
 #include "aes-internal.h"
 #include "macros.h"

+/* For fat builds */
+#if HAVE_NATIVE_aes_decrypt
+void
+_nettle_aes_decrypt_c(unsigned rounds, const uint32_t *keys,
+    const struct aes_table *T,
+    size_t length, uint8_t *dst,
+    const uint8_t *src);
+#define _nettle_aes_decrypt _nettle_aes_decrypt_c
+#endif
+
 void
 _nettle_aes_decrypt(unsigned rounds, const uint32_t *keys,
     const struct aes_table *T,
diff --git a/aes-encrypt-internal.c b/aes-encrypt-internal.c
index 9f61386d..7ff4ca40 100644
--- a/aes-encrypt-internal.c
+++ b/aes-encrypt-internal.c
@@ -40,6 +40,16 @@
 #include "aes-internal.h"
 #include "macros.h"

+/* For fat builds */
+#if HAVE_NATIVE_aes_encrypt
+void
+_nettle_aes_encrypt_c(unsigned rounds, const uint32_t *keys,
+    const struct aes_table *T,
+    size_t length, uint8_t *dst,
+    const uint8_t *src);
+#define _nettle_aes_encrypt _nettle_aes_encrypt_c
+#endif
+
 void
 _nettle_aes_encrypt(unsigned rounds, const uint32_t *keys,
     const struct aes_table *T,
diff --git a/fat-ppc.c b/fat-ppc.c
new file mode 100644
index 00000000..e09b2097
--- /dev/null
+++ b/fat-ppc.c
@@ -0,0 +1,173 @@
+/* fat-ppc.c
+
+   Copyright (C) 2020 Mamone Tarsha
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#define _GNU_SOURCE
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;stdio.h&gt;
+#include &lt;stdlib.h&gt;
+#include &lt;string.h&gt;
+#if defined(__FreeBSD__) &amp;&amp; __FreeBSD__ &lt; 12
+#include &lt;sys/sysctl.h&gt;
+#else
+#include &lt;sys/auxv.h&gt;
+#endif
+
+#include "nettle-types.h"
+
+#include "aes-internal.h"
+#include "gcm.h"
+#include "fat-setup.h"
+
+/* Define from arch/powerpc/include/uapi/asm/cputable.h in Linux kernel */
+#ifndef PPC_FEATURE2_VEC_CRYPTO
+#define PPC_FEATURE2_VEC_CRYPTO 0x02000000
+#endif
+
+struct ppc_features
+{
+  int have_crypto_ext;
+};
+
+static void
+get_ppc_features (struct ppc_features *features)
+{
+  unsigned long hwcap2 = 0;
+#if defined(__FreeBSD__)
+#if __FreeBSD__ &lt; 12
+  size_t len = sizeof(hwcap2);
+  sysctlbyname("hw.cpu_features2", &amp;hwcap2, &amp;len, NULL, 0);
+#else
+  elf_aux_info(AT_HWCAP2, &amp;hwcap2, sizeof(hwcap2));
+#endif
+#else
+  hwcap2 = getauxval(AT_HWCAP2);
+#endif
+  features-&gt;have_crypto_ext =
+   (hwcap2 &amp; PPC_FEATURE2_VEC_CRYPTO) == PPC_FEATURE2_VEC_CRYPTO ? 1 : 0;
+}
+
+DECLARE_FAT_FUNC(_nettle_aes_encrypt, aes_crypt_internal_func)
+DECLARE_FAT_FUNC_VAR(aes_encrypt, aes_crypt_internal_func, c)
+DECLARE_FAT_FUNC_VAR(aes_encrypt, aes_crypt_internal_func, ppc64)
+
+DECLARE_FAT_FUNC(_nettle_aes_decrypt, aes_crypt_internal_func)
+DECLARE_FAT_FUNC_VAR(aes_decrypt, aes_crypt_internal_func, c)
+DECLARE_FAT_FUNC_VAR(aes_decrypt, aes_crypt_internal_func, ppc64)
+
+#if GCM_TABLE_BITS == 8
+DECLARE_FAT_FUNC(_nettle_gcm_init_key, gcm_init_key_func)
+DECLARE_FAT_FUNC_VAR(gcm_init_key, gcm_init_key_func, c)
+DECLARE_FAT_FUNC_VAR(gcm_init_key, gcm_init_key_func, ppc64)
+
+DECLARE_FAT_FUNC(_nettle_gcm_hash, gcm_hash_func)
+DECLARE_FAT_FUNC_VAR(gcm_hash, gcm_hash_func, c)
+DECLARE_FAT_FUNC_VAR(gcm_hash, gcm_hash_func, ppc64)
+#endif /* GCM_TABLE_BITS == 8 */
+
+DECLARE_FAT_FUNC(_nettle_gcm_fill, gcm_fill_func)
+DECLARE_FAT_FUNC_VAR(gcm_fill, gcm_fill_func, c)
+DECLARE_FAT_FUNC_VAR(gcm_fill, gcm_fill_func, ppc64)
+
+static void CONSTRUCTOR
+fat_init (void)
+{
+  struct ppc_features features;
+  int verbose;
+
+  get_ppc_features (&amp;features);
+
+  verbose = getenv (ENV_VERBOSE) != NULL;
+  if (verbose)
+    fprintf (stderr, "libnettle: cpu features: %s\n",
+     features.have_crypto_ext ? "crypto extensions" : "");
+
+  if (features.have_crypto_ext)
+  {
+     if (verbose)
+        fprintf (stderr, "libnettle: enabling arch 2.07 code.\n");
+     _nettle_aes_encrypt_vec = _nettle_aes_encrypt_ppc64;
+     _nettle_aes_decrypt_vec = _nettle_aes_decrypt_ppc64;
+#if GCM_TABLE_BITS == 8
+     /* Make sure _nettle_gcm_init_key_vec function is compatible
+        with _nettle_gcm_hash_vec function e.g. _nettle_gcm_init_key_c()
+        fills gcm_key table with values that are incompatible with
+        _nettle_gcm_hash_ppc64() */
+     _nettle_gcm_init_key_vec = _nettle_gcm_init_key_ppc64;
+     _nettle_gcm_hash_vec = _nettle_gcm_hash_ppc64;
+#endif /* GCM_TABLE_BITS == 8 */
+     _nettle_gcm_fill_vec = _nettle_gcm_fill_ppc64;
+  }
+  else
+  {
+     _nettle_aes_encrypt_vec = _nettle_aes_encrypt_c;
+     _nettle_aes_decrypt_vec = _nettle_aes_decrypt_c;
+#if GCM_TABLE_BITS == 8
+     _nettle_gcm_init_key_vec = _nettle_gcm_init_key_c;
+     _nettle_gcm_hash_vec = _nettle_gcm_hash_c;
+#endif /* GCM_TABLE_BITS == 8 */
+     _nettle_gcm_fill_vec = _nettle_gcm_fill_c;
+  }
+}
+
+DEFINE_FAT_FUNC(_nettle_aes_encrypt, void,
+ (unsigned rounds, const uint32_t *keys,
+ const struct aes_table *T,
+ size_t length, uint8_t *dst,
+ const uint8_t *src),
+ (rounds, keys, T, length, dst, src))
+
+DEFINE_FAT_FUNC(_nettle_aes_decrypt, void,
+ (unsigned rounds, const uint32_t *keys,
+ const struct aes_table *T,
+ size_t length, uint8_t *dst,
+ const uint8_t *src),
+ (rounds, keys, T, length, dst, src))
+
+#if GCM_TABLE_BITS == 8
+DEFINE_FAT_FUNC(_nettle_gcm_init_key, void,
+ (union nettle_block16 *table),
+ (table))
+
+DEFINE_FAT_FUNC(_nettle_gcm_hash, void,
+ (const struct gcm_key *key, union nettle_block16 *x,
+ size_t length, const uint8_t *data),
+ (key, x, length, data))
+#endif /* GCM_TABLE_BITS == 8 */
+
+DEFINE_FAT_FUNC(_nettle_gcm_fill, void,
+ (uint8_t *ctr, size_t blocks,
+ union nettle_block16 *buffer),
+ (ctr, blocks, buffer))
diff --git a/fat-setup.h b/fat-setup.h
index 58b687fd..9793eebb 100644
--- a/fat-setup.h
+++ b/fat-setup.h
@@ -161,6 +161,15 @@ typedef void aes_crypt_internal_func (unsigned rounds,
const uint32_t *keys,
       size_t length, uint8_t *dst,
       const uint8_t *src);

+#if GCM_TABLE_BITS == 8
+typedef void gcm_init_key_func (union nettle_block16 *table);
+
+typedef void gcm_hash_func (const struct gcm_key *key, union
nettle_block16 *x,
+      size_t length, const uint8_t *data);
+
+typedef void gcm_fill_func (uint8_t *ctr, size_t blocks, union
nettle_block16 *buffer);
+#endif /* GCM_TABLE_BITS == 8 */
+
 typedef void *(memxor_func)(void *dst, const void *src, size_t n);

 typedef void salsa20_core_func (uint32_t *dst, const uint32_t *src,
unsigned rounds);
diff --git a/powerpc64/fat/aes-decrypt-internal-2.asm
b/powerpc64/fat/aes-decrypt-internal-2.asm
new file mode 100644
index 00000000..593bf6cf
--- /dev/null
+++ b/powerpc64/fat/aes-decrypt-internal-2.asm
@@ -0,0 +1,37 @@
+C powerpc64/fat/aes-decrypt-internal-2.asm
+
+
+ifelse(&lt;
+   Copyright (C) 2020 Mamone Tarsha
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+&gt;)
+
+dnl PROLOGUE(_nettle_aes_decrypt) picked up by configure
+
+define(&lt;fat_transform&gt;, &lt;$1_ppc64&gt;)
+include_src(&lt;powerpc64/P8/aes-decrypt-internal.asm&gt;)
diff --git a/powerpc64/fat/aes-encrypt-internal-2.asm
b/powerpc64/fat/aes-encrypt-internal-2.asm
new file mode 100644
index 00000000..73a4d543
--- /dev/null
+++ b/powerpc64/fat/aes-encrypt-internal-2.asm
@@ -0,0 +1,37 @@
+C powerpc64/fat/aes-encrypt-internal-2.asm
+
+
+ifelse(&lt;
+   Copyright (C) 2020 Mamone Tarsha
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+&gt;)
+
+dnl PROLOGUE(_nettle_aes_encrypt) picked up by configure
+
+define(&lt;fat_transform&gt;, &lt;$1_ppc64&gt;)
+include_src(&lt;powerpc64/P8/aes-encrypt-internal.asm&gt;)
diff --git a/powerpc64/fat/gcm-hash.asm b/powerpc64/fat/gcm-hash.asm
new file mode 100644
index 00000000..dbb827db
--- /dev/null
+++ b/powerpc64/fat/gcm-hash.asm
@@ -0,0 +1,40 @@
+C powerpc64/fat/gcm-hash.asm
+
+
+ifelse(&lt;
+   Copyright (C) 2020 Mamone Tarsha
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+&gt;)
+
+dnl picked up by configure
+dnl PROLOGUE(_nettle_gcm_init_key)
+dnl PROLOGUE(_nettle_gcm_hash)
+dnl PROLOGUE(_nettle_gcm_fill)
+
+define(&lt;fat_transform&gt;, &lt;$1_ppc64&gt;)
+include_src(&lt;powerpc64/P8/gcm-hash.asm&gt;)
-- 
2.17.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200714114439</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-07-14 11:44:39-0400</timestampReceived><subject>[PATCH 5/6] "PowerPC64" Add README</subject><body>

---
 powerpc64/README | 86
++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 86 insertions(+)
 create mode 100644 powerpc64/README

diff --git a/powerpc64/README b/powerpc64/README
new file mode 100644
index 00000000..f78357ab
--- /dev/null
+++ b/powerpc64/README
@@ -0,0 +1,86 @@
+General-Purpose Register Conventions
+
+Register Status Use
+
+GPR0 volatile In function prologs.
+GPR1 dedicated Stack pointer.
+GPR2 dedicated Table of Contents (TOC) pointer.
+GPR3 volatile First word of a function's argument list;
+    first word of a scalar function return.
+GPR4 volatile Second word of a function's argument list;
+    second word of a scalar function return.
+GPR5 volatile Third word of a function's argument list.
+GPR6 volatile Fourth word of a function's argument list.
+GPR7 volatile Fifth word of a function's argument list.
+GPR8 volatile Sixth word of a function's argument list.
+GPR9 volatile Seventh word of a function's argument list.
+GPR10 volatile Eighth word of a function's argument list.
+GPR11 volatile In calls by pointer and as an environment pointer for
languages
+    that require it (for example, PASCAL).
+GPR12 volatile For special exception handling required by certain
languages and in
+    glink code.
+GPR13 reserved Reserved under 64-bit environment; not restored across
system calls.
+GPR14:GPR31 nonvolatile These registers must be preserved across a
function call.
+
+Vector Register Conventions
+
+Register Status
+
+VR0 Volatile
+VR1 Volatile
+VR2 Volatile
+VR3 Volatile
+VR4 Volatile
+VR5 Volatile
+VR6 Volatile
+VR7 Volatile
+VR8 Volatile
+VR9 Volatile
+VR10 Volatile
+VR11 Volatile
+VR12 Volatile
+VR13 Volatile
+VR14 Volatile
+VR15 Volatile
+VR16 Volatile
+VR17 Volatile
+VR18 Volatile
+VR19 Volatile
+VR20:31 Nonvolatile (extended ABI mode) their values are preserved across
function calls
+
+Addressing memory
+
+There are many ways to reference data, in the sake of writing
position-independent code
+the current implementations uses GOT-indirect addressing (Accessing data
through the global
+offset table):
+1. Define data in .data section
+2. Load the address of data into register from the global offset table
e.g. ld 7, my_var@got(2)
+3. Use the address to load the value of data into register e.g. ld 3, 0(7)
+Refer to [2] for more information
+
+VSX instructions "lxvd2x/stxvd2x" are used to load and store data to memory
+instead of VR instructions "lvx/stvx" as it produces a fewer instructions
+"lvx/stvx" can be used to load/store data into storage operands
+but additional instructions are needed to access unaligned storage
operands, refer
+to "6.4.1 Accessing Unaligned Storage Operands" in [3]
+to see an example of accessing unaligned storage operands.
"lxvd2x/stxvd2x" can
+be used to load/store data into unaligned storage operands but permuting
is needed
+for loading and storing data in little-endian mode
+VSX registers are defined with "X" suffix
+TODO: use architecture 3.0 instructions "lxv/stxv" instead for POWER9 and
newer
+
+Function Prologue
+
+Big-endian systems only support ELFv1 ABI which requires the following
steps in the
+function prologue:
+1. Write the "official procedure descriptor" in ".opd","aw" section
+2. Write procedure description for .my_func in my_func label
+3. Switch back to ".text" section for program code
+4. Label the beginning of the code .my_func
+Refer to [1] for more information
+Little-endian systems are compatible with ELFv2 ABI, an example of
function prologue
+for ELFv2 ABI can be seen in [2]
+
+[1] http://www.ibm.com/developerworks/linux/library/l-powasm1.html
+[2]
https://openpowerfoundation.org/?resource_lib=64-bit-elf-v2-abi-specification-power-architecture
+[3]
https://openpowerfoundation.org/?resource_lib=ibm-power-isa-version-2-07-b
-- 
2.17.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200714114503</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-07-14 11:45:03-0400</timestampReceived><subject>[PATCH 6/6] "PowerPC64" Update configure.ac and Makefile.in</subject><body>

---
 Makefile.in  |  2 +-
 configure.ac | 21 +++++++++++++++++++--
 2 files changed, 20 insertions(+), 3 deletions(-)

diff --git a/Makefile.in b/Makefile.in
index 042ebe5f..92216d55 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -603,7 +603,7 @@ distdir: $(DISTFILES)
  done
  set -e; for d in sparc32 sparc64 x86 \
  x86_64 x86_64/aesni x86_64/sha_ni x86_64/fat \
- arm arm/neon arm/v6 arm/fat ; do \
+ arm arm/neon arm/v6 arm/fat powerpc64 powerpc64/P8 powerpc64/fat ; do \
   mkdir "$(distdir)/$$d" ; \
   find "$(srcdir)/$$d" -maxdepth 1 '(' -name '*.asm' -o -name '*.m4' ')' \
     -exec cp '{}' "$(distdir)/$$d" ';' ; \
diff --git a/configure.ac b/configure.ac
index a01eb7d3..49db7af1 100644
--- a/configure.ac
+++ b/configure.ac
@@ -89,6 +89,10 @@ AC_ARG_ENABLE(x86-sha-ni,
   AC_HELP_STRING([--enable-x86-sha-ni], [Enable x86_64 sha_ni
instructions. (default=no)]),,
   [enable_x86_sha_ni=no])

+AC_ARG_ENABLE(power-crypto-ext,
+  AC_HELP_STRING([--enable-power-crypto-ext], [Enable POWER crypto
extentions. (default=no)]),,
+  [enable_power_crypto_ext=no])
+
 AC_ARG_ENABLE(mini-gmp,
   AC_HELP_STRING([--enable-mini-gmp], [Enable mini-gmp, used instead of
libgmp.]),,
   [enable_mini_gmp=no])
@@ -434,6 +438,16 @@ if test "x$enable_assembler" = xyes ; then
  fi
       fi
       ;;
+    *powerpc64*)
+      if test "x$enable_fat" = xyes ; then
+        asm_path="powerpc64/fat powerpc64"
+        OPT_NETTLE_SOURCES="fat-ppc.c $OPT_NETTLE_SOURCES"
+     else
+        if test "x$enable_power_crypto_ext" = xyes ; then
+          asm_path="powerpc64/P8 powerpc64"
+        fi
+      fi
+      ;;
     *)
       enable_assembler=no
       ;;
@@ -453,7 +467,7 @@ asm_replace_list="aes-encrypt-internal.asm
aes-decrypt-internal.asm \
  sha3-permute.asm umac-nh.asm umac-nh-n.asm machine.m4"

 # Assembler files which generate additional object files if they are used.
-asm_nettle_optional_list="gcm-hash8.asm cpuid.asm \
+asm_nettle_optional_list="gcm-hash.asm gcm-hash8.asm cpuid.asm \
   aes-encrypt-internal-2.asm aes-decrypt-internal-2.asm memxor-2.asm \
   chacha-core-internal-2.asm salsa20-2core.asm \
   salsa20-core-internal-2.asm sha1-compress-2.asm sha256-compress-2.asm \
@@ -571,7 +585,10 @@ AH_VERBATIM([HAVE_NATIVE],
 #undef HAVE_NATIVE_ecc_secp384r1_redc
 #undef HAVE_NATIVE_ecc_secp521r1_modp
 #undef HAVE_NATIVE_ecc_secp521r1_redc
-#undef HAVE_NATIVE_gcm_init_key8
+#undef HAVE_NATIVE_aes_decrypt
+#undef HAVE_NATIVE_aes_encrypt
+#undef HAVE_NATIVE_gcm_init_key
+#undef HAVE_NATIVE_gcm_hash
 #undef HAVE_NATIVE_gcm_hash8
 #undef HAVE_NATIVE_gcm_fill
 #undef HAVE_NATIVE_salsa20_core
-- 
2.17.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200714125654</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-07-14 12:56:54-0400</timestampReceived><subject>Re: [PATCH 4/4] Add AES [Enc|Dec] optimized implementations for PowerPC64</subject><body>

You are right, I measured the throughput and latency for vncipher and vxor
instructions for POWER8 and updated the patch accordingly.

On Thu, Jul 9, 2020 at 5:58 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt; +L16x_round_loop:
&gt; &gt; + lxvd2x KX,10,KEYS
&gt; &gt; + vperm   K,K,K,swap_mask
&gt; &gt; + vncipher S0,S0,ZERO
&gt; &gt; + vncipher S1,S1,ZERO
&gt; &gt; + vncipher S2,S2,ZERO
&gt; &gt; + vncipher S3,S3,ZERO
&gt; &gt; + vncipher S4,S4,ZERO
&gt; &gt; + vncipher S5,S5,ZERO
&gt; &gt; + vncipher S6,S6,ZERO
&gt; &gt; + vncipher S7,S7,ZERO
&gt; &gt; + vncipher S8,S8,ZERO
&gt; &gt; + vncipher S9,S9,ZERO
&gt; &gt; + vncipher S10,S10,ZERO
&gt; &gt; + vncipher S11,S11,ZERO
&gt; &gt; + vncipher S12,S12,ZERO
&gt; &gt; + vncipher S13,S13,ZERO
&gt; &gt; + vncipher S14,S14,ZERO
&gt; &gt; + vncipher S15,S15,ZERO
&gt; &gt; + vxor S0,S0,K
&gt; &gt; + vxor S1,S1,K
&gt; &gt; + vxor S2,S2,K
&gt; &gt; + vxor S3,S3,K
&gt; &gt; + vxor S4,S4,K
&gt; &gt; + vxor S5,S5,K
&gt; &gt; + vxor S6,S6,K
&gt; &gt; + vxor S7,S7,K
&gt; &gt; + vxor S8,S8,K
&gt; &gt; + vxor S9,S9,K
&gt; &gt; + vxor S10,S10,K
&gt; &gt; + vxor S11,S11,K
&gt; &gt; + vxor S12,S12,K
&gt; &gt; + vxor S13,S13,K
&gt; &gt; + vxor S14,S14,K
&gt; &gt; + vxor S15,S15,K
&gt; &gt; + addi 10,10,0x10
&gt; &gt; + bdnz L16x_round_loop
&gt;
&gt; Do you really need to go all the way to 16 blocks in parallel to
&gt; saturate the execution units? I'm used to defining throughput and
&gt; latency of an instruction (e.g., vncipher) as follows:
&gt;
&gt; Throughput: The number of independent vncipher instructions that can be
&gt; executed per cycle. Can be measured by benchmarking a loop of
&gt; independent instructions.
&gt;
&gt; Latency: The number of cycles from the start of execution of a vncipher
&gt; instruction until execution of an instruction depending on the vncipher
&gt; result can start. Can be measured by benchmarking a loop where each
&gt; instruction depends on the result of the preceding instruction.
&gt;
&gt; Do you know throughput and latency of the vncipher and vxor
&gt; instructions? (Official manuals are not always to be trusted). Those
&gt; numbers determines how much parallelism is needed, typically the product
&gt; of latency and throughput.
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200714130429</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-07-14 13:04:29-0400</timestampReceived><subject>Re: [PATCH 1/4] Check for PowerPC64 assembly if crypto extensions are available</subject><body>

On Thu, Jul 9, 2020 at 4:11 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt;
&gt; Do you expect that this "auto" logic does what that user wants? I'm
&gt; thinking, maybe it's simpler to stick with just yes/no (no being the
&gt; default), and then add support for --enable-fat later, to select code at
&gt; run-time?


You are right, I removed the "auto" logic and set the default value "no".
fat support is added to the patch.


&gt; Overriding PROLOGUE here looks fine, but it would be nice with a comment
&gt; explaining what's needed, and/or linking the some appropriate ABI
&gt; specification.
&gt;
&gt;
Added to the README file.

Thanks,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200717180055</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-07-17 18:00:55-0400</timestampReceived><subject>relocation error: R_AMD64_64</subject><body>

Hi Everyone,

I'm seeing a fair amount of "ld: warning: relocation error:
R_AMD64_64" when linking from nettle-3.6 release tarball:

gcc -g2 -O2 -m64 -march=native -fPIC -pthread -ggdb3 -Wall -W
-Wno-sign-compare   -Wmissing-prototypes -Wmissing-declarations
-Wstrict-prototypes   -Wpointer-arith -Wbad-function-cast
-Wnested-externs -L.. -L/opt/ssh/lib -m64 -Wl,-R,'RIGIN/../lib'
-Wl,-R,/opt/ssh/lib -Wl,-z,now rsa-sign.o io.o read_rsa_key.o \
-lhogweed -lnettle -lgmp -ldl -lpthread -o rsa-sign
ld: warning: relocation error: R_AMD64_64: file ../getopt.o: symbol
optarg: external symbolic relocation against non-allocatable section
.debug_info; cannot be processed at runtime: relocation ignored

It looks like getopt was not built correctly.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200717200503</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-07-17 20:05:03-0400</timestampReceived><subject>Assembly recipe missing ASFLAGS</subject><body>

Hi Everyone,

I noticed *.s recipes do not use ASFLAGS. ASFLAGS includes -Wa,--noexecstack:
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200717170904</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-07-17 17:09:04-0400</timestampReceived><subject>Handling of ORIGIN-based rpaths and runpaths</subject><body>

Hi Everyone,

I build OpenSSH for downlevel machines, like OS X and Solaris. I
install into /opt/ssh, and I use a runpath of $ORIGIN/../lib. The
LDFLAGS are:

    -Wl,-runpath,'$ORIGIN/../lib' -Wl,-runpath,$(prefix)/lib
-Wl,--enable-new-dtags

I noticed Nettle does not handle the ORIGIN-based runpath properly:

  /opt/ssh/lib/libhogweed.so.6:
    RUNPATH:   RIGIN/../lib:/opt/ssh/lib
    RPATH:   RIGIN/../lib:/opt/ssh/lib

And:

  /opt/ssh/lib/libnettle.so.8.0:
    RUNPATH:   RIGIN/../lib:/opt/ssh/lib
    RPATH:   RIGIN/../lib:/opt/ssh/lib

Besides $ORIGIN, Nettle may encounter $LIB and $PLATFORM. Also see
ld.so man page (https://man7.org/linux/man-pages/man8/ld.so.8.html).

I believe the fix is to escape the dollar sign in the makefile. That
is, when Nettle creates its makefiles, it must use:

    -Wl,-runpath,'$$ORIGIN/../lib' ...

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200719071352</emailId><senderName>Daiki Ueno</senderName><senderEmail>ueno@gnu.org</senderEmail><timestampReceived>2020-07-19 07:13:52-0400</timestampReceived><subject>checking ECC point at infinity</subject><body>

Hello,

SP800-56A (revision 3) section 5.6.2.3.3 now mandates a check that the
generated public key (Q) multiplied by the curve order (n) results in an
identity element (= an infinity point).

It seem that it is not possible to implement this check with the
Nettle's public API.  The attached patch naively multiplies Q by n but
it causes the valgrind errors below.

As it works with the curve order minus 1, I added the following check
instead in my library, though I'm not sure if this satisfies the
original requirement:

  P = (n - 1) * Q

where P's x-coordinate is the same as Q's, and P also lies on the same
curve so that indicates P + Q (= n * Q) is an infinity point, according
to the group law.

Is there a better (direct) way to implement the check?  Suggestions
appreciated.

  Conditional jump or move depends on uninitialised value(s)
     at 0x4880DFB: _nettle_ecc_mul_a (ecc-mul-a.c:145)
     by 0x48815F8: nettle_ecc_point_mul (ecc-point-mul.c:55)
     by 0x4012EB: main (ecc-test.c:36)

  Conditional jump or move depends on uninitialised value(s)
     at 0x487D1D9: _nettle_sec_tabselect (sec-tabselect.c:54)
     by 0x4880E1B: _nettle_ecc_mul_a (ecc-mul-a.c:147)
     by 0x48815F8: nettle_ecc_point_mul (ecc-point-mul.c:55)
     by 0x4012EB: main (ecc-test.c:36)

  Conditional jump or move depends on uninitialised value(s)
     at 0x487E0F3: _nettle_ecc_mod_add (ecc-mod-arith.c:53)
     by 0x487F51B: _nettle_ecc_dup_jj (ecc-dup-jj.c:81)
     by 0x4880E66: _nettle_ecc_mul_a (ecc-mul-a.c:171)
     by 0x48815F8: nettle_ecc_point_mul (ecc-point-mul.c:55)
     by 0x4012EB: main (ecc-test.c:36)

Regards,
-- 
Daiki Ueno


#include &lt;nettle/ecdsa.h&gt;
#include &lt;nettle/ecc-curve.h&gt;
#include &lt;assert.h&gt;
#include &lt;string.h&gt;

static void
myrandom (void *ctx, size_t length, uint8_t *dst)
{
  memset (dst, 0, length);
  *dst = 0xff;
}

int
main (void)
{
  const struct ecc_curve *curve = nettle_get_secp_256r1 ();
  struct ecc_point pub;
  struct ecc_scalar key;
  mpz_t nz, x, y;
  struct ecc_scalar n;
  struct ecc_point r;

  ecc_point_init (&amp;pub, curve);
  ecc_scalar_init (&amp;key, curve);
  ecc_scalar_init (&amp;n, curve);
  ecc_point_init (&amp;r, curve);

  ecdsa_generate_keypair (&amp;pub, &amp;key, NULL, myrandom);

  /* Calculate P = nQ and check if it is an infinity point.  */
  mpz_init_set_str (nz, "ffffffff00000000ffffffffffffffff"
		    "bce6faada7179e84f3b9cac2fc632551", 16);
  ecc_scalar_set (&amp;n, nz);
  mpz_clear (nz);

  ecc_point_mul (&amp;r, &amp;n, &amp;pub);

  mpz_init (x);
  mpz_init (y);

  ecc_point_get (&amp;r, x, y);
  assert (mpz_cmp_ui (x, 0) == 0);
  assert (mpz_cmp_ui (y, 0) == 0);

  mpz_clear (x);
  mpz_clear (y);

  ecc_point_clear (&amp;pub);
  ecc_scalar_clear (&amp;key);
  ecc_scalar_clear (&amp;n);
  ecc_point_clear (&amp;r);

  return 0;
}

/**
 * Local variables:
 * compile-command: "gcc -o ecc-test ecc-test.c `pkg-config hogweed --cflags --libs` -lgmp"
 * End:
 */

[Attachment #4 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200720161835</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-07-20 16:18:35-0400</timestampReceived><subject>[PowerPC64] Add AIX to cpu detection</subject><body>

---
 fat-ppc.c | 29 ++++++++++++++++++++---------
 1 file changed, 20 insertions(+), 9 deletions(-)

diff --git a/fat-ppc.c b/fat-ppc.c
index e09b2097..eca689fe 100644
--- a/fat-ppc.c
+++ b/fat-ppc.c
@@ -39,10 +39,17 @@
 #include &lt;stdio.h&gt;
 #include &lt;stdlib.h&gt;
 #include &lt;string.h&gt;
-#if defined(__FreeBSD__) &amp;&amp; __FreeBSD__ &lt; 12
-#include &lt;sys/sysctl.h&gt;
-#else
+
+#if defined(_AIX)
+#include &lt;sys/systemcfg.h&gt;
+#elif defined(__linux__)
+#include &lt;sys/auxv.h&gt;
+#elif defined(__FreeBSD__)
+#if __FreeBSD__ &gt;= 12
 #include &lt;sys/auxv.h&gt;
+#else
+#include &lt;sys/sysctl.h&gt;
+#endif
 #endif

 #include "nettle-types.h"
@@ -64,19 +71,23 @@ struct ppc_features
 static void
 get_ppc_features (struct ppc_features *features)
 {
+#if defined(_AIX) &amp;&amp; defined(__power_8_andup)
+  features-&gt;have_crypto_ext = __power_8_andup() != 0 ? 1 : 0;
+#else
   unsigned long hwcap2 = 0;
-#if defined(__FreeBSD__)
-#if __FreeBSD__ &lt; 12
+#if defined(__linux__)
+  hwcap2 = getauxval(AT_HWCAP2);
+#elif defined(__FreeBSD__)
+#if __FreeBSD__ &gt;= 12
+  elf_aux_info(AT_HWCAP2, &amp;hwcap2, sizeof(hwcap2));
+#else
   size_t len = sizeof(hwcap2);
   sysctlbyname("hw.cpu_features2", &amp;hwcap2, &amp;len, NULL, 0);
-#else
-  elf_aux_info(AT_HWCAP2, &amp;hwcap2, sizeof(hwcap2));
 #endif
-#else
-  hwcap2 = getauxval(AT_HWCAP2);
 #endif
   features-&gt;have_crypto_ext =
    (hwcap2 &amp; PPC_FEATURE2_VEC_CRYPTO) == PPC_FEATURE2_VEC_CRYPTO ? 1 : 0;
+#endif
 }

 DECLARE_FAT_FUNC(_nettle_aes_encrypt, aes_crypt_internal_func)
--
2.17.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200707144636</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-07-07 14:46:36-0400</timestampReceived><subject>Optimizing salsa20</subject><body>

I've written some new ARM Neon assembly for salsa20. See
https://gitlab.com/gnutls/nettle/-/commit/2ac58a1ce729a6cfe1d3703f4deb6da8862909e9,
when configured with --enable-arm-neon.

It interleaves the processing of two blocks, which gives a speedup of
50% -- 100% on the ARM cores where I've tested it. Before merging, I
need to fix fat builds to use the new code on processors that support
it.

To make it work also on big-endian ARM, I'd need some help. (I think the
qemu-user package supports big-endian ARM, at least, it includes a
program named qemu-armeb. But I'm missing a cross compiler and cross
debugger).

I'd like to do the same for x86_64. And for chacha, it might give even
greater speedup to interleave processing of three blocks, which may be
possible since I think chacha needs fewer registers for temporaries.

For both x86_64 and ARM neon, the current code uses 128-bit wide
registers. Processors with 256-bit wide simd registers (at least 16 of
them) could do twice as many blocks at a time.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200709063005</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-07-09 06:30:05-0400</timestampReceived><subject>Re: Optimizing salsa20</subject><body>

I would like to help but I have no clue or experience with ARM NEON, sorry.

regards,
Mamone

On Tue, Jul 7, 2020 at 5:46 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; I've written some new ARM Neon assembly for salsa20. See
&gt;
&gt; https://gitlab.com/gnutls/nettle/-/commit/2ac58a1ce729a6cfe1d3703f4deb6da8862909e9
&gt; ,
&gt; when configured with --enable-arm-neon.
&gt;
&gt; It interleaves the processing of two blocks, which gives a speedup of
&gt; 50% -- 100% on the ARM cores where I've tested it. Before merging, I
&gt; need to fix fat builds to use the new code on processors that support
&gt; it.
&gt;
&gt; To make it work also on big-endian ARM, I'd need some help. (I think the
&gt; qemu-user package supports big-endian ARM, at least, it includes a
&gt; program named qemu-armeb. But I'm missing a cross compiler and cross
&gt; debugger).
&gt;
&gt; I'd like to do the same for x86_64. And for chacha, it might give even
&gt; greater speedup to interleave processing of three blocks, which may be
&gt; possible since I think chacha needs fewer registers for temporaries.
&gt;
&gt; For both x86_64 and ARM neon, the current code uses 128-bit wide
&gt; registers. Processors with 256-bit wide simd registers (at least 16 of
&gt; them) could do twice as many blocks at a time.
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt;
&gt; _______________________________________________
&gt; nettle-bugs mailing list
&gt; nettle-bugs@lists.lysator.liu.se
&gt; http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200721140216</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-07-21 14:02:16-0400</timestampReceived><subject>[PATCH] "PowerPC64" Add README</subject><body>

---
 powerpc64/README | 86
++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 86 insertions(+)
 create mode 100644 powerpc64/README

diff --git a/powerpc64/README b/powerpc64/README
new file mode 100644
index 00000000..6d6f3fbb
--- /dev/null
+++ b/powerpc64/README
@@ -0,0 +1,86 @@
+General-Purpose Register Conventions
+
+Register Status Use
+
+GPR0    volatile    In function prologs.
+GPR1    dedicated   Stack pointer.
+GPR2    dedicated   Table of Contents (TOC) pointer.
+GPR3    volatile    First word of a function's argument list;
+    first word of a scalar function return.
+GPR4    volatile    Second word of a function's argument list;
+    second word of a scalar function return.
+GPR5    volatile    Third word of a function's argument list.
+GPR6    volatile    Fourth word of a function's argument list.
+GPR7    volatile    Fifth word of a function's argument list.
+GPR8    volatile    Sixth word of a function's argument list.
+GPR9    volatile    Seventh word of a function's argument list.
+GPR10   volatile    Eighth word of a function's argument list.
+GPR11   volatile    In calls by pointer and as an environment pointer for
languages
+    that require it (for example, PASCAL).
+GPR12   volatile    For special exception handling required by certain
languages and in
+    glink code.
+GPR13   reserved    Reserved under 64-bit environment; not restored across
system calls.
+GPR14:GPR31 nonvolatile These registers must be preserved across a
function call.
+
+Vector Register Conventions
+
+Register Status
+
+VR0     Volatile
+VR1     Volatile
+VR2     Volatile
+VR3     Volatile
+VR4     Volatile
+VR5     Volatile
+VR6     Volatile
+VR7     Volatile
+VR8     Volatile
+VR9     Volatile
+VR10    Volatile
+VR11    Volatile
+VR12    Volatile
+VR13    Volatile
+VR14    Volatile
+VR15    Volatile
+VR16    Volatile
+VR17    Volatile
+VR18    Volatile
+VR19    Volatile
+VR20:31 Nonvolatile (extended ABI mode) their values are preserved across
function calls
+
+Addressing memory
+
+There are many ways to reference data, in the sake of writing
position-independent code
+the current implementations uses GOT-indirect addressing (Accessing data
through the global
+offset table):
+1. Define data in .data section
+2. Load the address of data into register from the global offset table
e.g. ld 7, my_var@got(2)
+3. Use the address to load the value of data into register e.g. ld 3, 0(7)
+Refer to [2] for more information
+
+VSX instructions "lxvd2x/stxvd2x" are used to load and store data to memory
+instead of VR instructions "lvx/stvx" as it produces a fewer instructions
+"lvx/stvx" can be used to load/store data into storage operands
+but additional instructions are needed to access unaligned storage
operands, refer
+to "6.4.1 Accessing Unaligned Storage Operands" in [3]
+to see an example of accessing unaligned storage operands.
"lxvd2x/stxvd2x" can
+be used to load/store data into unaligned storage operands but permuting
is needed
+for loading and storing data in little-endian mode
+VSX registers are defined with "X" suffix
+TODO: use architecture 3.0 instructions "lxv/stxv" instead for POWER9 and
newer
+
+Function Prologue
+
+Big-endian systems only support ELFv1 ABI which requires the following
steps in the
+function prologue:
+1. Write the "official procedure descriptor" in ".opd","aw" section
+2. Write procedure description for .my_func in my_func label
+3. Switch back to ".text" section for program code
+4. Label the beginning of the code .my_func
+Refer to [1] for more information
+Little-endian systems are compatible with ELFv2 ABI, an example of
function prologue
+for ELFv2 ABI can be seen in [2]
+
+[1] http://www.ibm.com/developerworks/linux/library/l-powasm1.html
+[2]
https://openpowerfoundation.org/?resource_lib=64-bit-elf-v2-abi-specification-power-architecture
+[3]
https://openpowerfoundation.org/?resource_lib=ibm-power-isa-version-2-07-b
-- 
2.17.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200709140521</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-07-09 14:05:21-0400</timestampReceived><subject>Re: Optimizing salsa20</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; It interleaves the processing of two blocks, which gives a speedup of
&gt; 50% -- 100% on the ARM cores where I've tested it. Before merging, I
&gt; need to fix fat builds to use the new code on processors that support
&gt; it.

I've added the fat build support, which needed a bit of reorganization,
and mergged to master. This will break support for big-endian ARM for
now, since I'm not able to test that.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200710185950</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-07-10 18:59:50-0400</timestampReceived><subject>Re: Optimizing salsa20</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; I'd like to do the same for x86_64.

I've now tried the same interleaving for salsa20 on x86_64, and it gives a
25% speedup on my laptop. Pushed to a new branch, x86_64-salsa20-2core.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200721102606</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2020-07-21 10:26:06-0400</timestampReceived><subject>Re: Optimizing salsa20</subject><body>

Hello Niels,

sorry for the delay - I've been on vacation.

On Thu, Jul 09, 2020 at 04:05:21PM +0200, Niels Möller wrote:

&gt; This will break support for big-endian ARM for
&gt; now, since I'm not able to test that.

We still have the ARM BE CI ready to go. Is it maybe time to get it
activated on GitLab? I've put it in an MR for reference
(https://git.lysator.liu.se/nettle/nettle/-/merge_requests/8) but can
also submit via the list once we've decided where to put the container
images for good. I'd still vote for GnuTLS's build-images, as the
others. nettle could have its own clone of it as well, I guess.

I've run branch master-updates through it and it compiles and runs the
testsuite fine:

https://gitlab.com/michaelweiser/nettle/-/jobs/648326607

master indeed fails:

https://gitlab.com/michaelweiser/nettle/-/jobs/648334928

libnettle: cpu features: arch:6,neon
libnettle: enabling armv6 code.
libnettle: enabling neon code.
Assert failed: testutils.c:831: MEMEQ(length, data, ciphertext-&gt;data)
qemu: uncaught target signal 6 (Aborted) - core dumped
Aborted (core dumped)
FAIL: chacha-poly1305

Is this about what you've expected? Then I'll look into it.

Any other branches I should try?
-- 
Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200720163404</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-07-20 16:34:04-0400</timestampReceived><subject>Re: [PowerPC64] Add AIX to cpu detection</subject><body>

On Mon, Jul 20, 2020 at 12:18 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt; wrote:
&gt;
&gt; ---
&gt;  fat-ppc.c | 29 ++++++++++++++++++++---------
&gt;  1 file changed, 20 insertions(+), 9 deletions(-)
&gt;
&gt; diff --git a/fat-ppc.c b/fat-ppc.c
&gt; index e09b2097..eca689fe 100644
&gt; --- a/fat-ppc.c
&gt; +++ b/fat-ppc.c
&gt; @@ -39,10 +39,17 @@
&gt;  #include &lt;stdio.h&gt;
&gt;  #include &lt;stdlib.h&gt;
&gt;  #include &lt;string.h&gt;
&gt; -#if defined(__FreeBSD__) &amp;&amp; __FreeBSD__ &lt; 12
&gt; -#include &lt;sys/sysctl.h&gt;
&gt; -#else
&gt; +
&gt; +#if defined(_AIX)
&gt; +#include &lt;sys/systemcfg.h&gt;
&gt; +#elif defined(__linux__)
&gt; +#include &lt;sys/auxv.h&gt;
&gt; +#elif defined(__FreeBSD__)
&gt; +#if __FreeBSD__ &gt;= 12
&gt;  #include &lt;sys/auxv.h&gt;
&gt; +#else
&gt; +#include &lt;sys/sysctl.h&gt;
&gt; +#endif
&gt;  #endif
&gt;
&gt;  #include "nettle-types.h"
&gt; @@ -64,19 +71,23 @@ struct ppc_features
&gt;  static void
&gt;  get_ppc_features (struct ppc_features *features)
&gt;  {
&gt; +#if defined(_AIX) &amp;&amp; defined(__power_8_andup)
&gt; +  features-&gt;have_crypto_ext = __power_8_andup() != 0 ? 1 : 0;
&gt; +#else
&gt;    unsigned long hwcap2 = 0;
&gt; -#if defined(__FreeBSD__)
&gt; -#if __FreeBSD__ &lt; 12
&gt; +#if defined(__linux__)
&gt; +  hwcap2 = getauxval(AT_HWCAP2);
&gt; +#elif defined(__FreeBSD__)
&gt; +#if __FreeBSD__ &gt;= 12
&gt; +  elf_aux_info(AT_HWCAP2, &amp;hwcap2, sizeof(hwcap2));
&gt; +#else
&gt;    size_t len = sizeof(hwcap2);
&gt;    sysctlbyname("hw.cpu_features2", &amp;hwcap2, &amp;len, NULL, 0);
&gt; -#else
&gt; -  elf_aux_info(AT_HWCAP2, &amp;hwcap2, sizeof(hwcap2));
&gt;  #endif
&gt; -#else
&gt; -  hwcap2 = getauxval(AT_HWCAP2);
&gt;  #endif
&gt;    features-&gt;have_crypto_ext =
&gt;     (hwcap2 &amp; PPC_FEATURE2_VEC_CRYPTO) == PPC_FEATURE2_VEC_CRYPTO ? 1 : 0;
&gt; +#endif
&gt;  }
&gt;
&gt;  DECLARE_FAT_FUNC(_nettle_aes_encrypt, aes_crypt_internal_func)
&gt; --
&gt; 2.17.1

Hi Maamon,

One small comment...

You may want to stay flexible enough to detect POWER7, VSX and above.
ChaCha is fast as hell even on POWER7 and without 64-bit vectors. In
fact, I found ChaCha is profitable down to POWER4 on an old PowerMac.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200720123405</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-07-20 12:34:05-0400</timestampReceived><subject>Re: checking ECC point at infinity</subject><body>

Daiki Ueno &lt;ueno@gnu.org&gt; writes:

&gt; It seem that it is not possible to implement this check with the
&gt; Nettle's public API.  The attached patch naively multiplies Q by n but
&gt; it causes the valgrind errors below.

I think the point multiplication functions were written under the
assumption that the scalar should be less than the group order.
Docs could perhaps be improved on that.

But I don't known now exactly how it fails. It's good you get the
valgrind failures, but line numbers don't quite match my version.

If ecc_mul_a can be made to support this, I take it the output will be a
point with z = 0 (mod p) in homogenenous coordinates. 

And then the special case z = 0 has to be detected in some way in the
conversion to affine coordinates. That's done by ecc_j_to_a, but that
assumes a finite input point, since it inverts z without checking for
zero.

&gt; As it works with the curve order minus 1, I added the following check
&gt; instead in my library, though I'm not sure if this satisfies the
&gt; original requirement:
&gt;
&gt;   P = (n - 1) * Q

Checking that (n-1) * Q = -Q should be mathematically equivalent.
There's a similar test in testsuite/ecc-mul-a-test.c and
testsuite/ecc-mul-g-test.c (but testing with the generator rather than
with an arbitrary public key).

If the point of the requirements of "SP800-56A (revision 3)" is to check
the mathematical properties of the point, rather than testing a
particular implementation of the ecc arithmetics, then (n-1) Q = -Q
sounds good enough to me. You should first check that Q really lies on
the curve (otherwise both left-hand side and right-hand side operations
suffer garbage-in-garbage-out), but you probably do that already.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200717192408</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-07-17 19:24:08-0400</timestampReceived><subject>Re: Handling of ORIGIN-based rpaths and runpaths</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; Hi Everyone,
&gt;
&gt; I build OpenSSH for downlevel machines, like OS X and Solaris. I
&gt; install into /opt/ssh, and I use a runpath of $ORIGIN/../lib. The
&gt; LDFLAGS are:
&gt;
&gt;     -Wl,-runpath,'$ORIGIN/../lib' -Wl,-runpath,$(prefix)/lib
&gt; -Wl,--enable-new-dtags
&gt;
&gt; I noticed Nettle does not handle the ORIGIN-based runpath properly:
&gt;
&gt;   /opt/ssh/lib/libhogweed.so.6:
&gt;     RUNPATH:   RIGIN/../lib:/opt/ssh/lib
&gt;     RPATH:   RIGIN/../lib:/opt/ssh/lib

Indeed looks like missing a quote/escape problem. Does it work with
other packages using autconf? How? I would suggest adding the quotes in
the input, i.e., set

  LDFLAGS='-Wl,-runpath,'$$ORIGIN/../lib' -Wl,-runpath,$(prefix)/lib ...'

when running configure.

Since you specify $(prefix), a Makefile-level substitution, and expect
that to work, it seems reasonable to me to use Makefile-style syntax,
including needed escapes, also for $ORIGIN.

&gt; I believe the fix is to escape the dollar sign in the makefile. That
&gt; is, when Nettle creates its makefiles, it must use:
&gt;
&gt;     -Wl,-runpath,'$$ORIGIN/../lib' ...

Where do you suggest that substitution be made? And how would Nettle's
configure script or Makefile know that you intend the $ in '$ORIGIN' to
be escaped, but not the $ in '$(prefix)' ?

I admit I'm quite skeptical, and I also think it's important to stay
consistent with how LDFLAGS is handled in other GNU packages. But if
you can suggest a good way to do it, I'm happy to listen.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200718171837</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-07-18 17:18:37-0400</timestampReceived><subject>Re: Handling of ORIGIN-based rpaths and runpaths</subject><body>

On Fri, Jul 17, 2020 at 3:24 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; Jeffrey Walton &lt;noloader@gmail.com&gt; writes:
&gt;
&gt; &gt; Hi Everyone,
&gt; &gt;
&gt; &gt; I build OpenSSH for downlevel machines, like OS X and Solaris. I
&gt; &gt; install into /opt/ssh, and I use a runpath of $ORIGIN/../lib. The
&gt; &gt; LDFLAGS are:
&gt; &gt;
&gt; &gt;     -Wl,-runpath,'$ORIGIN/../lib' -Wl,-runpath,$(prefix)/lib
&gt; &gt; -Wl,--enable-new-dtags
&gt; &gt;
&gt; &gt; I noticed Nettle does not handle the ORIGIN-based runpath properly:
&gt; &gt;
&gt; &gt;   /opt/ssh/lib/libhogweed.so.6:
&gt; &gt;     RUNPATH:   RIGIN/../lib:/opt/ssh/lib
&gt; &gt;     RPATH:   RIGIN/../lib:/opt/ssh/lib
&gt;
&gt; Indeed looks like missing a quote/escape problem. Does it work with
&gt; other packages using autconf? How? I would suggest adding the quotes in
&gt; the input, i.e., set
&gt;
&gt;   LDFLAGS='-Wl,-runpath,'$$ORIGIN/../lib' -Wl,-runpath,$(prefix)/lib ...'
&gt;
&gt; when running configure.
&gt;
&gt; Since you specify $(prefix), a Makefile-level substitution, and expect
&gt; that to work, it seems reasonable to me to use Makefile-style syntax,
&gt; including needed escapes, also for $ORIGIN.
&gt;
&gt; &gt; I believe the fix is to escape the dollar sign in the makefile. That
&gt; &gt; is, when Nettle creates its makefiles, it must use:
&gt; &gt;
&gt; &gt;     -Wl,-runpath,'$$ORIGIN/../lib' ...
&gt;
&gt; Where do you suggest that substitution be made? And how would Nettle's
&gt; configure script or Makefile know that you intend the $ in '$ORIGIN' to
&gt; be escaped, but not the $ in '$(prefix)' ?
&gt;
&gt; I admit I'm quite skeptical, and I also think it's important to stay
&gt; consistent with how LDFLAGS is handled in other GNU packages. But if
&gt; you can suggest a good way to do it, I'm happy to listen.

You have to fix the makefiles. If you escape the dollar signs in
LDFLAGS, then Autotools will fail its conftests because they don't use
a makefile. Autotools conftests use CFLAGS, LDFLAGS (and friends)
directly.

Run this after you write out your Makefiles. You can probably add it
to configure.ac since configure.ac is just another script.

# We want the leading single quote, and the trailing slash.
origin1=$(echo "'"'$ORIGIN/' | sed -e 's/[\/&amp;]/\\&amp;/g')
origin2=$(echo "'"'$$ORIGIN/' | sed -e 's/[\/&amp;]/\\&amp;/g')

IFS="" find "./" -name 'Makefile' -print | while read -r file
do
    chmod a+w "$file"
    sed -e "s/$origin1/$origin2/g" \
        -e "s/GZIP_ENV = --best/GZIP_ENV = -9/g" \
        "$file" &gt; "$file.fixed"
    mv "$file.fixed" "$file"
    chmod a-w "$file"
done

You can add additional expressions to the sed for $LIB and $PLATFORM.

Don't use 'sed -i' because it is not portable and fails on AIX and OS
X (and possibly others, like the BSDs and BusyBox). Sed to a new file,
and then move the new file to the old file.

The Gzip expression is due to '--best'. That's a GNU extension, and
fails for BusyBox and other non-GNU systems, like Alpine Linux.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200720120408</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-07-20 12:04:08-0400</timestampReceived><subject>Re: Handling of ORIGIN-based rpaths and runpaths</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; You have to fix the makefiles. If you escape the dollar signs in
&gt; LDFLAGS, then Autotools will fail its conftests because they don't use
&gt; a makefile. Autotools conftests use CFLAGS, LDFLAGS (and friends)
&gt; directly.

In that case, how is your "-Wl,-runpath,$(prefix)/lib" handled at that
stage?

I'll reach out to other GNU maintainers to ask for advice. I don't want
to depart much from what others do here.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200717193702</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-07-17 19:37:02-0400</timestampReceived><subject>Re: relocation error: R_AMD64_64</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; I'm seeing a fair amount of "ld: warning: relocation error:
&gt; R_AMD64_64" when linking from nettle-3.6 release tarball:

On what platform, and what version of gcc and linker?

&gt; gcc -g2 -O2 -m64 -march=native -fPIC -pthread -ggdb3 -Wall -W
&gt; -Wno-sign-compare   -Wmissing-prototypes -Wmissing-declarations
&gt; -Wstrict-prototypes   -Wpointer-arith -Wbad-function-cast
&gt; -Wnested-externs -L.. -L/opt/ssh/lib -m64 -Wl,-R,'RIGIN/../lib'
&gt; -Wl,-R,/opt/ssh/lib -Wl,-z,now rsa-sign.o io.o read_rsa_key.o \
&gt; -lhogweed -lnettle -lgmp -ldl -lpthread -o rsa-sign
&gt; ld: warning: relocation error: R_AMD64_64: file ../getopt.o: symbol

Is this command line correct? ../getopt.o doesn't appear on it, only in
the error message.

&gt; optarg: external symbolic relocation against non-allocatable section

optarg is a plain global variable (part of the traditional getopt
interface).

&gt; .debug_info; cannot be processed at runtime: relocation ignored
&gt;
&gt; It looks like getopt was not built correctly.

This all looks strange to me. For AMD64, Nettle is a plain C library, no
linker or assembly magic. And command line options above look reasonable
to me. Do your custom configure arguments matter, i.e., does it work
better with a plain ./configure &amp;&amp; make or ./configure CC='gcc -m64' &amp;&amp;
make?

In general, if you have problems with bulding nettle, gmp, or any other
package, please try configure with plain and documented options before
bug reporting. If that still fails, it will be easier for developers to
understand and reproduce the problem. And if works, it means it's
something in your specific configure setting that triggers the breakage.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200717201016</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-07-17 20:10:16-0400</timestampReceived><subject>Re: Assembly recipe missing ASFLAGS</subject><body>

Hi Everyone,

This one got away too soon. Sorry about that.

I noticed *.s recipes do not use ASFLAGS. ASFLAGS includes -Wa,--noexecstack:

/usr/bin/m4 ./asm.m4 machine.m4 config.m4 aes-decrypt-internal.asm
&gt;aes-decrypt-internal.s
gcc -I. -I/home/jwalton/tmp/ok2delete/include -DNDEBUG -DHAVE_CONFIG_H
-g2 -O2 -march=native -fPIC -pthread -ggdb3 -Wall -W -Wno-sign-compare
  -Wmissing-prototypes -Wmissing-declarations -Wstrict-prototypes
-Wpointer-arith -Wbad-function-cast -Wnested-externs -fpic -MT
aes-decrypt-internal.o -MD -MP -MF aes-decrypt-internal.o.d -c
aes-decrypt-internal.s

aes-decrypt-internal.s should be built using ASFLAGS, too. The recipe
should look something like:

  %.s:
    $(CC) $(CPPFLAGS) $(CFLAGS) $(ASFLAGS) -c $&lt; -o $@

Otherwise, the object file has an executable stack.

Jeff

On Fri, Jul 17, 2020 at 4:05 PM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:
&gt;
&gt; Hi Everyone,
&gt;
&gt; I noticed *.s recipes do not use ASFLAGS. ASFLAGS includes -Wa,--noexecstack:
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200720122254</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-07-20 12:22:54-0400</timestampReceived><subject>Re: Handling of ORIGIN-based rpaths and runpaths</subject><body>

On Mon, Jul 20, 2020 at 8:04 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; Jeffrey Walton &lt;noloader@gmail.com&gt; writes:
&gt;
&gt; &gt; You have to fix the makefiles. If you escape the dollar signs in
&gt; &gt; LDFLAGS, then Autotools will fail its conftests because they don't use
&gt; &gt; a makefile. Autotools conftests use CFLAGS, LDFLAGS (and friends)
&gt; &gt; directly.
&gt;
&gt; In that case, how is your "-Wl,-runpath,$(prefix)/lib" handled at that
&gt; stage?
&gt;
&gt; I'll reach out to other GNU maintainers to ask for advice. I don't want
&gt; to depart much from what others do here.

$(prefix) is expanded to a path. It is no longer a variable.

Here's how my variables look on Ubuntu 18.04:

   PREFIX: /usr/local
   LIBDIR: /usr/local/lib

 AUTOCONF_BUILD: x86_64-pc-linux-gnu
PKG_CONFIG_PATH: /usr/local/lib/pkgconfig
       CPPFLAGS: -I/usr/local/include -DNDEBUG
        ASFLAGS: -Wa,--noexecstack
         CFLAGS: -g2 -O2 -march=native -fPIC -pthread
       CXXFLAGS: -g2 -O2 -march=native -fPIC -pthread
        LDFLAGS: -L/usr/local/lib -Wl,-R,'$ORIGIN/../lib'
-Wl,-R,/usr/local/lib -Wl,--enable-new-dtags -Wl,-z,relro -Wl,-z,now
-Wl,-z,noexecstack -Wl,-z,origin
         LDLIBS: -ldl -lpthread

It looks like Nettle is one of three libraries that don't handle the
rpath tokens well. The other two are Perl and OpenLDAP.

Nettle is pretty easy to fix with editelf and patchelf. I can patch
the programs and libraries after 'make' and 'make check'. Perl and
OpenLDAP resist the fix by building shit during 'make install'. I
don't have access to the programs and libraries at that point.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200720155631</emailId><senderName>Daiki Ueno</senderName><senderEmail>ueno@gnu.org</senderEmail><timestampReceived>2020-07-20 15:56:31-0400</timestampReceived><subject>Re: checking ECC point at infinity</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; I think the point multiplication functions were written under the
&gt; assumption that the scalar should be less than the group order.
&gt; Docs could perhaps be improved on that.
&gt; 
&gt; But I don't known now exactly how it fails. It's good you get the
&gt; valgrind failures, but line numbers don't quite match my version.

I was using the Nettle version installed on the system, sorry.  I'm
attaching the complete log taken with the git master (d1e45e07f).

&gt; If ecc_mul_a can be made to support this, I take it the output will be a
&gt; point with z = 0 (mod p) in homogenenous coordinates. 
&gt; 
&gt; And then the special case z = 0 has to be detected in some way in the
&gt; conversion to affine coordinates. That's done by ecc_j_to_a, but that
&gt; assumes a finite input point, since it inverts z without checking for
&gt; zero.

I think it would be nice if it hits an assertion failure.

&gt; &gt; As it works with the curve order minus 1, I added the following check
&gt; &gt; instead in my library, though I'm not sure if this satisfies the
&gt; &gt; original requirement:
&gt; &gt; 
&gt; &gt; P = (n - 1) * Q
&gt; 
&gt; Checking that (n-1) * Q = -Q should be mathematically equivalent.
&gt; There's a similar test in testsuite/ecc-mul-a-test.c and
&gt; testsuite/ecc-mul-g-test.c (but testing with the generator rather than
&gt; with an arbitrary public key).

Thanks for the pointer and the confirmation; I've tightened the check
based on testsuite/ecc-mul-a-test.c.  For the record, the patch is:
https://gitlab.com/gnutls/gnutls/-/merge_requests/1299/diffs?commit_id=23756c8580dff99d0856adca49dd22a55352ad62


Regards,
-- 
Daiki Ueno



==42307== Memcheck, a memory error detector
==42307== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.
==42307== Using Valgrind-3.16.0 and LibVEX; rerun with -h for copyright info
==42307== Command: ./ecc-test
==42307== Parent PID: 3156
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x48670AA: _nettle_ecc_mul_a (ecc-mul-a.c:145)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485E278: _nettle_sec_tabselect (sec-tabselect.c:54)
==42307==    by 0x486711A: _nettle_ecc_mul_a (ecc-mul-a.c:147)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485F77F: _nettle_ecc_mod_add (ecc-mod-arith.c:53)
==42307==    by 0x4862069: _nettle_ecc_dup_jj (ecc-dup-jj.c:81)
==42307==    by 0x48671E6: _nettle_ecc_mul_a (ecc-mul-a.c:171)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485F83F: _nettle_ecc_mod_sub (ecc-mod-arith.c:64)
==42307==    by 0x4862117: _nettle_ecc_dup_jj (ecc-dup-jj.c:83)
==42307==    by 0x48671E6: _nettle_ecc_mul_a (ecc-mul-a.c:171)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485F83F: _nettle_ecc_mod_sub (ecc-mod-arith.c:64)
==42307==    by 0x486216B: _nettle_ecc_dup_jj (ecc-dup-jj.c:84)
==42307==    by 0x48671E6: _nettle_ecc_mul_a (ecc-mul-a.c:171)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485F77F: _nettle_ecc_mod_add (ecc-mod-arith.c:53)
==42307==    by 0x486219F: _nettle_ecc_dup_jj (ecc-dup-jj.c:87)
==42307==    by 0x48671E6: _nettle_ecc_mul_a (ecc-mul-a.c:171)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485F83F: _nettle_ecc_mod_sub (ecc-mod-arith.c:64)
==42307==    by 0x48621B7: _nettle_ecc_dup_jj (ecc-dup-jj.c:88)
==42307==    by 0x48671E6: _nettle_ecc_mul_a (ecc-mul-a.c:171)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485F8F4: _nettle_ecc_mod_mul_1 (ecc-mod-arith.c:76)
==42307==    by 0x486223F: _nettle_ecc_dup_jj (ecc-dup-jj.c:90)
==42307==    by 0x48671E6: _nettle_ecc_mul_a (ecc-mul-a.c:171)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485F948: _nettle_ecc_mod_mul_1 (ecc-mod-arith.c:79)
==42307==    by 0x486223F: _nettle_ecc_dup_jj (ecc-dup-jj.c:90)
==42307==    by 0x48671E6: _nettle_ecc_mul_a (ecc-mul-a.c:171)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485F8F4: _nettle_ecc_mod_mul_1 (ecc-mod-arith.c:76)
==42307==    by 0x4862323: _nettle_ecc_dup_jj (ecc-dup-jj.c:98)
==42307==    by 0x48671E6: _nettle_ecc_mul_a (ecc-mul-a.c:171)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485F948: _nettle_ecc_mod_mul_1 (ecc-mod-arith.c:79)
==42307==    by 0x4862323: _nettle_ecc_dup_jj (ecc-dup-jj.c:98)
==42307==    by 0x48671E6: _nettle_ecc_mul_a (ecc-mul-a.c:171)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485FB06: _nettle_ecc_mod_submul_1 (ecc-mod-arith.c:106)
==42307==    by 0x486239C: _nettle_ecc_dup_jj (ecc-dup-jj.c:102)
==42307==    by 0x48671E6: _nettle_ecc_mul_a (ecc-mul-a.c:171)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485FB5A: _nettle_ecc_mod_submul_1 (ecc-mod-arith.c:109)
==42307==    by 0x486239C: _nettle_ecc_dup_jj (ecc-dup-jj.c:102)
==42307==    by 0x48671E6: _nettle_ecc_mul_a (ecc-mul-a.c:171)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485F83F: _nettle_ecc_mod_sub (ecc-mod-arith.c:64)
==42307==    by 0x4862426: _nettle_ecc_dup_jj (ecc-dup-jj.c:106)
==42307==    by 0x48671E6: _nettle_ecc_mul_a (ecc-mul-a.c:171)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485FB06: _nettle_ecc_mod_submul_1 (ecc-mod-arith.c:106)
==42307==    by 0x48624C5: _nettle_ecc_dup_jj (ecc-dup-jj.c:108)
==42307==    by 0x48671E6: _nettle_ecc_mul_a (ecc-mul-a.c:171)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485FB5A: _nettle_ecc_mod_submul_1 (ecc-mod-arith.c:109)
==42307==    by 0x48624C5: _nettle_ecc_dup_jj (ecc-dup-jj.c:108)
==42307==    by 0x48671E6: _nettle_ecc_mul_a (ecc-mul-a.c:171)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485E278: _nettle_sec_tabselect (sec-tabselect.c:54)
==42307==    by 0x4867245: _nettle_ecc_mul_a (ecc-mul-a.c:174)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485F83F: _nettle_ecc_mod_sub (ecc-mod-arith.c:64)
==42307==    by 0x4862DFC: _nettle_ecc_add_jjj (ecc-add-jjj.c:81)
==42307==    by 0x486728A: _nettle_ecc_mul_a (ecc-mul-a.c:176)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485F77F: _nettle_ecc_mod_add (ecc-mod-arith.c:53)
==42307==    by 0x4862E49: _nettle_ecc_add_jjj (ecc-add-jjj.c:84)
==42307==    by 0x486728A: _nettle_ecc_mul_a (ecc-mul-a.c:176)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485F83F: _nettle_ecc_mod_sub (ecc-mod-arith.c:64)
==42307==    by 0x4862E78: _nettle_ecc_add_jjj (ecc-add-jjj.c:86)
==42307==    by 0x486728A: _nettle_ecc_mul_a (ecc-mul-a.c:176)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485F83F: _nettle_ecc_mod_sub (ecc-mod-arith.c:64)
==42307==    by 0x4862E90: _nettle_ecc_add_jjj (ecc-add-jjj.c:87)
==42307==    by 0x486728A: _nettle_ecc_mul_a (ecc-mul-a.c:176)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485F83F: _nettle_ecc_mod_sub (ecc-mod-arith.c:64)
==42307==    by 0x4862F8A: _nettle_ecc_add_jjj (ecc-add-jjj.c:96)
==42307==    by 0x486728A: _nettle_ecc_mul_a (ecc-mul-a.c:176)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485F8F4: _nettle_ecc_mod_mul_1 (ecc-mod-arith.c:76)
==42307==    by 0x4862FA3: _nettle_ecc_add_jjj (ecc-add-jjj.c:97)
==42307==    by 0x486728A: _nettle_ecc_mul_a (ecc-mul-a.c:176)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485F948: _nettle_ecc_mod_mul_1 (ecc-mod-arith.c:79)
==42307==    by 0x4862FA3: _nettle_ecc_add_jjj (ecc-add-jjj.c:97)
==42307==    by 0x486728A: _nettle_ecc_mul_a (ecc-mul-a.c:176)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485F8F4: _nettle_ecc_mod_mul_1 (ecc-mod-arith.c:76)
==42307==    by 0x486300B: _nettle_ecc_add_jjj (ecc-add-jjj.c:104)
==42307==    by 0x486728A: _nettle_ecc_mul_a (ecc-mul-a.c:176)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485F948: _nettle_ecc_mod_mul_1 (ecc-mod-arith.c:79)
==42307==    by 0x486300B: _nettle_ecc_add_jjj (ecc-add-jjj.c:104)
==42307==    by 0x486728A: _nettle_ecc_mul_a (ecc-mul-a.c:176)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485F83F: _nettle_ecc_mod_sub (ecc-mod-arith.c:64)
==42307==    by 0x486306A: _nettle_ecc_add_jjj (ecc-add-jjj.c:111)
==42307==    by 0x486728A: _nettle_ecc_mul_a (ecc-mul-a.c:176)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485FB06: _nettle_ecc_mod_submul_1 (ecc-mod-arith.c:106)
==42307==    by 0x4863083: _nettle_ecc_add_jjj (ecc-add-jjj.c:112)
==42307==    by 0x486728A: _nettle_ecc_mul_a (ecc-mul-a.c:176)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485FB5A: _nettle_ecc_mod_submul_1 (ecc-mod-arith.c:109)
==42307==    by 0x4863083: _nettle_ecc_add_jjj (ecc-add-jjj.c:112)
==42307==    by 0x486728A: _nettle_ecc_mul_a (ecc-mul-a.c:176)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485F83F: _nettle_ecc_mod_sub (ecc-mod-arith.c:64)
==42307==    by 0x48630B3: _nettle_ecc_add_jjj (ecc-add-jjj.c:116)
==42307==    by 0x486728A: _nettle_ecc_mul_a (ecc-mul-a.c:176)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485FB06: _nettle_ecc_mod_submul_1 (ecc-mod-arith.c:106)
==42307==    by 0x48630E4: _nettle_ecc_add_jjj (ecc-add-jjj.c:118)
==42307==    by 0x486728A: _nettle_ecc_mul_a (ecc-mul-a.c:176)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485FB5A: _nettle_ecc_mod_submul_1 (ecc-mod-arith.c:109)
==42307==    by 0x48630E4: _nettle_ecc_add_jjj (ecc-add-jjj.c:118)
==42307==    by 0x486728A: _nettle_ecc_mul_a (ecc-mul-a.c:176)
==42307==    by 0x4867D0F: nettle_ecc_point_mul (ecc-point-mul.c:56)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485F577: _nettle_ecc_mod_inv (ecc-mod-inv.c:148)
==42307==    by 0x48619DB: _nettle_ecc_j_to_a (ecc-j-to-a.c:70)
==42307==    by 0x4867D54: nettle_ecc_point_mul (ecc-point-mul.c:57)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485F5BA: _nettle_ecc_mod_inv (ecc-mod-inv.c:151)
==42307==    by 0x48619DB: _nettle_ecc_j_to_a (ecc-j-to-a.c:70)
==42307==    by 0x4867D54: nettle_ecc_point_mul (ecc-point-mul.c:57)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485F66A: _nettle_ecc_mod_inv (ecc-mod-inv.c:154)
==42307==    by 0x48619DB: _nettle_ecc_j_to_a (ecc-j-to-a.c:70)
==42307==    by 0x4867D54: nettle_ecc_point_mul (ecc-point-mul.c:57)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485F3F3: _nettle_ecc_mod_inv (ecc-mod-inv.c:138)
==42307==    by 0x48619DB: _nettle_ecc_j_to_a (ecc-j-to-a.c:70)
==42307==    by 0x4867D54: nettle_ecc_point_mul (ecc-point-mul.c:57)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x485F6BF: _nettle_ecc_mod_inv (ecc-mod-inv.c:156)
==42307==    by 0x48619DB: _nettle_ecc_j_to_a (ecc-j-to-a.c:70)
==42307==    by 0x4867D54: nettle_ecc_point_mul (ecc-point-mul.c:57)
==42307==    by 0x4012EB: main (ecc-test.c:36)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x492EE5C: __gmpz_limbs_finish (in /usr/lib64/libgmp.so.10.3.2)
==42307==    by 0x485E66A: _nettle_mpz_set_n (gmp-glue.c:111)
==42307==    by 0x4867A80: nettle_ecc_point_get (ecc-point.c:131)
==42307==    by 0x40131A: main (ecc-test.c:41)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x492EE54: __gmpz_limbs_finish (in /usr/lib64/libgmp.so.10.3.2)
==42307==    by 0x485E66A: _nettle_mpz_set_n (gmp-glue.c:111)
==42307==    by 0x4867A80: nettle_ecc_point_get (ecc-point.c:131)
==42307==    by 0x40131A: main (ecc-test.c:41)
==42307== 
==42307== Use of uninitialised value of size 8
==42307==    at 0x492EE54: __gmpz_limbs_finish (in /usr/lib64/libgmp.so.10.3.2)
==42307==    by 0x485E66A: _nettle_mpz_set_n (gmp-glue.c:111)
==42307==    by 0x4867A80: nettle_ecc_point_get (ecc-point.c:131)
==42307==    by 0x40131A: main (ecc-test.c:41)
==42307== 
==42307== Use of uninitialised value of size 8
==42307==    at 0x492EE56: __gmpz_limbs_finish (in /usr/lib64/libgmp.so.10.3.2)
==42307==    by 0x485E66A: _nettle_mpz_set_n (gmp-glue.c:111)
==42307==    by 0x4867A80: nettle_ecc_point_get (ecc-point.c:131)
==42307==    by 0x40131A: main (ecc-test.c:41)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x492EE5C: __gmpz_limbs_finish (in /usr/lib64/libgmp.so.10.3.2)
==42307==    by 0x485E66A: _nettle_mpz_set_n (gmp-glue.c:111)
==42307==    by 0x4867AAE: nettle_ecc_point_get (ecc-point.c:133)
==42307==    by 0x40131A: main (ecc-test.c:41)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x492EE54: __gmpz_limbs_finish (in /usr/lib64/libgmp.so.10.3.2)
==42307==    by 0x485E66A: _nettle_mpz_set_n (gmp-glue.c:111)
==42307==    by 0x4867AAE: nettle_ecc_point_get (ecc-point.c:133)
==42307==    by 0x40131A: main (ecc-test.c:41)
==42307== 
==42307== Use of uninitialised value of size 8
==42307==    at 0x492EE54: __gmpz_limbs_finish (in /usr/lib64/libgmp.so.10.3.2)
==42307==    by 0x485E66A: _nettle_mpz_set_n (gmp-glue.c:111)
==42307==    by 0x4867AAE: nettle_ecc_point_get (ecc-point.c:133)
==42307==    by 0x40131A: main (ecc-test.c:41)
==42307== 
==42307== Use of uninitialised value of size 8
==42307==    at 0x492EE56: __gmpz_limbs_finish (in /usr/lib64/libgmp.so.10.3.2)
==42307==    by 0x485E66A: _nettle_mpz_set_n (gmp-glue.c:111)
==42307==    by 0x4867AAE: nettle_ecc_point_get (ecc-point.c:133)
==42307==    by 0x40131A: main (ecc-test.c:41)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x401320: main (ecc-test.c:42)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x401327: main (ecc-test.c:42)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x401347: main (ecc-test.c:43)
==42307== 
==42307== Conditional jump or move depends on uninitialised value(s)
==42307==    at 0x40134E: main (ecc-test.c:43)
==42307== 
==42307== 
==42307== HEAP SUMMARY:
==42307==     in use at exit: 0 bytes in 0 blocks
==42307==   total heap usage: 11 allocs, 11 frees, 2,304 bytes allocated
==42307== 
==42307== All heap blocks were freed -- no leaks are possible
==42307== 
==42307== Use --track-origins=yes to see where uninitialised values come from
==42307== For lists of detected and suppressed errors, rerun with: -s
==42307== ERROR SUMMARY: 6602 errors from 49 contexts (suppressed: 0 from 0)

[Attachment #4 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200720170816</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-07-20 17:08:16-0400</timestampReceived><subject>Re: [PowerPC64] Add AIX to cpu detection</subject><body>

The current assembly implementations for ppc support only AES and GCM,
those implementations take advantage of crypto extensions that
introduced in POWER8. It may be good in the future to extend the detection
to VSX and arch 3.00 ...etc if more algorithms are implemented but for now
I think this is fine.

On Mon, Jul 20, 2020 at 7:34 PM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:

&gt; On Mon, Jul 20, 2020 at 12:18 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
&gt; wrote:
&gt; &gt;
&gt; &gt; ---
&gt; &gt;  fat-ppc.c | 29 ++++++++++++++++++++---------
&gt; &gt;  1 file changed, 20 insertions(+), 9 deletions(-)
&gt; &gt;
&gt; &gt; diff --git a/fat-ppc.c b/fat-ppc.c
&gt; &gt; index e09b2097..eca689fe 100644
&gt; &gt; --- a/fat-ppc.c
&gt; &gt; +++ b/fat-ppc.c
&gt; &gt; @@ -39,10 +39,17 @@
&gt; &gt;  #include &lt;stdio.h&gt;
&gt; &gt;  #include &lt;stdlib.h&gt;
&gt; &gt;  #include &lt;string.h&gt;
&gt; &gt; -#if defined(__FreeBSD__) &amp;&amp; __FreeBSD__ &lt; 12
&gt; &gt; -#include &lt;sys/sysctl.h&gt;
&gt; &gt; -#else
&gt; &gt; +
&gt; &gt; +#if defined(_AIX)
&gt; &gt; +#include &lt;sys/systemcfg.h&gt;
&gt; &gt; +#elif defined(__linux__)
&gt; &gt; +#include &lt;sys/auxv.h&gt;
&gt; &gt; +#elif defined(__FreeBSD__)
&gt; &gt; +#if __FreeBSD__ &gt;= 12
&gt; &gt;  #include &lt;sys/auxv.h&gt;
&gt; &gt; +#else
&gt; &gt; +#include &lt;sys/sysctl.h&gt;
&gt; &gt; +#endif
&gt; &gt;  #endif
&gt; &gt;
&gt; &gt;  #include "nettle-types.h"
&gt; &gt; @@ -64,19 +71,23 @@ struct ppc_features
&gt; &gt;  static void
&gt; &gt;  get_ppc_features (struct ppc_features *features)
&gt; &gt;  {
&gt; &gt; +#if defined(_AIX) &amp;&amp; defined(__power_8_andup)
&gt; &gt; +  features-&gt;have_crypto_ext = __power_8_andup() != 0 ? 1 : 0;
&gt; &gt; +#else
&gt; &gt;    unsigned long hwcap2 = 0;
&gt; &gt; -#if defined(__FreeBSD__)
&gt; &gt; -#if __FreeBSD__ &lt; 12
&gt; &gt; +#if defined(__linux__)
&gt; &gt; +  hwcap2 = getauxval(AT_HWCAP2);
&gt; &gt; +#elif defined(__FreeBSD__)
&gt; &gt; +#if __FreeBSD__ &gt;= 12
&gt; &gt; +  elf_aux_info(AT_HWCAP2, &amp;hwcap2, sizeof(hwcap2));
&gt; &gt; +#else
&gt; &gt;    size_t len = sizeof(hwcap2);
&gt; &gt;    sysctlbyname("hw.cpu_features2", &amp;hwcap2, &amp;len, NULL, 0);
&gt; &gt; -#else
&gt; &gt; -  elf_aux_info(AT_HWCAP2, &amp;hwcap2, sizeof(hwcap2));
&gt; &gt;  #endif
&gt; &gt; -#else
&gt; &gt; -  hwcap2 = getauxval(AT_HWCAP2);
&gt; &gt;  #endif
&gt; &gt;    features-&gt;have_crypto_ext =
&gt; &gt;     (hwcap2 &amp; PPC_FEATURE2_VEC_CRYPTO) == PPC_FEATURE2_VEC_CRYPTO ? 1 :
&gt; 0;
&gt; &gt; +#endif
&gt; &gt;  }
&gt; &gt;
&gt; &gt;  DECLARE_FAT_FUNC(_nettle_aes_encrypt, aes_crypt_internal_func)
&gt; &gt; --
&gt; &gt; 2.17.1
&gt;
&gt; Hi Maamon,
&gt;
&gt; One small comment...
&gt;
&gt; You may want to stay flexible enough to detect POWER7, VSX and above.
&gt; ChaCha is fast as hell even on POWER7 and without 64-bit vectors. In
&gt; fact, I found ChaCha is profitable down to POWER4 on an old PowerMac.
&gt;
&gt; Jeff
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200721102614</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2020-07-21 10:26:14-0400</timestampReceived><subject>Re: Add ppc64le arch to Gitlab CI</subject><body>

Hello Niels,

On Tue, Jun 23, 2020 at 09:50:20AM +0200, Niels Möller wrote:

&gt; &gt; I investigated this issue. The Debian image used for Gitlab CI only
&gt; &gt; supports the following archs amd64 mips armhf arm64. To add a new arch,
&gt; &gt; this arch should be added to the sources list of apt and install the
&gt; &gt; required packages to build and check nettle library.
&gt; Looks like the image is defined here:
&gt; https://gitlab.com/gnutls/build-images/-/blob/master/docker-debian-cross/Dockerfile

&gt; Nikos, Michael, can we just add ppc64el to the ARCHES and TRIPLES lists
&gt; there?

Sorry for the delay: In principile yes but as you've noticed already,
the number of supported drop-in architectures is limited. I had
additional unofficial architectures supported when developing the
mechanism but it wasn't as straight-forward and prone to breakage. Therefore
it did not make it upstream into GnuTLS's build-images.

If I understood the rest of the thread correctly, you've found a
workaround using a cross-package, which seems a better way to go than
fiddling with the unofficial architecture support, particularly if you
do not want to or cannot change the build-images repo.

For reference: This GnuTLS .gitlab-ci.yml has ppc64le support from way
back when: https://gitlab.com/michaelweiser/gnutls/-/blob/debian/.gitlab-ci.yml
and here's the corresponding build-images Dockefile:
https://gitlab.com/michaelweiser/build-images/-/blob/cross/docker-debian-cross/Dockerfile.
It seems, I had ppc64le in there and without much hassle as well. YMMV.
-- 
Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200722143349</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-07-22 14:33:49-0400</timestampReceived><subject>Re: Optimizing salsa20</subject><body>

Michael Weiser &lt;michael.weiser@gmx.de&gt; writes:

&gt; sorry for the delay - I've been on vacation.

No problem. If you can test and debug arm big-endian, that's apprecated.

&gt; We still have the ARM BE CI ready to go. Is it maybe time to get it
&gt; activated on GitLab? I've put it in an MR for reference
&gt; (https://git.lysator.liu.se/nettle/nettle/-/merge_requests/8) but can
&gt; also submit via the list once we've decided where to put the container
&gt; images for good. I'd still vote for GnuTLS's build-images, as the
&gt; others.

If the gnutls people are willing to host it, that would be nice. Do you
think that can happen soon? Otherwise, I'd be happy to merge as is.

I think Nikos wrote a while back that he's less active in gnutls, so I'm
not sure who we'd need to coordinate with. (And I haven't followed all
the details in how you generate the buildroot images).

BTW, I've noticed that the debian qemu-user package does include
qemu-armeb, but still no packaged armeb cross compiler, as far as I'm
aware.

&gt; master indeed fails:
&gt;
&gt; https://gitlab.com/michaelweiser/nettle/-/jobs/648334928
&gt;
&gt; libnettle: cpu features: arch:6,neon
&gt; libnettle: enabling armv6 code.
&gt; libnettle: enabling neon code.
&gt; Assert failed: testutils.c:831: MEMEQ(length, data, ciphertext-&gt;data)
&gt; qemu: uncaught target signal 6 (Aborted) - core dumped
&gt; Aborted (core dumped)
&gt; FAIL: chacha-poly1305
&gt;
&gt; Is this about what you've expected? Then I'll look into it.

I expect anything calling the new functions _chacha_3core and
_salsa_2core to fail. Easiest way to debug and fix is to run the test
cases salsa-20-test and chacha-test, they're exercised by the functions
test_chacha_core and test_salsa20_core I added to the tests recently. 

Those tests have the advantage that they set the input to 0,1,2,...,15
(except one counter word is set to 0xffffffff, to test carry
propagation), so it should be fairly easy to follow the permutations at
the top of the functions. At least, I've found that very helpful when
debugging the most recent neon and x86 code.

_chacha_3core interleaves three blocks with 4 separate state registers
for each block, so big-endian fixes should be very similar to what
you've done for _chacha_core (which I believe is still in working
shape). _salsa20_2core, on the other hand, uses a bit different register
allocation, each register holding corresponding words from two input
blocks.

&gt; Any other branches I should try?

The new code has been pushed to master, so that's the most relevant
branch.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200731184010</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-07-31 18:40:10-0400</timestampReceived><subject>Re: [PATCH] "PowerPC64" Add README</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt;  powerpc64/README | 86

Hi, this patch still has lien break problems, e.g.,

&gt; +GPR11   volatile    In calls by pointer and as an environment pointer for
&gt; languages
&gt; +    that require it (for example, PASCAL).

this line break makes it invalid patch syntax. Unclear to me where and
why that happens; the mail was sent using

Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: base64

so MTAs on the way won't care about line length. I could fix it manually
and apply, but maybe it's better to reformat the README file to keep
line length limited to 72 or so characters.

You could also have a look at the x86_64/README and arm/README files, to
use the same table style, e.g.,

Registers	May be		Argument
		clobbered	number

r0		Y		1
r1		Y		2
r2		Y		3
r3		Y		4
r4		N

(Not essential, but consistency would make it a bit easier for readers).

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200731184209</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-07-31 18:42:09-0400</timestampReceived><subject>Re: [PATCH 2/6] "PowerPC64" Add optimized AES [Enc|Dec]</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; Yes, both are part of the same extension. I considered calling the
&gt; directory "P8" for three reasons:
&gt; - POWER8 is the minimal processor that support the crypto extensions
&gt; - I measured the throughput and latency of the instructions on POWER8
&gt; - The current implementations can be enhanced further for POWER9 and newer
&gt; by using arch 3.00 specific instructions which was introduced in POWER9 so
&gt; we can call the directory of new implementations "P9"

Ok, let's stay with that naming (but I'll consider changing to lowercase
"p8", to match other directory names). If it turns out something more
fine grained is needed later, files can be mover around then.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200602054551</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-06-02 05:45:51-0400</timestampReceived><subject>Re: nettle-benchmark hangs at startup w/ 100% cpu</subject><body>

Daniel P. Berrangé &lt;berrange@redhat.com&gt; writes:

&gt; Alternatively adding __attribute__((noinline))  to "time_function"
&gt; fixes it - nb noinline on "bench_nothing" does NOT fix it.

I've now deleted the problematic code.

I would guess the reason the compiler thinks it can optimize away the
entire loop in time_function is that after inlining, it finds that the
loop body, f(arg), has no side effects. It will hopefully not do the
same with any other functions in the benchmark.

&gt; Alternatively adding   assert(ncalls != 0);  in the loop in time_function
&gt; fixes it, because causing GCC to stop inlining it. That's largely luck,
&gt; but it probably makes sense to have that assert() added regardless as
&gt; this loop is inherantly susceptible to this wraparound problem as written.

It would be more robust to check if ncalls is about to overflow, and in
that case let time_function return 0.0. I'll consider that if any
similar problems reappear.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200602104536</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-06-02 10:45:36-0400</timestampReceived><subject>[PATCH v2 4/8] hmac: add support for streebog256/512 hash function</subject><body>

Add support for calculating HMAC using Streebog hash functions.

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 Makefile.in               |  4 +--
 hmac-streebog-meta.c      | 56 ++++++++++++++++++++++++++++++
 hmac-streebog.c           | 73 +++++++++++++++++++++++++++++++++++++++
 hmac.h                    | 33 ++++++++++++++++++
 nettle-meta-macs.c        |  2 ++
 nettle-meta.h             |  2 ++
 testsuite/hmac-test.c     | 17 +++++++++
 testsuite/meta-mac-test.c |  2 ++
 8 files changed, 187 insertions(+), 2 deletions(-)
 create mode 100644 hmac-streebog-meta.c
 create mode 100644 hmac-streebog.c

diff --git a/Makefile.in b/Makefile.in
index c36764dc4c45..64ff10018af0 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -107,10 +107,10 @@ nettle_SOURCES = aes-decrypt-internal.c aes-decrypt.c \
 		 gost28147.c gosthash94.c gosthash94-meta.c \
 		 hmac.c hmac-gosthash94.c hmac-md5.c hmac-ripemd160.c \
 		 hmac-sha1.c hmac-sha224.c hmac-sha256.c hmac-sha384.c \
-		 hmac-sha512.c \
+		 hmac-sha512.c hmac-streebog.c \
 		 hmac-md5-meta.c hmac-ripemd160-meta.c hmac-sha1-meta.c \
 		 hmac-sha224-meta.c hmac-sha256-meta.c hmac-sha384-meta.c \
-		 hmac-sha512-meta.c \
+		 hmac-sha512-meta.c hmac-streebog-meta.c \
 		 knuth-lfib.c hkdf.c \
 		 md2.c md2-meta.c md4.c md4-meta.c \
 		 md5.c md5-compress.c md5-compat.c md5-meta.c \
diff --git a/hmac-streebog-meta.c b/hmac-streebog-meta.c
new file mode 100644
index 000000000000..d6028307aa5a
--- /dev/null
+++ b/hmac-streebog-meta.c
@@ -0,0 +1,56 @@
+/* hmac-streebog-meta.c
+
+   Copyright (C) 2020 Dmitry Baryshkov
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include "nettle-meta.h"
+
+#include "hmac.h"
+
+static void
+hmac_streebog256_set_key_wrapper (void *ctx, const uint8_t *key)
+{
+  hmac_streebog256_set_key (ctx, STREEBOG256_DIGEST_SIZE, key);
+}
+
+const struct nettle_mac nettle_hmac_streebog256
+= _NETTLE_HMAC(hmac_streebog256, STREEBOG256);
+
+static void
+hmac_streebog512_set_key_wrapper (void *ctx, const uint8_t *key)
+{
+  hmac_streebog512_set_key (ctx, STREEBOG512_DIGEST_SIZE, key);
+}
+
+const struct nettle_mac nettle_hmac_streebog512
+= _NETTLE_HMAC(hmac_streebog512, STREEBOG512);
diff --git a/hmac-streebog.c b/hmac-streebog.c
new file mode 100644
index 000000000000..3b07b95da936
--- /dev/null
+++ b/hmac-streebog.c
@@ -0,0 +1,73 @@
+/* hmac-streebog.c
+
+   HMAC-Streebog message authentication code.
+
+   Copyright (C) 2016 Dmitry Eremin-Solenikov
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include "hmac.h"
+
+void
+hmac_streebog512_set_key(struct hmac_streebog512_ctx *ctx,
+			 size_t key_length, const uint8_t *key)
+{
+  HMAC_SET_KEY(ctx, &amp;nettle_streebog512, key_length, key);
+}
+
+void
+hmac_streebog512_update(struct hmac_streebog512_ctx *ctx,
+			size_t length, const uint8_t *data)
+{
+  streebog512_update(&amp;ctx-&gt;state, length, data);
+}
+
+void
+hmac_streebog512_digest(struct hmac_streebog512_ctx *ctx,
+			size_t length, uint8_t *digest)
+{
+  HMAC_DIGEST(ctx, &amp;nettle_streebog512, length, digest);
+}
+
+void
+hmac_streebog256_set_key(struct hmac_streebog256_ctx *ctx,
+			 size_t key_length, const uint8_t *key)
+{
+  HMAC_SET_KEY(ctx, &amp;nettle_streebog256, key_length, key);
+}
+
+void
+hmac_streebog256_digest(struct hmac_streebog256_ctx *ctx,
+			size_t length, uint8_t *digest)
+{
+  HMAC_DIGEST(ctx, &amp;nettle_streebog256, length, digest);
+}
diff --git a/hmac.h b/hmac.h
index d9ee3400108d..72c8fd5768c4 100644
--- a/hmac.h
+++ b/hmac.h
@@ -41,6 +41,7 @@
 #include "ripemd160.h"
 #include "sha1.h"
 #include "sha2.h"
+#include "streebog.h"
 
 #ifdef __cplusplus
 extern "C" {
@@ -75,6 +76,11 @@ extern "C" {
 #define hmac_gosthash94cp_set_key nettle_hmac_gosthash94cp_set_key
 #define hmac_gosthash94cp_update nettle_hmac_gosthash94cp_update
 #define hmac_gosthash94cp_digest nettle_hmac_gosthash94cp_digest
+#define hmac_streebog256_set_key nettle_hmac_streebog256_set_key
+#define hmac_streebog256_digest nettle_hmac_streebog256_digest
+#define hmac_streebog512_set_key nettle_hmac_streebog512_set_key
+#define hmac_streebog512_update nettle_hmac_streebog512_update
+#define hmac_streebog512_digest nettle_hmac_streebog512_digest
 
 void
 hmac_set_key(void *outer, void *inner, void *state,
@@ -240,6 +246,33 @@ hmac_gosthash94cp_digest(struct hmac_gosthash94cp_ctx *ctx,
 			 size_t length, uint8_t *digest);
 
 
+/* hmac-streebog */
+struct hmac_streebog512_ctx HMAC_CTX(struct streebog512_ctx);
+
+void
+hmac_streebog512_set_key(struct hmac_streebog512_ctx *ctx,
+		    size_t key_length, const uint8_t *key);
+
+void
+hmac_streebog512_update(struct hmac_streebog512_ctx *ctx,
+		   size_t length, const uint8_t *data);
+
+void
+hmac_streebog512_digest(struct hmac_streebog512_ctx *ctx,
+		   size_t length, uint8_t *digest);
+
+#define hmac_streebog256_ctx hmac_streebog512_ctx
+
+void
+hmac_streebog256_set_key(struct hmac_streebog256_ctx *ctx,
+		    size_t key_length, const uint8_t *key);
+
+#define hmac_streebog256_update hmac_streebog512_update
+
+void
+hmac_streebog256_digest(struct hmac_streebog256_ctx *ctx,
+		   size_t length, uint8_t *digest);
+
 #ifdef __cplusplus
 }
 #endif
diff --git a/nettle-meta-macs.c b/nettle-meta-macs.c
index a658ee39e230..5e8f871329bb 100644
--- a/nettle-meta-macs.c
+++ b/nettle-meta-macs.c
@@ -48,6 +48,8 @@ const struct nettle_mac * const _nettle_macs[] = {
   &amp;nettle_hmac_sha256,
   &amp;nettle_hmac_sha384,
   &amp;nettle_hmac_sha512,
+  &amp;nettle_hmac_streebog256,
+  &amp;nettle_hmac_streebog512,
   NULL
 };
 
diff --git a/nettle-meta.h b/nettle-meta.h
index 7a6af363426b..cbcb1e5d5ffb 100644
--- a/nettle-meta.h
+++ b/nettle-meta.h
@@ -286,6 +286,8 @@ extern const struct nettle_mac nettle_hmac_sha224;
 extern const struct nettle_mac nettle_hmac_sha256;
 extern const struct nettle_mac nettle_hmac_sha384;
 extern const struct nettle_mac nettle_hmac_sha512;
+extern const struct nettle_mac nettle_hmac_streebog256;
+extern const struct nettle_mac nettle_hmac_streebog512;
 
 #ifdef __cplusplus
 }
diff --git a/testsuite/hmac-test.c b/testsuite/hmac-test.c
index de1b6bfe057c..348f7920add9 100644
--- a/testsuite/hmac-test.c
+++ b/testsuite/hmac-test.c
@@ -866,4 +866,21 @@ test_main(void)
 	    SHEX("0126bdb87800af214341456563780100"),
 	    SHEX("bad70b61c41095bc47e1141cfaed4272"
 		 "6a5ceebd62ce75dbbb9ad76cda9f72f7"));
+
+  /* RFC 7836 */
+  HMAC_TEST(streebog512,
+	    SHEX("000102030405060708090a0b0c0d0e0f"
+		 "101112131415161718191a1b1c1d1e1f"),
+	    SHEX("0126bdb87800af214341456563780100"),
+	    SHEX("a59bab22ecae19c65fbde6e5f4e9f5d8"
+	         "549d31f037f9df9b905500e171923a77"
+		 "3d5f1530f2ed7e964cb2eedc29e9ad2f"
+		 "3afe93b2814f79f5000ffc0366c251e6"));
+
+  HMAC_TEST(streebog256,
+	    SHEX("000102030405060708090a0b0c0d0e0f"
+		 "101112131415161718191a1b1c1d1e1f"),
+	    SHEX("0126bdb87800af214341456563780100"),
+	    SHEX("a1aa5f7de402d7b3d323f2991c8d4534"
+	         "013137010a83754fd0af6d7cd4922ed9"));
 }
diff --git a/testsuite/meta-mac-test.c b/testsuite/meta-mac-test.c
index 55339441c99f..adbd43263801 100644
--- a/testsuite/meta-mac-test.c
+++ b/testsuite/meta-mac-test.c
@@ -12,6 +12,8 @@ const char* macs[] = {
   "hmac_sha256",
   "hmac_sha384",
   "hmac_sha512",
+  "hmac_streebog256",
+  "hmac_streebog512",
 };
 
 void
-- 
2.26.2

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200602104537</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-06-02 10:45:37-0400</timestampReceived><subject>[PATCH v2 5/8] fixup! Implement GOST R 34.11-2012 (Streebog) hash function</subject><body>

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 nettle-meta-hashes.c       | 2 ++
 nettle-meta.h              | 2 ++
 testsuite/meta-hash-test.c | 2 ++
 3 files changed, 6 insertions(+)

diff --git a/nettle-meta-hashes.c b/nettle-meta-hashes.c
index 27b576cdc58c..8e96dd414d23 100644
--- a/nettle-meta-hashes.c
+++ b/nettle-meta-hashes.c
@@ -53,6 +53,8 @@ const struct nettle_hash * const _nettle_hashes[] = {
   &amp;nettle_sha3_256,
   &amp;nettle_sha3_384,
   &amp;nettle_sha3_512,
+  &amp;nettle_streebog256,
+  &amp;nettle_streebog512,
   NULL
 };
 
diff --git a/nettle-meta.h b/nettle-meta.h
index cbcb1e5d5ffb..6a62b653efa6 100644
--- a/nettle-meta.h
+++ b/nettle-meta.h
@@ -143,6 +143,8 @@ extern const struct nettle_hash nettle_sha3_224;
 extern const struct nettle_hash nettle_sha3_256;
 extern const struct nettle_hash nettle_sha3_384;
 extern const struct nettle_hash nettle_sha3_512;
+extern const struct nettle_hash nettle_streebog256;
+extern const struct nettle_hash nettle_streebog512;
 
 struct nettle_mac
 {
diff --git a/testsuite/meta-hash-test.c b/testsuite/meta-hash-test.c
index 7d863a7c386d..eb9f3698e353 100644
--- a/testsuite/meta-hash-test.c
+++ b/testsuite/meta-hash-test.c
@@ -20,6 +20,8 @@ const char* hashes[] = {
   "sha3_256",
   "sha3_384",
   "sha3_512",
+  "streebog256",
+  "streebog512"
 };
 
 void
-- 
2.26.2

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200602104538</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-06-02 10:45:38-0400</timestampReceived><subject>[PATCH v2 6/8] nettle-benchmark: bench Streebog hashes</subject><body>

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 examples/nettle-benchmark.c | 3 ++-
 1 file changed, 2 insertions(+), 1 deletion(-)

diff --git a/examples/nettle-benchmark.c b/examples/nettle-benchmark.c
index 69e34bfd7c9e..1ca277dd0651 100644
--- a/examples/nettle-benchmark.c
+++ b/examples/nettle-benchmark.c
@@ -901,7 +901,8 @@ main(int argc, char **argv)
       &amp;nettle_sha3_224, &amp;nettle_sha3_256,
       &amp;nettle_sha3_384, &amp;nettle_sha3_512,
       &amp;nettle_ripemd160, &amp;nettle_gosthash94,
-      &amp;nettle_gosthash94cp,
+      &amp;nettle_gosthash94cp, &amp;nettle_streebog256,
+      &amp;nettle_streebog512,
       NULL
     };
 
-- 
2.26.2

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200602104534</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-06-02 10:45:34-0400</timestampReceived><subject>[PATCH v2 2/8] testsuite: add test for Streebog hash function</subject><body>

Add a testuite for Streebog hash function. Test vectors are based on RFC
6986.

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 testsuite/.gitignore      |  1 +
 testsuite/Makefile.in     |  2 +-
 testsuite/streebog-test.c | 90 +++++++++++++++++++++++++++++++++++++++
 3 files changed, 92 insertions(+), 1 deletion(-)
 create mode 100644 testsuite/streebog-test.c

diff --git a/testsuite/.gitignore b/testsuite/.gitignore
index a2b3d52312cd..280ee45b0dee 100644
--- a/testsuite/.gitignore
+++ b/testsuite/.gitignore
@@ -96,6 +96,7 @@
 /sha512-224-test
 /sha512-256-test
 /sha512-test
+/streebog-test
 /twofish-test
 /umac-test
 /version-test
diff --git a/testsuite/Makefile.in b/testsuite/Makefile.in
index 3f5e5f6b995c..c66e139eee62 100644
--- a/testsuite/Makefile.in
+++ b/testsuite/Makefile.in
@@ -24,7 +24,7 @@ TS_NETTLE_SOURCES = aes-test.c arcfour-test.c arctwo-test.c \
 		    sha384-test.c sha512-test.c sha512-224-test.c sha512-256-test.c \
 		    sha3-permute-test.c sha3-224-test.c sha3-256-test.c \
 		    sha3-384-test.c sha3-512-test.c \
-		    shake256-test.c \
+		    shake256-test.c streebog-test.c \
 		    serpent-test.c twofish-test.c version-test.c \
 		    knuth-lfib-test.c \
 		    cbc-test.c cfb-test.c ctr-test.c gcm-test.c eax-test.c ccm-test.c \
diff --git a/testsuite/streebog-test.c b/testsuite/streebog-test.c
new file mode 100644
index 000000000000..350385d6b479
--- /dev/null
+++ b/testsuite/streebog-test.c
@@ -0,0 +1,90 @@
+#include "testutils.h"
+#include "streebog.h"
+
+void
+test_main(void)
+{
+  /* Using test vectors from the standard itself */
+
+  /* RFC 6986 provides all data in "Integer" big-endian format, while all
+   * constructs expects the data in little-endian format. Thus these examples
+   * (as the rest of the code) has data buffers reversed compared to the RFC
+   * 6986. */
+  /* 10.1.1 */
+  test_hash(&amp;nettle_streebog512,
+            SDATA("012345678901234567890123456789012345678901234567890123456789012"),
+            SHEX("1b54d01a4af5b9d5 cc3d86d68d285462"
+                 "b19abc2475222f35 c085122be4ba1ffa"
+                 "00ad30f8767b3a82 384c6574f024c311"
+                 "e2a481332b08ef7f 41797891c1646f48"));
+
+  /* 10.1.2 */
+  test_hash(&amp;nettle_streebog256,
+            SDATA("012345678901234567890123456789012345678901234567890123456789012"),
+            SHEX("9d151eefd8590b89 daa6ba6cb74af927"
+                 "5dd051026bb149a4 52fd84e5e57b5500"));
+
+  /* 10.2.1 */
+  test_hash(&amp;nettle_streebog512,
+            SHEX("d1e520e2e5f2f0e82c20d1f2f0e8e1ee"
+                 "e6e820e2edf3f6e82c20e2e5fef2fa20"
+                 "f120eceef0ff20f1f2f0e5ebe0ece820"
+                 "ede020f5f0e0e1f0fbff20efebfaeafb"
+                 "20c8e3eef0e5e2fb"),
+            SHEX("1e88e62226bfca6f 9994f1f2d51569e0"
+                 "daf8475a3b0fe61a 5300eee46d961376"
+                 "035fe83549ada2b8 620fcd7c496ce5b3"
+                 "3f0cb9dddc2b6460 143b03dabac9fb28"));
+
+  /* 10.2.2 */
+  test_hash(&amp;nettle_streebog256,
+            SHEX("d1e520e2e5f2f0e82c20d1f2f0e8e1ee"
+                 "e6e820e2edf3f6e82c20e2e5fef2fa20"
+                 "f120eceef0ff20f1f2f0e5ebe0ece820"
+                 "ede020f5f0e0e1f0fbff20efebfaeafb"
+                 "20c8e3eef0e5e2fb"),
+            SHEX("9dd2fe4e90409e5d a87f53976d7405b0"
+                 "c0cac628fc669a74 1d50063c557e8f50"));
+
+  /* Additional tests to verify long integer addition with carry */
+  test_hash(&amp;nettle_streebog512,
+	    SHEX("eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"
+		 "eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"
+		 "eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"
+		 "eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"
+		 "16111111111111111111111111111111"
+		 "11111111111111111111111111111111"
+		 "11111111111111111111111111111111"
+		 "11111111111111111111111111111116"),
+	    SHEX("8b06f41e59907d9636e892caf5942fcd"
+		 "fb71fa31169a5e70f0edb873664df41c"
+		 "2cce6e06dc6755d15a61cdeb92bd607c"
+		 "c4aaca6732bf3568a23a210dd520fd41"));
+
+  test_hash(&amp;nettle_streebog256,
+	    SHEX("eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"
+		 "eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"
+		 "eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"
+		 "eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"
+		 "16111111111111111111111111111111"
+		 "11111111111111111111111111111111"
+		 "11111111111111111111111111111111"
+		 "11111111111111111111111111111116"),
+	    SHEX("81bb632fa31fcc38b4c379a662dbc58b"
+		 "9bed83f50d3a1b2ce7271ab02d25babb"));
+
+  test_hash(&amp;nettle_streebog512,
+	    SHEX("ffffffffffffffffffffffffffffffff"
+		 "ffffffffffffffffffffffffffffffff"
+		 "ffffffffffffffffffffffffffffffff"
+		 "ffffffffffffffffffffffffffffffff"
+		 "ffffffffffffffffffffffffffffffff"
+		 "ffffffffffffffffffffffffffffffff"
+		 "ffffffffffffffffffffffffffffffff"
+		 "ffffffffffffffffffffffffffffffff"),
+	    SHEX("90a161d12ad309498d3fe5d48202d8a4"
+		 "e9c406d6a264aeab258ac5ecc37a7962"
+		 "aaf9587a5abb09b6bb81ec4b3752a3ff"
+		 "5a838ef175be5772056bc5fe54fcfc7e"));
+
+}
-- 
2.26.2

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200604232706</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-06-04 23:27:06-0400</timestampReceived><subject>[PATCH v3] Implement GOST R 34.11-2012 (Streebog) hash function</subject><body>

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 Makefile.in     |    3 +-
 streebog-meta.c |   44 ++
 streebog.c      | 1317 +++++++++++++++++++++++++++++++++++++++++++++++
 streebog.h      |   99 ++++
 4 files changed, 1462 insertions(+), 1 deletion(-)
 create mode 100644 streebog-meta.c
 create mode 100644 streebog.c
 create mode 100644 streebog.h

diff --git a/Makefile.in b/Makefile.in
index e5ccfc76b901..c36764dc4c45 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -137,6 +137,7 @@ nettle_SOURCES = aes-decrypt-internal.c aes-decrypt.c \
 		 shake256.c \
 		 serpent-set-key.c serpent-encrypt.c serpent-decrypt.c \
 		 serpent-meta.c \
+		 streebog.c streebog-meta.c \
 		 twofish.c twofish-meta.c \
 		 umac-nh.c umac-nh-n.c umac-l2.c umac-l3.c \
 		 umac-poly64.c umac-poly128.c umac-set-key.c \
@@ -222,7 +223,7 @@ HEADERS = aes.h arcfour.h arctwo.h asn1.h blowfish.h \
 	  pbkdf2.h \
 	  pgp.h pkcs1.h pss.h pss-mgf1.h realloc.h ripemd160.h rsa.h \
 	  salsa20.h sexp.h \
-	  serpent.h sha.h sha1.h sha2.h sha3.h twofish.h \
+	  serpent.h sha.h sha1.h sha2.h sha3.h streebog.h twofish.h \
 	  umac.h yarrow.h xts.h poly1305.h
 
 INSTALL_HEADERS = $(HEADERS) version.h @IF_MINI_GMP@ mini-gmp.h
diff --git a/streebog-meta.c b/streebog-meta.c
new file mode 100644
index 000000000000..de88651b8810
--- /dev/null
+++ b/streebog-meta.c
@@ -0,0 +1,44 @@
+/* streebog-meta.c
+
+   Copyright (C) 2020 Dmitry Baryshkov
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include "nettle-meta.h"
+
+#include "streebog.h"
+
+const struct nettle_hash nettle_streebog512
+= _NETTLE_HASH(streebog512, STREEBOG512);
+
+const struct nettle_hash nettle_streebog256
+= _NETTLE_HASH(streebog256, STREEBOG256);
diff --git a/streebog.c b/streebog.c
new file mode 100644
index 000000000000..7ad619d5e04d
--- /dev/null
+++ b/streebog.c
@@ -0,0 +1,1317 @@
+/* streebog.c - GOST R 34.11-2012 (Streebog) hash function
+   See RFC 6986 for the English translation of the standard
+
+   Copyright (C) 2020 Dmitry Baryshkov
+
+   Based on my code in libgcrypt.
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+ */
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;stdlib.h&gt;
+#include &lt;string.h&gt;
+
+#include "streebog.h"
+
+#include "macros.h"
+#include "nettle-write.h"
+
+
+/* Pre-computed results of multiplication of bytes on A and reordered with
+   Pi[]. */
+static const uint64_t streebog_table[8][256] =
+{
+  /* 0 */
+  { 0xd01f715b5c7ef8e6ULL, 0x16fa240980778325ULL,
+    0xa8a42e857ee049c8ULL, 0x6ac1068fa186465bULL,
+    0x6e417bd7a2e9320bULL, 0x665c8167a437daabULL,
+    0x7666681aa89617f6ULL, 0x4b959163700bdcf5ULL,
+    0xf14be6b78df36248ULL, 0xc585bd689a625cffULL,
+    0x9557d7fca67d82cbULL, 0x89f0b969af6dd366ULL,
+    0xb0833d48749f6c35ULL, 0xa1998c23b1ecbc7cULL,
+    0x8d70c431ac02a736ULL, 0xd6dfbc2fd0a8b69eULL,
+    0x37aeb3e551fa198bULL, 0x0b7d128a40b5cf9cULL,
+    0x5a8f2008b5780cbcULL, 0xedec882284e333e5ULL,
+    0xd25fc177d3c7c2ceULL, 0x5e0f5d50b61778ecULL,
+    0x1d873683c0c24cb9ULL, 0xad040bcbb45d208cULL,
+    0x2f89a0285b853c76ULL, 0x5732fff6791b8d58ULL,
+    0x3e9311439ef6ec3fULL, 0xc9183a809fd3c00fULL,
+    0x83adf3f5260a01eeULL, 0xa6791941f4e8ef10ULL,
+    0x103ae97d0ca1cd5dULL, 0x2ce948121dee1b4aULL,
+    0x39738421dbf2bf53ULL, 0x093da2a6cf0cf5b4ULL,
+    0xcd9847d89cbcb45fULL, 0xf9561c078b2d8ae8ULL,
+    0x9c6a755a6971777fULL, 0xbc1ebaa0712ef0c5ULL,
+    0x72e61542abf963a6ULL, 0x78bb5fde229eb12eULL,
+    0x14ba94250fceb90dULL, 0x844d6697630e5282ULL,
+    0x98ea08026a1e032fULL, 0xf06bbea144217f5cULL,
+    0xdb6263d11ccb377aULL, 0x641c314b2b8ee083ULL,
+    0x320e96ab9b4770cfULL, 0x1ee7deb986a96b85ULL,
+    0xe96cf57a878c47b5ULL, 0xfdd6615f8842feb8ULL,
+    0xc83862965601dd1bULL, 0x2ea9f83e92572162ULL,
+    0xf876441142ff97fcULL, 0xeb2c455608357d9dULL,
+    0x5612a7e0b0c9904cULL, 0x6c01cbfb2d500823ULL,
+    0x4548a6a7fa037a2dULL, 0xabc4c6bf388b6ef4ULL,
+    0xbade77d4fdf8bebdULL, 0x799b07c8eb4cac3aULL,
+    0x0c9d87e805b19cf0ULL, 0xcb588aac106afa27ULL,
+    0xea0c1d40c1e76089ULL, 0x2869354a1e816f1aULL,
+    0xff96d17307fbc490ULL, 0x9f0a9d602f1a5043ULL,
+    0x96373fc6e016a5f7ULL, 0x5292dab8b3a6e41cULL,
+    0x9b8ae0382c752413ULL, 0x4f15ec3b7364a8a5ULL,
+    0x3fb349555724f12bULL, 0xc7c50d4415db66d7ULL,
+    0x92b7429ee379d1a7ULL, 0xd37f99611a15dfdaULL,
+    0x231427c05e34a086ULL, 0xa439a96d7b51d538ULL,
+    0xb403401077f01865ULL, 0xdda2aea5901d7902ULL,
+    0x0a5d4a9c8967d288ULL, 0xc265280adf660f93ULL,
+    0x8bb0094520d4e94eULL, 0x2a29856691385532ULL,
+    0x42a833c5bf072941ULL, 0x73c64d54622b7eb2ULL,
+    0x07e095624504536cULL, 0x8a905153e906f45aULL,
+    0x6f6123c16b3b2f1fULL, 0xc6e55552dc097bc3ULL,
+    0x4468feb133d16739ULL, 0xe211e7f0c7398829ULL,
+    0xa2f96419f7879b40ULL, 0x19074bdbc3ad38e9ULL,
+    0xf4ebc3f9474e0b0cULL, 0x43886bd376d53455ULL,
+    0xd8028beb5aa01046ULL, 0x51f23282f5cdc320ULL,
+    0xe7b1c2be0d84e16dULL, 0x081dfab006dee8a0ULL,
+    0x3b33340d544b857bULL, 0x7f5bcabc679ae242ULL,
+    0x0edd37c48a08a6d8ULL, 0x81ed43d9a9b33bc6ULL,
+    0xb1a3655ebd4d7121ULL, 0x69a1eeb5e7ed6167ULL,
+    0xf6ab73d5c8f73124ULL, 0x1a67a3e185c61fd5ULL,
+    0x2dc91004d43c065eULL, 0x0240b02c8fb93a28ULL,
+    0x90f7f2b26cc0eb8fULL, 0x3cd3a16f114fd617ULL,
+    0xaae49ea9f15973e0ULL, 0x06c0cd748cd64e78ULL,
+    0xda423bc7d5192a6eULL, 0xc345701c16b41287ULL,
+    0x6d2193ede4821537ULL, 0xfcf639494190e3acULL,
+    0x7c3b228621f1c57eULL, 0xfb16ac2b0494b0c0ULL,
+    0xbf7e529a3745d7f9ULL, 0x6881b6a32e3f7c73ULL,
+    0xca78d2bad9b8e733ULL, 0xbbfe2fc2342aa3a9ULL,
+    0x0dbddffecc6381e4ULL, 0x70a6a56e2440598eULL,
+    0xe4d12a844befc651ULL, 0x8c509c2765d0ba22ULL,
+    0xee8c6018c28814d9ULL, 0x17da7c1f49a59e31ULL,
+    0x609c4c1328e194d3ULL, 0xb3e3d57232f44b09ULL,
+    0x91d7aaa4a512f69bULL, 0x0ffd6fd243dabbccULL,
+    0x50d26a943c1fde34ULL, 0x6be15e9968545b4fULL,
+    0x94778fea6faf9fdfULL, 0x2b09dd7058ea4826ULL,
+    0x677cd9716de5c7bfULL, 0x49d5214fffb2e6ddULL,
+    0x0360e83a466b273cULL, 0x1fc786af4f7b7691ULL,
+    0xa0b9d435783ea168ULL, 0xd49f0c035f118cb6ULL,
+    0x01205816c9d21d14ULL, 0xac2453dd7d8f3d98ULL,
+    0x545217cc3f70aa64ULL, 0x26b4028e9489c9c2ULL,
+    0xdec2469fd6765e3eULL, 0x04807d58036f7450ULL,
+    0xe5f17292823ddb45ULL, 0xf30b569b024a5860ULL,
+    0x62dcfc3fa758aefbULL, 0xe84cad6c4e5e5aa1ULL,
+    0xccb81fce556ea94bULL, 0x53b282ae7a74f908ULL,
+    0x1b47fbf74c1402c1ULL, 0x368eebf39828049fULL,
+    0x7afbeff2ad278b06ULL, 0xbe5e0a8cfe97caedULL,
+    0xcfd8f7f413058e77ULL, 0xf78b2bc301252c30ULL,
+    0x4d555c17fcdd928dULL, 0x5f2f05467fc565f8ULL,
+    0x24f4b2a21b30f3eaULL, 0x860dd6bbecb768aaULL,
+    0x4c750401350f8f99ULL, 0x0000000000000000ULL,
+    0xecccd0344d312ef1ULL, 0xb5231806be220571ULL,
+    0xc105c030990d28afULL, 0x653c695de25cfd97ULL,
+    0x159acc33c61ca419ULL, 0xb89ec7f872418495ULL,
+    0xa9847693b73254dcULL, 0x58cf90243ac13694ULL,
+    0x59efc832f3132b80ULL, 0x5c4fed7c39ae42c4ULL,
+    0x828dabe3efd81cfaULL, 0xd13f294d95ace5f2ULL,
+    0x7d1b7a90e823d86aULL, 0xb643f03cf849224dULL,
+    0x3df3f979d89dcb03ULL, 0x7426d836272f2ddeULL,
+    0xdfe21e891fa4432aULL, 0x3a136c1b9d99986fULL,
+    0xfa36f43dcd46add4ULL, 0xc025982650df35bbULL,
+    0x856d3e81aadc4f96ULL, 0xc4a5e57e53b041ebULL,
+    0x4708168b75ba4005ULL, 0xaf44bbe73be41aa4ULL,
+    0x971767d029c4b8e3ULL, 0xb9be9feebb939981ULL,
+    0x215497ecd18d9aaeULL, 0x316e7e91dd2c57f3ULL,
+    0xcef8afe2dad79363ULL, 0x3853dc371220a247ULL,
+    0x35ee03c9de4323a3ULL, 0xe6919aa8c456fc79ULL,
+    0xe05157dc4880b201ULL, 0x7bdbb7e464f59612ULL,
+    0x127a59518318f775ULL, 0x332ecebd52956ddbULL,
+    0x8f30741d23bb9d1eULL, 0xd922d3fd93720d52ULL,
+    0x7746300c61440ae2ULL, 0x25d4eab4d2e2eefeULL,
+    0x75068020eefd30caULL, 0x135a01474acaea61ULL,
+    0x304e268714fe4ae7ULL, 0xa519f17bb283c82cULL,
+    0xdc82f6b359cf6416ULL, 0x5baf781e7caa11a8ULL,
+    0xb2c38d64fb26561dULL, 0x34ce5bdf17913eb7ULL,
+    0x5d6fb56af07c5fd0ULL, 0x182713cd0a7f25fdULL,
+    0x9e2ac576e6c84d57ULL, 0x9aaab82ee5a73907ULL,
+    0xa3d93c0f3e558654ULL, 0x7e7b92aaae48ff56ULL,
+    0x872d8ead256575beULL, 0x41c8dbfff96c0e7dULL,
+    0x99ca5014a3cc1e3bULL, 0x40e883e930be1369ULL,
+    0x1ca76e95091051adULL, 0x4e35b42dbab6b5b1ULL,
+    0x05a0254ecabd6944ULL, 0xe1710fca8152af15ULL,
+    0xf22b0e8dcb984574ULL, 0xb763a82a319b3f59ULL,
+    0x63fca4296e8ab3efULL, 0x9d4a2d4ca0a36a6bULL,
+    0xe331bfe60eeb953dULL, 0xd5bf541596c391a2ULL,
+    0xf5cb9bef8e9c1618ULL, 0x46284e9dbc685d11ULL,
+    0x2074cffa185f87baULL, 0xbd3ee2b6b8fcedd1ULL,
+    0xae64e3f1f23607b0ULL, 0xfeb68965ce29d984ULL,
+    0x55724fdaf6a2b770ULL, 0x29496d5cd753720eULL,
+    0xa75941573d3af204ULL, 0x8e102c0bea69800aULL,
+    0x111ab16bc573d049ULL, 0xd7ffe439197aab8aULL,
+    0xefac380e0b5a09cdULL, 0x48f579593660fbc9ULL,
+    0x22347fd697e6bd92ULL, 0x61bc1405e13389c7ULL,
+    0x4ab5c975b9d9c1e1ULL, 0x80cd1bcf606126d2ULL,
+    0x7186fd78ed92449aULL, 0x93971a882aabccb3ULL,
+    0x88d0e17f66bfce72ULL, 0x27945a985d5bd4d6ULL },
+  /* 1 */
+  { 0xde553f8c05a811c8ULL, 0x1906b59631b4f565ULL,
+    0x436e70d6b1964ff7ULL, 0x36d343cb8b1e9d85ULL,
+    0x843dfacc858aab5aULL, 0xfdfc95c299bfc7f9ULL,
+    0x0f634bdea1d51fa2ULL, 0x6d458b3b76efb3cdULL,
+    0x85c3f77cf8593f80ULL, 0x3c91315fbe737cb2ULL,
+    0x2148b03366ace398ULL, 0x18f8b8264c6761bfULL,
+    0xc830c1c495c9fb0fULL, 0x981a76102086a0aaULL,
+    0xaa16012142f35760ULL, 0x35cc54060c763cf6ULL,
+    0x42907d66cc45db2dULL, 0x8203d44b965af4bcULL,
+    0x3d6f3cefc3a0e868ULL, 0xbc73ff69d292bda7ULL,
+    0x8722ed0102e20a29ULL, 0x8f8185e8cd34deb7ULL,
+    0x9b0561dda7ee01d9ULL, 0x5335a0193227fad6ULL,
+    0xc9cecc74e81a6fd5ULL, 0x54f5832e5c2431eaULL,
+    0x99e47ba05d553470ULL, 0xf7bee756acd226ceULL,
+    0x384e05a5571816fdULL, 0xd1367452a47d0e6aULL,
+    0xf29fde1c386ad85bULL, 0x320c77316275f7caULL,
+    0xd0c879e2d9ae9ab0ULL, 0xdb7406c69110ef5dULL,
+    0x45505e51a2461011ULL, 0xfc029872e46c5323ULL,
+    0xfa3cb6f5f7bc0cc5ULL, 0x031f17cd8768a173ULL,
+    0xbd8df2d9af41297dULL, 0x9d3b4f5ab43e5e3fULL,
+    0x4071671b36feee84ULL, 0x716207e7d3e3b83dULL,
+    0x48d20ff2f9283a1aULL, 0x27769eb4757cbc7eULL,
+    0x5c56ebc793f2e574ULL, 0xa48b474f9ef5dc18ULL,
+    0x52cbada94ff46e0cULL, 0x60c7da982d8199c6ULL,
+    0x0e9d466edc068b78ULL, 0x4eec2175eaf865fcULL,
+    0x550b8e9e21f7a530ULL, 0x6b7ba5bc653fec2bULL,
+    0x5eb7f1ba6949d0ddULL, 0x57ea94e3db4c9099ULL,
+    0xf640eae6d101b214ULL, 0xdd4a284182c0b0bbULL,
+    0xff1d8fbf6304f250ULL, 0xb8accb933bf9d7e8ULL,
+    0xe8867c478eb68c4dULL, 0x3f8e2692391bddc1ULL,
+    0xcb2fd60912a15a7cULL, 0xaec935dbab983d2fULL,
+    0xf55ffd2b56691367ULL, 0x80e2ce366ce1c115ULL,
+    0x179bf3f8edb27e1dULL, 0x01fe0db07dd394daULL,
+    0xda8a0b76ecc37b87ULL, 0x44ae53e1df9584cbULL,
+    0xb310b4b77347a205ULL, 0xdfab323c787b8512ULL,
+    0x3b511268d070b78eULL, 0x65e6e3d2b9396753ULL,
+    0x6864b271e2574d58ULL, 0x259784c98fc789d7ULL,
+    0x02e11a7dfabb35a9ULL, 0x8841a6dfa337158bULL,
+    0x7ade78c39b5dcdd0ULL, 0xb7cf804d9a2cc84aULL,
+    0x20b6bd831b7f7742ULL, 0x75bd331d3a88d272ULL,
+    0x418f6aab4b2d7a5eULL, 0xd9951cbb6babdaf4ULL,
+    0xb6318dfde7ff5c90ULL, 0x1f389b112264aa83ULL,
+    0x492c024284fbaec0ULL, 0xe33a0363c608f9a0ULL,
+    0x2688930408af28a4ULL, 0xc7538a1a341ce4adULL,
+    0x5da8e677ee2171aeULL, 0x8c9e92254a5c7fc4ULL,
+    0x63d8cd55aae938b5ULL, 0x29ebd8daa97a3706ULL,
+    0x959827b37be88aa1ULL, 0x1484e4356adadf6eULL,
+    0xa7945082199d7d6bULL, 0xbf6ce8a455fa1cd4ULL,
+    0x9cc542eac9edcae5ULL, 0x79c16f0e1c356ca3ULL,
+    0x89bfab6fdee48151ULL, 0xd4174d1830c5f0ffULL,
+    0x9258048415eb419dULL, 0x6139d72850520d1cULL,
+    0x6a85a80c18ec78f1ULL, 0xcd11f88e0171059aULL,
+    0xcceff53e7ca29140ULL, 0xd229639f2315af19ULL,
+    0x90b91ef9ef507434ULL, 0x5977d28d074a1be1ULL,
+    0x311360fce51d56b9ULL, 0xc093a92d5a1f2f91ULL,
+    0x1a19a25bb6dc5416ULL, 0xeb996b8a09de2d3eULL,
+    0xfee3820f1ed7668aULL, 0xd7085ad5b7ad518cULL,
+    0x7fff41890fe53345ULL, 0xec5948bd67dde602ULL,
+    0x2fd5f65dbaaa68e0ULL, 0xa5754affe32648c2ULL,
+    0xf8ddac880d07396cULL, 0x6fa491468c548664ULL,
+    0x0c7c5c1326bdbed1ULL, 0x4a33158f03930fb3ULL,
+    0x699abfc19f84d982ULL, 0xe4fa2054a80b329cULL,
+    0x6707f9af438252faULL, 0x08a368e9cfd6d49eULL,
+    0x47b1442c58fd25b8ULL, 0xbbb3dc5ebc91769bULL,
+    0x1665fe489061eac7ULL, 0x33f27a811fa66310ULL,
+    0x93a609346838d547ULL, 0x30ed6d4c98cec263ULL,
+    0x1dd9816cd8df9f2aULL, 0x94662a03063b1e7bULL,
+    0x83fdd9fbeb896066ULL, 0x7b207573e68e590aULL,
+    0x5f49fc0a149a4407ULL, 0x343259b671a5a82cULL,
+    0xfbc2bb458a6f981fULL, 0xc272b350a0a41a38ULL,
+    0x3aaf1fd8ada32354ULL, 0x6cbb868b0b3c2717ULL,
+    0xa2b569c88d2583feULL, 0xf180c9d1bf027928ULL,
+    0xaf37386bd64ba9f5ULL, 0x12bacab2790a8088ULL,
+    0x4c0d3b0810435055ULL, 0xb2eeb9070e9436dfULL,
+    0xc5b29067cea7d104ULL, 0xdcb425f1ff132461ULL,
+    0x4f122cc5972bf126ULL, 0xac282fa651230886ULL,
+    0xe7e537992f6393efULL, 0xe61b3a2952b00735ULL,
+    0x709c0a57ae302ce7ULL, 0xe02514ae416058d3ULL,
+    0xc44c9dd7b37445deULL, 0x5a68c5408022ba92ULL,
+    0x1c278cdca50c0bf0ULL, 0x6e5a9cf6f18712beULL,
+    0x86dce0b17f319ef3ULL, 0x2d34ec2040115d49ULL,
+    0x4bcd183f7e409b69ULL, 0x2815d56ad4a9a3dcULL,
+    0x24698979f2141d0dULL, 0x0000000000000000ULL,
+    0x1ec696a15fb73e59ULL, 0xd86b110b16784e2eULL,
+    0x8e7f8858b0e74a6dULL, 0x063e2e8713d05fe6ULL,
+    0xe2c40ed3bbdb6d7aULL, 0xb1f1aeca89fc97acULL,
+    0xe1db191e3cb3cc09ULL, 0x6418ee62c4eaf389ULL,
+    0xc6ad87aa49cf7077ULL, 0xd6f65765ca7ec556ULL,
+    0x9afb6c6dda3d9503ULL, 0x7ce05644888d9236ULL,
+    0x8d609f95378feb1eULL, 0x23a9aa4e9c17d631ULL,
+    0x6226c0e5d73aac6fULL, 0x56149953a69f0443ULL,
+    0xeeb852c09d66d3abULL, 0x2b0ac2a753c102afULL,
+    0x07c023376e03cb3cULL, 0x2ccae1903dc2c993ULL,
+    0xd3d76e2f5ec63bc3ULL, 0x9e2458973356ff4cULL,
+    0xa66a5d32644ee9b1ULL, 0x0a427294356de137ULL,
+    0x783f62be61e6f879ULL, 0x1344c70204d91452ULL,
+    0x5b96c8f0fdf12e48ULL, 0xa90916ecc59bf613ULL,
+    0xbe92e5142829880eULL, 0x727d102a548b194eULL,
+    0x1be7afebcb0fc0ccULL, 0x3e702b2244c8491bULL,
+    0xd5e940a84d166425ULL, 0x66f9f41f3e51c620ULL,
+    0xabe80c913f20c3baULL, 0xf07ec461c2d1edf2ULL,
+    0xf361d3ac45b94c81ULL, 0x0521394a94b8fe95ULL,
+    0xadd622162cf09c5cULL, 0xe97871f7f3651897ULL,
+    0xf4a1f09b2bba87bdULL, 0x095d6559b2054044ULL,
+    0x0bbc7f2448be75edULL, 0x2af4cf172e129675ULL,
+    0x157ae98517094bb4ULL, 0x9fda55274e856b96ULL,
+    0x914713499283e0eeULL, 0xb952c623462a4332ULL,
+    0x74433ead475b46a8ULL, 0x8b5eb112245fb4f8ULL,
+    0xa34b6478f0f61724ULL, 0x11a5dd7ffe6221fbULL,
+    0xc16da49d27ccbb4bULL, 0x76a224d0bde07301ULL,
+    0x8aa0bca2598c2022ULL, 0x4df336b86d90c48fULL,
+    0xea67663a740db9e4ULL, 0xef465f70e0b54771ULL,
+    0x39b008152acb8227ULL, 0x7d1e5bf4f55e06ecULL,
+    0x105bd0cf83b1b521ULL, 0x775c2960c033e7dbULL,
+    0x7e014c397236a79fULL, 0x811cc386113255cfULL,
+    0xeda7450d1a0e72d8ULL, 0x5889df3d7a998f3bULL,
+    0x2e2bfbedc779fc3aULL, 0xce0eef438619a4e9ULL,
+    0x372d4e7bf6cd095fULL, 0x04df34fae96b6a4fULL,
+    0xf923a13870d4adb6ULL, 0xa1aa7e050a4d228dULL,
+    0xa8f71b5cb84862c9ULL, 0xb52e9a306097fde3ULL,
+    0x0d8251a35b6e2a0bULL, 0x2257a7fee1c442ebULL,
+    0x73831d9a29588d94ULL, 0x51d4ba64c89ccf7fULL,
+    0x502ab7d4b54f5ba5ULL, 0x97793dce8153bf08ULL,
+    0xe5042de4d5d8a646ULL, 0x9687307efc802bd2ULL,
+    0xa05473b5779eb657ULL, 0xb4d097801d446939ULL,
+    0xcff0e2f3fbca3033ULL, 0xc38cbee0dd778ee2ULL,
+    0x464f499c252eb162ULL, 0xcad1dbb96f72cea6ULL,
+    0xba4dd1eec142e241ULL, 0xb00fa37af42f0376ULL },
+  /* 2 */
+  { 0xcce4cd3aa968b245ULL, 0x089d5484e80b7fafULL,
+    0x638246c1b3548304ULL, 0xd2fe0ec8c2355492ULL,
+    0xa7fbdf7ff2374eeeULL, 0x4df1600c92337a16ULL,
+    0x84e503ea523b12fbULL, 0x0790bbfd53ab0c4aULL,
+    0x198a780f38f6ea9dULL, 0x2ab30c8f55ec48cbULL,
+    0xe0f7fed6b2c49db5ULL, 0xb6ecf3f422cadbdcULL,
+    0x409c9a541358df11ULL, 0xd3ce8a56dfde3fe3ULL,
+    0xc3e9224312c8c1a0ULL, 0x0d6dfa58816ba507ULL,
+    0xddf3e1b179952777ULL, 0x04c02a42748bb1d9ULL,
+    0x94c2abff9f2decb8ULL, 0x4f91752da8f8acf4ULL,
+    0x78682befb169bf7bULL, 0xe1c77a48af2ff6c4ULL,
+    0x0c5d7ec69c80ce76ULL, 0x4cc1e4928fd81167ULL,
+    0xfeed3d24d9997b62ULL, 0x518bb6dfc3a54a23ULL,
+    0x6dbf2d26151f9b90ULL, 0xb5bc624b05ea664fULL,
+    0xe86aaa525acfe21aULL, 0x4801ced0fb53a0beULL,
+    0xc91463e6c00868edULL, 0x1027a815cd16fe43ULL,
+    0xf67069a0319204cdULL, 0xb04ccc976c8abce7ULL,
+    0xc0b9b3fc35e87c33ULL, 0xf380c77c58f2de65ULL,
+    0x50bb3241de4e2152ULL, 0xdf93f490435ef195ULL,
+    0xf1e0d25d62390887ULL, 0xaf668bfb1a3c3141ULL,
+    0xbc11b251f00a7291ULL, 0x73a5eed47e427d47ULL,
+    0x25bee3f6ee4c3b2eULL, 0x43cc0beb34786282ULL,
+    0xc824e778dde3039cULL, 0xf97d86d98a327728ULL,
+    0xf2b043e24519b514ULL, 0xe297ebf7880f4b57ULL,
+    0x3a94a49a98fab688ULL, 0x868516cb68f0c419ULL,
+    0xeffa11af0964ee50ULL, 0xa4ab4ec0d517f37dULL,
+    0xa9c6b498547c567aULL, 0x8e18424f80fbbbb6ULL,
+    0x0bcdc53bcf2bc23cULL, 0x137739aaea3643d0ULL,
+    0x2c1333ec1bac2ff0ULL, 0x8d48d3f0a7db0625ULL,
+    0x1e1ac3f26b5de6d7ULL, 0xf520f81f16b2b95eULL,
+    0x9f0f6ec450062e84ULL, 0x0130849e1deb6b71ULL,
+    0xd45e31ab8c7533a9ULL, 0x652279a2fd14e43fULL,
+    0x3209f01e70f1c927ULL, 0xbe71a770cac1a473ULL,
+    0x0e3d6be7a64b1894ULL, 0x7ec8148cff29d840ULL,
+    0xcb7476c7fac3be0fULL, 0x72956a4a63a91636ULL,
+    0x37f95ec21991138fULL, 0x9e3fea5a4ded45f5ULL,
+    0x7b38ba50964902e8ULL, 0x222e580bbde73764ULL,
+    0x61e253e0899f55e6ULL, 0xfc8d2805e352ad80ULL,
+    0x35994be3235ac56dULL, 0x09add01af5e014deULL,
+    0x5e8659a6780539c6ULL, 0xb17c48097161d796ULL,
+    0x026015213acbd6e2ULL, 0xd1ae9f77e515e901ULL,
+    0xb7dc776a3f21b0adULL, 0xaba6a1b96eb78098ULL,
+    0x9bcf4486248d9f5dULL, 0x582666c536455efdULL,
+    0xfdbdac9bfeb9c6f1ULL, 0xc47999be4163cdeaULL,
+    0x765540081722a7efULL, 0x3e548ed8ec710751ULL,
+    0x3d041f67cb51bac2ULL, 0x7958af71ac82d40aULL,
+    0x36c9da5c047a78feULL, 0xed9a048e33af38b2ULL,
+    0x26ee7249c96c86bdULL, 0x900281bdeba65d61ULL,
+    0x11172c8bd0fd9532ULL, 0xea0abf73600434f8ULL,
+    0x42fc8f75299309f3ULL, 0x34a9cf7d3eb1ae1cULL,
+    0x2b838811480723baULL, 0x5ce64c8742ceef24ULL,
+    0x1adae9b01fd6570eULL, 0x3c349bf9d6bad1b3ULL,
+    0x82453c891c7b75c0ULL, 0x97923a40b80d512bULL,
+    0x4a61dbf1c198765cULL, 0xb48ce6d518010d3eULL,
+    0xcfb45c858e480fd6ULL, 0xd933cbf30d1e96aeULL,
+    0xd70ea014ab558e3aULL, 0xc189376228031742ULL,
+    0x9262949cd16d8b83ULL, 0xeb3a3bed7def5f89ULL,
+    0x49314a4ee6b8cbcfULL, 0xdcc3652f647e4c06ULL,
+    0xda635a4c2a3e2b3dULL, 0x470c21a940f3d35bULL,
+    0x315961a157d174b4ULL, 0x6672e81dda3459acULL,
+    0x5b76f77a1165e36eULL, 0x445cb01667d36ec8ULL,
+    0xc5491d205c88a69bULL, 0x456c34887a3805b9ULL,
+    0xffddb9bac4721013ULL, 0x99af51a71e4649bfULL,
+    0xa15be01cbc7729d5ULL, 0x52db2760e485f7b0ULL,
+    0x8c78576eba306d54ULL, 0xae560f6507d75a30ULL,
+    0x95f22f6182c687c9ULL, 0x71c5fbf54489aba5ULL,
+    0xca44f259e728d57eULL, 0x88b87d2ccebbdc8dULL,
+    0xbab18d32be4a15aaULL, 0x8be8ec93e99b611eULL,
+    0x17b713e89ebdf209ULL, 0xb31c5d284baa0174ULL,
+    0xeeca9531148f8521ULL, 0xb8d198138481c348ULL,
+    0x8988f9b2d350b7fcULL, 0xb9e11c8d996aa839ULL,
+    0x5a4673e40c8e881fULL, 0x1687977683569978ULL,
+    0xbf4123eed72acf02ULL, 0x4ea1f1b3b513c785ULL,
+    0xe767452be16f91ffULL, 0x7505d1b730021a7cULL,
+    0xa59bca5ec8fc980cULL, 0xad069eda20f7e7a3ULL,
+    0x38f4b1bba231606aULL, 0x60d2d77e94743e97ULL,
+    0x9affc0183966f42cULL, 0x248e6768f3a7505fULL,
+    0xcdd449a4b483d934ULL, 0x87b59255751baf68ULL,
+    0x1bea6d2e023d3c7fULL, 0x6b1f12455b5ffcabULL,
+    0x743555292de9710dULL, 0xd8034f6d10f5fddfULL,
+    0xc6198c9f7ba81b08ULL, 0xbb8109aca3a17edbULL,
+    0xfa2d1766ad12cabbULL, 0xc729080166437079ULL,
+    0x9c5fff7b77269317ULL, 0x0000000000000000ULL,
+    0x15d706c9a47624ebULL, 0x6fdf38072fd44d72ULL,
+    0x5fb6dd3865ee52b7ULL, 0xa33bf53d86bcff37ULL,
+    0xe657c1b5fc84fa8eULL, 0xaa962527735cebe9ULL,
+    0x39c43525bfda0b1bULL, 0x204e4d2a872ce186ULL,
+    0x7a083ece8ba26999ULL, 0x554b9c9db72efbfaULL,
+    0xb22cd9b656416a05ULL, 0x96a2bedea5e63a5aULL,
+    0x802529a826b0a322ULL, 0x8115ad363b5bc853ULL,
+    0x8375b81701901eb1ULL, 0x3069e53f4a3a1fc5ULL,
+    0xbd2136cfede119e0ULL, 0x18bafc91251d81ecULL,
+    0x1d4a524d4c7d5b44ULL, 0x05f0aedc6960daa8ULL,
+    0x29e39d3072ccf558ULL, 0x70f57f6b5962c0d4ULL,
+    0x989fd53903ad22ceULL, 0xf84d024797d91c59ULL,
+    0x547b1803aac5908bULL, 0xf0d056c37fd263f6ULL,
+    0xd56eb535919e58d8ULL, 0x1c7ad6d351963035ULL,
+    0x2e7326cd2167f912ULL, 0xac361a443d1c8cd2ULL,
+    0x697f076461942a49ULL, 0x4b515f6fdc731d2dULL,
+    0x8ad8680df4700a6fULL, 0x41ac1eca0eb3b460ULL,
+    0x7d988533d80965d3ULL, 0xa8f6300649973d0bULL,
+    0x7765c4960ac9cc9eULL, 0x7ca801adc5e20ea2ULL,
+    0xdea3700e5eb59ae4ULL, 0xa06b6482a19c42a4ULL,
+    0x6a2f96db46b497daULL, 0x27def6d7d487edccULL,
+    0x463ca5375d18b82aULL, 0xa6cb5be1efdc259fULL,
+    0x53eba3fef96e9cc1ULL, 0xce84d81b93a364a7ULL,
+    0xf4107c810b59d22fULL, 0x333974806d1aa256ULL,
+    0x0f0def79bba073e5ULL, 0x231edc95a00c5c15ULL,
+    0xe437d494c64f2c6cULL, 0x91320523f64d3610ULL,
+    0x67426c83c7df32ddULL, 0x6eefbc99323f2603ULL,
+    0x9d6f7be56acdf866ULL, 0x5916e25b2bae358cULL,
+    0x7ff89012e2c2b331ULL, 0x035091bf2720bd93ULL,
+    0x561b0d22900e4669ULL, 0x28d319ae6f279e29ULL,
+    0x2f43a2533c8c9263ULL, 0xd09e1be9f8fe8270ULL,
+    0xf740ed3e2c796fbcULL, 0xdb53ded237d5404cULL,
+    0x62b2c25faebfe875ULL, 0x0afd41a5d2c0a94dULL,
+    0x6412fd3ce0ff8f4eULL, 0xe3a76f6995e42026ULL,
+    0x6c8fa9b808f4f0e1ULL, 0xc2d9a6dd0f23aad1ULL,
+    0x8f28c6d19d10d0c7ULL, 0x85d587744fd0798aULL,
+    0xa20b71a39b579446ULL, 0x684f83fa7c7f4138ULL,
+    0xe507500adba4471dULL, 0x3f640a46f19a6c20ULL,
+    0x1247bd34f7dd28a1ULL, 0x2d23b77206474481ULL,
+    0x93521002cc86e0f2ULL, 0x572b89bc8de52d18ULL,
+    0xfb1d93f8b0f9a1caULL, 0xe95a2ecc4724896bULL,
+    0x3ba420048511ddf9ULL, 0xd63e248ab6bee54bULL,
+    0x5dd6c8195f258455ULL, 0x06a03f634e40673bULL,
+    0x1f2a476c76b68da6ULL, 0x217ec9b49ac78af7ULL,
+    0xecaa80102e4453c3ULL, 0x14e78257b99d4f9aULL },
+  /* 3 */
+  { 0x20329b2cc87bba05ULL, 0x4f5eb6f86546a531ULL,
+    0xd4f44775f751b6b1ULL, 0x8266a47b850dfa8bULL,
+    0xbb986aa15a6ca985ULL, 0xc979eb08f9ae0f99ULL,
+    0x2da6f447a2375ea1ULL, 0x1e74275dcd7d8576ULL,
+    0xbc20180a800bc5f8ULL, 0xb4a2f701b2dc65beULL,
+    0xe726946f981b6d66ULL, 0x48e6c453bf21c94cULL,
+    0x42cad9930f0a4195ULL, 0xefa47b64aacccd20ULL,
+    0x71180a8960409a42ULL, 0x8bb3329bf6a44e0cULL,
+    0xd34c35de2d36daccULL, 0xa92f5b7cbc23dc96ULL,
+    0xb31a85aa68bb09c3ULL, 0x13e04836a73161d2ULL,
+    0xb24dfc4129c51d02ULL, 0x8ae44b70b7da5acdULL,
+    0xe671ed84d96579a7ULL, 0xa4bb3417d66f3832ULL,
+    0x4572ab38d56d2de8ULL, 0xb1b47761ea47215cULL,
+    0xe81c09cf70aba15dULL, 0xffbdb872ce7f90acULL,
+    0xa8782297fd5dc857ULL, 0x0d946f6b6a4ce4a4ULL,
+    0xe4df1f4f5b995138ULL, 0x9ebc71edca8c5762ULL,
+    0x0a2c1dc0b02b88d9ULL, 0x3b503c115d9d7b91ULL,
+    0xc64376a8111ec3a2ULL, 0xcec199a323c963e4ULL,
+    0xdc76a87ec58616f7ULL, 0x09d596e073a9b487ULL,
+    0x14583a9d7d560dafULL, 0xf4c6dc593f2a0cb4ULL,
+    0xdd21d19584f80236ULL, 0x4a4836983ddde1d3ULL,
+    0xe58866a41ae745f9ULL, 0xf591a5b27e541875ULL,
+    0x891dc05074586693ULL, 0x5b068c651810a89eULL,
+    0xa30346bc0c08544fULL, 0x3dbf3751c684032dULL,
+    0x2a1e86ec785032dcULL, 0xf73f5779fca830eaULL,
+    0xb60c05ca30204d21ULL, 0x0cc316802b32f065ULL,
+    0x8770241bdd96be69ULL, 0xb861e18199ee95dbULL,
+    0xf805cad91418fcd1ULL, 0x29e70dccbbd20e82ULL,
+    0xc7140f435060d763ULL, 0x0f3a9da0e8b0cc3bULL,
+    0xa2543f574d76408eULL, 0xbd7761e1c175d139ULL,
+    0x4b1f4f737ca3f512ULL, 0x6dc2df1f2fc137abULL,
+    0xf1d05c3967b14856ULL, 0xa742bf3715ed046cULL,
+    0x654030141d1697edULL, 0x07b872abda676c7dULL,
+    0x3ce84eba87fa17ecULL, 0xc1fb0403cb79afdfULL,
+    0x3e46bc7105063f73ULL, 0x278ae987121cd678ULL,
+    0xa1adb4778ef47cd0ULL, 0x26dd906c5362c2b9ULL,
+    0x05168060589b44e2ULL, 0xfbfc41f9d79ac08fULL,
+    0x0e6de44ba9ced8faULL, 0x9feb08068bf243a3ULL,
+    0x7b341749d06b129bULL, 0x229c69e74a87929aULL,
+    0xe09ee6c4427c011bULL, 0x5692e30e725c4c3aULL,
+    0xda99a33e5e9f6e4bULL, 0x353dd85af453a36bULL,
+    0x25241b4c90e0fee7ULL, 0x5de987258309d022ULL,
+    0xe230140fc0802984ULL, 0x93281e86a0c0b3c6ULL,
+    0xf229d719a4337408ULL, 0x6f6c2dd4ad3d1f34ULL,
+    0x8ea5b2fbae3f0aeeULL, 0x8331dd90c473ee4aULL,
+    0x346aa1b1b52db7aaULL, 0xdf8f235e06042aa9ULL,
+    0xcc6f6b68a1354b7bULL, 0x6c95a6f46ebf236aULL,
+    0x52d31a856bb91c19ULL, 0x1a35ded6d498d555ULL,
+    0xf37eaef2e54d60c9ULL, 0x72e181a9a3c2a61cULL,
+    0x98537aad51952fdeULL, 0x16f6c856ffaa2530ULL,
+    0xd960281e9d1d5215ULL, 0x3a0745fa1ce36f50ULL,
+    0x0b7b642bf1559c18ULL, 0x59a87eae9aec8001ULL,
+    0x5e100c05408bec7cULL, 0x0441f98b19e55023ULL,
+    0xd70dcc5534d38aefULL, 0x927f676de1bea707ULL,
+    0x9769e70db925e3e5ULL, 0x7a636ea29115065aULL,
+    0x468b201816ef11b6ULL, 0xab81a9b73edff409ULL,
+    0xc0ac7de88a07bb1eULL, 0x1f235eb68c0391b7ULL,
+    0x6056b074458dd30fULL, 0xbe8eeac102f7ed67ULL,
+    0xcd381283e04b5fbaULL, 0x5cbefecec277c4e3ULL,
+    0xd21b4c356c48ce0dULL, 0x1019c31664b35d8cULL,
+    0x247362a7d19eea26ULL, 0xebe582efb3299d03ULL,
+    0x02aef2cb82fc289fULL, 0x86275df09ce8aaa8ULL,
+    0x28b07427faac1a43ULL, 0x38a9b7319e1f47cfULL,
+    0xc82e92e3b8d01b58ULL, 0x06ef0b409b1978bcULL,
+    0x62f842bfc771fb90ULL, 0x9904034610eb3b1fULL,
+    0xded85ab5477a3e68ULL, 0x90d195a663428f98ULL,
+    0x5384636e2ac708d8ULL, 0xcbd719c37b522706ULL,
+    0xae9729d76644b0ebULL, 0x7c8c65e20a0c7ee6ULL,
+    0x80c856b007f1d214ULL, 0x8c0b40302cc32271ULL,
+    0xdbcedad51fe17a8aULL, 0x740e8ae938dbdea0ULL,
+    0xa615c6dc549310adULL, 0x19cc55f6171ae90bULL,
+    0x49b1bdb8fe5fdd8dULL, 0xed0a89af2830e5bfULL,
+    0x6a7aadb4f5a65bd6ULL, 0x7e22972988f05679ULL,
+    0xf952b3325566e810ULL, 0x39fecedadf61530eULL,
+    0x6101c99f04f3c7ceULL, 0x2e5f7f6761b562ffULL,
+    0xf08725d226cf5c97ULL, 0x63af3b54860fef51ULL,
+    0x8ff2cb10ef411e2fULL, 0x884ab9bb35267252ULL,
+    0x4df04433e7ba8daeULL, 0x9afd8866d3690741ULL,
+    0x66b9bb34de94abb3ULL, 0x9baaf18d92171380ULL,
+    0x543c11c5f0a064a5ULL, 0x17a1b1bdbed431f1ULL,
+    0xb5f58eeaf3a2717fULL, 0xc355f6c849858740ULL,
+    0xec5df044694ef17eULL, 0xd83751f5dc6346d4ULL,
+    0xfc4433520dfdacf2ULL, 0x0000000000000000ULL,
+    0x5a51f58e596ebc5fULL, 0x3285aaf12e34cf16ULL,
+    0x8d5c39db6dbd36b0ULL, 0x12b731dde64f7513ULL,
+    0x94906c2d7aa7dfbbULL, 0x302b583aacc8e789ULL,
+    0x9d45facd090e6b3cULL, 0x2165e2c78905aec4ULL,
+    0x68d45f7f775a7349ULL, 0x189b2c1d5664fdcaULL,
+    0xe1c99f2f030215daULL, 0x6983269436246788ULL,
+    0x8489af3b1e148237ULL, 0xe94b702431d5b59cULL,
+    0x33d2d31a6f4adbd7ULL, 0xbfd9932a4389f9a6ULL,
+    0xb0e30e8aab39359dULL, 0xd1e2c715afcaf253ULL,
+    0x150f43763c28196eULL, 0xc4ed846393e2eb3dULL,
+    0x03f98b20c3823c5eULL, 0xfd134ab94c83b833ULL,
+    0x556b682eb1de7064ULL, 0x36c4537a37d19f35ULL,
+    0x7559f30279a5ca61ULL, 0x799ae58252973a04ULL,
+    0x9c12832648707ffdULL, 0x78cd9c6913e92ec5ULL,
+    0x1d8dac7d0effb928ULL, 0x439da0784e745554ULL,
+    0x413352b3cc887dcbULL, 0xbacf134a1b12bd44ULL,
+    0x114ebafd25cd494dULL, 0x2f08068c20cb763eULL,
+    0x76a07822ba27f63fULL, 0xeab2fb04f25789c2ULL,
+    0xe3676de481fe3d45ULL, 0x1b62a73d95e6c194ULL,
+    0x641749ff5c68832cULL, 0xa5ec4dfc97112cf3ULL,
+    0xf6682e92bdd6242bULL, 0x3f11c59a44782bb2ULL,
+    0x317c21d1edb6f348ULL, 0xd65ab5be75ad9e2eULL,
+    0x6b2dd45fb4d84f17ULL, 0xfaab381296e4d44eULL,
+    0xd0b5befeeeb4e692ULL, 0x0882ef0b32d7a046ULL,
+    0x512a91a5a83b2047ULL, 0x963e9ee6f85bf724ULL,
+    0x4e09cf132438b1f0ULL, 0x77f701c9fb59e2feULL,
+    0x7ddb1c094b726a27ULL, 0x5f4775ee01f5f8bdULL,
+    0x9186ec4d223c9b59ULL, 0xfeeac1998f01846dULL,
+    0xac39db1ce4b89874ULL, 0xb75b7c21715e59e0ULL,
+    0xafc0503c273aa42aULL, 0x6e3b543fec430bf5ULL,
+    0x704f7362213e8e83ULL, 0x58ff0745db9294c0ULL,
+    0x67eec2df9feabf72ULL, 0xa0facd9ccf8a6811ULL,
+    0xb936986ad890811aULL, 0x95c715c63bd9cb7aULL,
+    0xca8060283a2c33c7ULL, 0x507de84ee9453486ULL,
+    0x85ded6d05f6a96f6ULL, 0x1cdad5964f81ade9ULL,
+    0xd5a33e9eb62fa270ULL, 0x40642b588df6690aULL,
+    0x7f75eec2c98e42b8ULL, 0x2cf18dace3494a60ULL,
+    0x23cb100c0bf9865bULL, 0xeef3028febb2d9e1ULL,
+    0x4425d2d394133929ULL, 0xaad6d05c7fa1e0c8ULL,
+    0xad6ea2f7a5c68cb5ULL, 0xc2028f2308fb9381ULL,
+    0x819f2f5b468fc6d5ULL, 0xc5bafd88d29cfffcULL,
+    0x47dc59f357910577ULL, 0x2b49ff07392e261dULL,
+    0x57c59ae5332258fbULL, 0x73b6f842e2bcb2ddULL,
+    0xcf96e04862b77725ULL, 0x4ca73dd8a6c4996fULL,
+    0x015779eb417e14c1ULL, 0x37932a9176af8bf4ULL },
+  /* 4 */
+  { 0x190a2c9b249df23eULL, 0x2f62f8b62263e1e9ULL,
+    0x7a7f754740993655ULL, 0x330b7ba4d5564d9fULL,
+    0x4c17a16a46672582ULL, 0xb22f08eb7d05f5b8ULL,
+    0x535f47f40bc148ccULL, 0x3aec5d27d4883037ULL,
+    0x10ed0a1825438f96ULL, 0x516101f72c233d17ULL,
+    0x13cc6f949fd04eaeULL, 0x739853c441474bfdULL,
+    0x653793d90d3f5b1bULL, 0x5240647b96b0fc2fULL,
+    0x0c84890ad27623e0ULL, 0xd7189b32703aaea3ULL,
+    0x2685de3523bd9c41ULL, 0x99317c5b11bffefaULL,
+    0x0d9baa854f079703ULL, 0x70b93648fbd48ac5ULL,
+    0xa80441fce30bc6beULL, 0x7287704bdc36ff1eULL,
+    0xb65384ed33dc1f13ULL, 0xd36417343ee34408ULL,
+    0x39cd38ab6e1bf10fULL, 0x5ab861770a1f3564ULL,
+    0x0ebacf09f594563bULL, 0xd04572b884708530ULL,
+    0x3cae9722bdb3af47ULL, 0x4a556b6f2f5cbaf2ULL,
+    0xe1704f1f76c4bd74ULL, 0x5ec4ed7144c6dfcfULL,
+    0x16afc01d4c7810e6ULL, 0x283f113cd629ca7aULL,
+    0xaf59a8761741ed2dULL, 0xeed5a3991e215facULL,
+    0x3bf37ea849f984d4ULL, 0xe413e096a56ce33cULL,
+    0x2c439d3a98f020d1ULL, 0x637559dc6404c46bULL,
+    0x9e6c95d1e5f5d569ULL, 0x24bb9836045fe99aULL,
+    0x44efa466dac8ecc9ULL, 0xc6eab2a5c80895d6ULL,
+    0x803b50c035220cc4ULL, 0x0321658cba93c138ULL,
+    0x8f9ebc465dc7ee1cULL, 0xd15a5137190131d3ULL,
+    0x0fa5ec8668e5e2d8ULL, 0x91c979578d1037b1ULL,
+    0x0642ca05693b9f70ULL, 0xefca80168350eb4fULL,
+    0x38d21b24f36a45ecULL, 0xbeab81e1af73d658ULL,
+    0x8cbfd9cae7542f24ULL, 0xfd19cc0d81f11102ULL,
+    0x0ac6430fbb4dbc90ULL, 0x1d76a09d6a441895ULL,
+    0x2a01573ff1cbbfa1ULL, 0xb572e161894fde2bULL,
+    0x8124734fa853b827ULL, 0x614b1fdf43e6b1b0ULL,
+    0x68ac395c4238cc18ULL, 0x21d837bfd7f7b7d2ULL,
+    0x20c714304a860331ULL, 0x5cfaab726324aa14ULL,
+    0x74c5ba4eb50d606eULL, 0xf3a3030474654739ULL,
+    0x23e671bcf015c209ULL, 0x45f087e947b9582aULL,
+    0xd8bd77b418df4c7bULL, 0xe06f6c90ebb50997ULL,
+    0x0bd96080263c0873ULL, 0x7e03f9410e40dcfeULL,
+    0xb8e94be4c6484928ULL, 0xfb5b0608e8ca8e72ULL,
+    0x1a2b49179e0e3306ULL, 0x4e29e76961855059ULL,
+    0x4f36c4e6fcf4e4baULL, 0x49740ee395cf7bcaULL,
+    0xc2963ea386d17f7dULL, 0x90d65ad810618352ULL,
+    0x12d34c1b02a1fa4dULL, 0xfa44258775bb3a91ULL,
+    0x18150f14b9ec46ddULL, 0x1491861e6b9a653dULL,
+    0x9a1019d7ab2c3fc2ULL, 0x3668d42d06fe13d7ULL,
+    0xdcc1fbb25606a6d0ULL, 0x969490dd795a1c22ULL,
+    0x3549b1a1bc6dd2efULL, 0xc94f5e23a0ed770eULL,
+    0xb9f6686b5b39fdcbULL, 0xc4d4f4a6efeae00dULL,
+    0xe732851a1fff2204ULL, 0x94aad6de5eb869f9ULL,
+    0x3f8ff2ae07206e7fULL, 0xfe38a9813b62d03aULL,
+    0xa7a1ad7a8bee2466ULL, 0x7b6056c8dde882b6ULL,
+    0x302a1e286fc58ca7ULL, 0x8da0fa457a259bc7ULL,
+    0xb3302b64e074415bULL, 0x5402ae7eff8b635fULL,
+    0x08f8050c9cafc94bULL, 0xae468bf98a3059ceULL,
+    0x88c355cca98dc58fULL, 0xb10e6d67c7963480ULL,
+    0xbad70de7e1aa3cf3ULL, 0xbfb4a26e320262bbULL,
+    0xcb711820870f02d5ULL, 0xce12b7a954a75c9dULL,
+    0x563ce87dd8691684ULL, 0x9f73b65e7884618aULL,
+    0x2b1e74b06cba0b42ULL, 0x47cec1ea605b2df1ULL,
+    0x1c698312f735ac76ULL, 0x5fdbcefed9b76b2cULL,
+    0x831a354c8fb1cdfcULL, 0x820516c312c0791fULL,
+    0xb74ca762aeadabf0ULL, 0xfc06ef821c80a5e1ULL,
+    0x5723cbf24518a267ULL, 0x9d4df05d5f661451ULL,
+    0x588627742dfd40bfULL, 0xda8331b73f3d39a0ULL,
+    0x17b0e392d109a405ULL, 0xf965400bcf28fba9ULL,
+    0x7c3dbf4229a2a925ULL, 0x023e460327e275dbULL,
+    0x6cd0b55a0ce126b3ULL, 0xe62da695828e96e7ULL,
+    0x42ad6e63b3f373b9ULL, 0xe50cc319381d57dfULL,
+    0xc5cbd729729b54eeULL, 0x46d1e265fd2a9912ULL,
+    0x6428b056904eeff8ULL, 0x8be23040131e04b7ULL,
+    0x6709d5da2add2ec0ULL, 0x075de98af44a2b93ULL,
+    0x8447dcc67bfbe66fULL, 0x6616f655b7ac9a23ULL,
+    0xd607b8bded4b1a40ULL, 0x0563af89d3a85e48ULL,
+    0x3db1b4ad20c21ba4ULL, 0x11f22997b8323b75ULL,
+    0x292032b34b587e99ULL, 0x7f1cdace9331681dULL,
+    0x8e819fc9c0b65affULL, 0xa1e3677fe2d5bb16ULL,
+    0xcd33d225ee349da5ULL, 0xd9a2543b85aef898ULL,
+    0x795e10cbfa0af76dULL, 0x25a4bbb9992e5d79ULL,
+    0x78413344677b438eULL, 0xf0826688cef68601ULL,
+    0xd27b34bba392f0ebULL, 0x551d8df162fad7bcULL,
+    0x1e57c511d0d7d9adULL, 0xdeffbdb171e4d30bULL,
+    0xf4feea8e802f6caaULL, 0xa480c8f6317de55eULL,
+    0xa0fc44f07fa40ff5ULL, 0x95b5f551c3c9dd1aULL,
+    0x22f952336d6476eaULL, 0x0000000000000000ULL,
+    0xa6be8ef5169f9085ULL, 0xcc2cf1aa73452946ULL,
+    0x2e7ddb39bf12550aULL, 0xd526dd3157d8db78ULL,
+    0x486b2d6c08becf29ULL, 0x9b0f3a58365d8b21ULL,
+    0xac78cdfaadd22c15ULL, 0xbc95c7e28891a383ULL,
+    0x6a927f5f65dab9c3ULL, 0xc3891d2c1ba0cb9eULL,
+    0xeaa92f9f50f8b507ULL, 0xcf0d9426c9d6e87eULL,
+    0xca6e3baf1a7eb636ULL, 0xab25247059980786ULL,
+    0x69b31ad3df4978fbULL, 0xe2512a93cc577c4cULL,
+    0xff278a0ea61364d9ULL, 0x71a615c766a53e26ULL,
+    0x89dc764334fc716cULL, 0xf87a638452594f4aULL,
+    0xf2bc208be914f3daULL, 0x8766b94ac1682757ULL,
+    0xbbc82e687cdb8810ULL, 0x626a7a53f9757088ULL,
+    0xa2c202f358467a2eULL, 0x4d0882e5db169161ULL,
+    0x09e7268301de7da8ULL, 0xe897699c771ac0dcULL,
+    0xc8507dac3d9cc3edULL, 0xc0a878a0a1330aa6ULL,
+    0x978bb352e42ba8c1ULL, 0xe9884a13ea6b743fULL,
+    0x279afdbabecc28a2ULL, 0x047c8c064ed9eaabULL,
+    0x507e2278b15289f4ULL, 0x599904fbb08cf45cULL,
+    0xbd8ae46d15e01760ULL, 0x31353da7f2b43844ULL,
+    0x8558ff49e68a528cULL, 0x76fbfc4d92ef15b5ULL,
+    0x3456922e211c660cULL, 0x86799ac55c1993b4ULL,
+    0x3e90d1219a51da9cULL, 0x2d5cbeb505819432ULL,
+    0x982e5fd48cce4a19ULL, 0xdb9c1238a24c8d43ULL,
+    0xd439febecaa96f9bULL, 0x418c0bef0960b281ULL,
+    0x158ea591f6ebd1deULL, 0x1f48e69e4da66d4eULL,
+    0x8afd13cf8e6fb054ULL, 0xf5e1c9011d5ed849ULL,
+    0xe34e091c5126c8afULL, 0xad67ee7530a398f6ULL,
+    0x43b24dec2e82c75aULL, 0x75da99c1287cd48dULL,
+    0x92e81cdb3783f689ULL, 0xa3dd217cc537cecdULL,
+    0x60543c50de970553ULL, 0x93f73f54aaf2426aULL,
+    0xa91b62737e7a725dULL, 0xf19d4507538732e2ULL,
+    0x77e4dfc20f9ea156ULL, 0x7d229ccdb4d31dc6ULL,
+    0x1b346a98037f87e5ULL, 0xedf4c615a4b29e94ULL,
+    0x4093286094110662ULL, 0xb0114ee85ae78063ULL,
+    0x6ff1d0d6b672e78bULL, 0x6dcf96d591909250ULL,
+    0xdfe09e3eec9567e8ULL, 0x3214582b4827f97cULL,
+    0xb46dc2ee143e6ac8ULL, 0xf6c0ac8da7cd1971ULL,
+    0xebb60c10cd8901e4ULL, 0xf7df8f023abcad92ULL,
+    0x9c52d3d2c217a0b2ULL, 0x6b8d5cd0f8ab0d20ULL,
+    0x3777f7a29b8fa734ULL, 0x011f238f9d71b4e3ULL,
+    0xc1b75b2f3c42be45ULL, 0x5de588fdfe551ef7ULL,
+    0x6eeef3592b035368ULL, 0xaa3a07ffc4e9b365ULL,
+    0xecebe59a39c32a77ULL, 0x5ba742f8976e8187ULL,
+    0x4b4a48e0b22d0e11ULL, 0xddded83dcb771233ULL,
+    0xa59feb79ac0c51bdULL, 0xc7f5912a55792135ULL },
+  /* 5 */
+  { 0x6d6ae04668a9b08aULL, 0x3ab3f04b0be8c743ULL,
+    0xe51e166b54b3c908ULL, 0xbe90a9eb35c2f139ULL,
+    0xb2c7066637f2bec1ULL, 0xaa6945613392202cULL,
+    0x9a28c36f3b5201ebULL, 0xddce5a93ab536994ULL,
+    0x0e34133ef6382827ULL, 0x52a02ba1ec55048bULL,
+    0xa2f88f97c4b2a177ULL, 0x8640e513ca2251a5ULL,
+    0xcdf1d36258137622ULL, 0xfe6cb708dedf8ddbULL,
+    0x8a174a9ec8121e5dULL, 0x679896036b81560eULL,
+    0x59ed033395795feeULL, 0x1dd778ab8b74edafULL,
+    0xee533ef92d9f926dULL, 0x2a8c79baf8a8d8f5ULL,
+    0x6bcf398e69b119f6ULL, 0xe20491742fafdd95ULL,
+    0x276488e0809c2aecULL, 0xea955b82d88f5cceULL,
+    0x7102c63a99d9e0c4ULL, 0xf9763017a5c39946ULL,
+    0x429fa2501f151b3dULL, 0x4659c72bea05d59eULL,
+    0x984b7fdccf5a6634ULL, 0xf742232953fbb161ULL,
+    0x3041860e08c021c7ULL, 0x747bfd9616cd9386ULL,
+    0x4bb1367192312787ULL, 0x1b72a1638a6c44d3ULL,
+    0x4a0e68a6e8359a66ULL, 0x169a5039f258b6caULL,
+    0xb98a2ef44edee5a4ULL, 0xd9083fe85e43a737ULL,
+    0x967f6ce239624e13ULL, 0x8874f62d3c1a7982ULL,
+    0x3c1629830af06e3fULL, 0x9165ebfd427e5a8eULL,
+    0xb5dd81794ceeaa5cULL, 0x0de8f15a7834f219ULL,
+    0x70bd98ede3dd5d25ULL, 0xaccc9ca9328a8950ULL,
+    0x56664eda1945ca28ULL, 0x221db34c0f8859aeULL,
+    0x26dbd637fa98970dULL, 0x1acdffb4f068f932ULL,
+    0x4585254f64090fa0ULL, 0x72de245e17d53afaULL,
+    0x1546b25d7c546cf4ULL, 0x207e0ffffb803e71ULL,
+    0xfaaad2732bcf4378ULL, 0xb462dfae36ea17bdULL,
+    0xcf926fd1ac1b11fdULL, 0xe0672dc7dba7ba4aULL,
+    0xd3fa49ad5d6b41b3ULL, 0x8ba81449b216a3bcULL,
+    0x14f9ec8a0650d115ULL, 0x40fc1ee3eb1d7ce2ULL,
+    0x23a2ed9b758ce44fULL, 0x782c521b14fddc7eULL,
+    0x1c68267cf170504eULL, 0xbcf31558c1ca96e6ULL,
+    0xa781b43b4ba6d235ULL, 0xf6fd7dfe29ff0c80ULL,
+    0xb0a4bad5c3fad91eULL, 0xd199f51ea963266cULL,
+    0x414340349119c103ULL, 0x5405f269ed4dadf7ULL,
+    0xabd61bb649969dcdULL, 0x6813dbeae7bdc3c8ULL,
+    0x65fb2ab09f8931d1ULL, 0xf1e7fae152e3181dULL,
+    0xc1a67cef5a2339daULL, 0x7a4feea8e0f5bba1ULL,
+    0x1e0b9acf05783791ULL, 0x5b8ebf8061713831ULL,
+    0x80e53cdbcb3af8d9ULL, 0x7e898bd315e57502ULL,
+    0xc6bcfbf0213f2d47ULL, 0x95a38e86b76e942dULL,
+    0x092e94218d243cbaULL, 0x8339debf453622e7ULL,
+    0xb11be402b9fe64ffULL, 0x57d9100d634177c9ULL,
+    0xcc4e8db52217cbc3ULL, 0x3b0cae9c71ec7aa2ULL,
+    0xfb158ca451cbfe99ULL, 0x2b33276d82ac6514ULL,
+    0x01bf5ed77a04bde1ULL, 0xc5601994af33f779ULL,
+    0x75c4a3416cc92e67ULL, 0xf3844652a6eb7fc2ULL,
+    0x3487e375fdd0ef64ULL, 0x18ae430704609eedULL,
+    0x4d14efb993298efbULL, 0x815a620cb13e4538ULL,
+    0x125c354207487869ULL, 0x9eeea614ce42cf48ULL,
+    0xce2d3106d61fac1cULL, 0xbbe99247bad6827bULL,
+    0x071a871f7b1c149dULL, 0x2e4a1cc10db81656ULL,
+    0x77a71ff298c149b8ULL, 0x06a5d9c80118a97cULL,
+    0xad73c27e488e34b1ULL, 0x443a7b981e0db241ULL,
+    0xe3bbcfa355ab6074ULL, 0x0af276450328e684ULL,
+    0x73617a896dd1871bULL, 0x58525de4ef7de20fULL,
+    0xb7be3dcab8e6cd83ULL, 0x19111dd07e64230cULL,
+    0x842359a03e2a367aULL, 0x103f89f1f3401fb6ULL,
+    0xdc710444d157d475ULL, 0xb835702334da5845ULL,
+    0x4320fc876511a6dcULL, 0xd026abc9d3679b8dULL,
+    0x17250eee885c0b2bULL, 0x90dab52a387ae76fULL,
+    0x31fed8d972c49c26ULL, 0x89cba8fa461ec463ULL,
+    0x2ff5421677bcabb7ULL, 0x396f122f85e41d7dULL,
+    0xa09b332430bac6a8ULL, 0xc888e8ced7070560ULL,
+    0xaeaf201ac682ee8fULL, 0x1180d7268944a257ULL,
+    0xf058a43628e7a5fcULL, 0xbd4c4b8fbbce2b07ULL,
+    0xa1246df34abe7b49ULL, 0x7d5569b79be9af3cULL,
+    0xa9b5a705bd9efa12ULL, 0xdb6b835baa4bc0e8ULL,
+    0x05793bac8f147342ULL, 0x21c1512881848390ULL,
+    0xfdb0556c50d357e5ULL, 0x613d4fcb6a99ff72ULL,
+    0x03dce2648e0cda3eULL, 0xe949b9e6568386f0ULL,
+    0xfc0f0bbb2ad7ea04ULL, 0x6a70675913b5a417ULL,
+    0x7f36d5046fe1c8e3ULL, 0x0c57af8d02304ff8ULL,
+    0x32223abdfcc84618ULL, 0x0891caf6f720815bULL,
+    0xa63eeaec31a26fd4ULL, 0x2507345374944d33ULL,
+    0x49d28ac266394058ULL, 0xf5219f9aa7f3d6beULL,
+    0x2d96fea583b4cc68ULL, 0x5a31e1571b7585d0ULL,
+    0x8ed12fe53d02d0feULL, 0xdfade6205f5b0e4bULL,
+    0x4cabb16ee92d331aULL, 0x04c6657bf510cea3ULL,
+    0xd73c2cd6a87b8f10ULL, 0xe1d87310a1a307abULL,
+    0x6cd5be9112ad0d6bULL, 0x97c032354366f3f2ULL,
+    0xd4e0ceb22677552eULL, 0x0000000000000000ULL,
+    0x29509bde76a402cbULL, 0xc27a9e8bd42fe3e4ULL,
+    0x5ef7842cee654b73ULL, 0xaf107ecdbc86536eULL,
+    0x3fcacbe784fcb401ULL, 0xd55f90655c73e8cfULL,
+    0xe6c2f40fdabf1336ULL, 0xe8f6e7312c873b11ULL,
+    0xeb2a0555a28be12fULL, 0xe4a148bc2eb774e9ULL,
+    0x9b979db84156bc0aULL, 0x6eb60222e6a56ab4ULL,
+    0x87ffbbc4b026ec44ULL, 0xc703a5275b3b90a6ULL,
+    0x47e699fc9001687fULL, 0x9c8d1aa73a4aa897ULL,
+    0x7cea3760e1ed12ddULL, 0x4ec80ddd1d2554c5ULL,
+    0x13e36b957d4cc588ULL, 0x5d2b66486069914dULL,
+    0x92b90999cc7280b0ULL, 0x517cc9c56259deb5ULL,
+    0xc937b619ad03b881ULL, 0xec30824ad997f5b2ULL,
+    0xa45d565fc5aa080bULL, 0xd6837201d27f32f1ULL,
+    0x635ef3789e9198adULL, 0x531f75769651b96aULL,
+    0x4f77530a6721e924ULL, 0x486dd4151c3dfdb9ULL,
+    0x5f48dafb9461f692ULL, 0x375b011173dc355aULL,
+    0x3da9775470f4d3deULL, 0x8d0dcd81b30e0ac0ULL,
+    0x36e45fc609d888bbULL, 0x55baacbe97491016ULL,
+    0x8cb29356c90ab721ULL, 0x76184125e2c5f459ULL,
+    0x99f4210bb55edbd5ULL, 0x6f095cf59ca1d755ULL,
+    0x9f51f8c3b44672a9ULL, 0x3538bda287d45285ULL,
+    0x50c39712185d6354ULL, 0xf23b1885dcefc223ULL,
+    0x79930ccc6ef9619fULL, 0xed8fdc9da3934853ULL,
+    0xcb540aaa590bdf5eULL, 0x5c94389f1a6d2cacULL,
+    0xe77daad8a0bbaed7ULL, 0x28efc5090ca0bf2aULL,
+    0xbf2ff73c4fc64cd8ULL, 0xb37858b14df60320ULL,
+    0xf8c96ec0dfc724a7ULL, 0x828680683f329f06ULL,
+    0x941cd051cd6a29ccULL, 0xc3c5c05cae2b5e05ULL,
+    0xb601631dc2e27062ULL, 0xc01922382027843bULL,
+    0x24b86a840e90f0d2ULL, 0xd245177a276ffc52ULL,
+    0x0f8b4de98c3c95c6ULL, 0x3e759530fef809e0ULL,
+    0x0b4d2892792c5b65ULL, 0xc4df4743d5374a98ULL,
+    0xa5e20888bfaeb5eaULL, 0xba56cc90c0d23f9aULL,
+    0x38d04cf8ffe0a09cULL, 0x62e1adafe495254cULL,
+    0x0263bcb3f40867dfULL, 0xcaeb547d230f62bfULL,
+    0x6082111c109d4293ULL, 0xdad4dd8cd04f7d09ULL,
+    0xefec602e579b2f8cULL, 0x1fb4c4187f7c8a70ULL,
+    0xffd3e9dfa4db303aULL, 0x7bf0b07f9af10640ULL,
+    0xf49ec14dddf76b5fULL, 0x8f6e713247066d1fULL,
+    0x339d646a86ccfbf9ULL, 0x64447467e58d8c30ULL,
+    0x2c29a072f9b07189ULL, 0xd8b7613f24471ad6ULL,
+    0x6627c8d41185ebefULL, 0xa347d140beb61c96ULL,
+    0xde12b8f7255fb3aaULL, 0x9d324470404e1576ULL,
+    0x9306574eb6763d51ULL, 0xa80af9d2c79a47f3ULL,
+    0x859c0777442e8b9bULL, 0x69ac853d9db97e29ULL },
+  /* 6 */
+  { 0xc3407dfc2de6377eULL, 0x5b9e93eea4256f77ULL,
+    0xadb58fdd50c845e0ULL, 0x5219ff11a75bed86ULL,
+    0x356b61cfd90b1de9ULL, 0xfb8f406e25abe037ULL,
+    0x7a5a0231c0f60796ULL, 0x9d3cd216e1f5020bULL,
+    0x0c6550fb6b48d8f3ULL, 0xf57508c427ff1c62ULL,
+    0x4ad35ffa71cb407dULL, 0x6290a2da1666aa6dULL,
+    0xe284ec2349355f9fULL, 0xb3c307c53d7c84ecULL,
+    0x05e23c0468365a02ULL, 0x190bac4d6c9ebfa8ULL,
+    0x94bbbee9e28b80faULL, 0xa34fc777529cb9b5ULL,
+    0xcc7b39f095bcd978ULL, 0x2426addb0ce532e3ULL,
+    0x7e79329312ce4fc7ULL, 0xab09a72eebec2917ULL,
+    0xf8d15499f6b9d6c2ULL, 0x1a55b8babf8c895dULL,
+    0xdb8add17fb769a85ULL, 0xb57f2f368658e81bULL,
+    0x8acd36f18f3f41f6ULL, 0x5ce3b7bba50f11d3ULL,
+    0x114dcc14d5ee2f0aULL, 0xb91a7fcded1030e8ULL,
+    0x81d5425fe55de7a1ULL, 0xb6213bc1554adeeeULL,
+    0x80144ef95f53f5f2ULL, 0x1e7688186db4c10cULL,
+    0x3b912965db5fe1bcULL, 0xc281715a97e8252dULL,
+    0x54a5d7e21c7f8171ULL, 0x4b12535ccbc5522eULL,
+    0x1d289cefbea6f7f9ULL, 0x6ef5f2217d2e729eULL,
+    0xe6a7dc819b0d17ceULL, 0x1b94b41c05829b0eULL,
+    0x33d7493c622f711eULL, 0xdcf7f942fa5ce421ULL,
+    0x600fba8b7f7a8ecbULL, 0x46b60f011a83988eULL,
+    0x235b898e0dcf4c47ULL, 0x957ab24f588592a9ULL,
+    0x4354330572b5c28cULL, 0xa5f3ef84e9b8d542ULL,
+    0x8c711e02341b2d01ULL, 0x0b1874ae6a62a657ULL,
+    0x1213d8e306fc19ffULL, 0xfe6d7c6a4d9dba35ULL,
+    0x65ed868f174cd4c9ULL, 0x88522ea0e6236550ULL,
+    0x899322065c2d7703ULL, 0xc01e690bfef4018bULL,
+    0x915982ed8abddaf8ULL, 0xbe675b98ec3a4e4cULL,
+    0xa996bf7f82f00db1ULL, 0xe1daf8d49a27696aULL,
+    0x2effd5d3dc8986e7ULL, 0xd153a51f2b1a2e81ULL,
+    0x18caa0ebd690adfbULL, 0x390e3134b243c51aULL,
+    0x2778b92cdff70416ULL, 0x029f1851691c24a6ULL,
+    0x5e7cafeacc133575ULL, 0xfa4e4cc89fa5f264ULL,
+    0x5a5f9f481e2b7d24ULL, 0x484c47ab18d764dbULL,
+    0x400a27f2a1a7f479ULL, 0xaeeb9b2a83da7315ULL,
+    0x721c626879869734ULL, 0x042330a2d2384851ULL,
+    0x85f672fd3765aff0ULL, 0xba446b3a3e02061dULL,
+    0x73dd6ecec3888567ULL, 0xffac70ccf793a866ULL,
+    0xdfa9edb5294ed2d4ULL, 0x6c6aea7014325638ULL,
+    0x834a5a0e8c41c307ULL, 0xcdba35562fb2cb2bULL,
+    0x0ad97808d06cb404ULL, 0x0f3b440cb85aee06ULL,
+    0xe5f9c876481f213bULL, 0x98deee1289c35809ULL,
+    0x59018bbfcd394bd1ULL, 0xe01bf47220297b39ULL,
+    0xde68e1139340c087ULL, 0x9fa3ca4788e926adULL,
+    0xbb85679c840c144eULL, 0x53d8f3b71d55ffd5ULL,
+    0x0da45c5dd146caa0ULL, 0x6f34fe87c72060cdULL,
+    0x57fbc315cf6db784ULL, 0xcee421a1fca0fddeULL,
+    0x3d2d0196607b8d4bULL, 0x642c8a29ad42c69aULL,
+    0x14aff010bdd87508ULL, 0xac74837beac657b3ULL,
+    0x3216459ad821634dULL, 0x3fb219c70967a9edULL,
+    0x06bc28f3bb246cf7ULL, 0xf2082c9126d562c6ULL,
+    0x66b39278c45ee23cULL, 0xbd394f6f3f2878b9ULL,
+    0xfd33689d9e8f8cc0ULL, 0x37f4799eb017394fULL,
+    0x108cc0b26fe03d59ULL, 0xda4bd1b1417888d6ULL,
+    0xb09d1332ee6eb219ULL, 0x2f3ed975668794b4ULL,
+    0x58c0871977375982ULL, 0x7561463d78ace990ULL,
+    0x09876cff037e82f1ULL, 0x7fb83e35a8c05d94ULL,
+    0x26b9b58a65f91645ULL, 0xef20b07e9873953fULL,
+    0x3148516d0b3355b8ULL, 0x41cb2b541ba9e62aULL,
+    0x790416c613e43163ULL, 0xa011d380818e8f40ULL,
+    0x3a5025c36151f3efULL, 0xd57095bdf92266d0ULL,
+    0x498d4b0da2d97688ULL, 0x8b0c3a57353153a5ULL,
+    0x21c491df64d368e1ULL, 0x8f2f0af5e7091bf4ULL,
+    0x2da1c1240f9bb012ULL, 0xc43d59a92ccc49daULL,
+    0xbfa6573e56345c1fULL, 0x828b56a8364fd154ULL,
+    0x9a41f643e0df7cafULL, 0xbcf843c985266aeaULL,
+    0x2b1de9d7b4bfdce5ULL, 0x20059d79dedd7ab2ULL,
+    0x6dabe6d6ae3c446bULL, 0x45e81bf6c991ae7bULL,
+    0x6351ae7cac68b83eULL, 0xa432e32253b6c711ULL,
+    0xd092a9b991143cd2ULL, 0xcac711032e98b58fULL,
+    0xd8d4c9e02864ac70ULL, 0xc5fc550f96c25b89ULL,
+    0xd7ef8dec903e4276ULL, 0x67729ede7e50f06fULL,
+    0xeac28c7af045cf3dULL, 0xb15c1f945460a04aULL,
+    0x9cfddeb05bfb1058ULL, 0x93c69abce3a1fe5eULL,
+    0xeb0380dc4a4bdd6eULL, 0xd20db1e8f8081874ULL,
+    0x229a8528b7c15e14ULL, 0x44291750739fbc28ULL,
+    0xd3ccbd4e42060a27ULL, 0xf62b1c33f4ed2a97ULL,
+    0x86a8660ae4779905ULL, 0xd62e814a2a305025ULL,
+    0x477703a7a08d8addULL, 0x7b9b0e977af815c5ULL,
+    0x78c51a60a9ea2330ULL, 0xa6adfb733aaae3b7ULL,
+    0x97e5aa1e3199b60fULL, 0x0000000000000000ULL,
+    0xf4b404629df10e31ULL, 0x5564db44a6719322ULL,
+    0x9207961a59afec0dULL, 0x9624a6b88b97a45cULL,
+    0x363575380a192b1cULL, 0x2c60cd82b595a241ULL,
+    0x7d272664c1dc7932ULL, 0x7142769faa94a1c1ULL,
+    0xa1d0df263b809d13ULL, 0x1630e841d4c451aeULL,
+    0xc1df65ad44fa13d8ULL, 0x13d2d445bcf20bacULL,
+    0xd915c546926abe23ULL, 0x38cf3d92084dd749ULL,
+    0xe766d0272103059dULL, 0xc7634d5effde7f2fULL,
+    0x077d2455012a7ea4ULL, 0xedbfa82ff16fb199ULL,
+    0xaf2a978c39d46146ULL, 0x42953fa3c8bbd0dfULL,
+    0xcb061da59496a7dcULL, 0x25e7a17db6eb20b0ULL,
+    0x34aa6d6963050fbaULL, 0xa76cf7d580a4f1e4ULL,
+    0xf7ea10954ee338c4ULL, 0xfcf2643b24819e93ULL,
+    0xcf252d0746aeef8dULL, 0x4ef06f58a3f3082cULL,
+    0x563acfb37563a5d7ULL, 0x5086e740ce47c920ULL,
+    0x2982f186dda3f843ULL, 0x87696aac5e798b56ULL,
+    0x5d22bb1d1f010380ULL, 0x035e14f7d31236f5ULL,
+    0x3cec0d30da759f18ULL, 0xf3c920379cdb7095ULL,
+    0xb8db736b571e22bbULL, 0xdd36f5e44052f672ULL,
+    0xaac8ab8851e23b44ULL, 0xa857b3d938fe1fe2ULL,
+    0x17f1e4e76eca43fdULL, 0xec7ea4894b61a3caULL,
+    0x9e62c6e132e734feULL, 0xd4b1991b432c7483ULL,
+    0x6ad6c283af163acfULL, 0x1ce9904904a8e5aaULL,
+    0x5fbda34c761d2726ULL, 0xf910583f4cb7c491ULL,
+    0xc6a241f845d06d7cULL, 0x4f3163fe19fd1a7fULL,
+    0xe99c988d2357f9c8ULL, 0x8eee06535d0709a7ULL,
+    0x0efa48aa0254fc55ULL, 0xb4be23903c56fa48ULL,
+    0x763f52caabbedf65ULL, 0xeee1bcd8227d876cULL,
+    0xe345e085f33b4dccULL, 0x3e731561b369bbbeULL,
+    0x2843fd2067adea10ULL, 0x2adce5710eb1ceb6ULL,
+    0xb7e03767ef44ccbdULL, 0x8db012a48e153f52ULL,
+    0x61ceb62dc5749c98ULL, 0xe85d942b9959eb9bULL,
+    0x4c6f7709caef2c8aULL, 0x84377e5b8d6bbda3ULL,
+    0x30895dcbb13d47ebULL, 0x74a04a9bc2a2fbc3ULL,
+    0x6b17ce251518289cULL, 0xe438c4d0f2113368ULL,
+    0x1fb784bed7bad35fULL, 0x9b80fae55ad16efcULL,
+    0x77fe5e6c11b0cd36ULL, 0xc858095247849129ULL,
+    0x08466059b97090a2ULL, 0x01c10ca6ba0e1253ULL,
+    0x6988d6747c040c3aULL, 0x6849dad2c60a1e69ULL,
+    0x5147ebe67449db73ULL, 0xc99905f4fd8a837aULL,
+    0x991fe2b433cd4a5aULL, 0xf09734c04fc94660ULL,
+    0xa28ecbd1e892abe6ULL, 0xf1563866f5c75433ULL,
+    0x4dae7baf70e13ed9ULL, 0x7ce62ac27bd26b61ULL,
+    0x70837a39109ab392ULL, 0x90988e4b30b3c8abULL,
+    0xb2020b63877296bfULL, 0x156efcb607d6675bULL },
+  /* 7 */
+  { 0xe63f55ce97c331d0ULL, 0x25b506b0015bba16ULL,
+    0xc8706e29e6ad9ba8ULL, 0x5b43d3775d521f6aULL,
+    0x0bfa3d577035106eULL, 0xab95fc172afb0e66ULL,
+    0xf64b63979e7a3276ULL, 0xf58b4562649dad4bULL,
+    0x48f7c3dbae0c83f1ULL, 0xff31916642f5c8c5ULL,
+    0xcbb048dc1c4a0495ULL, 0x66b8f83cdf622989ULL,
+    0x35c130e908e2b9b0ULL, 0x7c761a61f0b34fa1ULL,
+    0x3601161cf205268dULL, 0x9e54ccfe2219b7d6ULL,
+    0x8b7d90a538940837ULL, 0x9cd403588ea35d0bULL,
+    0xbc3c6fea9ccc5b5aULL, 0xe5ff733b6d24aeedULL,
+    0xceed22de0f7eb8d2ULL, 0xec8581cab1ab545eULL,
+    0xb96105e88ff8e71dULL, 0x8ca03501871a5eadULL,
+    0x76ccce65d6db2a2fULL, 0x5883f582a7b58057ULL,
+    0x3f7be4ed2e8adc3eULL, 0x0fe7be06355cd9c9ULL,
+    0xee054e6c1d11be83ULL, 0x1074365909b903a6ULL,
+    0x5dde9f80b4813c10ULL, 0x4a770c7d02b6692cULL,
+    0x5379c8d5d7809039ULL, 0xb4067448161ed409ULL,
+    0x5f5e5026183bd6cdULL, 0xe898029bf4c29df9ULL,
+    0x7fb63c940a54d09cULL, 0xc5171f897f4ba8bcULL,
+    0xa6f28db7b31d3d72ULL, 0x2e4f3be7716eaa78ULL,
+    0x0d6771a099e63314ULL, 0x82076254e41bf284ULL,
+    0x2f0fd2b42733df98ULL, 0x5c9e76d3e2dc49f0ULL,
+    0x7aeb569619606cdbULL, 0x83478b07b2468764ULL,
+    0xcfadcb8d5923cd32ULL, 0x85dac7f05b95a41eULL,
+    0xb5469d1b4043a1e9ULL, 0xb821ecbbd9a592fdULL,
+    0x1b8e0b0e798c13c8ULL, 0x62a57b6d9a0be02eULL,
+    0xfcf1b793b81257f8ULL, 0x9d94ea0bd8fe28ebULL,
+    0x4cea408aeb654a56ULL, 0x23284a47e888996cULL,
+    0x2d8f1d128b893545ULL, 0xf4cbac3132c0d8abULL,
+    0xbd7c86b9ca912ebaULL, 0x3a268eef3dbe6079ULL,
+    0xf0d62f6077a9110cULL, 0x2735c916ade150cbULL,
+    0x89fd5f03942ee2eaULL, 0x1acee25d2fd16628ULL,
+    0x90f39bab41181bffULL, 0x430dfe8cde39939fULL,
+    0xf70b8ac4c8274796ULL, 0x1c53aeaac6024552ULL,
+    0x13b410acf35e9c9bULL, 0xa532ab4249faa24fULL,
+    0x2b1251e5625a163fULL, 0xd7e3e676da4841c7ULL,
+    0xa7b264e4e5404892ULL, 0xda8497d643ae72d3ULL,
+    0x861ae105a1723b23ULL, 0x38a6414991048aa4ULL,
+    0x6578dec92585b6b4ULL, 0x0280cfa6acbaeaddULL,
+    0x88bdb650c273970aULL, 0x9333bd5ebbff84c2ULL,
+    0x4e6a8f2c47dfa08bULL, 0x321c954db76cef2aULL,
+    0x418d312a72837942ULL, 0xb29b38bfffcdf773ULL,
+    0x6c022c38f90a4c07ULL, 0x5a033a240b0f6a8aULL,
+    0x1f93885f3ce5da6fULL, 0xc38a537e96988bc6ULL,
+    0x39e6a81ac759ff44ULL, 0x29929e43cee0fce2ULL,
+    0x40cdd87924de0ca2ULL, 0xe9d8ebc8a29fe819ULL,
+    0x0c2798f3cfbb46f4ULL, 0x55e484223e53b343ULL,
+    0x4650948ecd0d2fd8ULL, 0x20e86cb2126f0651ULL,
+    0x6d42c56baf5739e7ULL, 0xa06fc1405ace1e08ULL,
+    0x7babbfc54f3d193bULL, 0x424d17df8864e67fULL,
+    0xd8045870ef14980eULL, 0xc6d7397c85ac3781ULL,
+    0x21a885e1443273b1ULL, 0x67f8116f893f5c69ULL,
+    0x24f5efe35706cff6ULL, 0xd56329d076f2ab1aULL,
+    0x5e1eb9754e66a32dULL, 0x28d2771098bd8902ULL,
+    0x8f6013f47dfdc190ULL, 0x17a993fdb637553cULL,
+    0xe0a219397e1012aaULL, 0x786b9930b5da8606ULL,
+    0x6e82e39e55b0a6daULL, 0x875a0856f72f4ec3ULL,
+    0x3741ff4fa458536dULL, 0xac4859b3957558fcULL,
+    0x7ef6d5c75c09a57cULL, 0xc04a758b6c7f14fbULL,
+    0xf9acdd91ab26ebbfULL, 0x7391a467c5ef9668ULL,
+    0x335c7c1ee1319acaULL, 0xa91533b18641e4bbULL,
+    0xe4bf9a683b79db0dULL, 0x8e20faa72ba0b470ULL,
+    0x51f907737b3a7ae4ULL, 0x2268a314bed5ec8cULL,
+    0xd944b123b949edeeULL, 0x31dcb3b84d8b7017ULL,
+    0xd3fe65279f218860ULL, 0x097af2f1dc8ffab3ULL,
+    0x9b09a6fc312d0b91ULL, 0xcc6ded78a3c4520fULL,
+    0x3481d9ba5ebfcc50ULL, 0x4f2a667f1182d56bULL,
+    0xdfd9fdd4509ace94ULL, 0x26752045fbbc252bULL,
+    0xbffc491f662bc467ULL, 0xdd593272fc202449ULL,
+    0x3cbbc218d46d4303ULL, 0x91b372f817456e1fULL,
+    0x681faf69bc6385a0ULL, 0xb686bbeebaa43ed4ULL,
+    0x1469b5084cd0ca01ULL, 0x98c98009cbca94acULL,
+    0x6438379a73d8c354ULL, 0xc2caba2dc0c5fe26ULL,
+    0x3e3b0dbe78d7a9deULL, 0x50b9ee202d670f04ULL,
+    0x4590b27b37eab0e5ULL, 0x6025b4cb36b10af3ULL,
+    0xfb2c1237079c0162ULL, 0xa12f28130c936be8ULL,
+    0x4b37e52e54eb1cccULL, 0x083a1ba28ad28f53ULL,
+    0xc10a9cd83a22611bULL, 0x9f1425ad7444c236ULL,
+    0x069d4cf7e9d3237aULL, 0xedc56899e7f621beULL,
+    0x778c273680865fcfULL, 0x309c5aeb1bd605f7ULL,
+    0x8de0dc52d1472b4dULL, 0xf8ec34c2fd7b9e5fULL,
+    0xea18cd3d58787724ULL, 0xaad515447ca67b86ULL,
+    0x9989695a9d97e14cULL, 0x0000000000000000ULL,
+    0xf196c63321f464ecULL, 0x71116bc169557cb5ULL,
+    0xaf887f466f92c7c1ULL, 0x972e3e0ffe964d65ULL,
+    0x190ec4a8d536f915ULL, 0x95aef1a9522ca7b8ULL,
+    0xdc19db21aa7d51a9ULL, 0x94ee18fa0471d258ULL,
+    0x8087adf248a11859ULL, 0xc457f6da2916dd5cULL,
+    0xfa6cfb6451c17482ULL, 0xf256e0c6db13fbd1ULL,
+    0x6a9f60cf10d96f7dULL, 0x4daaa9d9bd383fb6ULL,
+    0x03c026f5fae79f3dULL, 0xde99148706c7bb74ULL,
+    0x2a52b8b6340763dfULL, 0x6fc20acd03edd33aULL,
+    0xd423c08320afdefaULL, 0xbbe1ca4e23420dc0ULL,
+    0x966ed75ca8cb3885ULL, 0xeb58246e0e2502c4ULL,
+    0x055d6a021334bc47ULL, 0xa47242111fa7d7afULL,
+    0xe3623fcc84f78d97ULL, 0x81c744a11efc6db9ULL,
+    0xaec8961539cfb221ULL, 0xf31609958d4e8e31ULL,
+    0x63e5923ecc5695ceULL, 0x47107ddd9b505a38ULL,
+    0xa3afe7b5a0298135ULL, 0x792b7063e387f3e6ULL,
+    0x0140e953565d75e0ULL, 0x12f4f9ffa503e97bULL,
+    0x750ce8902c3cb512ULL, 0xdbc47e8515f30733ULL,
+    0x1ed3610c6ab8af8fULL, 0x5239218681dde5d9ULL,
+    0xe222d69fd2aaf877ULL, 0xfe71783514a8bd25ULL,
+    0xcaf0a18f4a177175ULL, 0x61655d9860ec7f13ULL,
+    0xe77fbc9dc19e4430ULL, 0x2ccff441ddd440a5ULL,
+    0x16e97aaee06a20dcULL, 0xa855dae2d01c915bULL,
+    0x1d1347f9905f30b2ULL, 0xb7c652bdecf94b34ULL,
+    0xd03e43d265c6175dULL, 0xfdb15ec0ee4f2218ULL,
+    0x57644b8492e9599eULL, 0x07dda5a4bf8e569aULL,
+    0x54a46d71680ec6a3ULL, 0x5624a2d7c4b42c7eULL,
+    0xbebca04c3076b187ULL, 0x7d36f332a6ee3a41ULL,
+    0x3b6667bc6be31599ULL, 0x695f463aea3ef040ULL,
+    0xad08b0e0c3282d1cULL, 0xb15b1e4a052a684eULL,
+    0x44d05b2861b7c505ULL, 0x15295c5b1a8dbfe1ULL,
+    0x744c01c37a61c0f2ULL, 0x59c31cd1f1e8f5b7ULL,
+    0xef45a73f4b4ccb63ULL, 0x6bdf899c46841a9dULL,
+    0x3dfb2b4b823036e3ULL, 0xa2ef0ee6f674f4d5ULL,
+    0x184e2dfb836b8cf5ULL, 0x1134df0a5fe47646ULL,
+    0xbaa1231d751f7820ULL, 0xd17eaa81339b62bdULL,
+    0xb01bf71953771daeULL, 0x849a2ea30dc8d1feULL,
+    0x705182923f080955ULL, 0x0ea757556301ac29ULL,
+    0x041d83514569c9a7ULL, 0x0abad4042668658eULL,
+    0x49b72a88f851f611ULL, 0x8a3d79f66ec97dd7ULL,
+    0xcd2d042bf59927efULL, 0xc930877ab0f0ee48ULL,
+    0x9273540deda2f122ULL, 0xc797d02fd3f14261ULL,
+    0xe1e2f06a284d674aULL, 0xd2be8c74c97cfd80ULL,
+    0x9a494faf67707e71ULL, 0xb3dbd1eca9908293ULL,
+    0x72d14d3493b2e388ULL, 0xd6a30f258c153427ULL },
+};
+
+static const uint64_t C16[12][8] =
+{
+  { 0xdd806559f2a64507ULL, 0x05767436cc744d23ULL,
+    0xa2422a08a460d315ULL, 0x4b7ce09192676901ULL,
+    0x714eb88d7585c4fcULL, 0x2f6a76432e45d016ULL,
+    0xebcb2f81c0657c1fULL, 0xb1085bda1ecadae9ULL },
+  { 0xe679047021b19bb7ULL, 0x55dda21bd7cbcd56ULL,
+    0x5cb561c2db0aa7caULL, 0x9ab5176b12d69958ULL,
+    0x61d55e0f16b50131ULL, 0xf3feea720a232b98ULL,
+    0x4fe39d460f70b5d7ULL, 0x6fa3b58aa99d2f1aULL },
+  { 0x991e96f50aba0ab2ULL, 0xc2b6f443867adb31ULL,
+    0xc1c93a376062db09ULL, 0xd3e20fe490359eb1ULL,
+    0xf2ea7514b1297b7bULL, 0x06f15e5f529c1f8bULL,
+    0x0a39fc286a3d8435ULL, 0xf574dcac2bce2fc7ULL },
+  { 0x220cbebc84e3d12eULL, 0x3453eaa193e837f1ULL,
+    0xd8b71333935203beULL, 0xa9d72c82ed03d675ULL,
+    0x9d721cad685e353fULL, 0x488e857e335c3c7dULL,
+    0xf948e1a05d71e4ddULL, 0xef1fdfb3e81566d2ULL },
+  { 0x601758fd7c6cfe57ULL, 0x7a56a27ea9ea63f5ULL,
+    0xdfff00b723271a16ULL, 0xbfcd1747253af5a3ULL,
+    0x359e35d7800fffbdULL, 0x7f151c1f1686104aULL,
+    0x9a3f410c6ca92363ULL, 0x4bea6bacad474799ULL },
+  { 0xfa68407a46647d6eULL, 0xbf71c57236904f35ULL,
+    0x0af21f66c2bec6b6ULL, 0xcffaa6b71c9ab7b4ULL,
+    0x187f9ab49af08ec6ULL, 0x2d66c4f95142a46cULL,
+    0x6fa4c33b7a3039c0ULL, 0xae4faeae1d3ad3d9ULL },
+  { 0x8886564d3a14d493ULL, 0x3517454ca23c4af3ULL,
+    0x06476983284a0504ULL, 0x0992abc52d822c37ULL,
+    0xd3473e33197a93c9ULL, 0x399ec6c7e6bf87c9ULL,
+    0x51ac86febf240954ULL, 0xf4c70e16eeaac5ecULL },
+  { 0xa47f0dd4bf02e71eULL, 0x36acc2355951a8d9ULL,
+    0x69d18d2bd1a5c42fULL, 0xf4892bcb929b0690ULL,
+    0x89b4443b4ddbc49aULL, 0x4eb7f8719c36de1eULL,
+    0x03e7aa020c6e4141ULL, 0x9b1f5b424d93c9a7ULL },
+  { 0x7261445183235adbULL, 0x0e38dc92cb1f2a60ULL,
+    0x7b2b8a9aa6079c54ULL, 0x800a440bdbb2ceb1ULL,
+    0x3cd955b7e00d0984ULL, 0x3a7d3a1b25894224ULL,
+    0x944c9ad8ec165fdeULL, 0x378f5a541631229bULL },
+  { 0x74b4c7fb98459cedULL, 0x3698fad1153bb6c3ULL,
+    0x7a1e6c303b7652f4ULL, 0x9fe76702af69334bULL,
+    0x1fffe18a1b336103ULL, 0x8941e71cff8a78dbULL,
+    0x382ae548b2e4f3f3ULL, 0xabbedea680056f52ULL },
+  { 0x6bcaa4cd81f32d1bULL, 0xdea2594ac06fd85dULL,
+    0xefbacd1d7d476e98ULL, 0x8a1d71efea48b9caULL,
+    0x2001802114846679ULL, 0xd8fa6bbbebab0761ULL,
+    0x3002c6cd635afe94ULL, 0x7bcd9ed0efc889fbULL },
+  { 0x48bc924af11bd720ULL, 0xfaf417d5d9b21b99ULL,
+    0xe71da4aa88e12852ULL, 0x5d80ef9d1891cc86ULL,
+    0xf82012d430219f9bULL, 0xcda43c32bcdf1d77ULL,
+    0xd21380b00449b17aULL, 0x378ee767f11631baULL },
+};
+
+#define strido(out, temp, i) do { \
+	uint64_t t; \
+	t  = streebog_table[0][(temp[0] &gt;&gt; (i * 8)) &amp; 0xff]; \
+	t ^= streebog_table[1][(temp[1] &gt;&gt; (i * 8)) &amp; 0xff]; \
+	t ^= streebog_table[2][(temp[2] &gt;&gt; (i * 8)) &amp; 0xff]; \
+	t ^= streebog_table[3][(temp[3] &gt;&gt; (i * 8)) &amp; 0xff]; \
+	t ^= streebog_table[4][(temp[4] &gt;&gt; (i * 8)) &amp; 0xff]; \
+	t ^= streebog_table[5][(temp[5] &gt;&gt; (i * 8)) &amp; 0xff]; \
+	t ^= streebog_table[6][(temp[6] &gt;&gt; (i * 8)) &amp; 0xff]; \
+	t ^= streebog_table[7][(temp[7] &gt;&gt; (i * 8)) &amp; 0xff]; \
+	out[i] = t; } while(0)
+
+static void LPSX (uint64_t *out, const uint64_t *a, const uint64_t *b)
+{
+  uint64_t temp[8];
+  temp[0] = a[0] ^ b[0];
+  temp[1] = a[1] ^ b[1];
+  temp[2] = a[2] ^ b[2];
+  temp[3] = a[3] ^ b[3];
+  temp[4] = a[4] ^ b[4];
+  temp[5] = a[5] ^ b[5];
+  temp[6] = a[6] ^ b[6];
+  temp[7] = a[7] ^ b[7];
+  strido (out, temp, 0);
+  strido (out, temp, 1);
+  strido (out, temp, 2);
+  strido (out, temp, 3);
+  strido (out, temp, 4);
+  strido (out, temp, 5);
+  strido (out, temp, 6);
+  strido (out, temp, 7);
+}
+
+static inline void g (uint64_t *h, uint64_t *m, uint64_t *N)
+{
+  uint64_t K[8];
+  uint64_t T[8];
+  int i;
+
+  LPSX (K, h, N);
+
+  LPSX (T, K, m);
+  LPSX (K, K, C16[0]);
+  for (i = 1; i &lt; 12; i++)
+    {
+      LPSX (T, K, T);
+      LPSX (K, K, C16[i]);
+    }
+
+  h[0] ^= T[0] ^ K[0] ^ m[0];
+  h[1] ^= T[1] ^ K[1] ^ m[1];
+  h[2] ^= T[2] ^ K[2] ^ m[2];
+  h[3] ^= T[3] ^ K[3] ^ m[3];
+  h[4] ^= T[4] ^ K[4] ^ m[4];
+  h[5] ^= T[5] ^ K[5] ^ m[5];
+  h[6] ^= T[6] ^ K[6] ^ m[6];
+  h[7] ^= T[7] ^ K[7] ^ m[7];
+}
+
+
+static void
+streebog512_compress (struct streebog512_ctx *ctx, const uint8_t *input, uint64_t count)
+{
+  uint64_t M[8];
+  uint64_t cf;
+  int i;
+
+  for (i = 0; i &lt; 8; i++, input += 8)
+    M[i] = LE_READ_UINT64(input);
+
+  g (ctx-&gt;state, M, ctx-&gt;count);
+  ctx-&gt;count[0] += count;
+  if (ctx-&gt;count[0] &lt; count)
+    { /* overflow */
+      for (i = 1; i &lt; 8; i++)
+        {
+          ctx-&gt;count[i]++;
+          if (ctx-&gt;count[i] != 0)
+            break;
+        }
+    }
+
+  ctx-&gt;sigma[0] += M[0];
+  cf = (ctx-&gt;sigma[0] &lt; M[0]);
+  for (i = 1; i &lt; 7; i++)
+    {
+      ctx-&gt;sigma[i] += cf;
+      cf = (ctx-&gt;sigma[i] &lt; cf);
+      ctx-&gt;sigma[i] += M[i];
+      cf |= (ctx-&gt;sigma[i] &lt; M[i]);
+    }
+  ctx-&gt;sigma[7] += M[7] + cf;
+}
+
+static void
+streebog_final (struct streebog512_ctx *ctx)
+{
+  uint64_t Z[8] = {};
+  unsigned int i;
+
+  /* PAD. It does not count towards message length */
+  i = ctx-&gt;index;
+  /* We have at least one byte free) */
+  ctx-&gt;block[i++] = 1;
+  while (i &lt; 64)
+    ctx-&gt;block[i++] = 0;
+  streebog512_compress (ctx, ctx-&gt;block, ctx-&gt;index * 8);
+
+  g (ctx-&gt;state, ctx-&gt;count, Z);
+  g (ctx-&gt;state, ctx-&gt;sigma, Z);
+}
+
+#define COMPRESS(ctx, data) (streebog512_compress((ctx), (data), 64 * 8))
+
+void
+streebog512_init(struct streebog512_ctx *ctx)
+{
+  memset(ctx-&gt;state, 0, sizeof(ctx-&gt;state));
+  memset(ctx-&gt;count, 0, sizeof(ctx-&gt;count));
+  memset(ctx-&gt;sigma, 0, sizeof(ctx-&gt;sigma));
+
+  /* Initialize buffer */
+  ctx-&gt;index = 0;
+}
+
+void
+streebog512_update(struct streebog512_ctx *ctx,
+                   size_t length, const uint8_t *data)
+{
+  MD_UPDATE (ctx, length, data, COMPRESS, (void)0);
+}
+
+static void
+streebog512_write_digest(struct streebog512_ctx *ctx,
+                         size_t offset, size_t length,
+                         uint8_t *digest)
+{
+  assert(offset + length &lt;= STREEBOG512_DIGEST_SIZE);
+
+  streebog_final(ctx);
+
+  _nettle_write_le64(length, digest, ctx-&gt;state + offset);
+}
+
+void
+streebog512_digest(struct streebog512_ctx *ctx,
+		   size_t length,
+		   uint8_t *digest)
+{
+  assert(length &lt;= STREEBOG512_DIGEST_SIZE);
+
+  streebog512_write_digest(ctx, 0, length, digest);
+  streebog512_init(ctx);
+}
+
+void
+streebog256_init(struct streebog256_ctx *ctx)
+{
+  memset(ctx-&gt;state, 1, sizeof(ctx-&gt;state));
+  memset(ctx-&gt;count, 0, sizeof(ctx-&gt;count));
+  memset(ctx-&gt;sigma, 0, sizeof(ctx-&gt;sigma));
+
+  /* Initialize buffer */
+  ctx-&gt;index = 0;
+}
+
+void
+streebog256_digest(struct streebog256_ctx *ctx,
+                   size_t length,
+                   uint8_t *digest)
+{
+  assert(length &lt;= STREEBOG256_DIGEST_SIZE);
+
+  streebog512_write_digest(ctx,
+      4,
+      length,
+      digest);
+  streebog256_init(ctx);
+}
diff --git a/streebog.h b/streebog.h
new file mode 100644
index 000000000000..69ac0d5c2746
--- /dev/null
+++ b/streebog.h
@@ -0,0 +1,99 @@
+/* streebog.h
+
+   The Streebog family of hash functions.
+
+   Copyright (C) 2020 Dmitry Baryshkov
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+ 
+#ifndef NETTLE_STREEBOG_H_INCLUDED
+#define NETTLE_STREEBOG_H_INCLUDED
+
+#include "nettle-types.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/* Name mangling */
+#define streebog256_init nettle_streebog256_init
+#define streebog256_digest nettle_streebog256_digest
+#define streebog512_init nettle_streebog512_init
+#define streebog512_update nettle_streebog512_update
+#define streebog512_digest nettle_streebog512_digest
+
+/* STREEBOG512 */
+
+#define STREEBOG512_DIGEST_SIZE 64
+#define STREEBOG512_BLOCK_SIZE 64
+
+/* Digest is kept internally as 8 64-bit words. */
+#define _STREEBOG512_DIGEST_LENGTH 8
+
+struct streebog512_ctx
+{
+  uint64_t state[_STREEBOG512_DIGEST_LENGTH];    /* State variables */
+  uint64_t count[_STREEBOG512_DIGEST_LENGTH];
+  uint64_t sigma[_STREEBOG512_DIGEST_LENGTH];
+  unsigned int index;                       /* index into buffer */
+  uint8_t block[STREEBOG512_BLOCK_SIZE];          /* STREEBOG512 data buffer */
+};
+
+void
+streebog512_init(struct streebog512_ctx *ctx);
+
+void
+streebog512_update(struct streebog512_ctx *ctx,
+	      size_t length,
+	      const uint8_t *data);
+
+void
+streebog512_digest(struct streebog512_ctx *ctx,
+	      size_t length,
+	      uint8_t *digest);
+
+
+#define STREEBOG256_DIGEST_SIZE 32
+#define STREEBOG256_BLOCK_SIZE STREEBOG512_BLOCK_SIZE
+#define streebog256_ctx streebog512_ctx
+
+void
+streebog256_init(struct streebog256_ctx *ctx);
+
+#define streebog256_update nettle_streebog512_update
+
+void
+streebog256_digest(struct streebog256_ctx *ctx,
+		  size_t length,
+		  uint8_t *digest);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* NETTLE_STREEBOG_H_INCLUDED */
-- 
2.26.2

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200605054639</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-06-05 05:46:39-0400</timestampReceived><subject>Re: [PATCH v3] Implement GOST R 34.11-2012 (Streebog) hash function</subject><body>

Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:

&gt; Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
&gt; ---
&gt;  Makefile.in     |    3 +-
&gt;  streebog-meta.c |   44 ++
&gt;  streebog.c      | 1317 +++++++++++++++++++++++++++++++++++++++++++++++
&gt;  streebog.h      |   99 ++++
&gt;  4 files changed, 1462 insertions(+), 1 deletion(-)
&gt;  create mode 100644 streebog-meta.c
&gt;  create mode 100644 streebog.c
&gt;  create mode 100644 streebog.h

Looks good. I'll merge when I can do it together with the tests. 

Found a minor problem when trying the tests on top of this: this patch
adds streebog-meta.c, but doesn't add the corresponding declarations in
nettle-meta.h. Ideally, those should go together (in this patch, in the test
patch, or as a separate patch). But it's also fine with me if you just
add the needed declarations together with the tests.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200612091251</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-06-12 09:12:51-0400</timestampReceived><subject>[PATCH 3/3] v4.0 Blowfish: Supply lengths instead of C-strings.</subject><body>

---
 blowfish-bcrypt.c | 56 ++++++++++++++++++++++++-----------------------
 blowfish.h        | 14 +++++++-----
 nettle.texinfo    | 27 +++++++++++++----------
 3 files changed, 52 insertions(+), 45 deletions(-)

diff --git a/blowfish-bcrypt.c b/blowfish-bcrypt.c
index c06f9e90..491aab82 100644
--- a/blowfish-bcrypt.c
+++ b/blowfish-bcrypt.c
@@ -76,13 +76,14 @@ static const char radix64_encode_table[64] =
     "0123456789";
 
 int
-blowfish_bcrypt_verify(const char *key,
-                       const char *hashed)
+blowfish_bcrypt_verify(size_t lenkey, const char *key,
+                       size_t lenhashed, const char *hashed)
 {
   char newhash[BLOWFISH_BCRYPT_HASH_SIZE];
 
-  return blowfish_bcrypt_hash(sizeof newhash,
-                              newhash, key, hashed, -1, (void*)0)
+  return blowfish_bcrypt_hash(newhash,
+                              lenkey, key, lenhashed, hashed,
+                              -1, (void*)0)
    &amp;&amp; !strcmp(newhash, hashed);
 }
 
@@ -159,10 +160,12 @@ static void swap32(uint32_t *x, int count)
 #endif
 }
 
-static void set_xkey(const char *key, bf_key expanded, bf_key initial,
-    unsigned bug, uint32_t safety)
+static void set_xkey(size_t lenkey, const char *key,
+                     bf_key expanded, bf_key initial,
+		     unsigned bug, uint32_t safety)
 {
   const char *ptr = key;
+  size_t n = lenkey;
   unsigned i, j;
   uint32_t sign, diff, tmp[2];
 
@@ -219,10 +222,10 @@ static void set_xkey(const char *key, bf_key expanded, bf_key \
                initial,
  */
       if (j)
         sign |= tmp[1] &amp; 0x80;
-      if (!*ptr)
-        ptr = key;
-      else
+      if (n--)
         ptr++;
+      else
+        ptr = key, n = lenkey;
     }
     diff |= tmp[0] ^ tmp[1]; /* Non-zero on any differences */
 
@@ -259,8 +262,9 @@ static void set_xkey(const char *key, bf_key expanded, bf_key \
initial,  initial[0] ^= sign;
 }
 
-static int ibcrypt(size_t length, char *dst,
-                   const char *key, const char *scheme,
+static int ibcrypt(char *dst,
+                   size_t lenkey, const char *key,
+		   size_t lenscheme, const char *scheme,
 		   int minlog2rounds,
 		   int log2rounds, const uint8_t *salt)
 {
@@ -277,12 +281,10 @@ static int ibcrypt(size_t length, char *dst,
   uint32_t *ptr;
   uint32_t count;
   int i;
-  size_t lenscheme = strlen(scheme);
   unsigned cscheme;
   unsigned bug = 0;
   uint32_t safety = 0;
-  if (length &lt; BLOWFISH_BCRYPT_HASH_SIZE ||
-      lenscheme &lt; 2)
+  if (lenscheme &lt; 2)
     return 0;
 
   if (lenscheme &gt;= 3 &amp;&amp; *scheme++ != '$')
@@ -336,7 +338,7 @@ static int ibcrypt(size_t length, char *dst,
     return 0;
   count = (uint32_t)1 &lt;&lt; log2rounds;
 
-  set_xkey(key, data.expanded_key, data.ctx.p, bug, safety);
+  set_xkey(lenkey, key, data.expanded_key, data.ctx.p, bug, safety);
   memcpy(data.ctx.s, _nettle_blowfish_initial_ctx.s, sizeof(data.ctx.s));
 
   L = R = 0;
@@ -461,12 +463,13 @@ static int ibcrypt(size_t length, char *dst,
  * The performance cost of this quick self-test is around 0.6% at the "$2a$08"
  * setting.
  */
-int blowfish_bcrypt_hash(size_t length, char *dst,
-                         const char *key, const char *scheme,
+int blowfish_bcrypt_hash(char *dst,
+                         size_t lenkey, const char *key,
+			 size_t lenscheme, const char *scheme,
 			 int log2rounds, const uint8_t *salt)
 {
-  const char *test_pw = "8b \xd0\xc1\xd2\xcf\xcc\xd8";
-  const char *test_scheme = "$2a$00$abcdefghijklmnopqrstuu";
+  const char test_pw[] = "8b \xd0\xc1\xd2\xcf\xcc\xd8";
+  const char test_scheme[] = "$2a$00$abcdefghijklmnopqrstuu";
   static const char * const test_hashes[2] =
     {"i1D709vfamulimlGcq0qq3UvuUasvEa\0\x55",  /* 'a', 'b', 'y' */
      "VUrPmXD6q/nVSSp7pNDhCR9071IfIRe\0\x55"}; /* 'x' */
@@ -478,10 +481,9 @@ int blowfish_bcrypt_hash(size_t length, char *dst,
     char o[HASHOFFSET + 31 + 1 + 1 + 1];
   } buf;
 
-  if (length)
-    *dst = '\0';
+  *dst = '\0';
 /* Hash the supplied password */
-  cscheme = ibcrypt(length, dst, key, scheme, 4, log2rounds, salt);
+  cscheme = ibcrypt(dst, lenkey, key, lenscheme, scheme, 4, log2rounds, salt);
 
 /*
  * Do a quick self-test. It is important that we make both calls to ibcrypt()
@@ -497,18 +499,18 @@ int blowfish_bcrypt_hash(size_t length, char *dst,
 
   memset(buf.o, 0x55, sizeof(buf.o));
   buf.o[sizeof(buf.o) - 1] = 0;
-  ok = ibcrypt(sizeof(buf.o) - (1 + 1), buf.o, test_pw,
-               buf.s, 0, -1, (void*)0);
+  ok = ibcrypt(buf.o, sizeof(test_pw), test_pw,
+               sizeof(buf.s), buf.s, 0, -1, (void*)0);
 
   ok = (ok &amp;&amp;
       !memcmp(buf.o, buf.s, HASHOFFSET) &amp;&amp;
       !memcmp(buf.o + HASHOFFSET, test_hash, 31 + 1 + 1 + 1));
 
   {
-    const char *k = "\xff\xa3" "34" "\xff\xff\xff\xa3" "345";
+    const char k[] = "\xff\xa3" "34" "\xff\xff\xff\xa3" "345";
     bf_key ae, ai, ye, yi;
-    set_xkey(k, ae, ai, 0, 0x10000); /* $2a$ */
-    set_xkey(k, ye, yi, 0, 0); /* $2y$ */
+    set_xkey(sizeof(k), k, ae, ai, 0, 0x10000); /* $2a$ */
+    set_xkey(sizeof(k), k, ye, yi, 0, 0); /* $2y$ */
     ai[0] ^= 0x10000; /* undo the safety (for comparison) */
     ok = ok &amp;&amp; ai[0] == 0xdb9c59bc &amp;&amp; ye[17] == 0x33343500 &amp;&amp;
         !memcmp(ae, ye, sizeof(ae)) &amp;&amp;
diff --git a/blowfish.h b/blowfish.h
index af48e20f..1c5bdbe1 100644
--- a/blowfish.h
+++ b/blowfish.h
@@ -86,16 +86,18 @@ void
 blowfish_decrypt(const struct blowfish_ctx *ctx,
                  size_t length, uint8_t *dst,
                  const uint8_t *src);
+
+/* dst parameter must point to a buffer of minimally
+ * BLOWFISH_BCRYPT_HASH_SIZE bytes */
 int
-blowfish_bcrypt_hash(size_t length,
-                     char *dst,
-                     const char *key,
-                     const char *scheme,
+blowfish_bcrypt_hash(char *dst,
+                     size_t lenkey, const char *key,
+                     size_t lenscheme, const char *scheme,
 		     int log2rounds,
 		     const uint8_t *salt);
 int
-blowfish_bcrypt_verify(const char *key,
-                       const char *hashed);
+blowfish_bcrypt_verify(size_t lenkey, const char *key,
+                       size_t lenhashed, const char *hashed);
 
 #ifdef __cplusplus
 }
diff --git a/nettle.texinfo b/nettle.texinfo
index 75e18b58..2269e11d 100644
--- a/nettle.texinfo
+++ b/nettle.texinfo
@@ -1513,7 +1513,7 @@ in any other way.
 Analogous to @code{blowfish_encrypt}
 @end deftypefun
 
-@deftypefun int blowfish_bcrypt_hash (size_t @var{length}, char *@var{dst}, const \
char *@var{key}, const char *@var{scheme}, int @var{log2rounds}, const uint8_t \
*@var{salt}) +@deftypefun int blowfish_bcrypt_hash (char *@var{dst}, size_t \
@var{lenkey}, const char *@var{key}, size_t @var{lenscheme}, const char \
*@var{scheme}, int @var{log2rounds}, const uint8_t *@var{salt})  Compute the bcrypt \
password hash.  The function will return @code{0} if the hash cannot be computed
 due to invalid input.
@@ -1522,13 +1522,13 @@ in the array pointed to by @var{dst}.  The hash is computed \
based  on the chosen @var{scheme}, number of rounds @var{log2rounds} and
 specified @var{salt}.
 
-@var{length} must be at least @code{BLOWFISH_BCRYPT_HASH_SIZE}.
+@var{dst} must point to a character array of at least
+ @code{BLOWFISH_BCRYPT_HASH_SIZE} bytes.
 
-@var{dst} must point to a character array of the specified @var{length}.
+@var{key} contains the plaintext password string of size @var{lenkey}.
 
-@var{key} contains the zero terminated plaintext password string.
-
-@var{scheme} contains either just the chosen scheme (valid schemes
+@var{scheme} is of size @var{lenscheme} and contains either just the
+chosen scheme (valid schemes
 are: @code{2a}, @code{2b}, @code{2x} or @code{2y}), or
 (the prefix of) an existing hashed password (typically @code{$2b$10$...}).
 
@@ -1543,26 +1543,28 @@ the salt will be extracted from @var{scheme}.
 Sample code to generate a bcrypt hash:
 @example
 char cleartxtpassword[] = "ExamplePassword";
+char scheme[] = "2b";
 uint8_t salt[BLOWFISH_BCRYPT_BINSALT_SIZE];
 @dots{}
 /* Make sure that salt is filled with random bytes */
 @dots{}
 char hashedresult[BLOWFISH_BCRYPT_HASH_SIZE];
-int result = blowfish_bcrypt(sizeof(hashedresult), hashedresult,
-                             cleartxtpassword, "2b", 10, salt);
+int result = blowfish_bcrypt(hashedresult,
+                             sizeof(cleartxtpassword), cleartxtpassword,
+                             sizeof(scheme), scheme, 10, salt);
 if (result)
   printf("%s\n", hashedresult);
 @end example
 @end deftypefun
 
-@deftypefun int blowfish_bcrypt_verify (const char *@var{key}, const char \
*@var{hashed}) +@deftypefun int blowfish_bcrypt_verify (size_t @var{lenkey}, const \
char *@var{key}, size_t @var{lenhashed}, const char *@var{hashed})  Verifies the \
bcrypt password hash against the supplied plaintext password.  The function will \
return @code{0} if the password does not match.  The function will return @code{1} if \
the password matches.  
-@var{key} contains the zero terminated plaintext password string.
+@var{key} contains the plaintext password string of size @var{lenkey}.
 
-@var{hashed} contains the zero terminated hashed string to compare with.
+@var{hashed} contains the hashed string of size @var{lenhashed} to compare with.
 
 Sample code to verify a bcrypt hash:
 @example
@@ -1573,7 +1575,8 @@ char existinghashed[] =
            "$"   /* separator */
            "1b2lPgo4XumibnJGN3r3sO" /* base64 encoded 16-byte salt */
            "u7wE7xNfYDKlAxZffJDCJdVfFTAyevu"; /* Hashedpart */
-if (blowfish_bcrypt_verify(cleartxtpassword, existinghashed))
+if (blowfish_bcrypt_verify(sizeof(cleartxtpassword), cleartxtpassword,
+                           sizeof(existinghashed), existinghashed))
   printf("Password is correct.");
 else
   printf("Password is incorrect.");
-- 
2.20.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200618202721</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-06-18 20:27:21-0400</timestampReceived><subject>[PATCH] optimized AES and GHASH for PPC64LE</subject><body>

diff --git a/configure.ac b/configure.ac
index 90ea1ea8..1ea54ce8 100644
--- a/configure.ac
+++ b/configure.ac
@@ -435,6 +435,9 @@ if test "x$enable_assembler" = xyes ; then
   esac
       fi
       ;;
+    *powerpc64le*)
+  asm_path=powerpc64le
+      ;;
     *)
       enable_assembler=no
       ;;
@@ -572,7 +575,9 @@ AH_VERBATIM([HAVE_NATIVE],
 #undef HAVE_NATIVE_ecc_secp384r1_redc
 #undef HAVE_NATIVE_ecc_secp521r1_modp
 #undef HAVE_NATIVE_ecc_secp521r1_redc
+#undef HAVE_NATIVE_gcm_init_key8
 #undef HAVE_NATIVE_gcm_hash8
+#undef HAVE_NATIVE_gcm_fill
 #undef HAVE_NATIVE_salsa20_core
 #undef HAVE_NATIVE_sha1_compress
 #undef HAVE_NATIVE_sha256_compress
diff --git a/gcm.c b/gcm.c
index cf615daf..809c03bc 100644
--- a/gcm.c
+++ b/gcm.c
@@ -140,6 +140,12 @@ gcm_gf_mul (union nettle_block16 *x, const union
nettle_block16 *table)
   memcpy (x-&gt;b, Z.b, sizeof(Z));
 }
 # elif GCM_TABLE_BITS == 8
+#  if HAVE_NATIVE_gcm_init_key8
+
+#define gcm_init_key _nettle_gcm_init_key8
+void
+_nettle_gcm_init_key8 (union nettle_block16 *table);
+#  endif /* HAVE_NATIVE_gcm_init_key8 */
 #  if HAVE_NATIVE_gcm_hash8

 #define gcm_hash _nettle_gcm_hash8
@@ -225,6 +231,13 @@ gcm_gf_mul (union nettle_block16 *x, const union
nettle_block16 *table)

 #endif /* GCM_TABLE_BITS */

+#if HAVE_NATIVE_gcm_fill
+
+#define gcm_fill _nettle_gcm_fill
+void
+_nettle_gcm_fill (uint8_t *ctr, size_t blocks, union nettle_block16 *buffer);
+#endif /* HAVE_NATIVE_gcm_fill */
+
 /* Increment the rightmost 32 bits. */
 #define INC32(block) INCREMENT(4, (block.b) + GCM_BLOCK_SIZE - 4)

@@ -245,7 +258,9 @@ gcm_set_key(struct gcm_key *key,
   memset(key-&gt;h[0].b, 0, GCM_BLOCK_SIZE);
   f (cipher, GCM_BLOCK_SIZE, key-&gt;h[i].b, key-&gt;h[0].b);

-#if GCM_TABLE_BITS
+#ifdef gcm_init_key
+  gcm_init_key(key-&gt;h);
+#elif GCM_TABLE_BITS
   /* Algorithm 3 from the gcm paper. First do powers of two, then do
      the rest by adding. */
   while (i /= 2)
@@ -333,6 +348,7 @@ gcm_update(struct gcm_ctx *ctx, const struct gcm_key *key,
   ctx-&gt;auth_size += length;
 }

+#ifndef gcm_fill
 static nettle_fill16_func gcm_fill;
 static void
 gcm_fill(uint8_t *ctr, size_t blocks, union nettle_block16 *buffer)
@@ -349,6 +365,7 @@ gcm_fill(uint8_t *ctr, size_t blocks, union
nettle_block16 *buffer)

   WRITE_UINT32(ctr + GCM_BLOCK_SIZE - 4, c);
 }
+#endif /* !gcm_fill */

 void
 gcm_encrypt (struct gcm_ctx *ctx, const struct gcm_key *key,
diff --git a/powerpc64le/aes-decrypt-internal.asm
b/powerpc64le/aes-decrypt-internal.asm
index e69de29b..bde34779 100755
--- a/powerpc64le/aes-decrypt-internal.asm
+++ b/powerpc64le/aes-decrypt-internal.asm
@@ -0,0 +1,573 @@
+C powerpc64le/aes-decrypt-internal.asm
+
+ifelse(&lt;
+   Copyright (C) 2020 Mamone Tarsha
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+&gt;)
+
+C Register usage:
+
+define(&lt;SP&gt;, &lt;1&gt;)
+define(&lt;TOCP&gt;, &lt;2&gt;)
+
+define(&lt;ROUNDS&gt;, &lt;3&gt;)
+define(&lt;KEYS&gt;, &lt;4&gt;)
+define(&lt;LENGTH&gt;, &lt;6&gt;)
+define(&lt;DST&gt;, &lt;7&gt;)
+define(&lt;SRC&gt;, &lt;8&gt;)
+
+define(&lt;swap_mask&gt;, &lt;0&gt;)
+
+define(&lt;K&gt;, &lt;1&gt;)
+define(&lt;S0&gt;, &lt;2&gt;)
+define(&lt;S1&gt;, &lt;3&gt;)
+define(&lt;S2&gt;, &lt;4&gt;)
+define(&lt;S3&gt;, &lt;5&gt;)
+define(&lt;S4&gt;, &lt;6&gt;)
+define(&lt;S5&gt;, &lt;7&gt;)
+define(&lt;S6&gt;, &lt;8&gt;)
+define(&lt;S7&gt;, &lt;9&gt;)
+define(&lt;S8&gt;, &lt;10&gt;)
+define(&lt;S9&gt;, &lt;11&gt;)
+define(&lt;S10&gt;, &lt;12&gt;)
+define(&lt;S11&gt;, &lt;13&gt;)
+define(&lt;S12&gt;, &lt;14&gt;)
+define(&lt;S13&gt;, &lt;15&gt;)
+define(&lt;S14&gt;, &lt;16&gt;)
+define(&lt;S15&gt;, &lt;17&gt;)
+
+define(&lt;KX&gt;, &lt;33&gt;)
+define(&lt;S0X&gt;, &lt;34&gt;)
+define(&lt;S1X&gt;, &lt;35&gt;)
+define(&lt;S2X&gt;, &lt;36&gt;)
+define(&lt;S3X&gt;, &lt;37&gt;)
+define(&lt;S4X&gt;, &lt;38&gt;)
+define(&lt;S5X&gt;, &lt;39&gt;)
+define(&lt;S6X&gt;, &lt;40&gt;)
+define(&lt;S7X&gt;, &lt;41&gt;)
+define(&lt;S8X&gt;, &lt;42&gt;)
+define(&lt;S9X&gt;, &lt;43&gt;)
+define(&lt;S10X&gt;, &lt;44&gt;)
+define(&lt;S11X&gt;, &lt;45&gt;)
+define(&lt;S12X&gt;, &lt;46&gt;)
+define(&lt;S13X&gt;, &lt;47&gt;)
+define(&lt;S14X&gt;, &lt;48&gt;)
+define(&lt;S15X&gt;, &lt;49&gt;)
+
+C ZERO vector register is used in place of RoundKey
+C for vncipher instruction because the order of InvMixColumns
+C and Xor processes are flipped in that instruction.
+C The Xor process with RoundKey is executed afterward.
+define(&lt;ZERO&gt;, &lt;18&gt;)
+
+  .file "aes-decrypt-internal.asm"
+
+  C _aes_decrypt(unsigned rounds, const uint32_t *keys,
+  C         const struct aes_table *T,
+  C         size_t length, uint8_t *dst,
+  C         uint8_t *src)
+
+  .text
+.align 5
+PROLOGUE(_nettle_aes_decrypt)
+  vxor      ZERO,ZERO,ZERO
+
+  ld          5,.swap_mask@got(TOCP)
+  lvx         swap_mask,0,5
+
+  subi      ROUNDS,ROUNDS,1
+  srdi      LENGTH,LENGTH,4
+
+  srdi      5,LENGTH,4              # 16x loop count
+  cmpldi      5,0
+  beq       L8x
+
+  std       17,-120(SP);
+  std       18,-112(SP);
+  std       19,-104(SP);
+  std       20,-96(SP);
+  std       21,-88(SP);
+  std       22,-80(SP);
+  std       23,-72(SP);
+  std       24,-64(SP);
+  std       25,-56(SP);
+  std       26,-48(SP);
+  std       27,-40(SP);
+  std       28,-32(SP);
+  std       29,-24(SP);
+  std       30,-16(SP);
+  std       31,-8(SP);
+
+  li        17,0x10
+  li        18,0x20
+  li        19,0x30
+  li        20,0x40
+  li        21,0x50
+  li        22,0x60
+  li        23,0x70
+  li        24,0x80
+  li        25,0x90
+  li        26,0xA0
+  li        27,0xB0
+  li        28,0xC0
+  li        29,0xD0
+  li        30,0xE0
+  li        31,0xF0
+
+.align 5
+Lx16_loop:
+  lxvd2x      KX,0,KEYS
+
+  lxvd2x      S0X,0,SRC
+  lxvd2x      S1X,17,SRC
+  lxvd2x      S2X,18,SRC
+  lxvd2x      S3X,19,SRC
+  lxvd2x      S4X,20,SRC
+  lxvd2x      S5X,21,SRC
+  lxvd2x      S6X,22,SRC
+  lxvd2x      S7X,23,SRC
+  lxvd2x      S8X,24,SRC
+  lxvd2x      S9X,25,SRC
+  lxvd2x      S10X,26,SRC
+  lxvd2x      S11X,27,SRC
+  lxvd2x      S12X,28,SRC
+  lxvd2x      S13X,29,SRC
+  lxvd2x      S14X,30,SRC
+  lxvd2x      S15X,31,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+  vxor      S4,S4,K
+  vxor      S5,S5,K
+  vxor      S6,S6,K
+  vxor      S7,S7,K
+  vxor      S8,S8,K
+  vxor      S9,S9,K
+  vxor      S10,S10,K
+  vxor      S11,S11,K
+  vxor      S12,S12,K
+  vxor      S13,S13,K
+  vxor      S14,S14,K
+  vxor      S15,S15,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+  vperm      S2,S2,S2,swap_mask
+  vperm      S3,S3,S3,swap_mask
+  vperm      S4,S4,S4,swap_mask
+  vperm      S5,S5,S5,swap_mask
+  vperm      S6,S6,S6,swap_mask
+  vperm      S7,S7,S7,swap_mask
+  vperm      S8,S8,S8,swap_mask
+  vperm      S9,S9,S9,swap_mask
+  vperm      S10,S10,S10,swap_mask
+  vperm      S11,S11,S11,swap_mask
+  vperm      S12,S12,S12,swap_mask
+  vperm      S13,S13,S13,swap_mask
+  vperm      S14,S14,S14,swap_mask
+  vperm      S15,S15,S15,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L16x_round_loop:
+  lxvd2x      KX,10,KEYS
+  vperm      K,K,K,swap_mask
+  vncipher   S0,S0,ZERO
+  vncipher   S1,S1,ZERO
+  vncipher   S2,S2,ZERO
+  vncipher   S3,S3,ZERO
+  vncipher   S4,S4,ZERO
+  vncipher   S5,S5,ZERO
+  vncipher   S6,S6,ZERO
+  vncipher   S7,S7,ZERO
+  vncipher   S8,S8,ZERO
+  vncipher   S9,S9,ZERO
+  vncipher   S10,S10,ZERO
+  vncipher   S11,S11,ZERO
+  vncipher   S12,S12,ZERO
+  vncipher   S13,S13,ZERO
+  vncipher   S14,S14,ZERO
+  vncipher   S15,S15,ZERO
+  vxor       S0,S0,K
+  vxor       S1,S1,K
+  vxor       S2,S2,K
+  vxor       S3,S3,K
+  vxor       S4,S4,K
+  vxor       S5,S5,K
+  vxor       S6,S6,K
+  vxor       S7,S7,K
+  vxor       S8,S8,K
+  vxor       S9,S9,K
+  vxor       S10,S10,K
+  vxor       S11,S11,K
+  vxor       S12,S12,K
+  vxor       S13,S13,K
+  vxor       S14,S14,K
+  vxor       S15,S15,K
+  addi      10,10,0x10
+  bdnz      L16x_round_loop
+
+  lxvd2x          KX,10,KEYS
+  vperm          K,K,K,swap_mask
+  vncipherlast   S0,S0,K
+  vncipherlast   S1,S1,K
+  vncipherlast   S2,S2,K
+  vncipherlast   S3,S3,K
+  vncipherlast   S4,S4,K
+  vncipherlast   S5,S5,K
+  vncipherlast   S6,S6,K
+  vncipherlast   S7,S7,K
+  vncipherlast   S8,S8,K
+  vncipherlast   S9,S9,K
+  vncipherlast   S10,S10,K
+  vncipherlast   S11,S11,K
+  vncipherlast   S12,S12,K
+  vncipherlast   S13,S13,K
+  vncipherlast   S14,S14,K
+  vncipherlast   S15,S15,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+  vperm      S2,S2,S2,swap_mask
+  vperm      S3,S3,S3,swap_mask
+  vperm      S4,S4,S4,swap_mask
+  vperm      S5,S5,S5,swap_mask
+  vperm      S6,S6,S6,swap_mask
+  vperm      S7,S7,S7,swap_mask
+  vperm      S8,S8,S8,swap_mask
+  vperm      S9,S9,S9,swap_mask
+  vperm      S10,S10,S10,swap_mask
+  vperm      S11,S11,S11,swap_mask
+  vperm      S12,S12,S12,swap_mask
+  vperm      S13,S13,S13,swap_mask
+  vperm      S14,S14,S14,swap_mask
+  vperm      S15,S15,S15,swap_mask
+
+  stxvd2x     S0X,0,DST
+  stxvd2x     S1X,17,DST
+  stxvd2x     S2X,18,DST
+  stxvd2x     S3X,19,DST
+  stxvd2x     S4X,20,DST
+  stxvd2x     S5X,21,DST
+  stxvd2x     S6X,22,DST
+  stxvd2x     S7X,23,DST
+  stxvd2x     S8X,24,DST
+  stxvd2x     S9X,25,DST
+  stxvd2x     S10X,26,DST
+  stxvd2x     S11X,27,DST
+  stxvd2x     S12X,28,DST
+  stxvd2x     S13X,29,DST
+  stxvd2x     S14X,30,DST
+  stxvd2x     S15X,31,DST
+
+  addi      SRC,SRC,0x100
+  addi      DST,DST,0x100
+  subic.    5,5,1
+  bne       Lx16_loop
+
+  ld        17,-120(SP);
+  ld        18,-112(SP);
+  ld        19,-104(SP);
+  ld        20,-96(SP);
+  ld        21,-88(SP);
+  ld        22,-80(SP);
+  ld        23,-72(SP);
+  ld        24,-64(SP);
+  ld        25,-56(SP);
+  ld        26,-48(SP);
+  ld        27,-40(SP);
+  ld        28,-32(SP);
+  ld        29,-24(SP);
+  ld        30,-16(SP);
+  ld        31,-8(SP);
+
+  clrldi   LENGTH,LENGTH,60
+
+L8x:
+  srdi      5,LENGTH,3
+  cmpldi      5,0
+  beq       L4x
+
+  lxvd2x      KX,0,KEYS
+
+  lxvd2x      S0X,0,SRC
+  li        9,0x10
+  lxvd2x      S1X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S2X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S3X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S4X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S5X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S6X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S7X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+  vxor      S4,S4,K
+  vxor      S5,S5,K
+  vxor      S6,S6,K
+  vxor      S7,S7,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+  vperm      S2,S2,S2,swap_mask
+  vperm      S3,S3,S3,swap_mask
+  vperm      S4,S4,S4,swap_mask
+  vperm      S5,S5,S5,swap_mask
+  vperm      S6,S6,S6,swap_mask
+  vperm      S7,S7,S7,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L8x_round_loop:
+  lxvd2x      KX,10,KEYS
+  vperm      K,K,K,swap_mask
+  vncipher   S0,S0,ZERO
+  vncipher   S1,S1,ZERO
+  vncipher   S2,S2,ZERO
+  vncipher   S3,S3,ZERO
+  vncipher   S4,S4,ZERO
+  vncipher   S5,S5,ZERO
+  vncipher   S6,S6,ZERO
+  vncipher   S7,S7,ZERO
+  vxor       S0,S0,K
+  vxor       S1,S1,K
+  vxor       S2,S2,K
+  vxor       S3,S3,K
+  vxor       S4,S4,K
+  vxor       S5,S5,K
+  vxor       S6,S6,K
+  vxor       S7,S7,K
+  addi      10,10,0x10
+  bdnz      L8x_round_loop
+
+  lxvd2x          KX,10,KEYS
+  vperm          K,K,K,swap_mask
+  vncipherlast   S0,S0,K
+  vncipherlast   S1,S1,K
+  vncipherlast   S2,S2,K
+  vncipherlast   S3,S3,K
+  vncipherlast   S4,S4,K
+  vncipherlast   S5,S5,K
+  vncipherlast   S6,S6,K
+  vncipherlast   S7,S7,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+  vperm      S2,S2,S2,swap_mask
+  vperm      S3,S3,S3,swap_mask
+  vperm      S4,S4,S4,swap_mask
+  vperm      S5,S5,S5,swap_mask
+  vperm      S6,S6,S6,swap_mask
+  vperm      S7,S7,S7,swap_mask
+
+  stxvd2x     S0X,0,DST
+  li        9,0x10
+  stxvd2x     S1X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S2X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S3X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S4X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S5X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S6X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S7X,9,DST
+
+  addi      SRC,SRC,0x80
+  addi      DST,DST,0x80
+
+  clrldi   LENGTH,LENGTH,61
+
+L4x:
+  srdi      5,LENGTH,2
+  cmpldi      5,0
+  beq       L2x
+
+  lxvd2x      KX,0,KEYS
+
+  lxvd2x      S0X,0,SRC
+  li        9,0x10
+  lxvd2x      S1X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S2X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S3X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+  vperm      S2,S2,S2,swap_mask
+  vperm      S3,S3,S3,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L4x_round_loop:
+  lxvd2x      KX,10,KEYS
+  vperm      K,K,K,swap_mask
+  vncipher   S0,S0,ZERO
+  vncipher   S1,S1,ZERO
+  vncipher   S2,S2,ZERO
+  vncipher   S3,S3,ZERO
+  vxor       S0,S0,K
+  vxor       S1,S1,K
+  vxor       S2,S2,K
+  vxor       S3,S3,K
+  addi      10,10,0x10
+  bdnz      L4x_round_loop
+
+  lxvd2x          KX,10,KEYS
+  vperm          K,K,K,swap_mask
+  vncipherlast   S0,S0,K
+  vncipherlast   S1,S1,K
+  vncipherlast   S2,S2,K
+  vncipherlast   S3,S3,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+  vperm      S2,S2,S2,swap_mask
+  vperm      S3,S3,S3,swap_mask
+
+  stxvd2x     S0X,0,DST
+  li        9,0x10
+  stxvd2x     S1X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S2X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S3X,9,DST
+
+  addi      SRC,SRC,0x40
+  addi      DST,DST,0x40
+
+  clrldi   LENGTH,LENGTH,62
+
+L2x:
+  srdi      5,LENGTH,1
+  cmpldi      5,0
+  beq       L1x
+
+  lxvd2x      KX,0,KEYS
+
+  lxvd2x      S0X,0,SRC
+  li        9,0x10
+  lxvd2x      S1X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L2x_round_loop:
+  lxvd2x      KX,10,KEYS
+  vperm      K,K,K,swap_mask
+  vncipher   S0,S0,ZERO
+  vncipher   S1,S1,ZERO
+  vxor       S0,S0,K
+  vxor       S1,S1,K
+  addi      10,10,0x10
+  bdnz      L2x_round_loop
+
+  lxvd2x          KX,10,KEYS
+  vperm          K,K,K,swap_mask
+  vncipherlast   S0,S0,K
+  vncipherlast   S1,S1,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+
+  stxvd2x     S0X,0,DST
+  li        9,0x10
+  stxvd2x     S1X,9,DST
+
+  addi      SRC,SRC,0x20
+  addi      DST,DST,0x20
+
+  clrldi   LENGTH,LENGTH,63
+
+L1x:
+  cmpldi      LENGTH,0
+  beq       Ldone
+
+  lxvd2x      KX,0,KEYS
+
+  lxvd2x      S0X,0,SRC
+
+  vxor      S0,S0,K
+
+  vperm      S0,S0,S0,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L1x_round_loop:
+  lxvd2x      KX,10,KEYS
+  vperm      K,K,K,swap_mask
+  vncipher   S0,S0,ZERO
+  vxor       S0,S0,K
+  addi      10,10,0x10
+  bdnz      L1x_round_loop
+
+  lxvd2x          KX,10,KEYS
+  vperm          K,K,K,swap_mask
+  vncipherlast   S0,S0,K
+
+  vperm      S0,S0,S0,swap_mask
+
+  stxvd2x     S0X,0,DST
+
+Ldone:
+  blr
+EPILOGUE(_nettle_aes_decrypt)
+
+  .data
+  .align   4
+.swap_mask:
+  .byte 8,9,10,11,12,13,14,15,0,1,2,3,4,5,6,7
diff --git a/powerpc64le/aes-encrypt-internal.asm
b/powerpc64le/aes-encrypt-internal.asm
index e69de29b..1bbd86a8 100755
--- a/powerpc64le/aes-encrypt-internal.asm
+++ b/powerpc64le/aes-encrypt-internal.asm
@@ -0,0 +1,534 @@
+C powerpc64le/aes-encrypt-internal.asm
+
+ifelse(&lt;
+   Copyright (C) 2020 Mamone Tarsha
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+&gt;)
+
+C Register usage:
+
+define(&lt;SP&gt;, &lt;1&gt;)
+define(&lt;TOCP&gt;, &lt;2&gt;)
+
+define(&lt;ROUNDS&gt;, &lt;3&gt;)
+define(&lt;KEYS&gt;, &lt;4&gt;)
+define(&lt;LENGTH&gt;, &lt;6&gt;)
+define(&lt;DST&gt;, &lt;7&gt;)
+define(&lt;SRC&gt;, &lt;8&gt;)
+
+define(&lt;swap_mask&gt;, &lt;0&gt;)
+
+define(&lt;K&gt;, &lt;1&gt;)
+define(&lt;S0&gt;, &lt;2&gt;)
+define(&lt;S1&gt;, &lt;3&gt;)
+define(&lt;S2&gt;, &lt;4&gt;)
+define(&lt;S3&gt;, &lt;5&gt;)
+define(&lt;S4&gt;, &lt;6&gt;)
+define(&lt;S5&gt;, &lt;7&gt;)
+define(&lt;S6&gt;, &lt;8&gt;)
+define(&lt;S7&gt;, &lt;9&gt;)
+define(&lt;S8&gt;, &lt;10&gt;)
+define(&lt;S9&gt;, &lt;11&gt;)
+define(&lt;S10&gt;, &lt;12&gt;)
+define(&lt;S11&gt;, &lt;13&gt;)
+define(&lt;S12&gt;, &lt;14&gt;)
+define(&lt;S13&gt;, &lt;15&gt;)
+define(&lt;S14&gt;, &lt;16&gt;)
+define(&lt;S15&gt;, &lt;17&gt;)
+
+define(&lt;KX&gt;, &lt;33&gt;)
+define(&lt;S0X&gt;, &lt;34&gt;)
+define(&lt;S1X&gt;, &lt;35&gt;)
+define(&lt;S2X&gt;, &lt;36&gt;)
+define(&lt;S3X&gt;, &lt;37&gt;)
+define(&lt;S4X&gt;, &lt;38&gt;)
+define(&lt;S5X&gt;, &lt;39&gt;)
+define(&lt;S6X&gt;, &lt;40&gt;)
+define(&lt;S7X&gt;, &lt;41&gt;)
+define(&lt;S8X&gt;, &lt;42&gt;)
+define(&lt;S9X&gt;, &lt;43&gt;)
+define(&lt;S10X&gt;, &lt;44&gt;)
+define(&lt;S11X&gt;, &lt;45&gt;)
+define(&lt;S12X&gt;, &lt;46&gt;)
+define(&lt;S13X&gt;, &lt;47&gt;)
+define(&lt;S14X&gt;, &lt;48&gt;)
+define(&lt;S15X&gt;, &lt;49&gt;)
+
+  .file "aes-encrypt-internal.asm"
+
+  C _aes_encrypt(unsigned rounds, const uint32_t *keys,
+  C         const struct aes_table *T,
+  C         size_t length, uint8_t *dst,
+  C         uint8_t *src)
+
+  .text
+.align 5
+PROLOGUE(_nettle_aes_encrypt)
+  ld          5,.swap_mask@got(TOCP)
+  lvx         swap_mask,0,5
+
+  subi      ROUNDS,ROUNDS,1
+  srdi      LENGTH,LENGTH,4
+
+  srdi      5,LENGTH,4              # 16x loop count
+  cmpldi      5,0
+  beq       L8x
+
+  std       17,-120(SP);
+  std       18,-112(SP);
+  std       19,-104(SP);
+  std       20,-96(SP);
+  std       21,-88(SP);
+  std       22,-80(SP);
+  std       23,-72(SP);
+  std       24,-64(SP);
+  std       25,-56(SP);
+  std       26,-48(SP);
+  std       27,-40(SP);
+  std       28,-32(SP);
+  std       29,-24(SP);
+  std       30,-16(SP);
+  std       31,-8(SP);
+
+  li        17,0x10
+  li        18,0x20
+  li        19,0x30
+  li        20,0x40
+  li        21,0x50
+  li        22,0x60
+  li        23,0x70
+  li        24,0x80
+  li        25,0x90
+  li        26,0xA0
+  li        27,0xB0
+  li        28,0xC0
+  li        29,0xD0
+  li        30,0xE0
+  li        31,0xF0
+
+.align 5
+Lx16_loop:
+  lxvd2x      KX,0,KEYS
+
+  lxvd2x      S0X,0,SRC
+  lxvd2x      S1X,17,SRC
+  lxvd2x      S2X,18,SRC
+  lxvd2x      S3X,19,SRC
+  lxvd2x      S4X,20,SRC
+  lxvd2x      S5X,21,SRC
+  lxvd2x      S6X,22,SRC
+  lxvd2x      S7X,23,SRC
+  lxvd2x      S8X,24,SRC
+  lxvd2x      S9X,25,SRC
+  lxvd2x      S10X,26,SRC
+  lxvd2x      S11X,27,SRC
+  lxvd2x      S12X,28,SRC
+  lxvd2x      S13X,29,SRC
+  lxvd2x      S14X,30,SRC
+  lxvd2x      S15X,31,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+  vxor      S4,S4,K
+  vxor      S5,S5,K
+  vxor      S6,S6,K
+  vxor      S7,S7,K
+  vxor      S8,S8,K
+  vxor      S9,S9,K
+  vxor      S10,S10,K
+  vxor      S11,S11,K
+  vxor      S12,S12,K
+  vxor      S13,S13,K
+  vxor      S14,S14,K
+  vxor      S15,S15,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+  vperm      S2,S2,S2,swap_mask
+  vperm      S3,S3,S3,swap_mask
+  vperm      S4,S4,S4,swap_mask
+  vperm      S5,S5,S5,swap_mask
+  vperm      S6,S6,S6,swap_mask
+  vperm      S7,S7,S7,swap_mask
+  vperm      S8,S8,S8,swap_mask
+  vperm      S9,S9,S9,swap_mask
+  vperm      S10,S10,S10,swap_mask
+  vperm      S11,S11,S11,swap_mask
+  vperm      S12,S12,S12,swap_mask
+  vperm      S13,S13,S13,swap_mask
+  vperm      S14,S14,S14,swap_mask
+  vperm      S15,S15,S15,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L16x_round_loop:
+  lxvd2x      KX,10,KEYS
+  vperm      K,K,K,swap_mask
+  vcipher   S0,S0,K
+  vcipher   S1,S1,K
+  vcipher   S2,S2,K
+  vcipher   S3,S3,K
+  vcipher   S4,S4,K
+  vcipher   S5,S5,K
+  vcipher   S6,S6,K
+  vcipher   S7,S7,K
+  vcipher   S8,S8,K
+  vcipher   S9,S9,K
+  vcipher   S10,S10,K
+  vcipher   S11,S11,K
+  vcipher   S12,S12,K
+  vcipher   S13,S13,K
+  vcipher   S14,S14,K
+  vcipher   S15,S15,K
+  addi      10,10,0x10
+  bdnz      L16x_round_loop
+
+  lxvd2x          KX,10,KEYS
+  vperm          K,K,K,swap_mask
+  vcipherlast   S0,S0,K
+  vcipherlast   S1,S1,K
+  vcipherlast   S2,S2,K
+  vcipherlast   S3,S3,K
+  vcipherlast   S4,S4,K
+  vcipherlast   S5,S5,K
+  vcipherlast   S6,S6,K
+  vcipherlast   S7,S7,K
+  vcipherlast   S8,S8,K
+  vcipherlast   S9,S9,K
+  vcipherlast   S10,S10,K
+  vcipherlast   S11,S11,K
+  vcipherlast   S12,S12,K
+  vcipherlast   S13,S13,K
+  vcipherlast   S14,S14,K
+  vcipherlast   S15,S15,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+  vperm      S2,S2,S2,swap_mask
+  vperm      S3,S3,S3,swap_mask
+  vperm      S4,S4,S4,swap_mask
+  vperm      S5,S5,S5,swap_mask
+  vperm      S6,S6,S6,swap_mask
+  vperm      S7,S7,S7,swap_mask
+  vperm      S8,S8,S8,swap_mask
+  vperm      S9,S9,S9,swap_mask
+  vperm      S10,S10,S10,swap_mask
+  vperm      S11,S11,S11,swap_mask
+  vperm      S12,S12,S12,swap_mask
+  vperm      S13,S13,S13,swap_mask
+  vperm      S14,S14,S14,swap_mask
+  vperm      S15,S15,S15,swap_mask
+
+  stxvd2x     S0X,0,DST
+  stxvd2x     S1X,17,DST
+  stxvd2x     S2X,18,DST
+  stxvd2x     S3X,19,DST
+  stxvd2x     S4X,20,DST
+  stxvd2x     S5X,21,DST
+  stxvd2x     S6X,22,DST
+  stxvd2x     S7X,23,DST
+  stxvd2x     S8X,24,DST
+  stxvd2x     S9X,25,DST
+  stxvd2x     S10X,26,DST
+  stxvd2x     S11X,27,DST
+  stxvd2x     S12X,28,DST
+  stxvd2x     S13X,29,DST
+  stxvd2x     S14X,30,DST
+  stxvd2x     S15X,31,DST
+
+  addi      SRC,SRC,0x100
+  addi      DST,DST,0x100
+  subic.    5,5,1
+  bne       Lx16_loop
+
+  ld        17,-120(SP);
+  ld        18,-112(SP);
+  ld        19,-104(SP);
+  ld        20,-96(SP);
+  ld        21,-88(SP);
+  ld        22,-80(SP);
+  ld        23,-72(SP);
+  ld        24,-64(SP);
+  ld        25,-56(SP);
+  ld        26,-48(SP);
+  ld        27,-40(SP);
+  ld        28,-32(SP);
+  ld        29,-24(SP);
+  ld        30,-16(SP);
+  ld        31,-8(SP);
+
+  clrldi   LENGTH,LENGTH,60
+
+L8x:
+  srdi      5,LENGTH,3
+  cmpldi      5,0
+  beq       L4x
+
+  lxvd2x      KX,0,KEYS
+
+  lxvd2x      S0X,0,SRC
+  li        9,0x10
+  lxvd2x      S1X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S2X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S3X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S4X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S5X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S6X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S7X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+  vxor      S4,S4,K
+  vxor      S5,S5,K
+  vxor      S6,S6,K
+  vxor      S7,S7,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+  vperm      S2,S2,S2,swap_mask
+  vperm      S3,S3,S3,swap_mask
+  vperm      S4,S4,S4,swap_mask
+  vperm      S5,S5,S5,swap_mask
+  vperm      S6,S6,S6,swap_mask
+  vperm      S7,S7,S7,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L8x_round_loop:
+  lxvd2x      KX,10,KEYS
+  vperm      K,K,K,swap_mask
+  vcipher   S0,S0,K
+  vcipher   S1,S1,K
+  vcipher   S2,S2,K
+  vcipher   S3,S3,K
+  vcipher   S4,S4,K
+  vcipher   S5,S5,K
+  vcipher   S6,S6,K
+  vcipher   S7,S7,K
+  addi      10,10,0x10
+  bdnz      L8x_round_loop
+
+  lxvd2x          KX,10,KEYS
+  vperm          K,K,K,swap_mask
+  vcipherlast   S0,S0,K
+  vcipherlast   S1,S1,K
+  vcipherlast   S2,S2,K
+  vcipherlast   S3,S3,K
+  vcipherlast   S4,S4,K
+  vcipherlast   S5,S5,K
+  vcipherlast   S6,S6,K
+  vcipherlast   S7,S7,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+  vperm      S2,S2,S2,swap_mask
+  vperm      S3,S3,S3,swap_mask
+  vperm      S4,S4,S4,swap_mask
+  vperm      S5,S5,S5,swap_mask
+  vperm      S6,S6,S6,swap_mask
+  vperm      S7,S7,S7,swap_mask
+
+  stxvd2x     S0X,0,DST
+  li        9,0x10
+  stxvd2x     S1X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S2X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S3X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S4X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S5X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S6X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S7X,9,DST
+
+  addi      SRC,SRC,0x80
+  addi      DST,DST,0x80
+
+  clrldi   LENGTH,LENGTH,61
+
+L4x:
+  srdi      5,LENGTH,2
+  cmpldi      5,0
+  beq       L2x
+
+  lxvd2x      KX,0,KEYS
+
+  lxvd2x      S0X,0,SRC
+  li        9,0x10
+  lxvd2x      S1X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S2X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S3X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+  vperm      S2,S2,S2,swap_mask
+  vperm      S3,S3,S3,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L4x_round_loop:
+  lxvd2x      KX,10,KEYS
+  vperm      K,K,K,swap_mask
+  vcipher   S0,S0,K
+  vcipher   S1,S1,K
+  vcipher   S2,S2,K
+  vcipher   S3,S3,K
+  addi      10,10,0x10
+  bdnz      L4x_round_loop
+
+  lxvd2x          KX,10,KEYS
+  vperm          K,K,K,swap_mask
+  vcipherlast   S0,S0,K
+  vcipherlast   S1,S1,K
+  vcipherlast   S2,S2,K
+  vcipherlast   S3,S3,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+  vperm      S2,S2,S2,swap_mask
+  vperm      S3,S3,S3,swap_mask
+
+  stxvd2x     S0X,0,DST
+  li        9,0x10
+  stxvd2x     S1X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S2X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S3X,9,DST
+
+  addi      SRC,SRC,0x40
+  addi      DST,DST,0x40
+
+  clrldi   LENGTH,LENGTH,62
+
+L2x:
+  srdi      5,LENGTH,1
+  cmpldi      5,0
+  beq       L1x
+
+  lxvd2x      KX,0,KEYS
+
+  lxvd2x      S0X,0,SRC
+  li        9,0x10
+  lxvd2x      S1X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L2x_round_loop:
+  lxvd2x      KX,10,KEYS
+  vperm      K,K,K,swap_mask
+  vcipher   S0,S0,K
+  vcipher   S1,S1,K
+  addi      10,10,0x10
+  bdnz      L2x_round_loop
+
+  lxvd2x          KX,10,KEYS
+  vperm          K,K,K,swap_mask
+  vcipherlast   S0,S0,K
+  vcipherlast   S1,S1,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+
+  stxvd2x     S0X,0,DST
+  li        9,0x10
+  stxvd2x     S1X,9,DST
+
+  addi      SRC,SRC,0x20
+  addi      DST,DST,0x20
+
+  clrldi   LENGTH,LENGTH,63
+
+L1x:
+  cmpldi      LENGTH,0
+  beq       Ldone
+
+  lxvd2x      KX,0,KEYS
+
+  lxvd2x      S0X,0,SRC
+
+  vxor      S0,S0,K
+
+  vperm      S0,S0,S0,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L1x_round_loop:
+  lxvd2x      KX,10,KEYS
+  vperm      K,K,K,swap_mask
+  vcipher   S0,S0,K
+  addi      10,10,0x10
+  bdnz      L1x_round_loop
+
+  lxvd2x          KX,10,KEYS
+  vperm          K,K,K,swap_mask
+  vcipherlast   S0,S0,K
+
+  vperm      S0,S0,S0,swap_mask
+
+  stxvd2x     S0X,0,DST
+
+Ldone:
+  blr
+EPILOGUE(_nettle_aes_encrypt)
+
+  .data
+  .align   4
+.swap_mask:
+  .byte 8,9,10,11,12,13,14,15,0,1,2,3,4,5,6,7
diff --git a/powerpc64le/gcm-hash8.asm b/powerpc64le/gcm-hash8.asm
index e69de29b..a809f6ef 100755
--- a/powerpc64le/gcm-hash8.asm
+++ b/powerpc64le/gcm-hash8.asm
@@ -0,0 +1,992 @@
+C powerpc64le/gcm-hash8.asm
+
+ifelse(&lt;
+   Copyright (C) 2020 Mamone Tarsha
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+&gt;)
+
+C Register usage:
+C VSX instructions is used to load and store data to memory "lxvd2x, stxvd2x"
+C instead of VR instructions "lvx, stvx" as a workaround to access
unaligned data
+C VSX registers are defined with "X" suffix
+
+define(&lt;SP&gt;, &lt;1&gt;)
+define(&lt;TOCP&gt;, &lt;2&gt;)
+
+define(&lt;TABLE&gt;, &lt;3&gt;)
+define(&lt;X&gt;, &lt;4&gt;)
+define(&lt;LENGTH&gt;, &lt;5&gt;)
+define(&lt;DATA&gt;, &lt;6&gt;)
+
+define(&lt;zero&gt;, &lt;0&gt;)
+define(&lt;swap_mask&gt;, &lt;1&gt;)
+define(&lt;hidw_mask&gt;, &lt;2&gt;)
+define(&lt;lodw_mask&gt;, &lt;3&gt;)
+define(&lt;poly&gt;, &lt;4&gt;)
+define(&lt;poly_h&gt;, &lt;4&gt;)
+define(&lt;poly_l&gt;, &lt;5&gt;)
+define(&lt;RP&gt;, &lt;6&gt;)
+define(&lt;Mh&gt;, &lt;7&gt;)
+define(&lt;Ml&gt;, &lt;8&gt;)
+define(&lt;H&gt;, &lt;9&gt;)
+define(&lt;Hh&gt;, &lt;10&gt;)
+define(&lt;Hl&gt;, &lt;11&gt;)
+define(&lt;RP2&gt;, &lt;9&gt;)
+define(&lt;M2h&gt;, &lt;10&gt;)
+define(&lt;M2l&gt;, &lt;11&gt;)
+
+define(&lt;HX&gt;, &lt;41&gt;)
+define(&lt;HhX&gt;, &lt;42&gt;)
+define(&lt;HlX&gt;, &lt;43&gt;)
+define(&lt;H_HhX&gt;, &lt;44&gt;)
+define(&lt;H_HX&gt;, &lt;45&gt;)
+define(&lt;H_HlX&gt;, &lt;46&gt;)
+
+define(&lt;sl1&gt;, &lt;1&gt;)
+define(&lt;msb&gt;, &lt;5&gt;)
+define(&lt;H2&gt;, &lt;6&gt;)
+define(&lt;H2h&gt;, &lt;7&gt;)
+define(&lt;H2l&gt;, &lt;8&gt;)
+define(&lt;H_h&gt;, &lt;12&gt;)
+define(&lt;H_m&gt;, &lt;13&gt;)
+define(&lt;H_l&gt;, &lt;14&gt;)
+define(&lt;H_Hh&gt;, &lt;12&gt;)
+define(&lt;H_H&gt;, &lt;13&gt;)
+define(&lt;H_Hl&gt;, &lt;14&gt;)
+define(&lt;H_t&gt;, &lt;15&gt;)
+define(&lt;H2_h&gt;, &lt;16&gt;)
+define(&lt;H2_m&gt;, &lt;17&gt;)
+define(&lt;H2_l&gt;, &lt;18&gt;)
+define(&lt;H2_t&gt;, &lt;19&gt;)
+
+define(&lt;C0X&gt;, &lt;38&gt;)
+define(&lt;C1X&gt;, &lt;39&gt;)
+define(&lt;C2X&gt;, &lt;40&gt;)
+define(&lt;C3X&gt;, &lt;44&gt;)
+define(&lt;C4X&gt;, &lt;38&gt;)
+define(&lt;C5X&gt;, &lt;39&gt;)
+define(&lt;C6X&gt;, &lt;40&gt;)
+define(&lt;C7X&gt;, &lt;44&gt;)
+
+define(&lt;CX&gt;, &lt;45&gt;)
+
+define(&lt;C0&gt;, &lt;6&gt;)
+define(&lt;C1&gt;, &lt;7&gt;)
+define(&lt;C2&gt;, &lt;8&gt;)
+define(&lt;C3&gt;, &lt;12&gt;)
+define(&lt;C4&gt;, &lt;6&gt;)
+define(&lt;C5&gt;, &lt;7&gt;)
+define(&lt;C6&gt;, &lt;8&gt;)
+define(&lt;C7&gt;, &lt;12&gt;)
+
+define(&lt;C&gt;, &lt;13&gt;)
+
+define(&lt;Ch&gt;, &lt;14&gt;)
+define(&lt;Cl&gt;, &lt;15&gt;)
+define(&lt;Cm&gt;, &lt;16&gt;)
+
+define(&lt;C01h&gt;, &lt;14&gt;)
+define(&lt;C01l&gt;, &lt;15&gt;)
+define(&lt;C01&gt;, &lt;16&gt;)
+define(&lt;C23h&gt;, &lt;17&gt;)
+define(&lt;C23l&gt;, &lt;18&gt;)
+define(&lt;C23&gt;, &lt;19&gt;)
+define(&lt;C45h&gt;, &lt;20&gt;)
+define(&lt;C45l&gt;, &lt;21&gt;)
+define(&lt;C45&gt;, &lt;22&gt;)
+define(&lt;C67h&gt;, &lt;6&gt;)
+define(&lt;C67l&gt;, &lt;7&gt;)
+define(&lt;C67&gt;, &lt;8&gt;)
+
+define(&lt;H21&gt;, &lt;9&gt;)
+define(&lt;H21h&gt;, &lt;10&gt;)
+define(&lt;H21l&gt;, &lt;11&gt;)
+define(&lt;H43&gt;, &lt;23&gt;)
+define(&lt;H43h&gt;, &lt;24&gt;)
+define(&lt;H43l&gt;, &lt;25&gt;)
+define(&lt;H65&gt;, &lt;26&gt;)
+define(&lt;H65h&gt;, &lt;27&gt;)
+define(&lt;H65l&gt;, &lt;28&gt;)
+define(&lt;H87&gt;, &lt;29&gt;)
+define(&lt;H87h&gt;, &lt;30&gt;)
+define(&lt;H87l&gt;, &lt;31&gt;)
+
+define(&lt;H21X&gt;, &lt;41&gt;)
+define(&lt;H21hX&gt;, &lt;42&gt;)
+define(&lt;H21lX&gt;, &lt;43&gt;)
+define(&lt;H43X&gt;, &lt;55&gt;)
+define(&lt;H43hX&gt;, &lt;56&gt;)
+define(&lt;H43lX&gt;, &lt;57&gt;)
+define(&lt;H65X&gt;, &lt;58&gt;)
+define(&lt;H65hX&gt;, &lt;59&gt;)
+define(&lt;H65lX&gt;, &lt;60&gt;)
+define(&lt;H87X&gt;, &lt;61&gt;)
+define(&lt;H87hX&gt;, &lt;62&gt;)
+define(&lt;H87lX&gt;, &lt;63&gt;)
+
+# gcm_fill registers:
+
+define(&lt;CTR&gt;, &lt;3&gt;)
+define(&lt;BLOCKS&gt;, &lt;4&gt;)
+define(&lt;BUFFER&gt;, &lt;5&gt;)
+
+define(&lt;CTR0&gt;, &lt;2&gt;)
+define(&lt;CTR0S&gt;, &lt;3&gt;)
+define(&lt;CTR1&gt;, &lt;4&gt;)
+define(&lt;CTR2&gt;, &lt;5&gt;)
+define(&lt;CTR3&gt;, &lt;6&gt;)
+define(&lt;CTR4&gt;, &lt;7&gt;)
+define(&lt;CTR5&gt;, &lt;8&gt;)
+define(&lt;CTR6&gt;, &lt;9&gt;)
+define(&lt;CTR7&gt;, &lt;10&gt;)
+
+define(&lt;CTR0X&gt;, &lt;34&gt;)
+define(&lt;CTR0SX&gt;, &lt;35&gt;)
+define(&lt;CTR1X&gt;, &lt;36&gt;)
+define(&lt;CTR2X&gt;, &lt;37&gt;)
+define(&lt;CTR3X&gt;, &lt;38&gt;)
+define(&lt;CTR4X&gt;, &lt;39&gt;)
+define(&lt;CTR5X&gt;, &lt;40&gt;)
+define(&lt;CTR6X&gt;, &lt;41&gt;)
+define(&lt;CTR7X&gt;, &lt;42&gt;)
+
+define(&lt;I1&gt;, &lt;11&gt;)
+define(&lt;I2&gt;, &lt;12&gt;)
+define(&lt;I3&gt;, &lt;13&gt;)
+define(&lt;I4&gt;, &lt;14&gt;)
+define(&lt;I5&gt;, &lt;15&gt;)
+define(&lt;I6&gt;, &lt;16&gt;)
+define(&lt;I7&gt;, &lt;17&gt;)
+define(&lt;I8&gt;, &lt;18&gt;)
+
+  .file "gcm-hash8.asm"
+
+  # void gcm_init_key (union gcm_block *table)
+
+    .text
+.align 5
+PROLOGUE(_nettle_gcm_init_key8)
+    ld           7,.polynomial@got(TOCP)
+  lvx            poly,0,7
+  ld          7,.swap_mask@got(TOCP)
+  lvx         swap_mask,0,7
+  ld          7,.hidw_mask@got(TOCP)
+  lvx         hidw_mask,0,7
+  ld          7,.lodw_mask@got(TOCP)
+  lvx            lodw_mask,0,7
+
+  li        10,0x800
+    lxvd2x    HX,10,TABLE          # load H
+  vperm    H,H,H,swap_mask
+
+  # --- calculate H = H shift left 1 modulo polynomial ---
+
+  vupkhsw      msb,H               # most significant bit word-extend
+  vspltisb sl1,1             # splat 1 for shift left
+  vspltw      msb,msb,0            # most significant bit extend
+  vsl          H,H,sl1             # H shift left 1
+  vand     msb,msb,poly
+  vxor     zero,zero,zero
+  vxor     H_t,H,msb
+
+  vsldoi      H,H_t,H_t,8          # doubleword swap
+  vsldoi      Hh,H,zero,8
+  vsldoi      Hl,zero,H,8
+
+  # --- calculate H^2 = H*H ---
+
+  # reduction pre-processing
+  vsldoi      poly_h,zero,poly,8
+  vsldoi      poly_l,poly_h,poly_h,8
+
+  # polynomial multiplication "classical"
+  vpmsumd     H_h,H_t,Hh           # H^1h*H^1h
+  vpmsumd     H_l,H_t,Hl           # H^1l*H^1l
+  vpmsumd     H_m,H_t,H            # H^1h*H^1l⊕H^1l*H^1h
+
+  # reduction first phase          # [1]
+  vpmsumd     RP,H_l,poly_h        # [1]
+
+  # polynomial multiplication post-processing # [2]
+  vsldoi      Mh,zero,H_m,8           # [2]
+  vsldoi      Ml,H_m,zero,8        # [2]
+  vsldoi      RP,RP,RP,8           # [1]
+  vxor     H_h,H_h,Mh           # [2]
+  vxor     H_l,H_l,Ml           # [2]
+  vxor     H_l,H_l,RP           # [1]
+
+  # reduction second phase
+  vpmsumd     RP,H_l,poly_l
+  vxor     H_h,H_l,H_h
+  vxor     H2_t,H_h,RP
+
+  vsldoi      H2,H2_t,H2_t,8
+  vsldoi      H2h,H2,zero,8
+  vsldoi      H2l,zero,H2,8
+
+  # --- calculate [H^2.Hi⊕H^2.Lo:H^1.Hi⊕H^1.Lo] ---
+
+  vperm    H_Hh,H2,H,lodw_mask
+  vperm    H_Hl,H2,H,hidw_mask
+  vxor     H_H,H_Hh,H_Hl
+
+  # --- store H,[H^2.Hi⊕H^2.Lo:H^1.Hi⊕H^1.Lo] ---
+
+  li        8,0x00
+  li        9,0x100
+  li        10,0x200
+  stxvd2x     HlX,8,TABLE
+  stxvd2x     HX,9,TABLE
+  stxvd2x     HhX,10,TABLE
+
+  li        8,0x300
+  li        9,0x400
+  li        10,0x500
+  stxvd2x     H_HhX,8,TABLE
+  stxvd2x     H_HX,9,TABLE
+  stxvd2x     H_HlX,10,TABLE
+
+  # --- calculate H^3,H^4 ---
+
+  # polynomial multiplication "classical"
+  vpmsumd     H_l,H_t,H2l          # H^1l*H^2l
+  vpmsumd     H_m,H_t,H2           # H^1h*H^2l⊕H^1l*H^2h
+  vpmsumd     H_h,H_t,H2h          # H^1h*H^2h
+  vpmsumd     H2_l,H2_t,H2l        # H^2l*H^2l
+  vpmsumd     H2_m,H2_t,H2         # H^2h*H^2l⊕H^2l*H^2h
+  vpmsumd     H2_h,H2_t,H2h        # H^2h*H^2h
+
+  # reduction first phase             # [1]
+  vpmsumd     RP,H_l,poly_h        # [1] H^3
+  vpmsumd      RP2,H2_l,poly_h        # [1] H^4
+
+  # polynomial multiplication post-processing # [2]
+  vsldoi      Mh,zero,H_m,8        # [2] H^3
+  vsldoi      M2h,zero,H2_m,8         # [2] H^4
+  vsldoi      Ml,H_m,zero,8        # [2] H^3
+  vsldoi      M2l,H2_m,zero,8         # [2] H^4
+  vsldoi      RP,RP,RP,8           # [1] H^3
+  vsldoi      RP2,RP2,RP2,8        # [1] H^4
+  vxor     H_h,H_h,Mh           # [2] H^3
+  vxor     H2_h,H2_h,M2h        # [2] H^4
+  vxor     H_l,H_l,Ml           # [2] H^3
+  vxor     H2_l,H2_l,M2l        # [2] H^4
+  vxor     H_l,H_l,RP           # [1] H^3
+  vxor     H2_l,H2_l,RP2        # [1] H^4
+
+  # reduction second phase
+  vpmsumd     RP,H_l,poly_l        # H^3
+  vpmsumd     RP2,H2_l,poly_l         # H^4
+  vxor     H_h,H_l,H_h          # H^3
+  vxor     H2_h,H2_l,H2_h       # H^4
+  vxor     H_h,H_h,RP           # H^3
+  vxor     H2_h,H2_h,RP2        # H^4
+
+  vsldoi      H2,H2_h,H2_h,8       # H^4
+  vsldoi      H,H_h,H_h,8          # H^3
+  vsldoi      H2l,zero,H2,8        # H^4
+  vsldoi      H2h,H2,zero,8        # H^4
+
+  # --- calculate [H^4.Hi⊕H^4.Lo:H^3.Hi⊕H^3.Lo] ---
+
+  vperm    H_Hh,H2,H,lodw_mask
+  vperm    H_Hl,H2,H,hidw_mask
+  vxor     H_H,H_Hh,H_Hl
+
+  # --- store [H^4.Hi⊕H^4.Lo:H^3.Hi⊕H^3.Lo] ---
+
+  li        8,0x600
+  li        9,0x700
+  li        10,0x800
+  stxvd2x     H_HhX,8,TABLE
+  stxvd2x     H_HX,9,TABLE
+  stxvd2x     H_HlX,10,TABLE
+
+  # --- calculate H^5,H^6 ---
+
+  # polynomial multiplication "classical"
+  vpmsumd     H_l,H_t,H2l          # H^1l*H^4l
+  vpmsumd     H_m,H_t,H2           # H^1h*H^4l⊕H^1l*H^4h
+  vpmsumd     H_h,H_t,H2h          # H^1h*H^4h
+  vpmsumd     H2_l,H2_t,H2l        # H^2l*H^4l
+  vpmsumd     H2_m,H2_t,H2         # H^2h*H^4l⊕H^2l*H^4h
+  vpmsumd     H2_h,H2_t,H2h        # H^2h*H^4h
+
+  # reduction first phase             # [1]
+  vpmsumd     RP,H_l,poly_h        # [1] H^5
+  vpmsumd      RP2,H2_l,poly_h        # [1] H^6
+
+  # polynomial multiplication post-processing # [2]
+  vsldoi      Mh,zero,H_m,8        # [2] H^5
+  vsldoi      M2h,zero,H2_m,8         # [2] H^6
+  vsldoi      Ml,H_m,zero,8        # [2] H^5
+  vsldoi      M2l,H2_m,zero,8         # [2] H^6
+  vsldoi      RP,RP,RP,8           # [1] H^5
+  vsldoi      RP2,RP2,RP2,8        # [1] H^6
+  vxor     H_h,H_h,Mh           # [2] H^5
+  vxor     H2_h,H2_h,M2h        # [2] H^6
+  vxor     H_l,H_l,Ml           # [2] H^5
+  vxor     H2_l,H2_l,M2l        # [2] H^6
+  vxor     H_l,H_l,RP           # [1] H^5
+  vxor     H2_l,H2_l,RP2        # [1] H^6
+
+  # reduction second phase
+  vpmsumd     RP,H_l,poly_l        # H^5
+  vpmsumd     RP2,H2_l,poly_l   # H^6
+  vxor     H_h,H_l,H_h          # H^5
+  vxor     H2_h,H2_l,H2_h       # H^6
+  vxor     H_h,H_h,RP           # H^5
+  vxor     H2_h,H2_h,RP2        # H^6
+
+  vsldoi      H2,H2_h,H2_h,8       # H^6
+  vsldoi      H,H_h,H_h,8          # H^5
+  vsldoi      H2l,zero,H2,8        # H^6
+  vsldoi      H2h,H2,zero,8        # H^6
+
+  # --- calculate [H^6.Hi⊕H^6.Lo:H^5.Hi⊕H^5.Lo] ---
+
+  vperm    H_Hh,H2,H,lodw_mask
+  vperm    H_Hl,H2,H,hidw_mask
+  vxor     H_H,H_Hh,H_Hl
+
+  # --- store [H^6.Hi⊕H^6.Lo:H^5.Hi⊕H^5.Lo] ---
+
+  li        8,0x900
+  li        9,0xA00
+  li        10,0xB00
+  stxvd2x     H_HhX,8,TABLE
+  stxvd2x     H_HX,9,TABLE
+  stxvd2x     H_HlX,10,TABLE
+
+  # --- calculate H^7,H^8 ---
+
+  # polynomial multiplication "classical"
+  vpmsumd     H_l,H_t,H2l          # H^1l*H^6l
+  vpmsumd     H_m,H_t,H2           # H^1h*H^6l⊕H^1l*H^6h
+  vpmsumd     H_h,H_t,H2h          # H^1h*H^6h
+  vpmsumd     H2_l,H2_t,H2l        # H^2l*H^6l
+  vpmsumd     H2_m,H2_t,H2         # H^2h*H^6l⊕H^2l*H^6h
+  vpmsumd     H2_h,H2_t,H2h        # H^2h*H^6h
+
+  # reduction first phase             # [1]
+  vpmsumd     RP,H_l,poly_h        # [1] H^7
+  vpmsumd      RP2,H2_l,poly_h        # [1] H^8
+
+  # polynomial multiplication post-processing # [2]
+  vsldoi      Mh,zero,H_m,8        # [2] H^7
+  vsldoi      M2h,zero,H2_m,8         # [2] H^8
+  vsldoi      Ml,H_m,zero,8        # [2] H^7
+  vsldoi      M2l,H2_m,zero,8         # [2] H^8
+  vsldoi      RP,RP,RP,8           # [1] H^7
+  vsldoi      RP2,RP2,RP2,8        # [1] H^8
+  vxor     H_h,H_h,Mh           # [2] H^7
+  vxor     H2_h,H2_h,M2h        # [2] H^8
+  vxor     H_l,H_l,Ml           # [2] H^7
+  vxor     H2_l,H2_l,M2l        # [2] H^8
+  vxor     H_l,H_l,RP           # [1] H^7
+  vxor     H2_l,H2_l,RP2        # [1] H^8
+
+  # reduction second phase
+  vpmsumd     RP,H_l,poly_l        # H^7
+  vpmsumd     RP2,H2_l,poly_l         # H^8
+  vxor     H_h,H_l,H_h          # H^7
+  vxor     H2_h,H2_l,H2_h       # H^8
+  vxor     H_h,H_h,RP           # H^7
+  vxor     H2_h,H2_h,RP2        # H^8
+
+  vsldoi      H,H_h,H_h,8          # H^7
+  vsldoi      H2,H2_h,H2_h,8       # H^8
+
+  # --- calculate [H^8.Hi⊕H^8.Lo:H^7.Hi⊕H^7.Lo] ---
+
+  vperm    H_Hh,H2,H,lodw_mask
+  vperm    H_Hl,H2,H,hidw_mask
+  vxor     H_H,H_Hh,H_Hl
+
+  # --- store [H^8.Hi⊕H^8.Lo:H^7.Hi⊕H^7.Lo] ---
+
+  li        8,0xC00
+  li        9,0xD00
+  li        10,0xE00
+  stxvd2x     H_HhX,8,TABLE
+  stxvd2x     H_HX,9,TABLE
+  stxvd2x     H_HlX,10,TABLE
+
+    blr
+EPILOGUE(_nettle_gcm_init_key8)
+
+  # void gcm_hash (const struct gcm_key *key, union gcm_block *x,
+  #                size_t length, const uint8_t *data)
+
+.align 5
+PROLOGUE(_nettle_gcm_hash8)
+    vxor      zero,zero,zero
+
+  ld          7,.polynomial@got(TOCP)
+  lvx            poly,0,7
+  ld          7,.swap_mask@got(TOCP)
+  lvx         swap_mask,0,7
+  ld        7,.hidw_mask@got(TOCP)
+  lvx         hidw_mask,0,7
+  ld          7,.lodw_mask@got(TOCP)
+  lvx            lodw_mask,0,7
+
+  vsldoi      poly_h,zero,poly,8
+  vsldoi      poly_l,poly_h,poly_h,8
+
+  lxvd2x      CX,0,X               # load X
+  vperm    C,C,C,swap_mask
+
+  srdi     7,LENGTH,7           # 8x loop count
+  cmpldi      7,0
+  beq         L2x
+
+  # backup registers
+  stdu     SP,-224(SP)
+  std         28,216(SP)
+  std         29,208(SP)
+  std         30,200(SP)
+  std         31,192(SP)
+    li        8,176
+    stvx      20,8,SP
+    subi      8,8,16
+    stvx      21,8,SP
+    subi      8,8,16
+    stvx      22,8,SP
+    subi      8,8,16
+    stvx      23,8,SP
+    subi      8,8,16
+    stvx      24,8,SP
+    subi      8,8,16
+    stvx      25,8,SP
+    subi      8,8,16
+    stvx      26,8,SP
+    subi      8,8,16
+    stvx      27,8,SP
+    subi      8,8,16
+    stvx      28,8,SP
+    subi      8,8,16
+    stvx      29,8,SP
+    subi      8,8,16
+    stvx      30,8,SP
+    subi      8,8,16
+    stvx      31,8,SP
+
+  # table loading
+  li       8,0x300
+  li       9,0x400
+  li       10,0x500
+  lxvd2x      H21hX,8,TABLE
+  lxvd2x      H21X,9,TABLE
+  lxvd2x      H21lX,10,TABLE
+  li       8,0x600
+  li       9,0x700
+  li       10,0x800
+  lxvd2x      H43hX,8,TABLE
+  lxvd2x      H43X,9,TABLE
+  lxvd2x      H43lX,10,TABLE
+  li       8,0x900
+  li       9,0xA00
+  li       10,0xB00
+  lxvd2x      H65hX,8,TABLE
+  lxvd2x      H65X,9,TABLE
+  lxvd2x      H65lX,10,TABLE
+  li       8,0xC00
+  li       9,0xD00
+  li       10,0xE00
+  lxvd2x      H87hX,8,TABLE
+  lxvd2x      H87X,9,TABLE
+  lxvd2x      H87lX,10,TABLE
+
+  li       8,0x10
+  li       9,0x20
+  li       10,0x30
+  li       28,0x40
+  li       29,0x50
+  li       30,0x60
+  li       31,0x70
+
+  mtctr       7
+.align 5
+L8x_loop:
+  # input loading
+  lxvd2x      C0X,0,DATA           # load C0
+  lxvd2x      C1X,8,DATA           # load C1
+  lxvd2x      C2X,9,DATA           # load C2
+  lxvd2x      C3X,10,DATA          # load C3
+
+  # swap permuting
+  vperm    C0,C0,C0,swap_mask
+  vperm    C1,C1,C1,swap_mask
+  vperm    C2,C2,C2,swap_mask
+  vperm    C3,C3,C3,swap_mask
+
+  # previous digest combining
+  vxor     C0,C0,C
+
+  # polynomial multiplication "karatsuba" pre-processing
+  vperm    C23h,C2,C3,hidw_mask
+  vperm    C23l,C2,C3,lodw_mask
+  vperm    C01h,C0,C1,hidw_mask
+  vperm    C01l,C0,C1,lodw_mask
+
+  # input loading
+  lxvd2x      C4X,28,DATA          # load C4
+  lxvd2x      C5X,29,DATA          # load C5
+  lxvd2x      C6X,30,DATA          # load C6
+  lxvd2x      C7X,31,DATA          # load C7
+
+  # swap permuting
+  vperm    C4,C4,C4,swap_mask
+  vperm    C5,C5,C5,swap_mask
+  vperm    C6,C6,C6,swap_mask
+  vperm    C7,C7,C7,swap_mask
+
+  # polynomial multiplication "karatsuba" pre-processing
+  vperm    C45h,C4,C5,hidw_mask
+  vperm    C45l,C4,C5,lodw_mask
+  vperm    C67h,C6,C7,hidw_mask
+  vperm    C67l,C6,C7,lodw_mask
+  vxor     C23,C23h,C23l
+  vxor     C01,C01h,C01l
+  vxor     C45,C45h,C45l
+  vxor     C67,C67h,C67l
+
+  # polynomial multiplication "karatsuba"
+  vpmsumd     C23h,C23h,H65h       # H23 = H^6h*C2h⊕H^5h*C3h
+  vpmsumd     C23l,C23l,H65l       # L23 = H^6l*C2l⊕H^5l*C3l
+  vpmsumd     C01h,C01h,H87h       # H01 = H^8h*C0h⊕H^7h*C1h
+  vpmsumd     C01l,C01l,H87l       # L01 = H^8l*C0l⊕H^7l*C1l
+  vpmsumd     C67h,C67h,H21h       # H67 = H^2h*C6h⊕H^1h*C7h
+  vpmsumd     C67l,C67l,H21l       # L67 = H^2l*C6l⊕H^1l*C7l
+  vpmsumd     C45h,C45h,H43h       # H45 = H^4h*C4h⊕H^3h*C5h
+  vpmsumd     C45l,C45l,H43l       # L45 = H^4l*C4l⊕H^3l*C5l
+  vpmsumd     C23,C23,H65          # M23 =
(H^6h⊕H^5h)*(C2h⊕C3h)⊕(H^6l⊕H^5l)*(C2l⊕C3l)
+  vpmsumd     C01,C01,H87          # M01 =
(H^8h⊕H^7h)*(C0h⊕C1h)⊕(H^8l⊕H^7l)*(C0l⊕C1l)
+  vpmsumd     C45,C45,H43          # M45 =
(H^4h⊕H^3h)*(C4h⊕C5h)⊕(H^4l⊕H^3l)*(C4l⊕C5l)
+  vpmsumd     C67,C67,H21          # M67 =
(H^2h⊕H^1h)*(C6h⊕C7h)⊕(H^2l⊕H^1l)*(C6l⊕C7l)
+
+  # polynomial multiplication "karatsuba" post-processing
+  vxor     C23,C23,C23h
+  vxor     C01,C01,C01h
+  vxor     C45,C45,C45h
+  vxor     C67,C67,C67h
+  vxor     C23,C23,C23l
+  vxor     C01,C01,C01l
+  vxor     C45,C45,C45l
+  vxor     C67,C67,C67l
+
+  # deferred recombination of partial products
+  vxor     C01h,C01h,C23h       # H0 = H01⊕H23
+  vxor     C45h,C45h,C67h       # H1 = H45⊕H67
+  vxor     C01l,C01l,C23l       # L0 = L01⊕L23
+  vxor     C45l,C45l,C67l       # L1 = L45⊕L45
+  vxor     C01,C01,C23          # M0 = M01⊕M23
+  vxor     C45,C45,C67          # M1 = M45⊕M45
+  vxor     C01h,C01h,C45h       # H = H0⊕H1
+  vxor     C01l,C01l,C45l       # L = L0⊕L1
+  vxor     C01,C01,C45          # M = M0⊕M1
+
+  # reduction first phase          # [1]
+  vpmsumd     RP,C01l,poly_h       # [1]
+
+  # polynomial multiplication post-processing # [2]
+  vsldoi      Mh,zero,C01,8           # [2]
+  vsldoi      Ml,C01,zero,8           # [2]
+  vsldoi      RP,RP,RP,8              # [1]
+  vxor     C01h,C01h,Mh         # [2]
+  vxor     C01l,C01l,Ml         # [2]
+  vxor     C01l,C01l,RP         # [1]
+
+  # reduction second phase
+  vpmsumd     RP,C01l,poly_l
+  vxor     C01h,C01l,C01h
+  vxor     C,C01h,RP
+
+  addi     DATA,DATA,0x80
+  bdnz     L8x_loop
+
+    # restore registers
+  li       8,0
+    lvx       31,8,SP
+    addi      8,8,16
+    lvx       30,8,SP
+    addi      8,8,16
+    lvx       29,8,SP
+    addi      8,8,16
+    lvx       28,8,SP
+    addi      8,8,16
+    lvx       27,8,SP
+    addi      8,8,16
+    lvx       26,8,SP
+    addi      8,8,16
+    lvx       25,8,SP
+    addi      8,8,16
+    lvx       24,8,SP
+    addi      8,8,16
+    lvx       23,8,SP
+    addi      8,8,16
+    lvx       22,8,SP
+    addi      8,8,16
+    lvx       21,8,SP
+    addi      8,8,16
+    lvx       20,8,SP
+  ld       31,192(SP)
+  ld       30,200(SP)
+  ld       29,208(SP)
+  ld       28,216(SP)
+  addi     SP,SP,224
+
+  clrldi   LENGTH,LENGTH,57
+L2x:
+  srdi     7,LENGTH,5
+  cmpldi      7,0
+  beq         L1x
+
+  # table loading
+  li       8,0x300
+  li       9,0x400
+  li       10,0x500
+  lxvd2x      H21hX,8,TABLE
+  lxvd2x      H21X,9,TABLE
+  lxvd2x      H21lX,10,TABLE
+
+  li       10,0x10
+
+  mtctr       7
+.align 5
+L2x_loop:
+  # input loading
+  lxvd2x      C0X,0,DATA           # load C0
+  lxvd2x      C1X,10,DATA          # load C1
+
+  # swap permuting
+  vperm    C0,C0,C0,swap_mask
+  vperm    C1,C1,C1,swap_mask
+
+  # previous digest combining
+  vxor     C0,C0,C
+
+  # polynomial multiplication "karatsuba" pre-processing
+  vperm    C01h,C0,C1,hidw_mask
+  vperm    C01l,C0,C1,lodw_mask
+  vxor     C01,C01h,C01l
+
+  # polynomial multiplication "karatsuba"
+  vpmsumd     C01h,C01h,H21h       # H01 = H^2h*C0h⊕H^1h*C1h
+  vpmsumd     C01l,C01l,H21l       # L01 = H^2l*C0l⊕H^1l*C1l
+  vpmsumd     C01,C01,H21          # M01 =
(H^2h⊕H^1h)*(C0h⊕C1h)⊕(H^2l⊕H^1l)*(C0l⊕C1l)
+
+  # polynomial multiplication "karatsuba" post-processing
+  vxor     C01,C01,C01h
+  vxor     C01,C01,C01l
+
+  # reduction first phase          # [1]
+  vpmsumd     RP,C01l,poly_h       # [1]
+
+  # polynomial multiplication post-processing # [2]
+  vsldoi      Mh,zero,C01,8           # [2]
+  vsldoi      Ml,C01,zero,8           # [2]
+  vsldoi      RP,RP,RP,8              # [1]
+  vxor     C01h,C01h,Mh         # [2]
+  vxor     C01l,C01l,Ml         # [2]
+  vxor     C01l,C01l,RP         # [1]
+
+  # reduction second phase
+  vpmsumd     RP,C01l,poly_l
+  vxor     C01h,C01l,C01h
+  vxor     C,C01h,RP
+
+  addi     DATA,DATA,0x20
+  bdnz     L2x_loop
+
+  clrldi   LENGTH,LENGTH,59
+L1x:
+  srdi     7,LENGTH,4
+  cmpldi      7,0
+  beq         Lrem
+
+  # table loading
+  li       9,0x100
+  li       10,0x200
+  lxvd2x      HlX,0,TABLE
+  lxvd2x      HX, 9,TABLE
+  lxvd2x      HhX,10,TABLE
+
+  # input loading
+  lxvd2x      C0X,0,DATA           # load C0
+
+  # swap permuting
+  vperm    C0,C0,C0,swap_mask
+
+  # previous digest combining
+  vxor     C0,C0,C
+
+  vpmsumd     Cl,C0,Hl          # L = Hl*Cl
+  vpmsumd     Cm,C0,H              # M = Hh*Cl⊕Hl*Ch
+  vpmsumd     Ch,C0,Hh          # H = Hh*Ch
+
+  # reduction first phase          # [1]
+  vpmsumd     RP,Cl,poly_h         # [1]
+
+  # polynomial multiplication post-processing # [2]
+  vsldoi      Mh,zero,Cm,8         # [2]
+  vsldoi      Ml,Cm,zero,8         # [2]
+  vsldoi      RP,RP,RP,8              # [1]
+  vxor     Ch,Ch,Mh             # [2]
+  vxor     Cl,Cl,Ml             # [2]
+  vxor     Cl,Cl,RP             # [1]
+
+  # reduction second phase
+  vpmsumd     RP,Cl,poly_l
+  vxor     Ch,Cl,Ch
+  vxor     C,Ch,RP
+
+  addi     DATA,DATA,0x10
+  clrldi   LENGTH,LENGTH,60
+Lrem:
+  cmpldi      LENGTH,0
+  beq         Ldone
+
+  # table loading
+  li       9,0x100
+  li       10,0x200
+  lxvd2x      HlX,0,TABLE
+  lxvd2x      HX, 9,TABLE
+  lxvd2x      HhX,10,TABLE
+
+  # input loading
+  stdu     SP,-16(SP)
+  stvx     zero,0,SP
+Lst_loop:
+  subic.      LENGTH,LENGTH,1
+  lbzx     7,LENGTH,DATA
+  stbx     7,LENGTH,SP
+  bne         Lst_loop
+  lxvd2x         C0X,0,SP
+  addi     SP,SP,16
+
+  # swap permuting
+  vperm    C0,C0,C0,swap_mask
+
+  # previous digest combining
+  vxor     C0,C0,C
+
+  vpmsumd     Cl,C0,Hl          # L = Hl*Cl
+  vpmsumd     Cm,C0,H              # M = Hh*Cl⊕Hl*Ch
+  vpmsumd     Ch,C0,Hh          # H = Hh*Ch
+
+  # reduction first phase          # [1]
+  vpmsumd     RP,Cl,poly_h         # [1]
+
+  # polynomial multiplication post-processing # [2]
+  vsldoi      Mh,zero,Cm,8         # [2]
+  vsldoi      Ml,Cm,zero,8         # [2]
+  vsldoi      RP,RP,RP,8              # [1]
+  vxor     Ch,Ch,Mh             # [2]
+  vxor     Cl,Cl,Ml                # [2]
+  vxor     Cl,Cl,RP             # [1]
+
+  # reduction second phase
+  vpmsumd     RP,Cl,poly_l
+  vxor     Ch,Cl,Ch
+  vxor     C,Ch,RP
+
+Ldone:
+  vperm    C,C,C,swap_mask
+  stxvd2x     CX,0,X               # store C
+  blr
+EPILOGUE(_nettle_gcm_hash8)
+
+  # gcm_fill (uint8_t *ctr, size_t blocks, union gcm_block *buffer)
+
+.align 5
+PROLOGUE(_nettle_gcm_fill)
+  ld       6,.swap_mask@got(TOCP)
+  lvx      swap_mask,0,6
+
+  vxor     zero,zero,zero
+  vspltisb I1,1
+  vspltisb I2,2
+  vspltisb I3,3
+  vspltisb I4,4
+  vspltisb I5,5
+  vspltisb I6,6
+  vspltisb I7,7
+  vspltisb I8,8
+  vsldoi   I1,zero,I1,1
+  vsldoi   I2,zero,I2,1
+  vsldoi   I3,zero,I3,1
+  vsldoi   I4,zero,I4,1
+  vsldoi   I5,zero,I5,1
+  vsldoi   I6,zero,I6,1
+  vsldoi   I7,zero,I7,1
+  vsldoi   I8,zero,I8,1
+
+  lxvd2x   CTR0X,0,CTR
+  vperm    CTR0,CTR0,CTR0,swap_mask
+
+  srdi      6,BLOCKS,3              # 8x loop count
+  cmpldi   6,0
+  beq       Lfill_4x
+
+  std       25,-56(SP);
+  std       26,-48(SP);
+  std       27,-40(SP);
+  std       28,-32(SP);
+  std       29,-24(SP);
+  std       30,-16(SP);
+  std       31,-8(SP);
+
+  li        25,0x10
+  li        26,0x20
+  li        27,0x30
+  li        28,0x40
+  li        29,0x50
+  li        30,0x60
+  li        31,0x70
+
+  mtctr     6
+L8x_fill_loop:
+  vadduwm  CTR1,CTR0,I1
+  vadduwm  CTR2,CTR0,I2
+  vadduwm  CTR3,CTR0,I3
+  vadduwm  CTR4,CTR0,I4
+  vadduwm  CTR5,CTR0,I5
+  vadduwm  CTR6,CTR0,I6
+  vadduwm  CTR7,CTR0,I7
+
+  vperm    CTR0S,CTR0,CTR0,swap_mask
+  vperm    CTR1,CTR1,CTR1,swap_mask
+  vperm    CTR2,CTR2,CTR2,swap_mask
+  vperm    CTR3,CTR3,CTR3,swap_mask
+  vperm    CTR4,CTR4,CTR4,swap_mask
+  vperm    CTR5,CTR5,CTR5,swap_mask
+  vperm    CTR6,CTR6,CTR6,swap_mask
+  vperm    CTR7,CTR7,CTR7,swap_mask
+
+  stxvd2x  CTR0SX,0,BUFFER
+  stxvd2x  CTR1X,25,BUFFER
+  stxvd2x  CTR2X,26,BUFFER
+  stxvd2x  CTR3X,27,BUFFER
+  stxvd2x  CTR4X,28,BUFFER
+  stxvd2x  CTR5X,29,BUFFER
+  stxvd2x  CTR6X,30,BUFFER
+  stxvd2x  CTR7X,31,BUFFER
+
+  vadduwm  CTR0,CTR0,I8
+  addi     BUFFER,BUFFER,0x80
+  bdnz      L8x_fill_loop
+
+  ld        25,-56(SP);
+  ld        26,-48(SP);
+  ld        27,-40(SP);
+  ld        28,-32(SP);
+  ld        29,-24(SP);
+  ld        30,-16(SP);
+  ld        31,-8(SP);
+
+  clrldi   BLOCKS,BLOCKS,61
+
+Lfill_4x:
+  srdi      6,BLOCKS,2
+  cmpldi   6,0
+  beq       Lfill_2x
+
+  li        8,0x10
+  li        9,0x20
+  li        10,0x30
+
+  vadduwm  CTR1,CTR0,I1
+  vadduwm  CTR2,CTR0,I2
+  vadduwm  CTR3,CTR0,I3
+
+  vperm    CTR0S,CTR0,CTR0,swap_mask
+  vperm    CTR1,CTR1,CTR1,swap_mask
+  vperm    CTR2,CTR2,CTR2,swap_mask
+  vperm    CTR3,CTR3,CTR3,swap_mask
+
+  stxvd2x  CTR0SX,0,BUFFER
+  stxvd2x  CTR1X,8,BUFFER
+  stxvd2x  CTR2X,9,BUFFER
+  stxvd2x  CTR3X,10,BUFFER
+
+  vadduwm  CTR0,CTR0,I4
+  addi     BUFFER,BUFFER,0x40
+
+  clrldi   BLOCKS,BLOCKS,62
+
+Lfill_2x:
+  srdi      6,BLOCKS,1
+  cmpldi   6,0
+  beq       Lfill_1x
+
+  li        10,0x10
+
+  vadduwm  CTR1,CTR0,I1
+
+  vperm    CTR0S,CTR0,CTR0,swap_mask
+  vperm    CTR1,CTR1,CTR1,swap_mask
+
+  stxvd2x  CTR0SX,0,BUFFER
+  stxvd2x  CTR1X,10,BUFFER
+
+  vadduwm  CTR0,CTR0,I2
+  addi     BUFFER,BUFFER,0x20
+
+  clrldi   BLOCKS,BLOCKS,63
+
+Lfill_1x:
+  cmpldi   BLOCKS,0
+  beq       Lfill_done
+
+  vperm    CTR0S,CTR0,CTR0,swap_mask
+
+  stxvd2x  CTR0SX,0,BUFFER
+
+  vadduwm  CTR0,CTR0,I1
+
+Lfill_done:
+  vperm    CTR0,CTR0,CTR0,swap_mask
+  stxvd2x  CTR0X,0,CTR
+
+  blr
+EPILOGUE(_nettle_gcm_fill)
+
+    .data
+    .align 4
+.polynomial:
+  .byte 1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0xc2
+    .align 4
+.swap_mask:
+  .byte 8,9,10,11,12,13,14,15,0,1,2,3,4,5,6,7
+    .align 4
+.hidw_mask:
+  .byte 23,22,21,20,19,18,17,16,7,6,5,4,3,2,1,0
+    .align 4
+.lodw_mask:
+  .byte 31,30,29,28,27,26,25,24,15,14,13,12,11,10,9,8
diff --git a/testsuite/gcm-test.c b/testsuite/gcm-test.c
index c8174019..df1fc94a 100644
--- a/testsuite/gcm-test.c
+++ b/testsuite/gcm-test.c
@@ -170,6 +170,29 @@ test_main(void)
       "16aedbf5a0de6a57a637b39b"),
       SHEX("619cc5aefffe0bfa462af43c1699d050"));

+  /* Test 128 bytes */
+  test_aead(&amp;nettle_gcm_aes128, NULL,
+      SHEX("feffe9928665731c6d6a8f9467308308"),
+      SHEX(""),
+      SHEX("d9313225f88406e5a55909c5aff5269a"
+      "86a7a9531534f7da2e4c303d8a318a72"
+      "1c3c0c95956809532fcf0e2449a6b525"
+      "b16aedf5aa0de657ba637b391aafd255"
+      "5ae376bc5e9f6a1b08e34db7a6ee0736"
+      "9ba662ea12f6f197e6bc3ed69d2480f3"
+      "ea5691347f2ba69113eb37910ebc18c8"
+      "0f697234582016fa956ca8f63ae6b473"),
+      SHEX("42831ec2217774244b7221b784d0d49c"
+      "e3aa212f2c02a4e035c17e2329aca12e"
+      "21d514b25466931c7d8f6a5aac84aa05"
+      "1ba30b396a0aac973d58e091473f5985"
+      "874b1178906ddbeab04ab2fe6cce8c57"
+      "8d7e961bd13fd6a8c56b66ca5e576492"
+      "1a48cd8bda04e66343e73055118b69b9"
+      "ced486813846958a11e602c03cfc232b"),
+      SHEX("cafebabefacedbaddecaf888"),
+      SHEX("796836f1246c9d735c5e1be0a715ccc3"));
+
   /* Test case 7 */
   test_aead(&amp;nettle_gcm_aes192, NULL,
       SHEX("00000000000000000000000000000000"
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200605114825</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-06-05 11:48:25-0400</timestampReceived><subject>Re: [PATCH v3] Implement GOST R 34.11-2012 (Streebog) hash function</subject><body>

Hello,

пт, 5 июн. 2020 г. в 08:46, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt;
&gt; Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:
&gt;
&gt; &gt; Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
&gt; &gt; ---
&gt; &gt;  Makefile.in     |    3 +-
&gt; &gt;  streebog-meta.c |   44 ++
&gt; &gt;  streebog.c      | 1317 +++++++++++++++++++++++++++++++++++++++++++++++
&gt; &gt;  streebog.h      |   99 ++++
&gt; &gt;  4 files changed, 1462 insertions(+), 1 deletion(-)
&gt; &gt;  create mode 100644 streebog-meta.c
&gt; &gt;  create mode 100644 streebog.c
&gt; &gt;  create mode 100644 streebog.h
&gt;
&gt; Looks good. I'll merge when I can do it together with the tests.
&gt;
&gt; Found a minor problem when trying the tests on top of this: this patch
&gt; adds streebog-meta.c, but doesn't add the corresponding declarations in
&gt; nettle-meta.h. Ideally, those should go together (in this patch, in the test
&gt; patch, or as a separate patch). But it's also fine with me if you just
&gt; add the needed declarations together with the tests.

I've sent the fixup. I'm fine with it being squashed into this patch.


-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200619010317</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-06-19 01:03:17-0400</timestampReceived><subject>[PATCH] optimizing AES and GHASH for PPC64LE</subject><body>

---
 Makefile.in                                   |   2 +-
 configure.ac                                  |   5 +
 gcm.c                                         |  19 +-
 powerpc64le/aes-decrypt-internal.asm          | 573 +++++++++++++++
 powerpc64le/aes-encrypt-internal.asm          | 534 ++++++++++++++
 powerpc64le/gcm-hash8.asm                     | 992
++++++++++++++++++++++++++
 powerpc64le/machine.m4                        |   0
 testsuite/gcm-test.c                          |  23 +
 8 files changed, 2146 insertions(+), 2 deletions(-)
 create mode 100644 powerpc64le/aes-decrypt-internal.asm
 create mode 100644 powerpc64le/aes-encrypt-internal.asm
 create mode 100644 powerpc64le/gcm-hash8.asm
 create mode 100644 powerpc64le/machine.m4

diff --git a/Makefile.in b/Makefile.in
index 64ff1001..5bbc0f79 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -603,7 +603,7 @@ distdir: $(DISTFILES)
  done
  set -e; for d in sparc32 sparc64 x86 \
  x86_64 x86_64/aesni x86_64/sha_ni x86_64/fat \
- arm arm/neon arm/v6 arm/fat ; do \
+ arm arm/neon arm/v6 arm/fat powerpc64le ; do \
   mkdir "$(distdir)/$$d" ; \
   find "$(srcdir)/$$d" -maxdepth 1 '(' -name '*.asm' -o -name '*.m4' ')' \
     -exec cp '{}' "$(distdir)/$$d" ';' ; \
diff --git a/configure.ac b/configure.ac
index 90ea1ea8..1ea54ce8 100644
--- a/configure.ac
+++ b/configure.ac
@@ -435,6 +435,9 @@ if test "x$enable_assembler" = xyes ; then
  esac
       fi
       ;;
+    *powerpc64le*)
+  asm_path=powerpc64le
+      ;;
     *)
       enable_assembler=no
       ;;
@@ -572,7 +575,9 @@ AH_VERBATIM([HAVE_NATIVE],
 #undef HAVE_NATIVE_ecc_secp384r1_redc
 #undef HAVE_NATIVE_ecc_secp521r1_modp
 #undef HAVE_NATIVE_ecc_secp521r1_redc
+#undef HAVE_NATIVE_gcm_init_key8
 #undef HAVE_NATIVE_gcm_hash8
+#undef HAVE_NATIVE_gcm_fill
 #undef HAVE_NATIVE_salsa20_core
 #undef HAVE_NATIVE_sha1_compress
 #undef HAVE_NATIVE_sha256_compress
diff --git a/gcm.c b/gcm.c
index cf615daf..809c03bc 100644
--- a/gcm.c
+++ b/gcm.c
@@ -140,6 +140,12 @@ gcm_gf_mul (union nettle_block16 *x, const union
nettle_block16 *table)
   memcpy (x-&gt;b, Z.b, sizeof(Z));
 }
 # elif GCM_TABLE_BITS == 8
+#  if HAVE_NATIVE_gcm_init_key8
+
+#define gcm_init_key _nettle_gcm_init_key8
+void
+_nettle_gcm_init_key8 (union nettle_block16 *table);
+#  endif /* HAVE_NATIVE_gcm_init_key8 */
 #  if HAVE_NATIVE_gcm_hash8

 #define gcm_hash _nettle_gcm_hash8
@@ -225,6 +231,13 @@ gcm_gf_mul (union nettle_block16 *x, const union
nettle_block16 *table)

 #endif /* GCM_TABLE_BITS */

+#if HAVE_NATIVE_gcm_fill
+
+#define gcm_fill _nettle_gcm_fill
+void
+_nettle_gcm_fill (uint8_t *ctr, size_t blocks, union nettle_block16
*buffer);
+#endif /* HAVE_NATIVE_gcm_fill */
+
 /* Increment the rightmost 32 bits. */
 #define INC32(block) INCREMENT(4, (block.b) + GCM_BLOCK_SIZE - 4)

@@ -245,7 +258,9 @@ gcm_set_key(struct gcm_key *key,
   memset(key-&gt;h[0].b, 0, GCM_BLOCK_SIZE);
   f (cipher, GCM_BLOCK_SIZE, key-&gt;h[i].b, key-&gt;h[0].b);

-#if GCM_TABLE_BITS
+#ifdef gcm_init_key
+  gcm_init_key(key-&gt;h);
+#elif GCM_TABLE_BITS
   /* Algorithm 3 from the gcm paper. First do powers of two, then do
      the rest by adding. */
   while (i /= 2)
@@ -333,6 +348,7 @@ gcm_update(struct gcm_ctx *ctx, const struct gcm_key
*key,
   ctx-&gt;auth_size += length;
 }

+#ifndef gcm_fill
 static nettle_fill16_func gcm_fill;
 static void
 gcm_fill(uint8_t *ctr, size_t blocks, union nettle_block16 *buffer)
@@ -349,6 +365,7 @@ gcm_fill(uint8_t *ctr, size_t blocks, union
nettle_block16 *buffer)

   WRITE_UINT32(ctr + GCM_BLOCK_SIZE - 4, c);
 }
+#endif /* !gcm_fill */

 void
 gcm_encrypt (struct gcm_ctx *ctx, const struct gcm_key *key,
diff --git a/powerpc64le/aes-decrypt-internal.asm
b/powerpc64le/aes-decrypt-internal.asm
new file mode 100644
index 00000000..bde34779
--- /dev/null
+++ b/powerpc64le/aes-decrypt-internal.asm
@@ -0,0 +1,573 @@
+C powerpc64le/aes-decrypt-internal.asm
+
+ifelse(&lt;
+   Copyright (C) 2020 Mamone Tarsha
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+&gt;)
+
+C Register usage:
+
+define(&lt;SP&gt;, &lt;1&gt;)
+define(&lt;TOCP&gt;, &lt;2&gt;)
+
+define(&lt;ROUNDS&gt;, &lt;3&gt;)
+define(&lt;KEYS&gt;, &lt;4&gt;)
+define(&lt;LENGTH&gt;, &lt;6&gt;)
+define(&lt;DST&gt;, &lt;7&gt;)
+define(&lt;SRC&gt;, &lt;8&gt;)
+
+define(&lt;swap_mask&gt;, &lt;0&gt;)
+
+define(&lt;K&gt;, &lt;1&gt;)
+define(&lt;S0&gt;, &lt;2&gt;)
+define(&lt;S1&gt;, &lt;3&gt;)
+define(&lt;S2&gt;, &lt;4&gt;)
+define(&lt;S3&gt;, &lt;5&gt;)
+define(&lt;S4&gt;, &lt;6&gt;)
+define(&lt;S5&gt;, &lt;7&gt;)
+define(&lt;S6&gt;, &lt;8&gt;)
+define(&lt;S7&gt;, &lt;9&gt;)
+define(&lt;S8&gt;, &lt;10&gt;)
+define(&lt;S9&gt;, &lt;11&gt;)
+define(&lt;S10&gt;, &lt;12&gt;)
+define(&lt;S11&gt;, &lt;13&gt;)
+define(&lt;S12&gt;, &lt;14&gt;)
+define(&lt;S13&gt;, &lt;15&gt;)
+define(&lt;S14&gt;, &lt;16&gt;)
+define(&lt;S15&gt;, &lt;17&gt;)
+
+define(&lt;KX&gt;, &lt;33&gt;)
+define(&lt;S0X&gt;, &lt;34&gt;)
+define(&lt;S1X&gt;, &lt;35&gt;)
+define(&lt;S2X&gt;, &lt;36&gt;)
+define(&lt;S3X&gt;, &lt;37&gt;)
+define(&lt;S4X&gt;, &lt;38&gt;)
+define(&lt;S5X&gt;, &lt;39&gt;)
+define(&lt;S6X&gt;, &lt;40&gt;)
+define(&lt;S7X&gt;, &lt;41&gt;)
+define(&lt;S8X&gt;, &lt;42&gt;)
+define(&lt;S9X&gt;, &lt;43&gt;)
+define(&lt;S10X&gt;, &lt;44&gt;)
+define(&lt;S11X&gt;, &lt;45&gt;)
+define(&lt;S12X&gt;, &lt;46&gt;)
+define(&lt;S13X&gt;, &lt;47&gt;)
+define(&lt;S14X&gt;, &lt;48&gt;)
+define(&lt;S15X&gt;, &lt;49&gt;)
+
+C ZERO vector register is used in place of RoundKey
+C for vncipher instruction because the order of InvMixColumns
+C and Xor processes are flipped in that instruction.
+C The Xor process with RoundKey is executed afterward.
+define(&lt;ZERO&gt;, &lt;18&gt;)
+
+ .file "aes-decrypt-internal.asm"
+
+ C _aes_decrypt(unsigned rounds, const uint32_t *keys,
+ C       const struct aes_table *T,
+ C       size_t length, uint8_t *dst,
+ C       uint8_t *src)
+
+ .text
+.align 5
+PROLOGUE(_nettle_aes_decrypt)
+  vxor      ZERO,ZERO,ZERO
+
+  ld     5,.swap_mask@got(TOCP)
+ lvx   swap_mask,0,5
+
+  subi      ROUNDS,ROUNDS,1
+  srdi      LENGTH,LENGTH,4
+
+  srdi      5,LENGTH,4              # 16x loop count
+  cmpldi 5,0
+  beq       L8x
+
+  std       17,-120(SP);
+  std       18,-112(SP);
+  std       19,-104(SP);
+  std       20,-96(SP);
+  std       21,-88(SP);
+  std       22,-80(SP);
+  std       23,-72(SP);
+  std       24,-64(SP);
+  std       25,-56(SP);
+  std       26,-48(SP);
+  std       27,-40(SP);
+  std       28,-32(SP);
+  std       29,-24(SP);
+  std       30,-16(SP);
+  std       31,-8(SP);
+
+  li        17,0x10
+  li        18,0x20
+  li        19,0x30
+  li        20,0x40
+  li        21,0x50
+  li        22,0x60
+  li        23,0x70
+  li        24,0x80
+  li        25,0x90
+  li        26,0xA0
+  li        27,0xB0
+  li        28,0xC0
+  li        29,0xD0
+  li        30,0xE0
+  li        31,0xF0
+
+.align 5
+Lx16_loop:
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+  lxvd2x S1X,17,SRC
+  lxvd2x S2X,18,SRC
+  lxvd2x S3X,19,SRC
+  lxvd2x S4X,20,SRC
+  lxvd2x S5X,21,SRC
+  lxvd2x S6X,22,SRC
+  lxvd2x S7X,23,SRC
+  lxvd2x S8X,24,SRC
+  lxvd2x S9X,25,SRC
+  lxvd2x S10X,26,SRC
+  lxvd2x S11X,27,SRC
+  lxvd2x S12X,28,SRC
+  lxvd2x S13X,29,SRC
+  lxvd2x S14X,30,SRC
+  lxvd2x S15X,31,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+  vxor      S4,S4,K
+  vxor      S5,S5,K
+  vxor      S6,S6,K
+  vxor      S7,S7,K
+  vxor      S8,S8,K
+  vxor      S9,S9,K
+  vxor      S10,S10,K
+  vxor      S11,S11,K
+  vxor      S12,S12,K
+  vxor      S13,S13,K
+  vxor      S14,S14,K
+  vxor      S15,S15,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+  vperm  S4,S4,S4,swap_mask
+  vperm  S5,S5,S5,swap_mask
+  vperm  S6,S6,S6,swap_mask
+  vperm  S7,S7,S7,swap_mask
+  vperm  S8,S8,S8,swap_mask
+  vperm  S9,S9,S9,swap_mask
+  vperm  S10,S10,S10,swap_mask
+  vperm  S11,S11,S11,swap_mask
+  vperm  S12,S12,S12,swap_mask
+  vperm  S13,S13,S13,swap_mask
+  vperm  S14,S14,S14,swap_mask
+  vperm  S15,S15,S15,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L16x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vncipher   S0,S0,ZERO
+  vncipher   S1,S1,ZERO
+  vncipher   S2,S2,ZERO
+  vncipher   S3,S3,ZERO
+  vncipher   S4,S4,ZERO
+  vncipher   S5,S5,ZERO
+  vncipher   S6,S6,ZERO
+  vncipher   S7,S7,ZERO
+  vncipher   S8,S8,ZERO
+  vncipher   S9,S9,ZERO
+  vncipher   S10,S10,ZERO
+  vncipher   S11,S11,ZERO
+  vncipher   S12,S12,ZERO
+  vncipher   S13,S13,ZERO
+  vncipher   S14,S14,ZERO
+  vncipher   S15,S15,ZERO
+  vxor       S0,S0,K
+  vxor       S1,S1,K
+  vxor       S2,S2,K
+  vxor       S3,S3,K
+  vxor       S4,S4,K
+  vxor       S5,S5,K
+  vxor       S6,S6,K
+  vxor       S7,S7,K
+  vxor       S8,S8,K
+  vxor       S9,S9,K
+  vxor       S10,S10,K
+  vxor       S11,S11,K
+  vxor       S12,S12,K
+  vxor       S13,S13,K
+  vxor       S14,S14,K
+  vxor       S15,S15,K
+  addi      10,10,0x10
+  bdnz      L16x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vncipherlast   S0,S0,K
+  vncipherlast   S1,S1,K
+  vncipherlast   S2,S2,K
+  vncipherlast   S3,S3,K
+  vncipherlast   S4,S4,K
+  vncipherlast   S5,S5,K
+  vncipherlast   S6,S6,K
+  vncipherlast   S7,S7,K
+  vncipherlast   S8,S8,K
+  vncipherlast   S9,S9,K
+  vncipherlast   S10,S10,K
+  vncipherlast   S11,S11,K
+  vncipherlast   S12,S12,K
+  vncipherlast   S13,S13,K
+  vncipherlast   S14,S14,K
+  vncipherlast   S15,S15,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+  vperm  S4,S4,S4,swap_mask
+  vperm  S5,S5,S5,swap_mask
+  vperm  S6,S6,S6,swap_mask
+  vperm  S7,S7,S7,swap_mask
+  vperm  S8,S8,S8,swap_mask
+  vperm  S9,S9,S9,swap_mask
+  vperm  S10,S10,S10,swap_mask
+  vperm  S11,S11,S11,swap_mask
+  vperm  S12,S12,S12,swap_mask
+  vperm  S13,S13,S13,swap_mask
+  vperm  S14,S14,S14,swap_mask
+  vperm  S15,S15,S15,swap_mask
+
+  stxvd2x S0X,0,DST
+  stxvd2x S1X,17,DST
+  stxvd2x S2X,18,DST
+  stxvd2x S3X,19,DST
+  stxvd2x S4X,20,DST
+  stxvd2x S5X,21,DST
+  stxvd2x S6X,22,DST
+  stxvd2x S7X,23,DST
+  stxvd2x S8X,24,DST
+  stxvd2x S9X,25,DST
+  stxvd2x S10X,26,DST
+  stxvd2x S11X,27,DST
+  stxvd2x S12X,28,DST
+  stxvd2x S13X,29,DST
+  stxvd2x S14X,30,DST
+  stxvd2x S15X,31,DST
+
+  addi      SRC,SRC,0x100
+  addi      DST,DST,0x100
+  subic.    5,5,1
+  bne       Lx16_loop
+
+  ld        17,-120(SP);
+  ld        18,-112(SP);
+  ld        19,-104(SP);
+  ld        20,-96(SP);
+  ld        21,-88(SP);
+  ld        22,-80(SP);
+  ld        23,-72(SP);
+  ld        24,-64(SP);
+  ld        25,-56(SP);
+  ld        26,-48(SP);
+  ld        27,-40(SP);
+  ld        28,-32(SP);
+  ld        29,-24(SP);
+  ld        30,-16(SP);
+  ld        31,-8(SP);
+
+  clrldi   LENGTH,LENGTH,60
+
+L8x:
+  srdi      5,LENGTH,3
+  cmpldi 5,0
+  beq       L4x
+
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+  li        9,0x10
+  lxvd2x S1X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S2X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S3X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S4X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S5X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S6X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S7X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+  vxor      S4,S4,K
+  vxor      S5,S5,K
+  vxor      S6,S6,K
+  vxor      S7,S7,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+  vperm  S4,S4,S4,swap_mask
+  vperm  S5,S5,S5,swap_mask
+  vperm  S6,S6,S6,swap_mask
+  vperm  S7,S7,S7,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L8x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vncipher   S0,S0,ZERO
+  vncipher   S1,S1,ZERO
+  vncipher   S2,S2,ZERO
+  vncipher   S3,S3,ZERO
+  vncipher   S4,S4,ZERO
+  vncipher   S5,S5,ZERO
+  vncipher   S6,S6,ZERO
+  vncipher   S7,S7,ZERO
+  vxor       S0,S0,K
+  vxor       S1,S1,K
+  vxor       S2,S2,K
+  vxor       S3,S3,K
+  vxor       S4,S4,K
+  vxor       S5,S5,K
+  vxor       S6,S6,K
+  vxor       S7,S7,K
+  addi      10,10,0x10
+  bdnz      L8x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vncipherlast   S0,S0,K
+  vncipherlast   S1,S1,K
+  vncipherlast   S2,S2,K
+  vncipherlast   S3,S3,K
+  vncipherlast   S4,S4,K
+  vncipherlast   S5,S5,K
+  vncipherlast   S6,S6,K
+  vncipherlast   S7,S7,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+  vperm  S4,S4,S4,swap_mask
+  vperm  S5,S5,S5,swap_mask
+  vperm  S6,S6,S6,swap_mask
+  vperm  S7,S7,S7,swap_mask
+
+  stxvd2x S0X,0,DST
+  li        9,0x10
+  stxvd2x S1X,9,DST
+  addi      9,9,0x10
+  stxvd2x S2X,9,DST
+  addi      9,9,0x10
+  stxvd2x S3X,9,DST
+  addi      9,9,0x10
+  stxvd2x S4X,9,DST
+  addi      9,9,0x10
+  stxvd2x S5X,9,DST
+  addi      9,9,0x10
+  stxvd2x S6X,9,DST
+  addi      9,9,0x10
+  stxvd2x S7X,9,DST
+
+  addi      SRC,SRC,0x80
+  addi      DST,DST,0x80
+
+  clrldi   LENGTH,LENGTH,61
+
+L4x:
+  srdi      5,LENGTH,2
+  cmpldi 5,0
+  beq       L2x
+
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+  li        9,0x10
+  lxvd2x S1X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S2X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S3X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L4x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vncipher   S0,S0,ZERO
+  vncipher   S1,S1,ZERO
+  vncipher   S2,S2,ZERO
+  vncipher   S3,S3,ZERO
+  vxor       S0,S0,K
+  vxor       S1,S1,K
+  vxor       S2,S2,K
+  vxor       S3,S3,K
+  addi      10,10,0x10
+  bdnz      L4x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vncipherlast   S0,S0,K
+  vncipherlast   S1,S1,K
+  vncipherlast   S2,S2,K
+  vncipherlast   S3,S3,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+
+  stxvd2x S0X,0,DST
+  li        9,0x10
+  stxvd2x S1X,9,DST
+  addi      9,9,0x10
+  stxvd2x S2X,9,DST
+  addi      9,9,0x10
+  stxvd2x S3X,9,DST
+
+  addi      SRC,SRC,0x40
+  addi      DST,DST,0x40
+
+  clrldi   LENGTH,LENGTH,62
+
+L2x:
+  srdi      5,LENGTH,1
+  cmpldi 5,0
+  beq       L1x
+
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+  li        9,0x10
+  lxvd2x S1X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L2x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vncipher   S0,S0,ZERO
+  vncipher   S1,S1,ZERO
+  vxor       S0,S0,K
+  vxor       S1,S1,K
+  addi      10,10,0x10
+  bdnz      L2x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vncipherlast   S0,S0,K
+  vncipherlast   S1,S1,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+
+  stxvd2x S0X,0,DST
+  li        9,0x10
+  stxvd2x S1X,9,DST
+
+  addi      SRC,SRC,0x20
+  addi      DST,DST,0x20
+
+  clrldi   LENGTH,LENGTH,63
+
+L1x:
+  cmpldi LENGTH,0
+  beq       Ldone
+
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+
+  vxor      S0,S0,K
+
+  vperm  S0,S0,S0,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L1x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vncipher   S0,S0,ZERO
+  vxor       S0,S0,K
+  addi      10,10,0x10
+  bdnz      L1x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vncipherlast   S0,S0,K
+
+  vperm  S0,S0,S0,swap_mask
+
+  stxvd2x S0X,0,DST
+
+Ldone:
+  blr
+EPILOGUE(_nettle_aes_decrypt)
+
+  .data
+  .align 4
+.swap_mask:
+ .byte 8,9,10,11,12,13,14,15,0,1,2,3,4,5,6,7
diff --git a/powerpc64le/aes-encrypt-internal.asm
b/powerpc64le/aes-encrypt-internal.asm
new file mode 100644
index 00000000..1bbd86a8
--- /dev/null
+++ b/powerpc64le/aes-encrypt-internal.asm
@@ -0,0 +1,534 @@
+C powerpc64le/aes-encrypt-internal.asm
+
+ifelse(&lt;
+   Copyright (C) 2020 Mamone Tarsha
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+&gt;)
+
+C Register usage:
+
+define(&lt;SP&gt;, &lt;1&gt;)
+define(&lt;TOCP&gt;, &lt;2&gt;)
+
+define(&lt;ROUNDS&gt;, &lt;3&gt;)
+define(&lt;KEYS&gt;, &lt;4&gt;)
+define(&lt;LENGTH&gt;, &lt;6&gt;)
+define(&lt;DST&gt;, &lt;7&gt;)
+define(&lt;SRC&gt;, &lt;8&gt;)
+
+define(&lt;swap_mask&gt;, &lt;0&gt;)
+
+define(&lt;K&gt;, &lt;1&gt;)
+define(&lt;S0&gt;, &lt;2&gt;)
+define(&lt;S1&gt;, &lt;3&gt;)
+define(&lt;S2&gt;, &lt;4&gt;)
+define(&lt;S3&gt;, &lt;5&gt;)
+define(&lt;S4&gt;, &lt;6&gt;)
+define(&lt;S5&gt;, &lt;7&gt;)
+define(&lt;S6&gt;, &lt;8&gt;)
+define(&lt;S7&gt;, &lt;9&gt;)
+define(&lt;S8&gt;, &lt;10&gt;)
+define(&lt;S9&gt;, &lt;11&gt;)
+define(&lt;S10&gt;, &lt;12&gt;)
+define(&lt;S11&gt;, &lt;13&gt;)
+define(&lt;S12&gt;, &lt;14&gt;)
+define(&lt;S13&gt;, &lt;15&gt;)
+define(&lt;S14&gt;, &lt;16&gt;)
+define(&lt;S15&gt;, &lt;17&gt;)
+
+define(&lt;KX&gt;, &lt;33&gt;)
+define(&lt;S0X&gt;, &lt;34&gt;)
+define(&lt;S1X&gt;, &lt;35&gt;)
+define(&lt;S2X&gt;, &lt;36&gt;)
+define(&lt;S3X&gt;, &lt;37&gt;)
+define(&lt;S4X&gt;, &lt;38&gt;)
+define(&lt;S5X&gt;, &lt;39&gt;)
+define(&lt;S6X&gt;, &lt;40&gt;)
+define(&lt;S7X&gt;, &lt;41&gt;)
+define(&lt;S8X&gt;, &lt;42&gt;)
+define(&lt;S9X&gt;, &lt;43&gt;)
+define(&lt;S10X&gt;, &lt;44&gt;)
+define(&lt;S11X&gt;, &lt;45&gt;)
+define(&lt;S12X&gt;, &lt;46&gt;)
+define(&lt;S13X&gt;, &lt;47&gt;)
+define(&lt;S14X&gt;, &lt;48&gt;)
+define(&lt;S15X&gt;, &lt;49&gt;)
+
+ .file "aes-encrypt-internal.asm"
+
+ C _aes_encrypt(unsigned rounds, const uint32_t *keys,
+ C       const struct aes_table *T,
+ C       size_t length, uint8_t *dst,
+ C       uint8_t *src)
+
+ .text
+.align 5
+PROLOGUE(_nettle_aes_encrypt)
+  ld     5,.swap_mask@got(TOCP)
+ lvx   swap_mask,0,5
+
+  subi      ROUNDS,ROUNDS,1
+  srdi      LENGTH,LENGTH,4
+
+  srdi      5,LENGTH,4              # 16x loop count
+  cmpldi 5,0
+  beq       L8x
+
+  std       17,-120(SP);
+  std       18,-112(SP);
+  std       19,-104(SP);
+  std       20,-96(SP);
+  std       21,-88(SP);
+  std       22,-80(SP);
+  std       23,-72(SP);
+  std       24,-64(SP);
+  std       25,-56(SP);
+  std       26,-48(SP);
+  std       27,-40(SP);
+  std       28,-32(SP);
+  std       29,-24(SP);
+  std       30,-16(SP);
+  std       31,-8(SP);
+
+  li        17,0x10
+  li        18,0x20
+  li        19,0x30
+  li        20,0x40
+  li        21,0x50
+  li        22,0x60
+  li        23,0x70
+  li        24,0x80
+  li        25,0x90
+  li        26,0xA0
+  li        27,0xB0
+  li        28,0xC0
+  li        29,0xD0
+  li        30,0xE0
+  li        31,0xF0
+
+.align 5
+Lx16_loop:
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+  lxvd2x S1X,17,SRC
+  lxvd2x S2X,18,SRC
+  lxvd2x S3X,19,SRC
+  lxvd2x S4X,20,SRC
+  lxvd2x S5X,21,SRC
+  lxvd2x S6X,22,SRC
+  lxvd2x S7X,23,SRC
+  lxvd2x S8X,24,SRC
+  lxvd2x S9X,25,SRC
+  lxvd2x S10X,26,SRC
+  lxvd2x S11X,27,SRC
+  lxvd2x S12X,28,SRC
+  lxvd2x S13X,29,SRC
+  lxvd2x S14X,30,SRC
+  lxvd2x S15X,31,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+  vxor      S4,S4,K
+  vxor      S5,S5,K
+  vxor      S6,S6,K
+  vxor      S7,S7,K
+  vxor      S8,S8,K
+  vxor      S9,S9,K
+  vxor      S10,S10,K
+  vxor      S11,S11,K
+  vxor      S12,S12,K
+  vxor      S13,S13,K
+  vxor      S14,S14,K
+  vxor      S15,S15,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+  vperm  S4,S4,S4,swap_mask
+  vperm  S5,S5,S5,swap_mask
+  vperm  S6,S6,S6,swap_mask
+  vperm  S7,S7,S7,swap_mask
+  vperm  S8,S8,S8,swap_mask
+  vperm  S9,S9,S9,swap_mask
+  vperm  S10,S10,S10,swap_mask
+  vperm  S11,S11,S11,swap_mask
+  vperm  S12,S12,S12,swap_mask
+  vperm  S13,S13,S13,swap_mask
+  vperm  S14,S14,S14,swap_mask
+  vperm  S15,S15,S15,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L16x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vcipher   S0,S0,K
+  vcipher   S1,S1,K
+  vcipher   S2,S2,K
+  vcipher   S3,S3,K
+  vcipher   S4,S4,K
+  vcipher   S5,S5,K
+  vcipher   S6,S6,K
+  vcipher   S7,S7,K
+  vcipher   S8,S8,K
+  vcipher   S9,S9,K
+  vcipher   S10,S10,K
+  vcipher   S11,S11,K
+  vcipher   S12,S12,K
+  vcipher   S13,S13,K
+  vcipher   S14,S14,K
+  vcipher   S15,S15,K
+  addi      10,10,0x10
+  bdnz      L16x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vcipherlast   S0,S0,K
+  vcipherlast   S1,S1,K
+  vcipherlast   S2,S2,K
+  vcipherlast   S3,S3,K
+  vcipherlast   S4,S4,K
+  vcipherlast   S5,S5,K
+  vcipherlast   S6,S6,K
+  vcipherlast   S7,S7,K
+  vcipherlast   S8,S8,K
+  vcipherlast   S9,S9,K
+  vcipherlast   S10,S10,K
+  vcipherlast   S11,S11,K
+  vcipherlast   S12,S12,K
+  vcipherlast   S13,S13,K
+  vcipherlast   S14,S14,K
+  vcipherlast   S15,S15,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+  vperm  S4,S4,S4,swap_mask
+  vperm  S5,S5,S5,swap_mask
+  vperm  S6,S6,S6,swap_mask
+  vperm  S7,S7,S7,swap_mask
+  vperm  S8,S8,S8,swap_mask
+  vperm  S9,S9,S9,swap_mask
+  vperm  S10,S10,S10,swap_mask
+  vperm  S11,S11,S11,swap_mask
+  vperm  S12,S12,S12,swap_mask
+  vperm  S13,S13,S13,swap_mask
+  vperm  S14,S14,S14,swap_mask
+  vperm  S15,S15,S15,swap_mask
+
+  stxvd2x S0X,0,DST
+  stxvd2x S1X,17,DST
+  stxvd2x S2X,18,DST
+  stxvd2x S3X,19,DST
+  stxvd2x S4X,20,DST
+  stxvd2x S5X,21,DST
+  stxvd2x S6X,22,DST
+  stxvd2x S7X,23,DST
+  stxvd2x S8X,24,DST
+  stxvd2x S9X,25,DST
+  stxvd2x S10X,26,DST
+  stxvd2x S11X,27,DST
+  stxvd2x S12X,28,DST
+  stxvd2x S13X,29,DST
+  stxvd2x S14X,30,DST
+  stxvd2x S15X,31,DST
+
+  addi      SRC,SRC,0x100
+  addi      DST,DST,0x100
+  subic.    5,5,1
+  bne       Lx16_loop
+
+  ld        17,-120(SP);
+  ld        18,-112(SP);
+  ld        19,-104(SP);
+  ld        20,-96(SP);
+  ld        21,-88(SP);
+  ld        22,-80(SP);
+  ld        23,-72(SP);
+  ld        24,-64(SP);
+  ld        25,-56(SP);
+  ld        26,-48(SP);
+  ld        27,-40(SP);
+  ld        28,-32(SP);
+  ld        29,-24(SP);
+  ld        30,-16(SP);
+  ld        31,-8(SP);
+
+  clrldi   LENGTH,LENGTH,60
+
+L8x:
+  srdi      5,LENGTH,3
+  cmpldi 5,0
+  beq       L4x
+
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+  li        9,0x10
+  lxvd2x S1X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S2X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S3X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S4X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S5X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S6X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S7X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+  vxor      S4,S4,K
+  vxor      S5,S5,K
+  vxor      S6,S6,K
+  vxor      S7,S7,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+  vperm  S4,S4,S4,swap_mask
+  vperm  S5,S5,S5,swap_mask
+  vperm  S6,S6,S6,swap_mask
+  vperm  S7,S7,S7,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L8x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vcipher   S0,S0,K
+  vcipher   S1,S1,K
+  vcipher   S2,S2,K
+  vcipher   S3,S3,K
+  vcipher   S4,S4,K
+  vcipher   S5,S5,K
+  vcipher   S6,S6,K
+  vcipher   S7,S7,K
+  addi      10,10,0x10
+  bdnz      L8x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vcipherlast   S0,S0,K
+  vcipherlast   S1,S1,K
+  vcipherlast   S2,S2,K
+  vcipherlast   S3,S3,K
+  vcipherlast   S4,S4,K
+  vcipherlast   S5,S5,K
+  vcipherlast   S6,S6,K
+  vcipherlast   S7,S7,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+  vperm  S4,S4,S4,swap_mask
+  vperm  S5,S5,S5,swap_mask
+  vperm  S6,S6,S6,swap_mask
+  vperm  S7,S7,S7,swap_mask
+
+  stxvd2x S0X,0,DST
+  li        9,0x10
+  stxvd2x S1X,9,DST
+  addi      9,9,0x10
+  stxvd2x S2X,9,DST
+  addi      9,9,0x10
+  stxvd2x S3X,9,DST
+  addi      9,9,0x10
+  stxvd2x S4X,9,DST
+  addi      9,9,0x10
+  stxvd2x S5X,9,DST
+  addi      9,9,0x10
+  stxvd2x S6X,9,DST
+  addi      9,9,0x10
+  stxvd2x S7X,9,DST
+
+  addi      SRC,SRC,0x80
+  addi      DST,DST,0x80
+
+  clrldi   LENGTH,LENGTH,61
+
+L4x:
+  srdi      5,LENGTH,2
+  cmpldi 5,0
+  beq       L2x
+
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+  li        9,0x10
+  lxvd2x S1X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S2X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S3X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L4x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vcipher   S0,S0,K
+  vcipher   S1,S1,K
+  vcipher   S2,S2,K
+  vcipher   S3,S3,K
+  addi      10,10,0x10
+  bdnz      L4x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vcipherlast   S0,S0,K
+  vcipherlast   S1,S1,K
+  vcipherlast   S2,S2,K
+  vcipherlast   S3,S3,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+
+  stxvd2x S0X,0,DST
+  li        9,0x10
+  stxvd2x S1X,9,DST
+  addi      9,9,0x10
+  stxvd2x S2X,9,DST
+  addi      9,9,0x10
+  stxvd2x S3X,9,DST
+
+  addi      SRC,SRC,0x40
+  addi      DST,DST,0x40
+
+  clrldi   LENGTH,LENGTH,62
+
+L2x:
+  srdi      5,LENGTH,1
+  cmpldi 5,0
+  beq       L1x
+
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+  li        9,0x10
+  lxvd2x S1X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L2x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vcipher   S0,S0,K
+  vcipher   S1,S1,K
+  addi      10,10,0x10
+  bdnz      L2x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vcipherlast   S0,S0,K
+  vcipherlast   S1,S1,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+
+  stxvd2x S0X,0,DST
+  li        9,0x10
+  stxvd2x S1X,9,DST
+
+  addi      SRC,SRC,0x20
+  addi      DST,DST,0x20
+
+  clrldi   LENGTH,LENGTH,63
+
+L1x:
+  cmpldi LENGTH,0
+  beq       Ldone
+
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+
+  vxor      S0,S0,K
+
+  vperm  S0,S0,S0,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L1x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vcipher   S0,S0,K
+  addi      10,10,0x10
+  bdnz      L1x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vcipherlast   S0,S0,K
+
+  vperm  S0,S0,S0,swap_mask
+
+  stxvd2x S0X,0,DST
+
+Ldone:
+  blr
+EPILOGUE(_nettle_aes_encrypt)
+
+  .data
+  .align 4
+.swap_mask:
+ .byte 8,9,10,11,12,13,14,15,0,1,2,3,4,5,6,7
diff --git a/powerpc64le/gcm-hash8.asm b/powerpc64le/gcm-hash8.asm
new file mode 100644
index 00000000..a809f6ef
--- /dev/null
+++ b/powerpc64le/gcm-hash8.asm
@@ -0,0 +1,992 @@
+C powerpc64le/gcm-hash8.asm
+
+ifelse(&lt;
+   Copyright (C) 2020 Mamone Tarsha
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+&gt;)
+
+C Register usage:
+C VSX instructions is used to load and store data to memory "lxvd2x,
stxvd2x"
+C instead of VR instructions "lvx, stvx" as a workaround to access
unaligned data
+C VSX registers are defined with "X" suffix
+
+define(&lt;SP&gt;, &lt;1&gt;)
+define(&lt;TOCP&gt;, &lt;2&gt;)
+
+define(&lt;TABLE&gt;, &lt;3&gt;)
+define(&lt;X&gt;, &lt;4&gt;)
+define(&lt;LENGTH&gt;, &lt;5&gt;)
+define(&lt;DATA&gt;, &lt;6&gt;)
+
+define(&lt;zero&gt;, &lt;0&gt;)
+define(&lt;swap_mask&gt;, &lt;1&gt;)
+define(&lt;hidw_mask&gt;, &lt;2&gt;)
+define(&lt;lodw_mask&gt;, &lt;3&gt;)
+define(&lt;poly&gt;, &lt;4&gt;)
+define(&lt;poly_h&gt;, &lt;4&gt;)
+define(&lt;poly_l&gt;, &lt;5&gt;)
+define(&lt;RP&gt;, &lt;6&gt;)
+define(&lt;Mh&gt;, &lt;7&gt;)
+define(&lt;Ml&gt;, &lt;8&gt;)
+define(&lt;H&gt;, &lt;9&gt;)
+define(&lt;Hh&gt;, &lt;10&gt;)
+define(&lt;Hl&gt;, &lt;11&gt;)
+define(&lt;RP2&gt;, &lt;9&gt;)
+define(&lt;M2h&gt;, &lt;10&gt;)
+define(&lt;M2l&gt;, &lt;11&gt;)
+
+define(&lt;HX&gt;, &lt;41&gt;)
+define(&lt;HhX&gt;, &lt;42&gt;)
+define(&lt;HlX&gt;, &lt;43&gt;)
+define(&lt;H_HhX&gt;, &lt;44&gt;)
+define(&lt;H_HX&gt;, &lt;45&gt;)
+define(&lt;H_HlX&gt;, &lt;46&gt;)
+
+define(&lt;sl1&gt;, &lt;1&gt;)
+define(&lt;msb&gt;, &lt;5&gt;)
+define(&lt;H2&gt;, &lt;6&gt;)
+define(&lt;H2h&gt;, &lt;7&gt;)
+define(&lt;H2l&gt;, &lt;8&gt;)
+define(&lt;H_h&gt;, &lt;12&gt;)
+define(&lt;H_m&gt;, &lt;13&gt;)
+define(&lt;H_l&gt;, &lt;14&gt;)
+define(&lt;H_Hh&gt;, &lt;12&gt;)
+define(&lt;H_H&gt;, &lt;13&gt;)
+define(&lt;H_Hl&gt;, &lt;14&gt;)
+define(&lt;H_t&gt;, &lt;15&gt;)
+define(&lt;H2_h&gt;, &lt;16&gt;)
+define(&lt;H2_m&gt;, &lt;17&gt;)
+define(&lt;H2_l&gt;, &lt;18&gt;)
+define(&lt;H2_t&gt;, &lt;19&gt;)
+
+define(&lt;C0X&gt;, &lt;38&gt;)
+define(&lt;C1X&gt;, &lt;39&gt;)
+define(&lt;C2X&gt;, &lt;40&gt;)
+define(&lt;C3X&gt;, &lt;44&gt;)
+define(&lt;C4X&gt;, &lt;38&gt;)
+define(&lt;C5X&gt;, &lt;39&gt;)
+define(&lt;C6X&gt;, &lt;40&gt;)
+define(&lt;C7X&gt;, &lt;44&gt;)
+
+define(&lt;CX&gt;, &lt;45&gt;)
+
+define(&lt;C0&gt;, &lt;6&gt;)
+define(&lt;C1&gt;, &lt;7&gt;)
+define(&lt;C2&gt;, &lt;8&gt;)
+define(&lt;C3&gt;, &lt;12&gt;)
+define(&lt;C4&gt;, &lt;6&gt;)
+define(&lt;C5&gt;, &lt;7&gt;)
+define(&lt;C6&gt;, &lt;8&gt;)
+define(&lt;C7&gt;, &lt;12&gt;)
+
+define(&lt;C&gt;, &lt;13&gt;)
+
+define(&lt;Ch&gt;, &lt;14&gt;)
+define(&lt;Cl&gt;, &lt;15&gt;)
+define(&lt;Cm&gt;, &lt;16&gt;)
+
+define(&lt;C01h&gt;, &lt;14&gt;)
+define(&lt;C01l&gt;, &lt;15&gt;)
+define(&lt;C01&gt;, &lt;16&gt;)
+define(&lt;C23h&gt;, &lt;17&gt;)
+define(&lt;C23l&gt;, &lt;18&gt;)
+define(&lt;C23&gt;, &lt;19&gt;)
+define(&lt;C45h&gt;, &lt;20&gt;)
+define(&lt;C45l&gt;, &lt;21&gt;)
+define(&lt;C45&gt;, &lt;22&gt;)
+define(&lt;C67h&gt;, &lt;6&gt;)
+define(&lt;C67l&gt;, &lt;7&gt;)
+define(&lt;C67&gt;, &lt;8&gt;)
+
+define(&lt;H21&gt;, &lt;9&gt;)
+define(&lt;H21h&gt;, &lt;10&gt;)
+define(&lt;H21l&gt;, &lt;11&gt;)
+define(&lt;H43&gt;, &lt;23&gt;)
+define(&lt;H43h&gt;, &lt;24&gt;)
+define(&lt;H43l&gt;, &lt;25&gt;)
+define(&lt;H65&gt;, &lt;26&gt;)
+define(&lt;H65h&gt;, &lt;27&gt;)
+define(&lt;H65l&gt;, &lt;28&gt;)
+define(&lt;H87&gt;, &lt;29&gt;)
+define(&lt;H87h&gt;, &lt;30&gt;)
+define(&lt;H87l&gt;, &lt;31&gt;)
+
+define(&lt;H21X&gt;, &lt;41&gt;)
+define(&lt;H21hX&gt;, &lt;42&gt;)
+define(&lt;H21lX&gt;, &lt;43&gt;)
+define(&lt;H43X&gt;, &lt;55&gt;)
+define(&lt;H43hX&gt;, &lt;56&gt;)
+define(&lt;H43lX&gt;, &lt;57&gt;)
+define(&lt;H65X&gt;, &lt;58&gt;)
+define(&lt;H65hX&gt;, &lt;59&gt;)
+define(&lt;H65lX&gt;, &lt;60&gt;)
+define(&lt;H87X&gt;, &lt;61&gt;)
+define(&lt;H87hX&gt;, &lt;62&gt;)
+define(&lt;H87lX&gt;, &lt;63&gt;)
+
+# gcm_fill registers:
+
+define(&lt;CTR&gt;, &lt;3&gt;)
+define(&lt;BLOCKS&gt;, &lt;4&gt;)
+define(&lt;BUFFER&gt;, &lt;5&gt;)
+
+define(&lt;CTR0&gt;, &lt;2&gt;)
+define(&lt;CTR0S&gt;, &lt;3&gt;)
+define(&lt;CTR1&gt;, &lt;4&gt;)
+define(&lt;CTR2&gt;, &lt;5&gt;)
+define(&lt;CTR3&gt;, &lt;6&gt;)
+define(&lt;CTR4&gt;, &lt;7&gt;)
+define(&lt;CTR5&gt;, &lt;8&gt;)
+define(&lt;CTR6&gt;, &lt;9&gt;)
+define(&lt;CTR7&gt;, &lt;10&gt;)
+
+define(&lt;CTR0X&gt;, &lt;34&gt;)
+define(&lt;CTR0SX&gt;, &lt;35&gt;)
+define(&lt;CTR1X&gt;, &lt;36&gt;)
+define(&lt;CTR2X&gt;, &lt;37&gt;)
+define(&lt;CTR3X&gt;, &lt;38&gt;)
+define(&lt;CTR4X&gt;, &lt;39&gt;)
+define(&lt;CTR5X&gt;, &lt;40&gt;)
+define(&lt;CTR6X&gt;, &lt;41&gt;)
+define(&lt;CTR7X&gt;, &lt;42&gt;)
+
+define(&lt;I1&gt;, &lt;11&gt;)
+define(&lt;I2&gt;, &lt;12&gt;)
+define(&lt;I3&gt;, &lt;13&gt;)
+define(&lt;I4&gt;, &lt;14&gt;)
+define(&lt;I5&gt;, &lt;15&gt;)
+define(&lt;I6&gt;, &lt;16&gt;)
+define(&lt;I7&gt;, &lt;17&gt;)
+define(&lt;I8&gt;, &lt;18&gt;)
+
+ .file "gcm-hash8.asm"
+
+ # void gcm_init_key (union gcm_block *table)
+
+    .text
+.align 5
+PROLOGUE(_nettle_gcm_init_key8)
+    ld     7,.polynomial@got(TOCP)
+ lvx   poly,0,7
+ ld     7,.swap_mask@got(TOCP)
+ lvx   swap_mask,0,7
+ ld     7,.hidw_mask@got(TOCP)
+ lvx     hidw_mask,0,7
+ ld     7,.lodw_mask@got(TOCP)
+ lvx   lodw_mask,0,7
+
+ li    10,0x800
+    lxvd2x HX,10,TABLE # load H
+ vperm H,H,H,swap_mask
+
+ # --- calculate H = H shift left 1 modulo polynomial ---
+
+ vupkhsw    msb,H # most significant bit word-extend
+ vspltisb sl1,1 # splat 1 for shift left
+ vspltw      msb,msb,0 # most significant bit extend
+ vsl    H,H,sl1 # H shift left 1
+ vand msb,msb,poly
+ vxor zero,zero,zero
+ vxor H_t,H,msb
+
+ vsldoi H,H_t,H_t,8 # doubleword swap
+ vsldoi Hh,H,zero,8
+ vsldoi Hl,zero,H,8
+
+ # --- calculate H^2 = H*H ---
+
+ # reduction pre-processing
+ vsldoi poly_h,zero,poly,8
+ vsldoi poly_l,poly_h,poly_h,8
+
+ # polynomial multiplication "classical"
+ vpmsumd H_h,H_t,Hh # H^1h*H^1h
+ vpmsumd H_l,H_t,Hl # H^1l*H^1l
+ vpmsumd H_m,H_t,H # H^1h*H^1l⊕H^1l*H^1h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h   # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8   # [2]
+ vsldoi Ml,H_m,zero,8 # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor H_h,H_h,Mh       # [2]
+ vxor H_l,H_l,Ml       # [2]
+ vxor H_l,H_l,RP       # [1]
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l
+ vxor H_h,H_l,H_h
+ vxor H2_t,H_h,RP
+
+ vsldoi H2,H2_t,H2_t,8
+ vsldoi H2h,H2,zero,8
+ vsldoi H2l,zero,H2,8
+
+ # --- calculate [H^2.Hi⊕H^2.Lo:H^1.Hi⊕H^1.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store H,[H^2.Hi⊕H^2.Lo:H^1.Hi⊕H^1.Lo] ---
+
+ li    8,0x00
+ li    9,0x100
+ li    10,0x200
+ stxvd2x HlX,8,TABLE
+ stxvd2x HX,9,TABLE
+ stxvd2x HhX,10,TABLE
+
+ li    8,0x300
+ li    9,0x400
+ li    10,0x500
+ stxvd2x H_HhX,8,TABLE
+ stxvd2x H_HX,9,TABLE
+ stxvd2x H_HlX,10,TABLE
+
+ # --- calculate H^3,H^4 ---
+
+ # polynomial multiplication "classical"
+ vpmsumd H_l,H_t,H2l # H^1l*H^2l
+ vpmsumd H_m,H_t,H2 # H^1h*H^2l⊕H^1l*H^2h
+ vpmsumd H_h,H_t,H2h # H^1h*H^2h
+ vpmsumd H2_l,H2_t,H2l # H^2l*H^2l
+ vpmsumd H2_m,H2_t,H2 # H^2h*H^2l⊕H^2l*H^2h
+ vpmsumd H2_h,H2_t,H2h # H^2h*H^2h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h # [1] H^3
+ vpmsumd    RP2,H2_l,poly_h # [1] H^4
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8 # [2] H^3
+ vsldoi M2h,zero,H2_m,8 # [2] H^4
+ vsldoi Ml,H_m,zero,8 # [2] H^3
+ vsldoi M2l,H2_m,zero,8 # [2] H^4
+ vsldoi RP,RP,RP,8 # [1] H^3
+ vsldoi RP2,RP2,RP2,8 # [1] H^4
+ vxor H_h,H_h,Mh # [2] H^3
+ vxor H2_h,H2_h,M2h # [2] H^4
+ vxor H_l,H_l,Ml # [2] H^3
+ vxor H2_l,H2_l,M2l # [2] H^4
+ vxor H_l,H_l,RP # [1] H^3
+ vxor H2_l,H2_l,RP2 # [1] H^4
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l # H^3
+ vpmsumd RP2,H2_l,poly_l # H^4
+ vxor H_h,H_l,H_h # H^3
+ vxor H2_h,H2_l,H2_h # H^4
+ vxor H_h,H_h,RP # H^3
+ vxor H2_h,H2_h,RP2 # H^4
+
+ vsldoi H2,H2_h,H2_h,8 # H^4
+ vsldoi H,H_h,H_h,8 # H^3
+ vsldoi H2l,zero,H2,8 # H^4
+ vsldoi H2h,H2,zero,8 # H^4
+
+ # --- calculate [H^4.Hi⊕H^4.Lo:H^3.Hi⊕H^3.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store [H^4.Hi⊕H^4.Lo:H^3.Hi⊕H^3.Lo] ---
+
+ li    8,0x600
+ li    9,0x700
+ li    10,0x800
+ stxvd2x H_HhX,8,TABLE
+ stxvd2x H_HX,9,TABLE
+ stxvd2x H_HlX,10,TABLE
+
+ # --- calculate H^5,H^6 ---
+
+ # polynomial multiplication "classical"
+ vpmsumd H_l,H_t,H2l # H^1l*H^4l
+ vpmsumd H_m,H_t,H2 # H^1h*H^4l⊕H^1l*H^4h
+ vpmsumd H_h,H_t,H2h # H^1h*H^4h
+ vpmsumd H2_l,H2_t,H2l # H^2l*H^4l
+ vpmsumd H2_m,H2_t,H2 # H^2h*H^4l⊕H^2l*H^4h
+ vpmsumd H2_h,H2_t,H2h # H^2h*H^4h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h # [1] H^5
+ vpmsumd    RP2,H2_l,poly_h # [1] H^6
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8 # [2] H^5
+ vsldoi M2h,zero,H2_m,8 # [2] H^6
+ vsldoi Ml,H_m,zero,8 # [2] H^5
+ vsldoi M2l,H2_m,zero,8 # [2] H^6
+ vsldoi RP,RP,RP,8 # [1] H^5
+ vsldoi RP2,RP2,RP2,8 # [1] H^6
+ vxor H_h,H_h,Mh # [2] H^5
+ vxor H2_h,H2_h,M2h # [2] H^6
+ vxor H_l,H_l,Ml # [2] H^5
+ vxor H2_l,H2_l,M2l # [2] H^6
+ vxor H_l,H_l,RP # [1] H^5
+ vxor H2_l,H2_l,RP2 # [1] H^6
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l # H^5
+ vpmsumd RP2,H2_l,poly_l # H^6
+ vxor H_h,H_l,H_h # H^5
+ vxor H2_h,H2_l,H2_h # H^6
+ vxor H_h,H_h,RP # H^5
+ vxor H2_h,H2_h,RP2 # H^6
+
+ vsldoi H2,H2_h,H2_h,8 # H^6
+ vsldoi H,H_h,H_h,8 # H^5
+ vsldoi H2l,zero,H2,8 # H^6
+ vsldoi H2h,H2,zero,8 # H^6
+
+ # --- calculate [H^6.Hi⊕H^6.Lo:H^5.Hi⊕H^5.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store [H^6.Hi⊕H^6.Lo:H^5.Hi⊕H^5.Lo] ---
+
+ li    8,0x900
+ li    9,0xA00
+ li    10,0xB00
+ stxvd2x H_HhX,8,TABLE
+ stxvd2x H_HX,9,TABLE
+ stxvd2x H_HlX,10,TABLE
+
+ # --- calculate H^7,H^8 ---
+
+ # polynomial multiplication "classical"
+ vpmsumd H_l,H_t,H2l # H^1l*H^6l
+ vpmsumd H_m,H_t,H2 # H^1h*H^6l⊕H^1l*H^6h
+ vpmsumd H_h,H_t,H2h # H^1h*H^6h
+ vpmsumd H2_l,H2_t,H2l # H^2l*H^6l
+ vpmsumd H2_m,H2_t,H2 # H^2h*H^6l⊕H^2l*H^6h
+ vpmsumd H2_h,H2_t,H2h # H^2h*H^6h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h # [1] H^7
+ vpmsumd    RP2,H2_l,poly_h # [1] H^8
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8 # [2] H^7
+ vsldoi M2h,zero,H2_m,8 # [2] H^8
+ vsldoi Ml,H_m,zero,8 # [2] H^7
+ vsldoi M2l,H2_m,zero,8 # [2] H^8
+ vsldoi RP,RP,RP,8 # [1] H^7
+ vsldoi RP2,RP2,RP2,8 # [1] H^8
+ vxor H_h,H_h,Mh # [2] H^7
+ vxor H2_h,H2_h,M2h # [2] H^8
+ vxor H_l,H_l,Ml # [2] H^7
+ vxor H2_l,H2_l,M2l # [2] H^8
+ vxor H_l,H_l,RP # [1] H^7
+ vxor H2_l,H2_l,RP2 # [1] H^8
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l # H^7
+ vpmsumd RP2,H2_l,poly_l # H^8
+ vxor H_h,H_l,H_h # H^7
+ vxor H2_h,H2_l,H2_h # H^8
+ vxor H_h,H_h,RP # H^7
+ vxor H2_h,H2_h,RP2 # H^8
+
+ vsldoi H,H_h,H_h,8 # H^7
+ vsldoi H2,H2_h,H2_h,8 # H^8
+
+ # --- calculate [H^8.Hi⊕H^8.Lo:H^7.Hi⊕H^7.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store [H^8.Hi⊕H^8.Lo:H^7.Hi⊕H^7.Lo] ---
+
+ li    8,0xC00
+ li    9,0xD00
+ li    10,0xE00
+ stxvd2x H_HhX,8,TABLE
+ stxvd2x H_HX,9,TABLE
+ stxvd2x H_HlX,10,TABLE
+
+    blr
+EPILOGUE(_nettle_gcm_init_key8)
+
+ # void gcm_hash (const struct gcm_key *key, union gcm_block *x,
+ #                size_t length, const uint8_t *data)
+
+.align 5
+PROLOGUE(_nettle_gcm_hash8)
+    vxor zero,zero,zero
+
+ ld     7,.polynomial@got(TOCP)
+ lvx   poly,0,7
+ ld     7,.swap_mask@got(TOCP)
+ lvx   swap_mask,0,7
+ ld      7,.hidw_mask@got(TOCP)
+ lvx     hidw_mask,0,7
+ ld     7,.lodw_mask@got(TOCP)
+ lvx   lodw_mask,0,7
+
+ vsldoi poly_h,zero,poly,8
+ vsldoi poly_l,poly_h,poly_h,8
+
+ lxvd2x CX,0,X # load X
+ vperm C,C,C,swap_mask
+
+ srdi 7,LENGTH,7 # 8x loop count
+ cmpldi 7,0
+ beq L2x
+
+ # backup registers
+ stdu SP,-224(SP)
+ std 28,216(SP)
+ std 29,208(SP)
+ std 30,200(SP)
+ std 31,192(SP)
+    li 8,176
+    stvx 20,8,SP
+    subi 8,8,16
+    stvx 21,8,SP
+    subi 8,8,16
+    stvx 22,8,SP
+    subi 8,8,16
+    stvx 23,8,SP
+    subi 8,8,16
+    stvx 24,8,SP
+    subi 8,8,16
+    stvx 25,8,SP
+    subi 8,8,16
+    stvx 26,8,SP
+    subi 8,8,16
+    stvx 27,8,SP
+    subi 8,8,16
+    stvx 28,8,SP
+    subi 8,8,16
+    stvx 29,8,SP
+    subi 8,8,16
+    stvx 30,8,SP
+    subi 8,8,16
+    stvx 31,8,SP
+
+ # table loading
+ li 8,0x300
+ li 9,0x400
+ li 10,0x500
+ lxvd2x H21hX,8,TABLE
+ lxvd2x H21X,9,TABLE
+ lxvd2x H21lX,10,TABLE
+ li 8,0x600
+ li 9,0x700
+ li 10,0x800
+ lxvd2x H43hX,8,TABLE
+ lxvd2x H43X,9,TABLE
+ lxvd2x H43lX,10,TABLE
+ li 8,0x900
+ li 9,0xA00
+ li 10,0xB00
+ lxvd2x H65hX,8,TABLE
+ lxvd2x H65X,9,TABLE
+ lxvd2x H65lX,10,TABLE
+ li 8,0xC00
+ li 9,0xD00
+ li 10,0xE00
+ lxvd2x H87hX,8,TABLE
+ lxvd2x H87X,9,TABLE
+ lxvd2x H87lX,10,TABLE
+
+ li 8,0x10
+ li 9,0x20
+ li 10,0x30
+ li 28,0x40
+ li 29,0x50
+ li 30,0x60
+ li 31,0x70
+
+ mtctr     7
+.align 5
+L8x_loop:
+ # input loading
+ lxvd2x C0X,0,DATA # load C0
+ lxvd2x C1X,8,DATA # load C1
+ lxvd2x C2X,9,DATA # load C2
+ lxvd2x C3X,10,DATA # load C3
+
+ # swap permuting
+ vperm C0,C0,C0,swap_mask
+ vperm C1,C1,C1,swap_mask
+ vperm C2,C2,C2,swap_mask
+ vperm C3,C3,C3,swap_mask
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ # polynomial multiplication "karatsuba" pre-processing
+ vperm C23h,C2,C3,hidw_mask
+ vperm C23l,C2,C3,lodw_mask
+ vperm C01h,C0,C1,hidw_mask
+ vperm C01l,C0,C1,lodw_mask
+
+ # input loading
+ lxvd2x C4X,28,DATA # load C4
+ lxvd2x C5X,29,DATA # load C5
+ lxvd2x C6X,30,DATA # load C6
+ lxvd2x C7X,31,DATA # load C7
+
+ # swap permuting
+ vperm C4,C4,C4,swap_mask
+ vperm C5,C5,C5,swap_mask
+ vperm C6,C6,C6,swap_mask
+ vperm C7,C7,C7,swap_mask
+
+ # polynomial multiplication "karatsuba" pre-processing
+ vperm C45h,C4,C5,hidw_mask
+ vperm C45l,C4,C5,lodw_mask
+ vperm C67h,C6,C7,hidw_mask
+ vperm C67l,C6,C7,lodw_mask
+ vxor C23,C23h,C23l
+ vxor C01,C01h,C01l
+ vxor C45,C45h,C45l
+ vxor C67,C67h,C67l
+
+ # polynomial multiplication "karatsuba"
+ vpmsumd C23h,C23h,H65h # H23 = H^6h*C2h⊕H^5h*C3h
+ vpmsumd C23l,C23l,H65l # L23 = H^6l*C2l⊕H^5l*C3l
+ vpmsumd C01h,C01h,H87h # H01 = H^8h*C0h⊕H^7h*C1h
+ vpmsumd C01l,C01l,H87l # L01 = H^8l*C0l⊕H^7l*C1l
+ vpmsumd C67h,C67h,H21h # H67 = H^2h*C6h⊕H^1h*C7h
+ vpmsumd C67l,C67l,H21l # L67 = H^2l*C6l⊕H^1l*C7l
+ vpmsumd C45h,C45h,H43h # H45 = H^4h*C4h⊕H^3h*C5h
+ vpmsumd C45l,C45l,H43l # L45 = H^4l*C4l⊕H^3l*C5l
+ vpmsumd C23,C23,H65 # M23 = (H^6h⊕H^5h)*(C2h⊕C3h)⊕(H^6l⊕H^5l)*(C2l⊕C3l)
+ vpmsumd C01,C01,H87 # M01 = (H^8h⊕H^7h)*(C0h⊕C1h)⊕(H^8l⊕H^7l)*(C0l⊕C1l)
+ vpmsumd C45,C45,H43 # M45 = (H^4h⊕H^3h)*(C4h⊕C5h)⊕(H^4l⊕H^3l)*(C4l⊕C5l)
+ vpmsumd C67,C67,H21 # M67 = (H^2h⊕H^1h)*(C6h⊕C7h)⊕(H^2l⊕H^1l)*(C6l⊕C7l)
+
+ # polynomial multiplication "karatsuba" post-processing
+ vxor C23,C23,C23h
+ vxor C01,C01,C01h
+ vxor C45,C45,C45h
+ vxor C67,C67,C67h
+ vxor C23,C23,C23l
+ vxor C01,C01,C01l
+ vxor C45,C45,C45l
+ vxor C67,C67,C67l
+
+ # deferred recombination of partial products
+ vxor C01h,C01h,C23h # H0 = H01⊕H23
+ vxor C45h,C45h,C67h # H1 = H45⊕H67
+ vxor C01l,C01l,C23l # L0 = L01⊕L23
+ vxor C45l,C45l,C67l # L1 = L45⊕L45
+ vxor C01,C01,C23 # M0 = M01⊕M23
+ vxor C45,C45,C67 # M1 = M45⊕M45
+ vxor C01h,C01h,C45h # H = H0⊕H1
+ vxor C01l,C01l,C45l # L = L0⊕L1
+ vxor C01,C01,C45 # M = M0⊕M1
+
+ # reduction first phase # [1]
+ vpmsumd RP,C01l,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,C01,8   # [2]
+ vsldoi Ml,C01,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor C01h,C01h,Mh     # [2]
+ vxor C01l,C01l,Ml     # [2]
+ vxor C01l,C01l,RP     # [1]
+
+ # reduction second phase
+ vpmsumd RP,C01l,poly_l
+ vxor C01h,C01l,C01h
+ vxor C,C01h,RP
+
+ addi DATA,DATA,0x80
+ bdnz L8x_loop
+
+    # restore registers
+ li 8,0
+    lvx 31,8,SP
+    addi 8,8,16
+    lvx 30,8,SP
+    addi 8,8,16
+    lvx 29,8,SP
+    addi 8,8,16
+    lvx 28,8,SP
+    addi 8,8,16
+    lvx 27,8,SP
+    addi 8,8,16
+    lvx 26,8,SP
+    addi 8,8,16
+    lvx 25,8,SP
+    addi 8,8,16
+    lvx 24,8,SP
+    addi 8,8,16
+    lvx 23,8,SP
+    addi 8,8,16
+    lvx 22,8,SP
+    addi 8,8,16
+    lvx 21,8,SP
+    addi 8,8,16
+    lvx 20,8,SP
+ ld 31,192(SP)
+ ld 30,200(SP)
+ ld 29,208(SP)
+ ld 28,216(SP)
+ addi SP,SP,224
+
+ clrldi   LENGTH,LENGTH,57
+L2x:
+ srdi 7,LENGTH,5
+ cmpldi 7,0
+ beq L1x
+
+ # table loading
+ li 8,0x300
+ li 9,0x400
+ li 10,0x500
+ lxvd2x H21hX,8,TABLE
+ lxvd2x H21X,9,TABLE
+ lxvd2x H21lX,10,TABLE
+
+ li 10,0x10
+
+ mtctr     7
+.align 5
+L2x_loop:
+ # input loading
+ lxvd2x C0X,0,DATA # load C0
+ lxvd2x C1X,10,DATA # load C1
+
+ # swap permuting
+ vperm C0,C0,C0,swap_mask
+ vperm C1,C1,C1,swap_mask
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ # polynomial multiplication "karatsuba" pre-processing
+ vperm C01h,C0,C1,hidw_mask
+ vperm C01l,C0,C1,lodw_mask
+ vxor C01,C01h,C01l
+
+ # polynomial multiplication "karatsuba"
+ vpmsumd C01h,C01h,H21h # H01 = H^2h*C0h⊕H^1h*C1h
+ vpmsumd C01l,C01l,H21l # L01 = H^2l*C0l⊕H^1l*C1l
+ vpmsumd C01,C01,H21 # M01 = (H^2h⊕H^1h)*(C0h⊕C1h)⊕(H^2l⊕H^1l)*(C0l⊕C1l)
+
+ # polynomial multiplication "karatsuba" post-processing
+ vxor C01,C01,C01h
+ vxor C01,C01,C01l
+
+ # reduction first phase # [1]
+ vpmsumd RP,C01l,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,C01,8   # [2]
+ vsldoi Ml,C01,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor C01h,C01h,Mh     # [2]
+ vxor C01l,C01l,Ml     # [2]
+ vxor C01l,C01l,RP     # [1]
+
+ # reduction second phase
+ vpmsumd RP,C01l,poly_l
+ vxor C01h,C01l,C01h
+ vxor C,C01h,RP
+
+ addi DATA,DATA,0x20
+ bdnz L2x_loop
+
+ clrldi   LENGTH,LENGTH,59
+L1x:
+ srdi 7,LENGTH,4
+ cmpldi 7,0
+ beq Lrem
+
+ # table loading
+ li 9,0x100
+ li 10,0x200
+ lxvd2x HlX,0,TABLE
+ lxvd2x HX, 9,TABLE
+ lxvd2x HhX,10,TABLE
+
+ # input loading
+ lxvd2x C0X,0,DATA # load C0
+
+ # swap permuting
+ vperm C0,C0,C0,swap_mask
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ vpmsumd Cl,C0,Hl # L = Hl*Cl
+ vpmsumd Cm,C0,H # M = Hh*Cl⊕Hl*Ch
+ vpmsumd Ch,C0,Hh # H = Hh*Ch
+
+ # reduction first phase # [1]
+ vpmsumd RP,Cl,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,Cm,8   # [2]
+ vsldoi Ml,Cm,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor Ch,Ch,Mh   # [2]
+ vxor Cl,Cl,Ml       # [2]
+ vxor Cl,Cl,RP   # [1]
+
+ # reduction second phase
+ vpmsumd RP,Cl,poly_l
+ vxor Ch,Cl,Ch
+ vxor C,Ch,RP
+
+ addi DATA,DATA,0x10
+ clrldi   LENGTH,LENGTH,60
+Lrem:
+ cmpldi LENGTH,0
+ beq Ldone
+
+ # table loading
+ li 9,0x100
+ li 10,0x200
+ lxvd2x HlX,0,TABLE
+ lxvd2x HX, 9,TABLE
+ lxvd2x HhX,10,TABLE
+
+ # input loading
+ stdu SP,-16(SP)
+ stvx zero,0,SP
+Lst_loop:
+ subic.      LENGTH,LENGTH,1
+ lbzx 7,LENGTH,DATA
+ stbx 7,LENGTH,SP
+ bne Lst_loop
+ lxvd2x   C0X,0,SP
+ addi SP,SP,16
+
+ # swap permuting
+ vperm C0,C0,C0,swap_mask
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ vpmsumd Cl,C0,Hl # L = Hl*Cl
+ vpmsumd Cm,C0,H # M = Hh*Cl⊕Hl*Ch
+ vpmsumd Ch,C0,Hh # H = Hh*Ch
+
+ # reduction first phase # [1]
+ vpmsumd RP,Cl,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,Cm,8   # [2]
+ vsldoi Ml,Cm,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor Ch,Ch,Mh   # [2]
+ vxor Cl,Cl,Ml     # [2]
+ vxor Cl,Cl,RP   # [1]
+
+ # reduction second phase
+ vpmsumd RP,Cl,poly_l
+ vxor Ch,Cl,Ch
+ vxor C,Ch,RP
+
+Ldone:
+ vperm C,C,C,swap_mask
+ stxvd2x CX,0,X # store C
+ blr
+EPILOGUE(_nettle_gcm_hash8)
+
+ # gcm_fill (uint8_t *ctr, size_t blocks, union gcm_block *buffer)
+
+.align 5
+PROLOGUE(_nettle_gcm_fill)
+  ld     6,.swap_mask@got(TOCP)
+  lvx   swap_mask,0,6
+
+  vxor zero,zero,zero
+  vspltisb I1,1
+  vspltisb I2,2
+  vspltisb I3,3
+  vspltisb I4,4
+  vspltisb I5,5
+  vspltisb I6,6
+  vspltisb I7,7
+  vspltisb I8,8
+  vsldoi I1,zero,I1,1
+  vsldoi I2,zero,I2,1
+  vsldoi I3,zero,I3,1
+  vsldoi I4,zero,I4,1
+  vsldoi I5,zero,I5,1
+  vsldoi I6,zero,I6,1
+  vsldoi I7,zero,I7,1
+  vsldoi I8,zero,I8,1
+
+  lxvd2x CTR0X,0,CTR
+  vperm CTR0,CTR0,CTR0,swap_mask
+
+  srdi      6,BLOCKS,3              # 8x loop count
+  cmpldi 6,0
+  beq       Lfill_4x
+
+  std       25,-56(SP);
+  std       26,-48(SP);
+  std       27,-40(SP);
+  std       28,-32(SP);
+  std       29,-24(SP);
+  std       30,-16(SP);
+  std       31,-8(SP);
+
+  li        25,0x10
+  li        26,0x20
+  li        27,0x30
+  li        28,0x40
+  li        29,0x50
+  li        30,0x60
+  li        31,0x70
+
+  mtctr     6
+L8x_fill_loop:
+  vadduwm CTR1,CTR0,I1
+  vadduwm CTR2,CTR0,I2
+  vadduwm CTR3,CTR0,I3
+  vadduwm CTR4,CTR0,I4
+  vadduwm CTR5,CTR0,I5
+  vadduwm CTR6,CTR0,I6
+  vadduwm CTR7,CTR0,I7
+
+  vperm CTR0S,CTR0,CTR0,swap_mask
+  vperm CTR1,CTR1,CTR1,swap_mask
+  vperm CTR2,CTR2,CTR2,swap_mask
+  vperm CTR3,CTR3,CTR3,swap_mask
+  vperm CTR4,CTR4,CTR4,swap_mask
+  vperm CTR5,CTR5,CTR5,swap_mask
+  vperm CTR6,CTR6,CTR6,swap_mask
+  vperm CTR7,CTR7,CTR7,swap_mask
+
+  stxvd2x CTR0SX,0,BUFFER
+  stxvd2x CTR1X,25,BUFFER
+  stxvd2x CTR2X,26,BUFFER
+  stxvd2x CTR3X,27,BUFFER
+  stxvd2x CTR4X,28,BUFFER
+  stxvd2x CTR5X,29,BUFFER
+  stxvd2x CTR6X,30,BUFFER
+  stxvd2x CTR7X,31,BUFFER
+
+  vadduwm CTR0,CTR0,I8
+  addi BUFFER,BUFFER,0x80
+  bdnz      L8x_fill_loop
+
+  ld        25,-56(SP);
+  ld        26,-48(SP);
+  ld        27,-40(SP);
+  ld        28,-32(SP);
+  ld        29,-24(SP);
+  ld        30,-16(SP);
+  ld        31,-8(SP);
+
+  clrldi   BLOCKS,BLOCKS,61
+
+Lfill_4x:
+  srdi      6,BLOCKS,2
+  cmpldi 6,0
+  beq       Lfill_2x
+
+  li        8,0x10
+  li        9,0x20
+  li        10,0x30
+
+  vadduwm CTR1,CTR0,I1
+  vadduwm CTR2,CTR0,I2
+  vadduwm CTR3,CTR0,I3
+
+  vperm CTR0S,CTR0,CTR0,swap_mask
+  vperm CTR1,CTR1,CTR1,swap_mask
+  vperm CTR2,CTR2,CTR2,swap_mask
+  vperm CTR3,CTR3,CTR3,swap_mask
+
+  stxvd2x CTR0SX,0,BUFFER
+  stxvd2x CTR1X,8,BUFFER
+  stxvd2x CTR2X,9,BUFFER
+  stxvd2x CTR3X,10,BUFFER
+
+  vadduwm CTR0,CTR0,I4
+  addi BUFFER,BUFFER,0x40
+
+  clrldi   BLOCKS,BLOCKS,62
+
+Lfill_2x:
+  srdi      6,BLOCKS,1
+  cmpldi 6,0
+  beq       Lfill_1x
+
+  li        10,0x10
+
+  vadduwm CTR1,CTR0,I1
+
+  vperm CTR0S,CTR0,CTR0,swap_mask
+  vperm CTR1,CTR1,CTR1,swap_mask
+
+  stxvd2x CTR0SX,0,BUFFER
+  stxvd2x CTR1X,10,BUFFER
+
+  vadduwm CTR0,CTR0,I2
+  addi BUFFER,BUFFER,0x20
+
+  clrldi   BLOCKS,BLOCKS,63
+
+Lfill_1x:
+  cmpldi BLOCKS,0
+  beq       Lfill_done
+
+  vperm CTR0S,CTR0,CTR0,swap_mask
+
+  stxvd2x CTR0SX,0,BUFFER
+
+  vadduwm CTR0,CTR0,I1
+
+Lfill_done:
+  vperm CTR0,CTR0,CTR0,swap_mask
+  stxvd2x CTR0X,0,CTR
+
+  blr
+EPILOGUE(_nettle_gcm_fill)
+
+    .data
+    .align 4
+.polynomial:
+ .byte 1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0xc2
+    .align 4
+.swap_mask:
+ .byte 8,9,10,11,12,13,14,15,0,1,2,3,4,5,6,7
+    .align 4
+.hidw_mask:
+ .byte 23,22,21,20,19,18,17,16,7,6,5,4,3,2,1,0
+    .align 4
+.lodw_mask:
+ .byte 31,30,29,28,27,26,25,24,15,14,13,12,11,10,9,8
diff --git a/powerpc64le/machine.m4 b/powerpc64le/machine.m4
new file mode 100644
index 00000000..e69de29b
diff --git a/testsuite/gcm-test.c b/testsuite/gcm-test.c
index c8174019..df1fc94a 100644
--- a/testsuite/gcm-test.c
+++ b/testsuite/gcm-test.c
@@ -170,6 +170,29 @@ test_main(void)
  "16aedbf5a0de6a57a637b39b"),
     SHEX("619cc5aefffe0bfa462af43c1699d050"));

+  /* Test 128 bytes */
+  test_aead(&amp;nettle_gcm_aes128, NULL,
+    SHEX("feffe9928665731c6d6a8f9467308308"),
+    SHEX(""),
+    SHEX("d9313225f88406e5a55909c5aff5269a"
+ "86a7a9531534f7da2e4c303d8a318a72"
+ "1c3c0c95956809532fcf0e2449a6b525"
+ "b16aedf5aa0de657ba637b391aafd255"
+ "5ae376bc5e9f6a1b08e34db7a6ee0736"
+ "9ba662ea12f6f197e6bc3ed69d2480f3"
+ "ea5691347f2ba69113eb37910ebc18c8"
+ "0f697234582016fa956ca8f63ae6b473"),
+    SHEX("42831ec2217774244b7221b784d0d49c"
+ "e3aa212f2c02a4e035c17e2329aca12e"
+ "21d514b25466931c7d8f6a5aac84aa05"
+ "1ba30b396a0aac973d58e091473f5985"
+ "874b1178906ddbeab04ab2fe6cce8c57"
+ "8d7e961bd13fd6a8c56b66ca5e576492"
+ "1a48cd8bda04e66343e73055118b69b9"
+ "ced486813846958a11e602c03cfc232b"),
+    SHEX("cafebabefacedbaddecaf888"),
+    SHEX("796836f1246c9d735c5e1be0a715ccc3"));
+
   /* Test case 7 */
   test_aead(&amp;nettle_gcm_aes192, NULL,
     SHEX("00000000000000000000000000000000"
-- 
2.17.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200619112215</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-06-19 11:22:15-0400</timestampReceived><subject>Post patch on nettle-bugs list</subject><body>

Is there a limit to the number of lines of a message posted on the
list or special
option that should be passed to git diff?
I created a patch with command "git diff --stat --summary --patch HEAD~1 &gt;
patch.patch", when I posted this patch on the list nothing happened.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200606153813</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-06-06 15:38:13-0400</timestampReceived><subject>Re: [PATCH v3] Implement GOST R 34.11-2012 (Streebog) hash function</subject><body>

Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:

&gt; I've sent the fixup. I'm fine with it being squashed into this patch.

Done. I've merged this patch and the test patch to master-updates now.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200618155828</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-06-18 15:58:28-0400</timestampReceived><subject>PPC64LE optimizing AES and GHASH</subject><body>

I added a PowerPC64LE optimized version of AES and GHASH to nettle.
Patch summary:

 GHASH Algorithm

I took the advantage of several references and researches to achieve the
high-speed implementation of this algorithm. These references include
several techniques that have been used to improve the performance of the
algorithm, I will summarize the important techniques used as follows:

   - The main equation: The main equation for 4 block (128-bit each) can be
   seen in reference [1]  Digest = (((((((Digest⊕C0)*H)⊕C1)*H)⊕C2)*H)⊕C3)*H
   = ((Digest⊕C0)*H4)⊕(C1*H3)⊕(C2*H2)⊕(C3*H) to achieve more parallelism,
   this equation can be modified to address 8 blocks per one loop. It looks
   like as follows Digest =
   ((Digest⊕C0)*H8)⊕(C1*H7)⊕(C2*H6)⊕(C3*H5)⊕(C4*H4)⊕(C5*H3)⊕(C6*H2)⊕(C7*H)
                
   - Handling Bit-reflection of the multiplication product [1]: This
   technique moves part of the workload inside the loop to the init function
   so it is executed only once.
   - Karatsuba Algorithm: This algorithm allows to perform three
   multiplication instructions instead of four, in exchange for two additional
   Xor. This technique is well explained with figures in reference [1]
   - Deferred Recombination of partial products This technique is well
   explained with figures in reference [1]
   - Multiplication-based reduction: I tested both classical shift-based
   reduction and multiplication-based reduction, the multiplication-based
   reduction achieved better performance and less instructions. Example of
   both reductions can be seen in reference [2]

 AES
   Power ISA makes it easy to optimize AES by offering built-in AES
instructions.

AES-GCM performance (Tested on POWER9):

   - GCM_AES Encrypt ~x13.5 of nettle C implementation
   - GCM_AES Decrypt ~x13.5 of nettle C implementation
   - GCM_AES Update (Only GHASH is called) ~x26 of nettle C implementation

Notes:

   - Test 128 bytes is added to gcm-test in testsuite to test 8x loop in
   GHASH optimized function.
   - Since the functionality of gcm_set_key() is replaced with
   gcm_init_key() for PowerPC64LE, two warnings will pop up: [‘gcm_gf_shift'
   defined but not used] and [‘gcm_gf_add' defined but not used]

 References: [1]
https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/communications-ia-galois-counter-mode-paper.pdf
  [2]
https://www.intel.com/content/dam/www/public/us/en/documents/software-support/enabling-high-performance-gcm.pdf
  [3] https://software.intel.com/file/24918 [4]
https://github.com/dot-asm/cryptogams
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200622130450</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-06-22 13:04:50-0400</timestampReceived><subject>Add ppc64le arch to Gitlab CI</subject><body>

I investigated this issue. The Debian image used for Gitlab CI only
supports the following archs amd64 mips armhf arm64. To add a new arch,
this arch should be added to the sources list of apt and install the
required packages to build and check nettle library.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200602104540</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-06-02 10:45:40-0400</timestampReceived><subject>[PATCH v2 8/8] test/gostdsa-vko: add hashed test vectors from RFC 7836</subject><body>

It was not possible to check gostdsa_vko test vectors with the outputs
from RFC 7836 because Nettle lacked Streebog hash function. Now as the
function is supported, add full test vectors.

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 testsuite/gostdsa-vko-test.c | 45 ++++++++++++++++++++++++++++++++++++
 1 file changed, 45 insertions(+)

diff --git a/testsuite/gostdsa-vko-test.c b/testsuite/gostdsa-vko-test.c
index c8a762b125c2..5d65cd4d15d6 100644
--- a/testsuite/gostdsa-vko-test.c
+++ b/testsuite/gostdsa-vko-test.c
@@ -1,5 +1,6 @@
 #include "testutils.h"
 #include "gostdsa.h"
+#include "streebog.h"
 
 static void
 test_vko (const struct ecc_curve *ecc,
@@ -57,6 +58,9 @@ test_vko (const struct ecc_curve *ecc,
 void
 test_main (void)
 {
+    struct streebog256_ctx ctx_256;
+    struct streebog256_ctx ctx_512;
+
     /* RFC 7836, App B, provides test vectors, values there are little endian.
      *
      * However those test vectors depend on the availability of Streebog hash
@@ -88,4 +92,45 @@ test_main (void)
 		  "3b8e53a1ea920eb1 d7f3d08aa9e47595 4a53ac018c210b48 15451b7accc4a797"
 		  "a2b8faf3d89ee717 d07a857794b9b053 f8e0fd5456ccfcc2 2fd081c873416a3f"));
 
+    /* RFC 7836, App B, 7), values there are little endian, calculation for size A \
*/ +    test_vko(nettle_get_gost_gc512a(),
+	     "67b63ca4ac8d2bb32618d89296c7476dbeb9f9048496f202b1902cf2ce41dbc2f847712d960483458d4b380867f426c7ca0ff5782702dbc44ee8fc72d9ec90c9",
 +	     "51a6d54ee932d176e87591121cce5f395cb2f2f147114d95f463c8a7ed74a9fc5ecd2325a35fb6387831ea66bc3d2aa42ede35872cc75372073a71b983e12f19",
 +	     "793bde5bf72840ad22b02a363ae4772d4a52fc08ba1a20f7458a222a13bf98b53be002d1973f1e398ce46c17da6d00d9b6d0076f8284dcc42e599b4c413b8804",
 +	     SHEX("1d 80 60 3c 85 44 c7 27"),
+	     &amp;nettle_streebog256,
+	     &amp;ctx_256,
+	     SHEX("c9 a9 a7 73 20 e2 cc 55 9e d7 2d ce 6f 47 e2 19 2c ce a9 5f a6 48 67 05 \
82 c0 54 c0 ef 36 c2 21")); +
+    /* RFC 7836, App B, 7), values there are little endian, calculation for size B \
*/ +    test_vko(nettle_get_gost_gc512a(),
+	     "dbd09213a592da5bbfd8ed068cccccbbfbeda4feac96b9b4908591440b0714803b9eb763ef932266d4c0181a9b73eacf9013efc65ec07c888515f1b6f759c848",
 +	     "a7c0adb12743c10c3c1beb97c8f631242f7937a1deb6bce5e664e49261baccd3f5dc56ec53b2abb90ca1eb703078ba546655a8b99f79188d2021ffaba4edb0aa",
 +	     "5adb1c63a4e4465e0bbefd897fb9016475934cfa0f8c95f992ea402d47921f46382d00481b720314b19d8c878e75d81b9763358dd304b2ed3a364e07a3134691",
 +	     SHEX("1d 80 60 3c 85 44 c7 27"),
+	     &amp;nettle_streebog256,
+	     &amp;ctx_256,
+	     SHEX("c9 a9 a7 73 20 e2 cc 55 9e d7 2d ce 6f 47 e2 19 2c ce a9 5f a6 48 67 05 \
82 c0 54 c0 ef 36 c2 21")); +
+    /* RFC 7836, App B, 8), values there are little endian, calculation for size A \
*/ +    test_vko(nettle_get_gost_gc512a(),
+	     "67b63ca4ac8d2bb32618d89296c7476dbeb9f9048496f202b1902cf2ce41dbc2f847712d960483458d4b380867f426c7ca0ff5782702dbc44ee8fc72d9ec90c9",
 +	     "51a6d54ee932d176e87591121cce5f395cb2f2f147114d95f463c8a7ed74a9fc5ecd2325a35fb6387831ea66bc3d2aa42ede35872cc75372073a71b983e12f19",
 +	     "793bde5bf72840ad22b02a363ae4772d4a52fc08ba1a20f7458a222a13bf98b53be002d1973f1e398ce46c17da6d00d9b6d0076f8284dcc42e599b4c413b8804",
 +	     SHEX("1d 80 60 3c 85 44 c7 27"),
+	     &amp;nettle_streebog512,
+	     &amp;ctx_512,
+	     SHEX("79 f0 02 a9 69 40 ce 7b de 32 59 a5 2e 01 52 97 ad aa d8 45 97 a0 d2 05 \
b5 0e 3e 17 19 f9 7b fa" +		  "7e e1 d2 66 1f a9 97 9a 5a a2 35 b5 58 a7 e6 d9 f8 8f \
98 2d d6 3f c3 5a 8e c0 dd 5e 24 2d 3b df")); +
+    /* RFC 7836, App B, 8), values there are little endian, calculation for size B \
*/ +    test_vko(nettle_get_gost_gc512a(),
+	     "dbd09213a592da5bbfd8ed068cccccbbfbeda4feac96b9b4908591440b0714803b9eb763ef932266d4c0181a9b73eacf9013efc65ec07c888515f1b6f759c848",
 +	     "a7c0adb12743c10c3c1beb97c8f631242f7937a1deb6bce5e664e49261baccd3f5dc56ec53b2abb90ca1eb703078ba546655a8b99f79188d2021ffaba4edb0aa",
 +	     "5adb1c63a4e4465e0bbefd897fb9016475934cfa0f8c95f992ea402d47921f46382d00481b720314b19d8c878e75d81b9763358dd304b2ed3a364e07a3134691",
 +	     SHEX("1d 80 60 3c 85 44 c7 27"),
+	     &amp;nettle_streebog512,
+	     &amp;ctx_512,
+	     SHEX("79 f0 02 a9 69 40 ce 7b de 32 59 a5 2e 01 52 97 ad aa d8 45 97 a0 d2 05 \
b5 0e 3e 17 19 f9 7b fa" +		  "7e e1 d2 66 1f a9 97 9a 5a a2 35 b5 58 a7 e6 d9 f8 8f \
98 2d d6 3f c3 5a 8e c0 dd 5e 24 2d 3b df"));  }
-- 
2.26.2

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200602104535</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-06-02 10:45:35-0400</timestampReceived><subject>[PATCH v2 3/8] nettle.texinfo: add documentation for Streebog hash function</subject><body>

Add documentation describing Streebog hash function and it's API.

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 nettle.texinfo | 72 ++++++++++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 72 insertions(+)

diff --git a/nettle.texinfo b/nettle.texinfo
index 995d5de80813..2425b4f9d331 100644
--- a/nettle.texinfo
+++ b/nettle.texinfo
@@ -857,6 +857,78 @@ to @var{digest}. @var{length} can be of arbitrary size.
 This function also resets the context.
 @end deftypefun
 
+@subsubsection @acronym{STREEBOG512}
+
+STREEBOG512 is a member of the Streebog (GOST R 34.11-2012) family.  It outputs
+hash values of 512 bits, or 64 octets. Nettle defines STREEBOG512 in
+@file{&lt;nettle/streebog.h&gt;}.
+
+@deftp {Context struct} {struct streebog512_ctx}
+@end deftp
+
+@defvr Constant STREEBOG512_DIGEST_SIZE
+The size of a STREEBOG512 digest, i.e. 64.
+@end defvr
+
+@defvr Constant STREEBOG512_BLOCK_SIZE
+The internal block size of STREEBOG512. Useful for some special constructions,
+in particular HMAC-STREEBOG512.
+@end defvr
+
+@deftypefun void streebog512_init (struct streebog512_ctx *@var{ctx})
+Initialize the STREEBOG512 state.
+@end deftypefun
+
+@deftypefun void streebog512_update (struct streebog512_ctx *@var{ctx}, size_t \
@var{length}, const uint8_t *@var{data}) +Hash some more data.
+@end deftypefun
+
+@deftypefun void streebog512_digest (struct streebog512_ctx *@var{ctx}, size_t \
@var{length}, uint8_t *@var{digest}) +Performs final processing and extracts the \
message digest, writing it +to @var{digest}. @var{length} may be smaller than
+@code{STREEBOG512_DIGEST_SIZE}, in which case only the first @var{length}
+octets of the digest are written.
+
+This function also resets the context in the same way as
+@code{streebog512_init}.
+@end deftypefun
+
+@subsubsection @acronym{STREEBOG256}
+
+STREEBOG256 is a variant of STREEBOG512, with a different initial state, and with
+the output truncated to 256 bits, or 32 octets. Nettle defines STREEBOG256 in
+@file{&lt;nettle/streebog.h&gt;}.
+
+@deftp {Context struct} {struct streebog256_ctx}
+@end deftp
+
+@defvr Constant STREEBOG256_DIGEST_SIZE
+The size of a STREEBOG256 digest, i.e. 32.
+@end defvr
+
+@defvr Constant STREEBOG256_BLOCK_SIZE
+The internal block size of STREEBOG256. Useful for some special constructions,
+in particular HMAC-STREEBOG256.
+@end defvr
+
+@deftypefun void streebog256_init (struct streebog256_ctx *@var{ctx})
+Initialize the STREEBOG256 state.
+@end deftypefun
+
+@deftypefun void streebog256_update (struct streebog256_ctx *@var{ctx}, size_t \
@var{length}, const uint8_t *@var{data}) +Hash some more data.
+@end deftypefun
+
+@deftypefun void streebog256_digest (struct streebog256_ctx *@var{ctx}, size_t \
@var{length}, uint8_t *@var{digest}) +Performs final processing and extracts the \
message digest, writing it +to @var{digest}. @var{length} may be smaller than
+@code{STREEBOG256_DIGEST_SIZE}, in which case only the first @var{length}
+octets of the digest are written.
+
+This function also resets the context in the same way as
+@code{streebog256_init}.
+@end deftypefun
+
 @node Legacy hash functions, nettle_hash abstraction, Recommended hash functions, \
Hash functions  @comment  node-name,  next,  previous,  up
 @subsection Legacy hash functions
-- 
2.26.2

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200624000040</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-06-24 00:00:40-0400</timestampReceived><subject>[PATCH] Add ppc64 and ppc64el to Gitlab CI</subject><body>

To run tests on ppc64 and ppc64el, this patch install cross building
packages for both architectures on the Debian image, these packages will be
install every time the CI triggered. A proper fix would be to install these
packages to the image directly.
This patch follows a different approach to get access LD shared library for
qemu. Other architectures install native libc6 packages while both ppc64
and ppc64el install cross libc6 packages and export QEMU_LD_PREFIX to point
to LD path which is more reasonable.

 .gitlab-ci.yml | 9 +++++++++
 1 file changed, 9 insertions(+)

diff --git a/.gitlab-ci.yml b/.gitlab-ci.yml
index 9f3b5c63..7f12ecfa 100644
--- a/.gitlab-ci.yml
+++ b/.gitlab-ci.yml
@@ -139,6 +139,11 @@ Debian.cross.x86:
   before_script:
   # remove any previously installed nettle headers to avoid conflicts
   - for arch in armhf mips arm64;do apt-get remove -y nettle-dev:$arch;done
+  - host="${CI_JOB_NAME#*.cross.}"
+  - if [ "$host" == "powerpc64-linux-gnu" ];then apt-get update &amp;&amp; apt-get
install -y gcc-$host &amp;&amp;
+    apt-get install -y g++-$host &amp;&amp; apt-get install -y
libstdc++6-ppc64-cross &amp;&amp; export QEMU_LD_PREFIX=/usr/$host;fi
+  - if [ "$host" == "powerpc64le-linux-gnu" ];then apt-get update &amp;&amp;
apt-get install -y gcc-$host &amp;&amp;
+    apt-get install -y g++-$host &amp;&amp; apt-get install -y
libstdc++6-ppc64el-cross &amp;&amp; export QEMU_LD_PREFIX=/usr/$host;fi
   script:
   - build=$(dpkg-architecture -qDEB_HOST_GNU_TYPE)
   - host="${CI_JOB_NAME#*.cross.}"
@@ -162,3 +167,7 @@ Debian.cross.mips-linux-gnu:
   &lt;&lt;: *Debian_cross_template
 Debian.cross.aarch64-linux-gnu:
   &lt;&lt;: *Debian_cross_template
+Debian.cross.powerpc64-linux-gnu:
+  &lt;&lt;: *Debian_cross_template
+Debian.cross.powerpc64le-linux-gnu:
+  &lt;&lt;: *Debian_cross_template
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200623164357</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-06-23 16:43:57-0400</timestampReceived><subject>[PATCH 3/3] v4.3 Blowfish: Supply lengths instead of C-strings.</subject><body>

Fix examples in the docs relative to v4.2.
---
 blowfish-bcrypt.c | 100 +++++++++++++++++++++++++---------------------
 blowfish.h        |  14 ++++---
 nettle.texinfo    |  27 +++++++------
 3 files changed, 77 insertions(+), 64 deletions(-)

diff --git a/blowfish-bcrypt.c b/blowfish-bcrypt.c
index c06f9e90..64858880 100644
--- a/blowfish-bcrypt.c
+++ b/blowfish-bcrypt.c
@@ -76,14 +76,15 @@ static const char radix64_encode_table[64] =
     "0123456789";
 
 int
-blowfish_bcrypt_verify(const char *key,
-                       const char *hashed)
+blowfish_bcrypt_verify(size_t lenkey, const uint8_t *key,
+                       size_t lenhashed, const uint8_t *hashed)
 {
-  char newhash[BLOWFISH_BCRYPT_HASH_SIZE];
+  uint8_t newhash[BLOWFISH_BCRYPT_HASH_SIZE];
 
-  return blowfish_bcrypt_hash(sizeof newhash,
-                              newhash, key, hashed, -1, (void*)0)
-   &amp;&amp; !strcmp(newhash, hashed);
+  return blowfish_bcrypt_hash(newhash,
+                              lenkey, key, lenhashed, hashed,
+                              -1, (void*)0)
+   &amp;&amp; !strcmp((const char*)newhash, (const char*)hashed);
 }
 
 static char *encode_radix64(char *dst, size_t len, const uint8_t *src)
@@ -159,10 +160,12 @@ static void swap32(uint32_t *x, int count)
 #endif
 }
 
-static void set_xkey(const char *key, bf_key expanded, bf_key initial,
-    unsigned bug, uint32_t safety)
+static void set_xkey(size_t lenkey, const uint8_t *key,
+                     bf_key expanded, bf_key initial,
+		     unsigned bug, uint32_t safety)
 {
-  const char *ptr = key;
+  const uint8_t *ptr = key;
+  size_t n = lenkey;
   unsigned i, j;
   uint32_t sign, diff, tmp[2];
 
@@ -219,10 +222,10 @@ static void set_xkey(const char *key, bf_key expanded, bf_key \
                initial,
  */
       if (j)
         sign |= tmp[1] &amp; 0x80;
-      if (!*ptr)
-        ptr = key;
-      else
+      if (n--)
         ptr++;
+      else
+        ptr = key, n = lenkey;
     }
     diff |= tmp[0] ^ tmp[1]; /* Non-zero on any differences */
 
@@ -259,8 +262,9 @@ static void set_xkey(const char *key, bf_key expanded, bf_key \
initial,  initial[0] ^= sign;
 }
 
-static int ibcrypt(size_t length, char *dst,
-                   const char *key, const char *scheme,
+static int ibcrypt(uint8_t *dst,
+                   size_t lenkey, const uint8_t *key,
+		   size_t lenscheme, const uint8_t *scheme,
 		   int minlog2rounds,
 		   int log2rounds, const uint8_t *salt)
 {
@@ -277,12 +281,10 @@ static int ibcrypt(size_t length, char *dst,
   uint32_t *ptr;
   uint32_t count;
   int i;
-  size_t lenscheme = strlen(scheme);
   unsigned cscheme;
   unsigned bug = 0;
   uint32_t safety = 0;
-  if (length &lt; BLOWFISH_BCRYPT_HASH_SIZE ||
-      lenscheme &lt; 2)
+  if (lenscheme &lt; 2)
     return 0;
 
   if (lenscheme &gt;= 3 &amp;&amp; *scheme++ != '$')
@@ -305,9 +307,17 @@ static int ibcrypt(size_t length, char *dst,
     if (*scheme++ != '$')
       return 0;
     if (lenscheme &gt;= 6) {
-      if (log2rounds &lt; 0)
-        log2rounds = atoi(scheme);
-      scheme += 2;
+      if (log2rounds &lt; 0) {
+        unsigned c = *scheme++ - '0';
+	if (c &gt; 9)
+	  return 0;
+	log2rounds = c * 10;
+        c = *scheme++ - '0';
+	if (c &gt; 9)
+	  return 0;
+	log2rounds += c;
+      } else
+        scheme += 2;
       if (lenscheme &gt;= CRYPTPLEN &amp;&amp; *scheme++ != '$')
 	return 0;
       if (lenscheme &gt;= HASHOFFSET &amp;&amp; !salt) {
@@ -318,7 +328,7 @@ static int ibcrypt(size_t length, char *dst,
         ctx.table = radix64_decode_table;
 
         if (!base64_decode_update(&amp;ctx, &amp;saltlen, (uint8_t *) data.binary.salt,
-                                  SALTLEN, scheme)
+                                  SALTLEN, (const char*) scheme)
          || saltlen != BLOWFISH_BCRYPT_BINSALT_SIZE)
           return 0;
       }
@@ -336,7 +346,7 @@ static int ibcrypt(size_t length, char *dst,
     return 0;
   count = (uint32_t)1 &lt;&lt; log2rounds;
 
-  set_xkey(key, data.expanded_key, data.ctx.p, bug, safety);
+  set_xkey(lenkey, key, data.expanded_key, data.ctx.p, bug, safety);
   memcpy(data.ctx.s, _nettle_blowfish_initial_ctx.s, sizeof(data.ctx.s));
 
   L = R = 0;
@@ -432,12 +442,13 @@ static int ibcrypt(size_t length, char *dst,
   *dst++ = '0' + log2rounds / 10;
   *dst++ = '0' + log2rounds % 10;
   *dst++ = '$';
-  dst = encode_radix64(dst, BLOWFISH_BCRYPT_BINSALT_SIZE, psalt) - 1;
+  dst = (uint8_t*)
+        encode_radix64((char*) dst, BLOWFISH_BCRYPT_BINSALT_SIZE, psalt) - 1;
 
   swap32(data.binary.output, 6);
 /* This has to be bug-compatible with the original implementation, so
    only encode 23 of the 24 bytes. */
-  encode_radix64(dst, 23, (uint8_t *) data.binary.output);
+  encode_radix64((char*) dst, 23, (uint8_t *) data.binary.output);
   return cscheme;
 }
 
@@ -461,27 +472,25 @@ static int ibcrypt(size_t length, char *dst,
  * The performance cost of this quick self-test is around 0.6% at the "$2a$08"
  * setting.
  */
-int blowfish_bcrypt_hash(size_t length, char *dst,
-                         const char *key, const char *scheme,
+int blowfish_bcrypt_hash(uint8_t *dst,
+                         size_t lenkey, const uint8_t *key,
+			 size_t lenscheme, const uint8_t *scheme,
 			 int log2rounds, const uint8_t *salt)
 {
-  const char *test_pw = "8b \xd0\xc1\xd2\xcf\xcc\xd8";
-  const char *test_scheme = "$2a$00$abcdefghijklmnopqrstuu";
+  const uint8_t test_pw[] = "8b \xd0\xc1\xd2\xcf\xcc\xd8";
+  const uint8_t test_scheme[] = "$2a$00$abcdefghijklmnopqrstuu";
   static const char * const test_hashes[2] =
     {"i1D709vfamulimlGcq0qq3UvuUasvEa\0\x55",  /* 'a', 'b', 'y' */
      "VUrPmXD6q/nVSSp7pNDhCR9071IfIRe\0\x55"}; /* 'x' */
   const char *test_hash = test_hashes[0];
   int cscheme;
   int ok;
-  struct {
-    char s[HASHOFFSET + 1];
-    char o[HASHOFFSET + 31 + 1 + 1 + 1];
-  } buf;
+  uint8_t bufs[sizeof(test_scheme) - 1];
+  uint8_t bufo[BLOWFISH_BCRYPT_HASH_SIZE];
 
-  if (length)
-    *dst = '\0';
+  *dst = '\0';
 /* Hash the supplied password */
-  cscheme = ibcrypt(length, dst, key, scheme, 4, log2rounds, salt);
+  cscheme = ibcrypt(dst, lenkey, key, lenscheme, scheme, 4, log2rounds, salt);
 
 /*
  * Do a quick self-test. It is important that we make both calls to ibcrypt()
@@ -490,25 +499,24 @@ int blowfish_bcrypt_hash(size_t length, char *dst,
  * stack and makes it more likely that any alignment related issues would be
  * detected by the self-test.
  */
-  memcpy(buf.s, test_scheme, sizeof(buf.s));
+  memcpy(bufs, test_scheme, sizeof(test_scheme) - 1);
 
   if (cscheme)
-    test_hash = test_hashes[(buf.s[2] = cscheme) == 'x'];
+    test_hash = test_hashes[(bufs[2] = cscheme) == 'x'];
 
-  memset(buf.o, 0x55, sizeof(buf.o));
-  buf.o[sizeof(buf.o) - 1] = 0;
-  ok = ibcrypt(sizeof(buf.o) - (1 + 1), buf.o, test_pw,
-               buf.s, 0, -1, (void*)0);
+  *bufo = 0;
+  ok = ibcrypt(bufo, sizeof(test_pw) - 1, test_pw,
+               sizeof(bufs), bufs, 0, -1, (void*)0);
 
   ok = (ok &amp;&amp;
-      !memcmp(buf.o, buf.s, HASHOFFSET) &amp;&amp;
-      !memcmp(buf.o + HASHOFFSET, test_hash, 31 + 1 + 1 + 1));
+      !memcmp(bufo, bufs, sizeof(bufs)) &amp;&amp;
+      !memcmp(bufo + HASHOFFSET, test_hash, sizeof(test_hash) - 1));
 
   {
-    const char *k = "\xff\xa3" "34" "\xff\xff\xff\xa3" "345";
+    const uint8_t k[] = "\xff\xa3" "34" "\xff\xff\xff\xa3" "345";
     bf_key ae, ai, ye, yi;
-    set_xkey(k, ae, ai, 0, 0x10000); /* $2a$ */
-    set_xkey(k, ye, yi, 0, 0); /* $2y$ */
+    set_xkey(sizeof(k) - 1, k, ae, ai, 0, 0x10000); /* $2a$ */
+    set_xkey(sizeof(k) - 1, k, ye, yi, 0, 0); /* $2y$ */
     ai[0] ^= 0x10000; /* undo the safety (for comparison) */
     ok = ok &amp;&amp; ai[0] == 0xdb9c59bc &amp;&amp; ye[17] == 0x33343500 &amp;&amp;
         !memcmp(ae, ye, sizeof(ae)) &amp;&amp;
diff --git a/blowfish.h b/blowfish.h
index af48e20f..01813cbc 100644
--- a/blowfish.h
+++ b/blowfish.h
@@ -86,16 +86,18 @@ void
 blowfish_decrypt(const struct blowfish_ctx *ctx,
                  size_t length, uint8_t *dst,
                  const uint8_t *src);
+
+/* dst parameter must point to a buffer of minimally
+ * BLOWFISH_BCRYPT_HASH_SIZE bytes */
 int
-blowfish_bcrypt_hash(size_t length,
-                     char *dst,
-                     const char *key,
-                     const char *scheme,
+blowfish_bcrypt_hash(uint8_t *dst,
+                     size_t lenkey, const uint8_t *key,
+                     size_t lenscheme, const uint8_t *scheme,
 		     int log2rounds,
 		     const uint8_t *salt);
 int
-blowfish_bcrypt_verify(const char *key,
-                       const char *hashed);
+blowfish_bcrypt_verify(size_t lenkey, const uint8_t *key,
+                       size_t lenhashed, const uint8_t *hashed);
 
 #ifdef __cplusplus
 }
diff --git a/nettle.texinfo b/nettle.texinfo
index 75e18b58..e9a8a08d 100644
--- a/nettle.texinfo
+++ b/nettle.texinfo
@@ -1513,7 +1513,7 @@ in any other way.
 Analogous to @code{blowfish_encrypt}
 @end deftypefun
 
-@deftypefun int blowfish_bcrypt_hash (size_t @var{length}, char *@var{dst}, const \
char *@var{key}, const char *@var{scheme}, int @var{log2rounds}, const uint8_t \
*@var{salt}) +@deftypefun int blowfish_bcrypt_hash (char *@var{dst}, size_t \
@var{lenkey}, const char *@var{key}, size_t @var{lenscheme}, const char \
*@var{scheme}, int @var{log2rounds}, const uint8_t *@var{salt})  Compute the bcrypt \
password hash.  The function will return @code{0} if the hash cannot be computed
 due to invalid input.
@@ -1522,13 +1522,13 @@ in the array pointed to by @var{dst}.  The hash is computed \
based  on the chosen @var{scheme}, number of rounds @var{log2rounds} and
 specified @var{salt}.
 
-@var{length} must be at least @code{BLOWFISH_BCRYPT_HASH_SIZE}.
+@var{dst} must point to a character array of at least
+ @code{BLOWFISH_BCRYPT_HASH_SIZE} bytes.
 
-@var{dst} must point to a character array of the specified @var{length}.
+@var{key} contains the plaintext password string of size @var{lenkey}.
 
-@var{key} contains the zero terminated plaintext password string.
-
-@var{scheme} contains either just the chosen scheme (valid schemes
+@var{scheme} is of size @var{lenscheme} and contains either just the
+chosen scheme (valid schemes
 are: @code{2a}, @code{2b}, @code{2x} or @code{2y}), or
 (the prefix of) an existing hashed password (typically @code{$2b$10$...}).
 
@@ -1543,26 +1543,28 @@ the salt will be extracted from @var{scheme}.
 Sample code to generate a bcrypt hash:
 @example
 char cleartxtpassword[] = "ExamplePassword";
+char scheme[] = "2b";
 uint8_t salt[BLOWFISH_BCRYPT_BINSALT_SIZE];
 @dots{}
 /* Make sure that salt is filled with random bytes */
 @dots{}
 char hashedresult[BLOWFISH_BCRYPT_HASH_SIZE];
-int result = blowfish_bcrypt(sizeof(hashedresult), hashedresult,
-                             cleartxtpassword, "2b", 10, salt);
+int result = blowfish_bcrypt(hashedresult,
+                             sizeof(cleartxtpassword) - 1, cleartxtpassword,
+                             sizeof(scheme) - 1, scheme, 10, salt);
 if (result)
   printf("%s\n", hashedresult);
 @end example
 @end deftypefun
 
-@deftypefun int blowfish_bcrypt_verify (const char *@var{key}, const char \
*@var{hashed}) +@deftypefun int blowfish_bcrypt_verify (size_t @var{lenkey}, const \
char *@var{key}, size_t @var{lenhashed}, const char *@var{hashed})  Verifies the \
bcrypt password hash against the supplied plaintext password.  The function will \
return @code{0} if the password does not match.  The function will return @code{1} if \
the password matches.  
-@var{key} contains the zero terminated plaintext password string.
+@var{key} contains the plaintext password string of size @var{lenkey}.
 
-@var{hashed} contains the zero terminated hashed string to compare with.
+@var{hashed} contains the hashed string of size @var{lenhashed} to compare with.
 
 Sample code to verify a bcrypt hash:
 @example
@@ -1573,7 +1575,8 @@ char existinghashed[] =
            "$"   /* separator */
            "1b2lPgo4XumibnJGN3r3sO" /* base64 encoded 16-byte salt */
            "u7wE7xNfYDKlAxZffJDCJdVfFTAyevu"; /* Hashedpart */
-if (blowfish_bcrypt_verify(cleartxtpassword, existinghashed))
+if (blowfish_bcrypt_verify(sizeof(cleartxtpassword) - 1, cleartxtpassword,
+                           sizeof(existinghashed) - 1, existinghashed))
   printf("Password is correct.");
 else
   printf("Password is incorrect.");
-- 
2.20.1


_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200626014446</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-06-26 01:44:46-0400</timestampReceived><subject>[Patch] Optimize AES and GHASH for PowerPC64 (support little-endian and big-endian)</subject><body>

Patch implementation benchmark for GCM_AES (Tested on POWER8):
little-endian:
- Encrypt x~17.5 of nettle C implementation
- Decrypt x~17.5 of nettle C implementation
- Update x~30 of nettle C implementation
big-endian:
- Encrypt x~18.5 of nettle C implementation
- Decrypt x~18.5 of nettle C implementation
- Update x~28.5 of nettle C implementation

I investigated falling back to process 4 blocks instead of 8 blocks, 8x
loop outperform 4x loop by x~1.22 on POWER8.
Processing 4 blocks leaves plenty of registers on the table, to reduce the
performance margin these registers can be
used to overlap the instructions inside the loop.
GHASH loop has two separate operations:
- Digest calculation
- Reduction
The reduction procedure is hardly parallelized, to overcome that, the two
procedures can overlap as follows

|`````````````````````````````````````````|
|Head:                                    |
|Digest calculation [0..3]                |
|`````````````````````````````````````````|
|Loop:                                    |
|Overlapped Reduction [i+0..i+3] and      |
|Digest calculation [i+4..i+7]            |
|`````````````````````````````````````````|
|Tail:                                    |
|Reduction [i+4..i+7]                     |
```````````````````````````````````````````

With that implemented the performance margin is reduced to x~1.15 and the
code is messed up a little bit
I can do more documentations so the reader can still keep track of what's
going on but with that said
the performance margin is still considerable and I think it's better to
stick with 8x loop.

- The patch passed the testsuite for both ppc64 and ppc64el.

---
 Makefile.in                        |    2 +-
 asm.m4                             |   17 +-
 config.m4.in                       |    1 +
 configure.ac                       |   12 +
 gcm.c                              |   19 +-
 powerpc64/aes-decrypt-internal.asm |  584 +++++++++++++++++++++
 powerpc64/aes-encrypt-internal.asm |  545 +++++++++++++++++++
 powerpc64/gcm-hash8.asm            | 1015
++++++++++++++++++++++++++++++++++++
 powerpc64/machine.m4               |    0
 testsuite/gcm-test.c               |   23 +
 10 files changed, 2214 insertions(+), 4 deletions(-)
 create mode 100644 powerpc64/aes-decrypt-internal.asm
 create mode 100644 powerpc64/aes-encrypt-internal.asm
 create mode 100644 powerpc64/gcm-hash8.asm
 create mode 100644 powerpc64/machine.m4

diff --git a/Makefile.in b/Makefile.in
index 64ff1001..fdc819f1 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -603,7 +603,7 @@ distdir: $(DISTFILES)
  done
  set -e; for d in sparc32 sparc64 x86 \
  x86_64 x86_64/aesni x86_64/sha_ni x86_64/fat \
- arm arm/neon arm/v6 arm/fat ; do \
+ arm arm/neon arm/v6 arm/fat powerpc64 ; do \
   mkdir "$(distdir)/$$d" ; \
   find "$(srcdir)/$$d" -maxdepth 1 '(' -name '*.asm' -o -name '*.m4' ')' \
     -exec cp '{}' "$(distdir)/$$d" ';' ; \
diff --git a/asm.m4 b/asm.m4
index 59d64098..1033a326 100644
--- a/asm.m4
+++ b/asm.m4
@@ -30,13 +30,26 @@ COFF_STYLE, yes,
 define(&lt;GMP_NUMB_BITS&gt;,&lt;&gt;)dnl

 define(&lt;PROLOGUE&gt;,
+&lt;ifelse(ASM_POWERPC64,no,
 &lt;.globl C_NAME($1)
 DECLARE_FUNC(C_NAME($1))
-C_NAME($1): ASM_X86_ENDBR&gt;)
+C_NAME($1): ASM_X86_ENDBR&gt;,
+&lt;.globl C_NAME($1)
+DECLARE_FUNC(C_NAME($1))
+.section ".opd","aw"
+.align 3
+C_NAME($1):
+.quad .C_NAME($1),.TOC.@tocbase,0
+.previous
+.align 5
+.C_NAME($1):&gt;)&gt;)

 define(&lt;EPILOGUE&gt;,
 &lt;ifelse(ELF_STYLE,yes,
-&lt;.size C_NAME($1), . - C_NAME($1)&gt;,&lt;&gt;)&gt;)
+&lt;ifelse(ASM_POWERPC64,no,
+&lt;.size C_NAME($1), . - C_NAME($1)&gt;,
+&lt;.size .C_NAME($1), . - .C_NAME($1)
+.size C_NAME($1), . - .C_NAME($1)&gt;)&gt;,&lt;&gt;)&gt;)

 define(&lt;m4_log2&gt;, &lt;m4_log2_internal($1,1,0)&gt;)
 define(&lt;m4_log2_internal&gt;,
diff --git a/config.m4.in b/config.m4.in
index f7f5f283..6265a679 100644
--- a/config.m4.in
+++ b/config.m4.in
@@ -10,6 +10,7 @@ define(&lt;RODATA&gt;, &lt;@ASM_RODATA@&gt;)dnl
 define(&lt;WORDS_BIGENDIAN&gt;, &lt;@ASM_WORDS_BIGENDIAN@&gt;)dnl
 define(&lt;ASM_X86_ENDBR&gt;,&lt;@ASM_X86_ENDBR@&gt;)dnl
 define(&lt;ASM_X86_MARK_CET_ALIGN&gt;,&lt;@ASM_X86_MARK_CET_ALIGN@&gt;)dnl
+define(&lt;ASM_POWERPC64&gt;,&lt;@ASM_POWERPC64@&gt;)dnl
 divert(1)
 @ASM_X86_MARK_CET@
 @ASM_MARK_NOEXEC_STACK@
diff --git a/configure.ac b/configure.ac
index 90ea1ea8..d7baface 100644
--- a/configure.ac
+++ b/configure.ac
@@ -435,6 +435,9 @@ if test "x$enable_assembler" = xyes ; then
  esac
       fi
       ;;
+    *powerpc64*)
+      asm_path=powerpc64
+      ;;
     *)
       enable_assembler=no
       ;;
@@ -572,7 +575,9 @@ AH_VERBATIM([HAVE_NATIVE],
 #undef HAVE_NATIVE_ecc_secp384r1_redc
 #undef HAVE_NATIVE_ecc_secp521r1_modp
 #undef HAVE_NATIVE_ecc_secp521r1_redc
+#undef HAVE_NATIVE_gcm_init_key8
 #undef HAVE_NATIVE_gcm_hash8
+#undef HAVE_NATIVE_gcm_fill
 #undef HAVE_NATIVE_salsa20_core
 #undef HAVE_NATIVE_sha1_compress
 #undef HAVE_NATIVE_sha256_compress
@@ -866,6 +871,12 @@ if test "$nettle_cv_asm_x86_gnu_property" = yes; then
  .popsection'
 fi

+if test "$host_cpu" = "powerpc64" ; then
+  ASM_POWERPC64='yes'
+else
+  ASM_POWERPC64='no'
+fi
+
 AC_SUBST(ASM_SYMBOL_PREFIX)
 AC_SUBST(ASM_ELF_STYLE)
 AC_SUBST(ASM_COFF_STYLE)
@@ -879,6 +890,7 @@ AC_SUBST(EMULATOR)
 AC_SUBST(ASM_X86_ENDBR)
 AC_SUBST(ASM_X86_MARK_CET)
 AC_SUBST(ASM_X86_MARK_CET_ALIGN)
+AC_SUBST(ASM_POWERPC64)

 AC_SUBST(LIBNETTLE_MAJOR)
 AC_SUBST(LIBNETTLE_MINOR)
diff --git a/gcm.c b/gcm.c
index cf615daf..809c03bc 100644
--- a/gcm.c
+++ b/gcm.c
@@ -140,6 +140,12 @@ gcm_gf_mul (union nettle_block16 *x, const union
nettle_block16 *table)
   memcpy (x-&gt;b, Z.b, sizeof(Z));
 }
 # elif GCM_TABLE_BITS == 8
+#  if HAVE_NATIVE_gcm_init_key8
+
+#define gcm_init_key _nettle_gcm_init_key8
+void
+_nettle_gcm_init_key8 (union nettle_block16 *table);
+#  endif /* HAVE_NATIVE_gcm_init_key8 */
 #  if HAVE_NATIVE_gcm_hash8

 #define gcm_hash _nettle_gcm_hash8
@@ -225,6 +231,13 @@ gcm_gf_mul (union nettle_block16 *x, const union
nettle_block16 *table)

 #endif /* GCM_TABLE_BITS */

+#if HAVE_NATIVE_gcm_fill
+
+#define gcm_fill _nettle_gcm_fill
+void
+_nettle_gcm_fill (uint8_t *ctr, size_t blocks, union nettle_block16
*buffer);
+#endif /* HAVE_NATIVE_gcm_fill */
+
 /* Increment the rightmost 32 bits. */
 #define INC32(block) INCREMENT(4, (block.b) + GCM_BLOCK_SIZE - 4)

@@ -245,7 +258,9 @@ gcm_set_key(struct gcm_key *key,
   memset(key-&gt;h[0].b, 0, GCM_BLOCK_SIZE);
   f (cipher, GCM_BLOCK_SIZE, key-&gt;h[i].b, key-&gt;h[0].b);

-#if GCM_TABLE_BITS
+#ifdef gcm_init_key
+  gcm_init_key(key-&gt;h);
+#elif GCM_TABLE_BITS
   /* Algorithm 3 from the gcm paper. First do powers of two, then do
      the rest by adding. */
   while (i /= 2)
@@ -333,6 +348,7 @@ gcm_update(struct gcm_ctx *ctx, const struct gcm_key
*key,
   ctx-&gt;auth_size += length;
 }

+#ifndef gcm_fill
 static nettle_fill16_func gcm_fill;
 static void
 gcm_fill(uint8_t *ctr, size_t blocks, union nettle_block16 *buffer)
@@ -349,6 +365,7 @@ gcm_fill(uint8_t *ctr, size_t blocks, union
nettle_block16 *buffer)

   WRITE_UINT32(ctr + GCM_BLOCK_SIZE - 4, c);
 }
+#endif /* !gcm_fill */

 void
 gcm_encrypt (struct gcm_ctx *ctx, const struct gcm_key *key,
diff --git a/powerpc64/aes-decrypt-internal.asm
b/powerpc64/aes-decrypt-internal.asm
new file mode 100644
index 00000000..70fd69f0
--- /dev/null
+++ b/powerpc64/aes-decrypt-internal.asm
@@ -0,0 +1,584 @@
+C powerpc64/aes-decrypt-internal.asm
+
+ifelse(&lt;
+   Copyright (C) 2020 Mamone Tarsha
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+&gt;)
+
+C Register usage:
+
+define(&lt;SP&gt;, &lt;1&gt;)
+define(&lt;TOCP&gt;, &lt;2&gt;)
+
+define(&lt;ROUNDS&gt;, &lt;3&gt;)
+define(&lt;KEYS&gt;, &lt;4&gt;)
+define(&lt;LENGTH&gt;, &lt;6&gt;)
+define(&lt;DST&gt;, &lt;7&gt;)
+define(&lt;SRC&gt;, &lt;8&gt;)
+
+define(&lt;swap_mask&gt;, &lt;0&gt;)
+
+define(&lt;K&gt;, &lt;1&gt;)
+define(&lt;S0&gt;, &lt;2&gt;)
+define(&lt;S1&gt;, &lt;3&gt;)
+define(&lt;S2&gt;, &lt;4&gt;)
+define(&lt;S3&gt;, &lt;5&gt;)
+define(&lt;S4&gt;, &lt;6&gt;)
+define(&lt;S5&gt;, &lt;7&gt;)
+define(&lt;S6&gt;, &lt;8&gt;)
+define(&lt;S7&gt;, &lt;9&gt;)
+define(&lt;S8&gt;, &lt;10&gt;)
+define(&lt;S9&gt;, &lt;11&gt;)
+define(&lt;S10&gt;, &lt;12&gt;)
+define(&lt;S11&gt;, &lt;13&gt;)
+define(&lt;S12&gt;, &lt;14&gt;)
+define(&lt;S13&gt;, &lt;15&gt;)
+define(&lt;S14&gt;, &lt;16&gt;)
+define(&lt;S15&gt;, &lt;17&gt;)
+
+define(&lt;KX&gt;, &lt;33&gt;)
+define(&lt;S0X&gt;, &lt;34&gt;)
+define(&lt;S1X&gt;, &lt;35&gt;)
+define(&lt;S2X&gt;, &lt;36&gt;)
+define(&lt;S3X&gt;, &lt;37&gt;)
+define(&lt;S4X&gt;, &lt;38&gt;)
+define(&lt;S5X&gt;, &lt;39&gt;)
+define(&lt;S6X&gt;, &lt;40&gt;)
+define(&lt;S7X&gt;, &lt;41&gt;)
+define(&lt;S8X&gt;, &lt;42&gt;)
+define(&lt;S9X&gt;, &lt;43&gt;)
+define(&lt;S10X&gt;, &lt;44&gt;)
+define(&lt;S11X&gt;, &lt;45&gt;)
+define(&lt;S12X&gt;, &lt;46&gt;)
+define(&lt;S13X&gt;, &lt;47&gt;)
+define(&lt;S14X&gt;, &lt;48&gt;)
+define(&lt;S15X&gt;, &lt;49&gt;)
+
+C ZERO vector register is used in place of RoundKey
+C for vncipher instruction because the order of InvMixColumns
+C and Xor processes are flipped in that instruction.
+C The Xor process with RoundKey is executed afterward.
+define(&lt;ZERO&gt;, &lt;18&gt;)
+
+.file "aes-decrypt-internal.asm"
+
+.machine "any"
+
+IF_LE(&lt;.abiversion 2&gt;)
+.text
+
+ C _aes_decrypt(unsigned rounds, const uint32_t *keys,
+ C       const struct aes_table *T,
+ C       size_t length, uint8_t *dst,
+ C       uint8_t *src)
+
+IF_LE(&lt;.align 5&gt;)
+PROLOGUE(_nettle_aes_decrypt)
+IF_LE(&lt;.localentry _nettle_aes_decrypt,0&gt;)
+
+ vxor ZERO,ZERO,ZERO
+
+ ld 5,.swap_mask@got(TOCP)
+ lvx swap_mask,0,5
+
+ subi ROUNDS,ROUNDS,1
+ srdi LENGTH,LENGTH,4
+
+ srdi 5,LENGTH,4 #16x loop count
+ cmpldi 5,0
+ beq L8x
+
+ std 17,-120(SP);
+ std 18,-112(SP);
+ std 19,-104(SP);
+ std 20,-96(SP);
+ std 21,-88(SP);
+ std 22,-80(SP);
+ std 23,-72(SP);
+ std 24,-64(SP);
+ std 25,-56(SP);
+ std 26,-48(SP);
+ std 27,-40(SP);
+ std 28,-32(SP);
+ std 29,-24(SP);
+ std 30,-16(SP);
+ std 31,-8(SP);
+
+ li 17,0x10
+ li 18,0x20
+ li 19,0x30
+ li 20,0x40
+ li 21,0x50
+ li 22,0x60
+ li 23,0x70
+ li 24,0x80
+ li 25,0x90
+ li 26,0xA0
+ li 27,0xB0
+ li 28,0xC0
+ li 29,0xD0
+ li 30,0xE0
+ li 31,0xF0
+
+.align 5
+Lx16_loop:
+ lxvd2x KX,0,KEYS
+ vperm   K,K,K,swap_mask
+
+ lxvd2x S0X,0,SRC
+ lxvd2x S1X,17,SRC
+ lxvd2x S2X,18,SRC
+ lxvd2x S3X,19,SRC
+ lxvd2x S4X,20,SRC
+ lxvd2x S5X,21,SRC
+ lxvd2x S6X,22,SRC
+ lxvd2x S7X,23,SRC
+ lxvd2x S8X,24,SRC
+ lxvd2x S9X,25,SRC
+ lxvd2x S10X,26,SRC
+ lxvd2x S11X,27,SRC
+ lxvd2x S12X,28,SRC
+ lxvd2x S13X,29,SRC
+ lxvd2x S14X,30,SRC
+ lxvd2x S15X,31,SRC
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask
+ vperm S4,S4,S4,swap_mask
+ vperm S5,S5,S5,swap_mask
+ vperm S6,S6,S6,swap_mask
+ vperm S7,S7,S7,swap_mask
+ vperm S8,S8,S8,swap_mask
+ vperm S9,S9,S9,swap_mask
+ vperm S10,S10,S10,swap_mask
+ vperm S11,S11,S11,swap_mask
+ vperm S12,S12,S12,swap_mask
+ vperm S13,S13,S13,swap_mask
+ vperm S14,S14,S14,swap_mask
+ vperm S15,S15,S15,swap_mask&gt;)
+
+ vxor S0,S0,K
+ vxor S1,S1,K
+ vxor S2,S2,K
+ vxor S3,S3,K
+ vxor S4,S4,K
+ vxor S5,S5,K
+ vxor S6,S6,K
+ vxor S7,S7,K
+ vxor S8,S8,K
+ vxor S9,S9,K
+ vxor S10,S10,K
+ vxor S11,S11,K
+ vxor S12,S12,K
+ vxor S13,S13,K
+ vxor S14,S14,K
+ vxor S15,S15,K
+
+ mtctr ROUNDS
+ li 10,0x10
+.align 5
+L16x_round_loop:
+ lxvd2x KX,10,KEYS
+ vperm   K,K,K,swap_mask
+ vncipher S0,S0,ZERO
+ vncipher S1,S1,ZERO
+ vncipher S2,S2,ZERO
+ vncipher S3,S3,ZERO
+ vncipher S4,S4,ZERO
+ vncipher S5,S5,ZERO
+ vncipher S6,S6,ZERO
+ vncipher S7,S7,ZERO
+ vncipher S8,S8,ZERO
+ vncipher S9,S9,ZERO
+ vncipher S10,S10,ZERO
+ vncipher S11,S11,ZERO
+ vncipher S12,S12,ZERO
+ vncipher S13,S13,ZERO
+ vncipher S14,S14,ZERO
+ vncipher S15,S15,ZERO
+ vxor S0,S0,K
+ vxor S1,S1,K
+ vxor S2,S2,K
+ vxor S3,S3,K
+ vxor S4,S4,K
+ vxor S5,S5,K
+ vxor S6,S6,K
+ vxor S7,S7,K
+ vxor S8,S8,K
+ vxor S9,S9,K
+ vxor S10,S10,K
+ vxor S11,S11,K
+ vxor S12,S12,K
+ vxor S13,S13,K
+ vxor S14,S14,K
+ vxor S15,S15,K
+ addi 10,10,0x10
+ bdnz L16x_round_loop
+
+ lxvd2x KX,10,KEYS
+ vperm   K,K,K,swap_mask
+ vncipherlast S0,S0,K
+ vncipherlast S1,S1,K
+ vncipherlast S2,S2,K
+ vncipherlast S3,S3,K
+ vncipherlast S4,S4,K
+ vncipherlast S5,S5,K
+ vncipherlast S6,S6,K
+ vncipherlast S7,S7,K
+ vncipherlast S8,S8,K
+ vncipherlast S9,S9,K
+ vncipherlast S10,S10,K
+ vncipherlast S11,S11,K
+ vncipherlast S12,S12,K
+ vncipherlast S13,S13,K
+ vncipherlast S14,S14,K
+ vncipherlast S15,S15,K
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask
+ vperm S4,S4,S4,swap_mask
+ vperm S5,S5,S5,swap_mask
+ vperm S6,S6,S6,swap_mask
+ vperm S7,S7,S7,swap_mask
+ vperm S8,S8,S8,swap_mask
+ vperm S9,S9,S9,swap_mask
+ vperm S10,S10,S10,swap_mask
+ vperm S11,S11,S11,swap_mask
+ vperm S12,S12,S12,swap_mask
+ vperm S13,S13,S13,swap_mask
+ vperm S14,S14,S14,swap_mask
+ vperm S15,S15,S15,swap_mask&gt;)
+
+ stxvd2x S0X,0,DST
+ stxvd2x S1X,17,DST
+ stxvd2x S2X,18,DST
+ stxvd2x S3X,19,DST
+ stxvd2x S4X,20,DST
+ stxvd2x S5X,21,DST
+ stxvd2x S6X,22,DST
+ stxvd2x S7X,23,DST
+ stxvd2x S8X,24,DST
+ stxvd2x S9X,25,DST
+ stxvd2x S10X,26,DST
+ stxvd2x S11X,27,DST
+ stxvd2x S12X,28,DST
+ stxvd2x S13X,29,DST
+ stxvd2x S14X,30,DST
+ stxvd2x S15X,31,DST
+
+ addi SRC,SRC,0x100
+ addi DST,DST,0x100
+ subic. 5,5,1
+ bne Lx16_loop
+
+ ld 17,-120(SP);
+ ld 18,-112(SP);
+ ld 19,-104(SP);
+ ld 20,-96(SP);
+ ld 21,-88(SP);
+ ld 22,-80(SP);
+ ld 23,-72(SP);
+ ld 24,-64(SP);
+ ld 25,-56(SP);
+ ld 26,-48(SP);
+ ld 27,-40(SP);
+ ld 28,-32(SP);
+ ld 29,-24(SP);
+ ld 30,-16(SP);
+ ld 31,-8(SP);
+
+ clrldi LENGTH,LENGTH,60
+
+L8x:
+ srdi 5,LENGTH,3
+ cmpldi 5,0
+ beq L4x
+
+ lxvd2x KX,0,KEYS
+ vperm   K,K,K,swap_mask
+
+ lxvd2x S0X,0,SRC
+ li   9,0x10
+ lxvd2x S1X,9,SRC
+ addi   9,9,0x10
+ lxvd2x S2X,9,SRC
+ addi   9,9,0x10
+ lxvd2x S3X,9,SRC
+ addi  9,9,0x10
+ lxvd2x S4X,9,SRC
+ addi   9,9,0x10
+ lxvd2x S5X,9,SRC
+ addi   9,9,0x10
+ lxvd2x S6X,9,SRC
+ addi  9,9,0x10
+ lxvd2x S7X,9,SRC
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask
+ vperm S4,S4,S4,swap_mask
+ vperm S5,S5,S5,swap_mask
+ vperm S6,S6,S6,swap_mask
+ vperm S7,S7,S7,swap_mask&gt;)
+
+ vxor S0,S0,K
+ vxor S1,S1,K
+ vxor S2,S2,K
+ vxor S3,S3,K
+ vxor S4,S4,K
+ vxor S5,S5,K
+ vxor S6,S6,K
+ vxor S7,S7,K
+
+ mtctr ROUNDS
+ li 10,0x10
+.align 5
+L8x_round_loop:
+ lxvd2x KX,10,KEYS
+ vperm   K,K,K,swap_mask
+ vncipher S0,S0,ZERO
+ vncipher S1,S1,ZERO
+ vncipher S2,S2,ZERO
+ vncipher S3,S3,ZERO
+ vncipher S4,S4,ZERO
+ vncipher S5,S5,ZERO
+ vncipher S6,S6,ZERO
+ vncipher S7,S7,ZERO
+ vxor S0,S0,K
+ vxor S1,S1,K
+ vxor S2,S2,K
+ vxor S3,S3,K
+ vxor S4,S4,K
+ vxor S5,S5,K
+ vxor S6,S6,K
+ vxor S7,S7,K
+ addi 10,10,0x10
+ bdnz L8x_round_loop
+
+ lxvd2x  KX,10,KEYS
+ vperm       K,K,K,swap_mask
+ vncipherlast S0,S0,K
+ vncipherlast S1,S1,K
+ vncipherlast S2,S2,K
+ vncipherlast S3,S3,K
+ vncipherlast S4,S4,K
+ vncipherlast S5,S5,K
+ vncipherlast S6,S6,K
+ vncipherlast S7,S7,K
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask
+ vperm S4,S4,S4,swap_mask
+ vperm S5,S5,S5,swap_mask
+ vperm S6,S6,S6,swap_mask
+ vperm S7,S7,S7,swap_mask&gt;)
+
+ stxvd2x S0X,0,DST
+ li  9,0x10
+ stxvd2x S1X,9,DST
+ addi  9,9,0x10
+ stxvd2x S2X,9,DST
+ addi   9,9,0x10
+ stxvd2x S3X,9,DST
+ addi   9,9,0x10
+ stxvd2x S4X,9,DST
+ addi   9,9,0x10
+ stxvd2x S5X,9,DST
+ addi   9,9,0x10
+ stxvd2x S6X,9,DST
+ addi   9,9,0x10
+ stxvd2x S7X,9,DST
+
+ addi   SRC,SRC,0x80
+ addi   DST,DST,0x80
+
+ clrldi LENGTH,LENGTH,61
+
+L4x:
+ srdi   5,LENGTH,2
+ cmpldi   5,0
+ beq   L2x
+
+ lxvd2x   KX,0,KEYS
+ vperm   K,K,K,swap_mask
+
+ lxvd2x S0X,0,SRC
+ li  9,0x10
+ lxvd2x S1X,9,SRC
+ addi   9,9,0x10
+ lxvd2x S2X,9,SRC
+ addi   9,9,0x10
+ lxvd2x S3X,9,SRC
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask&gt;)
+
+ vxor S0,S0,K
+ vxor S1,S1,K
+ vxor S2,S2,K
+ vxor S3,S3,K
+
+ mtctr ROUNDS
+ li 10,0x10
+.align 5
+L4x_round_loop:
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vncipher S0,S0,ZERO
+ vncipher S1,S1,ZERO
+ vncipher S2,S2,ZERO
+ vncipher S3,S3,ZERO
+ vxor   S0,S0,K
+ vxor  S1,S1,K
+ vxor   S2,S2,K
+ vxor   S3,S3,K
+ addi   10,10,0x10
+ bdnz  L4x_round_loop
+
+ lxvd2x KX,10,KEYS
+ vperm   K,K,K,swap_mask
+ vncipherlast S0,S0,K
+ vncipherlast S1,S1,K
+ vncipherlast S2,S2,K
+ vncipherlast S3,S3,K
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask&gt;)
+
+ stxvd2x S0X,0,DST
+ li  9,0x10
+ stxvd2x S1X,9,DST
+ addi   9,9,0x10
+ stxvd2x S2X,9,DST
+ addi  9,9,0x10
+ stxvd2x S3X,9,DST
+
+ addi   SRC,SRC,0x40
+ addi   DST,DST,0x40
+
+ clrldi LENGTH,LENGTH,62
+
+L2x:
+ srdi  5,LENGTH,1
+ cmpldi  5,0
+ beq   L1x
+
+ lxvd2x KX,0,KEYS
+ vperm K,K,K,swap_mask
+
+ lxvd2x S0X,0,SRC
+ li   9,0x10
+ lxvd2x S1X,9,SRC
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask&gt;)
+
+ vxor  S0,S0,K
+ vxor   S1,S1,K
+
+ mtctr   ROUNDS
+ li  10,0x10
+.align 5
+L2x_round_loop:
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vncipher S0,S0,ZERO
+ vncipher S1,S1,ZERO
+ vxor  S0,S0,K
+ vxor  S1,S1,K
+ addi   10,10,0x10
+ bdnz   L2x_round_loop
+
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vncipherlast S0,S0,K
+ vncipherlast S1,S1,K
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask&gt;)
+
+ stxvd2x S0X,0,DST
+ li  9,0x10
+ stxvd2x S1X,9,DST
+
+ addi   SRC,SRC,0x20
+ addi   DST,DST,0x20
+
+ clrldi LENGTH,LENGTH,63
+
+L1x:
+ cmpldi LENGTH,0
+ beq   Ldone
+
+ lxvd2x KX,0,KEYS
+ vperm   K,K,K,swap_mask
+
+ lxvd2x S0X,0,SRC
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask&gt;)
+
+ vxor   S0,S0,K
+
+ mtctr   ROUNDS
+ li   10,0x10
+.align 5
+L1x_round_loop:
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vncipher S0,S0,ZERO
+ vxor   S0,S0,K
+ addi   10,10,0x10
+ bdnz   L1x_round_loop
+
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vncipherlast S0,S0,K
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask&gt;)
+
+ stxvd2x S0X,0,DST
+
+Ldone:
+ blr
+EPILOGUE(_nettle_aes_decrypt)
+
+ .data
+ .align 4
+.swap_mask:
+IF_LE(&lt;.byte 8,9,10,11,12,13,14,15,0,1,2,3,4,5,6,7&gt;)
+IF_BE(&lt;.byte 3,2,1,0,7,6,5,4,11,10,9,8,15,14,13,12&gt;)
diff --git a/powerpc64/aes-encrypt-internal.asm
b/powerpc64/aes-encrypt-internal.asm
new file mode 100644
index 00000000..20711598
--- /dev/null
+++ b/powerpc64/aes-encrypt-internal.asm
@@ -0,0 +1,545 @@
+C powerpc64/aes-encrypt-internal.asm
+
+ifelse(&lt;
+   Copyright (C) 2020 Mamone Tarsha
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+&gt;)
+
+C Register usage:
+
+define(&lt;SP&gt;, &lt;1&gt;)
+define(&lt;TOCP&gt;, &lt;2&gt;)
+
+define(&lt;ROUNDS&gt;, &lt;3&gt;)
+define(&lt;KEYS&gt;, &lt;4&gt;)
+define(&lt;LENGTH&gt;, &lt;6&gt;)
+define(&lt;DST&gt;, &lt;7&gt;)
+define(&lt;SRC&gt;, &lt;8&gt;)
+
+define(&lt;swap_mask&gt;, &lt;0&gt;)
+
+define(&lt;K&gt;, &lt;1&gt;)
+define(&lt;S0&gt;, &lt;2&gt;)
+define(&lt;S1&gt;, &lt;3&gt;)
+define(&lt;S2&gt;, &lt;4&gt;)
+define(&lt;S3&gt;, &lt;5&gt;)
+define(&lt;S4&gt;, &lt;6&gt;)
+define(&lt;S5&gt;, &lt;7&gt;)
+define(&lt;S6&gt;, &lt;8&gt;)
+define(&lt;S7&gt;, &lt;9&gt;)
+define(&lt;S8&gt;, &lt;10&gt;)
+define(&lt;S9&gt;, &lt;11&gt;)
+define(&lt;S10&gt;, &lt;12&gt;)
+define(&lt;S11&gt;, &lt;13&gt;)
+define(&lt;S12&gt;, &lt;14&gt;)
+define(&lt;S13&gt;, &lt;15&gt;)
+define(&lt;S14&gt;, &lt;16&gt;)
+define(&lt;S15&gt;, &lt;17&gt;)
+
+define(&lt;KX&gt;, &lt;33&gt;)
+define(&lt;S0X&gt;, &lt;34&gt;)
+define(&lt;S1X&gt;, &lt;35&gt;)
+define(&lt;S2X&gt;, &lt;36&gt;)
+define(&lt;S3X&gt;, &lt;37&gt;)
+define(&lt;S4X&gt;, &lt;38&gt;)
+define(&lt;S5X&gt;, &lt;39&gt;)
+define(&lt;S6X&gt;, &lt;40&gt;)
+define(&lt;S7X&gt;, &lt;41&gt;)
+define(&lt;S8X&gt;, &lt;42&gt;)
+define(&lt;S9X&gt;, &lt;43&gt;)
+define(&lt;S10X&gt;, &lt;44&gt;)
+define(&lt;S11X&gt;, &lt;45&gt;)
+define(&lt;S12X&gt;, &lt;46&gt;)
+define(&lt;S13X&gt;, &lt;47&gt;)
+define(&lt;S14X&gt;, &lt;48&gt;)
+define(&lt;S15X&gt;, &lt;49&gt;)
+
+.file "aes-encrypt-internal.asm"
+
+.machine "any"
+
+IF_LE(&lt;.abiversion 2&gt;)
+.text
+
+ C _aes_encrypt(unsigned rounds, const uint32_t *keys,
+ C       const struct aes_table *T,
+ C       size_t length, uint8_t *dst,
+ C       uint8_t *src)
+
+IF_LE(&lt;.align 5&gt;)
+PROLOGUE(_nettle_aes_encrypt)
+IF_LE(&lt;.localentry _nettle_aes_encrypt,0&gt;)
+
+ ld 5,.swap_mask@got(TOCP)
+ lvx swap_mask,0,5
+
+ subi ROUNDS,ROUNDS,1
+ srdi LENGTH,LENGTH,4
+
+ srdi 5,LENGTH,4 #16x loop count
+ cmpldi 5,0
+ beq L8x
+
+ std 17,-120(SP);
+ std 18,-112(SP);
+ std 19,-104(SP);
+ std 20,-96(SP);
+ std 21,-88(SP);
+ std 22,-80(SP);
+ std 23,-72(SP);
+ std 24,-64(SP);
+ std 25,-56(SP);
+ std 26,-48(SP);
+ std 27,-40(SP);
+ std 28,-32(SP);
+ std 29,-24(SP);
+ std 30,-16(SP);
+ std 31,-8(SP);
+
+ li 17,0x10
+ li 18,0x20
+ li 19,0x30
+ li 20,0x40
+ li 21,0x50
+ li 22,0x60
+ li 23,0x70
+ li 24,0x80
+ li 25,0x90
+ li 26,0xA0
+ li 27,0xB0
+ li 28,0xC0
+ li 29,0xD0
+ li 30,0xE0
+ li 31,0xF0
+
+.align 5
+Lx16_loop:
+ lxvd2x KX,0,KEYS
+ vperm   K,K,K,swap_mask
+
+ lxvd2x S0X,0,SRC
+ lxvd2x S1X,17,SRC
+ lxvd2x S2X,18,SRC
+ lxvd2x S3X,19,SRC
+ lxvd2x S4X,20,SRC
+ lxvd2x S5X,21,SRC
+ lxvd2x S6X,22,SRC
+ lxvd2x S7X,23,SRC
+ lxvd2x S8X,24,SRC
+ lxvd2x S9X,25,SRC
+ lxvd2x S10X,26,SRC
+ lxvd2x S11X,27,SRC
+ lxvd2x S12X,28,SRC
+ lxvd2x S13X,29,SRC
+ lxvd2x S14X,30,SRC
+ lxvd2x S15X,31,SRC
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask
+ vperm S4,S4,S4,swap_mask
+ vperm S5,S5,S5,swap_mask
+ vperm S6,S6,S6,swap_mask
+ vperm S7,S7,S7,swap_mask
+ vperm S8,S8,S8,swap_mask
+ vperm S9,S9,S9,swap_mask
+ vperm S10,S10,S10,swap_mask
+ vperm S11,S11,S11,swap_mask
+ vperm S12,S12,S12,swap_mask
+ vperm S13,S13,S13,swap_mask
+ vperm S14,S14,S14,swap_mask
+ vperm S15,S15,S15,swap_mask&gt;)
+
+ vxor S0,S0,K
+ vxor S1,S1,K
+ vxor S2,S2,K
+ vxor S3,S3,K
+ vxor S4,S4,K
+ vxor S5,S5,K
+ vxor S6,S6,K
+ vxor S7,S7,K
+ vxor S8,S8,K
+ vxor S9,S9,K
+ vxor S10,S10,K
+ vxor S11,S11,K
+ vxor S12,S12,K
+ vxor S13,S13,K
+ vxor S14,S14,K
+ vxor S15,S15,K
+
+ mtctr ROUNDS
+ li 10,0x10
+.align 5
+L16x_round_loop:
+ lxvd2x KX,10,KEYS
+ vperm   K,K,K,swap_mask
+ vcipher S0,S0,K
+ vcipher S1,S1,K
+ vcipher S2,S2,K
+ vcipher S3,S3,K
+ vcipher S4,S4,K
+ vcipher S5,S5,K
+ vcipher S6,S6,K
+ vcipher S7,S7,K
+ vcipher S8,S8,K
+ vcipher S9,S9,K
+ vcipher S10,S10,K
+ vcipher S11,S11,K
+ vcipher S12,S12,K
+ vcipher S13,S13,K
+ vcipher S14,S14,K
+ vcipher S15,S15,K
+ addi 10,10,0x10
+ bdnz L16x_round_loop
+
+ lxvd2x KX,10,KEYS
+ vperm   K,K,K,swap_mask
+ vcipherlast S0,S0,K
+ vcipherlast S1,S1,K
+ vcipherlast S2,S2,K
+ vcipherlast S3,S3,K
+ vcipherlast S4,S4,K
+ vcipherlast S5,S5,K
+ vcipherlast S6,S6,K
+ vcipherlast S7,S7,K
+ vcipherlast S8,S8,K
+ vcipherlast S9,S9,K
+ vcipherlast S10,S10,K
+ vcipherlast S11,S11,K
+ vcipherlast S12,S12,K
+ vcipherlast S13,S13,K
+ vcipherlast S14,S14,K
+ vcipherlast S15,S15,K
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask
+ vperm S4,S4,S4,swap_mask
+ vperm S5,S5,S5,swap_mask
+ vperm S6,S6,S6,swap_mask
+ vperm S7,S7,S7,swap_mask
+ vperm S8,S8,S8,swap_mask
+ vperm S9,S9,S9,swap_mask
+ vperm S10,S10,S10,swap_mask
+ vperm S11,S11,S11,swap_mask
+ vperm S12,S12,S12,swap_mask
+ vperm S13,S13,S13,swap_mask
+ vperm S14,S14,S14,swap_mask
+ vperm S15,S15,S15,swap_mask&gt;)
+
+ stxvd2x S0X,0,DST
+ stxvd2x S1X,17,DST
+ stxvd2x S2X,18,DST
+ stxvd2x S3X,19,DST
+ stxvd2x S4X,20,DST
+ stxvd2x S5X,21,DST
+ stxvd2x S6X,22,DST
+ stxvd2x S7X,23,DST
+ stxvd2x S8X,24,DST
+ stxvd2x S9X,25,DST
+ stxvd2x S10X,26,DST
+ stxvd2x S11X,27,DST
+ stxvd2x S12X,28,DST
+ stxvd2x S13X,29,DST
+ stxvd2x S14X,30,DST
+ stxvd2x S15X,31,DST
+
+ addi SRC,SRC,0x100
+ addi DST,DST,0x100
+ subic. 5,5,1
+ bne Lx16_loop
+
+ ld 17,-120(SP);
+ ld 18,-112(SP);
+ ld 19,-104(SP);
+ ld 20,-96(SP);
+ ld 21,-88(SP);
+ ld 22,-80(SP);
+ ld 23,-72(SP);
+ ld 24,-64(SP);
+ ld 25,-56(SP);
+ ld 26,-48(SP);
+ ld 27,-40(SP);
+ ld 28,-32(SP);
+ ld 29,-24(SP);
+ ld 30,-16(SP);
+ ld 31,-8(SP);
+
+ clrldi LENGTH,LENGTH,60
+
+L8x:
+ srdi 5,LENGTH,3
+ cmpldi 5,0
+ beq L4x
+
+ lxvd2x KX,0,KEYS
+ vperm   K,K,K,swap_mask
+
+ lxvd2x S0X,0,SRC
+ li   9,0x10
+ lxvd2x S1X,9,SRC
+ addi   9,9,0x10
+ lxvd2x S2X,9,SRC
+ addi   9,9,0x10
+ lxvd2x S3X,9,SRC
+ addi  9,9,0x10
+ lxvd2x S4X,9,SRC
+ addi   9,9,0x10
+ lxvd2x S5X,9,SRC
+ addi   9,9,0x10
+ lxvd2x S6X,9,SRC
+ addi  9,9,0x10
+ lxvd2x S7X,9,SRC
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask
+ vperm S4,S4,S4,swap_mask
+ vperm S5,S5,S5,swap_mask
+ vperm S6,S6,S6,swap_mask
+ vperm S7,S7,S7,swap_mask&gt;)
+
+ vxor S0,S0,K
+ vxor S1,S1,K
+ vxor S2,S2,K
+ vxor S3,S3,K
+ vxor S4,S4,K
+ vxor S5,S5,K
+ vxor S6,S6,K
+ vxor S7,S7,K
+
+ mtctr ROUNDS
+ li 10,0x10
+.align 5
+L8x_round_loop:
+ lxvd2x KX,10,KEYS
+ vperm   K,K,K,swap_mask
+ vcipher S0,S0,K
+ vcipher S1,S1,K
+ vcipher S2,S2,K
+ vcipher S3,S3,K
+ vcipher S4,S4,K
+ vcipher S5,S5,K
+ vcipher S6,S6,K
+ vcipher S7,S7,K
+ addi 10,10,0x10
+ bdnz L8x_round_loop
+
+ lxvd2x  KX,10,KEYS
+ vperm       K,K,K,swap_mask
+ vcipherlast S0,S0,K
+ vcipherlast S1,S1,K
+ vcipherlast S2,S2,K
+ vcipherlast S3,S3,K
+ vcipherlast S4,S4,K
+ vcipherlast S5,S5,K
+ vcipherlast S6,S6,K
+ vcipherlast S7,S7,K
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask
+ vperm S4,S4,S4,swap_mask
+ vperm S5,S5,S5,swap_mask
+ vperm S6,S6,S6,swap_mask
+ vperm S7,S7,S7,swap_mask&gt;)
+
+ stxvd2x S0X,0,DST
+ li  9,0x10
+ stxvd2x S1X,9,DST
+ addi  9,9,0x10
+ stxvd2x S2X,9,DST
+ addi   9,9,0x10
+ stxvd2x S3X,9,DST
+ addi   9,9,0x10
+ stxvd2x S4X,9,DST
+ addi   9,9,0x10
+ stxvd2x S5X,9,DST
+ addi   9,9,0x10
+ stxvd2x S6X,9,DST
+ addi   9,9,0x10
+ stxvd2x S7X,9,DST
+
+ addi   SRC,SRC,0x80
+ addi   DST,DST,0x80
+
+ clrldi LENGTH,LENGTH,61
+
+L4x:
+ srdi   5,LENGTH,2
+ cmpldi   5,0
+ beq   L2x
+
+ lxvd2x   KX,0,KEYS
+ vperm   K,K,K,swap_mask
+
+ lxvd2x S0X,0,SRC
+ li  9,0x10
+ lxvd2x S1X,9,SRC
+ addi   9,9,0x10
+ lxvd2x S2X,9,SRC
+ addi   9,9,0x10
+ lxvd2x S3X,9,SRC
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask&gt;)
+
+ vxor S0,S0,K
+ vxor S1,S1,K
+ vxor S2,S2,K
+ vxor S3,S3,K
+
+ mtctr ROUNDS
+ li 10,0x10
+.align 5
+L4x_round_loop:
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vcipher S0,S0,K
+ vcipher S1,S1,K
+ vcipher S2,S2,K
+ vcipher S3,S3,K
+ addi   10,10,0x10
+ bdnz  L4x_round_loop
+
+ lxvd2x KX,10,KEYS
+ vperm   K,K,K,swap_mask
+ vcipherlast S0,S0,K
+ vcipherlast S1,S1,K
+ vcipherlast S2,S2,K
+ vcipherlast S3,S3,K
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask
+ vperm S2,S2,S2,swap_mask
+ vperm S3,S3,S3,swap_mask&gt;)
+
+ stxvd2x S0X,0,DST
+ li  9,0x10
+ stxvd2x S1X,9,DST
+ addi   9,9,0x10
+ stxvd2x S2X,9,DST
+ addi  9,9,0x10
+ stxvd2x S3X,9,DST
+
+ addi   SRC,SRC,0x40
+ addi   DST,DST,0x40
+
+ clrldi LENGTH,LENGTH,62
+
+L2x:
+ srdi  5,LENGTH,1
+ cmpldi  5,0
+ beq   L1x
+
+ lxvd2x KX,0,KEYS
+ vperm K,K,K,swap_mask
+
+ lxvd2x S0X,0,SRC
+ li   9,0x10
+ lxvd2x S1X,9,SRC
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask&gt;)
+
+ vxor  S0,S0,K
+ vxor   S1,S1,K
+
+ mtctr   ROUNDS
+ li  10,0x10
+.align 5
+L2x_round_loop:
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vcipher S0,S0,K
+ vcipher S1,S1,K
+ addi   10,10,0x10
+ bdnz   L2x_round_loop
+
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vcipherlast S0,S0,K
+ vcipherlast S1,S1,K
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask
+ vperm S1,S1,S1,swap_mask&gt;)
+
+ stxvd2x S0X,0,DST
+ li  9,0x10
+ stxvd2x S1X,9,DST
+
+ addi   SRC,SRC,0x20
+ addi   DST,DST,0x20
+
+ clrldi LENGTH,LENGTH,63
+
+L1x:
+ cmpldi LENGTH,0
+ beq   Ldone
+
+ lxvd2x KX,0,KEYS
+ vperm   K,K,K,swap_mask
+
+ lxvd2x S0X,0,SRC
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask&gt;)
+
+ vxor   S0,S0,K
+
+ mtctr   ROUNDS
+ li   10,0x10
+.align 5
+L1x_round_loop:
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vcipher S0,S0,K
+ addi   10,10,0x10
+ bdnz   L1x_round_loop
+
+ lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+ vcipherlast S0,S0,K
+
+IF_LE(&lt;vperm S0,S0,S0,swap_mask&gt;)
+
+ stxvd2x S0X,0,DST
+
+Ldone:
+ blr
+EPILOGUE(_nettle_aes_encrypt)
+
+ .data
+ .align 4
+.swap_mask:
+IF_LE(&lt;.byte 8,9,10,11,12,13,14,15,0,1,2,3,4,5,6,7&gt;)
+IF_BE(&lt;.byte 3,2,1,0,7,6,5,4,11,10,9,8,15,14,13,12&gt;)
diff --git a/powerpc64/gcm-hash8.asm b/powerpc64/gcm-hash8.asm
new file mode 100644
index 00000000..fc9ce739
--- /dev/null
+++ b/powerpc64/gcm-hash8.asm
@@ -0,0 +1,1015 @@
+C powerpc64/gcm-hash8.asm
+
+ifelse(&lt;
+   Copyright (C) 2020 Mamone Tarsha
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+&gt;)
+
+C Register usage:
+C VSX instructions is used to load and store data to memory "lxvd2x,
stxvd2x"
+C instead of VR instructions "lvx, stvx" as a workaround to access
unaligned data
+C VSX registers are defined with "X" suffix
+
+define(&lt;SP&gt;, &lt;1&gt;)
+define(&lt;TOCP&gt;, &lt;2&gt;)
+
+define(&lt;TABLE&gt;, &lt;3&gt;)
+define(&lt;X&gt;, &lt;4&gt;)
+define(&lt;LENGTH&gt;, &lt;5&gt;)
+define(&lt;DATA&gt;, &lt;6&gt;)
+
+define(&lt;zero&gt;, &lt;0&gt;)
+define(&lt;swap_mask&gt;, &lt;1&gt;)
+define(&lt;hidw_mask&gt;, &lt;2&gt;)
+define(&lt;lodw_mask&gt;, &lt;3&gt;)
+define(&lt;poly&gt;, &lt;4&gt;)
+define(&lt;poly_h&gt;, &lt;4&gt;)
+define(&lt;poly_l&gt;, &lt;5&gt;)
+define(&lt;RP&gt;, &lt;6&gt;)
+define(&lt;Mh&gt;, &lt;7&gt;)
+define(&lt;Ml&gt;, &lt;8&gt;)
+define(&lt;H&gt;, &lt;9&gt;)
+define(&lt;Hh&gt;, &lt;10&gt;)
+define(&lt;Hl&gt;, &lt;11&gt;)
+define(&lt;RP2&gt;, &lt;9&gt;)
+define(&lt;M2h&gt;, &lt;10&gt;)
+define(&lt;M2l&gt;, &lt;11&gt;)
+
+define(&lt;HX&gt;, &lt;41&gt;)
+define(&lt;HhX&gt;, &lt;42&gt;)
+define(&lt;HlX&gt;, &lt;43&gt;)
+define(&lt;H_HhX&gt;, &lt;44&gt;)
+define(&lt;H_HX&gt;, &lt;45&gt;)
+define(&lt;H_HlX&gt;, &lt;46&gt;)
+
+define(&lt;sl1&gt;, &lt;1&gt;)
+define(&lt;msb&gt;, &lt;5&gt;)
+define(&lt;H2&gt;, &lt;6&gt;)
+define(&lt;H2h&gt;, &lt;7&gt;)
+define(&lt;H2l&gt;, &lt;8&gt;)
+define(&lt;H_h&gt;, &lt;12&gt;)
+define(&lt;H_m&gt;, &lt;13&gt;)
+define(&lt;H_l&gt;, &lt;14&gt;)
+define(&lt;H_Hh&gt;, &lt;12&gt;)
+define(&lt;H_H&gt;, &lt;13&gt;)
+define(&lt;H_Hl&gt;, &lt;14&gt;)
+define(&lt;H_t&gt;, &lt;15&gt;)
+define(&lt;H2_h&gt;, &lt;16&gt;)
+define(&lt;H2_m&gt;, &lt;17&gt;)
+define(&lt;H2_l&gt;, &lt;18&gt;)
+define(&lt;H2_t&gt;, &lt;19&gt;)
+
+define(&lt;C0X&gt;, &lt;38&gt;)
+define(&lt;C1X&gt;, &lt;39&gt;)
+define(&lt;C2X&gt;, &lt;40&gt;)
+define(&lt;C3X&gt;, &lt;44&gt;)
+define(&lt;C4X&gt;, &lt;38&gt;)
+define(&lt;C5X&gt;, &lt;39&gt;)
+define(&lt;C6X&gt;, &lt;40&gt;)
+define(&lt;C7X&gt;, &lt;44&gt;)
+
+define(&lt;CX&gt;, &lt;45&gt;)
+
+define(&lt;C0&gt;, &lt;6&gt;)
+define(&lt;C1&gt;, &lt;7&gt;)
+define(&lt;C2&gt;, &lt;8&gt;)
+define(&lt;C3&gt;, &lt;12&gt;)
+define(&lt;C4&gt;, &lt;6&gt;)
+define(&lt;C5&gt;, &lt;7&gt;)
+define(&lt;C6&gt;, &lt;8&gt;)
+define(&lt;C7&gt;, &lt;12&gt;)
+
+define(&lt;C&gt;, &lt;13&gt;)
+
+define(&lt;Ch&gt;, &lt;14&gt;)
+define(&lt;Cl&gt;, &lt;15&gt;)
+define(&lt;Cm&gt;, &lt;16&gt;)
+
+define(&lt;C01h&gt;, &lt;14&gt;)
+define(&lt;C01l&gt;, &lt;15&gt;)
+define(&lt;C01&gt;, &lt;16&gt;)
+define(&lt;C23h&gt;, &lt;17&gt;)
+define(&lt;C23l&gt;, &lt;18&gt;)
+define(&lt;C23&gt;, &lt;19&gt;)
+define(&lt;C45h&gt;, &lt;20&gt;)
+define(&lt;C45l&gt;, &lt;21&gt;)
+define(&lt;C45&gt;, &lt;22&gt;)
+define(&lt;C67h&gt;, &lt;6&gt;)
+define(&lt;C67l&gt;, &lt;7&gt;)
+define(&lt;C67&gt;, &lt;8&gt;)
+
+define(&lt;H21&gt;, &lt;9&gt;)
+define(&lt;H21h&gt;, &lt;10&gt;)
+define(&lt;H21l&gt;, &lt;11&gt;)
+define(&lt;H43&gt;, &lt;23&gt;)
+define(&lt;H43h&gt;, &lt;24&gt;)
+define(&lt;H43l&gt;, &lt;25&gt;)
+define(&lt;H65&gt;, &lt;26&gt;)
+define(&lt;H65h&gt;, &lt;27&gt;)
+define(&lt;H65l&gt;, &lt;28&gt;)
+define(&lt;H87&gt;, &lt;29&gt;)
+define(&lt;H87h&gt;, &lt;30&gt;)
+define(&lt;H87l&gt;, &lt;31&gt;)
+
+define(&lt;H21X&gt;, &lt;41&gt;)
+define(&lt;H21hX&gt;, &lt;42&gt;)
+define(&lt;H21lX&gt;, &lt;43&gt;)
+define(&lt;H43X&gt;, &lt;55&gt;)
+define(&lt;H43hX&gt;, &lt;56&gt;)
+define(&lt;H43lX&gt;, &lt;57&gt;)
+define(&lt;H65X&gt;, &lt;58&gt;)
+define(&lt;H65hX&gt;, &lt;59&gt;)
+define(&lt;H65lX&gt;, &lt;60&gt;)
+define(&lt;H87X&gt;, &lt;61&gt;)
+define(&lt;H87hX&gt;, &lt;62&gt;)
+define(&lt;H87lX&gt;, &lt;63&gt;)
+
+# gcm_fill registers:
+
+define(&lt;CTR&gt;, &lt;3&gt;)
+define(&lt;BLOCKS&gt;, &lt;4&gt;)
+define(&lt;BUFFER&gt;, &lt;5&gt;)
+
+define(&lt;CTR0&gt;, &lt;2&gt;)
+define(&lt;CTR0S&gt;, &lt;3&gt;)
+define(&lt;CTR1&gt;, &lt;4&gt;)
+define(&lt;CTR2&gt;, &lt;5&gt;)
+define(&lt;CTR3&gt;, &lt;6&gt;)
+define(&lt;CTR4&gt;, &lt;7&gt;)
+define(&lt;CTR5&gt;, &lt;8&gt;)
+define(&lt;CTR6&gt;, &lt;9&gt;)
+define(&lt;CTR7&gt;, &lt;10&gt;)
+
+define(&lt;CTR0X&gt;, &lt;34&gt;)
+define(&lt;CTR0SX&gt;, &lt;35&gt;)
+define(&lt;CTR1X&gt;, &lt;36&gt;)
+define(&lt;CTR2X&gt;, &lt;37&gt;)
+define(&lt;CTR3X&gt;, &lt;38&gt;)
+define(&lt;CTR4X&gt;, &lt;39&gt;)
+define(&lt;CTR5X&gt;, &lt;40&gt;)
+define(&lt;CTR6X&gt;, &lt;41&gt;)
+define(&lt;CTR7X&gt;, &lt;42&gt;)
+
+define(&lt;I1&gt;, &lt;11&gt;)
+define(&lt;I2&gt;, &lt;12&gt;)
+define(&lt;I3&gt;, &lt;13&gt;)
+define(&lt;I4&gt;, &lt;14&gt;)
+define(&lt;I5&gt;, &lt;15&gt;)
+define(&lt;I6&gt;, &lt;16&gt;)
+define(&lt;I7&gt;, &lt;17&gt;)
+define(&lt;I8&gt;, &lt;18&gt;)
+
+.file "gcm-hash8.asm"
+
+.machine "any"
+
+IF_LE(&lt;.abiversion 2&gt;)
+.text
+
+ # void gcm_init_key (union gcm_block *table)
+
+IF_LE(&lt;.align 5&gt;)
+PROLOGUE(_nettle_gcm_init_key8)
+IF_LE(&lt;.localentry _nettle_gcm_init_key8,0&gt;)
+
+ ld     7,.polynomial@got(TOCP)
+ lvx   poly,0,7
+IF_LE(&lt;ld 7,.swap_mask@got(TOCP)
+ lvx   swap_mask,0,7&gt;)
+ ld     7,.hidw_mask@got(TOCP)
+ lvx     hidw_mask,0,7
+ ld     7,.lodw_mask@got(TOCP)
+ lvx   lodw_mask,0,7
+
+ li    10,0x800
+  lxvd2x HX,10,TABLE # load H
+IF_LE(&lt;vperm H,H,H,swap_mask&gt;)
+
+ # --- calculate H = H shift left 1 modulo polynomial ---
+
+ vupkhsw    msb,H # most significant bit word-extend
+ vspltisb sl1,1 # splat 1 for shift left
+ vspltw      msb,msb,0 # most significant bit extend
+ vsl    H,H,sl1 # H shift left 1
+ vand msb,msb,poly
+ vxor zero,zero,zero
+ vxor H_t,H,msb
+
+ vsldoi H,H_t,H_t,8 # doubleword swap
+ vsldoi Hh,H,zero,8
+ vsldoi Hl,zero,H,8
+
+ # --- calculate H^2 = H*H ---
+
+ # reduction pre-processing
+ vsldoi poly_h,zero,poly,8
+ vsldoi poly_l,poly_h,poly_h,8
+
+ # polynomial multiplication "classical"
+ vpmsumd H_h,H_t,Hh # H^1h*H^1h
+ vpmsumd H_l,H_t,Hl # H^1l*H^1l
+ vpmsumd H_m,H_t,H # H^1h*H^1l⊕H^1l*H^1h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h   # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8   # [2]
+ vsldoi Ml,H_m,zero,8 # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor H_h,H_h,Mh       # [2]
+ vxor H_l,H_l,Ml       # [2]
+ vxor H_l,H_l,RP       # [1]
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l
+ vxor H_h,H_l,H_h
+ vxor H2_t,H_h,RP
+
+ vsldoi H2,H2_t,H2_t,8
+ vsldoi H2h,H2,zero,8
+ vsldoi H2l,zero,H2,8
+
+ # --- calculate [H^2.Hi⊕H^2.Lo:H^1.Hi⊕H^1.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store H,[H^2.Hi⊕H^2.Lo:H^1.Hi⊕H^1.Lo] ---
+
+ li    8,0x00
+ li    9,0x100
+ li    10,0x200
+ stxvd2x HlX,8,TABLE
+ stxvd2x HX,9,TABLE
+ stxvd2x HhX,10,TABLE
+
+ li    8,0x300
+ li    9,0x400
+ li    10,0x500
+ stxvd2x H_HhX,8,TABLE
+ stxvd2x H_HX,9,TABLE
+ stxvd2x H_HlX,10,TABLE
+
+ # --- calculate H^3,H^4 ---
+
+ # polynomial multiplication "classical"
+ vpmsumd H_l,H_t,H2l # H^1l*H^2l
+ vpmsumd H_m,H_t,H2 # H^1h*H^2l⊕H^1l*H^2h
+ vpmsumd H_h,H_t,H2h # H^1h*H^2h
+ vpmsumd H2_l,H2_t,H2l # H^2l*H^2l
+ vpmsumd H2_m,H2_t,H2 # H^2h*H^2l⊕H^2l*H^2h
+ vpmsumd H2_h,H2_t,H2h # H^2h*H^2h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h # [1] H^3
+ vpmsumd    RP2,H2_l,poly_h # [1] H^4
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8 # [2] H^3
+ vsldoi M2h,zero,H2_m,8 # [2] H^4
+ vsldoi Ml,H_m,zero,8 # [2] H^3
+ vsldoi M2l,H2_m,zero,8 # [2] H^4
+ vsldoi RP,RP,RP,8 # [1] H^3
+ vsldoi RP2,RP2,RP2,8 # [1] H^4
+ vxor H_h,H_h,Mh # [2] H^3
+ vxor H2_h,H2_h,M2h # [2] H^4
+ vxor H_l,H_l,Ml # [2] H^3
+ vxor H2_l,H2_l,M2l # [2] H^4
+ vxor H_l,H_l,RP # [1] H^3
+ vxor H2_l,H2_l,RP2 # [1] H^4
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l # H^3
+ vpmsumd RP2,H2_l,poly_l # H^4
+ vxor H_h,H_l,H_h # H^3
+ vxor H2_h,H2_l,H2_h # H^4
+ vxor H_h,H_h,RP # H^3
+ vxor H2_h,H2_h,RP2 # H^4
+
+ vsldoi H2,H2_h,H2_h,8 # H^4
+ vsldoi H,H_h,H_h,8 # H^3
+ vsldoi H2l,zero,H2,8 # H^4
+ vsldoi H2h,H2,zero,8 # H^4
+
+ # --- calculate [H^4.Hi⊕H^4.Lo:H^3.Hi⊕H^3.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store [H^4.Hi⊕H^4.Lo:H^3.Hi⊕H^3.Lo] ---
+
+ li    8,0x600
+ li    9,0x700
+ li    10,0x800
+ stxvd2x H_HhX,8,TABLE
+ stxvd2x H_HX,9,TABLE
+ stxvd2x H_HlX,10,TABLE
+
+ # --- calculate H^5,H^6 ---
+
+ # polynomial multiplication "classical"
+ vpmsumd H_l,H_t,H2l # H^1l*H^4l
+ vpmsumd H_m,H_t,H2 # H^1h*H^4l⊕H^1l*H^4h
+ vpmsumd H_h,H_t,H2h # H^1h*H^4h
+ vpmsumd H2_l,H2_t,H2l # H^2l*H^4l
+ vpmsumd H2_m,H2_t,H2 # H^2h*H^4l⊕H^2l*H^4h
+ vpmsumd H2_h,H2_t,H2h # H^2h*H^4h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h # [1] H^5
+ vpmsumd    RP2,H2_l,poly_h # [1] H^6
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8 # [2] H^5
+ vsldoi M2h,zero,H2_m,8 # [2] H^6
+ vsldoi Ml,H_m,zero,8 # [2] H^5
+ vsldoi M2l,H2_m,zero,8 # [2] H^6
+ vsldoi RP,RP,RP,8 # [1] H^5
+ vsldoi RP2,RP2,RP2,8 # [1] H^6
+ vxor H_h,H_h,Mh # [2] H^5
+ vxor H2_h,H2_h,M2h # [2] H^6
+ vxor H_l,H_l,Ml # [2] H^5
+ vxor H2_l,H2_l,M2l # [2] H^6
+ vxor H_l,H_l,RP # [1] H^5
+ vxor H2_l,H2_l,RP2 # [1] H^6
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l # H^5
+ vpmsumd RP2,H2_l,poly_l # H^6
+ vxor H_h,H_l,H_h # H^5
+ vxor H2_h,H2_l,H2_h # H^6
+ vxor H_h,H_h,RP # H^5
+ vxor H2_h,H2_h,RP2 # H^6
+
+ vsldoi H2,H2_h,H2_h,8 # H^6
+ vsldoi H,H_h,H_h,8 # H^5
+ vsldoi H2l,zero,H2,8 # H^6
+ vsldoi H2h,H2,zero,8 # H^6
+
+ # --- calculate [H^6.Hi⊕H^6.Lo:H^5.Hi⊕H^5.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store [H^6.Hi⊕H^6.Lo:H^5.Hi⊕H^5.Lo] ---
+
+ li    8,0x900
+ li    9,0xA00
+ li    10,0xB00
+ stxvd2x H_HhX,8,TABLE
+ stxvd2x H_HX,9,TABLE
+ stxvd2x H_HlX,10,TABLE
+
+ # --- calculate H^7,H^8 ---
+
+ # polynomial multiplication "classical"
+ vpmsumd H_l,H_t,H2l # H^1l*H^6l
+ vpmsumd H_m,H_t,H2 # H^1h*H^6l⊕H^1l*H^6h
+ vpmsumd H_h,H_t,H2h # H^1h*H^6h
+ vpmsumd H2_l,H2_t,H2l # H^2l*H^6l
+ vpmsumd H2_m,H2_t,H2 # H^2h*H^6l⊕H^2l*H^6h
+ vpmsumd H2_h,H2_t,H2h # H^2h*H^6h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h # [1] H^7
+ vpmsumd    RP2,H2_l,poly_h # [1] H^8
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8 # [2] H^7
+ vsldoi M2h,zero,H2_m,8 # [2] H^8
+ vsldoi Ml,H_m,zero,8 # [2] H^7
+ vsldoi M2l,H2_m,zero,8 # [2] H^8
+ vsldoi RP,RP,RP,8 # [1] H^7
+ vsldoi RP2,RP2,RP2,8 # [1] H^8
+ vxor H_h,H_h,Mh # [2] H^7
+ vxor H2_h,H2_h,M2h # [2] H^8
+ vxor H_l,H_l,Ml # [2] H^7
+ vxor H2_l,H2_l,M2l # [2] H^8
+ vxor H_l,H_l,RP # [1] H^7
+ vxor H2_l,H2_l,RP2 # [1] H^8
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l # H^7
+ vpmsumd RP2,H2_l,poly_l # H^8
+ vxor H_h,H_l,H_h # H^7
+ vxor H2_h,H2_l,H2_h # H^8
+ vxor H_h,H_h,RP # H^7
+ vxor H2_h,H2_h,RP2 # H^8
+
+ vsldoi H,H_h,H_h,8 # H^7
+ vsldoi H2,H2_h,H2_h,8 # H^8
+
+ # --- calculate [H^8.Hi⊕H^8.Lo:H^7.Hi⊕H^7.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store [H^8.Hi⊕H^8.Lo:H^7.Hi⊕H^7.Lo] ---
+
+ li    8,0xC00
+ li    9,0xD00
+ li    10,0xE00
+ stxvd2x H_HhX,8,TABLE
+ stxvd2x H_HX,9,TABLE
+ stxvd2x H_HlX,10,TABLE
+
+  blr
+EPILOGUE(_nettle_gcm_init_key8)
+
+ # void gcm_hash (const struct gcm_key *key, union gcm_block *x,
+ #                size_t length, const uint8_t *data)
+
+IF_LE(&lt;.align 5&gt;)
+PROLOGUE(_nettle_gcm_hash8)
+IF_LE(&lt;.localentry _nettle_gcm_hash8,0&gt;)
+
+  vxor zero,zero,zero
+
+ ld     7,.polynomial@got(TOCP)
+ lvx   poly,0,7
+IF_LE(&lt;ld 7,.swap_mask@got(TOCP)
+ lvx   swap_mask,0,7&gt;)
+ ld      7,.hidw_mask@got(TOCP)
+ lvx     hidw_mask,0,7
+ ld     7,.lodw_mask@got(TOCP)
+ lvx   lodw_mask,0,7
+
+ vsldoi poly_h,zero,poly,8
+ vsldoi poly_l,poly_h,poly_h,8
+
+ lxvd2x CX,0,X # load X
+IF_LE(&lt;vperm C,C,C,swap_mask&gt;)
+
+ srdi 7,LENGTH,7 # 8x loop count
+ cmpldi 7,0
+ beq L2x
+
+ # backup registers
+ stdu SP,-224(SP)
+ std 28,216(SP)
+ std 29,208(SP)
+ std 30,200(SP)
+ std 31,192(SP)
+    li 8,176
+    stvx 20,8,SP
+    subi 8,8,16
+    stvx 21,8,SP
+    subi 8,8,16
+    stvx 22,8,SP
+    subi 8,8,16
+    stvx 23,8,SP
+    subi 8,8,16
+    stvx 24,8,SP
+    subi 8,8,16
+    stvx 25,8,SP
+    subi 8,8,16
+    stvx 26,8,SP
+    subi 8,8,16
+    stvx 27,8,SP
+    subi 8,8,16
+    stvx 28,8,SP
+    subi 8,8,16
+    stvx 29,8,SP
+    subi 8,8,16
+    stvx 30,8,SP
+    subi 8,8,16
+    stvx 31,8,SP
+
+ # table loading
+ li 8,0x300
+ li 9,0x400
+ li 10,0x500
+ lxvd2x H21hX,8,TABLE
+ lxvd2x H21X,9,TABLE
+ lxvd2x H21lX,10,TABLE
+ li 8,0x600
+ li 9,0x700
+ li 10,0x800
+ lxvd2x H43hX,8,TABLE
+ lxvd2x H43X,9,TABLE
+ lxvd2x H43lX,10,TABLE
+ li 8,0x900
+ li 9,0xA00
+ li 10,0xB00
+ lxvd2x H65hX,8,TABLE
+ lxvd2x H65X,9,TABLE
+ lxvd2x H65lX,10,TABLE
+ li 8,0xC00
+ li 9,0xD00
+ li 10,0xE00
+ lxvd2x H87hX,8,TABLE
+ lxvd2x H87X,9,TABLE
+ lxvd2x H87lX,10,TABLE
+
+ li 8,0x10
+ li 9,0x20
+ li 10,0x30
+ li 28,0x40
+ li 29,0x50
+ li 30,0x60
+ li 31,0x70
+
+ mtctr     7
+.align 5
+L8x_loop:
+ # input loading
+ lxvd2x C0X,0,DATA # load C0
+ lxvd2x C1X,8,DATA # load C1
+ lxvd2x C2X,9,DATA # load C2
+ lxvd2x C3X,10,DATA # load C3
+
+ # swap permuting
+IF_LE(&lt;vperm C0,C0,C0,swap_mask
+ vperm C1,C1,C1,swap_mask
+ vperm C2,C2,C2,swap_mask
+ vperm C3,C3,C3,swap_mask&gt;)
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ # polynomial multiplication "karatsuba" pre-processing
+ vperm C23h,C2,C3,hidw_mask
+ vperm C23l,C2,C3,lodw_mask
+ vperm C01h,C0,C1,hidw_mask
+ vperm C01l,C0,C1,lodw_mask
+
+ # input loading
+ lxvd2x C4X,28,DATA # load C4
+ lxvd2x C5X,29,DATA # load C5
+ lxvd2x C6X,30,DATA # load C6
+ lxvd2x C7X,31,DATA # load C7
+
+ # swap permuting
+IF_LE(&lt;vperm C4,C4,C4,swap_mask
+ vperm C5,C5,C5,swap_mask
+ vperm C6,C6,C6,swap_mask
+ vperm C7,C7,C7,swap_mask&gt;)
+
+ # polynomial multiplication "karatsuba" pre-processing
+ vperm C45h,C4,C5,hidw_mask
+ vperm C45l,C4,C5,lodw_mask
+ vperm C67h,C6,C7,hidw_mask
+ vperm C67l,C6,C7,lodw_mask
+ vxor C23,C23h,C23l
+ vxor C01,C01h,C01l
+ vxor C45,C45h,C45l
+ vxor C67,C67h,C67l
+
+ # polynomial multiplication "karatsuba"
+ vpmsumd C23h,C23h,H65h # H23 = H^6h*C2h⊕H^5h*C3h
+ vpmsumd C23l,C23l,H65l # L23 = H^6l*C2l⊕H^5l*C3l
+ vpmsumd C01h,C01h,H87h # H01 = H^8h*C0h⊕H^7h*C1h
+ vpmsumd C01l,C01l,H87l # L01 = H^8l*C0l⊕H^7l*C1l
+ vpmsumd C67h,C67h,H21h # H67 = H^2h*C6h⊕H^1h*C7h
+ vpmsumd C67l,C67l,H21l # L67 = H^2l*C6l⊕H^1l*C7l
+ vpmsumd C45h,C45h,H43h # H45 = H^4h*C4h⊕H^3h*C5h
+ vpmsumd C45l,C45l,H43l # L45 = H^4l*C4l⊕H^3l*C5l
+ vpmsumd C23,C23,H65 # M23 = (H^6h⊕H^5h)*(C2h⊕C3h)⊕(H^6l⊕H^5l)*(C2l⊕C3l)
+ vpmsumd C01,C01,H87 # M01 = (H^8h⊕H^7h)*(C0h⊕C1h)⊕(H^8l⊕H^7l)*(C0l⊕C1l)
+ vpmsumd C45,C45,H43 # M45 = (H^4h⊕H^3h)*(C4h⊕C5h)⊕(H^4l⊕H^3l)*(C4l⊕C5l)
+ vpmsumd C67,C67,H21 # M67 = (H^2h⊕H^1h)*(C6h⊕C7h)⊕(H^2l⊕H^1l)*(C6l⊕C7l)
+
+ # polynomial multiplication "karatsuba" post-processing
+ vxor C23,C23,C23h
+ vxor C01,C01,C01h
+ vxor C45,C45,C45h
+ vxor C67,C67,C67h
+ vxor C23,C23,C23l
+ vxor C01,C01,C01l
+ vxor C45,C45,C45l
+ vxor C67,C67,C67l
+
+ # deferred recombination of partial products
+ vxor C01h,C01h,C23h # H0 = H01⊕H23
+ vxor C45h,C45h,C67h # H1 = H45⊕H67
+ vxor C01l,C01l,C23l # L0 = L01⊕L23
+ vxor C45l,C45l,C67l # L1 = L45⊕L45
+ vxor C01,C01,C23 # M0 = M01⊕M23
+ vxor C45,C45,C67 # M1 = M45⊕M45
+ vxor C01h,C01h,C45h # H = H0⊕H1
+ vxor C01l,C01l,C45l # L = L0⊕L1
+ vxor C01,C01,C45 # M = M0⊕M1
+
+ # reduction first phase # [1]
+ vpmsumd RP,C01l,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,C01,8   # [2]
+ vsldoi Ml,C01,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor C01h,C01h,Mh     # [2]
+ vxor C01l,C01l,Ml     # [2]
+ vxor C01l,C01l,RP     # [1]
+
+ # reduction second phase
+ vpmsumd RP,C01l,poly_l
+ vxor C01h,C01l,C01h
+ vxor C,C01h,RP
+
+ addi DATA,DATA,0x80
+ bdnz L8x_loop
+
+    # restore registers
+ li 8,0
+    lvx 31,8,SP
+    addi 8,8,16
+    lvx 30,8,SP
+    addi 8,8,16
+    lvx 29,8,SP
+    addi 8,8,16
+    lvx 28,8,SP
+    addi 8,8,16
+    lvx 27,8,SP
+    addi 8,8,16
+    lvx 26,8,SP
+    addi 8,8,16
+    lvx 25,8,SP
+    addi 8,8,16
+    lvx 24,8,SP
+    addi 8,8,16
+    lvx 23,8,SP
+    addi 8,8,16
+    lvx 22,8,SP
+    addi 8,8,16
+    lvx 21,8,SP
+    addi 8,8,16
+    lvx 20,8,SP
+ ld 31,192(SP)
+ ld 30,200(SP)
+ ld 29,208(SP)
+ ld 28,216(SP)
+ addi SP,SP,224
+
+ clrldi   LENGTH,LENGTH,57
+L2x:
+ srdi 7,LENGTH,5
+ cmpldi 7,0
+ beq L1x
+
+ # table loading
+ li 8,0x300
+ li 9,0x400
+ li 10,0x500
+ lxvd2x H21hX,8,TABLE
+ lxvd2x H21X,9,TABLE
+ lxvd2x H21lX,10,TABLE
+
+ li 10,0x10
+
+ mtctr     7
+.align 5
+L2x_loop:
+ # input loading
+ lxvd2x C0X,0,DATA # load C0
+ lxvd2x C1X,10,DATA # load C1
+
+ # swap permuting
+IF_LE(&lt;vperm C0,C0,C0,swap_mask
+ vperm C1,C1,C1,swap_mask&gt;)
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ # polynomial multiplication "karatsuba" pre-processing
+ vperm C01h,C0,C1,hidw_mask
+ vperm C01l,C0,C1,lodw_mask
+ vxor C01,C01h,C01l
+
+ # polynomial multiplication "karatsuba"
+ vpmsumd C01h,C01h,H21h # H01 = H^2h*C0h⊕H^1h*C1h
+ vpmsumd C01l,C01l,H21l # L01 = H^2l*C0l⊕H^1l*C1l
+ vpmsumd C01,C01,H21 # M01 = (H^2h⊕H^1h)*(C0h⊕C1h)⊕(H^2l⊕H^1l)*(C0l⊕C1l)
+
+ # polynomial multiplication "karatsuba" post-processing
+ vxor C01,C01,C01h
+ vxor C01,C01,C01l
+
+ # reduction first phase # [1]
+ vpmsumd RP,C01l,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,C01,8   # [2]
+ vsldoi Ml,C01,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor C01h,C01h,Mh     # [2]
+ vxor C01l,C01l,Ml     # [2]
+ vxor C01l,C01l,RP     # [1]
+
+ # reduction second phase
+ vpmsumd RP,C01l,poly_l
+ vxor C01h,C01l,C01h
+ vxor C,C01h,RP
+
+ addi DATA,DATA,0x20
+ bdnz L2x_loop
+
+ clrldi   LENGTH,LENGTH,59
+L1x:
+ srdi 7,LENGTH,4
+ cmpldi 7,0
+ beq Lrem
+
+ # table loading
+ li 9,0x100
+ li 10,0x200
+ lxvd2x HlX,0,TABLE
+ lxvd2x HX, 9,TABLE
+ lxvd2x HhX,10,TABLE
+
+ # input loading
+ lxvd2x C0X,0,DATA # load C0
+
+ # swap permuting
+IF_LE(&lt;vperm C0,C0,C0,swap_mask&gt;)
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ vpmsumd Cl,C0,Hl # L = Hl*Cl
+ vpmsumd Cm,C0,H # M = Hh*Cl⊕Hl*Ch
+ vpmsumd Ch,C0,Hh # H = Hh*Ch
+
+ # reduction first phase # [1]
+ vpmsumd RP,Cl,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,Cm,8   # [2]
+ vsldoi Ml,Cm,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor Ch,Ch,Mh   # [2]
+ vxor Cl,Cl,Ml       # [2]
+ vxor Cl,Cl,RP   # [1]
+
+ # reduction second phase
+ vpmsumd RP,Cl,poly_l
+ vxor Ch,Cl,Ch
+ vxor C,Ch,RP
+
+ addi DATA,DATA,0x10
+ clrldi   LENGTH,LENGTH,60
+Lrem:
+ cmpldi LENGTH,0
+ beq Ldone
+
+ # table loading
+ li 9,0x100
+ li 10,0x200
+ lxvd2x HlX,0,TABLE
+ lxvd2x HX, 9,TABLE
+ lxvd2x HhX,10,TABLE
+
+ # input loading
+ stdu SP,-16(SP)
+ stvx zero,0,SP
+Lst_loop:
+ subic.      LENGTH,LENGTH,1
+ lbzx 7,LENGTH,DATA
+ stbx 7,LENGTH,SP
+ bne Lst_loop
+ lxvd2x   C0X,0,SP
+ addi SP,SP,16
+
+ # swap permuting
+IF_LE(&lt;vperm C0,C0,C0,swap_mask&gt;)
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ vpmsumd Cl,C0,Hl # L = Hl*Cl
+ vpmsumd Cm,C0,H # M = Hh*Cl⊕Hl*Ch
+ vpmsumd Ch,C0,Hh # H = Hh*Ch
+
+ # reduction first phase # [1]
+ vpmsumd RP,Cl,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,Cm,8   # [2]
+ vsldoi Ml,Cm,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor Ch,Ch,Mh   # [2]
+ vxor Cl,Cl,Ml     # [2]
+ vxor Cl,Cl,RP   # [1]
+
+ # reduction second phase
+ vpmsumd RP,Cl,poly_l
+ vxor Ch,Cl,Ch
+ vxor C,Ch,RP
+
+Ldone:
+IF_LE(&lt;vperm C,C,C,swap_mask&gt;)
+ stxvd2x CX,0,X # store C
+ blr
+EPILOGUE(_nettle_gcm_hash8)
+
+ # gcm_fill (uint8_t *ctr, size_t blocks, union gcm_block *buffer)
+
+IF_LE(&lt;.align 5&gt;)
+PROLOGUE(_nettle_gcm_fill)
+IF_LE(&lt;.localentry _nettle_gcm_fill,0&gt;)
+
+IF_LE(&lt;ld 6,.swap_mask@got(TOCP)
+ lvx swap_mask,0,6&gt;)
+
+ vxor zero,zero,zero
+ vspltisb I1,1
+ vspltisb I2,2
+ vspltisb I3,3
+ vspltisb I4,4
+ vspltisb I5,5
+ vspltisb I6,6
+ vspltisb I7,7
+ vspltisb I8,8
+ vsldoi I1,zero,I1,1
+ vsldoi I2,zero,I2,1
+ vsldoi I3,zero,I3,1
+ vsldoi I4,zero,I4,1
+ vsldoi I5,zero,I5,1
+ vsldoi I6,zero,I6,1
+ vsldoi I7,zero,I7,1
+ vsldoi I8,zero,I8,1
+
+ lxvd2x CTR0X,0,CTR
+ IF_LE(&lt;vperm CTR0,CTR0,CTR0,swap_mask&gt;)
+
+ srdi 6,BLOCKS,3 # 8x loop count
+ cmpldi 6,0
+ beq Lfill_4x
+
+ std 25,-56(SP);
+ std 26,-48(SP);
+ std 27,-40(SP);
+ std 28,-32(SP);
+ std 29,-24(SP);
+ std 30,-16(SP);
+ std 31,-8(SP);
+
+ li 25,0x10
+ li 26,0x20
+ li 27,0x30
+ li 28,0x40
+ li 29,0x50
+ li 30,0x60
+ li 31,0x70
+
+ mtctr 6
+ L8x_fill_loop:
+ vadduwm CTR1,CTR0,I1
+ vadduwm CTR2,CTR0,I2
+ vadduwm CTR3,CTR0,I3
+ vadduwm CTR4,CTR0,I4
+ vadduwm CTR5,CTR0,I5
+ vadduwm CTR6,CTR0,I6
+ vadduwm CTR7,CTR0,I7
+
+ IF_LE(&lt;vperm CTR0S,CTR0,CTR0,swap_mask
+ vperm CTR1,CTR1,CTR1,swap_mask
+ vperm CTR2,CTR2,CTR2,swap_mask
+ vperm CTR3,CTR3,CTR3,swap_mask
+ vperm CTR4,CTR4,CTR4,swap_mask
+ vperm CTR5,CTR5,CTR5,swap_mask
+ vperm CTR6,CTR6,CTR6,swap_mask
+ vperm CTR7,CTR7,CTR7,swap_mask&gt;)
+
+ IF_LE(&lt;stxvd2x CTR0SX,0,BUFFER&gt;)
+ IF_BE(&lt;stxvd2x CTR0X,0,BUFFER&gt;)
+ stxvd2x CTR1X,25,BUFFER
+ stxvd2x CTR2X,26,BUFFER
+ stxvd2x CTR3X,27,BUFFER
+ stxvd2x CTR4X,28,BUFFER
+ stxvd2x CTR5X,29,BUFFER
+ stxvd2x CTR6X,30,BUFFER
+ stxvd2x CTR7X,31,BUFFER
+
+ vadduwm CTR0,CTR0,I8
+ addi BUFFER,BUFFER,0x80
+ bdnz L8x_fill_loop
+
+ ld 25,-56(SP);
+ ld 26,-48(SP);
+ ld 27,-40(SP);
+ ld 28,-32(SP);
+ ld 29,-24(SP);
+ ld 30,-16(SP);
+ ld 31,-8(SP);
+
+ clrldi BLOCKS,BLOCKS,61
+
+ Lfill_4x:
+ srdi 6,BLOCKS,2
+ cmpldi 6,0
+ beq Lfill_2x
+
+ li 8,0x10
+ li 9,0x20
+ li 10,0x30
+
+ vadduwm CTR1,CTR0,I1
+ vadduwm CTR2,CTR0,I2
+ vadduwm CTR3,CTR0,I3
+
+ IF_LE(&lt;vperm CTR0S,CTR0,CTR0,swap_mask
+ vperm CTR1,CTR1,CTR1,swap_mask
+ vperm CTR2,CTR2,CTR2,swap_mask
+ vperm CTR3,CTR3,CTR3,swap_mask&gt;)
+
+ IF_LE(&lt;stxvd2x CTR0SX,0,BUFFER&gt;)
+ IF_BE(&lt;stxvd2x CTR0X,0,BUFFER&gt;)
+ stxvd2x CTR1X,8,BUFFER
+ stxvd2x CTR2X,9,BUFFER
+ stxvd2x CTR3X,10,BUFFER
+
+ vadduwm CTR0,CTR0,I4
+ addi BUFFER,BUFFER,0x40
+
+ clrldi BLOCKS,BLOCKS,62
+
+ Lfill_2x:
+ srdi 6,BLOCKS,1
+ cmpldi 6,0
+ beq Lfill_1x
+
+ li 10,0x10
+
+ vadduwm CTR1,CTR0,I1
+
+ IF_LE(&lt;vperm CTR0S,CTR0,CTR0,swap_mask
+ vperm CTR1,CTR1,CTR1,swap_mask&gt;)
+
+ IF_LE(&lt;stxvd2x CTR0SX,0,BUFFER&gt;)
+ IF_BE(&lt;stxvd2x CTR0X,0,BUFFER&gt;)
+ stxvd2x CTR1X,10,BUFFER
+
+ vadduwm CTR0,CTR0,I2
+ addi BUFFER,BUFFER,0x20
+
+ clrldi BLOCKS,BLOCKS,63
+
+ Lfill_1x:
+ cmpldi BLOCKS,0
+ beq Lfill_done
+
+ IF_LE(&lt;vperm CTR0S,CTR0,CTR0,swap_mask&gt;)
+
+ IF_LE(&lt;stxvd2x CTR0SX,0,BUFFER&gt;)
+ IF_BE(&lt;stxvd2x CTR0X,0,BUFFER&gt;)
+
+ vadduwm CTR0,CTR0,I1
+
+ Lfill_done:
+ IF_LE(&lt;vperm CTR0,CTR0,CTR0,swap_mask&gt;)
+ stxvd2x CTR0X,0,CTR
+
+ blr
+EPILOGUE(_nettle_gcm_fill)
+
+    .data
+IF_LE(&lt;.align 4
+.polynomial:
+ .byte 1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0xc2
+    .align 4
+.swap_mask:
+ .byte 8,9,10,11,12,13,14,15,0,1,2,3,4,5,6,7
+    .align 4
+.hidw_mask:
+ .byte 23,22,21,20,19,18,17,16,7,6,5,4,3,2,1,0
+    .align 4
+.lodw_mask:
+ .byte 31,30,29,28,27,26,25,24,15,14,13,12,11,10,9,8&gt;)
+IF_BE(&lt;.align 4
+.polynomial:
+ .byte 0xc2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
+    .align 4
+.hidw_mask:
+ .byte 0,1,2,3,4,5,6,7,16,17,18,19,20,21,22,23
+    .align 4
+.lodw_mask:
+ .byte 8,9,10,11,12,13,14,15,24,25,26,27,28,29,30,31&gt;)
diff --git a/powerpc64/machine.m4 b/powerpc64/machine.m4
new file mode 100644
index 00000000..e69de29b
diff --git a/testsuite/gcm-test.c b/testsuite/gcm-test.c
index c8174019..df1fc94a 100644
--- a/testsuite/gcm-test.c
+++ b/testsuite/gcm-test.c
@@ -170,6 +170,29 @@ test_main(void)
  "16aedbf5a0de6a57a637b39b"),
     SHEX("619cc5aefffe0bfa462af43c1699d050"));

+  /* Test 128 bytes */
+  test_aead(&amp;nettle_gcm_aes128, NULL,
+    SHEX("feffe9928665731c6d6a8f9467308308"),
+    SHEX(""),
+    SHEX("d9313225f88406e5a55909c5aff5269a"
+ "86a7a9531534f7da2e4c303d8a318a72"
+ "1c3c0c95956809532fcf0e2449a6b525"
+ "b16aedf5aa0de657ba637b391aafd255"
+ "5ae376bc5e9f6a1b08e34db7a6ee0736"
+ "9ba662ea12f6f197e6bc3ed69d2480f3"
+ "ea5691347f2ba69113eb37910ebc18c8"
+ "0f697234582016fa956ca8f63ae6b473"),
+    SHEX("42831ec2217774244b7221b784d0d49c"
+ "e3aa212f2c02a4e035c17e2329aca12e"
+ "21d514b25466931c7d8f6a5aac84aa05"
+ "1ba30b396a0aac973d58e091473f5985"
+ "874b1178906ddbeab04ab2fe6cce8c57"
+ "8d7e961bd13fd6a8c56b66ca5e576492"
+ "1a48cd8bda04e66343e73055118b69b9"
+ "ced486813846958a11e602c03cfc232b"),
+    SHEX("cafebabefacedbaddecaf888"),
+    SHEX("796836f1246c9d735c5e1be0a715ccc3"));
+
   /* Test case 7 */
   test_aead(&amp;nettle_gcm_aes192, NULL,
     SHEX("00000000000000000000000000000000"
-- 
2.17.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200630092910</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-06-30 09:29:10-0400</timestampReceived><subject>Re: [Patch] Optimize AES and GHASH for PowerPC64 (support little-endian and big-endian)</subject><body>

On Tue, Jun 30, 2020 at 5:14 AM Maamoun TK &lt;maamoun.tk@googlemail.com&gt; wrote:
&gt;
&gt; Patch implementation benchmark for GCM_AES (Tested on POWER8):
&gt; little-endian:
&gt; - Encrypt x~17.5 of nettle C implementation
&gt; - Decrypt x~17.5 of nettle C implementation
&gt; - Update x~30 of nettle C implementation
&gt; big-endian:
&gt; - Encrypt x~18.5 of nettle C implementation
&gt; - Decrypt x~18.5 of nettle C implementation
&gt; - Update x~28.5 of nettle C implementation
...

One small comment for aes_encrypt and aes_decrypt... src and dst are
usually user supplied buffers. Using lxvd2x to load a vector may
produce incorrect results if the user is feeding a stream to an
encryptor or decryptor that is not naturally aligned to that of an
unsigned int. (On the other hand, Nettle controls the round keys array
so lxvd2x should be fine.)

Instead of lxvd2x and friends for the user's buffers you should
consider using lvx and doing the lvsl thing to fix the data in the
registers.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200630093508</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-06-30 09:35:08-0400</timestampReceived><subject>Re: [Patch] Optimize AES and GHASH for PowerPC64 (support little-endian and big-endian)</subject><body>

On Tue, Jun 30, 2020 at 5:29 AM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:
&gt;
&gt; On Tue, Jun 30, 2020 at 5:14 AM Maamoun TK &lt;maamoun.tk@googlemail.com&gt; wrote:
&gt; &gt;
&gt; &gt; Patch implementation benchmark for GCM_AES (Tested on POWER8):
&gt; &gt; little-endian:
&gt; &gt; - Encrypt x~17.5 of nettle C implementation
&gt; &gt; - Decrypt x~17.5 of nettle C implementation
&gt; &gt; - Update x~30 of nettle C implementation
&gt; &gt; big-endian:
&gt; &gt; - Encrypt x~18.5 of nettle C implementation
&gt; &gt; - Decrypt x~18.5 of nettle C implementation
&gt; &gt; - Update x~28.5 of nettle C implementation
&gt; ...
&gt;
&gt; One small comment for aes_encrypt and aes_decrypt... src and dst are
&gt; usually user supplied buffers. Using lxvd2x to load a vector may
&gt; produce incorrect results if the user is feeding a stream to an
&gt; encryptor or decryptor that is not naturally aligned to that of an
&gt; unsigned int. (On the other hand, Nettle controls the round keys array
&gt; so lxvd2x should be fine.)
&gt;
&gt; Instead of lxvd2x and friends for the user's buffers you should
&gt; consider using lvx and doing the lvsl thing to fix the data in the
&gt; registers.

In fact, you might want to add a test case like this:

    uint8_t plain[19] = {0,1, ..., 17, 18};
    uint8_t cipher[16], recover[16];

Then send plain, plain+1, plain+2 and plain+3 into the encryptor and
see if it round trips. lxvd2x will choke even on POWER9 because two of
the tests will not even be naturally aligned for a byte.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200630111425</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-06-30 11:14:25-0400</timestampReceived><subject>Re: [Patch] Optimize AES and GHASH for PowerPC64 (support little-endian and big-endian)</subject><body>

On Tue, Jun 30, 2020 at 12:29 PM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:

One small comment for aes_encrypt and aes_decrypt... src and dst are
&gt; usually user supplied buffers. Using lxvd2x to load a vector may
&gt; produce incorrect results if the user is feeding a stream to an
&gt; encryptor or decryptor that is not naturally aligned to that of an
&gt; unsigned int. (On the other hand, Nettle controls the round keys array
&gt; so lxvd2x should be fine.)
&gt;
&gt; Instead of lxvd2x and friends for the user's buffers you should
&gt; consider using lvx and doing the lvsl thing to fix the data in the
&gt; registers.
&gt;
&gt; Jeff
&gt;

I considered using lvx and lvsl to load the user's buffers but lxvd2x loads
unaligned data properly as well as making the loading process simpler.
I tested loading data that was not aligned at 1 byte and so lxvd2x handled
it properly. Let me know if I miss something.

&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200630115529</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-06-30 11:55:29-0400</timestampReceived><subject>Re: [Patch] Optimize AES and GHASH for PowerPC64 (support little-endian and big-endian)</subject><body>

I tested something similar, I tried to load data at address 0xXXXXXXX1
using lxvd2x and it loaded it properly.

On Tue, Jun 30, 2020 at 12:35 PM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:

&gt; On Tue, Jun 30, 2020 at 5:29 AM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:
&gt; &gt;
&gt; &gt; On Tue, Jun 30, 2020 at 5:14 AM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
&gt; wrote:
&gt; &gt; &gt;
&gt; &gt; &gt; Patch implementation benchmark for GCM_AES (Tested on POWER8):
&gt; &gt; &gt; little-endian:
&gt; &gt; &gt; - Encrypt x~17.5 of nettle C implementation
&gt; &gt; &gt; - Decrypt x~17.5 of nettle C implementation
&gt; &gt; &gt; - Update x~30 of nettle C implementation
&gt; &gt; &gt; big-endian:
&gt; &gt; &gt; - Encrypt x~18.5 of nettle C implementation
&gt; &gt; &gt; - Decrypt x~18.5 of nettle C implementation
&gt; &gt; &gt; - Update x~28.5 of nettle C implementation
&gt; &gt; ...
&gt; &gt;
&gt; &gt; One small comment for aes_encrypt and aes_decrypt... src and dst are
&gt; &gt; usually user supplied buffers. Using lxvd2x to load a vector may
&gt; &gt; produce incorrect results if the user is feeding a stream to an
&gt; &gt; encryptor or decryptor that is not naturally aligned to that of an
&gt; &gt; unsigned int. (On the other hand, Nettle controls the round keys array
&gt; &gt; so lxvd2x should be fine.)
&gt; &gt;
&gt; &gt; Instead of lxvd2x and friends for the user's buffers you should
&gt; &gt; consider using lvx and doing the lvsl thing to fix the data in the
&gt; &gt; registers.
&gt;
&gt; In fact, you might want to add a test case like this:
&gt;
&gt;     uint8_t plain[19] = {0,1, ..., 17, 18};
&gt;     uint8_t cipher[16], recover[16];
&gt;
&gt; Then send plain, plain+1, plain+2 and plain+3 into the encryptor and
&gt; see if it round trips. lxvd2x will choke even on POWER9 because two of
&gt; the tests will not even be naturally aligned for a byte.
&gt;
&gt; Jeff
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200630200628</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-06-30 20:06:28-0400</timestampReceived><subject>Re: [Patch] Optimize AES and GHASH for PowerPC64 (support little-endian and big-endian)</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; --- a/asm.m4
&gt; +++ b/asm.m4
&gt; @@ -30,13 +30,26 @@ COFF_STYLE, yes,
&gt;  define(&lt;GMP_NUMB_BITS&gt;,&lt;&gt;)dnl
&gt;
&gt;  define(&lt;PROLOGUE&gt;,
&gt; +&lt;ifelse(ASM_POWERPC64,no,
&gt;  &lt;.globl C_NAME($1)
&gt;  DECLARE_FUNC(C_NAME($1))
&gt; -C_NAME($1): ASM_X86_ENDBR&gt;)
&gt; +C_NAME($1): ASM_X86_ENDBR&gt;,
&gt; +&lt;.globl C_NAME($1)
&gt; +DECLARE_FUNC(C_NAME($1))
&gt; +.section ".opd","aw"
&gt; +.align 3
&gt; +C_NAME($1):
&gt; +.quad .C_NAME($1),.TOC.@tocbase,0
&gt; +.previous
&gt; +.align 5
&gt; +.C_NAME($1):&gt;)&gt;)
&gt;
&gt;  define(&lt;EPILOGUE&gt;,
&gt;  &lt;ifelse(ELF_STYLE,yes,
&gt; -&lt;.size C_NAME($1), . - C_NAME($1)&gt;,&lt;&gt;)&gt;)
&gt; +&lt;ifelse(ASM_POWERPC64,no,
&gt; +&lt;.size C_NAME($1), . - C_NAME($1)&gt;,
&gt; +&lt;.size .C_NAME($1), . - .C_NAME($1)
&gt; +.size C_NAME($1), . - .C_NAME($1)&gt;)&gt;,&lt;&gt;)&gt;)

Can you explain a bit more what's special with the powerpc64 prologue
and epilogue? What are the .C_NAME($1) symbols?

If possible, definitions could be moved to powerpc64/machine.m4 instead,
avoiding ifelse(ASM_POWERPC64,...).

It would also be nice with a powerpc64/README summarizing register usage
and calling conventions.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200630203114</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-06-30 20:31:14-0400</timestampReceived><subject>Re: [Patch] Optimize AES and GHASH for PowerPC64 (support little-endian and big-endian)</subject><body>

On Tue, Jun 30, 2020 at 7:55 AM Maamoun TK &lt;maamoun.tk@googlemail.com&gt; wrote:
&gt;
&gt; I tested something similar, I tried to load data at address 0xXXXXXXX1
&gt; using lxvd2x and it loaded it properly.

I think you should reconsider.

Consider, even Andy Polyakov uses lvx/lvsl when loading [potentially]
unaligned buffers on POWER8:
https://github.com/dot-asm/cryptogams/blob/master/ppc/aesp8-ppc.pl.
Andy uses it for the user's key and data.

Jeff

&gt; On Tue, Jun 30, 2020 at 12:35 PM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:
&gt;
&gt; &gt; On Tue, Jun 30, 2020 at 5:29 AM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:
&gt; &gt; &gt;
&gt; &gt; &gt; On Tue, Jun 30, 2020 at 5:14 AM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
&gt; &gt; wrote:
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; Patch implementation benchmark for GCM_AES (Tested on POWER8):
&gt; &gt; &gt; &gt; little-endian:
&gt; &gt; &gt; &gt; - Encrypt x~17.5 of nettle C implementation
&gt; &gt; &gt; &gt; - Decrypt x~17.5 of nettle C implementation
&gt; &gt; &gt; &gt; - Update x~30 of nettle C implementation
&gt; &gt; &gt; &gt; big-endian:
&gt; &gt; &gt; &gt; - Encrypt x~18.5 of nettle C implementation
&gt; &gt; &gt; &gt; - Decrypt x~18.5 of nettle C implementation
&gt; &gt; &gt; &gt; - Update x~28.5 of nettle C implementation
&gt; &gt; &gt; ...
&gt; &gt; &gt;
&gt; &gt; &gt; One small comment for aes_encrypt and aes_decrypt... src and dst are
&gt; &gt; &gt; usually user supplied buffers. Using lxvd2x to load a vector may
&gt; &gt; &gt; produce incorrect results if the user is feeding a stream to an
&gt; &gt; &gt; encryptor or decryptor that is not naturally aligned to that of an
&gt; &gt; &gt; unsigned int. (On the other hand, Nettle controls the round keys array
&gt; &gt; &gt; so lxvd2x should be fine.)
&gt; &gt; &gt;
&gt; &gt; &gt; Instead of lxvd2x and friends for the user's buffers you should
&gt; &gt; &gt; consider using lvx and doing the lvsl thing to fix the data in the
&gt; &gt; &gt; registers.
&gt; &gt;
&gt; &gt; In fact, you might want to add a test case like this:
&gt; &gt;
&gt; &gt;     uint8_t plain[19] = {0,1, ..., 17, 18};
&gt; &gt;     uint8_t cipher[16], recover[16];
&gt; &gt;
&gt; &gt; Then send plain, plain+1, plain+2 and plain+3 into the encryptor and
&gt; &gt; see if it round trips. lxvd2x will choke even on POWER9 because two of
&gt; &gt; the tests will not even be naturally aligned for a byte.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200630205830</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-06-30 20:58:30-0400</timestampReceived><subject>Re: [Patch] Optimize AES and GHASH for PowerPC64 (support little-endian and big-endian)</subject><body>

From POWER ISA 2.07 B:
- Load Vector Indexed X-form
lvx VRT,RA,RB
.
.
VRT ← MEM(EA &amp; 0xFFFF_FFFF_FFFF_FFF0, 16)

- Load VSX Vector Doubleword*2 Indexed XX1-form
lxvd2x XT,RA,RB
.
.
VSR[XT]{0:63} ← MEM(EA,8)
VSR[XT]{64:127} ← MEM(EA+8,8)

lxvd2x doesn't set the least significant 4-bit of effective address to
zero, this isn't enough to prove that lxvd2x loads unaligned data properly
so I tested this instruction to load unaligned data and it did succeed.

Andy Polyakov did use lxvd2x to load user's buffers in his ghash
implementation for ppc:
https://github.com/dot-asm/cryptogams/blob/master/ppc/ghashp8-ppc.pl
He uses lvx_u which indicate to lvx_unaligned I guess, Perl translates this
instruction to lxvd2x before passing it to the assembler.

regards,
Mamone

On Tue, Jun 30, 2020 at 11:31 PM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:

&gt; On Tue, Jun 30, 2020 at 7:55 AM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
&gt; wrote:
&gt; &gt;
&gt; &gt; I tested something similar, I tried to load data at address 0xXXXXXXX1
&gt; &gt; using lxvd2x and it loaded it properly.
&gt;
&gt; I think you should reconsider.
&gt;
&gt; Consider, even Andy Polyakov uses lvx/lvsl when loading [potentially]
&gt; unaligned buffers on POWER8:
&gt; https://github.com/dot-asm/cryptogams/blob/master/ppc/aesp8-ppc.pl.
&gt; Andy uses it for the user's key and data.
&gt;
&gt; Jeff
&gt;
&gt; &gt; On Tue, Jun 30, 2020 at 12:35 PM Jeffrey Walton &lt;noloader@gmail.com&gt;
&gt; wrote:
&gt; &gt;
&gt; &gt; &gt; On Tue, Jun 30, 2020 at 5:29 AM Jeffrey Walton &lt;noloader@gmail.com&gt;
&gt; wrote:
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; On Tue, Jun 30, 2020 at 5:14 AM Maamoun TK &lt;
&gt; maamoun.tk@googlemail.com&gt;
&gt; &gt; &gt; wrote:
&gt; &gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; &gt; Patch implementation benchmark for GCM_AES (Tested on POWER8):
&gt; &gt; &gt; &gt; &gt; little-endian:
&gt; &gt; &gt; &gt; &gt; - Encrypt x~17.5 of nettle C implementation
&gt; &gt; &gt; &gt; &gt; - Decrypt x~17.5 of nettle C implementation
&gt; &gt; &gt; &gt; &gt; - Update x~30 of nettle C implementation
&gt; &gt; &gt; &gt; &gt; big-endian:
&gt; &gt; &gt; &gt; &gt; - Encrypt x~18.5 of nettle C implementation
&gt; &gt; &gt; &gt; &gt; - Decrypt x~18.5 of nettle C implementation
&gt; &gt; &gt; &gt; &gt; - Update x~28.5 of nettle C implementation
&gt; &gt; &gt; &gt; ...
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; One small comment for aes_encrypt and aes_decrypt... src and dst are
&gt; &gt; &gt; &gt; usually user supplied buffers. Using lxvd2x to load a vector may
&gt; &gt; &gt; &gt; produce incorrect results if the user is feeding a stream to an
&gt; &gt; &gt; &gt; encryptor or decryptor that is not naturally aligned to that of an
&gt; &gt; &gt; &gt; unsigned int. (On the other hand, Nettle controls the round keys
&gt; array
&gt; &gt; &gt; &gt; so lxvd2x should be fine.)
&gt; &gt; &gt; &gt;
&gt; &gt; &gt; &gt; Instead of lxvd2x and friends for the user's buffers you should
&gt; &gt; &gt; &gt; consider using lvx and doing the lvsl thing to fix the data in the
&gt; &gt; &gt; &gt; registers.
&gt; &gt; &gt;
&gt; &gt; &gt; In fact, you might want to add a test case like this:
&gt; &gt; &gt;
&gt; &gt; &gt;     uint8_t plain[19] = {0,1, ..., 17, 18};
&gt; &gt; &gt;     uint8_t cipher[16], recover[16];
&gt; &gt; &gt;
&gt; &gt; &gt; Then send plain, plain+1, plain+2 and plain+3 into the encryptor and
&gt; &gt; &gt; see if it round trips. lxvd2x will choke even on POWER9 because two of
&gt; &gt; &gt; the tests will not even be naturally aligned for a byte.
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200624063409</emailId><senderName>Nikos Mavrogiannopoulos</senderName><senderEmail>nmav@redhat.com</senderEmail><timestampReceived>2020-06-24 06:34:09-0400</timestampReceived><subject>Re: [PATCH] Add ppc64 and ppc64el to Gitlab CI</subject><body>

Hi,
 I no longer talk for the gnutls developers, but why don't you submit an MR at:
https://gitlab.com/gnutls/build-images/

to add a ppc64le image? If you mention that this is used by nettle, I
doubt there will be an objection to it. That way you can use it
directly for testing nettle.

regards,
Nikos

On Wed, Jun 24, 2020 at 2:09 AM Maamoun TK &lt;maamoun.tk@googlemail.com&gt; wrote:
&gt;
&gt; To run tests on ppc64 and ppc64el, this patch install cross building
&gt; packages for both architectures on the Debian image, these packages will be
&gt; install every time the CI triggered. A proper fix would be to install these
&gt; packages to the image directly.
&gt; This patch follows a different approach to get access LD shared library for
&gt; qemu. Other architectures install native libc6 packages while both ppc64
&gt; and ppc64el install cross libc6 packages and export QEMU_LD_PREFIX to point
&gt; to LD path which is more reasonable.
&gt;
&gt;  .gitlab-ci.yml | 9 +++++++++
&gt;  1 file changed, 9 insertions(+)
&gt;
&gt; diff --git a/.gitlab-ci.yml b/.gitlab-ci.yml
&gt; index 9f3b5c63..7f12ecfa 100644
&gt; --- a/.gitlab-ci.yml
&gt; +++ b/.gitlab-ci.yml
&gt; @@ -139,6 +139,11 @@ Debian.cross.x86:
&gt;    before_script:
&gt;    # remove any previously installed nettle headers to avoid conflicts
&gt;    - for arch in armhf mips arm64;do apt-get remove -y nettle-dev:$arch;done
&gt; +  - host="${CI_JOB_NAME#*.cross.}"
&gt; +  - if [ "$host" == "powerpc64-linux-gnu" ];then apt-get update &amp;&amp; apt-get
&gt; install -y gcc-$host &amp;&amp;
&gt; +    apt-get install -y g++-$host &amp;&amp; apt-get install -y
&gt; libstdc++6-ppc64-cross &amp;&amp; export QEMU_LD_PREFIX=/usr/$host;fi
&gt; +  - if [ "$host" == "powerpc64le-linux-gnu" ];then apt-get update &amp;&amp;
&gt; apt-get install -y gcc-$host &amp;&amp;
&gt; +    apt-get install -y g++-$host &amp;&amp; apt-get install -y
&gt; libstdc++6-ppc64el-cross &amp;&amp; export QEMU_LD_PREFIX=/usr/$host;fi
&gt;    script:
&gt;    - build=$(dpkg-architecture -qDEB_HOST_GNU_TYPE)
&gt;    - host="${CI_JOB_NAME#*.cross.}"
&gt; @@ -162,3 +167,7 @@ Debian.cross.mips-linux-gnu:
&gt;    &lt;&lt;: *Debian_cross_template
&gt;  Debian.cross.aarch64-linux-gnu:
&gt;    &lt;&lt;: *Debian_cross_template
&gt; +Debian.cross.powerpc64-linux-gnu:
&gt; +  &lt;&lt;: *Debian_cross_template
&gt; +Debian.cross.powerpc64le-linux-gnu:
&gt; +  &lt;&lt;: *Debian_cross_template
&gt; _______________________________________________
&gt; nettle-bugs mailing list
&gt; nettle-bugs@lists.lysator.liu.se
&gt; http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200624074332</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-06-24 07:43:32-0400</timestampReceived><subject>Re: [PATCH] Add ppc64 and ppc64el to Gitlab CI</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; To run tests on ppc64 and ppc64el, this patch install cross building
&gt; packages for both architectures on the Debian image,

Speaking of ppc64 (big-endian, I assume) vs ppc64el, do you think it's
possible and reasonable to use same assembly files? That's how the
current ARM big-endian support works.

&gt; This patch follows a different approach to get access LD shared library for
&gt; qemu. Other architectures install native libc6 packages while both ppc64
&gt; and ppc64el install cross libc6 packages and export QEMU_LD_PREFIX to point
&gt; to LD path which is more reasonable.

Can you explain why it's different? I thought the point of the debian
multilib organization was to enable installing the native packages,
i.e., apt-get install libstdc++6:ppc64el rather than apt-get install
libstdc++6-ppc64el-cross. But I'm not that familiar with the details of
the debian cross packages.

From a quick look, it seems that e.g., gcc-mips-linux-gnu depends on
libc6-dev-mips-cross, and gcc-powerpc64-linux-gnu has a similar
dependency.

&gt; diff --git a/.gitlab-ci.yml b/.gitlab-ci.yml
&gt; index 9f3b5c63..7f12ecfa 100644
&gt; --- a/.gitlab-ci.yml
&gt; +++ b/.gitlab-ci.yml
&gt; @@ -139,6 +139,11 @@ Debian.cross.x86:
&gt;    before_script:
&gt;    # remove any previously installed nettle headers to avoid conflicts
&gt;    - for arch in armhf mips arm64;do apt-get remove -y nettle-dev:$arch;done
&gt; +  - host="${CI_JOB_NAME#*.cross.}"
&gt; +  - if [ "$host" == "powerpc64-linux-gnu" ];then apt-get update &amp;&amp; apt-get
&gt; install -y gcc-$host &amp;&amp;
&gt; +    apt-get install -y g++-$host &amp;&amp; apt-get install -y
&gt; libstdc++6-ppc64-cross &amp;&amp; export QEMU_LD_PREFIX=/usr/$host;fi

Do you need to explicitly install libstdc++? I would expect the
g++-$host to depend (or recommend) on the right library packages.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200624092503</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-06-24 09:25:03-0400</timestampReceived><subject>Re: [PATCH] Add ppc64 and ppc64el to Gitlab CI</subject><body>

On Wed, Jun 24, 2020 at 10:43 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

Speaking of ppc64 (big-endian, I assume) vs ppc64el, do you think it's
&gt; possible and reasonable to use same assembly files? That's how the
&gt; current ARM big-endian support works.
&gt;

Yes, that is what I'm working on. nettle has IF_LE and IF_BE macros to be
used in assembly files for this purpose. It's not reasonable to make two
different files of the same implementation just to change permuting loaded
data for big-endian version.


&gt; Can you explain why it's different? I thought the point of the debian
&gt; multilib organization was to enable installing the native packages,
&gt; i.e., apt-get install libstdc++6:ppc64el rather than apt-get install
&gt; libstdc++6-ppc64el-cross. But I'm not that familiar with the details of
&gt; the debian cross packages.
&gt;

Yes it's possible but I think if the cross packages would do the job it's
less reasonable to install the native ones. Another reason to do that is
Debian doesn't support ppc64 officially, I didn't figure out how to install
libstdc++6:ppc64 so the cross package is the only option here.


&gt; Do you need to explicitly install libstdc++? I would expect the
&gt; g++-$host to depend (or recommend) on the right library packages.
&gt;

My fault, seems to explicitly install libstdc++ is not needed.

Thanks,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200629121518</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-06-29 12:15:18-0400</timestampReceived><subject>Re: [PATCH] Add ppc64 and ppc64el to Gitlab CI</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; To run tests on ppc64 and ppc64el, this patch install cross building
&gt; packages for both architectures on the Debian image, these packages will be
&gt; install every time the CI triggered. A proper fix would be to install these
&gt; packages to the image directly.

I've committed a change based on this patch. I dropped big-endian ppc
support for now (the "apt-get remove nettle-dev:$arch" failed because
it's not an arch in official debian. Not sure if that was the only
problem, but I wanted to get ppc64el working first, before investigating
further). And I had to add a dpkg --add-architecture, since that was
also missing in the build image.

It would be great if you could prepare a merge request for the image
repository. And any advice on what's needed for big-endian ppc, should
it work fine to install the cross-compiler packages, despite it not being
an official debian arch?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200629161050</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-06-29 16:10:50-0400</timestampReceived><subject>Re: [PATCH] Add ppc64 and ppc64el to Gitlab CI</subject><body>

On Mon, Jun 29, 2020 at 3:15 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; I've committed a change based on this patch. I dropped big-endian ppc
&gt; support for now (the "apt-get remove nettle-dev:$arch" failed because
&gt; it's not an arch in official debian. Not sure if that was the only
&gt; problem, but I wanted to get ppc64el working first, before investigating
&gt; further). And I had to add a dpkg --add-architecture, since that was
&gt; also missing in the build image.
&gt;

Is nettle-dev:ppe64el installed in the image?
If not installed, there is no point in removing it.


&gt; It would be great if you could prepare a merge request for the image
&gt; repository. And any advice on what's needed for big-endian ppc, should
&gt; it work fine to install the cross-compiler packages, despite it not being
&gt; an official debian arch?
&gt;

I have no experience modifying build images, I will open an issue in the
image
repository asking to add support for powerpc64.
The cross-compiler packages are supported officially. libc6-ppc64-cross
installs
 the same required files that are installed by libc6:ppc64 but without
copying the LD shared
library to the default directory so the patch exports QEMU_LD_PREFIX to
point out to
the LD location. So yes, it works fine since it behaves the same.

Thank you,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200630092643</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-06-30 09:26:43-0400</timestampReceived><subject>Re: [PATCH] Add ppc64 and ppc64el to Gitlab CI</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; Is nettle-dev:ppe64el installed in the image?
&gt; If not installed, there is no point in removing it.

There was a loop over all archs. But I guess I should just remove ppc64
from that list. I was a bit in a hurry to get something working.

&gt; I have no experience modifying build images, I will open an issue in the
&gt; image
&gt; repository asking to add support for powerpc64.

I too have no experience with docker, but it looks like it should be
fairly easy to add.

&gt; The cross-compiler packages are supported officially. libc6-ppc64-cross
&gt; installs
&gt;  the same required files that are installed by libc6:ppc64 but without
&gt; copying the LD shared
&gt; library to the default directory so the patch exports QEMU_LD_PREFIX to
&gt; point out to
&gt; the LD location. So yes, it works fine since it behaves the same.

Nice, I'll try enabling that then. Does that mean that explicitly
setting QEMU_LD_PREFIX is needed only for ppc64 (big-endian), but not
for ppc64el?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200630115954</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-06-30 11:59:54-0400</timestampReceived><subject>Re: [PATCH] Add ppc64 and ppc64el to Gitlab CI</subject><body>

On Tue, Jun 30, 2020 at 12:26 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Does that mean that explicitly
&gt; setting QEMU_LD_PREFIX is needed only for ppc64 (big-endian), but not
&gt; for ppc64el?
&gt;

 It's needed for both, I just give ppc64 as an example.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200609165315</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-06-09 16:53:15-0400</timestampReceived><subject>Re: [PATCH v2 3/8] nettle.texinfo: add documentation for Streebog hash function</subject><body>

Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:

&gt; Add documentation describing Streebog hash function and it's API.

Is there any consensus on the cryptographic strength and general quality
of streebog? I wonder if it really should go in the section "Recommended
hash functions" with SHA2 and SHA3, or in the "Legacy hash functions"
section. The wikipedia page
(https://en.wikipedia.org/wiki/Streebog#Cryptanalysis) says

  In 2015 Birykov, Perrin and Udovenko reverse engineered the
  unpublished S-box generation structure (which was earlier claimed to
  be generated randomly) and concluded that the underlying components
  are cryptographically weak. 

referring to https://eprint.iacr.org/2016/071.

And https://en.wikipedia.org/wiki/Hash_function_security_summary lists a
"theoretical" preimage attack on the full hash function, referencing
https://eprint.iacr.org/2014/675.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200614212100</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-06-14 21:21:00-0400</timestampReceived><subject>Re: [PATCH v2 3/8] nettle.texinfo: add documentation for Streebog hash function</subject><body>

Hello,

вт, 9 июн. 2020 г. в 19:53, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt;
&gt; Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:
&gt;
&gt; &gt; Add documentation describing Streebog hash function and it's API.
&gt;
&gt; Is there any consensus on the cryptographic strength and general quality
&gt; of streebog? I wonder if it really should go in the section "Recommended
&gt; hash functions" with SHA2 and SHA3, or in the "Legacy hash functions"
&gt; section.

I wouldn't call it legacy (since it is an actual standard). What about
adding the "Other hash functions" section? It can further receive
algorithms such as SM3 (if somebody submits it)?

&gt; The wikipedia page
&gt; (https://en.wikipedia.org/wiki/Streebog#Cryptanalysis) says
&gt;
&gt;   In 2015 Birykov, Perrin and Udovenko reverse engineered the
&gt;   unpublished S-box generation structure (which was earlier claimed to
&gt;   be generated randomly) and concluded that the underlying components
&gt;   are cryptographically weak.
&gt;
&gt; referring to https://eprint.iacr.org/2016/071.

Yes, this is interesting research which has raised a lot of
controversion here. However it did not result in demonstration of
theoretical or practical weakness of such constructions.

&gt; And https://en.wikipedia.org/wiki/Hash_function_security_summary lists a
&gt; "theoretical" preimage attack on the full hash function, referencing
&gt; https://eprint.iacr.org/2014/675.

-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200620081924</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-06-20 08:19:24-0400</timestampReceived><subject>Re: [PATCH v2 3/8] nettle.texinfo: add documentation for Streebog hash function</subject><body>

Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:

&gt;&gt; Is there any consensus on the cryptographic strength and general quality
&gt;&gt; of streebog? I wonder if it really should go in the section "Recommended
&gt;&gt; hash functions" with SHA2 and SHA3, or in the "Legacy hash functions"
&gt;&gt; section.
&gt;
&gt; I wouldn't call it legacy (since it is an actual standard). What about
&gt; adding the "Other hash functions" section? It can further receive
&gt; algorithms such as SM3 (if somebody submits it)?

"Other" sounds goood to me. Would you like to do that?

&gt; Yes, this is interesting research which has raised a lot of
&gt; controversion here. However it did not result in demonstration of
&gt; theoretical or practical weakness of such constructions.
&gt;
&gt;&gt; And https://en.wikipedia.org/wiki/Hash_function_security_summary lists a
&gt;&gt; "theoretical" preimage attack on the full hash function, referencing
&gt;&gt; https://eprint.iacr.org/2014/675.

As I read the numbers there, it sounds like streebog 512 is
significantly weaker then the claimed security level, and not much more
secure than streebog 256. But I haven't looked into the details. And as
far as I'm aware, attacks on a good hash function with 256 bit output
are completely not practical today.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200630110448</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-06-30 11:04:48-0400</timestampReceived><subject>Re: [PATCH v2 3/8] nettle.texinfo: add documentation for Streebog hash function</subject><body>

Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:

&gt; I wouldn't call it legacy (since it is an actual standard). What about
&gt; adding the "Other hash functions" section? It can further receive
&gt; algorithms such as SM3 (if somebody submits it)?

I've now committed your docs, in a "Miscellaneous hash functions"
section.

Thanks,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200620083816</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-06-20 08:38:16-0400</timestampReceived><subject>Re: [PATCH v2 8/8] test/gostdsa-vko: add hashed test vectors from RFC 7836</subject><body>

Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:

&gt; It was not possible to check gostdsa_vko test vectors with the outputs
&gt; from RFC 7836 because Nettle lacked Streebog hash function. Now as the
&gt; function is supported, add full test vectors.

I've now merged this and preceding patches to master-updates. I think
that is all of the changes needed for streebog hashes (except the docs,
which should go into an other section, as discussed in a different
thread). Let me know if there's anything I've missed.

After this, my next priority will be to review and merge the latest
round of bcrypt patches.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200623075020</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-06-23 07:50:20-0400</timestampReceived><subject>Re: Add ppc64le arch to Gitlab CI</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; I investigated this issue. The Debian image used for Gitlab CI only
&gt; supports the following archs amd64 mips armhf arm64. To add a new arch,
&gt; this arch should be added to the sources list of apt and install the
&gt; required packages to build and check nettle library.

Looks like the image is defined here:
https://gitlab.com/gnutls/build-images/-/blob/master/docker-debian-cross/Dockerfile

Nikos, Michael, can we just add ppc64el to the ARCHES and TRIPLES lists
there?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200623090606</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-06-23 09:06:06-0400</timestampReceived><subject>Re: Add ppc64le arch to Gitlab CI</subject><body>

I made a workaround by installing the required packages for ppc64el via
.gitlab-ci.yml
I will post the patch with big endian support for the optimized functions.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200618160926</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-06-18 16:09:26-0400</timestampReceived><subject>Re: PPC64LE optimizing AES and GHASH</subject><body>

On Thu, Jun 18, 2020 at 6:58 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
wrote:

&gt; I added a PowerPC64LE optimized version of AES and GHASH to nettle.
&gt; Patch summary:
&gt; 
&gt; GHASH Algorithm
&gt; 
&gt; I took the advantage of several references and researches to achieve the
&gt; high-speed implementation of this algorithm. These references include
&gt; several techniques that have been used to improve the performance of the
&gt; algorithm, I will summarize the important techniques used as follows:
&gt; 
&gt; - The main equation: The main equation for 4 block (128-bit each) can
&gt; be seen in reference [1]  Digest =
&gt; (((((((Digest⊕C0)*H)⊕C1)*H)⊕C2)*H)⊕C3)*H =
&gt; ((Digest⊕C0)*H4)⊕(C1*H3)⊕(C2*H2)⊕(C3*H) to achieve more parallelism,
&gt; this equation can be modified to address 8 blocks per one loop. It looks
&gt; like as follows Digest =
&gt; ((Digest⊕C0)*H8)⊕(C1*H7)⊕(C2*H6)⊕(C3*H5)⊕(C4*H4)⊕(C5*H3)⊕(C6*H2)⊕(C7*H)
&gt;                 
&gt; - Handling Bit-reflection of the multiplication product [1]: This
&gt; technique moves part of the workload inside the loop to the init function
&gt; so it is executed only once.
&gt; - Karatsuba Algorithm: This algorithm allows to perform three
&gt; multiplication instructions instead of four, in exchange for two additional
&gt; Xor. This technique is well explained with figures in reference [1]
&gt; - Deferred Recombination of partial products This technique is well
&gt; explained with figures in reference [1]
&gt; - Multiplication-based reduction: I tested both classical shift-based
&gt; reduction and multiplication-based reduction, the multiplication-based
&gt; reduction achieved better performance and less instructions. Example of
&gt; both reductions can be seen in reference [2]
&gt; 
&gt; AES
&gt; Power ISA makes it easy to optimize AES by offering built-in AES
&gt; instructions.
&gt; 
&gt; AES-GCM performance (Tested on POWER9):
&gt; 
&gt; - GCM_AES Encrypt ~x13.5 of nettle C implementation
&gt; - GCM_AES Decrypt ~x13.5 of nettle C implementation
&gt; - GCM_AES Update (Only GHASH is called) ~x26 of nettle C implementation
&gt; 
&gt; Notes:
&gt; 
&gt; - Test 128 bytes is added to gcm-test in testsuite to test 8x loop in
&gt; GHASH optimized function.
&gt; - Since the functionality of gcm_set_key() is replaced with
&gt; gcm_init_key() for PowerPC64LE, two warnings will pop up: [‘gcm_gf_shift'
&gt; defined but not used] and [‘gcm_gf_add' defined but not used]
&gt; 
&gt; References: [1]
&gt; https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/communications-ia-galois-counter-mode-paper.pdf
&gt;  [2]
&gt; https://www.intel.com/content/dam/www/public/us/en/documents/software-support/enabling-high-performance-gcm.pdf
&gt;  [3] https://software.intel.com/file/24918 [4]
&gt; https://github.com/dot-asm/cryptogams
&gt; 
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200618161136</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-06-18 16:11:36-0400</timestampReceived><subject>Re: PPC64LE optimizing AES and GHASH</subject><body>

diff -urN nettle/configure.ac nettle_PowerPC64LE/configure.ac
--- nettle/configure.ac 2020-06-08 08:42:20.000000000 +0300
+++ nettle_PowerPC64LE/configure.ac 2020-06-15 18:41:43.485342900 +0300
@@ -435,6 +435,9 @@
   esac
       fi
       ;;
+    *powerpc64le*)
+  asm_path=powerpc64le
+      ;;
     *)
       enable_assembler=no
       ;;
@@ -572,7 +575,9 @@
 #undef HAVE_NATIVE_ecc_secp384r1_redc
 #undef HAVE_NATIVE_ecc_secp521r1_modp
 #undef HAVE_NATIVE_ecc_secp521r1_redc
+#undef HAVE_NATIVE_gcm_init_key8
 #undef HAVE_NATIVE_gcm_hash8
+#undef HAVE_NATIVE_gcm_fill
 #undef HAVE_NATIVE_salsa20_core
 #undef HAVE_NATIVE_sha1_compress
 #undef HAVE_NATIVE_sha256_compress
diff -urN nettle/gcm.c nettle_PowerPC64LE/gcm.c
--- nettle/gcm.c  2020-06-08 08:42:20.000000000 +0300
+++ nettle_PowerPC64LE/gcm.c  2020-06-15 18:45:28.115078300 +0300
@@ -140,6 +140,12 @@
   memcpy (x-&gt;b, Z.b, sizeof(Z));
 }
 # elif GCM_TABLE_BITS == 8
+#  if HAVE_NATIVE_gcm_init_key8
+
+#define gcm_init_key _nettle_gcm_init_key8
+void
+_nettle_gcm_init_key8 (union nettle_block16 *table);
+#  endif /* HAVE_NATIVE_gcm_init_key8 */
 #  if HAVE_NATIVE_gcm_hash8

 #define gcm_hash _nettle_gcm_hash8
@@ -225,6 +231,13 @@

 #endif /* GCM_TABLE_BITS */

+# if HAVE_NATIVE_gcm_fill
+
+#define gcm_fill _nettle_gcm_fill
+void
+_nettle_gcm_fill (uint8_t *ctr, size_t blocks, union nettle_block16 *buffer);
+# endif /* HAVE_NATIVE_gcm_fill */
+
 /* Increment the rightmost 32 bits. */
 #define INC32(block) INCREMENT(4, (block.b) + GCM_BLOCK_SIZE - 4)

@@ -245,7 +258,9 @@
   memset(key-&gt;h[0].b, 0, GCM_BLOCK_SIZE);
   f (cipher, GCM_BLOCK_SIZE, key-&gt;h[i].b, key-&gt;h[0].b);

-#if GCM_TABLE_BITS
+#ifdef gcm_init_key
+  gcm_init_key(key-&gt;h);
+#elif GCM_TABLE_BITS
   /* Algorithm 3 from the gcm paper. First do powers of two, then do
      the rest by adding. */
   while (i /= 2)
@@ -333,6 +348,7 @@
   ctx-&gt;auth_size += length;
 }

+#ifndef gcm_fill
 static nettle_fill16_func gcm_fill;
 static void
 gcm_fill(uint8_t *ctr, size_t blocks, union nettle_block16 *buffer)
@@ -349,6 +365,7 @@

   WRITE_UINT32(ctr + GCM_BLOCK_SIZE - 4, c);
 }
+#endif /* !gcm_fill */

 void
 gcm_encrypt (struct gcm_ctx *ctx, const struct gcm_key *key,
diff -urN nettle/powerpc64le/aes-decrypt-internal.asm
nettle_PowerPC64LE/powerpc64le/aes-decrypt-internal.asm
--- nettle/powerpc64le/aes-decrypt-internal.asm 1970-01-01
02:00:00.000000000 +0200
+++ nettle_PowerPC64LE/powerpc64le/aes-decrypt-internal.asm 2020-06-14
21:43:35.886234400 +0300
@@ -0,0 +1,573 @@
+C powerpc64le/aes-decrypt-internal.asm
+
+ifelse(&lt;
+   Copyright (C) 2020 Mamone Tarsha
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+&gt;)
+
+C Register usage:
+
+define(&lt;SP&gt;, &lt;1&gt;)
+define(&lt;TOCP&gt;, &lt;2&gt;)
+
+define(&lt;ROUNDS&gt;, &lt;3&gt;)
+define(&lt;KEYS&gt;, &lt;4&gt;)
+define(&lt;LENGTH&gt;, &lt;6&gt;)
+define(&lt;DST&gt;, &lt;7&gt;)
+define(&lt;SRC&gt;, &lt;8&gt;)
+
+define(&lt;swap_mask&gt;, &lt;0&gt;)
+
+define(&lt;K&gt;, &lt;1&gt;)
+define(&lt;S0&gt;, &lt;2&gt;)
+define(&lt;S1&gt;, &lt;3&gt;)
+define(&lt;S2&gt;, &lt;4&gt;)
+define(&lt;S3&gt;, &lt;5&gt;)
+define(&lt;S4&gt;, &lt;6&gt;)
+define(&lt;S5&gt;, &lt;7&gt;)
+define(&lt;S6&gt;, &lt;8&gt;)
+define(&lt;S7&gt;, &lt;9&gt;)
+define(&lt;S8&gt;, &lt;10&gt;)
+define(&lt;S9&gt;, &lt;11&gt;)
+define(&lt;S10&gt;, &lt;12&gt;)
+define(&lt;S11&gt;, &lt;13&gt;)
+define(&lt;S12&gt;, &lt;14&gt;)
+define(&lt;S13&gt;, &lt;15&gt;)
+define(&lt;S14&gt;, &lt;16&gt;)
+define(&lt;S15&gt;, &lt;17&gt;)
+
+define(&lt;KX&gt;, &lt;33&gt;)
+define(&lt;S0X&gt;, &lt;34&gt;)
+define(&lt;S1X&gt;, &lt;35&gt;)
+define(&lt;S2X&gt;, &lt;36&gt;)
+define(&lt;S3X&gt;, &lt;37&gt;)
+define(&lt;S4X&gt;, &lt;38&gt;)
+define(&lt;S5X&gt;, &lt;39&gt;)
+define(&lt;S6X&gt;, &lt;40&gt;)
+define(&lt;S7X&gt;, &lt;41&gt;)
+define(&lt;S8X&gt;, &lt;42&gt;)
+define(&lt;S9X&gt;, &lt;43&gt;)
+define(&lt;S10X&gt;, &lt;44&gt;)
+define(&lt;S11X&gt;, &lt;45&gt;)
+define(&lt;S12X&gt;, &lt;46&gt;)
+define(&lt;S13X&gt;, &lt;47&gt;)
+define(&lt;S14X&gt;, &lt;48&gt;)
+define(&lt;S15X&gt;, &lt;49&gt;)
+
+C ZERO vector register is used in place of RoundKey
+C for vncipher instruction because the order of InvMixColumns
+C and Xor processes are flipped in that instruction.
+C The Xor process with RoundKey is executed afterward.
+define(&lt;ZERO&gt;, &lt;18&gt;)
+
+  .file "aes-decrypt-internal.asm"
+
+  C _aes_decrypt(unsigned rounds, const uint32_t *keys,
+  C         const struct aes_table *T,
+  C         size_t length, uint8_t *dst,
+  C         uint8_t *src)
+
+  .text
+.align 5
+PROLOGUE(_nettle_aes_decrypt)
+  vxor      ZERO,ZERO,ZERO
+
+  ld          5,.swap_mask@got(TOCP)
+  lvx         swap_mask,0,5
+
+  subi      ROUNDS,ROUNDS,1
+  srdi      LENGTH,LENGTH,4
+
+  srdi      5,LENGTH,4              # 16x loop count
+  cmpldi      5,0
+  beq       L8x
+
+  std       17,-120(SP);
+  std       18,-112(SP);
+  std       19,-104(SP);
+  std       20,-96(SP);
+  std       21,-88(SP);
+  std       22,-80(SP);
+  std       23,-72(SP);
+  std       24,-64(SP);
+  std       25,-56(SP);
+  std       26,-48(SP);
+  std       27,-40(SP);
+  std       28,-32(SP);
+  std       29,-24(SP);
+  std       30,-16(SP);
+  std       31,-8(SP);
+
+  li        17,0x10
+  li        18,0x20
+  li        19,0x30
+  li        20,0x40
+  li        21,0x50
+  li        22,0x60
+  li        23,0x70
+  li        24,0x80
+  li        25,0x90
+  li        26,0xA0
+  li        27,0xB0
+  li        28,0xC0
+  li        29,0xD0
+  li        30,0xE0
+  li        31,0xF0
+
+.align 5
+Lx16_loop:
+  lxvd2x      KX,0,KEYS
+
+  lxvd2x      S0X,0,SRC
+  lxvd2x      S1X,17,SRC
+  lxvd2x      S2X,18,SRC
+  lxvd2x      S3X,19,SRC
+  lxvd2x      S4X,20,SRC
+  lxvd2x      S5X,21,SRC
+  lxvd2x      S6X,22,SRC
+  lxvd2x      S7X,23,SRC
+  lxvd2x      S8X,24,SRC
+  lxvd2x      S9X,25,SRC
+  lxvd2x      S10X,26,SRC
+  lxvd2x      S11X,27,SRC
+  lxvd2x      S12X,28,SRC
+  lxvd2x      S13X,29,SRC
+  lxvd2x      S14X,30,SRC
+  lxvd2x      S15X,31,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+  vxor      S4,S4,K
+  vxor      S5,S5,K
+  vxor      S6,S6,K
+  vxor      S7,S7,K
+  vxor      S8,S8,K
+  vxor      S9,S9,K
+  vxor      S10,S10,K
+  vxor      S11,S11,K
+  vxor      S12,S12,K
+  vxor      S13,S13,K
+  vxor      S14,S14,K
+  vxor      S15,S15,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+  vperm      S2,S2,S2,swap_mask
+  vperm      S3,S3,S3,swap_mask
+  vperm      S4,S4,S4,swap_mask
+  vperm      S5,S5,S5,swap_mask
+  vperm      S6,S6,S6,swap_mask
+  vperm      S7,S7,S7,swap_mask
+  vperm      S8,S8,S8,swap_mask
+  vperm      S9,S9,S9,swap_mask
+  vperm      S10,S10,S10,swap_mask
+  vperm      S11,S11,S11,swap_mask
+  vperm      S12,S12,S12,swap_mask
+  vperm      S13,S13,S13,swap_mask
+  vperm      S14,S14,S14,swap_mask
+  vperm      S15,S15,S15,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L16x_round_loop:
+  lxvd2x      KX,10,KEYS
+  vperm      K,K,K,swap_mask
+  vncipher   S0,S0,ZERO
+  vncipher   S1,S1,ZERO
+  vncipher   S2,S2,ZERO
+  vncipher   S3,S3,ZERO
+  vncipher   S4,S4,ZERO
+  vncipher   S5,S5,ZERO
+  vncipher   S6,S6,ZERO
+  vncipher   S7,S7,ZERO
+  vncipher   S8,S8,ZERO
+  vncipher   S9,S9,ZERO
+  vncipher   S10,S10,ZERO
+  vncipher   S11,S11,ZERO
+  vncipher   S12,S12,ZERO
+  vncipher   S13,S13,ZERO
+  vncipher   S14,S14,ZERO
+  vncipher   S15,S15,ZERO
+  vxor       S0,S0,K
+  vxor       S1,S1,K
+  vxor       S2,S2,K
+  vxor       S3,S3,K
+  vxor       S4,S4,K
+  vxor       S5,S5,K
+  vxor       S6,S6,K
+  vxor       S7,S7,K
+  vxor       S8,S8,K
+  vxor       S9,S9,K
+  vxor       S10,S10,K
+  vxor       S11,S11,K
+  vxor       S12,S12,K
+  vxor       S13,S13,K
+  vxor       S14,S14,K
+  vxor       S15,S15,K
+  addi      10,10,0x10
+  bdnz      L16x_round_loop
+
+  lxvd2x          KX,10,KEYS
+  vperm          K,K,K,swap_mask
+  vncipherlast   S0,S0,K
+  vncipherlast   S1,S1,K
+  vncipherlast   S2,S2,K
+  vncipherlast   S3,S3,K
+  vncipherlast   S4,S4,K
+  vncipherlast   S5,S5,K
+  vncipherlast   S6,S6,K
+  vncipherlast   S7,S7,K
+  vncipherlast   S8,S8,K
+  vncipherlast   S9,S9,K
+  vncipherlast   S10,S10,K
+  vncipherlast   S11,S11,K
+  vncipherlast   S12,S12,K
+  vncipherlast   S13,S13,K
+  vncipherlast   S14,S14,K
+  vncipherlast   S15,S15,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+  vperm      S2,S2,S2,swap_mask
+  vperm      S3,S3,S3,swap_mask
+  vperm      S4,S4,S4,swap_mask
+  vperm      S5,S5,S5,swap_mask
+  vperm      S6,S6,S6,swap_mask
+  vperm      S7,S7,S7,swap_mask
+  vperm      S8,S8,S8,swap_mask
+  vperm      S9,S9,S9,swap_mask
+  vperm      S10,S10,S10,swap_mask
+  vperm      S11,S11,S11,swap_mask
+  vperm      S12,S12,S12,swap_mask
+  vperm      S13,S13,S13,swap_mask
+  vperm      S14,S14,S14,swap_mask
+  vperm      S15,S15,S15,swap_mask
+
+  stxvd2x     S0X,0,DST
+  stxvd2x     S1X,17,DST
+  stxvd2x     S2X,18,DST
+  stxvd2x     S3X,19,DST
+  stxvd2x     S4X,20,DST
+  stxvd2x     S5X,21,DST
+  stxvd2x     S6X,22,DST
+  stxvd2x     S7X,23,DST
+  stxvd2x     S8X,24,DST
+  stxvd2x     S9X,25,DST
+  stxvd2x     S10X,26,DST
+  stxvd2x     S11X,27,DST
+  stxvd2x     S12X,28,DST
+  stxvd2x     S13X,29,DST
+  stxvd2x     S14X,30,DST
+  stxvd2x     S15X,31,DST
+
+  addi      SRC,SRC,0x100
+  addi      DST,DST,0x100
+  subic.    5,5,1
+  bne       Lx16_loop
+
+  ld        17,-120(SP);
+  ld        18,-112(SP);
+  ld        19,-104(SP);
+  ld        20,-96(SP);
+  ld        21,-88(SP);
+  ld        22,-80(SP);
+  ld        23,-72(SP);
+  ld        24,-64(SP);
+  ld        25,-56(SP);
+  ld        26,-48(SP);
+  ld        27,-40(SP);
+  ld        28,-32(SP);
+  ld        29,-24(SP);
+  ld        30,-16(SP);
+  ld        31,-8(SP);
+
+  clrldi   LENGTH,LENGTH,60
+
+L8x:
+  srdi      5,LENGTH,3
+  cmpldi      5,0
+  beq       L4x
+
+  lxvd2x      KX,0,KEYS
+
+  lxvd2x      S0X,0,SRC
+  li        9,0x10
+  lxvd2x      S1X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S2X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S3X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S4X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S5X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S6X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S7X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+  vxor      S4,S4,K
+  vxor      S5,S5,K
+  vxor      S6,S6,K
+  vxor      S7,S7,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+  vperm      S2,S2,S2,swap_mask
+  vperm      S3,S3,S3,swap_mask
+  vperm      S4,S4,S4,swap_mask
+  vperm      S5,S5,S5,swap_mask
+  vperm      S6,S6,S6,swap_mask
+  vperm      S7,S7,S7,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L8x_round_loop:
+  lxvd2x      KX,10,KEYS
+  vperm      K,K,K,swap_mask
+  vncipher   S0,S0,ZERO
+  vncipher   S1,S1,ZERO
+  vncipher   S2,S2,ZERO
+  vncipher   S3,S3,ZERO
+  vncipher   S4,S4,ZERO
+  vncipher   S5,S5,ZERO
+  vncipher   S6,S6,ZERO
+  vncipher   S7,S7,ZERO
+  vxor       S0,S0,K
+  vxor       S1,S1,K
+  vxor       S2,S2,K
+  vxor       S3,S3,K
+  vxor       S4,S4,K
+  vxor       S5,S5,K
+  vxor       S6,S6,K
+  vxor       S7,S7,K
+  addi      10,10,0x10
+  bdnz      L8x_round_loop
+
+  lxvd2x          KX,10,KEYS
+  vperm          K,K,K,swap_mask
+  vncipherlast   S0,S0,K
+  vncipherlast   S1,S1,K
+  vncipherlast   S2,S2,K
+  vncipherlast   S3,S3,K
+  vncipherlast   S4,S4,K
+  vncipherlast   S5,S5,K
+  vncipherlast   S6,S6,K
+  vncipherlast   S7,S7,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+  vperm      S2,S2,S2,swap_mask
+  vperm      S3,S3,S3,swap_mask
+  vperm      S4,S4,S4,swap_mask
+  vperm      S5,S5,S5,swap_mask
+  vperm      S6,S6,S6,swap_mask
+  vperm      S7,S7,S7,swap_mask
+
+  stxvd2x     S0X,0,DST
+  li        9,0x10
+  stxvd2x     S1X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S2X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S3X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S4X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S5X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S6X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S7X,9,DST
+
+  addi      SRC,SRC,0x80
+  addi      DST,DST,0x80
+
+  clrldi   LENGTH,LENGTH,61
+
+L4x:
+  srdi      5,LENGTH,2
+  cmpldi      5,0
+  beq       L2x
+
+  lxvd2x      KX,0,KEYS
+
+  lxvd2x      S0X,0,SRC
+  li        9,0x10
+  lxvd2x      S1X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S2X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S3X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+  vperm      S2,S2,S2,swap_mask
+  vperm      S3,S3,S3,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L4x_round_loop:
+  lxvd2x      KX,10,KEYS
+  vperm      K,K,K,swap_mask
+  vncipher   S0,S0,ZERO
+  vncipher   S1,S1,ZERO
+  vncipher   S2,S2,ZERO
+  vncipher   S3,S3,ZERO
+  vxor       S0,S0,K
+  vxor       S1,S1,K
+  vxor       S2,S2,K
+  vxor       S3,S3,K
+  addi      10,10,0x10
+  bdnz      L4x_round_loop
+
+  lxvd2x          KX,10,KEYS
+  vperm          K,K,K,swap_mask
+  vncipherlast   S0,S0,K
+  vncipherlast   S1,S1,K
+  vncipherlast   S2,S2,K
+  vncipherlast   S3,S3,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+  vperm      S2,S2,S2,swap_mask
+  vperm      S3,S3,S3,swap_mask
+
+  stxvd2x     S0X,0,DST
+  li        9,0x10
+  stxvd2x     S1X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S2X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S3X,9,DST
+
+  addi      SRC,SRC,0x40
+  addi      DST,DST,0x40
+
+  clrldi   LENGTH,LENGTH,62
+
+L2x:
+  srdi      5,LENGTH,1
+  cmpldi      5,0
+  beq       L1x
+
+  lxvd2x      KX,0,KEYS
+
+  lxvd2x      S0X,0,SRC
+  li        9,0x10
+  lxvd2x      S1X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L2x_round_loop:
+  lxvd2x      KX,10,KEYS
+  vperm      K,K,K,swap_mask
+  vncipher   S0,S0,ZERO
+  vncipher   S1,S1,ZERO
+  vxor       S0,S0,K
+  vxor       S1,S1,K
+  addi      10,10,0x10
+  bdnz      L2x_round_loop
+
+  lxvd2x          KX,10,KEYS
+  vperm          K,K,K,swap_mask
+  vncipherlast   S0,S0,K
+  vncipherlast   S1,S1,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+
+  stxvd2x     S0X,0,DST
+  li        9,0x10
+  stxvd2x     S1X,9,DST
+
+  addi      SRC,SRC,0x20
+  addi      DST,DST,0x20
+
+  clrldi   LENGTH,LENGTH,63
+
+L1x:
+  cmpldi      LENGTH,0
+  beq       Ldone
+
+  lxvd2x      KX,0,KEYS
+
+  lxvd2x      S0X,0,SRC
+
+  vxor      S0,S0,K
+
+  vperm      S0,S0,S0,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L1x_round_loop:
+  lxvd2x      KX,10,KEYS
+  vperm      K,K,K,swap_mask
+  vncipher   S0,S0,ZERO
+  vxor       S0,S0,K
+  addi      10,10,0x10
+  bdnz      L1x_round_loop
+
+  lxvd2x          KX,10,KEYS
+  vperm          K,K,K,swap_mask
+  vncipherlast   S0,S0,K
+
+  vperm      S0,S0,S0,swap_mask
+
+  stxvd2x     S0X,0,DST
+
+Ldone:
+  blr
+EPILOGUE(_nettle_aes_decrypt)
+
+  .data
+  .align   4
+.swap_mask:
+  .byte 8,9,10,11,12,13,14,15,0,1,2,3,4,5,6,7
diff -urN nettle/powerpc64le/aes-encrypt-internal.asm
nettle_PowerPC64LE/powerpc64le/aes-encrypt-internal.asm
--- nettle/powerpc64le/aes-encrypt-internal.asm 1970-01-01
02:00:00.000000000 +0200
+++ nettle_PowerPC64LE/powerpc64le/aes-encrypt-internal.asm 2020-06-14
21:45:21.463826800 +0300
@@ -0,0 +1,534 @@
+C powerpc64le/aes-encrypt-internal.asm
+
+ifelse(&lt;
+   Copyright (C) 2020 Mamone Tarsha
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+&gt;)
+
+C Register usage:
+
+define(&lt;SP&gt;, &lt;1&gt;)
+define(&lt;TOCP&gt;, &lt;2&gt;)
+
+define(&lt;ROUNDS&gt;, &lt;3&gt;)
+define(&lt;KEYS&gt;, &lt;4&gt;)
+define(&lt;LENGTH&gt;, &lt;6&gt;)
+define(&lt;DST&gt;, &lt;7&gt;)
+define(&lt;SRC&gt;, &lt;8&gt;)
+
+define(&lt;swap_mask&gt;, &lt;0&gt;)
+
+define(&lt;K&gt;, &lt;1&gt;)
+define(&lt;S0&gt;, &lt;2&gt;)
+define(&lt;S1&gt;, &lt;3&gt;)
+define(&lt;S2&gt;, &lt;4&gt;)
+define(&lt;S3&gt;, &lt;5&gt;)
+define(&lt;S4&gt;, &lt;6&gt;)
+define(&lt;S5&gt;, &lt;7&gt;)
+define(&lt;S6&gt;, &lt;8&gt;)
+define(&lt;S7&gt;, &lt;9&gt;)
+define(&lt;S8&gt;, &lt;10&gt;)
+define(&lt;S9&gt;, &lt;11&gt;)
+define(&lt;S10&gt;, &lt;12&gt;)
+define(&lt;S11&gt;, &lt;13&gt;)
+define(&lt;S12&gt;, &lt;14&gt;)
+define(&lt;S13&gt;, &lt;15&gt;)
+define(&lt;S14&gt;, &lt;16&gt;)
+define(&lt;S15&gt;, &lt;17&gt;)
+
+define(&lt;KX&gt;, &lt;33&gt;)
+define(&lt;S0X&gt;, &lt;34&gt;)
+define(&lt;S1X&gt;, &lt;35&gt;)
+define(&lt;S2X&gt;, &lt;36&gt;)
+define(&lt;S3X&gt;, &lt;37&gt;)
+define(&lt;S4X&gt;, &lt;38&gt;)
+define(&lt;S5X&gt;, &lt;39&gt;)
+define(&lt;S6X&gt;, &lt;40&gt;)
+define(&lt;S7X&gt;, &lt;41&gt;)
+define(&lt;S8X&gt;, &lt;42&gt;)
+define(&lt;S9X&gt;, &lt;43&gt;)
+define(&lt;S10X&gt;, &lt;44&gt;)
+define(&lt;S11X&gt;, &lt;45&gt;)
+define(&lt;S12X&gt;, &lt;46&gt;)
+define(&lt;S13X&gt;, &lt;47&gt;)
+define(&lt;S14X&gt;, &lt;48&gt;)
+define(&lt;S15X&gt;, &lt;49&gt;)
+
+  .file "aes-encrypt-internal.asm"
+
+  C _aes_encrypt(unsigned rounds, const uint32_t *keys,
+  C         const struct aes_table *T,
+  C         size_t length, uint8_t *dst,
+  C         uint8_t *src)
+
+  .text
+.align 5
+PROLOGUE(_nettle_aes_encrypt)
+  ld          5,.swap_mask@got(TOCP)
+  lvx         swap_mask,0,5
+
+  subi      ROUNDS,ROUNDS,1
+  srdi      LENGTH,LENGTH,4
+
+  srdi      5,LENGTH,4              # 16x loop count
+  cmpldi      5,0
+  beq       L8x
+
+  std       17,-120(SP);
+  std       18,-112(SP);
+  std       19,-104(SP);
+  std       20,-96(SP);
+  std       21,-88(SP);
+  std       22,-80(SP);
+  std       23,-72(SP);
+  std       24,-64(SP);
+  std       25,-56(SP);
+  std       26,-48(SP);
+  std       27,-40(SP);
+  std       28,-32(SP);
+  std       29,-24(SP);
+  std       30,-16(SP);
+  std       31,-8(SP);
+
+  li        17,0x10
+  li        18,0x20
+  li        19,0x30
+  li        20,0x40
+  li        21,0x50
+  li        22,0x60
+  li        23,0x70
+  li        24,0x80
+  li        25,0x90
+  li        26,0xA0
+  li        27,0xB0
+  li        28,0xC0
+  li        29,0xD0
+  li        30,0xE0
+  li        31,0xF0
+
+.align 5
+Lx16_loop:
+  lxvd2x      KX,0,KEYS
+
+  lxvd2x      S0X,0,SRC
+  lxvd2x      S1X,17,SRC
+  lxvd2x      S2X,18,SRC
+  lxvd2x      S3X,19,SRC
+  lxvd2x      S4X,20,SRC
+  lxvd2x      S5X,21,SRC
+  lxvd2x      S6X,22,SRC
+  lxvd2x      S7X,23,SRC
+  lxvd2x      S8X,24,SRC
+  lxvd2x      S9X,25,SRC
+  lxvd2x      S10X,26,SRC
+  lxvd2x      S11X,27,SRC
+  lxvd2x      S12X,28,SRC
+  lxvd2x      S13X,29,SRC
+  lxvd2x      S14X,30,SRC
+  lxvd2x      S15X,31,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+  vxor      S4,S4,K
+  vxor      S5,S5,K
+  vxor      S6,S6,K
+  vxor      S7,S7,K
+  vxor      S8,S8,K
+  vxor      S9,S9,K
+  vxor      S10,S10,K
+  vxor      S11,S11,K
+  vxor      S12,S12,K
+  vxor      S13,S13,K
+  vxor      S14,S14,K
+  vxor      S15,S15,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+  vperm      S2,S2,S2,swap_mask
+  vperm      S3,S3,S3,swap_mask
+  vperm      S4,S4,S4,swap_mask
+  vperm      S5,S5,S5,swap_mask
+  vperm      S6,S6,S6,swap_mask
+  vperm      S7,S7,S7,swap_mask
+  vperm      S8,S8,S8,swap_mask
+  vperm      S9,S9,S9,swap_mask
+  vperm      S10,S10,S10,swap_mask
+  vperm      S11,S11,S11,swap_mask
+  vperm      S12,S12,S12,swap_mask
+  vperm      S13,S13,S13,swap_mask
+  vperm      S14,S14,S14,swap_mask
+  vperm      S15,S15,S15,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L16x_round_loop:
+  lxvd2x      KX,10,KEYS
+  vperm      K,K,K,swap_mask
+  vcipher   S0,S0,K
+  vcipher   S1,S1,K
+  vcipher   S2,S2,K
+  vcipher   S3,S3,K
+  vcipher   S4,S4,K
+  vcipher   S5,S5,K
+  vcipher   S6,S6,K
+  vcipher   S7,S7,K
+  vcipher   S8,S8,K
+  vcipher   S9,S9,K
+  vcipher   S10,S10,K
+  vcipher   S11,S11,K
+  vcipher   S12,S12,K
+  vcipher   S13,S13,K
+  vcipher   S14,S14,K
+  vcipher   S15,S15,K
+  addi      10,10,0x10
+  bdnz      L16x_round_loop
+
+  lxvd2x          KX,10,KEYS
+  vperm          K,K,K,swap_mask
+  vcipherlast   S0,S0,K
+  vcipherlast   S1,S1,K
+  vcipherlast   S2,S2,K
+  vcipherlast   S3,S3,K
+  vcipherlast   S4,S4,K
+  vcipherlast   S5,S5,K
+  vcipherlast   S6,S6,K
+  vcipherlast   S7,S7,K
+  vcipherlast   S8,S8,K
+  vcipherlast   S9,S9,K
+  vcipherlast   S10,S10,K
+  vcipherlast   S11,S11,K
+  vcipherlast   S12,S12,K
+  vcipherlast   S13,S13,K
+  vcipherlast   S14,S14,K
+  vcipherlast   S15,S15,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+  vperm      S2,S2,S2,swap_mask
+  vperm      S3,S3,S3,swap_mask
+  vperm      S4,S4,S4,swap_mask
+  vperm      S5,S5,S5,swap_mask
+  vperm      S6,S6,S6,swap_mask
+  vperm      S7,S7,S7,swap_mask
+  vperm      S8,S8,S8,swap_mask
+  vperm      S9,S9,S9,swap_mask
+  vperm      S10,S10,S10,swap_mask
+  vperm      S11,S11,S11,swap_mask
+  vperm      S12,S12,S12,swap_mask
+  vperm      S13,S13,S13,swap_mask
+  vperm      S14,S14,S14,swap_mask
+  vperm      S15,S15,S15,swap_mask
+
+  stxvd2x     S0X,0,DST
+  stxvd2x     S1X,17,DST
+  stxvd2x     S2X,18,DST
+  stxvd2x     S3X,19,DST
+  stxvd2x     S4X,20,DST
+  stxvd2x     S5X,21,DST
+  stxvd2x     S6X,22,DST
+  stxvd2x     S7X,23,DST
+  stxvd2x     S8X,24,DST
+  stxvd2x     S9X,25,DST
+  stxvd2x     S10X,26,DST
+  stxvd2x     S11X,27,DST
+  stxvd2x     S12X,28,DST
+  stxvd2x     S13X,29,DST
+  stxvd2x     S14X,30,DST
+  stxvd2x     S15X,31,DST
+
+  addi      SRC,SRC,0x100
+  addi      DST,DST,0x100
+  subic.    5,5,1
+  bne       Lx16_loop
+
+  ld        17,-120(SP);
+  ld        18,-112(SP);
+  ld        19,-104(SP);
+  ld        20,-96(SP);
+  ld        21,-88(SP);
+  ld        22,-80(SP);
+  ld        23,-72(SP);
+  ld        24,-64(SP);
+  ld        25,-56(SP);
+  ld        26,-48(SP);
+  ld        27,-40(SP);
+  ld        28,-32(SP);
+  ld        29,-24(SP);
+  ld        30,-16(SP);
+  ld        31,-8(SP);
+
+  clrldi   LENGTH,LENGTH,60
+
+L8x:
+  srdi      5,LENGTH,3
+  cmpldi      5,0
+  beq       L4x
+
+  lxvd2x      KX,0,KEYS
+
+  lxvd2x      S0X,0,SRC
+  li        9,0x10
+  lxvd2x      S1X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S2X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S3X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S4X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S5X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S6X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S7X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+  vxor      S4,S4,K
+  vxor      S5,S5,K
+  vxor      S6,S6,K
+  vxor      S7,S7,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+  vperm      S2,S2,S2,swap_mask
+  vperm      S3,S3,S3,swap_mask
+  vperm      S4,S4,S4,swap_mask
+  vperm      S5,S5,S5,swap_mask
+  vperm      S6,S6,S6,swap_mask
+  vperm      S7,S7,S7,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L8x_round_loop:
+  lxvd2x      KX,10,KEYS
+  vperm      K,K,K,swap_mask
+  vcipher   S0,S0,K
+  vcipher   S1,S1,K
+  vcipher   S2,S2,K
+  vcipher   S3,S3,K
+  vcipher   S4,S4,K
+  vcipher   S5,S5,K
+  vcipher   S6,S6,K
+  vcipher   S7,S7,K
+  addi      10,10,0x10
+  bdnz      L8x_round_loop
+
+  lxvd2x          KX,10,KEYS
+  vperm          K,K,K,swap_mask
+  vcipherlast   S0,S0,K
+  vcipherlast   S1,S1,K
+  vcipherlast   S2,S2,K
+  vcipherlast   S3,S3,K
+  vcipherlast   S4,S4,K
+  vcipherlast   S5,S5,K
+  vcipherlast   S6,S6,K
+  vcipherlast   S7,S7,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+  vperm      S2,S2,S2,swap_mask
+  vperm      S3,S3,S3,swap_mask
+  vperm      S4,S4,S4,swap_mask
+  vperm      S5,S5,S5,swap_mask
+  vperm      S6,S6,S6,swap_mask
+  vperm      S7,S7,S7,swap_mask
+
+  stxvd2x     S0X,0,DST
+  li        9,0x10
+  stxvd2x     S1X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S2X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S3X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S4X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S5X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S6X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S7X,9,DST
+
+  addi      SRC,SRC,0x80
+  addi      DST,DST,0x80
+
+  clrldi   LENGTH,LENGTH,61
+
+L4x:
+  srdi      5,LENGTH,2
+  cmpldi      5,0
+  beq       L2x
+
+  lxvd2x      KX,0,KEYS
+
+  lxvd2x      S0X,0,SRC
+  li        9,0x10
+  lxvd2x      S1X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S2X,9,SRC
+  addi      9,9,0x10
+  lxvd2x      S3X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+  vperm      S2,S2,S2,swap_mask
+  vperm      S3,S3,S3,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L4x_round_loop:
+  lxvd2x      KX,10,KEYS
+  vperm      K,K,K,swap_mask
+  vcipher   S0,S0,K
+  vcipher   S1,S1,K
+  vcipher   S2,S2,K
+  vcipher   S3,S3,K
+  addi      10,10,0x10
+  bdnz      L4x_round_loop
+
+  lxvd2x          KX,10,KEYS
+  vperm          K,K,K,swap_mask
+  vcipherlast   S0,S0,K
+  vcipherlast   S1,S1,K
+  vcipherlast   S2,S2,K
+  vcipherlast   S3,S3,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+  vperm      S2,S2,S2,swap_mask
+  vperm      S3,S3,S3,swap_mask
+
+  stxvd2x     S0X,0,DST
+  li        9,0x10
+  stxvd2x     S1X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S2X,9,DST
+  addi      9,9,0x10
+  stxvd2x     S3X,9,DST
+
+  addi      SRC,SRC,0x40
+  addi      DST,DST,0x40
+
+  clrldi   LENGTH,LENGTH,62
+
+L2x:
+  srdi      5,LENGTH,1
+  cmpldi      5,0
+  beq       L1x
+
+  lxvd2x      KX,0,KEYS
+
+  lxvd2x      S0X,0,SRC
+  li        9,0x10
+  lxvd2x      S1X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L2x_round_loop:
+  lxvd2x      KX,10,KEYS
+  vperm      K,K,K,swap_mask
+  vcipher   S0,S0,K
+  vcipher   S1,S1,K
+  addi      10,10,0x10
+  bdnz      L2x_round_loop
+
+  lxvd2x          KX,10,KEYS
+  vperm          K,K,K,swap_mask
+  vcipherlast   S0,S0,K
+  vcipherlast   S1,S1,K
+
+  vperm      S0,S0,S0,swap_mask
+  vperm      S1,S1,S1,swap_mask
+
+  stxvd2x     S0X,0,DST
+  li        9,0x10
+  stxvd2x     S1X,9,DST
+
+  addi      SRC,SRC,0x20
+  addi      DST,DST,0x20
+
+  clrldi   LENGTH,LENGTH,63
+
+L1x:
+  cmpldi      LENGTH,0
+  beq       Ldone
+
+  lxvd2x      KX,0,KEYS
+
+  lxvd2x      S0X,0,SRC
+
+  vxor      S0,S0,K
+
+  vperm      S0,S0,S0,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L1x_round_loop:
+  lxvd2x      KX,10,KEYS
+  vperm      K,K,K,swap_mask
+  vcipher   S0,S0,K
+  addi      10,10,0x10
+  bdnz      L1x_round_loop
+
+  lxvd2x          KX,10,KEYS
+  vperm          K,K,K,swap_mask
+  vcipherlast   S0,S0,K
+
+  vperm      S0,S0,S0,swap_mask
+
+  stxvd2x     S0X,0,DST
+
+Ldone:
+  blr
+EPILOGUE(_nettle_aes_encrypt)
+
+  .data
+  .align   4
+.swap_mask:
+  .byte 8,9,10,11,12,13,14,15,0,1,2,3,4,5,6,7
diff -urN nettle/powerpc64le/gcm-hash8.asm
nettle_PowerPC64LE/powerpc64le/gcm-hash8.asm
--- nettle/powerpc64le/gcm-hash8.asm   1970-01-01 02:00:00.000000000 +0200
+++ nettle_PowerPC64LE/powerpc64le/gcm-hash8.asm   2020-06-14
21:47:12.539221100 +0300
@@ -0,0 +1,992 @@
+C powerpc64le/gcm-hash8.asm
+
+ifelse(&lt;
+   Copyright (C) 2020 Mamone Tarsha
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+&gt;)
+
+C Register usage:
+C VSX instructions is used to load and store data to memory "lxvd2x, stxvd2x"
+C instead of VR instructions "lvx, stvx" as a workaround to access
unaligned data
+C VSX registers are defined with "X" suffix
+
+define(&lt;SP&gt;, &lt;1&gt;)
+define(&lt;TOCP&gt;, &lt;2&gt;)
+
+define(&lt;TABLE&gt;, &lt;3&gt;)
+define(&lt;X&gt;, &lt;4&gt;)
+define(&lt;LENGTH&gt;, &lt;5&gt;)
+define(&lt;DATA&gt;, &lt;6&gt;)
+
+define(&lt;zero&gt;, &lt;0&gt;)
+define(&lt;swap_mask&gt;, &lt;1&gt;)
+define(&lt;hidw_mask&gt;, &lt;2&gt;)
+define(&lt;lodw_mask&gt;, &lt;3&gt;)
+define(&lt;poly&gt;, &lt;4&gt;)
+define(&lt;poly_h&gt;, &lt;4&gt;)
+define(&lt;poly_l&gt;, &lt;5&gt;)
+define(&lt;RP&gt;, &lt;6&gt;)
+define(&lt;Mh&gt;, &lt;7&gt;)
+define(&lt;Ml&gt;, &lt;8&gt;)
+define(&lt;H&gt;, &lt;9&gt;)
+define(&lt;Hh&gt;, &lt;10&gt;)
+define(&lt;Hl&gt;, &lt;11&gt;)
+define(&lt;RP2&gt;, &lt;9&gt;)
+define(&lt;M2h&gt;, &lt;10&gt;)
+define(&lt;M2l&gt;, &lt;11&gt;)
+
+define(&lt;HX&gt;, &lt;41&gt;)
+define(&lt;HhX&gt;, &lt;42&gt;)
+define(&lt;HlX&gt;, &lt;43&gt;)
+define(&lt;H_HhX&gt;, &lt;44&gt;)
+define(&lt;H_HX&gt;, &lt;45&gt;)
+define(&lt;H_HlX&gt;, &lt;46&gt;)
+
+define(&lt;sl1&gt;, &lt;1&gt;)
+define(&lt;msb&gt;, &lt;5&gt;)
+define(&lt;H2&gt;, &lt;6&gt;)
+define(&lt;H2h&gt;, &lt;7&gt;)
+define(&lt;H2l&gt;, &lt;8&gt;)
+define(&lt;H_h&gt;, &lt;12&gt;)
+define(&lt;H_m&gt;, &lt;13&gt;)
+define(&lt;H_l&gt;, &lt;14&gt;)
+define(&lt;H_Hh&gt;, &lt;12&gt;)
+define(&lt;H_H&gt;, &lt;13&gt;)
+define(&lt;H_Hl&gt;, &lt;14&gt;)
+define(&lt;H_t&gt;, &lt;15&gt;)
+define(&lt;H2_h&gt;, &lt;16&gt;)
+define(&lt;H2_m&gt;, &lt;17&gt;)
+define(&lt;H2_l&gt;, &lt;18&gt;)
+define(&lt;H2_t&gt;, &lt;19&gt;)
+
+define(&lt;C0X&gt;, &lt;38&gt;)
+define(&lt;C1X&gt;, &lt;39&gt;)
+define(&lt;C2X&gt;, &lt;40&gt;)
+define(&lt;C3X&gt;, &lt;44&gt;)
+define(&lt;C4X&gt;, &lt;38&gt;)
+define(&lt;C5X&gt;, &lt;39&gt;)
+define(&lt;C6X&gt;, &lt;40&gt;)
+define(&lt;C7X&gt;, &lt;44&gt;)
+
+define(&lt;CX&gt;, &lt;45&gt;)
+
+define(&lt;C0&gt;, &lt;6&gt;)
+define(&lt;C1&gt;, &lt;7&gt;)
+define(&lt;C2&gt;, &lt;8&gt;)
+define(&lt;C3&gt;, &lt;12&gt;)
+define(&lt;C4&gt;, &lt;6&gt;)
+define(&lt;C5&gt;, &lt;7&gt;)
+define(&lt;C6&gt;, &lt;8&gt;)
+define(&lt;C7&gt;, &lt;12&gt;)
+
+define(&lt;C&gt;, &lt;13&gt;)
+
+define(&lt;Ch&gt;, &lt;14&gt;)
+define(&lt;Cl&gt;, &lt;15&gt;)
+define(&lt;Cm&gt;, &lt;16&gt;)
+
+define(&lt;C01h&gt;, &lt;14&gt;)
+define(&lt;C01l&gt;, &lt;15&gt;)
+define(&lt;C01&gt;, &lt;16&gt;)
+define(&lt;C23h&gt;, &lt;17&gt;)
+define(&lt;C23l&gt;, &lt;18&gt;)
+define(&lt;C23&gt;, &lt;19&gt;)
+define(&lt;C45h&gt;, &lt;20&gt;)
+define(&lt;C45l&gt;, &lt;21&gt;)
+define(&lt;C45&gt;, &lt;22&gt;)
+define(&lt;C67h&gt;, &lt;6&gt;)
+define(&lt;C67l&gt;, &lt;7&gt;)
+define(&lt;C67&gt;, &lt;8&gt;)
+
+define(&lt;H21&gt;, &lt;9&gt;)
+define(&lt;H21h&gt;, &lt;10&gt;)
+define(&lt;H21l&gt;, &lt;11&gt;)
+define(&lt;H43&gt;, &lt;23&gt;)
+define(&lt;H43h&gt;, &lt;24&gt;)
+define(&lt;H43l&gt;, &lt;25&gt;)
+define(&lt;H65&gt;, &lt;26&gt;)
+define(&lt;H65h&gt;, &lt;27&gt;)
+define(&lt;H65l&gt;, &lt;28&gt;)
+define(&lt;H87&gt;, &lt;29&gt;)
+define(&lt;H87h&gt;, &lt;30&gt;)
+define(&lt;H87l&gt;, &lt;31&gt;)
+
+define(&lt;H21X&gt;, &lt;41&gt;)
+define(&lt;H21hX&gt;, &lt;42&gt;)
+define(&lt;H21lX&gt;, &lt;43&gt;)
+define(&lt;H43X&gt;, &lt;55&gt;)
+define(&lt;H43hX&gt;, &lt;56&gt;)
+define(&lt;H43lX&gt;, &lt;57&gt;)
+define(&lt;H65X&gt;, &lt;58&gt;)
+define(&lt;H65hX&gt;, &lt;59&gt;)
+define(&lt;H65lX&gt;, &lt;60&gt;)
+define(&lt;H87X&gt;, &lt;61&gt;)
+define(&lt;H87hX&gt;, &lt;62&gt;)
+define(&lt;H87lX&gt;, &lt;63&gt;)
+
+# gcm_fill registers:
+
+define(&lt;CTR&gt;, &lt;3&gt;)
+define(&lt;BLOCKS&gt;, &lt;4&gt;)
+define(&lt;BUFFER&gt;, &lt;5&gt;)
+
+define(&lt;CTR0&gt;, &lt;2&gt;)
+define(&lt;CTR0S&gt;, &lt;3&gt;)
+define(&lt;CTR1&gt;, &lt;4&gt;)
+define(&lt;CTR2&gt;, &lt;5&gt;)
+define(&lt;CTR3&gt;, &lt;6&gt;)
+define(&lt;CTR4&gt;, &lt;7&gt;)
+define(&lt;CTR5&gt;, &lt;8&gt;)
+define(&lt;CTR6&gt;, &lt;9&gt;)
+define(&lt;CTR7&gt;, &lt;10&gt;)
+
+define(&lt;CTR0X&gt;, &lt;34&gt;)
+define(&lt;CTR0SX&gt;, &lt;35&gt;)
+define(&lt;CTR1X&gt;, &lt;36&gt;)
+define(&lt;CTR2X&gt;, &lt;37&gt;)
+define(&lt;CTR3X&gt;, &lt;38&gt;)
+define(&lt;CTR4X&gt;, &lt;39&gt;)
+define(&lt;CTR5X&gt;, &lt;40&gt;)
+define(&lt;CTR6X&gt;, &lt;41&gt;)
+define(&lt;CTR7X&gt;, &lt;42&gt;)
+
+define(&lt;I1&gt;, &lt;11&gt;)
+define(&lt;I2&gt;, &lt;12&gt;)
+define(&lt;I3&gt;, &lt;13&gt;)
+define(&lt;I4&gt;, &lt;14&gt;)
+define(&lt;I5&gt;, &lt;15&gt;)
+define(&lt;I6&gt;, &lt;16&gt;)
+define(&lt;I7&gt;, &lt;17&gt;)
+define(&lt;I8&gt;, &lt;18&gt;)
+
+  .file "gcm-hash8.asm"
+
+  # void gcm_init_key (union gcm_block *table)
+
+    .text
+.align 5
+PROLOGUE(_nettle_gcm_init_key8)
+    ld           7,.polynomial@got(TOCP)
+  lvx            poly,0,7
+  ld          7,.swap_mask@got(TOCP)
+  lvx         swap_mask,0,7
+  ld          7,.hidw_mask@got(TOCP)
+  lvx         hidw_mask,0,7
+  ld          7,.lodw_mask@got(TOCP)
+  lvx            lodw_mask,0,7
+
+  li        10,0x800
+    lxvd2x    HX,10,TABLE          # load H
+  vperm    H,H,H,swap_mask
+
+  # --- calculate H = H shift left 1 modulo polynomial ---
+
+  vupkhsw      msb,H               # most significant bit word-extend
+  vspltisb sl1,1             # splat 1 for shift left
+  vspltw      msb,msb,0            # most significant bit extend
+  vsl          H,H,sl1             # H shift left 1
+  vand     msb,msb,poly
+  vxor     zero,zero,zero
+  vxor     H_t,H,msb
+
+  vsldoi      H,H_t,H_t,8          # doubleword swap
+  vsldoi      Hh,H,zero,8
+  vsldoi      Hl,zero,H,8
+
+  # --- calculate H^2 = H*H ---
+
+  # reduction pre-processing
+  vsldoi      poly_h,zero,poly,8
+  vsldoi      poly_l,poly_h,poly_h,8
+
+  # polynomial multiplication "classical"
+  vpmsumd     H_h,H_t,Hh           # H^1h*H^1h
+  vpmsumd     H_l,H_t,Hl           # H^1l*H^1l
+  vpmsumd     H_m,H_t,H            # H^1h*H^1l⊕H^1l*H^1h
+
+  # reduction first phase          # [1]
+  vpmsumd     RP,H_l,poly_h        # [1]
+
+  # polynomial multiplication post-processing # [2]
+  vsldoi      Mh,zero,H_m,8           # [2]
+  vsldoi      Ml,H_m,zero,8        # [2]
+  vsldoi      RP,RP,RP,8           # [1]
+  vxor     H_h,H_h,Mh           # [2]
+  vxor     H_l,H_l,Ml           # [2]
+  vxor     H_l,H_l,RP           # [1]
+
+  # reduction second phase
+  vpmsumd     RP,H_l,poly_l
+  vxor     H_h,H_l,H_h
+  vxor     H2_t,H_h,RP
+
+  vsldoi      H2,H2_t,H2_t,8
+  vsldoi      H2h,H2,zero,8
+  vsldoi      H2l,zero,H2,8
+
+  # --- calculate [H^2.Hi⊕H^2.Lo:H^1.Hi⊕H^1.Lo] ---
+
+  vperm    H_Hh,H2,H,lodw_mask
+  vperm    H_Hl,H2,H,hidw_mask
+  vxor     H_H,H_Hh,H_Hl
+
+  # --- store H,[H^2.Hi⊕H^2.Lo:H^1.Hi⊕H^1.Lo] ---
+
+  li        8,0x00
+  li        9,0x100
+  li        10,0x200
+  stxvd2x     HlX,8,TABLE
+  stxvd2x     HX,9,TABLE
+  stxvd2x     HhX,10,TABLE
+
+  li        8,0x300
+  li        9,0x400
+  li        10,0x500
+  stxvd2x     H_HhX,8,TABLE
+  stxvd2x     H_HX,9,TABLE
+  stxvd2x     H_HlX,10,TABLE
+
+  # --- calculate H^3,H^4 ---
+
+  # polynomial multiplication "classical"
+  vpmsumd     H_l,H_t,H2l          # H^1l*H^2l
+  vpmsumd     H_m,H_t,H2           # H^1h*H^2l⊕H^1l*H^2h
+  vpmsumd     H_h,H_t,H2h          # H^1h*H^2h
+  vpmsumd     H2_l,H2_t,H2l        # H^2l*H^2l
+  vpmsumd     H2_m,H2_t,H2         # H^2h*H^2l⊕H^2l*H^2h
+  vpmsumd     H2_h,H2_t,H2h        # H^2h*H^2h
+
+  # reduction first phase             # [1]
+  vpmsumd     RP,H_l,poly_h        # [1] H^3
+  vpmsumd      RP2,H2_l,poly_h        # [1] H^4
+
+  # polynomial multiplication post-processing # [2]
+  vsldoi      Mh,zero,H_m,8        # [2] H^3
+  vsldoi      M2h,zero,H2_m,8         # [2] H^4
+  vsldoi      Ml,H_m,zero,8        # [2] H^3
+  vsldoi      M2l,H2_m,zero,8         # [2] H^4
+  vsldoi      RP,RP,RP,8           # [1] H^3
+  vsldoi      RP2,RP2,RP2,8        # [1] H^4
+  vxor     H_h,H_h,Mh           # [2] H^3
+  vxor     H2_h,H2_h,M2h        # [2] H^4
+  vxor     H_l,H_l,Ml           # [2] H^3
+  vxor     H2_l,H2_l,M2l        # [2] H^4
+  vxor     H_l,H_l,RP           # [1] H^3
+  vxor     H2_l,H2_l,RP2        # [1] H^4
+
+  # reduction second phase
+  vpmsumd     RP,H_l,poly_l        # H^3
+  vpmsumd     RP2,H2_l,poly_l         # H^4
+  vxor     H_h,H_l,H_h          # H^3
+  vxor     H2_h,H2_l,H2_h       # H^4
+  vxor     H_h,H_h,RP           # H^3
+  vxor     H2_h,H2_h,RP2        # H^4
+
+  vsldoi      H2,H2_h,H2_h,8       # H^4
+  vsldoi      H,H_h,H_h,8          # H^3
+  vsldoi      H2l,zero,H2,8        # H^4
+  vsldoi      H2h,H2,zero,8        # H^4
+
+  # --- calculate [H^4.Hi⊕H^4.Lo:H^3.Hi⊕H^3.Lo] ---
+
+  vperm    H_Hh,H2,H,lodw_mask
+  vperm    H_Hl,H2,H,hidw_mask
+  vxor     H_H,H_Hh,H_Hl
+
+  # --- store [H^4.Hi⊕H^4.Lo:H^3.Hi⊕H^3.Lo] ---
+
+  li        8,0x600
+  li        9,0x700
+  li        10,0x800
+  stxvd2x     H_HhX,8,TABLE
+  stxvd2x     H_HX,9,TABLE
+  stxvd2x     H_HlX,10,TABLE
+
+  # --- calculate H^5,H^6 ---
+
+  # polynomial multiplication "classical"
+  vpmsumd     H_l,H_t,H2l          # H^1l*H^4l
+  vpmsumd     H_m,H_t,H2           # H^1h*H^4l⊕H^1l*H^4h
+  vpmsumd     H_h,H_t,H2h          # H^1h*H^4h
+  vpmsumd     H2_l,H2_t,H2l        # H^2l*H^4l
+  vpmsumd     H2_m,H2_t,H2         # H^2h*H^4l⊕H^2l*H^4h
+  vpmsumd     H2_h,H2_t,H2h        # H^2h*H^4h
+
+  # reduction first phase             # [1]
+  vpmsumd     RP,H_l,poly_h        # [1] H^5
+  vpmsumd      RP2,H2_l,poly_h        # [1] H^6
+
+  # polynomial multiplication post-processing # [2]
+  vsldoi      Mh,zero,H_m,8        # [2] H^5
+  vsldoi      M2h,zero,H2_m,8         # [2] H^6
+  vsldoi      Ml,H_m,zero,8        # [2] H^5
+  vsldoi      M2l,H2_m,zero,8         # [2] H^6
+  vsldoi      RP,RP,RP,8           # [1] H^5
+  vsldoi      RP2,RP2,RP2,8        # [1] H^6
+  vxor     H_h,H_h,Mh           # [2] H^5
+  vxor     H2_h,H2_h,M2h        # [2] H^6
+  vxor     H_l,H_l,Ml           # [2] H^5
+  vxor     H2_l,H2_l,M2l        # [2] H^6
+  vxor     H_l,H_l,RP           # [1] H^5
+  vxor     H2_l,H2_l,RP2        # [1] H^6
+
+  # reduction second phase
+  vpmsumd     RP,H_l,poly_l        # H^5
+  vpmsumd     RP2,H2_l,poly_l   # H^6
+  vxor     H_h,H_l,H_h          # H^5
+  vxor     H2_h,H2_l,H2_h       # H^6
+  vxor     H_h,H_h,RP           # H^5
+  vxor     H2_h,H2_h,RP2        # H^6
+
+  vsldoi      H2,H2_h,H2_h,8       # H^6
+  vsldoi      H,H_h,H_h,8          # H^5
+  vsldoi      H2l,zero,H2,8        # H^6
+  vsldoi      H2h,H2,zero,8        # H^6
+
+  # --- calculate [H^6.Hi⊕H^6.Lo:H^5.Hi⊕H^5.Lo] ---
+
+  vperm    H_Hh,H2,H,lodw_mask
+  vperm    H_Hl,H2,H,hidw_mask
+  vxor     H_H,H_Hh,H_Hl
+
+  # --- store [H^6.Hi⊕H^6.Lo:H^5.Hi⊕H^5.Lo] ---
+
+  li        8,0x900
+  li        9,0xA00
+  li        10,0xB00
+  stxvd2x     H_HhX,8,TABLE
+  stxvd2x     H_HX,9,TABLE
+  stxvd2x     H_HlX,10,TABLE
+
+  # --- calculate H^7,H^8 ---
+
+  # polynomial multiplication "classical"
+  vpmsumd     H_l,H_t,H2l          # H^1l*H^6l
+  vpmsumd     H_m,H_t,H2           # H^1h*H^6l⊕H^1l*H^6h
+  vpmsumd     H_h,H_t,H2h          # H^1h*H^6h
+  vpmsumd     H2_l,H2_t,H2l        # H^2l*H^6l
+  vpmsumd     H2_m,H2_t,H2         # H^2h*H^6l⊕H^2l*H^6h
+  vpmsumd     H2_h,H2_t,H2h        # H^2h*H^6h
+
+  # reduction first phase             # [1]
+  vpmsumd     RP,H_l,poly_h        # [1] H^7
+  vpmsumd      RP2,H2_l,poly_h        # [1] H^8
+
+  # polynomial multiplication post-processing # [2]
+  vsldoi      Mh,zero,H_m,8        # [2] H^7
+  vsldoi      M2h,zero,H2_m,8         # [2] H^8
+  vsldoi      Ml,H_m,zero,8        # [2] H^7
+  vsldoi      M2l,H2_m,zero,8         # [2] H^8
+  vsldoi      RP,RP,RP,8           # [1] H^7
+  vsldoi      RP2,RP2,RP2,8        # [1] H^8
+  vxor     H_h,H_h,Mh           # [2] H^7
+  vxor     H2_h,H2_h,M2h        # [2] H^8
+  vxor     H_l,H_l,Ml           # [2] H^7
+  vxor     H2_l,H2_l,M2l        # [2] H^8
+  vxor     H_l,H_l,RP           # [1] H^7
+  vxor     H2_l,H2_l,RP2        # [1] H^8
+
+  # reduction second phase
+  vpmsumd     RP,H_l,poly_l        # H^7
+  vpmsumd     RP2,H2_l,poly_l         # H^8
+  vxor     H_h,H_l,H_h          # H^7
+  vxor     H2_h,H2_l,H2_h       # H^8
+  vxor     H_h,H_h,RP           # H^7
+  vxor     H2_h,H2_h,RP2        # H^8
+
+  vsldoi      H,H_h,H_h,8          # H^7
+  vsldoi      H2,H2_h,H2_h,8       # H^8
+
+  # --- calculate [H^8.Hi⊕H^8.Lo:H^7.Hi⊕H^7.Lo] ---
+
+  vperm    H_Hh,H2,H,lodw_mask
+  vperm    H_Hl,H2,H,hidw_mask
+  vxor     H_H,H_Hh,H_Hl
+
+  # --- store [H^8.Hi⊕H^8.Lo:H^7.Hi⊕H^7.Lo] ---
+
+  li        8,0xC00
+  li        9,0xD00
+  li        10,0xE00
+  stxvd2x     H_HhX,8,TABLE
+  stxvd2x     H_HX,9,TABLE
+  stxvd2x     H_HlX,10,TABLE
+
+    blr
+EPILOGUE(_nettle_gcm_init_key8)
+
+  # void gcm_hash (const struct gcm_key *key, union gcm_block *x,
+  #                size_t length, const uint8_t *data)
+
+.align 5
+PROLOGUE(_nettle_gcm_hash8)
+    vxor      zero,zero,zero
+
+  ld          7,.polynomial@got(TOCP)
+  lvx            poly,0,7
+  ld          7,.swap_mask@got(TOCP)
+  lvx         swap_mask,0,7
+  ld        7,.hidw_mask@got(TOCP)
+  lvx         hidw_mask,0,7
+  ld          7,.lodw_mask@got(TOCP)
+  lvx            lodw_mask,0,7
+
+  vsldoi      poly_h,zero,poly,8
+  vsldoi      poly_l,poly_h,poly_h,8
+
+  lxvd2x      CX,0,X               # load X
+  vperm    C,C,C,swap_mask
+
+  srdi     7,LENGTH,7           # 8x loop count
+  cmpldi      7,0
+  beq         L2x
+
+  # backup registers
+  stdu     SP,-224(SP)
+  std         28,216(SP)
+  std         29,208(SP)
+  std         30,200(SP)
+  std         31,192(SP)
+    li        8,176
+    stvx      20,8,SP
+    subi      8,8,16
+    stvx      21,8,SP
+    subi      8,8,16
+    stvx      22,8,SP
+    subi      8,8,16
+    stvx      23,8,SP
+    subi      8,8,16
+    stvx      24,8,SP
+    subi      8,8,16
+    stvx      25,8,SP
+    subi      8,8,16
+    stvx      26,8,SP
+    subi      8,8,16
+    stvx      27,8,SP
+    subi      8,8,16
+    stvx      28,8,SP
+    subi      8,8,16
+    stvx      29,8,SP
+    subi      8,8,16
+    stvx      30,8,SP
+    subi      8,8,16
+    stvx      31,8,SP
+
+  # table loading
+  li       8,0x300
+  li       9,0x400
+  li       10,0x500
+  lxvd2x      H21hX,8,TABLE
+  lxvd2x      H21X,9,TABLE
+  lxvd2x      H21lX,10,TABLE
+  li       8,0x600
+  li       9,0x700
+  li       10,0x800
+  lxvd2x      H43hX,8,TABLE
+  lxvd2x      H43X,9,TABLE
+  lxvd2x      H43lX,10,TABLE
+  li       8,0x900
+  li       9,0xA00
+  li       10,0xB00
+  lxvd2x      H65hX,8,TABLE
+  lxvd2x      H65X,9,TABLE
+  lxvd2x      H65lX,10,TABLE
+  li       8,0xC00
+  li       9,0xD00
+  li       10,0xE00
+  lxvd2x      H87hX,8,TABLE
+  lxvd2x      H87X,9,TABLE
+  lxvd2x      H87lX,10,TABLE
+
+  li       8,0x10
+  li       9,0x20
+  li       10,0x30
+  li       28,0x40
+  li       29,0x50
+  li       30,0x60
+  li       31,0x70
+
+  mtctr       7
+.align 5
+L8x_loop:
+  # input loading
+  lxvd2x      C0X,0,DATA           # load C0
+  lxvd2x      C1X,8,DATA           # load C1
+  lxvd2x      C2X,9,DATA           # load C2
+  lxvd2x      C3X,10,DATA          # load C3
+
+  # swap permuting
+  vperm    C0,C0,C0,swap_mask
+  vperm    C1,C1,C1,swap_mask
+  vperm    C2,C2,C2,swap_mask
+  vperm    C3,C3,C3,swap_mask
+
+  # previous digest combining
+  vxor     C0,C0,C
+
+  # polynomial multiplication "karatsuba" pre-processing
+  vperm    C23h,C2,C3,hidw_mask
+  vperm    C23l,C2,C3,lodw_mask
+  vperm    C01h,C0,C1,hidw_mask
+  vperm    C01l,C0,C1,lodw_mask
+
+  # input loading
+  lxvd2x      C4X,28,DATA          # load C4
+  lxvd2x      C5X,29,DATA          # load C5
+  lxvd2x      C6X,30,DATA          # load C6
+  lxvd2x      C7X,31,DATA          # load C7
+
+  # swap permuting
+  vperm    C4,C4,C4,swap_mask
+  vperm    C5,C5,C5,swap_mask
+  vperm    C6,C6,C6,swap_mask
+  vperm    C7,C7,C7,swap_mask
+
+  # polynomial multiplication "karatsuba" pre-processing
+  vperm    C45h,C4,C5,hidw_mask
+  vperm    C45l,C4,C5,lodw_mask
+  vperm    C67h,C6,C7,hidw_mask
+  vperm    C67l,C6,C7,lodw_mask
+  vxor     C23,C23h,C23l
+  vxor     C01,C01h,C01l
+  vxor     C45,C45h,C45l
+  vxor     C67,C67h,C67l
+
+  # polynomial multiplication "karatsuba"
+  vpmsumd     C23h,C23h,H65h       # H23 = H^6h*C2h⊕H^5h*C3h
+  vpmsumd     C23l,C23l,H65l       # L23 = H^6l*C2l⊕H^5l*C3l
+  vpmsumd     C01h,C01h,H87h       # H01 = H^8h*C0h⊕H^7h*C1h
+  vpmsumd     C01l,C01l,H87l       # L01 = H^8l*C0l⊕H^7l*C1l
+  vpmsumd     C67h,C67h,H21h       # H67 = H^2h*C6h⊕H^1h*C7h
+  vpmsumd     C67l,C67l,H21l       # L67 = H^2l*C6l⊕H^1l*C7l
+  vpmsumd     C45h,C45h,H43h       # H45 = H^4h*C4h⊕H^3h*C5h
+  vpmsumd     C45l,C45l,H43l       # L45 = H^4l*C4l⊕H^3l*C5l
+  vpmsumd     C23,C23,H65          # M23 =
(H^6h⊕H^5h)*(C2h⊕C3h)⊕(H^6l⊕H^5l)*(C2l⊕C3l)
+  vpmsumd     C01,C01,H87          # M01 =
(H^8h⊕H^7h)*(C0h⊕C1h)⊕(H^8l⊕H^7l)*(C0l⊕C1l)
+  vpmsumd     C45,C45,H43          # M45 =
(H^4h⊕H^3h)*(C4h⊕C5h)⊕(H^4l⊕H^3l)*(C4l⊕C5l)
+  vpmsumd     C67,C67,H21          # M67 =
(H^2h⊕H^1h)*(C6h⊕C7h)⊕(H^2l⊕H^1l)*(C6l⊕C7l)
+
+  # polynomial multiplication "karatsuba" post-processing
+  vxor     C23,C23,C23h
+  vxor     C01,C01,C01h
+  vxor     C45,C45,C45h
+  vxor     C67,C67,C67h
+  vxor     C23,C23,C23l
+  vxor     C01,C01,C01l
+  vxor     C45,C45,C45l
+  vxor     C67,C67,C67l
+
+  # deferred recombination of partial products
+  vxor     C01h,C01h,C23h       # H0 = H01⊕H23
+  vxor     C45h,C45h,C67h       # H1 = H45⊕H67
+  vxor     C01l,C01l,C23l       # L0 = L01⊕L23
+  vxor     C45l,C45l,C67l       # L1 = L45⊕L45
+  vxor     C01,C01,C23          # M0 = M01⊕M23
+  vxor     C45,C45,C67          # M1 = M45⊕M45
+  vxor     C01h,C01h,C45h       # H = H0⊕H1
+  vxor     C01l,C01l,C45l       # L = L0⊕L1
+  vxor     C01,C01,C45          # M = M0⊕M1
+
+  # reduction first phase          # [1]
+  vpmsumd     RP,C01l,poly_h       # [1]
+
+  # polynomial multiplication post-processing # [2]
+  vsldoi      Mh,zero,C01,8           # [2]
+  vsldoi      Ml,C01,zero,8           # [2]
+  vsldoi      RP,RP,RP,8              # [1]
+  vxor     C01h,C01h,Mh         # [2]
+  vxor     C01l,C01l,Ml         # [2]
+  vxor     C01l,C01l,RP         # [1]
+
+  # reduction second phase
+  vpmsumd     RP,C01l,poly_l
+  vxor     C01h,C01l,C01h
+  vxor     C,C01h,RP
+
+  addi     DATA,DATA,0x80
+  bdnz     L8x_loop
+
+    # restore registers
+  li       8,0
+    lvx       31,8,SP
+    addi      8,8,16
+    lvx       30,8,SP
+    addi      8,8,16
+    lvx       29,8,SP
+    addi      8,8,16
+    lvx       28,8,SP
+    addi      8,8,16
+    lvx       27,8,SP
+    addi      8,8,16
+    lvx       26,8,SP
+    addi      8,8,16
+    lvx       25,8,SP
+    addi      8,8,16
+    lvx       24,8,SP
+    addi      8,8,16
+    lvx       23,8,SP
+    addi      8,8,16
+    lvx       22,8,SP
+    addi      8,8,16
+    lvx       21,8,SP
+    addi      8,8,16
+    lvx       20,8,SP
+  ld       31,192(SP)
+  ld       30,200(SP)
+  ld       29,208(SP)
+  ld       28,216(SP)
+  addi     SP,SP,224
+
+  clrldi   LENGTH,LENGTH,57
+L2x:
+  srdi     7,LENGTH,5
+  cmpldi      7,0
+  beq         L1x
+
+  # table loading
+  li       8,0x300
+  li       9,0x400
+  li       10,0x500
+  lxvd2x      H21hX,8,TABLE
+  lxvd2x      H21X,9,TABLE
+  lxvd2x      H21lX,10,TABLE
+
+  li       10,0x10
+
+  mtctr       7
+.align 5
+L2x_loop:
+  # input loading
+  lxvd2x      C0X,0,DATA           # load C0
+  lxvd2x      C1X,10,DATA          # load C1
+
+  # swap permuting
+  vperm    C0,C0,C0,swap_mask
+  vperm    C1,C1,C1,swap_mask
+
+  # previous digest combining
+  vxor     C0,C0,C
+
+  # polynomial multiplication "karatsuba" pre-processing
+  vperm    C01h,C0,C1,hidw_mask
+  vperm    C01l,C0,C1,lodw_mask
+  vxor     C01,C01h,C01l
+
+  # polynomial multiplication "karatsuba"
+  vpmsumd     C01h,C01h,H21h       # H01 = H^2h*C0h⊕H^1h*C1h
+  vpmsumd     C01l,C01l,H21l       # L01 = H^2l*C0l⊕H^1l*C1l
+  vpmsumd     C01,C01,H21          # M01 =
(H^2h⊕H^1h)*(C0h⊕C1h)⊕(H^2l⊕H^1l)*(C0l⊕C1l)
+
+  # polynomial multiplication "karatsuba" post-processing
+  vxor     C01,C01,C01h
+  vxor     C01,C01,C01l
+
+  # reduction first phase          # [1]
+  vpmsumd     RP,C01l,poly_h       # [1]
+
+  # polynomial multiplication post-processing # [2]
+  vsldoi      Mh,zero,C01,8           # [2]
+  vsldoi      Ml,C01,zero,8           # [2]
+  vsldoi      RP,RP,RP,8              # [1]
+  vxor     C01h,C01h,Mh         # [2]
+  vxor     C01l,C01l,Ml         # [2]
+  vxor     C01l,C01l,RP         # [1]
+
+  # reduction second phase
+  vpmsumd     RP,C01l,poly_l
+  vxor     C01h,C01l,C01h
+  vxor     C,C01h,RP
+
+  addi     DATA,DATA,0x20
+  bdnz     L2x_loop
+
+  clrldi   LENGTH,LENGTH,59
+L1x:
+  srdi     7,LENGTH,4
+  cmpldi      7,0
+  beq         Lrem
+
+  # table loading
+  li       9,0x100
+  li       10,0x200
+  lxvd2x      HlX,0,TABLE
+  lxvd2x      HX, 9,TABLE
+  lxvd2x      HhX,10,TABLE
+
+  # input loading
+  lxvd2x      C0X,0,DATA           # load C0
+
+  # swap permuting
+  vperm    C0,C0,C0,swap_mask
+
+  # previous digest combining
+  vxor     C0,C0,C
+
+  vpmsumd     Cl,C0,Hl          # L = Hl*Cl
+  vpmsumd     Cm,C0,H              # M = Hh*Cl⊕Hl*Ch
+  vpmsumd     Ch,C0,Hh          # H = Hh*Ch
+
+  # reduction first phase          # [1]
+  vpmsumd     RP,Cl,poly_h         # [1]
+
+  # polynomial multiplication post-processing # [2]
+  vsldoi      Mh,zero,Cm,8         # [2]
+  vsldoi      Ml,Cm,zero,8         # [2]
+  vsldoi      RP,RP,RP,8              # [1]
+  vxor     Ch,Ch,Mh             # [2]
+  vxor     Cl,Cl,Ml             # [2]
+  vxor     Cl,Cl,RP             # [1]
+
+  # reduction second phase
+  vpmsumd     RP,Cl,poly_l
+  vxor     Ch,Cl,Ch
+  vxor     C,Ch,RP
+
+  addi     DATA,DATA,0x10
+  clrldi   LENGTH,LENGTH,60
+Lrem:
+  cmpldi      LENGTH,0
+  beq         Ldone
+
+  # table loading
+  li       9,0x100
+  li       10,0x200
+  lxvd2x      HlX,0,TABLE
+  lxvd2x      HX, 9,TABLE
+  lxvd2x      HhX,10,TABLE
+
+  # input loading
+  stdu     SP,-16(SP)
+  stvx     zero,0,SP
+Lst_loop:
+  subic.      LENGTH,LENGTH,1
+  lbzx     7,LENGTH,DATA
+  stbx     7,LENGTH,SP
+  bne         Lst_loop
+  lxvd2x         C0X,0,SP
+  addi     SP,SP,16
+
+  # swap permuting
+  vperm    C0,C0,C0,swap_mask
+
+  # previous digest combining
+  vxor     C0,C0,C
+
+  vpmsumd     Cl,C0,Hl          # L = Hl*Cl
+  vpmsumd     Cm,C0,H              # M = Hh*Cl⊕Hl*Ch
+  vpmsumd     Ch,C0,Hh          # H = Hh*Ch
+
+  # reduction first phase          # [1]
+  vpmsumd     RP,Cl,poly_h         # [1]
+
+  # polynomial multiplication post-processing # [2]
+  vsldoi      Mh,zero,Cm,8         # [2]
+  vsldoi      Ml,Cm,zero,8         # [2]
+  vsldoi      RP,RP,RP,8              # [1]
+  vxor     Ch,Ch,Mh             # [2]
+  vxor     Cl,Cl,Ml                # [2]
+  vxor     Cl,Cl,RP             # [1]
+
+  # reduction second phase
+  vpmsumd     RP,Cl,poly_l
+  vxor     Ch,Cl,Ch
+  vxor     C,Ch,RP
+
+Ldone:
+  vperm    C,C,C,swap_mask
+  stxvd2x     CX,0,X               # store C
+  blr
+EPILOGUE(_nettle_gcm_hash8)
+
+  # gcm_fill (uint8_t *ctr, size_t blocks, union gcm_block *buffer)
+
+.align 5
+PROLOGUE(_nettle_gcm_fill)
+  ld       6,.swap_mask@got(TOCP)
+  lvx      swap_mask,0,6
+
+  vxor     zero,zero,zero
+  vspltisb I1,1
+  vspltisb I2,2
+  vspltisb I3,3
+  vspltisb I4,4
+  vspltisb I5,5
+  vspltisb I6,6
+  vspltisb I7,7
+  vspltisb I8,8
+  vsldoi   I1,zero,I1,1
+  vsldoi   I2,zero,I2,1
+  vsldoi   I3,zero,I3,1
+  vsldoi   I4,zero,I4,1
+  vsldoi   I5,zero,I5,1
+  vsldoi   I6,zero,I6,1
+  vsldoi   I7,zero,I7,1
+  vsldoi   I8,zero,I8,1
+
+  lxvd2x   CTR0X,0,CTR
+  vperm    CTR0,CTR0,CTR0,swap_mask
+
+  srdi      6,BLOCKS,3              # 8x loop count
+  cmpldi   6,0
+  beq       Lfill_4x
+
+  std       25,-56(SP);
+  std       26,-48(SP);
+  std       27,-40(SP);
+  std       28,-32(SP);
+  std       29,-24(SP);
+  std       30,-16(SP);
+  std       31,-8(SP);
+
+  li        25,0x10
+  li        26,0x20
+  li        27,0x30
+  li        28,0x40
+  li        29,0x50
+  li        30,0x60
+  li        31,0x70
+
+  mtctr     6
+L8x_fill_loop:
+  vadduwm  CTR1,CTR0,I1
+  vadduwm  CTR2,CTR0,I2
+  vadduwm  CTR3,CTR0,I3
+  vadduwm  CTR4,CTR0,I4
+  vadduwm  CTR5,CTR0,I5
+  vadduwm  CTR6,CTR0,I6
+  vadduwm  CTR7,CTR0,I7
+
+  vperm    CTR0S,CTR0,CTR0,swap_mask
+  vperm    CTR1,CTR1,CTR1,swap_mask
+  vperm    CTR2,CTR2,CTR2,swap_mask
+  vperm    CTR3,CTR3,CTR3,swap_mask
+  vperm    CTR4,CTR4,CTR4,swap_mask
+  vperm    CTR5,CTR5,CTR5,swap_mask
+  vperm    CTR6,CTR6,CTR6,swap_mask
+  vperm    CTR7,CTR7,CTR7,swap_mask
+
+  stxvd2x  CTR0SX,0,BUFFER
+  stxvd2x  CTR1X,25,BUFFER
+  stxvd2x  CTR2X,26,BUFFER
+  stxvd2x  CTR3X,27,BUFFER
+  stxvd2x  CTR4X,28,BUFFER
+  stxvd2x  CTR5X,29,BUFFER
+  stxvd2x  CTR6X,30,BUFFER
+  stxvd2x  CTR7X,31,BUFFER
+
+  vadduwm  CTR0,CTR0,I8
+  addi     BUFFER,BUFFER,0x80
+  bdnz      L8x_fill_loop
+
+  ld        25,-56(SP);
+  ld        26,-48(SP);
+  ld        27,-40(SP);
+  ld        28,-32(SP);
+  ld        29,-24(SP);
+  ld        30,-16(SP);
+  ld        31,-8(SP);
+
+  clrldi   BLOCKS,BLOCKS,61
+
+Lfill_4x:
+  srdi      6,BLOCKS,2
+  cmpldi   6,0
+  beq       Lfill_2x
+
+  li        8,0x10
+  li        9,0x20
+  li        10,0x30
+
+  vadduwm  CTR1,CTR0,I1
+  vadduwm  CTR2,CTR0,I2
+  vadduwm  CTR3,CTR0,I3
+
+  vperm    CTR0S,CTR0,CTR0,swap_mask
+  vperm    CTR1,CTR1,CTR1,swap_mask
+  vperm    CTR2,CTR2,CTR2,swap_mask
+  vperm    CTR3,CTR3,CTR3,swap_mask
+
+  stxvd2x  CTR0SX,0,BUFFER
+  stxvd2x  CTR1X,8,BUFFER
+  stxvd2x  CTR2X,9,BUFFER
+  stxvd2x  CTR3X,10,BUFFER
+
+  vadduwm  CTR0,CTR0,I4
+  addi     BUFFER,BUFFER,0x40
+
+  clrldi   BLOCKS,BLOCKS,62
+
+Lfill_2x:
+  srdi      6,BLOCKS,1
+  cmpldi   6,0
+  beq       Lfill_1x
+
+  li        10,0x10
+
+  vadduwm  CTR1,CTR0,I1
+
+  vperm    CTR0S,CTR0,CTR0,swap_mask
+  vperm    CTR1,CTR1,CTR1,swap_mask
+
+  stxvd2x  CTR0SX,0,BUFFER
+  stxvd2x  CTR1X,10,BUFFER
+
+  vadduwm  CTR0,CTR0,I2
+  addi     BUFFER,BUFFER,0x20
+
+  clrldi   BLOCKS,BLOCKS,63
+
+Lfill_1x:
+  cmpldi   BLOCKS,0
+  beq       Lfill_done
+
+  vperm    CTR0S,CTR0,CTR0,swap_mask
+
+  stxvd2x  CTR0SX,0,BUFFER
+
+  vadduwm  CTR0,CTR0,I1
+
+Lfill_done:
+  vperm    CTR0,CTR0,CTR0,swap_mask
+  stxvd2x  CTR0X,0,CTR
+
+  blr
+EPILOGUE(_nettle_gcm_fill)
+
+    .data
+    .align 4
+.polynomial:
+  .byte 1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0xc2
+    .align 4
+.swap_mask:
+  .byte 8,9,10,11,12,13,14,15,0,1,2,3,4,5,6,7
+    .align 4
+.hidw_mask:
+  .byte 23,22,21,20,19,18,17,16,7,6,5,4,3,2,1,0
+    .align 4
+.lodw_mask:
+  .byte 31,30,29,28,27,26,25,24,15,14,13,12,11,10,9,8
diff -urN nettle/testsuite/gcm-test.c nettle_PowerPC64LE/testsuite/gcm-test.c
--- nettle/testsuite/gcm-test.c  2020-06-08 08:42:20.000000000 +0300
+++ nettle_PowerPC64LE/testsuite/gcm-test.c  2020-06-14 05:25:42.645815700 +0300
@@ -170,6 +170,29 @@
       "16aedbf5a0de6a57a637b39b"),
       SHEX("619cc5aefffe0bfa462af43c1699d050"));

+  /* Test 128 bytes */
+  test_aead(&amp;nettle_gcm_aes128, NULL,
+      SHEX("feffe9928665731c6d6a8f9467308308"),
+      SHEX(""),
+      SHEX("d9313225f88406e5a55909c5aff5269a"
+      "86a7a9531534f7da2e4c303d8a318a72"
+      "1c3c0c95956809532fcf0e2449a6b525"
+      "b16aedf5aa0de657ba637b391aafd255"
+      "5ae376bc5e9f6a1b08e34db7a6ee0736"
+      "9ba662ea12f6f197e6bc3ed69d2480f3"
+      "ea5691347f2ba69113eb37910ebc18c8"
+      "0f697234582016fa956ca8f63ae6b473"),
+      SHEX("42831ec2217774244b7221b784d0d49c"
+      "e3aa212f2c02a4e035c17e2329aca12e"
+      "21d514b25466931c7d8f6a5aac84aa05"
+      "1ba30b396a0aac973d58e091473f5985"
+      "874b1178906ddbeab04ab2fe6cce8c57"
+      "8d7e961bd13fd6a8c56b66ca5e576492"
+      "1a48cd8bda04e66343e73055118b69b9"
+      "ced486813846958a11e602c03cfc232b"),
+      SHEX("cafebabefacedbaddecaf888"),
+      SHEX("796836f1246c9d735c5e1be0a715ccc3"));
+
   /* Test case 7 */
   test_aead(&amp;nettle_gcm_aes192, NULL,
       SHEX("00000000000000000000000000000000"


On Thu, Jun 18, 2020 at 6:58 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
wrote:

&gt; I added a PowerPC64LE optimized version of AES and GHASH to nettle.
&gt; Patch summary:
&gt; 
&gt; GHASH Algorithm
&gt; 
&gt; I took the advantage of several references and researches to achieve the
&gt; high-speed implementation of this algorithm. These references include
&gt; several techniques that have been used to improve the performance of the
&gt; algorithm, I will summarize the important techniques used as follows:
&gt; 
&gt; - The main equation: The main equation for 4 block (128-bit each) can
&gt; be seen in reference [1]  Digest =
&gt; (((((((Digest⊕C0)*H)⊕C1)*H)⊕C2)*H)⊕C3)*H =
&gt; ((Digest⊕C0)*H4)⊕(C1*H3)⊕(C2*H2)⊕(C3*H) to achieve more parallelism,
&gt; this equation can be modified to address 8 blocks per one loop. It looks
&gt; like as follows Digest =
&gt; ((Digest⊕C0)*H8)⊕(C1*H7)⊕(C2*H6)⊕(C3*H5)⊕(C4*H4)⊕(C5*H3)⊕(C6*H2)⊕(C7*H)
&gt;                 
&gt; - Handling Bit-reflection of the multiplication product [1]: This
&gt; technique moves part of the workload inside the loop to the init function
&gt; so it is executed only once.
&gt; - Karatsuba Algorithm: This algorithm allows to perform three
&gt; multiplication instructions instead of four, in exchange for two additional
&gt; Xor. This technique is well explained with figures in reference [1]
&gt; - Deferred Recombination of partial products This technique is well
&gt; explained with figures in reference [1]
&gt; - Multiplication-based reduction: I tested both classical shift-based
&gt; reduction and multiplication-based reduction, the multiplication-based
&gt; reduction achieved better performance and less instructions. Example of
&gt; both reductions can be seen in reference [2]
&gt; 
&gt; AES
&gt; Power ISA makes it easy to optimize AES by offering built-in AES
&gt; instructions.
&gt; 
&gt; AES-GCM performance (Tested on POWER9):
&gt; 
&gt; - GCM_AES Encrypt ~x13.5 of nettle C implementation
&gt; - GCM_AES Decrypt ~x13.5 of nettle C implementation
&gt; - GCM_AES Update (Only GHASH is called) ~x26 of nettle C implementation
&gt; 
&gt; Notes:
&gt; 
&gt; - Test 128 bytes is added to gcm-test in testsuite to test 8x loop in
&gt; GHASH optimized function.
&gt; - Since the functionality of gcm_set_key() is replaced with
&gt; gcm_init_key() for PowerPC64LE, two warnings will pop up: [‘gcm_gf_shift'
&gt; defined but not used] and [‘gcm_gf_add' defined but not used]
&gt; 
&gt; References: [1]
&gt; https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/communications-ia-galois-counter-mode-paper.pdf
&gt;  [2]
&gt; https://www.intel.com/content/dam/www/public/us/en/documents/software-support/enabling-high-performance-gcm.pdf
&gt;  [3] https://software.intel.com/file/24918 [4]
&gt; https://github.com/dot-asm/cryptogams
&gt; 
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200607113417</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-06-07 11:34:17-0400</timestampReceived><subject>Re: [PATCH v3] Implement GOST R 34.11-2012 (Streebog) hash function</subject><body>

Hello,

сб, 6 июн. 2020 г. в 18:38, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt;
&gt; Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:
&gt;
&gt; &gt; I've sent the fixup. I'm fine with it being squashed into this patch.
&gt;
&gt; Done. I've merged this patch and the test patch to master-updates now.

I noticed that gnutls build fails with the current master-updates.
GnuTLS requires the HMAC-STREEBOG patch to be present. Could you
please add it to master-updates?

-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200608055824</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-06-08 05:58:24-0400</timestampReceived><subject>Re: [PATCH v3] Implement GOST R 34.11-2012 (Streebog) hash function</subject><body>

Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:

&gt; I noticed that gnutls build fails with the current master-updates.
&gt; GnuTLS requires the HMAC-STREEBOG patch to be present. Could you
&gt; please add it to master-updates?

Done. But to me, not all errors looked hmac-related, e.g., 

5358 mac.c:98:26: error: field 'streebog256' has incomplete type
5359    98 |   struct streebog256_ctx streebog256;
5360       |                          ^~~~~~~~~~~
5361 mac.c:99:26: error: field 'streebog512' has incomplete type

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200602104539</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-06-02 10:45:39-0400</timestampReceived><subject>[PATCH v2 7/8] pbkdf2-test: add PBKDF2 tests using Streebog HMAC function</subject><body>

Add test vectors from R 50.1.111-2016 to verify using HMAC-STREEBOG in
PBKDF2 function.

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 testsuite/pbkdf2-test.c | 31 ++++++++++++++++++++++++++++++-
 1 file changed, 30 insertions(+), 1 deletion(-)

diff --git a/testsuite/pbkdf2-test.c b/testsuite/pbkdf2-test.c
index e64a20d09dea..365c8a0d8fe8 100644
--- a/testsuite/pbkdf2-test.c
+++ b/testsuite/pbkdf2-test.c
@@ -19,7 +19,8 @@
     ASSERT(dk[expect-&gt;length] == 17);					\
   } while (0)
 
-#define MAX_DKLEN SHA512_DIGEST_SIZE
+/* Streebog test has particularly long testcase */
+#define MAX_DKLEN 100
 
 void
 test_main (void)
@@ -29,6 +30,8 @@ test_main (void)
   struct hmac_sha256_ctx sha256ctx;
   struct hmac_sha512_ctx sha512ctx;
   struct hmac_gosthash94cp_ctx gosthash94cpctx;
+  struct hmac_streebog512_ctx streebog512ctx;
+  struct hmac_streebog256_ctx streebog256ctx;
 
   /* Test vectors for PBKDF2 from RFC 6070. */
 
@@ -134,4 +137,30 @@ test_main (void)
 
   PBKDF2_HMAC_TEST (pbkdf2_hmac_gosthash94cp, LDATA("password"), 1, LDATA("salt"),
 	       SHEX("7314e7c04fb2e662c543674253f68bd0b73445d07f241bed872882da21662d58"));
+
+  /* From TC26 document R 50.1.111-2016 */
+  hmac_streebog512_set_key (&amp;streebog512ctx, LDATA("password"));
+  PBKDF2_TEST (&amp;streebog512ctx, hmac_streebog512_update, hmac_streebog512_digest,
+	       STREEBOG512_DIGEST_SIZE, 1, LDATA("salt"),
+	       SHEX("64770af7f748c3b1c9ac831dbcfd85c26111b30a8a657ddc3056b80ca73e040d2854fd36811f6d825cc4ab66ec0a68a490a9e5cf5156b3a2b7eecddbf9a16b47"));
 +  PBKDF2_TEST (&amp;streebog512ctx, hmac_streebog512_update, hmac_streebog512_digest,
+	       STREEBOG512_DIGEST_SIZE, 4096, LDATA("salt"),
+	       SHEX("e52deb9a2d2aaff4e2ac9d47a41f34c20376591c67807f0477e32549dc341bc7867c09841b6d58e29d0347c996301d55df0d34e47cf68f4e3c2cdaf1d9ab86c3"));
 +
+  hmac_streebog512_set_key (&amp;streebog512ctx, LDATA("passwordPASSWORDpassword"));
+  PBKDF2_TEST (&amp;streebog512ctx, hmac_streebog512_update, hmac_streebog512_digest,
+	       STREEBOG512_DIGEST_SIZE, 4096, \
LDATA("saltSALTsaltSALTsaltSALTsaltSALTsalt"), +	       \
SHEX("b2d8f1245fc4d29274802057e4b54e0a0753aa22fc53760b301cf008679e58fe4bee9addcae99ba2b0b20f431a9c5e50f395"
 +		    "c89387d0945aedeca6eb4015dfc2bd2421ee9bb71183ba882ceebfef259f33f9e27dc6178cb89dc37428cf9cc52a2baa2d3a"));
 +
+  hmac_streebog512_set_key (&amp;streebog512ctx, LDATA("pass\0word"));
+  PBKDF2_TEST (&amp;streebog512ctx, hmac_streebog512_update, hmac_streebog512_digest,
+	       STREEBOG512_DIGEST_SIZE, 4096, LDATA("sa\0lt"),
+	       SHEX("50df062885b69801a3c10248eb0a27ab6e522ffeb20c991c660f001475d73a4e167f782c18e97e92976d9c1d970831ea78ccb879f67068cdac1910740844e830"));
 +
+  /* Generated */
+  hmac_streebog256_set_key (&amp;streebog256ctx, LDATA("password"));
+  PBKDF2_TEST (&amp;streebog256ctx, hmac_streebog256_update, hmac_streebog256_digest,
+	       STREEBOG256_DIGEST_SIZE, 1, LDATA("salt"),
+	       SHEX("d789458d143b9abebc4ef63ca8e576c72b13c7d4289db23fc1e946f84cd605bc"));
 }
-- 
2.26.2

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200602110055</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-06-02 11:00:55-0400</timestampReceived><subject>Re: [PATCH 1/2] Implement GOST R 34.11-2012 (Streebog) hash function</subject><body>

Hello,

вс, 31 мая 2020 г. в 11:11, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt;
&gt; Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:
&gt;
&gt; &gt; From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;
&gt;
&gt; This is a bit too large to be easy to review in one go. Could you split
&gt; it into a patch with the streebog hash and basic tests only, and hmac
&gt; and pbkdf2-related tests as followups? Otherwise, I could try to review
&gt; and apply one piece at a time, not sure what process would be most
&gt; efficient.

I've split the first patch into the serie of smaller patches. Hope this
eases review.
I can split it further if you want.

V2 has been sent to the mailing list. Also it has been uploaded to
https://git.lysator.liu.se/nettle/nettle/-/merge_requests/6

-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200604232605</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-06-04 23:26:05-0400</timestampReceived><subject>Re: [PATCH v2 1/8] Implement GOST R 34.11-2012 (Streebog) hash function</subject><body>

Hello,

чт, 4 июн. 2020 г. в 20:59, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt;
&gt; Thanks for splitting this out for review. Looks pretty good, a few minor
&gt; comments below.
&gt;
&gt; Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:
&gt;
&gt; &gt; --- /dev/null
&gt; &gt; +++ b/streebog.c
&gt; &gt; @@ -0,0 +1,1334 @@
&gt; &gt; +/* streebog.c - GOST R 34.11-2012 (Streebog) hash function
&gt;
&gt; Would be nice with a reference to an English language spec, both in the
&gt; file header and the docs (later patch). I take it it's RFC 6986?

Yes, I'll add the reference.

&gt;
&gt; &gt; +/* Pre-computed results of multiplication of bytes on A and reordered with
&gt; &gt; +   Pi[]. */
&gt; &gt; +static const uint64_t streebog_table[8][256] =
&gt; &gt; +{
&gt; &gt; +  /* 0 */
&gt; &gt; +  { 0xd01f715b5c7ef8e6ULL, 0x16fa240980778325ULL,
&gt;
&gt; In some ways, UINT64_C(0xd01f715b5c7ef8e6), from stdint.h, is more
&gt; kosher. But ULL is a bit more readable (IMO), so unless it causes any
&gt; practical problems on some platform, I think it's fine as is.
&gt;
&gt; &gt; +static void
&gt; &gt; +streebog512_compress (struct streebog512_ctx *ctx, const uint8_t *input, size_t count)
&gt; &gt; +{
&gt; &gt; +  uint64_t M[8];
&gt; &gt; +  uint64_t l, cf;
&gt; &gt; +  int i;
&gt; &gt; +
&gt; &gt; +  for (i = 0; i &lt; 8; i++, input += 8)
&gt; &gt; +    M[i] = LE_READ_UINT64(input);
&gt; &gt; +
&gt; &gt; +  g (ctx-&gt;state, M, ctx-&gt;count);
&gt; &gt; +  l = ctx-&gt;count[0];
&gt; &gt; +  ctx-&gt;count[0] += count;
&gt; &gt; +  if (ctx-&gt;count[0] &lt; l)
&gt;
&gt; The overflow check could be written
&gt;
&gt;   if (ctx-&gt;count[0] &lt; count)
&gt;
&gt; and then the local variable l can be deleted. I also think it would be
&gt; clearer to change the type of count to uint64_t to match the type of
&gt; ctx-&gt;count. Do I get it right, that the count argument always is fairly
&gt; small?

Yes, count is not greater than 8*64 = 512. Changing it to uint64_t is
an interesting idea.

&gt;
&gt; &gt; +    { /* overflow */
&gt; &gt; +      for (i = 1; i &lt; 8; i++)
&gt; &gt; +        {
&gt; &gt; +          ctx-&gt;count[i]++;
&gt; &gt; +          if (ctx-&gt;count[i] != 0)
&gt; &gt; +            break;
&gt; &gt; +        }
&gt; &gt; +    }
&gt;
&gt; How far can carry propagate here? If I read it correctly, the count
&gt; array represents a 512 bit number, initialized to zero. So will be
&gt; tricky to get test coverage.

Nothing stops one from hashing 4GB array. Or even bigger array.

&gt;
&gt; &gt; +  cf = 0;
&gt; &gt; +  ctx-&gt;sigma[0] += M[0];
&gt; &gt; +  for (i = 1; i &lt; 8; i++)
&gt; &gt; +    {
&gt; &gt; +      if (ctx-&gt;sigma[i-1] != M[i-1])
&gt; &gt; +     cf = (ctx-&gt;sigma[i-1] &lt; M[i-1]);
&gt; &gt; +      ctx-&gt;sigma[i] += M[i] + cf;
&gt; &gt; +    }
&gt;
&gt; This is a bignum addition of the sigma and the M arrays? I think I would
&gt; write it as something like (untested):
&gt;
&gt;   ctx-&gt;sigma[0] += M[0];
&gt;   cf = (ctx-&gt;sigma[0] &lt; M[0]);
&gt;   for (i = 1; i &lt; 8; i++)
&gt;     {
&gt;       ctx-&gt;sigma[i] += cf;
&gt;       cf = (ctx-&gt;sigma[i] &lt; cf);
&gt;       ctx-&gt;sigma[i] += M[i];
&gt;       cf += (ctx-&gt;sigma[i] &lt; M[i]);  /* |= works fine too */
&gt;     }
&gt;
&gt; Or maybe with
&gt;
&gt;   for (i = 1; i &lt; 7; i++) {...}
&gt;   ctx-&gt;sigma[7] += M[7] + cf;
&gt;
&gt; if we want to skip operations for the final carry out.
&gt;
&gt; Maybe with a local variable accumulating the final value for sigma[i],
&gt; to not have to read and write multiple times (but maybe the compiler
&gt; will eliminate memory accesses). For reference, the corresponding GMP C
&gt; loop is at https://gmplib.org/repo/gmp/file/tip/mpn/generic/add_n.c#l37

OK, I'll rewrite it so, but it gives no speedup on my laptop.

[skipped]

&gt; &gt; +  if (leftover)
&gt; &gt; +    {
&gt; &gt; +      /* Truncate to the right size */
&gt; &gt; +      uint64_t word = ctx-&gt;state[offset + i] &lt;&lt; (8*(8 - leftover));
&gt; &gt; +
&gt; &gt; +      do {
&gt; &gt; +     digest[--leftover] = (word &gt;&gt; 56) &amp; 0xff;
&gt; &gt; +     word &lt;&lt;= 8;
&gt; &gt; +      } while (leftover);
&gt; &gt; +    }
&gt;
&gt; Could this use _nettle_write_le64 instead?

Done. I wonder, why I have c&amp;p'd that code (it look so).

-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200605053756</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-06-05 05:37:56-0400</timestampReceived><subject>Re: [PATCH v2 2/8] testsuite: add test for Streebog hash function</subject><body>

Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:

&gt; Add a testuite for Streebog hash function. Test vectors are based on RFC
&gt; 6986.

Hi, tried this out on top of the v3 patch, but doesn't quite work as is.
See below.

&gt; --- /dev/null
&gt; +++ b/testsuite/streebog-test.c
&gt; @@ -0,0 +1,90 @@
&gt; +#include "testutils.h"
&gt; +#include "streebog.h"

nettle_streebog256 and nettle_streebog512 are undeclared after these
includes. Declarations should go in nettle-meta.h (which this file
then needs to include), but that was missing in the previous patch which
added streebog-meta.c.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200605114724</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-06-05 11:47:24-0400</timestampReceived><subject>[PATCH] streebog: add to nettle-meta and nettle-meta-hashes</subject><body>

Add nettle_streebog256 and nettle_streebog512 to nettle meta interface.

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 nettle-meta-hashes.c       | 2 ++
 nettle-meta.h              | 2 ++
 testsuite/meta-hash-test.c | 2 ++
 3 files changed, 6 insertions(+)

diff --git a/nettle-meta-hashes.c b/nettle-meta-hashes.c
index 27b576cdc58c..8e96dd414d23 100644
--- a/nettle-meta-hashes.c
+++ b/nettle-meta-hashes.c
@@ -53,6 +53,8 @@ const struct nettle_hash * const _nettle_hashes[] = {
   &amp;nettle_sha3_256,
   &amp;nettle_sha3_384,
   &amp;nettle_sha3_512,
+  &amp;nettle_streebog256,
+  &amp;nettle_streebog512,
   NULL
 };
 
diff --git a/nettle-meta.h b/nettle-meta.h
index cbcb1e5d5ffb..6a62b653efa6 100644
--- a/nettle-meta.h
+++ b/nettle-meta.h
@@ -143,6 +143,8 @@ extern const struct nettle_hash nettle_sha3_224;
 extern const struct nettle_hash nettle_sha3_256;
 extern const struct nettle_hash nettle_sha3_384;
 extern const struct nettle_hash nettle_sha3_512;
+extern const struct nettle_hash nettle_streebog256;
+extern const struct nettle_hash nettle_streebog512;
 
 struct nettle_mac
 {
diff --git a/testsuite/meta-hash-test.c b/testsuite/meta-hash-test.c
index 7d863a7c386d..eb9f3698e353 100644
--- a/testsuite/meta-hash-test.c
+++ b/testsuite/meta-hash-test.c
@@ -20,6 +20,8 @@ const char* hashes[] = {
   "sha3_256",
   "sha3_384",
   "sha3_512",
+  "streebog256",
+  "streebog512"
 };
 
 void
-- 
2.26.2

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200609164507</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-06-09 16:45:07-0400</timestampReceived><subject>Re: [PATCH v3] Implement GOST R 34.11-2012 (Streebog) hash function</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:
&gt;
&gt;&gt; I noticed that gnutls build fails with the current master-updates.
&gt;&gt; GnuTLS requires the HMAC-STREEBOG patch to be present. Could you
&gt;&gt; please add it to master-updates?
&gt;
&gt; Done.

The CI looks green, so merged to the master branch now.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200612091044</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-06-12 09:10:44-0400</timestampReceived><subject>[PATCH 1/3] v4.0 Blowfish: Prepare for bcrypt support.</subject><body>

---
 blowfish-internal.h | 52 +++++++++++++++++++++++++++++++++++++++++++++
 blowfish.c          | 23 ++++++++++----------
 2 files changed, 64 insertions(+), 11 deletions(-)
 create mode 100644 blowfish-internal.h

diff --git a/blowfish-internal.h b/blowfish-internal.h
new file mode 100644
index 00000000..6ededa88
--- /dev/null
+++ b/blowfish-internal.h
@@ -0,0 +1,52 @@
+/* blowfish-internal.h
+
+   Blowfish block cipher.
+
+   Copyright (C) 2014 Niels Möller
+   Copyright (C) 1998, 2001 FSF, Ray Dassen, Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#ifndef NETTLE_BLOWFISH_INTERNAL_H_INCLUDED
+#define NETTLE_BLOWFISH_INTERNAL_H_INCLUDED
+
+#include "nettle-types.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+extern const struct blowfish_ctx _nettle_blowfish_initial_ctx;
+extern void _nettle_blowfish_encround (const struct blowfish_ctx *ctx,
+                                       uint32_t * ret_xl, uint32_t * ret_xr);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* NETTLE_BLOWFISH_INTERNAL_H_INCLUDED */
diff --git a/blowfish.c b/blowfish.c
index 52040f13..e73caffe 100644
--- a/blowfish.c
+++ b/blowfish.c
@@ -54,12 +54,13 @@
 #include &lt;assert.h&gt;
 
 #include "blowfish.h"
+#include "blowfish-internal.h"
 
 #include "macros.h"
 
 /* precomputed S boxes */
-static const struct blowfish_ctx
-initial_ctx = {
+const struct blowfish_ctx
+_nettle_blowfish_initial_ctx = {
   {
     { /* ks0 */
       0xD1310BA6, 0x98DFB5AC, 0x2FFD72DB, 0xD01ADFB7, 0xB8E1AFED, 0x6A267E96,
@@ -261,8 +262,8 @@ initial_ctx = {
 
 #define R(c, l,r,i)  do { l ^= c-&gt;p[i]; r ^= F(c,l); } while(0)
 
-static void
-encrypt (const struct blowfish_ctx *ctx, uint32_t * ret_xl,
+void
+_nettle_blowfish_encround (const struct blowfish_ctx *ctx, uint32_t * ret_xl,
 	    uint32_t * ret_xr)
 {
   uint32_t xl, xr;
@@ -295,7 +296,7 @@ encrypt (const struct blowfish_ctx *ctx, uint32_t * ret_xl,
 }
 
 static void
-decrypt (const struct blowfish_ctx *ctx, uint32_t * ret_xl, uint32_t * ret_xr)
+decround (const struct blowfish_ctx *ctx, uint32_t * ret_xl, uint32_t * ret_xr)
 {
   uint32_t xl, xr;
 
@@ -339,7 +340,7 @@ blowfish_encrypt (const struct blowfish_ctx *ctx,
 
       d1 = READ_UINT32(src);
       d2 = READ_UINT32(src+4);
-      encrypt (ctx, &amp;d1, &amp;d2);
+      _nettle_blowfish_encround (ctx, &amp;d1, &amp;d2);
       dst[0] = (d1 &gt;&gt; 24) &amp; 0xff;
       dst[1] = (d1 &gt;&gt; 16) &amp; 0xff;
       dst[2] = (d1 &gt;&gt; 8) &amp; 0xff;
@@ -361,7 +362,7 @@ blowfish_decrypt (const struct blowfish_ctx *ctx,
 
       d1 = READ_UINT32(src);
       d2 = READ_UINT32(src+4);
-      decrypt (ctx, &amp;d1, &amp;d2);
+      decround (ctx, &amp;d1, &amp;d2);
       dst[0] = (d1 &gt;&gt; 24) &amp; 0xff;
       dst[1] = (d1 &gt;&gt; 16) &amp; 0xff;
       dst[2] = (d1 &gt;&gt; 8) &amp; 0xff;
@@ -380,7 +381,7 @@ blowfish_set_key (struct blowfish_ctx *ctx,
   int i, j;
   uint32_t data, datal, datar;
 
-  *ctx = initial_ctx;
+  *ctx = _nettle_blowfish_initial_ctx;
 
   for (i = j = 0; i &lt; _BLOWFISH_ROUNDS + 2; i++)
     {
@@ -393,15 +394,15 @@ blowfish_set_key (struct blowfish_ctx *ctx,
   datal = datar = 0;
   for (i = 0; i &lt; _BLOWFISH_ROUNDS + 2; i += 2)
     {
-      encrypt (ctx, &amp;datal, &amp;datar);
+      _nettle_blowfish_encround (ctx, &amp;datal, &amp;datar);
       ctx-&gt;p[i] = datal;
       ctx-&gt;p[i + 1] = datar;
     }
-  
+
   for (j = 0; j &lt; 4; j++)
     for (i = 0; i &lt; 256; i += 2)
       {
-	encrypt (ctx, &amp;datal, &amp;datar);
+	_nettle_blowfish_encround (ctx, &amp;datal, &amp;datar);
 	ctx-&gt;s[j][i] = datal;
 	ctx-&gt;s[j][i + 1] = datar;
     }
-- 
2.20.1


[Attachment #3 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200612091146</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-06-12 09:11:46-0400</timestampReceived><subject>[PATCH 2/3] v4.0 Blowfish: Add bcrypt support.</subject><body>

---
 Makefile.in       |   2 +-
 blowfish-bcrypt.c | 519 ++++++++++++++++++++++++++++++++++++++++++++++
 blowfish.h        |  15 ++
 nettle.texinfo    |  67 ++++++
 4 files changed, 602 insertions(+), 1 deletion(-)
 create mode 100644 blowfish-bcrypt.c

diff --git a/Makefile.in b/Makefile.in
index 64ff1001..77efb5c9 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -73,7 +73,7 @@ nettle_SOURCES = aes-decrypt-internal.c aes-decrypt.c \
 		 aes256-set-encrypt-key.c aes256-set-decrypt-key.c \
 		 aes256-meta.c \
 		 arcfour.c arcfour-crypt.c \
-		 arctwo.c arctwo-meta.c blowfish.c \
+		 arctwo.c arctwo-meta.c blowfish.c blowfish-bcrypt.c \
 		 base16-encode.c base16-decode.c base16-meta.c \
 		 base64-encode.c base64-decode.c base64-meta.c \
 		 base64url-encode.c base64url-decode.c base64url-meta.c \
diff --git a/blowfish-bcrypt.c b/blowfish-bcrypt.c
new file mode 100644
index 00000000..c06f9e90
--- /dev/null
+++ b/blowfish-bcrypt.c
@@ -0,0 +1,519 @@
+/* blowfish-bcrypt.c
+
+   The blowfish bcrypt implementation.
+
+   Copyright (c) 2020 Stephen R. van den Berg
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+#include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;string.h&gt;
+#include &lt;stdlib.h&gt;
+
+#include "blowfish.h"
+#include "blowfish-internal.h"
+#include "base64.h"
+
+#include "macros.h"
+
+#define CRYPTPLEN 7
+#define SALTLEN ((BLOWFISH_BCRYPT_BINSALT_SIZE*8+5) / 6)
+
+#define HASHOFFSET (CRYPTPLEN + SALTLEN)
+
+static const signed char radix64_decode_table[0x100] = {
+  /* White space is HT, VT, FF, CR, LF and SPC */
+  -1, -1, -1, -1, -1, -1, -1, -1, -1, -2, -2, -2, -2, -2, -1, -1,
+  -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+  -2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  1,
+  54, 55, 56, 57, 58, 59, 60, 61, 62, 63, -1, -1, -1, -3, -1, -1,
+  -1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,
+  17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, -1, -1, -1, -1, -1,
+  -1, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42,
+  43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, -1, -1, -1, -1, -1,
+  -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+  -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+  -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+  -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+  -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+  -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+  -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+  -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+};
+
+static const char radix64_encode_table[64] =
+  "./ABCDEFGHIJKLMNOPQRSTUVWXYZ"
+    "abcdefghijklmnopqrstuvwxyz"
+    "0123456789";
+
+int
+blowfish_bcrypt_verify(const char *key,
+                       const char *hashed)
+{
+  char newhash[BLOWFISH_BCRYPT_HASH_SIZE];
+
+  return blowfish_bcrypt_hash(sizeof newhash,
+                              newhash, key, hashed, -1, (void*)0)
+   &amp;&amp; !strcmp(newhash, hashed);
+}
+
+static char *encode_radix64(char *dst, size_t len, const uint8_t *src)
+{
+  struct base64_encode_ctx ctx;
+  base64_encode_init(&amp;ctx);
+  ctx.alphabet = radix64_encode_table;
+  dst += base64_encode_update(&amp;ctx, dst, len, src);
+  dst += base64_encode_final(&amp;ctx, dst);
+  *--dst = '\0';	    /* Strip the trailing = */
+  return dst;
+}
+
+/*
+ * Large parts of the code below are based on public domain sources.
+ * The comments and copyright notices have been preserved.
+ * Any code added or modified by me is licensed under the
+ * licenses listed above.  --  Stephen R. van den Berg
+ */
+
+/*
+ * This code comes from John the Ripper password cracker, with reentrant
+ * and crypt(3) interfaces added, but optimizations specific to password
+ * cracking removed.
+ *
+ * Written by Solar Designer &lt;solar at openwall.com&gt; in 1998-2015.
+ * No copyright is claimed, and the software is hereby placed in the public
+ * domain. In case this attempt to disclaim copyright and place the software
+ * in the public domain is deemed null and void, then the software is
+ * Copyright (c) 1998-2015 Solar Designer and it is hereby released to the
+ * general public under the following terms:
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted.
+ *
+ * There's ABSOLUTELY NO WARRANTY, express or implied.
+ *
+ * It is my intent that you should be able to use this on your system,
+ * as part of a software package, or anywhere else to improve security,
+ * ensure compatibility, or for any other purpose. I would appreciate
+ * it if you give credit where it is due and keep your modifications in
+ * the public domain as well, but I don't require that in order to let
+ * you place this code and any modifications you make under a license
+ * of your choice.
+ *
+ * This implementation is fully compatible with OpenBSD's bcrypt.c for prefix
+ * "$2b$", originally by Niels Provos &lt;provos at citi.umich.edu&gt;, and it uses
+ * some of his ideas. The password hashing algorithm was designed by David
+ * Mazieres &lt;dm at lcs.mit.edu&gt;. For information on the level of
+ * compatibility for bcrypt hash prefixes other than "$2b$", please refer to
+ * the comments in set_key() below and to the included crypt(3) man page.
+ */
+
+typedef uint32_t bf_key[_BLOWFISH_ROUNDS + 2];
+
+/*
+ * Magic IV for 64 Blowfish encryptions that we do at the end.
+ * The string is "OrpheanBeholderScryDoubt" on big-endian.
+ */
+static uint32_t magic_w[6] = {
+  0x4F727068, 0x65616E42, 0x65686F6C,
+  0x64657253, 0x63727944, 0x6F756274
+};
+
+static void swap32(uint32_t *x, int count)
+{
+#if !WORDS_BIGENDIAN
+  do {
+    uint32_t tmp = *x;
+    tmp = (tmp &lt;&lt; 16) | (tmp &gt;&gt; 16);
+    *x++ = ((tmp &amp; 0x00FF00FF) &lt;&lt; 8) | ((tmp &gt;&gt; 8) &amp; 0x00FF00FF);
+  } while (--count);
+#endif
+}
+
+static void set_xkey(const char *key, bf_key expanded, bf_key initial,
+    unsigned bug, uint32_t safety)
+{
+  const char *ptr = key;
+  unsigned i, j;
+  uint32_t sign, diff, tmp[2];
+
+/*
+ * There was a sign extension bug in older revisions of this function. While
+ * we would have liked to simply fix the bug and move on, we have to provide
+ * a backwards compatibility feature (essentially the bug) for some systems and
+ * a safety measure for some others. The latter is needed because for certain
+ * multiple inputs to the buggy algorithm there exist easily found inputs to
+ * the correct algorithm that produce the same hash. Thus, we optionally
+ * deviate from the correct algorithm just enough to avoid such collisions.
+ * While the bug itself affected the majority of passwords containing
+ * characters with the 8th bit set (although only a percentage of those in a
+ * collision-producing way), the anti-collision safety measure affects
+ * only a subset of passwords containing the '\xff' character (not even all of
+ * those passwords, just some of them). This character is not found in valid
+ * UTF-8 sequences and is rarely used in popular 8-bit character encodings.
+ * Thus, the safety measure is unlikely to cause much annoyance, and is a
+ * reasonable tradeoff to use when authenticating against existing hashes that
+ * are not reliably known to have been computed with the correct algorithm.
+ *
+ * We use an approach that tries to minimize side-channel leaks of password
+ * information - that is, we mostly use fixed-cost bitwise operations instead
+ * of branches or table lookups. (One conditional branch based on password
+ * length remains. It is not part of the bug aftermath, though, and is
+ * difficult and possibly unreasonable to avoid given the use of C strings by
+ * the caller, which results in similar timing leaks anyway.)
+ *
+ * For actual implementation, we set an array index in the variable "bug"
+ * (0 means no bug, 1 means sign extension bug emulation) and a flag in the
+ * variable "safety" (bit 16 is set when the safety measure is requested).
+ * Valid combinations of settings are:
+ *
+ * Prefix "$2a$": bug = 0, safety = 0x10000
+ * Prefix "$2b$": bug = 0, safety = 0
+ * Prefix "$2x$": bug = 1, safety = 0
+ * Prefix "$2y$": bug = 0, safety = 0
+ */
+
+  sign = diff = 0;
+
+  for (i = 0; i &lt; _BLOWFISH_ROUNDS + 2; i++) {
+    tmp[0] = tmp[1] = 0;
+    for (j = 0; j &lt; 4; j++) {
+      tmp[0] &lt;&lt;= 8;
+      tmp[0] |= (unsigned char)*ptr; /* correct */
+      tmp[1] &lt;&lt;= 8;
+      tmp[1] |= (signed char)*ptr; /* bug */
+/*
+ * Sign extension in the first char has no effect - nothing to overwrite yet,
+ * and those extra 24 bits will be fully shifted out of the 32-bit word. For
+ * chars 2, 3, 4 in each four-char block, we set bit 7 of "sign" if sign
+ * extension in tmp[1] occurs. Once this flag is set, it remains set.
+ */
+      if (j)
+        sign |= tmp[1] &amp; 0x80;
+      if (!*ptr)
+        ptr = key;
+      else
+        ptr++;
+    }
+    diff |= tmp[0] ^ tmp[1]; /* Non-zero on any differences */
+
+    expanded[i] = tmp[bug];
+    initial[i] = _nettle_blowfish_initial_ctx.p[i] ^ tmp[bug];
+  }
+
+/*
+ * At this point, "diff" is zero if the correct and buggy algorithms produced
+ * exactly the same result. If so and if "sign" is non-zero, which indicates
+ * that there was a non-benign sign extension, this means that we have a
+ * collision between the correctly computed hash for this password and a set of
+ * passwords that could be supplied to the buggy algorithm. Our safety measure
+ * is meant to protect from such many-buggy to one-correct collisions, by
+ * deviating from the correct algorithm in such cases. Let's check for this.
+ */
+  diff |= diff &gt;&gt; 16; /* still zero if exact match */
+  diff &amp;= 0xffff; /* ditto */
+  diff += 0xffff; /* bit 16 set if "diff" was non-zero (on non-match) */
+  sign &lt;&lt;= 9; /* move the non-benign sign extension flag to bit 16 */
+  sign &amp;= ~diff &amp; safety; /* action needed? */
+
+/*
+ * If we have determined that we need to deviate from the correct algorithm,
+ * flip bit 16 in initial expanded key. (The choice of 16 is arbitrary, but
+ * let's stick to it now. It came out of the approach we used above, and it's
+ * not any worse than any other choice we could make.)
+ *
+ * It is crucial that we don't do the same to the expanded key used in the main
+ * Eksblowfish loop. By doing it to only one of these two, we deviate from a
+ * state that could be directly specified by a password to the buggy algorithm
+ * (and to the fully correct one as well, but that's a side-effect).
+ */
+  initial[0] ^= sign;
+}
+
+static int ibcrypt(size_t length, char *dst,
+                   const char *key, const char *scheme,
+		   int minlog2rounds,
+		   int log2rounds, const uint8_t *salt)
+{
+  struct {
+    struct blowfish_ctx ctx;
+    bf_key expanded_key;
+    union {
+      uint32_t salt[4];
+      uint32_t output[6];
+    } binary;
+  } data;
+  uint8_t psalt[BLOWFISH_BCRYPT_BINSALT_SIZE];
+  uint32_t L, R;
+  uint32_t *ptr;
+  uint32_t count;
+  int i;
+  size_t lenscheme = strlen(scheme);
+  unsigned cscheme;
+  unsigned bug = 0;
+  uint32_t safety = 0;
+  if (length &lt; BLOWFISH_BCRYPT_HASH_SIZE ||
+      lenscheme &lt; 2)
+    return 0;
+
+  if (lenscheme &gt;= 3 &amp;&amp; *scheme++ != '$')
+    return 0;
+  if (*scheme++ != '2')
+    return 0;
+
+  switch (cscheme = *scheme++) {
+    default:
+      return 0;
+    case 'a': safety = 0x10000;
+      break;
+    case 'x': bug = 1;
+      break;
+    case 'b': case 'y':
+      break;
+  }
+
+  if (lenscheme &gt;= 4) {
+    if (*scheme++ != '$')
+      return 0;
+    if (lenscheme &gt;= 6) {
+      if (log2rounds &lt; 0)
+        log2rounds = atoi(scheme);
+      scheme += 2;
+      if (lenscheme &gt;= CRYPTPLEN &amp;&amp; *scheme++ != '$')
+	return 0;
+      if (lenscheme &gt;= HASHOFFSET &amp;&amp; !salt) {
+        struct base64_decode_ctx ctx;
+        size_t saltlen = BLOWFISH_BCRYPT_BINSALT_SIZE;
+
+        base64_decode_init(&amp;ctx);
+        ctx.table = radix64_decode_table;
+
+        if (!base64_decode_update(&amp;ctx, &amp;saltlen, (uint8_t *) data.binary.salt,
+                                  SALTLEN, scheme)
+         || saltlen != BLOWFISH_BCRYPT_BINSALT_SIZE)
+          return 0;
+      }
+    }
+  }
+
+  if (salt)
+    memcpy(data.binary.salt, salt, BLOWFISH_BCRYPT_BINSALT_SIZE);
+  else if (lenscheme &lt; HASHOFFSET)
+    return 0;
+  memcpy(psalt, data.binary.salt, BLOWFISH_BCRYPT_BINSALT_SIZE);
+  swap32(data.binary.salt, 4);
+
+  if (log2rounds &lt; minlog2rounds || log2rounds &gt; 31)
+    return 0;
+  count = (uint32_t)1 &lt;&lt; log2rounds;
+
+  set_xkey(key, data.expanded_key, data.ctx.p, bug, safety);
+  memcpy(data.ctx.s, _nettle_blowfish_initial_ctx.s, sizeof(data.ctx.s));
+
+  L = R = 0;
+  for (i = 0; i &lt; _BLOWFISH_ROUNDS + 2; i += 2) {
+    L ^= data.binary.salt[i &amp; 2];
+    R ^= data.binary.salt[(i &amp; 2) + 1];
+    _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+    data.ctx.p[i] = L;
+    data.ctx.p[i + 1] = R;
+  }
+
+  ptr = data.ctx.s[0];
+  do {
+    ptr += 4;
+    L ^= data.binary.salt[(_BLOWFISH_ROUNDS + 2) &amp; 3];
+    R ^= data.binary.salt[(_BLOWFISH_ROUNDS + 3) &amp; 3];
+    _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+    *(ptr - 4) = L;
+    *(ptr - 3) = R;
+
+    L ^= data.binary.salt[(_BLOWFISH_ROUNDS + 4) &amp; 3];
+    R ^= data.binary.salt[(_BLOWFISH_ROUNDS + 5) &amp; 3];
+    _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+    *(ptr - 2) = L;
+    *(ptr - 1) = R;
+  } while (ptr &lt; &amp;data.ctx.s[3][0xFF]);
+
+  do {
+    int done;
+
+    for (i = 0; i &lt; _BLOWFISH_ROUNDS + 2; i += 2) {
+      data.ctx.p[i] ^= data.expanded_key[i];
+      data.ctx.p[i + 1] ^= data.expanded_key[i + 1];
+    }
+
+    done = 0;
+    do {
+      uint32_t tmp1, tmp2, tmp3, tmp4;
+
+      L = R = 0;
+      ptr = data.ctx.p;
+      do {
+        ptr += 2;
+        _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+        *(ptr - 2) = L;
+        *(ptr - 1) = R;
+      } while (ptr &lt; &amp;data.ctx.p[_BLOWFISH_ROUNDS + 2]);
+
+      ptr = data.ctx.s[0];
+      do {
+        ptr += 2;
+        _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+        *(ptr - 2) = L;
+        *(ptr - 1) = R;
+      } while (ptr &lt; &amp;data.ctx.s[3][0xFF]);
+
+      if (done)
+        break;
+      done = 1;
+
+      tmp1 = data.binary.salt[0];
+      tmp2 = data.binary.salt[1];
+      tmp3 = data.binary.salt[2];
+      tmp4 = data.binary.salt[3];
+      for (i = 0; i &lt; _BLOWFISH_ROUNDS; i += 4) {
+        data.ctx.p[i] ^= tmp1;
+        data.ctx.p[i + 1] ^= tmp2;
+        data.ctx.p[i + 2] ^= tmp3;
+        data.ctx.p[i + 3] ^= tmp4;
+      }
+      data.ctx.p[16] ^= tmp1;
+      data.ctx.p[17] ^= tmp2;
+    } while (1);
+  } while (--count);
+
+  for (i = 0; i &lt; 6; i += 2) {
+    L = magic_w[i];
+    R = magic_w[i + 1];
+
+    count = 64;
+    do
+      _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+    while (--count);
+
+    data.binary.output[i] = L;
+    data.binary.output[i + 1] = R;
+  }
+
+  *dst++ = '$';
+  *dst++ = '2';
+  *dst++ = cscheme;
+  *dst++ = '$';
+  *dst++ = '0' + log2rounds / 10;
+  *dst++ = '0' + log2rounds % 10;
+  *dst++ = '$';
+  dst = encode_radix64(dst, BLOWFISH_BCRYPT_BINSALT_SIZE, psalt) - 1;
+
+  swap32(data.binary.output, 6);
+/* This has to be bug-compatible with the original implementation, so
+   only encode 23 of the 24 bytes. */
+  encode_radix64(dst, 23, (uint8_t *) data.binary.output);
+  return cscheme;
+}
+
+/*
+ * Please preserve the runtime self-test. It serves two purposes at once:
+ *
+ * 1. We really can't afford the risk of producing incompatible hashes e.g.
+ * when there's something like gcc bug 26587 again, whereas an application or
+ * library integrating this code might not also integrate our external tests or
+ * it might not run them after every build. Even if it does, the miscompile
+ * might only occur on the production build, but not on a testing build (such
+ * as because of different optimization settings). It is painful to recover
+ * from incorrectly-computed hashes - merely fixing whatever broke is not
+ * enough. Thus, a proactive measure like this self-test is needed.
+ *
+ * 2. We don't want to leave sensitive data from our actual password hash
+ * computation on the stack or in registers. Previous revisions of the code
+ * would do explicit cleanups, but simply running the self-test after hash
+ * computation is more reliable.
+ *
+ * The performance cost of this quick self-test is around 0.6% at the "$2a$08"
+ * setting.
+ */
+int blowfish_bcrypt_hash(size_t length, char *dst,
+                         const char *key, const char *scheme,
+			 int log2rounds, const uint8_t *salt)
+{
+  const char *test_pw = "8b \xd0\xc1\xd2\xcf\xcc\xd8";
+  const char *test_scheme = "$2a$00$abcdefghijklmnopqrstuu";
+  static const char * const test_hashes[2] =
+    {"i1D709vfamulimlGcq0qq3UvuUasvEa\0\x55",  /* 'a', 'b', 'y' */
+     "VUrPmXD6q/nVSSp7pNDhCR9071IfIRe\0\x55"}; /* 'x' */
+  const char *test_hash = test_hashes[0];
+  int cscheme;
+  int ok;
+  struct {
+    char s[HASHOFFSET + 1];
+    char o[HASHOFFSET + 31 + 1 + 1 + 1];
+  } buf;
+
+  if (length)
+    *dst = '\0';
+/* Hash the supplied password */
+  cscheme = ibcrypt(length, dst, key, scheme, 4, log2rounds, salt);
+
+/*
+ * Do a quick self-test. It is important that we make both calls to ibcrypt()
+ * from the same scope such that they likely use the same stack locations,
+ * which makes the second call overwrite the first call's sensitive data on the
+ * stack and makes it more likely that any alignment related issues would be
+ * detected by the self-test.
+ */
+  memcpy(buf.s, test_scheme, sizeof(buf.s));
+
+  if (cscheme)
+    test_hash = test_hashes[(buf.s[2] = cscheme) == 'x'];
+
+  memset(buf.o, 0x55, sizeof(buf.o));
+  buf.o[sizeof(buf.o) - 1] = 0;
+  ok = ibcrypt(sizeof(buf.o) - (1 + 1), buf.o, test_pw,
+               buf.s, 0, -1, (void*)0);
+
+  ok = (ok &amp;&amp;
+      !memcmp(buf.o, buf.s, HASHOFFSET) &amp;&amp;
+      !memcmp(buf.o + HASHOFFSET, test_hash, 31 + 1 + 1 + 1));
+
+  {
+    const char *k = "\xff\xa3" "34" "\xff\xff\xff\xa3" "345";
+    bf_key ae, ai, ye, yi;
+    set_xkey(k, ae, ai, 0, 0x10000); /* $2a$ */
+    set_xkey(k, ye, yi, 0, 0); /* $2y$ */
+    ai[0] ^= 0x10000; /* undo the safety (for comparison) */
+    ok = ok &amp;&amp; ai[0] == 0xdb9c59bc &amp;&amp; ye[17] == 0x33343500 &amp;&amp;
+        !memcmp(ae, ye, sizeof(ae)) &amp;&amp;
+        !memcmp(ai, yi, sizeof(ai));
+  }
+
+  return ok &amp;&amp; !!cscheme;
+}
diff --git a/blowfish.h b/blowfish.h
index bcdc7cb6..af48e20f 100644
--- a/blowfish.h
+++ b/blowfish.h
@@ -46,6 +46,8 @@ extern "C" {
 #define blowfish128_set_key nettle_blowfish128_set_key
 #define blowfish_encrypt nettle_blowfish_encrypt
 #define blowfish_decrypt nettle_blowfish_decrypt
+#define blowfish_bcrypt_hash nettle_blowfish_bcrypt_hash
+#define blowfish_bcrypt_verify nettle_blowfish_bcrypt_verify
 
 #define BLOWFISH_BLOCK_SIZE 8
 
@@ -60,6 +62,9 @@ extern "C" {
 
 #define _BLOWFISH_ROUNDS 16
 
+#define BLOWFISH_BCRYPT_HASH_SIZE (60 + 1) /* Including null-terminator */
+#define BLOWFISH_BCRYPT_BINSALT_SIZE 16    /* Binary string size */
+
 struct blowfish_ctx
 {
   uint32_t s[4][256];
@@ -81,6 +86,16 @@ void
 blowfish_decrypt(const struct blowfish_ctx *ctx,
                  size_t length, uint8_t *dst,
                  const uint8_t *src);
+int
+blowfish_bcrypt_hash(size_t length,
+                     char *dst,
+                     const char *key,
+                     const char *scheme,
+		     int log2rounds,
+		     const uint8_t *salt);
+int
+blowfish_bcrypt_verify(const char *key,
+                       const char *hashed);
 
 #ifdef __cplusplus
 }
diff --git a/nettle.texinfo b/nettle.texinfo
index 995d5de8..75e18b58 100644
--- a/nettle.texinfo
+++ b/nettle.texinfo
@@ -1513,6 +1513,73 @@ in any other way.
 Analogous to @code{blowfish_encrypt}
 @end deftypefun
 
+@deftypefun int blowfish_bcrypt_hash (size_t @var{length}, char *@var{dst}, const \
char *@var{key}, const char *@var{scheme}, int @var{log2rounds}, const uint8_t \
*@var{salt}) +Compute the bcrypt password hash.
+The function will return @code{0} if the hash cannot be computed
+due to invalid input.
+The function will return @code{1} and store the computed hash
+in the array pointed to by @var{dst}.  The hash is computed based
+on the chosen @var{scheme}, number of rounds @var{log2rounds} and
+specified @var{salt}.
+
+@var{length} must be at least @code{BLOWFISH_BCRYPT_HASH_SIZE}.
+
+@var{dst} must point to a character array of the specified @var{length}.
+
+@var{key} contains the zero terminated plaintext password string.
+
+@var{scheme} contains either just the chosen scheme (valid schemes
+are: @code{2a}, @code{2b}, @code{2x} or @code{2y}), or
+(the prefix of) an existing hashed password (typically @code{$2b$10$...}).
+
+@var{log2rounds} contains the log2 of the number of encryption rounds
+that must be used to compute the hash.  If it is @code{-1} the value
+will be extracted from @var{scheme}.
+
+@var{salt} should point to an array of @code{BLOWFISH_BCRYPT_BINSALT_SIZE}
+random bytes to be used to perturb the hash computation.  If it is @code{NULL}
+the salt will be extracted from @var{scheme}.
+
+Sample code to generate a bcrypt hash:
+@example
+char cleartxtpassword[] = "ExamplePassword";
+uint8_t salt[BLOWFISH_BCRYPT_BINSALT_SIZE];
+@dots{}
+/* Make sure that salt is filled with random bytes */
+@dots{}
+char hashedresult[BLOWFISH_BCRYPT_HASH_SIZE];
+int result = blowfish_bcrypt(sizeof(hashedresult), hashedresult,
+                             cleartxtpassword, "2b", 10, salt);
+if (result)
+  printf("%s\n", hashedresult);
+@end example
+@end deftypefun
+
+@deftypefun int blowfish_bcrypt_verify (const char *@var{key}, const char \
*@var{hashed}) +Verifies the bcrypt password hash against the supplied plaintext \
password. +The function will return @code{0} if the password does not match.
+The function will return @code{1} if the password matches.
+
+@var{key} contains the zero terminated plaintext password string.
+
+@var{hashed} contains the zero terminated hashed string to compare with.
+
+Sample code to verify a bcrypt hash:
+@example
+char cleartxtpassword[] = "ExamplePassword";
+char existinghashed[] =
+           "$2y$"  /* Hash algorithm version */
+           "10"   /* 2^10 hash rounds (strength) */
+           "$"   /* separator */
+           "1b2lPgo4XumibnJGN3r3sO" /* base64 encoded 16-byte salt */
+           "u7wE7xNfYDKlAxZffJDCJdVfFTAyevu"; /* Hashedpart */
+if (blowfish_bcrypt_verify(cleartxtpassword, existinghashed))
+  printf("Password is correct.");
+else
+  printf("Password is incorrect.");
+@end example
+@end deftypefun
+
 @subsection Camellia
 @cindex Camellia
 
-- 
2.20.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200612092640</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-06-12 09:26:40-0400</timestampReceived><subject>Re: [PATCH 3/3] v4.0 Blowfish: Supply lengths instead of C-strings.</subject><body>

There will be a v4.1.
Forgot to change the types to uint8_t instead of char.
-- 
Stephen.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200612103857</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-06-12 10:38:57-0400</timestampReceived><subject>[PATCH 3/3] v4.1 Blowfish: Supply lengths instead of C-strings.</subject><body>

---
 blowfish-bcrypt.c | 85 ++++++++++++++++++++++++++---------------------
 blowfish.h        | 14 ++++----
 nettle.texinfo    | 27 ++++++++-------
 3 files changed, 71 insertions(+), 55 deletions(-)

diff --git a/blowfish-bcrypt.c b/blowfish-bcrypt.c
index c06f9e90..bfee8e44 100644
--- a/blowfish-bcrypt.c
+++ b/blowfish-bcrypt.c
@@ -76,14 +76,15 @@ static const char radix64_encode_table[64] =
     "0123456789";
 
 int
-blowfish_bcrypt_verify(const char *key,
-                       const char *hashed)
+blowfish_bcrypt_verify(size_t lenkey, const uint8_t *key,
+                       size_t lenhashed, const uint8_t *hashed)
 {
-  char newhash[BLOWFISH_BCRYPT_HASH_SIZE];
+  uint8_t newhash[BLOWFISH_BCRYPT_HASH_SIZE];
 
-  return blowfish_bcrypt_hash(sizeof newhash,
-                              newhash, key, hashed, -1, (void*)0)
-   &amp;&amp; !strcmp(newhash, hashed);
+  return blowfish_bcrypt_hash(newhash,
+                              lenkey, key, lenhashed, hashed,
+                              -1, (void*)0)
+   &amp;&amp; !strcmp((const char*)newhash, (const char*)hashed);
 }
 
 static char *encode_radix64(char *dst, size_t len, const uint8_t *src)
@@ -159,10 +160,12 @@ static void swap32(uint32_t *x, int count)
 #endif
 }
 
-static void set_xkey(const char *key, bf_key expanded, bf_key initial,
-    unsigned bug, uint32_t safety)
+static void set_xkey(size_t lenkey, const uint8_t *key,
+                     bf_key expanded, bf_key initial,
+		     unsigned bug, uint32_t safety)
 {
-  const char *ptr = key;
+  const uint8_t *ptr = key;
+  size_t n = lenkey;
   unsigned i, j;
   uint32_t sign, diff, tmp[2];
 
@@ -219,10 +222,10 @@ static void set_xkey(const char *key, bf_key expanded, bf_key \
                initial,
  */
       if (j)
         sign |= tmp[1] &amp; 0x80;
-      if (!*ptr)
-        ptr = key;
-      else
+      if (n--)
         ptr++;
+      else
+        ptr = key, n = lenkey;
     }
     diff |= tmp[0] ^ tmp[1]; /* Non-zero on any differences */
 
@@ -259,8 +262,9 @@ static void set_xkey(const char *key, bf_key expanded, bf_key \
initial,  initial[0] ^= sign;
 }
 
-static int ibcrypt(size_t length, char *dst,
-                   const char *key, const char *scheme,
+static int ibcrypt(uint8_t *dst,
+                   size_t lenkey, const uint8_t *key,
+		   size_t lenscheme, const uint8_t *scheme,
 		   int minlog2rounds,
 		   int log2rounds, const uint8_t *salt)
 {
@@ -277,12 +281,10 @@ static int ibcrypt(size_t length, char *dst,
   uint32_t *ptr;
   uint32_t count;
   int i;
-  size_t lenscheme = strlen(scheme);
   unsigned cscheme;
   unsigned bug = 0;
   uint32_t safety = 0;
-  if (length &lt; BLOWFISH_BCRYPT_HASH_SIZE ||
-      lenscheme &lt; 2)
+  if (lenscheme &lt; 2)
     return 0;
 
   if (lenscheme &gt;= 3 &amp;&amp; *scheme++ != '$')
@@ -305,8 +307,16 @@ static int ibcrypt(size_t length, char *dst,
     if (*scheme++ != '$')
       return 0;
     if (lenscheme &gt;= 6) {
-      if (log2rounds &lt; 0)
-        log2rounds = atoi(scheme);
+      if (log2rounds &lt; 0) {
+        unsigned c = *scheme - '0';
+	if (c &gt; 9)
+	  return 0;
+	log2rounds = c * 10;
+        c = *scheme - '0';
+	if (c &gt; 9)
+	  return 0;
+	log2rounds += c;
+      }
       scheme += 2;
       if (lenscheme &gt;= CRYPTPLEN &amp;&amp; *scheme++ != '$')
 	return 0;
@@ -318,7 +328,7 @@ static int ibcrypt(size_t length, char *dst,
         ctx.table = radix64_decode_table;
 
         if (!base64_decode_update(&amp;ctx, &amp;saltlen, (uint8_t *) data.binary.salt,
-                                  SALTLEN, scheme)
+                                  SALTLEN, (const char*) scheme)
          || saltlen != BLOWFISH_BCRYPT_BINSALT_SIZE)
           return 0;
       }
@@ -336,7 +346,7 @@ static int ibcrypt(size_t length, char *dst,
     return 0;
   count = (uint32_t)1 &lt;&lt; log2rounds;
 
-  set_xkey(key, data.expanded_key, data.ctx.p, bug, safety);
+  set_xkey(lenkey, key, data.expanded_key, data.ctx.p, bug, safety);
   memcpy(data.ctx.s, _nettle_blowfish_initial_ctx.s, sizeof(data.ctx.s));
 
   L = R = 0;
@@ -432,12 +442,13 @@ static int ibcrypt(size_t length, char *dst,
   *dst++ = '0' + log2rounds / 10;
   *dst++ = '0' + log2rounds % 10;
   *dst++ = '$';
-  dst = encode_radix64(dst, BLOWFISH_BCRYPT_BINSALT_SIZE, psalt) - 1;
+  dst = (uint8_t*)
+        encode_radix64((char*) dst, BLOWFISH_BCRYPT_BINSALT_SIZE, psalt) - 1;
 
   swap32(data.binary.output, 6);
 /* This has to be bug-compatible with the original implementation, so
    only encode 23 of the 24 bytes. */
-  encode_radix64(dst, 23, (uint8_t *) data.binary.output);
+  encode_radix64((char*) dst, 23, (uint8_t *) data.binary.output);
   return cscheme;
 }
 
@@ -461,12 +472,13 @@ static int ibcrypt(size_t length, char *dst,
  * The performance cost of this quick self-test is around 0.6% at the "$2a$08"
  * setting.
  */
-int blowfish_bcrypt_hash(size_t length, char *dst,
-                         const char *key, const char *scheme,
+int blowfish_bcrypt_hash(uint8_t *dst,
+                         size_t lenkey, const uint8_t *key,
+			 size_t lenscheme, const uint8_t *scheme,
 			 int log2rounds, const uint8_t *salt)
 {
-  const char *test_pw = "8b \xd0\xc1\xd2\xcf\xcc\xd8";
-  const char *test_scheme = "$2a$00$abcdefghijklmnopqrstuu";
+  const uint8_t test_pw[] = "8b \xd0\xc1\xd2\xcf\xcc\xd8";
+  const uint8_t test_scheme[] = "$2a$00$abcdefghijklmnopqrstuu";
   static const char * const test_hashes[2] =
     {"i1D709vfamulimlGcq0qq3UvuUasvEa\0\x55",  /* 'a', 'b', 'y' */
      "VUrPmXD6q/nVSSp7pNDhCR9071IfIRe\0\x55"}; /* 'x' */
@@ -474,14 +486,13 @@ int blowfish_bcrypt_hash(size_t length, char *dst,
   int cscheme;
   int ok;
   struct {
-    char s[HASHOFFSET + 1];
-    char o[HASHOFFSET + 31 + 1 + 1 + 1];
+    uint8_t s[HASHOFFSET + 1];
+    uint8_t o[HASHOFFSET + 31 + 1 + 1 + 1];
   } buf;
 
-  if (length)
-    *dst = '\0';
+  *dst = '\0';
 /* Hash the supplied password */
-  cscheme = ibcrypt(length, dst, key, scheme, 4, log2rounds, salt);
+  cscheme = ibcrypt(dst, lenkey, key, lenscheme, scheme, 4, log2rounds, salt);
 
 /*
  * Do a quick self-test. It is important that we make both calls to ibcrypt()
@@ -497,18 +508,18 @@ int blowfish_bcrypt_hash(size_t length, char *dst,
 
   memset(buf.o, 0x55, sizeof(buf.o));
   buf.o[sizeof(buf.o) - 1] = 0;
-  ok = ibcrypt(sizeof(buf.o) - (1 + 1), buf.o, test_pw,
-               buf.s, 0, -1, (void*)0);
+  ok = ibcrypt(buf.o, sizeof(test_pw), test_pw,
+               sizeof(buf.s), buf.s, 0, -1, (void*)0);
 
   ok = (ok &amp;&amp;
       !memcmp(buf.o, buf.s, HASHOFFSET) &amp;&amp;
       !memcmp(buf.o + HASHOFFSET, test_hash, 31 + 1 + 1 + 1));
 
   {
-    const char *k = "\xff\xa3" "34" "\xff\xff\xff\xa3" "345";
+    const uint8_t k[] = "\xff\xa3" "34" "\xff\xff\xff\xa3" "345";
     bf_key ae, ai, ye, yi;
-    set_xkey(k, ae, ai, 0, 0x10000); /* $2a$ */
-    set_xkey(k, ye, yi, 0, 0); /* $2y$ */
+    set_xkey(sizeof(k), k, ae, ai, 0, 0x10000); /* $2a$ */
+    set_xkey(sizeof(k), k, ye, yi, 0, 0); /* $2y$ */
     ai[0] ^= 0x10000; /* undo the safety (for comparison) */
     ok = ok &amp;&amp; ai[0] == 0xdb9c59bc &amp;&amp; ye[17] == 0x33343500 &amp;&amp;
         !memcmp(ae, ye, sizeof(ae)) &amp;&amp;
diff --git a/blowfish.h b/blowfish.h
index af48e20f..01813cbc 100644
--- a/blowfish.h
+++ b/blowfish.h
@@ -86,16 +86,18 @@ void
 blowfish_decrypt(const struct blowfish_ctx *ctx,
                  size_t length, uint8_t *dst,
                  const uint8_t *src);
+
+/* dst parameter must point to a buffer of minimally
+ * BLOWFISH_BCRYPT_HASH_SIZE bytes */
 int
-blowfish_bcrypt_hash(size_t length,
-                     char *dst,
-                     const char *key,
-                     const char *scheme,
+blowfish_bcrypt_hash(uint8_t *dst,
+                     size_t lenkey, const uint8_t *key,
+                     size_t lenscheme, const uint8_t *scheme,
 		     int log2rounds,
 		     const uint8_t *salt);
 int
-blowfish_bcrypt_verify(const char *key,
-                       const char *hashed);
+blowfish_bcrypt_verify(size_t lenkey, const uint8_t *key,
+                       size_t lenhashed, const uint8_t *hashed);
 
 #ifdef __cplusplus
 }
diff --git a/nettle.texinfo b/nettle.texinfo
index 75e18b58..2269e11d 100644
--- a/nettle.texinfo
+++ b/nettle.texinfo
@@ -1513,7 +1513,7 @@ in any other way.
 Analogous to @code{blowfish_encrypt}
 @end deftypefun
 
-@deftypefun int blowfish_bcrypt_hash (size_t @var{length}, char *@var{dst}, const \
char *@var{key}, const char *@var{scheme}, int @var{log2rounds}, const uint8_t \
*@var{salt}) +@deftypefun int blowfish_bcrypt_hash (char *@var{dst}, size_t \
@var{lenkey}, const char *@var{key}, size_t @var{lenscheme}, const char \
*@var{scheme}, int @var{log2rounds}, const uint8_t *@var{salt})  Compute the bcrypt \
password hash.  The function will return @code{0} if the hash cannot be computed
 due to invalid input.
@@ -1522,13 +1522,13 @@ in the array pointed to by @var{dst}.  The hash is computed \
based  on the chosen @var{scheme}, number of rounds @var{log2rounds} and
 specified @var{salt}.
 
-@var{length} must be at least @code{BLOWFISH_BCRYPT_HASH_SIZE}.
+@var{dst} must point to a character array of at least
+ @code{BLOWFISH_BCRYPT_HASH_SIZE} bytes.
 
-@var{dst} must point to a character array of the specified @var{length}.
+@var{key} contains the plaintext password string of size @var{lenkey}.
 
-@var{key} contains the zero terminated plaintext password string.
-
-@var{scheme} contains either just the chosen scheme (valid schemes
+@var{scheme} is of size @var{lenscheme} and contains either just the
+chosen scheme (valid schemes
 are: @code{2a}, @code{2b}, @code{2x} or @code{2y}), or
 (the prefix of) an existing hashed password (typically @code{$2b$10$...}).
 
@@ -1543,26 +1543,28 @@ the salt will be extracted from @var{scheme}.
 Sample code to generate a bcrypt hash:
 @example
 char cleartxtpassword[] = "ExamplePassword";
+char scheme[] = "2b";
 uint8_t salt[BLOWFISH_BCRYPT_BINSALT_SIZE];
 @dots{}
 /* Make sure that salt is filled with random bytes */
 @dots{}
 char hashedresult[BLOWFISH_BCRYPT_HASH_SIZE];
-int result = blowfish_bcrypt(sizeof(hashedresult), hashedresult,
-                             cleartxtpassword, "2b", 10, salt);
+int result = blowfish_bcrypt(hashedresult,
+                             sizeof(cleartxtpassword), cleartxtpassword,
+                             sizeof(scheme), scheme, 10, salt);
 if (result)
   printf("%s\n", hashedresult);
 @end example
 @end deftypefun
 
-@deftypefun int blowfish_bcrypt_verify (const char *@var{key}, const char \
*@var{hashed}) +@deftypefun int blowfish_bcrypt_verify (size_t @var{lenkey}, const \
char *@var{key}, size_t @var{lenhashed}, const char *@var{hashed})  Verifies the \
bcrypt password hash against the supplied plaintext password.  The function will \
return @code{0} if the password does not match.  The function will return @code{1} if \
the password matches.  
-@var{key} contains the zero terminated plaintext password string.
+@var{key} contains the plaintext password string of size @var{lenkey}.
 
-@var{hashed} contains the zero terminated hashed string to compare with.
+@var{hashed} contains the hashed string of size @var{lenhashed} to compare with.
 
 Sample code to verify a bcrypt hash:
 @example
@@ -1573,7 +1575,8 @@ char existinghashed[] =
            "$"   /* separator */
            "1b2lPgo4XumibnJGN3r3sO" /* base64 encoded 16-byte salt */
            "u7wE7xNfYDKlAxZffJDCJdVfFTAyevu"; /* Hashedpart */
-if (blowfish_bcrypt_verify(cleartxtpassword, existinghashed))
+if (blowfish_bcrypt_verify(sizeof(cleartxtpassword), cleartxtpassword,
+                           sizeof(existinghashed), existinghashed))
   printf("Password is correct.");
 else
   printf("Password is incorrect.");
-- 
2.20.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200614212356</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-06-14 21:23:56-0400</timestampReceived><subject>[PATCH v2 1/2] gost28147: move params to separate source file</subject><body>

Move big tables to separate source file.

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 Makefile.in        |   2 +-
 gost28147-params.c | 571 +++++++++++++++++++++++++++++++++++++++++++++
 gost28147.c        | 535 ------------------------------------------
 3 files changed, 572 insertions(+), 536 deletions(-)
 create mode 100644 gost28147-params.c

diff --git a/Makefile.in b/Makefile.in
index e5ccfc76b901..41e0389f2979 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -104,7 +104,7 @@ nettle_SOURCES = aes-decrypt-internal.c aes-decrypt.c \
 		 gcm-camellia256.c gcm-camellia256-meta.c \
 		 cmac.c cmac64.c cmac-aes128.c cmac-aes256.c cmac-des3.c \
 		 cmac-aes128-meta.c cmac-aes256-meta.c cmac-des3-meta.c \
-		 gost28147.c gosthash94.c gosthash94-meta.c \
+		 gost28147.c gost28147-params.c gosthash94.c gosthash94-meta.c \
 		 hmac.c hmac-gosthash94.c hmac-md5.c hmac-ripemd160.c \
 		 hmac-sha1.c hmac-sha224.c hmac-sha256.c hmac-sha384.c \
 		 hmac-sha512.c \
diff --git a/gost28147-params.c b/gost28147-params.c
new file mode 100644
index 000000000000..6addec31f170
--- /dev/null
+++ b/gost28147-params.c
@@ -0,0 +1,571 @@
+/* gost28147-params.c - GOST 28147-89 cipher implementation
+ *
+ * based on Russian standard GOST 28147-89
+ * For English description, check RFC 5830.
+ * S-Boxes are expanded from the tables defined in RFC4357:
+ *   https://tools.ietf.org/html/rfc4357
+ *
+ * Copyright: 2019 Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;
+ * Copyright: 2009-2012 Aleksey Kravchenko &lt;rhash.admin@gmail.com&gt;
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sublicense, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included
+ * in all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
+ * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+ * IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
+ * CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
+ * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
+ * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+#if HAVE_CONFIG_H
+#include "config.h"
+#endif
+
+#include "macros.h"
+#include "gost28147-internal.h"
+
+/* pre-initialized GOST lookup tables based on rotated S-Box */
+const struct gost28147_param _gost28147_param_test_3411 =
+{
+  {
+    { /* 0 */
+      0x00072000, 0x00075000, 0x00074800, 0x00071000,
+      0x00076800, 0x00074000, 0x00070000, 0x00077000,
+      0x00073000, 0x00075800, 0x00070800, 0x00076000,
+      0x00073800, 0x00077800, 0x00072800, 0x00071800,
+      0x0005a000, 0x0005d000, 0x0005c800, 0x00059000,
+      0x0005e800, 0x0005c000, 0x00058000, 0x0005f000,
+      0x0005b000, 0x0005d800, 0x00058800, 0x0005e000,
+      0x0005b800, 0x0005f800, 0x0005a800, 0x00059800,
+      0x00022000, 0x00025000, 0x00024800, 0x00021000,
+      0x00026800, 0x00024000, 0x00020000, 0x00027000,
+      0x00023000, 0x00025800, 0x00020800, 0x00026000,
+      0x00023800, 0x00027800, 0x00022800, 0x00021800,
+      0x00062000, 0x00065000, 0x00064800, 0x00061000,
+      0x00066800, 0x00064000, 0x00060000, 0x00067000,
+      0x00063000, 0x00065800, 0x00060800, 0x00066000,
+      0x00063800, 0x00067800, 0x00062800, 0x00061800,
+      0x00032000, 0x00035000, 0x00034800, 0x00031000,
+      0x00036800, 0x00034000, 0x00030000, 0x00037000,
+      0x00033000, 0x00035800, 0x00030800, 0x00036000,
+      0x00033800, 0x00037800, 0x00032800, 0x00031800,
+      0x0006a000, 0x0006d000, 0x0006c800, 0x00069000,
+      0x0006e800, 0x0006c000, 0x00068000, 0x0006f000,
+      0x0006b000, 0x0006d800, 0x00068800, 0x0006e000,
+      0x0006b800, 0x0006f800, 0x0006a800, 0x00069800,
+      0x0007a000, 0x0007d000, 0x0007c800, 0x00079000,
+      0x0007e800, 0x0007c000, 0x00078000, 0x0007f000,
+      0x0007b000, 0x0007d800, 0x00078800, 0x0007e000,
+      0x0007b800, 0x0007f800, 0x0007a800, 0x00079800,
+      0x00052000, 0x00055000, 0x00054800, 0x00051000,
+      0x00056800, 0x00054000, 0x00050000, 0x00057000,
+      0x00053000, 0x00055800, 0x00050800, 0x00056000,
+      0x00053800, 0x00057800, 0x00052800, 0x00051800,
+      0x00012000, 0x00015000, 0x00014800, 0x00011000,
+      0x00016800, 0x00014000, 0x00010000, 0x00017000,
+      0x00013000, 0x00015800, 0x00010800, 0x00016000,
+      0x00013800, 0x00017800, 0x00012800, 0x00011800,
+      0x0001a000, 0x0001d000, 0x0001c800, 0x00019000,
+      0x0001e800, 0x0001c000, 0x00018000, 0x0001f000,
+      0x0001b000, 0x0001d800, 0x00018800, 0x0001e000,
+      0x0001b800, 0x0001f800, 0x0001a800, 0x00019800,
+      0x00042000, 0x00045000, 0x00044800, 0x00041000,
+      0x00046800, 0x00044000, 0x00040000, 0x00047000,
+      0x00043000, 0x00045800, 0x00040800, 0x00046000,
+      0x00043800, 0x00047800, 0x00042800, 0x00041800,
+      0x0000a000, 0x0000d000, 0x0000c800, 0x00009000,
+      0x0000e800, 0x0000c000, 0x00008000, 0x0000f000,
+      0x0000b000, 0x0000d800, 0x00008800, 0x0000e000,
+      0x0000b800, 0x0000f800, 0x0000a800, 0x00009800,
+      0x00002000, 0x00005000, 0x00004800, 0x00001000,
+      0x00006800, 0x00004000, 0x00000000, 0x00007000,
+      0x00003000, 0x00005800, 0x00000800, 0x00006000,
+      0x00003800, 0x00007800, 0x00002800, 0x00001800,
+      0x0003a000, 0x0003d000, 0x0003c800, 0x00039000,
+      0x0003e800, 0x0003c000, 0x00038000, 0x0003f000,
+      0x0003b000, 0x0003d800, 0x00038800, 0x0003e000,
+      0x0003b800, 0x0003f800, 0x0003a800, 0x00039800,
+      0x0002a000, 0x0002d000, 0x0002c800, 0x00029000,
+      0x0002e800, 0x0002c000, 0x00028000, 0x0002f000,
+      0x0002b000, 0x0002d800, 0x00028800, 0x0002e000,
+      0x0002b800, 0x0002f800, 0x0002a800, 0x00029800,
+      0x0004a000, 0x0004d000, 0x0004c800, 0x00049000,
+      0x0004e800, 0x0004c000, 0x00048000, 0x0004f000,
+      0x0004b000, 0x0004d800, 0x00048800, 0x0004e000,
+      0x0004b800, 0x0004f800, 0x0004a800, 0x00049800,
+    }, { /* 1 */
+      0x03a80000, 0x03c00000, 0x03880000, 0x03e80000,
+      0x03d00000, 0x03980000, 0x03a00000, 0x03900000,
+      0x03f00000, 0x03f80000, 0x03e00000, 0x03b80000,
+      0x03b00000, 0x03800000, 0x03c80000, 0x03d80000,
+      0x06a80000, 0x06c00000, 0x06880000, 0x06e80000,
+      0x06d00000, 0x06980000, 0x06a00000, 0x06900000,
+      0x06f00000, 0x06f80000, 0x06e00000, 0x06b80000,
+      0x06b00000, 0x06800000, 0x06c80000, 0x06d80000,
+      0x05280000, 0x05400000, 0x05080000, 0x05680000,
+      0x05500000, 0x05180000, 0x05200000, 0x05100000,
+      0x05700000, 0x05780000, 0x05600000, 0x05380000,
+      0x05300000, 0x05000000, 0x05480000, 0x05580000,
+      0x00a80000, 0x00c00000, 0x00880000, 0x00e80000,
+      0x00d00000, 0x00980000, 0x00a00000, 0x00900000,
+      0x00f00000, 0x00f80000, 0x00e00000, 0x00b80000,
+      0x00b00000, 0x00800000, 0x00c80000, 0x00d80000,
+      0x00280000, 0x00400000, 0x00080000, 0x00680000,
+      0x00500000, 0x00180000, 0x00200000, 0x00100000,
+      0x00700000, 0x00780000, 0x00600000, 0x00380000,
+      0x00300000, 0x00000000, 0x00480000, 0x00580000,
+      0x04280000, 0x04400000, 0x04080000, 0x04680000,
+      0x04500000, 0x04180000, 0x04200000, 0x04100000,
+      0x04700000, 0x04780000, 0x04600000, 0x04380000,
+      0x04300000, 0x04000000, 0x04480000, 0x04580000,
+      0x04a80000, 0x04c00000, 0x04880000, 0x04e80000,
+      0x04d00000, 0x04980000, 0x04a00000, 0x04900000,
+      0x04f00000, 0x04f80000, 0x04e00000, 0x04b80000,
+      0x04b00000, 0x04800000, 0x04c80000, 0x04d80000,
+      0x07a80000, 0x07c00000, 0x07880000, 0x07e80000,
+      0x07d00000, 0x07980000, 0x07a00000, 0x07900000,
+      0x07f00000, 0x07f80000, 0x07e00000, 0x07b80000,
+      0x07b00000, 0x07800000, 0x07c80000, 0x07d80000,
+      0x07280000, 0x07400000, 0x07080000, 0x07680000,
+      0x07500000, 0x07180000, 0x07200000, 0x07100000,
+      0x07700000, 0x07780000, 0x07600000, 0x07380000,
+      0x07300000, 0x07000000, 0x07480000, 0x07580000,
+      0x02280000, 0x02400000, 0x02080000, 0x02680000,
+      0x02500000, 0x02180000, 0x02200000, 0x02100000,
+      0x02700000, 0x02780000, 0x02600000, 0x02380000,
+      0x02300000, 0x02000000, 0x02480000, 0x02580000,
+      0x03280000, 0x03400000, 0x03080000, 0x03680000,
+      0x03500000, 0x03180000, 0x03200000, 0x03100000,
+      0x03700000, 0x03780000, 0x03600000, 0x03380000,
+      0x03300000, 0x03000000, 0x03480000, 0x03580000,
+      0x06280000, 0x06400000, 0x06080000, 0x06680000,
+      0x06500000, 0x06180000, 0x06200000, 0x06100000,
+      0x06700000, 0x06780000, 0x06600000, 0x06380000,
+      0x06300000, 0x06000000, 0x06480000, 0x06580000,
+      0x05a80000, 0x05c00000, 0x05880000, 0x05e80000,
+      0x05d00000, 0x05980000, 0x05a00000, 0x05900000,
+      0x05f00000, 0x05f80000, 0x05e00000, 0x05b80000,
+      0x05b00000, 0x05800000, 0x05c80000, 0x05d80000,
+      0x01280000, 0x01400000, 0x01080000, 0x01680000,
+      0x01500000, 0x01180000, 0x01200000, 0x01100000,
+      0x01700000, 0x01780000, 0x01600000, 0x01380000,
+      0x01300000, 0x01000000, 0x01480000, 0x01580000,
+      0x02a80000, 0x02c00000, 0x02880000, 0x02e80000,
+      0x02d00000, 0x02980000, 0x02a00000, 0x02900000,
+      0x02f00000, 0x02f80000, 0x02e00000, 0x02b80000,
+      0x02b00000, 0x02800000, 0x02c80000, 0x02d80000,
+      0x01a80000, 0x01c00000, 0x01880000, 0x01e80000,
+      0x01d00000, 0x01980000, 0x01a00000, 0x01900000,
+      0x01f00000, 0x01f80000, 0x01e00000, 0x01b80000,
+      0x01b00000, 0x01800000, 0x01c80000, 0x01d80000,
+    }, { /* 2 */
+      0x30000002, 0x60000002, 0x38000002, 0x08000002,
+      0x28000002, 0x78000002, 0x68000002, 0x40000002,
+      0x20000002, 0x50000002, 0x48000002, 0x70000002,
+      0x00000002, 0x18000002, 0x58000002, 0x10000002,
+      0xb0000005, 0xe0000005, 0xb8000005, 0x88000005,
+      0xa8000005, 0xf8000005, 0xe8000005, 0xc0000005,
+      0xa0000005, 0xd0000005, 0xc8000005, 0xf0000005,
+      0x80000005, 0x98000005, 0xd8000005, 0x90000005,
+      0x30000005, 0x60000005, 0x38000005, 0x08000005,
+      0x28000005, 0x78000005, 0x68000005, 0x40000005,
+      0x20000005, 0x50000005, 0x48000005, 0x70000005,
+      0x00000005, 0x18000005, 0x58000005, 0x10000005,
+      0x30000000, 0x60000000, 0x38000000, 0x08000000,
+      0x28000000, 0x78000000, 0x68000000, 0x40000000,
+      0x20000000, 0x50000000, 0x48000000, 0x70000000,
+      0x00000000, 0x18000000, 0x58000000, 0x10000000,
+      0xb0000003, 0xe0000003, 0xb8000003, 0x88000003,
+      0xa8000003, 0xf8000003, 0xe8000003, 0xc0000003,
+      0xa0000003, 0xd0000003, 0xc8000003, 0xf0000003,
+      0x80000003, 0x98000003, 0xd8000003, 0x90000003,
+      0x30000001, 0x60000001, 0x38000001, 0x08000001,
+      0x28000001, 0x78000001, 0x68000001, 0x40000001,
+      0x20000001, 0x50000001, 0x48000001, 0x70000001,
+      0x00000001, 0x18000001, 0x58000001, 0x10000001,
+      0xb0000000, 0xe0000000, 0xb8000000, 0x88000000,
+      0xa8000000, 0xf8000000, 0xe8000000, 0xc0000000,
+      0xa0000000, 0xd0000000, 0xc8000000, 0xf0000000,
+      0x80000000, 0x98000000, 0xd8000000, 0x90000000,
+      0xb0000006, 0xe0000006, 0xb8000006, 0x88000006,
+      0xa8000006, 0xf8000006, 0xe8000006, 0xc0000006,
+      0xa0000006, 0xd0000006, 0xc8000006, 0xf0000006,
+      0x80000006, 0x98000006, 0xd8000006, 0x90000006,
+      0xb0000001, 0xe0000001, 0xb8000001, 0x88000001,
+      0xa8000001, 0xf8000001, 0xe8000001, 0xc0000001,
+      0xa0000001, 0xd0000001, 0xc8000001, 0xf0000001,
+      0x80000001, 0x98000001, 0xd8000001, 0x90000001,
+      0x30000003, 0x60000003, 0x38000003, 0x08000003,
+      0x28000003, 0x78000003, 0x68000003, 0x40000003,
+      0x20000003, 0x50000003, 0x48000003, 0x70000003,
+      0x00000003, 0x18000003, 0x58000003, 0x10000003,
+      0x30000004, 0x60000004, 0x38000004, 0x08000004,
+      0x28000004, 0x78000004, 0x68000004, 0x40000004,
+      0x20000004, 0x50000004, 0x48000004, 0x70000004,
+      0x00000004, 0x18000004, 0x58000004, 0x10000004,
+      0xb0000002, 0xe0000002, 0xb8000002, 0x88000002,
+      0xa8000002, 0xf8000002, 0xe8000002, 0xc0000002,
+      0xa0000002, 0xd0000002, 0xc8000002, 0xf0000002,
+      0x80000002, 0x98000002, 0xd8000002, 0x90000002,
+      0xb0000004, 0xe0000004, 0xb8000004, 0x88000004,
+      0xa8000004, 0xf8000004, 0xe8000004, 0xc0000004,
+      0xa0000004, 0xd0000004, 0xc8000004, 0xf0000004,
+      0x80000004, 0x98000004, 0xd8000004, 0x90000004,
+      0x30000006, 0x60000006, 0x38000006, 0x08000006,
+      0x28000006, 0x78000006, 0x68000006, 0x40000006,
+      0x20000006, 0x50000006, 0x48000006, 0x70000006,
+      0x00000006, 0x18000006, 0x58000006, 0x10000006,
+      0xb0000007, 0xe0000007, 0xb8000007, 0x88000007,
+      0xa8000007, 0xf8000007, 0xe8000007, 0xc0000007,
+      0xa0000007, 0xd0000007, 0xc8000007, 0xf0000007,
+      0x80000007, 0x98000007, 0xd8000007, 0x90000007,
+      0x30000007, 0x60000007, 0x38000007, 0x08000007,
+      0x28000007, 0x78000007, 0x68000007, 0x40000007,
+      0x20000007, 0x50000007, 0x48000007, 0x70000007,
+      0x00000007, 0x18000007, 0x58000007, 0x10000007,
+    }, { /* 3 */
+      0x000000e8, 0x000000d8, 0x000000a0, 0x00000088,
+      0x00000098, 0x000000f8, 0x000000a8, 0x000000c8,
+      0x00000080, 0x000000d0, 0x000000f0, 0x000000b8,
+      0x000000b0, 0x000000c0, 0x00000090, 0x000000e0,
+      0x000007e8, 0x000007d8, 0x000007a0, 0x00000788,
+      0x00000798, 0x000007f8, 0x000007a8, 0x000007c8,
+      0x00000780, 0x000007d0, 0x000007f0, 0x000007b8,
+      0x000007b0, 0x000007c0, 0x00000790, 0x000007e0,
+      0x000006e8, 0x000006d8, 0x000006a0, 0x00000688,
+      0x00000698, 0x000006f8, 0x000006a8, 0x000006c8,
+      0x00000680, 0x000006d0, 0x000006f0, 0x000006b8,
+      0x000006b0, 0x000006c0, 0x00000690, 0x000006e0,
+      0x00000068, 0x00000058, 0x00000020, 0x00000008,
+      0x00000018, 0x00000078, 0x00000028, 0x00000048,
+      0x00000000, 0x00000050, 0x00000070, 0x00000038,
+      0x00000030, 0x00000040, 0x00000010, 0x00000060,
+      0x000002e8, 0x000002d8, 0x000002a0, 0x00000288,
+      0x00000298, 0x000002f8, 0x000002a8, 0x000002c8,
+      0x00000280, 0x000002d0, 0x000002f0, 0x000002b8,
+      0x000002b0, 0x000002c0, 0x00000290, 0x000002e0,
+      0x000003e8, 0x000003d8, 0x000003a0, 0x00000388,
+      0x00000398, 0x000003f8, 0x000003a8, 0x000003c8,
+      0x00000380, 0x000003d0, 0x000003f0, 0x000003b8,
+      0x000003b0, 0x000003c0, 0x00000390, 0x000003e0,
+      0x00000568, 0x00000558, 0x00000520, 0x00000508,
+      0x00000518, 0x00000578, 0x00000528, 0x00000548,
+      0x00000500, 0x00000550, 0x00000570, 0x00000538,
+      0x00000530, 0x00000540, 0x00000510, 0x00000560,
+      0x00000268, 0x00000258, 0x00000220, 0x00000208,
+      0x00000218, 0x00000278, 0x00000228, 0x00000248,
+      0x00000200, 0x00000250, 0x00000270, 0x00000238,
+      0x00000230, 0x00000240, 0x00000210, 0x00000260,
+      0x000004e8, 0x000004d8, 0x000004a0, 0x00000488,
+      0x00000498, 0x000004f8, 0x000004a8, 0x000004c8,
+      0x00000480, 0x000004d0, 0x000004f0, 0x000004b8,
+      0x000004b0, 0x000004c0, 0x00000490, 0x000004e0,
+      0x00000168, 0x00000158, 0x00000120, 0x00000108,
+      0x00000118, 0x00000178, 0x00000128, 0x00000148,
+      0x00000100, 0x00000150, 0x00000170, 0x00000138,
+      0x00000130, 0x00000140, 0x00000110, 0x00000160,
+      0x000001e8, 0x000001d8, 0x000001a0, 0x00000188,
+      0x00000198, 0x000001f8, 0x000001a8, 0x000001c8,
+      0x00000180, 0x000001d0, 0x000001f0, 0x000001b8,
+      0x000001b0, 0x000001c0, 0x00000190, 0x000001e0,
+      0x00000768, 0x00000758, 0x00000720, 0x00000708,
+      0x00000718, 0x00000778, 0x00000728, 0x00000748,
+      0x00000700, 0x00000750, 0x00000770, 0x00000738,
+      0x00000730, 0x00000740, 0x00000710, 0x00000760,
+      0x00000368, 0x00000358, 0x00000320, 0x00000308,
+      0x00000318, 0x00000378, 0x00000328, 0x00000348,
+      0x00000300, 0x00000350, 0x00000370, 0x00000338,
+      0x00000330, 0x00000340, 0x00000310, 0x00000360,
+      0x000005e8, 0x000005d8, 0x000005a0, 0x00000588,
+      0x00000598, 0x000005f8, 0x000005a8, 0x000005c8,
+      0x00000580, 0x000005d0, 0x000005f0, 0x000005b8,
+      0x000005b0, 0x000005c0, 0x00000590, 0x000005e0,
+      0x00000468, 0x00000458, 0x00000420, 0x00000408,
+      0x00000418, 0x00000478, 0x00000428, 0x00000448,
+      0x00000400, 0x00000450, 0x00000470, 0x00000438,
+      0x00000430, 0x00000440, 0x00000410, 0x00000460,
+      0x00000668, 0x00000658, 0x00000620, 0x00000608,
+      0x00000618, 0x00000678, 0x00000628, 0x00000648,
+      0x00000600, 0x00000650, 0x00000670, 0x00000638,
+      0x00000630, 0x00000640, 0x00000610, 0x00000660,
+    }
+  }
+};
+
+const struct gost28147_param _gost28147_param_CryptoPro_3411 =
+{
+  {
+    { /* 0 */
+      0x0002d000, 0x0002a000, 0x0002a800, 0x0002b000,
+      0x0002c000, 0x00028800, 0x00029800, 0x0002b800,
+      0x0002e800, 0x0002e000, 0x0002f000, 0x00028000,
+      0x0002c800, 0x00029000, 0x0002d800, 0x0002f800,
+      0x0007d000, 0x0007a000, 0x0007a800, 0x0007b000,
+      0x0007c000, 0x00078800, 0x00079800, 0x0007b800,
+      0x0007e800, 0x0007e000, 0x0007f000, 0x00078000,
+      0x0007c800, 0x00079000, 0x0007d800, 0x0007f800,
+      0x00025000, 0x00022000, 0x00022800, 0x00023000,
+      0x00024000, 0x00020800, 0x00021800, 0x00023800,
+      0x00026800, 0x00026000, 0x00027000, 0x00020000,
+      0x00024800, 0x00021000, 0x00025800, 0x00027800,
+      0x00005000, 0x00002000, 0x00002800, 0x00003000,
+      0x00004000, 0x00000800, 0x00001800, 0x00003800,
+      0x00006800, 0x00006000, 0x00007000, 0x00000000,
+      0x00004800, 0x00001000, 0x00005800, 0x00007800,
+      0x00015000, 0x00012000, 0x00012800, 0x00013000,
+      0x00014000, 0x00010800, 0x00011800, 0x00013800,
+      0x00016800, 0x00016000, 0x00017000, 0x00010000,
+      0x00014800, 0x00011000, 0x00015800, 0x00017800,
+      0x0006d000, 0x0006a000, 0x0006a800, 0x0006b000,
+      0x0006c000, 0x00068800, 0x00069800, 0x0006b800,
+      0x0006e800, 0x0006e000, 0x0006f000, 0x00068000,
+      0x0006c800, 0x00069000, 0x0006d800, 0x0006f800,
+      0x0005d000, 0x0005a000, 0x0005a800, 0x0005b000,
+      0x0005c000, 0x00058800, 0x00059800, 0x0005b800,
+      0x0005e800, 0x0005e000, 0x0005f000, 0x00058000,
+      0x0005c800, 0x00059000, 0x0005d800, 0x0005f800,
+      0x0004d000, 0x0004a000, 0x0004a800, 0x0004b000,
+      0x0004c000, 0x00048800, 0x00049800, 0x0004b800,
+      0x0004e800, 0x0004e000, 0x0004f000, 0x00048000,
+      0x0004c800, 0x00049000, 0x0004d800, 0x0004f800,
+      0x0000d000, 0x0000a000, 0x0000a800, 0x0000b000,
+      0x0000c000, 0x00008800, 0x00009800, 0x0000b800,
+      0x0000e800, 0x0000e000, 0x0000f000, 0x00008000,
+      0x0000c800, 0x00009000, 0x0000d800, 0x0000f800,
+      0x0003d000, 0x0003a000, 0x0003a800, 0x0003b000,
+      0x0003c000, 0x00038800, 0x00039800, 0x0003b800,
+      0x0003e800, 0x0003e000, 0x0003f000, 0x00038000,
+      0x0003c800, 0x00039000, 0x0003d800, 0x0003f800,
+      0x00035000, 0x00032000, 0x00032800, 0x00033000,
+      0x00034000, 0x00030800, 0x00031800, 0x00033800,
+      0x00036800, 0x00036000, 0x00037000, 0x00030000,
+      0x00034800, 0x00031000, 0x00035800, 0x00037800,
+      0x0001d000, 0x0001a000, 0x0001a800, 0x0001b000,
+      0x0001c000, 0x00018800, 0x00019800, 0x0001b800,
+      0x0001e800, 0x0001e000, 0x0001f000, 0x00018000,
+      0x0001c800, 0x00019000, 0x0001d800, 0x0001f800,
+      0x00065000, 0x00062000, 0x00062800, 0x00063000,
+      0x00064000, 0x00060800, 0x00061800, 0x00063800,
+      0x00066800, 0x00066000, 0x00067000, 0x00060000,
+      0x00064800, 0x00061000, 0x00065800, 0x00067800,
+      0x00075000, 0x00072000, 0x00072800, 0x00073000,
+      0x00074000, 0x00070800, 0x00071800, 0x00073800,
+      0x00076800, 0x00076000, 0x00077000, 0x00070000,
+      0x00074800, 0x00071000, 0x00075800, 0x00077800,
+      0x00055000, 0x00052000, 0x00052800, 0x00053000,
+      0x00054000, 0x00050800, 0x00051800, 0x00053800,
+      0x00056800, 0x00056000, 0x00057000, 0x00050000,
+      0x00054800, 0x00051000, 0x00055800, 0x00057800,
+      0x00045000, 0x00042000, 0x00042800, 0x00043000,
+      0x00044000, 0x00040800, 0x00041800, 0x00043800,
+      0x00046800, 0x00046000, 0x00047000, 0x00040000,
+      0x00044800, 0x00041000, 0x00045800, 0x00047800,
+    }, { /* 1 */
+      0x02380000, 0x02780000, 0x02600000, 0x02700000,
+      0x02480000, 0x02200000, 0x02080000, 0x02000000,
+      0x02180000, 0x02580000, 0x02280000, 0x02100000,
+      0x02300000, 0x02500000, 0x02400000, 0x02680000,
+      0x05380000, 0x05780000, 0x05600000, 0x05700000,
+      0x05480000, 0x05200000, 0x05080000, 0x05000000,
+      0x05180000, 0x05580000, 0x05280000, 0x05100000,
+      0x05300000, 0x05500000, 0x05400000, 0x05680000,
+      0x03b80000, 0x03f80000, 0x03e00000, 0x03f00000,
+      0x03c80000, 0x03a00000, 0x03880000, 0x03800000,
+      0x03980000, 0x03d80000, 0x03a80000, 0x03900000,
+      0x03b00000, 0x03d00000, 0x03c00000, 0x03e80000,
+      0x06380000, 0x06780000, 0x06600000, 0x06700000,
+      0x06480000, 0x06200000, 0x06080000, 0x06000000,
+      0x06180000, 0x06580000, 0x06280000, 0x06100000,
+      0x06300000, 0x06500000, 0x06400000, 0x06680000,
+      0x00380000, 0x00780000, 0x00600000, 0x00700000,
+      0x00480000, 0x00200000, 0x00080000, 0x00000000,
+      0x00180000, 0x00580000, 0x00280000, 0x00100000,
+      0x00300000, 0x00500000, 0x00400000, 0x00680000,
+      0x07b80000, 0x07f80000, 0x07e00000, 0x07f00000,
+      0x07c80000, 0x07a00000, 0x07880000, 0x07800000,
+      0x07980000, 0x07d80000, 0x07a80000, 0x07900000,
+      0x07b00000, 0x07d00000, 0x07c00000, 0x07e80000,
+      0x01380000, 0x01780000, 0x01600000, 0x01700000,
+      0x01480000, 0x01200000, 0x01080000, 0x01000000,
+      0x01180000, 0x01580000, 0x01280000, 0x01100000,
+      0x01300000, 0x01500000, 0x01400000, 0x01680000,
+      0x04380000, 0x04780000, 0x04600000, 0x04700000,
+      0x04480000, 0x04200000, 0x04080000, 0x04000000,
+      0x04180000, 0x04580000, 0x04280000, 0x04100000,
+      0x04300000, 0x04500000, 0x04400000, 0x04680000,
+      0x07380000, 0x07780000, 0x07600000, 0x07700000,
+      0x07480000, 0x07200000, 0x07080000, 0x07000000,
+      0x07180000, 0x07580000, 0x07280000, 0x07100000,
+      0x07300000, 0x07500000, 0x07400000, 0x07680000,
+      0x00b80000, 0x00f80000, 0x00e00000, 0x00f00000,
+      0x00c80000, 0x00a00000, 0x00880000, 0x00800000,
+      0x00980000, 0x00d80000, 0x00a80000, 0x00900000,
+      0x00b00000, 0x00d00000, 0x00c00000, 0x00e80000,
+      0x03380000, 0x03780000, 0x03600000, 0x03700000,
+      0x03480000, 0x03200000, 0x03080000, 0x03000000,
+      0x03180000, 0x03580000, 0x03280000, 0x03100000,
+      0x03300000, 0x03500000, 0x03400000, 0x03680000,
+      0x02b80000, 0x02f80000, 0x02e00000, 0x02f00000,
+      0x02c80000, 0x02a00000, 0x02880000, 0x02800000,
+      0x02980000, 0x02d80000, 0x02a80000, 0x02900000,
+      0x02b00000, 0x02d00000, 0x02c00000, 0x02e80000,
+      0x06b80000, 0x06f80000, 0x06e00000, 0x06f00000,
+      0x06c80000, 0x06a00000, 0x06880000, 0x06800000,
+      0x06980000, 0x06d80000, 0x06a80000, 0x06900000,
+      0x06b00000, 0x06d00000, 0x06c00000, 0x06e80000,
+      0x05b80000, 0x05f80000, 0x05e00000, 0x05f00000,
+      0x05c80000, 0x05a00000, 0x05880000, 0x05800000,
+      0x05980000, 0x05d80000, 0x05a80000, 0x05900000,
+      0x05b00000, 0x05d00000, 0x05c00000, 0x05e80000,
+      0x04b80000, 0x04f80000, 0x04e00000, 0x04f00000,
+      0x04c80000, 0x04a00000, 0x04880000, 0x04800000,
+      0x04980000, 0x04d80000, 0x04a80000, 0x04900000,
+      0x04b00000, 0x04d00000, 0x04c00000, 0x04e80000,
+      0x01b80000, 0x01f80000, 0x01e00000, 0x01f00000,
+      0x01c80000, 0x01a00000, 0x01880000, 0x01800000,
+      0x01980000, 0x01d80000, 0x01a80000, 0x01900000,
+      0x01b00000, 0x01d00000, 0x01c00000, 0x01e80000,
+    }, { /* 2 */
+      0xb8000003, 0xb0000003, 0xa0000003, 0xd8000003,
+      0xc8000003, 0xe0000003, 0x90000003, 0xd0000003,
+      0x88000003, 0xc0000003, 0x80000003, 0xf0000003,
+      0xf8000003, 0xe8000003, 0x98000003, 0xa8000003,
+      0x38000003, 0x30000003, 0x20000003, 0x58000003,
+      0x48000003, 0x60000003, 0x10000003, 0x50000003,
+      0x08000003, 0x40000003, 0x00000003, 0x70000003,
+      0x78000003, 0x68000003, 0x18000003, 0x28000003,
+      0x38000001, 0x30000001, 0x20000001, 0x58000001,
+      0x48000001, 0x60000001, 0x10000001, 0x50000001,
+      0x08000001, 0x40000001, 0x00000001, 0x70000001,
+      0x78000001, 0x68000001, 0x18000001, 0x28000001,
+      0x38000002, 0x30000002, 0x20000002, 0x58000002,
+      0x48000002, 0x60000002, 0x10000002, 0x50000002,
+      0x08000002, 0x40000002, 0x00000002, 0x70000002,
+      0x78000002, 0x68000002, 0x18000002, 0x28000002,
+      0xb8000006, 0xb0000006, 0xa0000006, 0xd8000006,
+      0xc8000006, 0xe0000006, 0x90000006, 0xd0000006,
+      0x88000006, 0xc0000006, 0x80000006, 0xf0000006,
+      0xf8000006, 0xe8000006, 0x98000006, 0xa8000006,
+      0xb8000004, 0xb0000004, 0xa0000004, 0xd8000004,
+      0xc8000004, 0xe0000004, 0x90000004, 0xd0000004,
+      0x88000004, 0xc0000004, 0x80000004, 0xf0000004,
+      0xf8000004, 0xe8000004, 0x98000004, 0xa8000004,
+      0xb8000007, 0xb0000007, 0xa0000007, 0xd8000007,
+      0xc8000007, 0xe0000007, 0x90000007, 0xd0000007,
+      0x88000007, 0xc0000007, 0x80000007, 0xf0000007,
+      0xf8000007, 0xe8000007, 0x98000007, 0xa8000007,
+      0x38000000, 0x30000000, 0x20000000, 0x58000000,
+      0x48000000, 0x60000000, 0x10000000, 0x50000000,
+      0x08000000, 0x40000000, 0x00000000, 0x70000000,
+      0x78000000, 0x68000000, 0x18000000, 0x28000000,
+      0x38000005, 0x30000005, 0x20000005, 0x58000005,
+      0x48000005, 0x60000005, 0x10000005, 0x50000005,
+      0x08000005, 0x40000005, 0x00000005, 0x70000005,
+      0x78000005, 0x68000005, 0x18000005, 0x28000005,
+      0xb8000000, 0xb0000000, 0xa0000000, 0xd8000000,
+      0xc8000000, 0xe0000000, 0x90000000, 0xd0000000,
+      0x88000000, 0xc0000000, 0x80000000, 0xf0000000,
+      0xf8000000, 0xe8000000, 0x98000000, 0xa8000000,
+      0xb8000002, 0xb0000002, 0xa0000002, 0xd8000002,
+      0xc8000002, 0xe0000002, 0x90000002, 0xd0000002,
+      0x88000002, 0xc0000002, 0x80000002, 0xf0000002,
+      0xf8000002, 0xe8000002, 0x98000002, 0xa8000002,
+      0xb8000005, 0xb0000005, 0xa0000005, 0xd8000005,
+      0xc8000005, 0xe0000005, 0x90000005, 0xd0000005,
+      0x88000005, 0xc0000005, 0x80000005, 0xf0000005,
+      0xf8000005, 0xe8000005, 0x98000005, 0xa8000005,
+      0x38000004, 0x30000004, 0x20000004, 0x58000004,
+      0x48000004, 0x60000004, 0x10000004, 0x50000004,
+      0x08000004, 0x40000004, 0x00000004, 0x70000004,
+      0x78000004, 0x68000004, 0x18000004, 0x28000004,
+      0x38000007, 0x30000007, 0x20000007, 0x58000007,
+      0x48000007, 0x60000007, 0x10000007, 0x50000007,
+      0x08000007, 0x40000007, 0x00000007, 0x70000007,
+      0x78000007, 0x68000007, 0x18000007, 0x28000007,
+      0x38000006, 0x30000006, 0x20000006, 0x58000006,
+      0x48000006, 0x60000006, 0x10000006, 0x50000006,
+      0x08000006, 0x40000006, 0x00000006, 0x70000006,
+      0x78000006, 0x68000006, 0x18000006, 0x28000006,
+      0xb8000001, 0xb0000001, 0xa0000001, 0xd8000001,
+      0xc8000001, 0xe0000001, 0x90000001, 0xd0000001,
+      0x88000001, 0xc0000001, 0x80000001, 0xf0000001,
+      0xf8000001, 0xe8000001, 0x98000001, 0xa8000001,
+    }, { /* 3 */
+      0x000000e8, 0x000000f0, 0x000000a0, 0x00000088,
+      0x000000b8, 0x00000080, 0x000000a8, 0x000000d0,
+      0x00000098, 0x000000e0, 0x000000c0, 0x000000f8,
+      0x000000b0, 0x00000090, 0x000000c8, 0x000000d8,
+      0x000001e8, 0x000001f0, 0x000001a0, 0x00000188,
+      0x000001b8, 0x00000180, 0x000001a8, 0x000001d0,
+      0x00000198, 0x000001e0, 0x000001c0, 0x000001f8,
+      0x000001b0, 0x00000190, 0x000001c8, 0x000001d8,
+      0x00000568, 0x00000570, 0x00000520, 0x00000508,
+      0x00000538, 0x00000500, 0x00000528, 0x00000550,
+      0x00000518, 0x00000560, 0x00000540, 0x00000578,
+      0x00000530, 0x00000510, 0x00000548, 0x00000558,
+      0x000004e8, 0x000004f0, 0x000004a0, 0x00000488,
+      0x000004b8, 0x00000480, 0x000004a8, 0x000004d0,
+      0x00000498, 0x000004e0, 0x000004c0, 0x000004f8,
+      0x000004b0, 0x00000490, 0x000004c8, 0x000004d8,
+      0x000002e8, 0x000002f0, 0x000002a0, 0x00000288,
+      0x000002b8, 0x00000280, 0x000002a8, 0x000002d0,
+      0x00000298, 0x000002e0, 0x000002c0, 0x000002f8,
+      0x000002b0, 0x00000290, 0x000002c8, 0x000002d8,
+      0x000005e8, 0x000005f0, 0x000005a0, 0x00000588,
+      0x000005b8, 0x00000580, 0x000005a8, 0x000005d0,
+      0x00000598, 0x000005e0, 0x000005c0, 0x000005f8,
+      0x000005b0, 0x00000590, 0x000005c8, 0x000005d8,
+      0x00000268, 0x00000270, 0x00000220, 0x00000208,
+      0x00000238, 0x00000200, 0x00000228, 0x00000250,
+      0x00000218, 0x00000260, 0x00000240, 0x00000278,
+      0x00000230, 0x00000210, 0x00000248, 0x00000258,
+      0x000007e8, 0x000007f0, 0x000007a0, 0x00000788,
+      0x000007b8, 0x00000780, 0x000007a8, 0x000007d0,
+      0x00000798, 0x000007e0, 0x000007c0, 0x000007f8,
+      0x000007b0, 0x00000790, 0x000007c8, 0x000007d8,
+      0x00000468, 0x00000470, 0x00000420, 0x00000408,
+      0x00000438, 0x00000400, 0x00000428, 0x00000450,
+      0x00000418, 0x00000460, 0x00000440, 0x00000478,
+      0x00000430, 0x00000410, 0x00000448, 0x00000458,
+      0x00000368, 0x00000370, 0x00000320, 0x00000308,
+      0x00000338, 0x00000300, 0x00000328, 0x00000350,
+      0x00000318, 0x00000360, 0x00000340, 0x00000378,
+      0x00000330, 0x00000310, 0x00000348, 0x00000358,
+      0x000003e8, 0x000003f0, 0x000003a0, 0x00000388,
+      0x000003b8, 0x00000380, 0x000003a8, 0x000003d0,
+      0x00000398, 0x000003e0, 0x000003c0, 0x000003f8,
+      0x000003b0, 0x00000390, 0x000003c8, 0x000003d8,
+      0x00000768, 0x00000770, 0x00000720, 0x00000708,
+      0x00000738, 0x00000700, 0x00000728, 0x00000750,
+      0x00000718, 0x00000760, 0x00000740, 0x00000778,
+      0x00000730, 0x00000710, 0x00000748, 0x00000758,
+      0x000006e8, 0x000006f0, 0x000006a0, 0x00000688,
+      0x000006b8, 0x00000680, 0x000006a8, 0x000006d0,
+      0x00000698, 0x000006e0, 0x000006c0, 0x000006f8,
+      0x000006b0, 0x00000690, 0x000006c8, 0x000006d8,
+      0x00000068, 0x00000070, 0x00000020, 0x00000008,
+      0x00000038, 0x00000000, 0x00000028, 0x00000050,
+      0x00000018, 0x00000060, 0x00000040, 0x00000078,
+      0x00000030, 0x00000010, 0x00000048, 0x00000058,
+      0x00000168, 0x00000170, 0x00000120, 0x00000108,
+      0x00000138, 0x00000100, 0x00000128, 0x00000150,
+      0x00000118, 0x00000160, 0x00000140, 0x00000178,
+      0x00000130, 0x00000110, 0x00000148, 0x00000158,
+      0x00000668, 0x00000670, 0x00000620, 0x00000608,
+      0x00000638, 0x00000600, 0x00000628, 0x00000650,
+      0x00000618, 0x00000660, 0x00000640, 0x00000678,
+      0x00000630, 0x00000610, 0x00000648, 0x00000658,
+    }
+  }
+};
diff --git a/gost28147.c b/gost28147.c
index b6db334b2a0b..669fc85d2083 100644
--- a/gost28147.c
+++ b/gost28147.c
@@ -35,541 +35,6 @@
 #include "macros.h"
 #include "gost28147-internal.h"
 
-/* pre-initialized GOST lookup tables based on rotated S-Box */
-const struct gost28147_param _gost28147_param_test_3411 =
-{
-  {
-    { /* 0 */
-      0x00072000, 0x00075000, 0x00074800, 0x00071000,
-      0x00076800, 0x00074000, 0x00070000, 0x00077000,
-      0x00073000, 0x00075800, 0x00070800, 0x00076000,
-      0x00073800, 0x00077800, 0x00072800, 0x00071800,
-      0x0005a000, 0x0005d000, 0x0005c800, 0x00059000,
-      0x0005e800, 0x0005c000, 0x00058000, 0x0005f000,
-      0x0005b000, 0x0005d800, 0x00058800, 0x0005e000,
-      0x0005b800, 0x0005f800, 0x0005a800, 0x00059800,
-      0x00022000, 0x00025000, 0x00024800, 0x00021000,
-      0x00026800, 0x00024000, 0x00020000, 0x00027000,
-      0x00023000, 0x00025800, 0x00020800, 0x00026000,
-      0x00023800, 0x00027800, 0x00022800, 0x00021800,
-      0x00062000, 0x00065000, 0x00064800, 0x00061000,
-      0x00066800, 0x00064000, 0x00060000, 0x00067000,
-      0x00063000, 0x00065800, 0x00060800, 0x00066000,
-      0x00063800, 0x00067800, 0x00062800, 0x00061800,
-      0x00032000, 0x00035000, 0x00034800, 0x00031000,
-      0x00036800, 0x00034000, 0x00030000, 0x00037000,
-      0x00033000, 0x00035800, 0x00030800, 0x00036000,
-      0x00033800, 0x00037800, 0x00032800, 0x00031800,
-      0x0006a000, 0x0006d000, 0x0006c800, 0x00069000,
-      0x0006e800, 0x0006c000, 0x00068000, 0x0006f000,
-      0x0006b000, 0x0006d800, 0x00068800, 0x0006e000,
-      0x0006b800, 0x0006f800, 0x0006a800, 0x00069800,
-      0x0007a000, 0x0007d000, 0x0007c800, 0x00079000,
-      0x0007e800, 0x0007c000, 0x00078000, 0x0007f000,
-      0x0007b000, 0x0007d800, 0x00078800, 0x0007e000,
-      0x0007b800, 0x0007f800, 0x0007a800, 0x00079800,
-      0x00052000, 0x00055000, 0x00054800, 0x00051000,
-      0x00056800, 0x00054000, 0x00050000, 0x00057000,
-      0x00053000, 0x00055800, 0x00050800, 0x00056000,
-      0x00053800, 0x00057800, 0x00052800, 0x00051800,
-      0x00012000, 0x00015000, 0x00014800, 0x00011000,
-      0x00016800, 0x00014000, 0x00010000, 0x00017000,
-      0x00013000, 0x00015800, 0x00010800, 0x00016000,
-      0x00013800, 0x00017800, 0x00012800, 0x00011800,
-      0x0001a000, 0x0001d000, 0x0001c800, 0x00019000,
-      0x0001e800, 0x0001c000, 0x00018000, 0x0001f000,
-      0x0001b000, 0x0001d800, 0x00018800, 0x0001e000,
-      0x0001b800, 0x0001f800, 0x0001a800, 0x00019800,
-      0x00042000, 0x00045000, 0x00044800, 0x00041000,
-      0x00046800, 0x00044000, 0x00040000, 0x00047000,
-      0x00043000, 0x00045800, 0x00040800, 0x00046000,
-      0x00043800, 0x00047800, 0x00042800, 0x00041800,
-      0x0000a000, 0x0000d000, 0x0000c800, 0x00009000,
-      0x0000e800, 0x0000c000, 0x00008000, 0x0000f000,
-      0x0000b000, 0x0000d800, 0x00008800, 0x0000e000,
-      0x0000b800, 0x0000f800, 0x0000a800, 0x00009800,
-      0x00002000, 0x00005000, 0x00004800, 0x00001000,
-      0x00006800, 0x00004000, 0x00000000, 0x00007000,
-      0x00003000, 0x00005800, 0x00000800, 0x00006000,
-      0x00003800, 0x00007800, 0x00002800, 0x00001800,
-      0x0003a000, 0x0003d000, 0x0003c800, 0x00039000,
-      0x0003e800, 0x0003c000, 0x00038000, 0x0003f000,
-      0x0003b000, 0x0003d800, 0x00038800, 0x0003e000,
-      0x0003b800, 0x0003f800, 0x0003a800, 0x00039800,
-      0x0002a000, 0x0002d000, 0x0002c800, 0x00029000,
-      0x0002e800, 0x0002c000, 0x00028000, 0x0002f000,
-      0x0002b000, 0x0002d800, 0x00028800, 0x0002e000,
-      0x0002b800, 0x0002f800, 0x0002a800, 0x00029800,
-      0x0004a000, 0x0004d000, 0x0004c800, 0x00049000,
-      0x0004e800, 0x0004c000, 0x00048000, 0x0004f000,
-      0x0004b000, 0x0004d800, 0x00048800, 0x0004e000,
-      0x0004b800, 0x0004f800, 0x0004a800, 0x00049800,
-    }, { /* 1 */
-      0x03a80000, 0x03c00000, 0x03880000, 0x03e80000,
-      0x03d00000, 0x03980000, 0x03a00000, 0x03900000,
-      0x03f00000, 0x03f80000, 0x03e00000, 0x03b80000,
-      0x03b00000, 0x03800000, 0x03c80000, 0x03d80000,
-      0x06a80000, 0x06c00000, 0x06880000, 0x06e80000,
-      0x06d00000, 0x06980000, 0x06a00000, 0x06900000,
-      0x06f00000, 0x06f80000, 0x06e00000, 0x06b80000,
-      0x06b00000, 0x06800000, 0x06c80000, 0x06d80000,
-      0x05280000, 0x05400000, 0x05080000, 0x05680000,
-      0x05500000, 0x05180000, 0x05200000, 0x05100000,
-      0x05700000, 0x05780000, 0x05600000, 0x05380000,
-      0x05300000, 0x05000000, 0x05480000, 0x05580000,
-      0x00a80000, 0x00c00000, 0x00880000, 0x00e80000,
-      0x00d00000, 0x00980000, 0x00a00000, 0x00900000,
-      0x00f00000, 0x00f80000, 0x00e00000, 0x00b80000,
-      0x00b00000, 0x00800000, 0x00c80000, 0x00d80000,
-      0x00280000, 0x00400000, 0x00080000, 0x00680000,
-      0x00500000, 0x00180000, 0x00200000, 0x00100000,
-      0x00700000, 0x00780000, 0x00600000, 0x00380000,
-      0x00300000, 0x00000000, 0x00480000, 0x00580000,
-      0x04280000, 0x04400000, 0x04080000, 0x04680000,
-      0x04500000, 0x04180000, 0x04200000, 0x04100000,
-      0x04700000, 0x04780000, 0x04600000, 0x04380000,
-      0x04300000, 0x04000000, 0x04480000, 0x04580000,
-      0x04a80000, 0x04c00000, 0x04880000, 0x04e80000,
-      0x04d00000, 0x04980000, 0x04a00000, 0x04900000,
-      0x04f00000, 0x04f80000, 0x04e00000, 0x04b80000,
-      0x04b00000, 0x04800000, 0x04c80000, 0x04d80000,
-      0x07a80000, 0x07c00000, 0x07880000, 0x07e80000,
-      0x07d00000, 0x07980000, 0x07a00000, 0x07900000,
-      0x07f00000, 0x07f80000, 0x07e00000, 0x07b80000,
-      0x07b00000, 0x07800000, 0x07c80000, 0x07d80000,
-      0x07280000, 0x07400000, 0x07080000, 0x07680000,
-      0x07500000, 0x07180000, 0x07200000, 0x07100000,
-      0x07700000, 0x07780000, 0x07600000, 0x07380000,
-      0x07300000, 0x07000000, 0x07480000, 0x07580000,
-      0x02280000, 0x02400000, 0x02080000, 0x02680000,
-      0x02500000, 0x02180000, 0x02200000, 0x02100000,
-      0x02700000, 0x02780000, 0x02600000, 0x02380000,
-      0x02300000, 0x02000000, 0x02480000, 0x02580000,
-      0x03280000, 0x03400000, 0x03080000, 0x03680000,
-      0x03500000, 0x03180000, 0x03200000, 0x03100000,
-      0x03700000, 0x03780000, 0x03600000, 0x03380000,
-      0x03300000, 0x03000000, 0x03480000, 0x03580000,
-      0x06280000, 0x06400000, 0x06080000, 0x06680000,
-      0x06500000, 0x06180000, 0x06200000, 0x06100000,
-      0x06700000, 0x06780000, 0x06600000, 0x06380000,
-      0x06300000, 0x06000000, 0x06480000, 0x06580000,
-      0x05a80000, 0x05c00000, 0x05880000, 0x05e80000,
-      0x05d00000, 0x05980000, 0x05a00000, 0x05900000,
-      0x05f00000, 0x05f80000, 0x05e00000, 0x05b80000,
-      0x05b00000, 0x05800000, 0x05c80000, 0x05d80000,
-      0x01280000, 0x01400000, 0x01080000, 0x01680000,
-      0x01500000, 0x01180000, 0x01200000, 0x01100000,
-      0x01700000, 0x01780000, 0x01600000, 0x01380000,
-      0x01300000, 0x01000000, 0x01480000, 0x01580000,
-      0x02a80000, 0x02c00000, 0x02880000, 0x02e80000,
-      0x02d00000, 0x02980000, 0x02a00000, 0x02900000,
-      0x02f00000, 0x02f80000, 0x02e00000, 0x02b80000,
-      0x02b00000, 0x02800000, 0x02c80000, 0x02d80000,
-      0x01a80000, 0x01c00000, 0x01880000, 0x01e80000,
-      0x01d00000, 0x01980000, 0x01a00000, 0x01900000,
-      0x01f00000, 0x01f80000, 0x01e00000, 0x01b80000,
-      0x01b00000, 0x01800000, 0x01c80000, 0x01d80000,
-    }, { /* 2 */
-      0x30000002, 0x60000002, 0x38000002, 0x08000002,
-      0x28000002, 0x78000002, 0x68000002, 0x40000002,
-      0x20000002, 0x50000002, 0x48000002, 0x70000002,
-      0x00000002, 0x18000002, 0x58000002, 0x10000002,
-      0xb0000005, 0xe0000005, 0xb8000005, 0x88000005,
-      0xa8000005, 0xf8000005, 0xe8000005, 0xc0000005,
-      0xa0000005, 0xd0000005, 0xc8000005, 0xf0000005,
-      0x80000005, 0x98000005, 0xd8000005, 0x90000005,
-      0x30000005, 0x60000005, 0x38000005, 0x08000005,
-      0x28000005, 0x78000005, 0x68000005, 0x40000005,
-      0x20000005, 0x50000005, 0x48000005, 0x70000005,
-      0x00000005, 0x18000005, 0x58000005, 0x10000005,
-      0x30000000, 0x60000000, 0x38000000, 0x08000000,
-      0x28000000, 0x78000000, 0x68000000, 0x40000000,
-      0x20000000, 0x50000000, 0x48000000, 0x70000000,
-      0x00000000, 0x18000000, 0x58000000, 0x10000000,
-      0xb0000003, 0xe0000003, 0xb8000003, 0x88000003,
-      0xa8000003, 0xf8000003, 0xe8000003, 0xc0000003,
-      0xa0000003, 0xd0000003, 0xc8000003, 0xf0000003,
-      0x80000003, 0x98000003, 0xd8000003, 0x90000003,
-      0x30000001, 0x60000001, 0x38000001, 0x08000001,
-      0x28000001, 0x78000001, 0x68000001, 0x40000001,
-      0x20000001, 0x50000001, 0x48000001, 0x70000001,
-      0x00000001, 0x18000001, 0x58000001, 0x10000001,
-      0xb0000000, 0xe0000000, 0xb8000000, 0x88000000,
-      0xa8000000, 0xf8000000, 0xe8000000, 0xc0000000,
-      0xa0000000, 0xd0000000, 0xc8000000, 0xf0000000,
-      0x80000000, 0x98000000, 0xd8000000, 0x90000000,
-      0xb0000006, 0xe0000006, 0xb8000006, 0x88000006,
-      0xa8000006, 0xf8000006, 0xe8000006, 0xc0000006,
-      0xa0000006, 0xd0000006, 0xc8000006, 0xf0000006,
-      0x80000006, 0x98000006, 0xd8000006, 0x90000006,
-      0xb0000001, 0xe0000001, 0xb8000001, 0x88000001,
-      0xa8000001, 0xf8000001, 0xe8000001, 0xc0000001,
-      0xa0000001, 0xd0000001, 0xc8000001, 0xf0000001,
-      0x80000001, 0x98000001, 0xd8000001, 0x90000001,
-      0x30000003, 0x60000003, 0x38000003, 0x08000003,
-      0x28000003, 0x78000003, 0x68000003, 0x40000003,
-      0x20000003, 0x50000003, 0x48000003, 0x70000003,
-      0x00000003, 0x18000003, 0x58000003, 0x10000003,
-      0x30000004, 0x60000004, 0x38000004, 0x08000004,
-      0x28000004, 0x78000004, 0x68000004, 0x40000004,
-      0x20000004, 0x50000004, 0x48000004, 0x70000004,
-      0x00000004, 0x18000004, 0x58000004, 0x10000004,
-      0xb0000002, 0xe0000002, 0xb8000002, 0x88000002,
-      0xa8000002, 0xf8000002, 0xe8000002, 0xc0000002,
-      0xa0000002, 0xd0000002, 0xc8000002, 0xf0000002,
-      0x80000002, 0x98000002, 0xd8000002, 0x90000002,
-      0xb0000004, 0xe0000004, 0xb8000004, 0x88000004,
-      0xa8000004, 0xf8000004, 0xe8000004, 0xc0000004,
-      0xa0000004, 0xd0000004, 0xc8000004, 0xf0000004,
-      0x80000004, 0x98000004, 0xd8000004, 0x90000004,
-      0x30000006, 0x60000006, 0x38000006, 0x08000006,
-      0x28000006, 0x78000006, 0x68000006, 0x40000006,
-      0x20000006, 0x50000006, 0x48000006, 0x70000006,
-      0x00000006, 0x18000006, 0x58000006, 0x10000006,
-      0xb0000007, 0xe0000007, 0xb8000007, 0x88000007,
-      0xa8000007, 0xf8000007, 0xe8000007, 0xc0000007,
-      0xa0000007, 0xd0000007, 0xc8000007, 0xf0000007,
-      0x80000007, 0x98000007, 0xd8000007, 0x90000007,
-      0x30000007, 0x60000007, 0x38000007, 0x08000007,
-      0x28000007, 0x78000007, 0x68000007, 0x40000007,
-      0x20000007, 0x50000007, 0x48000007, 0x70000007,
-      0x00000007, 0x18000007, 0x58000007, 0x10000007,
-    }, { /* 3 */
-      0x000000e8, 0x000000d8, 0x000000a0, 0x00000088,
-      0x00000098, 0x000000f8, 0x000000a8, 0x000000c8,
-      0x00000080, 0x000000d0, 0x000000f0, 0x000000b8,
-      0x000000b0, 0x000000c0, 0x00000090, 0x000000e0,
-      0x000007e8, 0x000007d8, 0x000007a0, 0x00000788,
-      0x00000798, 0x000007f8, 0x000007a8, 0x000007c8,
-      0x00000780, 0x000007d0, 0x000007f0, 0x000007b8,
-      0x000007b0, 0x000007c0, 0x00000790, 0x000007e0,
-      0x000006e8, 0x000006d8, 0x000006a0, 0x00000688,
-      0x00000698, 0x000006f8, 0x000006a8, 0x000006c8,
-      0x00000680, 0x000006d0, 0x000006f0, 0x000006b8,
-      0x000006b0, 0x000006c0, 0x00000690, 0x000006e0,
-      0x00000068, 0x00000058, 0x00000020, 0x00000008,
-      0x00000018, 0x00000078, 0x00000028, 0x00000048,
-      0x00000000, 0x00000050, 0x00000070, 0x00000038,
-      0x00000030, 0x00000040, 0x00000010, 0x00000060,
-      0x000002e8, 0x000002d8, 0x000002a0, 0x00000288,
-      0x00000298, 0x000002f8, 0x000002a8, 0x000002c8,
-      0x00000280, 0x000002d0, 0x000002f0, 0x000002b8,
-      0x000002b0, 0x000002c0, 0x00000290, 0x000002e0,
-      0x000003e8, 0x000003d8, 0x000003a0, 0x00000388,
-      0x00000398, 0x000003f8, 0x000003a8, 0x000003c8,
-      0x00000380, 0x000003d0, 0x000003f0, 0x000003b8,
-      0x000003b0, 0x000003c0, 0x00000390, 0x000003e0,
-      0x00000568, 0x00000558, 0x00000520, 0x00000508,
-      0x00000518, 0x00000578, 0x00000528, 0x00000548,
-      0x00000500, 0x00000550, 0x00000570, 0x00000538,
-      0x00000530, 0x00000540, 0x00000510, 0x00000560,
-      0x00000268, 0x00000258, 0x00000220, 0x00000208,
-      0x00000218, 0x00000278, 0x00000228, 0x00000248,
-      0x00000200, 0x00000250, 0x00000270, 0x00000238,
-      0x00000230, 0x00000240, 0x00000210, 0x00000260,
-      0x000004e8, 0x000004d8, 0x000004a0, 0x00000488,
-      0x00000498, 0x000004f8, 0x000004a8, 0x000004c8,
-      0x00000480, 0x000004d0, 0x000004f0, 0x000004b8,
-      0x000004b0, 0x000004c0, 0x00000490, 0x000004e0,
-      0x00000168, 0x00000158, 0x00000120, 0x00000108,
-      0x00000118, 0x00000178, 0x00000128, 0x00000148,
-      0x00000100, 0x00000150, 0x00000170, 0x00000138,
-      0x00000130, 0x00000140, 0x00000110, 0x00000160,
-      0x000001e8, 0x000001d8, 0x000001a0, 0x00000188,
-      0x00000198, 0x000001f8, 0x000001a8, 0x000001c8,
-      0x00000180, 0x000001d0, 0x000001f0, 0x000001b8,
-      0x000001b0, 0x000001c0, 0x00000190, 0x000001e0,
-      0x00000768, 0x00000758, 0x00000720, 0x00000708,
-      0x00000718, 0x00000778, 0x00000728, 0x00000748,
-      0x00000700, 0x00000750, 0x00000770, 0x00000738,
-      0x00000730, 0x00000740, 0x00000710, 0x00000760,
-      0x00000368, 0x00000358, 0x00000320, 0x00000308,
-      0x00000318, 0x00000378, 0x00000328, 0x00000348,
-      0x00000300, 0x00000350, 0x00000370, 0x00000338,
-      0x00000330, 0x00000340, 0x00000310, 0x00000360,
-      0x000005e8, 0x000005d8, 0x000005a0, 0x00000588,
-      0x00000598, 0x000005f8, 0x000005a8, 0x000005c8,
-      0x00000580, 0x000005d0, 0x000005f0, 0x000005b8,
-      0x000005b0, 0x000005c0, 0x00000590, 0x000005e0,
-      0x00000468, 0x00000458, 0x00000420, 0x00000408,
-      0x00000418, 0x00000478, 0x00000428, 0x00000448,
-      0x00000400, 0x00000450, 0x00000470, 0x00000438,
-      0x00000430, 0x00000440, 0x00000410, 0x00000460,
-      0x00000668, 0x00000658, 0x00000620, 0x00000608,
-      0x00000618, 0x00000678, 0x00000628, 0x00000648,
-      0x00000600, 0x00000650, 0x00000670, 0x00000638,
-      0x00000630, 0x00000640, 0x00000610, 0x00000660,
-    }
-  }
-};
-
-const struct gost28147_param _gost28147_param_CryptoPro_3411 =
-{
-  {
-    { /* 0 */
-      0x0002d000, 0x0002a000, 0x0002a800, 0x0002b000,
-      0x0002c000, 0x00028800, 0x00029800, 0x0002b800,
-      0x0002e800, 0x0002e000, 0x0002f000, 0x00028000,
-      0x0002c800, 0x00029000, 0x0002d800, 0x0002f800,
-      0x0007d000, 0x0007a000, 0x0007a800, 0x0007b000,
-      0x0007c000, 0x00078800, 0x00079800, 0x0007b800,
-      0x0007e800, 0x0007e000, 0x0007f000, 0x00078000,
-      0x0007c800, 0x00079000, 0x0007d800, 0x0007f800,
-      0x00025000, 0x00022000, 0x00022800, 0x00023000,
-      0x00024000, 0x00020800, 0x00021800, 0x00023800,
-      0x00026800, 0x00026000, 0x00027000, 0x00020000,
-      0x00024800, 0x00021000, 0x00025800, 0x00027800,
-      0x00005000, 0x00002000, 0x00002800, 0x00003000,
-      0x00004000, 0x00000800, 0x00001800, 0x00003800,
-      0x00006800, 0x00006000, 0x00007000, 0x00000000,
-      0x00004800, 0x00001000, 0x00005800, 0x00007800,
-      0x00015000, 0x00012000, 0x00012800, 0x00013000,
-      0x00014000, 0x00010800, 0x00011800, 0x00013800,
-      0x00016800, 0x00016000, 0x00017000, 0x00010000,
-      0x00014800, 0x00011000, 0x00015800, 0x00017800,
-      0x0006d000, 0x0006a000, 0x0006a800, 0x0006b000,
-      0x0006c000, 0x00068800, 0x00069800, 0x0006b800,
-      0x0006e800, 0x0006e000, 0x0006f000, 0x00068000,
-      0x0006c800, 0x00069000, 0x0006d800, 0x0006f800,
-      0x0005d000, 0x0005a000, 0x0005a800, 0x0005b000,
-      0x0005c000, 0x00058800, 0x00059800, 0x0005b800,
-      0x0005e800, 0x0005e000, 0x0005f000, 0x00058000,
-      0x0005c800, 0x00059000, 0x0005d800, 0x0005f800,
-      0x0004d000, 0x0004a000, 0x0004a800, 0x0004b000,
-      0x0004c000, 0x00048800, 0x00049800, 0x0004b800,
-      0x0004e800, 0x0004e000, 0x0004f000, 0x00048000,
-      0x0004c800, 0x00049000, 0x0004d800, 0x0004f800,
-      0x0000d000, 0x0000a000, 0x0000a800, 0x0000b000,
-      0x0000c000, 0x00008800, 0x00009800, 0x0000b800,
-      0x0000e800, 0x0000e000, 0x0000f000, 0x00008000,
-      0x0000c800, 0x00009000, 0x0000d800, 0x0000f800,
-      0x0003d000, 0x0003a000, 0x0003a800, 0x0003b000,
-      0x0003c000, 0x00038800, 0x00039800, 0x0003b800,
-      0x0003e800, 0x0003e000, 0x0003f000, 0x00038000,
-      0x0003c800, 0x00039000, 0x0003d800, 0x0003f800,
-      0x00035000, 0x00032000, 0x00032800, 0x00033000,
-      0x00034000, 0x00030800, 0x00031800, 0x00033800,
-      0x00036800, 0x00036000, 0x00037000, 0x00030000,
-      0x00034800, 0x00031000, 0x00035800, 0x00037800,
-      0x0001d000, 0x0001a000, 0x0001a800, 0x0001b000,
-      0x0001c000, 0x00018800, 0x00019800, 0x0001b800,
-      0x0001e800, 0x0001e000, 0x0001f000, 0x00018000,
-      0x0001c800, 0x00019000, 0x0001d800, 0x0001f800,
-      0x00065000, 0x00062000, 0x00062800, 0x00063000,
-      0x00064000, 0x00060800, 0x00061800, 0x00063800,
-      0x00066800, 0x00066000, 0x00067000, 0x00060000,
-      0x00064800, 0x00061000, 0x00065800, 0x00067800,
-      0x00075000, 0x00072000, 0x00072800, 0x00073000,
-      0x00074000, 0x00070800, 0x00071800, 0x00073800,
-      0x00076800, 0x00076000, 0x00077000, 0x00070000,
-      0x00074800, 0x00071000, 0x00075800, 0x00077800,
-      0x00055000, 0x00052000, 0x00052800, 0x00053000,
-      0x00054000, 0x00050800, 0x00051800, 0x00053800,
-      0x00056800, 0x00056000, 0x00057000, 0x00050000,
-      0x00054800, 0x00051000, 0x00055800, 0x00057800,
-      0x00045000, 0x00042000, 0x00042800, 0x00043000,
-      0x00044000, 0x00040800, 0x00041800, 0x00043800,
-      0x00046800, 0x00046000, 0x00047000, 0x00040000,
-      0x00044800, 0x00041000, 0x00045800, 0x00047800,
-    }, { /* 1 */
-      0x02380000, 0x02780000, 0x02600000, 0x02700000,
-      0x02480000, 0x02200000, 0x02080000, 0x02000000,
-      0x02180000, 0x02580000, 0x02280000, 0x02100000,
-      0x02300000, 0x02500000, 0x02400000, 0x02680000,
-      0x05380000, 0x05780000, 0x05600000, 0x05700000,
-      0x05480000, 0x05200000, 0x05080000, 0x05000000,
-      0x05180000, 0x05580000, 0x05280000, 0x05100000,
-      0x05300000, 0x05500000, 0x05400000, 0x05680000,
-      0x03b80000, 0x03f80000, 0x03e00000, 0x03f00000,
-      0x03c80000, 0x03a00000, 0x03880000, 0x03800000,
-      0x03980000, 0x03d80000, 0x03a80000, 0x03900000,
-      0x03b00000, 0x03d00000, 0x03c00000, 0x03e80000,
-      0x06380000, 0x06780000, 0x06600000, 0x06700000,
-      0x06480000, 0x06200000, 0x06080000, 0x06000000,
-      0x06180000, 0x06580000, 0x06280000, 0x06100000,
-      0x06300000, 0x06500000, 0x06400000, 0x06680000,
-      0x00380000, 0x00780000, 0x00600000, 0x00700000,
-      0x00480000, 0x00200000, 0x00080000, 0x00000000,
-      0x00180000, 0x00580000, 0x00280000, 0x00100000,
-      0x00300000, 0x00500000, 0x00400000, 0x00680000,
-      0x07b80000, 0x07f80000, 0x07e00000, 0x07f00000,
-      0x07c80000, 0x07a00000, 0x07880000, 0x07800000,
-      0x07980000, 0x07d80000, 0x07a80000, 0x07900000,
-      0x07b00000, 0x07d00000, 0x07c00000, 0x07e80000,
-      0x01380000, 0x01780000, 0x01600000, 0x01700000,
-      0x01480000, 0x01200000, 0x01080000, 0x01000000,
-      0x01180000, 0x01580000, 0x01280000, 0x01100000,
-      0x01300000, 0x01500000, 0x01400000, 0x01680000,
-      0x04380000, 0x04780000, 0x04600000, 0x04700000,
-      0x04480000, 0x04200000, 0x04080000, 0x04000000,
-      0x04180000, 0x04580000, 0x04280000, 0x04100000,
-      0x04300000, 0x04500000, 0x04400000, 0x04680000,
-      0x07380000, 0x07780000, 0x07600000, 0x07700000,
-      0x07480000, 0x07200000, 0x07080000, 0x07000000,
-      0x07180000, 0x07580000, 0x07280000, 0x07100000,
-      0x07300000, 0x07500000, 0x07400000, 0x07680000,
-      0x00b80000, 0x00f80000, 0x00e00000, 0x00f00000,
-      0x00c80000, 0x00a00000, 0x00880000, 0x00800000,
-      0x00980000, 0x00d80000, 0x00a80000, 0x00900000,
-      0x00b00000, 0x00d00000, 0x00c00000, 0x00e80000,
-      0x03380000, 0x03780000, 0x03600000, 0x03700000,
-      0x03480000, 0x03200000, 0x03080000, 0x03000000,
-      0x03180000, 0x03580000, 0x03280000, 0x03100000,
-      0x03300000, 0x03500000, 0x03400000, 0x03680000,
-      0x02b80000, 0x02f80000, 0x02e00000, 0x02f00000,
-      0x02c80000, 0x02a00000, 0x02880000, 0x02800000,
-      0x02980000, 0x02d80000, 0x02a80000, 0x02900000,
-      0x02b00000, 0x02d00000, 0x02c00000, 0x02e80000,
-      0x06b80000, 0x06f80000, 0x06e00000, 0x06f00000,
-      0x06c80000, 0x06a00000, 0x06880000, 0x06800000,
-      0x06980000, 0x06d80000, 0x06a80000, 0x06900000,
-      0x06b00000, 0x06d00000, 0x06c00000, 0x06e80000,
-      0x05b80000, 0x05f80000, 0x05e00000, 0x05f00000,
-      0x05c80000, 0x05a00000, 0x05880000, 0x05800000,
-      0x05980000, 0x05d80000, 0x05a80000, 0x05900000,
-      0x05b00000, 0x05d00000, 0x05c00000, 0x05e80000,
-      0x04b80000, 0x04f80000, 0x04e00000, 0x04f00000,
-      0x04c80000, 0x04a00000, 0x04880000, 0x04800000,
-      0x04980000, 0x04d80000, 0x04a80000, 0x04900000,
-      0x04b00000, 0x04d00000, 0x04c00000, 0x04e80000,
-      0x01b80000, 0x01f80000, 0x01e00000, 0x01f00000,
-      0x01c80000, 0x01a00000, 0x01880000, 0x01800000,
-      0x01980000, 0x01d80000, 0x01a80000, 0x01900000,
-      0x01b00000, 0x01d00000, 0x01c00000, 0x01e80000,
-    }, { /* 2 */
-      0xb8000003, 0xb0000003, 0xa0000003, 0xd8000003,
-      0xc8000003, 0xe0000003, 0x90000003, 0xd0000003,
-      0x88000003, 0xc0000003, 0x80000003, 0xf0000003,
-      0xf8000003, 0xe8000003, 0x98000003, 0xa8000003,
-      0x38000003, 0x30000003, 0x20000003, 0x58000003,
-      0x48000003, 0x60000003, 0x10000003, 0x50000003,
-      0x08000003, 0x40000003, 0x00000003, 0x70000003,
-      0x78000003, 0x68000003, 0x18000003, 0x28000003,
-      0x38000001, 0x30000001, 0x20000001, 0x58000001,
-      0x48000001, 0x60000001, 0x10000001, 0x50000001,
-      0x08000001, 0x40000001, 0x00000001, 0x70000001,
-      0x78000001, 0x68000001, 0x18000001, 0x28000001,
-      0x38000002, 0x30000002, 0x20000002, 0x58000002,
-      0x48000002, 0x60000002, 0x10000002, 0x50000002,
-      0x08000002, 0x40000002, 0x00000002, 0x70000002,
-      0x78000002, 0x68000002, 0x18000002, 0x28000002,
-      0xb8000006, 0xb0000006, 0xa0000006, 0xd8000006,
-      0xc8000006, 0xe0000006, 0x90000006, 0xd0000006,
-      0x88000006, 0xc0000006, 0x80000006, 0xf0000006,
-      0xf8000006, 0xe8000006, 0x98000006, 0xa8000006,
-      0xb8000004, 0xb0000004, 0xa0000004, 0xd8000004,
-      0xc8000004, 0xe0000004, 0x90000004, 0xd0000004,
-      0x88000004, 0xc0000004, 0x80000004, 0xf0000004,
-      0xf8000004, 0xe8000004, 0x98000004, 0xa8000004,
-      0xb8000007, 0xb0000007, 0xa0000007, 0xd8000007,
-      0xc8000007, 0xe0000007, 0x90000007, 0xd0000007,
-      0x88000007, 0xc0000007, 0x80000007, 0xf0000007,
-      0xf8000007, 0xe8000007, 0x98000007, 0xa8000007,
-      0x38000000, 0x30000000, 0x20000000, 0x58000000,
-      0x48000000, 0x60000000, 0x10000000, 0x50000000,
-      0x08000000, 0x40000000, 0x00000000, 0x70000000,
-      0x78000000, 0x68000000, 0x18000000, 0x28000000,
-      0x38000005, 0x30000005, 0x20000005, 0x58000005,
-      0x48000005, 0x60000005, 0x10000005, 0x50000005,
-      0x08000005, 0x40000005, 0x00000005, 0x70000005,
-      0x78000005, 0x68000005, 0x18000005, 0x28000005,
-      0xb8000000, 0xb0000000, 0xa0000000, 0xd8000000,
-      0xc8000000, 0xe0000000, 0x90000000, 0xd0000000,
-      0x88000000, 0xc0000000, 0x80000000, 0xf0000000,
-      0xf8000000, 0xe8000000, 0x98000000, 0xa8000000,
-      0xb8000002, 0xb0000002, 0xa0000002, 0xd8000002,
-      0xc8000002, 0xe0000002, 0x90000002, 0xd0000002,
-      0x88000002, 0xc0000002, 0x80000002, 0xf0000002,
-      0xf8000002, 0xe8000002, 0x98000002, 0xa8000002,
-      0xb8000005, 0xb0000005, 0xa0000005, 0xd8000005,
-      0xc8000005, 0xe0000005, 0x90000005, 0xd0000005,
-      0x88000005, 0xc0000005, 0x80000005, 0xf0000005,
-      0xf8000005, 0xe8000005, 0x98000005, 0xa8000005,
-      0x38000004, 0x30000004, 0x20000004, 0x58000004,
-      0x48000004, 0x60000004, 0x10000004, 0x50000004,
-      0x08000004, 0x40000004, 0x00000004, 0x70000004,
-      0x78000004, 0x68000004, 0x18000004, 0x28000004,
-      0x38000007, 0x30000007, 0x20000007, 0x58000007,
-      0x48000007, 0x60000007, 0x10000007, 0x50000007,
-      0x08000007, 0x40000007, 0x00000007, 0x70000007,
-      0x78000007, 0x68000007, 0x18000007, 0x28000007,
-      0x38000006, 0x30000006, 0x20000006, 0x58000006,
-      0x48000006, 0x60000006, 0x10000006, 0x50000006,
-      0x08000006, 0x40000006, 0x00000006, 0x70000006,
-      0x78000006, 0x68000006, 0x18000006, 0x28000006,
-      0xb8000001, 0xb0000001, 0xa0000001, 0xd8000001,
-      0xc8000001, 0xe0000001, 0x90000001, 0xd0000001,
-      0x88000001, 0xc0000001, 0x80000001, 0xf0000001,
-      0xf8000001, 0xe8000001, 0x98000001, 0xa8000001,
-    }, { /* 3 */
-      0x000000e8, 0x000000f0, 0x000000a0, 0x00000088,
-      0x000000b8, 0x00000080, 0x000000a8, 0x000000d0,
-      0x00000098, 0x000000e0, 0x000000c0, 0x000000f8,
-      0x000000b0, 0x00000090, 0x000000c8, 0x000000d8,
-      0x000001e8, 0x000001f0, 0x000001a0, 0x00000188,
-      0x000001b8, 0x00000180, 0x000001a8, 0x000001d0,
-      0x00000198, 0x000001e0, 0x000001c0, 0x000001f8,
-      0x000001b0, 0x00000190, 0x000001c8, 0x000001d8,
-      0x00000568, 0x00000570, 0x00000520, 0x00000508,
-      0x00000538, 0x00000500, 0x00000528, 0x00000550,
-      0x00000518, 0x00000560, 0x00000540, 0x00000578,
-      0x00000530, 0x00000510, 0x00000548, 0x00000558,
-      0x000004e8, 0x000004f0, 0x000004a0, 0x00000488,
-      0x000004b8, 0x00000480, 0x000004a8, 0x000004d0,
-      0x00000498, 0x000004e0, 0x000004c0, 0x000004f8,
-      0x000004b0, 0x00000490, 0x000004c8, 0x000004d8,
-      0x000002e8, 0x000002f0, 0x000002a0, 0x00000288,
-      0x000002b8, 0x00000280, 0x000002a8, 0x000002d0,
-      0x00000298, 0x000002e0, 0x000002c0, 0x000002f8,
-      0x000002b0, 0x00000290, 0x000002c8, 0x000002d8,
-      0x000005e8, 0x000005f0, 0x000005a0, 0x00000588,
-      0x000005b8, 0x00000580, 0x000005a8, 0x000005d0,
-      0x00000598, 0x000005e0, 0x000005c0, 0x000005f8,
-      0x000005b0, 0x00000590, 0x000005c8, 0x000005d8,
-      0x00000268, 0x00000270, 0x00000220, 0x00000208,
-      0x00000238, 0x00000200, 0x00000228, 0x00000250,
-      0x00000218, 0x00000260, 0x00000240, 0x00000278,
-      0x00000230, 0x00000210, 0x00000248, 0x00000258,
-      0x000007e8, 0x000007f0, 0x000007a0, 0x00000788,
-      0x000007b8, 0x00000780, 0x000007a8, 0x000007d0,
-      0x00000798, 0x000007e0, 0x000007c0, 0x000007f8,
-      0x000007b0, 0x00000790, 0x000007c8, 0x000007d8,
-      0x00000468, 0x00000470, 0x00000420, 0x00000408,
-      0x00000438, 0x00000400, 0x00000428, 0x00000450,
-      0x00000418, 0x00000460, 0x00000440, 0x00000478,
-      0x00000430, 0x00000410, 0x00000448, 0x00000458,
-      0x00000368, 0x00000370, 0x00000320, 0x00000308,
-      0x00000338, 0x00000300, 0x00000328, 0x00000350,
-      0x00000318, 0x00000360, 0x00000340, 0x00000378,
-      0x00000330, 0x00000310, 0x00000348, 0x00000358,
-      0x000003e8, 0x000003f0, 0x000003a0, 0x00000388,
-      0x000003b8, 0x00000380, 0x000003a8, 0x000003d0,
-      0x00000398, 0x000003e0, 0x000003c0, 0x000003f8,
-      0x000003b0, 0x00000390, 0x000003c8, 0x000003d8,
-      0x00000768, 0x00000770, 0x00000720, 0x00000708,
-      0x00000738, 0x00000700, 0x00000728, 0x00000750,
-      0x00000718, 0x00000760, 0x00000740, 0x00000778,
-      0x00000730, 0x00000710, 0x00000748, 0x00000758,
-      0x000006e8, 0x000006f0, 0x000006a0, 0x00000688,
-      0x000006b8, 0x00000680, 0x000006a8, 0x000006d0,
-      0x00000698, 0x000006e0, 0x000006c0, 0x000006f8,
-      0x000006b0, 0x00000690, 0x000006c8, 0x000006d8,
-      0x00000068, 0x00000070, 0x00000020, 0x00000008,
-      0x00000038, 0x00000000, 0x00000028, 0x00000050,
-      0x00000018, 0x00000060, 0x00000040, 0x00000078,
-      0x00000030, 0x00000010, 0x00000048, 0x00000058,
-      0x00000168, 0x00000170, 0x00000120, 0x00000108,
-      0x00000138, 0x00000100, 0x00000128, 0x00000150,
-      0x00000118, 0x00000160, 0x00000140, 0x00000178,
-      0x00000130, 0x00000110, 0x00000148, 0x00000158,
-      0x00000668, 0x00000670, 0x00000620, 0x00000608,
-      0x00000638, 0x00000600, 0x00000628, 0x00000650,
-      0x00000618, 0x00000660, 0x00000640, 0x00000678,
-      0x00000630, 0x00000610, 0x00000648, 0x00000658,
-    }
-  }
-};
-
 /*
  *  A macro that performs a full encryption round of GOST 28147-89.
  */
-- 
2.27.0

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200614212357</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-06-14 21:23:57-0400</timestampReceived><subject>[PATCH v2 2/2] Add GOST 28147-89 ECB encryption and decryption support</subject><body>

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 Makefile.in                |  2 +-
 gost28147-params.c         | 11 +++++
 gost28147.c                | 86 ++++++++++++++++++++++++++++++++++++++
 gost28147.h                | 85 +++++++++++++++++++++++++++++++++++++
 testsuite/Makefile.in      |  2 +-
 testsuite/gost28147-test.c | 77 ++++++++++++++++++++++++++++++++++
 6 files changed, 261 insertions(+), 2 deletions(-)
 create mode 100644 gost28147.h
 create mode 100644 testsuite/gost28147-test.c

diff --git a/Makefile.in b/Makefile.in
index 41e0389f2979..d4bec88615ed 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -211,7 +211,7 @@ HEADERS = aes.h arcfour.h arctwo.h asn1.h blowfish.h \
 	  cbc.h ccm.h cfb.h chacha.h chacha-poly1305.h ctr.h \
 	  curve25519.h curve448.h des.h dsa.h dsa-compat.h eax.h \
 	  ecc-curve.h ecc.h ecdsa.h eddsa.h \
-	  gcm.h gostdsa.h gosthash94.h hmac.h \
+	  gcm.h gost28147.h gostdsa.h gosthash94.h hmac.h \
 	  knuth-lfib.h hkdf.h \
 	  macros.h \
 	  cmac.h siv-cmac.h \
diff --git a/gost28147-params.c b/gost28147-params.c
index 6addec31f170..7489641ba5a1 100644
--- a/gost28147-params.c
+++ b/gost28147-params.c
@@ -33,6 +33,7 @@
 #endif
 
 #include "macros.h"
+#include "gost28147.h"
 #include "gost28147-internal.h"
 
 /* pre-initialized GOST lookup tables based on rotated S-Box */
@@ -569,3 +570,13 @@ const struct gost28147_param _gost28147_param_CryptoPro_3411 =
     }
   }
 };
+
+const struct gost28147_param * gost28147_get_param_test_3411 (void)
+{
+  return &amp;_gost28147_param_test_3411;
+}
+
+const struct gost28147_param * gost28147_get_param_CryptoPro_3411 (void)
+{
+  return &amp;_gost28147_param_CryptoPro_3411;
+}
diff --git a/gost28147.c b/gost28147.c
index 669fc85d2083..9525b41b148b 100644
--- a/gost28147.c
+++ b/gost28147.c
@@ -32,7 +32,10 @@
 #include "config.h"
 #endif
 
+#include &lt;assert.h&gt;
+
 #include "macros.h"
+#include "gost28147.h"
 #include "gost28147-internal.h"
 
 /*
@@ -79,3 +82,86 @@ void _gost28147_encrypt_block (const uint32_t *key, const uint32_t sbox[4][256],
   GOST_ENCRYPT_ROUND(l, r, key[1], key[0], sbox);
   *out = l, *(out + 1) = r;
 }
+
+static
+void _gost28147_decrypt_block (const uint32_t *key, const uint32_t sbox[4][256],
+			       const uint32_t *in, uint32_t *out)
+{
+  uint32_t l, r;
+
+  r = in[0], l = in[1];
+  GOST_ENCRYPT_ROUND(l, r, key[0], key[1], sbox);
+  GOST_ENCRYPT_ROUND(l, r, key[2], key[3], sbox);
+  GOST_ENCRYPT_ROUND(l, r, key[4], key[5], sbox);
+  GOST_ENCRYPT_ROUND(l, r, key[6], key[7], sbox);
+  GOST_ENCRYPT_ROUND(l, r, key[7], key[6], sbox);
+  GOST_ENCRYPT_ROUND(l, r, key[5], key[4], sbox);
+  GOST_ENCRYPT_ROUND(l, r, key[3], key[2], sbox);
+  GOST_ENCRYPT_ROUND(l, r, key[1], key[0], sbox);
+  GOST_ENCRYPT_ROUND(l, r, key[7], key[6], sbox);
+  GOST_ENCRYPT_ROUND(l, r, key[5], key[4], sbox);
+  GOST_ENCRYPT_ROUND(l, r, key[3], key[2], sbox);
+  GOST_ENCRYPT_ROUND(l, r, key[1], key[0], sbox);
+  GOST_ENCRYPT_ROUND(l, r, key[7], key[6], sbox);
+  GOST_ENCRYPT_ROUND(l, r, key[5], key[4], sbox);
+  GOST_ENCRYPT_ROUND(l, r, key[3], key[2], sbox);
+  GOST_ENCRYPT_ROUND(l, r, key[1], key[0], sbox);
+  *out = l, *(out + 1) = r;
+}
+
+void
+gost28147_set_key(struct gost28147_ctx *ctx, const uint8_t *key)
+{
+  unsigned i;
+
+  assert(key);
+  for (i = 0; i &lt; 8; i++, key += 4)
+    ctx-&gt;key[i] = LE_READ_UINT32(key);
+}
+
+void
+gost28147_set_param(struct gost28147_ctx *ctx, const struct gost28147_param *param)
+{
+  assert(param);
+  ctx-&gt;sbox = param-&gt;sbox;
+}
+
+void
+gost28147_encrypt(const struct gost28147_ctx *ctx,
+		  size_t length, uint8_t *dst,
+		  const uint8_t *src)
+{
+  uint32_t block[2];
+
+  assert(!(length % GOST28147_BLOCK_SIZE));
+
+  while (length)
+    {
+      block[0] = LE_READ_UINT32(src); src += 4;
+      block[1] = LE_READ_UINT32(src); src += 4;
+      _gost28147_encrypt_block(ctx-&gt;key, ctx-&gt;sbox, block, block);
+      LE_WRITE_UINT32(dst, block[0]); dst += 4;
+      LE_WRITE_UINT32(dst, block[1]); dst += 4;
+      length -= GOST28147_BLOCK_SIZE;
+    }
+}
+
+void
+gost28147_decrypt(const struct gost28147_ctx *ctx,
+		  size_t length, uint8_t *dst,
+		  const uint8_t *src)
+{
+  uint32_t block[2];
+
+  assert(!(length % GOST28147_BLOCK_SIZE));
+
+  while (length)
+    {
+      block[0] = LE_READ_UINT32(src); src += 4;
+      block[1] = LE_READ_UINT32(src); src += 4;
+      _gost28147_decrypt_block(ctx-&gt;key, ctx-&gt;sbox, block, block);
+      LE_WRITE_UINT32(dst, block[0]); dst += 4;
+      LE_WRITE_UINT32(dst, block[1]); dst += 4;
+      length -= GOST28147_BLOCK_SIZE;
+    }
+}
diff --git a/gost28147.h b/gost28147.h
new file mode 100644
index 000000000000..0df1662ce86d
--- /dev/null
+++ b/gost28147.h
@@ -0,0 +1,85 @@
+/* gost28147.h
+
+   The GOST 28147-89 cipher function, described in RFC 5831.
+
+   Copyright (C) 2020 Dmitry Baryshkov
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#ifndef NETTLE_GOST28147_H_INCLUDED
+#define NETTLE_GOST28147_H_INCLUDED
+
+#include "nettle-types.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#define gost28147_get_param_test_3411 nettle_gost28147_get_param_test_3411
+#define gost28147_get_param_CryptoPro_3411 nettle_gost28147_get_param_CryptoPro_3411
+
+#define gost28147_set_key nettle_gost28147_set_key
+#define gost28147_set_param nettle_gost28147_set_param
+#define gost28147_encrypt nettle_gost28147_encrypt
+#define gost28147_decrypt nettle_gost28147_decrypt
+
+#define GOST28147_KEY_SIZE 32
+#define GOST28147_BLOCK_SIZE 8
+
+struct gost28147_ctx
+{
+  uint32_t key[GOST28147_KEY_SIZE/4];
+  const uint32_t (*sbox)[256];
+};
+
+struct gost28147_param;
+
+const struct gost28147_param * gost28147_get_param_test_3411 (void);
+const struct gost28147_param * gost28147_get_param_CryptoPro_3411 (void);
+
+void
+gost28147_set_key(struct gost28147_ctx *ctx, const uint8_t *key);
+
+void
+gost28147_set_param(struct gost28147_ctx *ctx,
+		    const struct gost28147_param *param);
+
+void
+gost28147_encrypt(const struct gost28147_ctx *ctx,
+		  size_t length, uint8_t *dst,
+		  const uint8_t *src);
+void
+gost28147_decrypt(const struct gost28147_ctx *ctx,
+		  size_t length, uint8_t *dst,
+		  const uint8_t *src);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* NETTLE_GOST28147_H_INCLUDED */
diff --git a/testsuite/Makefile.in b/testsuite/Makefile.in
index 3f5e5f6b995c..07dd0ecf3e8d 100644
--- a/testsuite/Makefile.in
+++ b/testsuite/Makefile.in
@@ -17,7 +17,7 @@ TS_NETTLE_SOURCES = aes-test.c arcfour-test.c arctwo-test.c \
 		    cnd-memcpy-test.c \
 		    des-test.c des3-test.c \
 		    md2-test.c md4-test.c md5-test.c md5-compat-test.c \
-		    memeql-test.c memxor-test.c gosthash94-test.c \
+		    memeql-test.c memxor-test.c gost28147-test.c gosthash94-test.c \
 		    ripemd160-test.c hkdf-test.c \
 		    salsa20-test.c \
 		    sha1-test.c sha224-test.c sha256-test.c \
diff --git a/testsuite/gost28147-test.c b/testsuite/gost28147-test.c
new file mode 100644
index 000000000000..ee9615b15cf2
--- /dev/null
+++ b/testsuite/gost28147-test.c
@@ -0,0 +1,77 @@
+#include "testutils.h"
+#include "gost28147.h"
+#include "cfb.h"
+#include "macros.h"
+
+static void
+test_gost28147(const struct gost28147_param *param,
+	       const struct tstring *key,
+	       const struct tstring *cleartext,
+	       const struct tstring *ciphertext)
+{
+  struct gost28147_ctx ctx;
+  uint8_t *data = xalloc(cleartext-&gt;length);
+  size_t length;
+
+  ASSERT (cleartext-&gt;length == ciphertext-&gt;length);
+  length = cleartext-&gt;length;
+
+  gost28147_set_param(&amp;ctx, param);
+  gost28147_set_key(&amp;ctx, key-&gt;data);
+  gost28147_encrypt(&amp;ctx, length, data, cleartext-&gt;data);
+
+  if (!MEMEQ(length, data, ciphertext-&gt;data))
+    {
+      fprintf(stderr, "Encrypt failed:\nInput:");
+      tstring_print_hex(cleartext);
+      fprintf(stderr, "\nOutput: ");
+      print_hex(length, data);
+      fprintf(stderr, "\nExpected:");
+      tstring_print_hex(ciphertext);
+      fprintf(stderr, "\n");
+      FAIL();
+    }
+
+  gost28147_set_param(&amp;ctx, param);
+  gost28147_set_key(&amp;ctx, key-&gt;data);
+  gost28147_decrypt(&amp;ctx, length, data, data);
+
+  if (!MEMEQ(length, data, cleartext-&gt;data))
+    {
+      fprintf(stderr, "Decrypt failed:\nInput:");
+      tstring_print_hex(ciphertext);
+      fprintf(stderr, "\nOutput: ");
+      print_hex(length, data);
+      fprintf(stderr, "\nExpected:");
+      tstring_print_hex(cleartext);
+      fprintf(stderr, "\n");
+      FAIL();
+    }
+
+  free(data);
+}
+
+void test_main(void)
+{
+  /* Examples from GOST R 34.11-94 standard, see RFC 5831, Section 7.3.1.
+   * Exaples there are represented in different endianness */
+  test_gost28147(gost28147_get_param_test_3411(),
+      SHEX("546D2033 68656C32 69736520 73736E62 20616779 69677474 73656865 202C3D73"),
+      SHEX("00000000 00000000"),
+      SHEX("1B0BBC32 CEBCAB42"));
+
+  test_gost28147(gost28147_get_param_test_3411(),
+      SHEX("2033394D 6C320D09 65201A16 6E62001D 67794106 74740E13 6865160D 3D730C11"),
+      SHEX("00000000 00000000"),
+      SHEX("FDCF9B5D C8EB0352"));
+
+  test_gost28147(gost28147_get_param_test_3411(),
+      SHEX("39B213F5 F209A13F 1AE9BA3A FF1D0C62 41F9E1C7 F1130085 16F20D73 F311B180"),
+      SHEX("00000000 00000000"),
+      SHEX("280EFF00 9958348D"));
+
+  test_gost28147(gost28147_get_param_test_3411(),
+      SHEX("EC0A8BA1 5EC004A8 BAC50CAC 0C621DEE E1C7B8E7 007AE2EC F2731BFF 4E80E2A0 "),
+      SHEX("00000000 00000000"),
+      SHEX("2D562A0D 190486E7 "));
+}
-- 
2.27.0

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200619004336</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-06-19 00:43:36-0400</timestampReceived><subject>[PATCH] optimized AES and GHASH for PPC64LE</subject><body>

 Makefile.in                                   |   2 +-
 configure.ac                                  |   5 +
 gcm.c                                         |  19 +-
 powerpc64le/aes-decrypt-internal.asm (new +x) | 573 +++++++++++++++
 powerpc64le/aes-encrypt-internal.asm (new +x) | 534 ++++++++++++++
 powerpc64le/gcm-hash8.asm (new +x)            | 992
++++++++++++++++++++++++++
 powerpc64le/machine.m4 (new +x)               |   0
 testsuite/gcm-test.c                          |  23 +
 8 files changed, 2146 insertions(+), 2 deletions(-)
 create mode 100644 powerpc64le/aes-decrypt-internal.asm
 create mode 100644 powerpc64le/aes-encrypt-internal.asm
 create mode 100644 powerpc64le/gcm-hash8.asm
 create mode 100644 powerpc64le/machine.m4

diff --git a/Makefile.in b/Makefile.in
index 64ff1001..5bbc0f79 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -603,7 +603,7 @@ distdir: $(DISTFILES)
  done
  set -e; for d in sparc32 sparc64 x86 \
  x86_64 x86_64/aesni x86_64/sha_ni x86_64/fat \
- arm arm/neon arm/v6 arm/fat ; do \
+ arm arm/neon arm/v6 arm/fat powerpc64le ; do \
   mkdir "$(distdir)/$$d" ; \
   find "$(srcdir)/$$d" -maxdepth 1 '(' -name '*.asm' -o -name '*.m4' ')' \
     -exec cp '{}' "$(distdir)/$$d" ';' ; \
diff --git a/configure.ac b/configure.ac
index 90ea1ea8..1ea54ce8 100644
--- a/configure.ac
+++ b/configure.ac
@@ -435,6 +435,9 @@ if test "x$enable_assembler" = xyes ; then
  esac
       fi
       ;;
+    *powerpc64le*)
+  asm_path=powerpc64le
+      ;;
     *)
       enable_assembler=no
       ;;
@@ -572,7 +575,9 @@ AH_VERBATIM([HAVE_NATIVE],
 #undef HAVE_NATIVE_ecc_secp384r1_redc
 #undef HAVE_NATIVE_ecc_secp521r1_modp
 #undef HAVE_NATIVE_ecc_secp521r1_redc
+#undef HAVE_NATIVE_gcm_init_key8
 #undef HAVE_NATIVE_gcm_hash8
+#undef HAVE_NATIVE_gcm_fill
 #undef HAVE_NATIVE_salsa20_core
 #undef HAVE_NATIVE_sha1_compress
 #undef HAVE_NATIVE_sha256_compress
diff --git a/gcm.c b/gcm.c
index cf615daf..809c03bc 100644
--- a/gcm.c
+++ b/gcm.c
@@ -140,6 +140,12 @@ gcm_gf_mul (union nettle_block16 *x, const union
nettle_block16 *table)
   memcpy (x-&gt;b, Z.b, sizeof(Z));
 }
 # elif GCM_TABLE_BITS == 8
+#  if HAVE_NATIVE_gcm_init_key8
+
+#define gcm_init_key _nettle_gcm_init_key8
+void
+_nettle_gcm_init_key8 (union nettle_block16 *table);
+#  endif /* HAVE_NATIVE_gcm_init_key8 */
 #  if HAVE_NATIVE_gcm_hash8

 #define gcm_hash _nettle_gcm_hash8
@@ -225,6 +231,13 @@ gcm_gf_mul (union nettle_block16 *x, const union
nettle_block16 *table)

 #endif /* GCM_TABLE_BITS */

+#if HAVE_NATIVE_gcm_fill
+
+#define gcm_fill _nettle_gcm_fill
+void
+_nettle_gcm_fill (uint8_t *ctr, size_t blocks, union nettle_block16
*buffer);
+#endif /* HAVE_NATIVE_gcm_fill */
+
 /* Increment the rightmost 32 bits. */
 #define INC32(block) INCREMENT(4, (block.b) + GCM_BLOCK_SIZE - 4)

@@ -245,7 +258,9 @@ gcm_set_key(struct gcm_key *key,
   memset(key-&gt;h[0].b, 0, GCM_BLOCK_SIZE);
   f (cipher, GCM_BLOCK_SIZE, key-&gt;h[i].b, key-&gt;h[0].b);

-#if GCM_TABLE_BITS
+#ifdef gcm_init_key
+  gcm_init_key(key-&gt;h);
+#elif GCM_TABLE_BITS
   /* Algorithm 3 from the gcm paper. First do powers of two, then do
      the rest by adding. */
   while (i /= 2)
@@ -333,6 +348,7 @@ gcm_update(struct gcm_ctx *ctx, const struct gcm_key
*key,
   ctx-&gt;auth_size += length;
 }

+#ifndef gcm_fill
 static nettle_fill16_func gcm_fill;
 static void
 gcm_fill(uint8_t *ctr, size_t blocks, union nettle_block16 *buffer)
@@ -349,6 +365,7 @@ gcm_fill(uint8_t *ctr, size_t blocks, union
nettle_block16 *buffer)

   WRITE_UINT32(ctr + GCM_BLOCK_SIZE - 4, c);
 }
+#endif /* !gcm_fill */

 void
 gcm_encrypt (struct gcm_ctx *ctx, const struct gcm_key *key,
diff --git a/powerpc64le/aes-decrypt-internal.asm
b/powerpc64le/aes-decrypt-internal.asm
new file mode 100644
index 00000000..bde34779
--- /dev/null
+++ b/powerpc64le/aes-decrypt-internal.asm
@@ -0,0 +1,573 @@
+C powerpc64le/aes-decrypt-internal.asm
+
+ifelse(&lt;
+   Copyright (C) 2020 Mamone Tarsha
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+&gt;)
+
+C Register usage:
+
+define(&lt;SP&gt;, &lt;1&gt;)
+define(&lt;TOCP&gt;, &lt;2&gt;)
+
+define(&lt;ROUNDS&gt;, &lt;3&gt;)
+define(&lt;KEYS&gt;, &lt;4&gt;)
+define(&lt;LENGTH&gt;, &lt;6&gt;)
+define(&lt;DST&gt;, &lt;7&gt;)
+define(&lt;SRC&gt;, &lt;8&gt;)
+
+define(&lt;swap_mask&gt;, &lt;0&gt;)
+
+define(&lt;K&gt;, &lt;1&gt;)
+define(&lt;S0&gt;, &lt;2&gt;)
+define(&lt;S1&gt;, &lt;3&gt;)
+define(&lt;S2&gt;, &lt;4&gt;)
+define(&lt;S3&gt;, &lt;5&gt;)
+define(&lt;S4&gt;, &lt;6&gt;)
+define(&lt;S5&gt;, &lt;7&gt;)
+define(&lt;S6&gt;, &lt;8&gt;)
+define(&lt;S7&gt;, &lt;9&gt;)
+define(&lt;S8&gt;, &lt;10&gt;)
+define(&lt;S9&gt;, &lt;11&gt;)
+define(&lt;S10&gt;, &lt;12&gt;)
+define(&lt;S11&gt;, &lt;13&gt;)
+define(&lt;S12&gt;, &lt;14&gt;)
+define(&lt;S13&gt;, &lt;15&gt;)
+define(&lt;S14&gt;, &lt;16&gt;)
+define(&lt;S15&gt;, &lt;17&gt;)
+
+define(&lt;KX&gt;, &lt;33&gt;)
+define(&lt;S0X&gt;, &lt;34&gt;)
+define(&lt;S1X&gt;, &lt;35&gt;)
+define(&lt;S2X&gt;, &lt;36&gt;)
+define(&lt;S3X&gt;, &lt;37&gt;)
+define(&lt;S4X&gt;, &lt;38&gt;)
+define(&lt;S5X&gt;, &lt;39&gt;)
+define(&lt;S6X&gt;, &lt;40&gt;)
+define(&lt;S7X&gt;, &lt;41&gt;)
+define(&lt;S8X&gt;, &lt;42&gt;)
+define(&lt;S9X&gt;, &lt;43&gt;)
+define(&lt;S10X&gt;, &lt;44&gt;)
+define(&lt;S11X&gt;, &lt;45&gt;)
+define(&lt;S12X&gt;, &lt;46&gt;)
+define(&lt;S13X&gt;, &lt;47&gt;)
+define(&lt;S14X&gt;, &lt;48&gt;)
+define(&lt;S15X&gt;, &lt;49&gt;)
+
+C ZERO vector register is used in place of RoundKey
+C for vncipher instruction because the order of InvMixColumns
+C and Xor processes are flipped in that instruction.
+C The Xor process with RoundKey is executed afterward.
+define(&lt;ZERO&gt;, &lt;18&gt;)
+
+ .file "aes-decrypt-internal.asm"
+
+ C _aes_decrypt(unsigned rounds, const uint32_t *keys,
+ C       const struct aes_table *T,
+ C       size_t length, uint8_t *dst,
+ C       uint8_t *src)
+
+ .text
+.align 5
+PROLOGUE(_nettle_aes_decrypt)
+  vxor      ZERO,ZERO,ZERO
+
+  ld     5,.swap_mask@got(TOCP)
+ lvx   swap_mask,0,5
+
+  subi      ROUNDS,ROUNDS,1
+  srdi      LENGTH,LENGTH,4
+
+  srdi      5,LENGTH,4              # 16x loop count
+  cmpldi 5,0
+  beq       L8x
+
+  std       17,-120(SP);
+  std       18,-112(SP);
+  std       19,-104(SP);
+  std       20,-96(SP);
+  std       21,-88(SP);
+  std       22,-80(SP);
+  std       23,-72(SP);
+  std       24,-64(SP);
+  std       25,-56(SP);
+  std       26,-48(SP);
+  std       27,-40(SP);
+  std       28,-32(SP);
+  std       29,-24(SP);
+  std       30,-16(SP);
+  std       31,-8(SP);
+
+  li        17,0x10
+  li        18,0x20
+  li        19,0x30
+  li        20,0x40
+  li        21,0x50
+  li        22,0x60
+  li        23,0x70
+  li        24,0x80
+  li        25,0x90
+  li        26,0xA0
+  li        27,0xB0
+  li        28,0xC0
+  li        29,0xD0
+  li        30,0xE0
+  li        31,0xF0
+
+.align 5
+Lx16_loop:
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+  lxvd2x S1X,17,SRC
+  lxvd2x S2X,18,SRC
+  lxvd2x S3X,19,SRC
+  lxvd2x S4X,20,SRC
+  lxvd2x S5X,21,SRC
+  lxvd2x S6X,22,SRC
+  lxvd2x S7X,23,SRC
+  lxvd2x S8X,24,SRC
+  lxvd2x S9X,25,SRC
+  lxvd2x S10X,26,SRC
+  lxvd2x S11X,27,SRC
+  lxvd2x S12X,28,SRC
+  lxvd2x S13X,29,SRC
+  lxvd2x S14X,30,SRC
+  lxvd2x S15X,31,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+  vxor      S4,S4,K
+  vxor      S5,S5,K
+  vxor      S6,S6,K
+  vxor      S7,S7,K
+  vxor      S8,S8,K
+  vxor      S9,S9,K
+  vxor      S10,S10,K
+  vxor      S11,S11,K
+  vxor      S12,S12,K
+  vxor      S13,S13,K
+  vxor      S14,S14,K
+  vxor      S15,S15,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+  vperm  S4,S4,S4,swap_mask
+  vperm  S5,S5,S5,swap_mask
+  vperm  S6,S6,S6,swap_mask
+  vperm  S7,S7,S7,swap_mask
+  vperm  S8,S8,S8,swap_mask
+  vperm  S9,S9,S9,swap_mask
+  vperm  S10,S10,S10,swap_mask
+  vperm  S11,S11,S11,swap_mask
+  vperm  S12,S12,S12,swap_mask
+  vperm  S13,S13,S13,swap_mask
+  vperm  S14,S14,S14,swap_mask
+  vperm  S15,S15,S15,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L16x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vncipher   S0,S0,ZERO
+  vncipher   S1,S1,ZERO
+  vncipher   S2,S2,ZERO
+  vncipher   S3,S3,ZERO
+  vncipher   S4,S4,ZERO
+  vncipher   S5,S5,ZERO
+  vncipher   S6,S6,ZERO
+  vncipher   S7,S7,ZERO
+  vncipher   S8,S8,ZERO
+  vncipher   S9,S9,ZERO
+  vncipher   S10,S10,ZERO
+  vncipher   S11,S11,ZERO
+  vncipher   S12,S12,ZERO
+  vncipher   S13,S13,ZERO
+  vncipher   S14,S14,ZERO
+  vncipher   S15,S15,ZERO
+  vxor       S0,S0,K
+  vxor       S1,S1,K
+  vxor       S2,S2,K
+  vxor       S3,S3,K
+  vxor       S4,S4,K
+  vxor       S5,S5,K
+  vxor       S6,S6,K
+  vxor       S7,S7,K
+  vxor       S8,S8,K
+  vxor       S9,S9,K
+  vxor       S10,S10,K
+  vxor       S11,S11,K
+  vxor       S12,S12,K
+  vxor       S13,S13,K
+  vxor       S14,S14,K
+  vxor       S15,S15,K
+  addi      10,10,0x10
+  bdnz      L16x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vncipherlast   S0,S0,K
+  vncipherlast   S1,S1,K
+  vncipherlast   S2,S2,K
+  vncipherlast   S3,S3,K
+  vncipherlast   S4,S4,K
+  vncipherlast   S5,S5,K
+  vncipherlast   S6,S6,K
+  vncipherlast   S7,S7,K
+  vncipherlast   S8,S8,K
+  vncipherlast   S9,S9,K
+  vncipherlast   S10,S10,K
+  vncipherlast   S11,S11,K
+  vncipherlast   S12,S12,K
+  vncipherlast   S13,S13,K
+  vncipherlast   S14,S14,K
+  vncipherlast   S15,S15,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+  vperm  S4,S4,S4,swap_mask
+  vperm  S5,S5,S5,swap_mask
+  vperm  S6,S6,S6,swap_mask
+  vperm  S7,S7,S7,swap_mask
+  vperm  S8,S8,S8,swap_mask
+  vperm  S9,S9,S9,swap_mask
+  vperm  S10,S10,S10,swap_mask
+  vperm  S11,S11,S11,swap_mask
+  vperm  S12,S12,S12,swap_mask
+  vperm  S13,S13,S13,swap_mask
+  vperm  S14,S14,S14,swap_mask
+  vperm  S15,S15,S15,swap_mask
+
+  stxvd2x S0X,0,DST
+  stxvd2x S1X,17,DST
+  stxvd2x S2X,18,DST
+  stxvd2x S3X,19,DST
+  stxvd2x S4X,20,DST
+  stxvd2x S5X,21,DST
+  stxvd2x S6X,22,DST
+  stxvd2x S7X,23,DST
+  stxvd2x S8X,24,DST
+  stxvd2x S9X,25,DST
+  stxvd2x S10X,26,DST
+  stxvd2x S11X,27,DST
+  stxvd2x S12X,28,DST
+  stxvd2x S13X,29,DST
+  stxvd2x S14X,30,DST
+  stxvd2x S15X,31,DST
+
+  addi      SRC,SRC,0x100
+  addi      DST,DST,0x100
+  subic.    5,5,1
+  bne       Lx16_loop
+
+  ld        17,-120(SP);
+  ld        18,-112(SP);
+  ld        19,-104(SP);
+  ld        20,-96(SP);
+  ld        21,-88(SP);
+  ld        22,-80(SP);
+  ld        23,-72(SP);
+  ld        24,-64(SP);
+  ld        25,-56(SP);
+  ld        26,-48(SP);
+  ld        27,-40(SP);
+  ld        28,-32(SP);
+  ld        29,-24(SP);
+  ld        30,-16(SP);
+  ld        31,-8(SP);
+
+  clrldi   LENGTH,LENGTH,60
+
+L8x:
+  srdi      5,LENGTH,3
+  cmpldi 5,0
+  beq       L4x
+
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+  li        9,0x10
+  lxvd2x S1X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S2X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S3X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S4X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S5X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S6X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S7X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+  vxor      S4,S4,K
+  vxor      S5,S5,K
+  vxor      S6,S6,K
+  vxor      S7,S7,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+  vperm  S4,S4,S4,swap_mask
+  vperm  S5,S5,S5,swap_mask
+  vperm  S6,S6,S6,swap_mask
+  vperm  S7,S7,S7,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L8x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vncipher   S0,S0,ZERO
+  vncipher   S1,S1,ZERO
+  vncipher   S2,S2,ZERO
+  vncipher   S3,S3,ZERO
+  vncipher   S4,S4,ZERO
+  vncipher   S5,S5,ZERO
+  vncipher   S6,S6,ZERO
+  vncipher   S7,S7,ZERO
+  vxor       S0,S0,K
+  vxor       S1,S1,K
+  vxor       S2,S2,K
+  vxor       S3,S3,K
+  vxor       S4,S4,K
+  vxor       S5,S5,K
+  vxor       S6,S6,K
+  vxor       S7,S7,K
+  addi      10,10,0x10
+  bdnz      L8x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vncipherlast   S0,S0,K
+  vncipherlast   S1,S1,K
+  vncipherlast   S2,S2,K
+  vncipherlast   S3,S3,K
+  vncipherlast   S4,S4,K
+  vncipherlast   S5,S5,K
+  vncipherlast   S6,S6,K
+  vncipherlast   S7,S7,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+  vperm  S4,S4,S4,swap_mask
+  vperm  S5,S5,S5,swap_mask
+  vperm  S6,S6,S6,swap_mask
+  vperm  S7,S7,S7,swap_mask
+
+  stxvd2x S0X,0,DST
+  li        9,0x10
+  stxvd2x S1X,9,DST
+  addi      9,9,0x10
+  stxvd2x S2X,9,DST
+  addi      9,9,0x10
+  stxvd2x S3X,9,DST
+  addi      9,9,0x10
+  stxvd2x S4X,9,DST
+  addi      9,9,0x10
+  stxvd2x S5X,9,DST
+  addi      9,9,0x10
+  stxvd2x S6X,9,DST
+  addi      9,9,0x10
+  stxvd2x S7X,9,DST
+
+  addi      SRC,SRC,0x80
+  addi      DST,DST,0x80
+
+  clrldi   LENGTH,LENGTH,61
+
+L4x:
+  srdi      5,LENGTH,2
+  cmpldi 5,0
+  beq       L2x
+
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+  li        9,0x10
+  lxvd2x S1X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S2X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S3X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L4x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vncipher   S0,S0,ZERO
+  vncipher   S1,S1,ZERO
+  vncipher   S2,S2,ZERO
+  vncipher   S3,S3,ZERO
+  vxor       S0,S0,K
+  vxor       S1,S1,K
+  vxor       S2,S2,K
+  vxor       S3,S3,K
+  addi      10,10,0x10
+  bdnz      L4x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vncipherlast   S0,S0,K
+  vncipherlast   S1,S1,K
+  vncipherlast   S2,S2,K
+  vncipherlast   S3,S3,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+
+  stxvd2x S0X,0,DST
+  li        9,0x10
+  stxvd2x S1X,9,DST
+  addi      9,9,0x10
+  stxvd2x S2X,9,DST
+  addi      9,9,0x10
+  stxvd2x S3X,9,DST
+
+  addi      SRC,SRC,0x40
+  addi      DST,DST,0x40
+
+  clrldi   LENGTH,LENGTH,62
+
+L2x:
+  srdi      5,LENGTH,1
+  cmpldi 5,0
+  beq       L1x
+
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+  li        9,0x10
+  lxvd2x S1X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L2x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vncipher   S0,S0,ZERO
+  vncipher   S1,S1,ZERO
+  vxor       S0,S0,K
+  vxor       S1,S1,K
+  addi      10,10,0x10
+  bdnz      L2x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vncipherlast   S0,S0,K
+  vncipherlast   S1,S1,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+
+  stxvd2x S0X,0,DST
+  li        9,0x10
+  stxvd2x S1X,9,DST
+
+  addi      SRC,SRC,0x20
+  addi      DST,DST,0x20
+
+  clrldi   LENGTH,LENGTH,63
+
+L1x:
+  cmpldi LENGTH,0
+  beq       Ldone
+
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+
+  vxor      S0,S0,K
+
+  vperm  S0,S0,S0,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L1x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vncipher   S0,S0,ZERO
+  vxor       S0,S0,K
+  addi      10,10,0x10
+  bdnz      L1x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vncipherlast   S0,S0,K
+
+  vperm  S0,S0,S0,swap_mask
+
+  stxvd2x S0X,0,DST
+
+Ldone:
+  blr
+EPILOGUE(_nettle_aes_decrypt)
+
+  .data
+  .align 4
+.swap_mask:
+ .byte 8,9,10,11,12,13,14,15,0,1,2,3,4,5,6,7
diff --git a/powerpc64le/aes-encrypt-internal.asm
b/powerpc64le/aes-encrypt-internal.asm
new file mode 100644
index 00000000..1bbd86a8
--- /dev/null
+++ b/powerpc64le/aes-encrypt-internal.asm
@@ -0,0 +1,534 @@
+C powerpc64le/aes-encrypt-internal.asm
+
+ifelse(&lt;
+   Copyright (C) 2020 Mamone Tarsha
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+&gt;)
+
+C Register usage:
+
+define(&lt;SP&gt;, &lt;1&gt;)
+define(&lt;TOCP&gt;, &lt;2&gt;)
+
+define(&lt;ROUNDS&gt;, &lt;3&gt;)
+define(&lt;KEYS&gt;, &lt;4&gt;)
+define(&lt;LENGTH&gt;, &lt;6&gt;)
+define(&lt;DST&gt;, &lt;7&gt;)
+define(&lt;SRC&gt;, &lt;8&gt;)
+
+define(&lt;swap_mask&gt;, &lt;0&gt;)
+
+define(&lt;K&gt;, &lt;1&gt;)
+define(&lt;S0&gt;, &lt;2&gt;)
+define(&lt;S1&gt;, &lt;3&gt;)
+define(&lt;S2&gt;, &lt;4&gt;)
+define(&lt;S3&gt;, &lt;5&gt;)
+define(&lt;S4&gt;, &lt;6&gt;)
+define(&lt;S5&gt;, &lt;7&gt;)
+define(&lt;S6&gt;, &lt;8&gt;)
+define(&lt;S7&gt;, &lt;9&gt;)
+define(&lt;S8&gt;, &lt;10&gt;)
+define(&lt;S9&gt;, &lt;11&gt;)
+define(&lt;S10&gt;, &lt;12&gt;)
+define(&lt;S11&gt;, &lt;13&gt;)
+define(&lt;S12&gt;, &lt;14&gt;)
+define(&lt;S13&gt;, &lt;15&gt;)
+define(&lt;S14&gt;, &lt;16&gt;)
+define(&lt;S15&gt;, &lt;17&gt;)
+
+define(&lt;KX&gt;, &lt;33&gt;)
+define(&lt;S0X&gt;, &lt;34&gt;)
+define(&lt;S1X&gt;, &lt;35&gt;)
+define(&lt;S2X&gt;, &lt;36&gt;)
+define(&lt;S3X&gt;, &lt;37&gt;)
+define(&lt;S4X&gt;, &lt;38&gt;)
+define(&lt;S5X&gt;, &lt;39&gt;)
+define(&lt;S6X&gt;, &lt;40&gt;)
+define(&lt;S7X&gt;, &lt;41&gt;)
+define(&lt;S8X&gt;, &lt;42&gt;)
+define(&lt;S9X&gt;, &lt;43&gt;)
+define(&lt;S10X&gt;, &lt;44&gt;)
+define(&lt;S11X&gt;, &lt;45&gt;)
+define(&lt;S12X&gt;, &lt;46&gt;)
+define(&lt;S13X&gt;, &lt;47&gt;)
+define(&lt;S14X&gt;, &lt;48&gt;)
+define(&lt;S15X&gt;, &lt;49&gt;)
+
+ .file "aes-encrypt-internal.asm"
+
+ C _aes_encrypt(unsigned rounds, const uint32_t *keys,
+ C       const struct aes_table *T,
+ C       size_t length, uint8_t *dst,
+ C       uint8_t *src)
+
+ .text
+.align 5
+PROLOGUE(_nettle_aes_encrypt)
+  ld     5,.swap_mask@got(TOCP)
+ lvx   swap_mask,0,5
+
+  subi      ROUNDS,ROUNDS,1
+  srdi      LENGTH,LENGTH,4
+
+  srdi      5,LENGTH,4              # 16x loop count
+  cmpldi 5,0
+  beq       L8x
+
+  std       17,-120(SP);
+  std       18,-112(SP);
+  std       19,-104(SP);
+  std       20,-96(SP);
+  std       21,-88(SP);
+  std       22,-80(SP);
+  std       23,-72(SP);
+  std       24,-64(SP);
+  std       25,-56(SP);
+  std       26,-48(SP);
+  std       27,-40(SP);
+  std       28,-32(SP);
+  std       29,-24(SP);
+  std       30,-16(SP);
+  std       31,-8(SP);
+
+  li        17,0x10
+  li        18,0x20
+  li        19,0x30
+  li        20,0x40
+  li        21,0x50
+  li        22,0x60
+  li        23,0x70
+  li        24,0x80
+  li        25,0x90
+  li        26,0xA0
+  li        27,0xB0
+  li        28,0xC0
+  li        29,0xD0
+  li        30,0xE0
+  li        31,0xF0
+
+.align 5
+Lx16_loop:
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+  lxvd2x S1X,17,SRC
+  lxvd2x S2X,18,SRC
+  lxvd2x S3X,19,SRC
+  lxvd2x S4X,20,SRC
+  lxvd2x S5X,21,SRC
+  lxvd2x S6X,22,SRC
+  lxvd2x S7X,23,SRC
+  lxvd2x S8X,24,SRC
+  lxvd2x S9X,25,SRC
+  lxvd2x S10X,26,SRC
+  lxvd2x S11X,27,SRC
+  lxvd2x S12X,28,SRC
+  lxvd2x S13X,29,SRC
+  lxvd2x S14X,30,SRC
+  lxvd2x S15X,31,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+  vxor      S4,S4,K
+  vxor      S5,S5,K
+  vxor      S6,S6,K
+  vxor      S7,S7,K
+  vxor      S8,S8,K
+  vxor      S9,S9,K
+  vxor      S10,S10,K
+  vxor      S11,S11,K
+  vxor      S12,S12,K
+  vxor      S13,S13,K
+  vxor      S14,S14,K
+  vxor      S15,S15,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+  vperm  S4,S4,S4,swap_mask
+  vperm  S5,S5,S5,swap_mask
+  vperm  S6,S6,S6,swap_mask
+  vperm  S7,S7,S7,swap_mask
+  vperm  S8,S8,S8,swap_mask
+  vperm  S9,S9,S9,swap_mask
+  vperm  S10,S10,S10,swap_mask
+  vperm  S11,S11,S11,swap_mask
+  vperm  S12,S12,S12,swap_mask
+  vperm  S13,S13,S13,swap_mask
+  vperm  S14,S14,S14,swap_mask
+  vperm  S15,S15,S15,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L16x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vcipher   S0,S0,K
+  vcipher   S1,S1,K
+  vcipher   S2,S2,K
+  vcipher   S3,S3,K
+  vcipher   S4,S4,K
+  vcipher   S5,S5,K
+  vcipher   S6,S6,K
+  vcipher   S7,S7,K
+  vcipher   S8,S8,K
+  vcipher   S9,S9,K
+  vcipher   S10,S10,K
+  vcipher   S11,S11,K
+  vcipher   S12,S12,K
+  vcipher   S13,S13,K
+  vcipher   S14,S14,K
+  vcipher   S15,S15,K
+  addi      10,10,0x10
+  bdnz      L16x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vcipherlast   S0,S0,K
+  vcipherlast   S1,S1,K
+  vcipherlast   S2,S2,K
+  vcipherlast   S3,S3,K
+  vcipherlast   S4,S4,K
+  vcipherlast   S5,S5,K
+  vcipherlast   S6,S6,K
+  vcipherlast   S7,S7,K
+  vcipherlast   S8,S8,K
+  vcipherlast   S9,S9,K
+  vcipherlast   S10,S10,K
+  vcipherlast   S11,S11,K
+  vcipherlast   S12,S12,K
+  vcipherlast   S13,S13,K
+  vcipherlast   S14,S14,K
+  vcipherlast   S15,S15,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+  vperm  S4,S4,S4,swap_mask
+  vperm  S5,S5,S5,swap_mask
+  vperm  S6,S6,S6,swap_mask
+  vperm  S7,S7,S7,swap_mask
+  vperm  S8,S8,S8,swap_mask
+  vperm  S9,S9,S9,swap_mask
+  vperm  S10,S10,S10,swap_mask
+  vperm  S11,S11,S11,swap_mask
+  vperm  S12,S12,S12,swap_mask
+  vperm  S13,S13,S13,swap_mask
+  vperm  S14,S14,S14,swap_mask
+  vperm  S15,S15,S15,swap_mask
+
+  stxvd2x S0X,0,DST
+  stxvd2x S1X,17,DST
+  stxvd2x S2X,18,DST
+  stxvd2x S3X,19,DST
+  stxvd2x S4X,20,DST
+  stxvd2x S5X,21,DST
+  stxvd2x S6X,22,DST
+  stxvd2x S7X,23,DST
+  stxvd2x S8X,24,DST
+  stxvd2x S9X,25,DST
+  stxvd2x S10X,26,DST
+  stxvd2x S11X,27,DST
+  stxvd2x S12X,28,DST
+  stxvd2x S13X,29,DST
+  stxvd2x S14X,30,DST
+  stxvd2x S15X,31,DST
+
+  addi      SRC,SRC,0x100
+  addi      DST,DST,0x100
+  subic.    5,5,1
+  bne       Lx16_loop
+
+  ld        17,-120(SP);
+  ld        18,-112(SP);
+  ld        19,-104(SP);
+  ld        20,-96(SP);
+  ld        21,-88(SP);
+  ld        22,-80(SP);
+  ld        23,-72(SP);
+  ld        24,-64(SP);
+  ld        25,-56(SP);
+  ld        26,-48(SP);
+  ld        27,-40(SP);
+  ld        28,-32(SP);
+  ld        29,-24(SP);
+  ld        30,-16(SP);
+  ld        31,-8(SP);
+
+  clrldi   LENGTH,LENGTH,60
+
+L8x:
+  srdi      5,LENGTH,3
+  cmpldi 5,0
+  beq       L4x
+
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+  li        9,0x10
+  lxvd2x S1X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S2X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S3X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S4X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S5X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S6X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S7X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+  vxor      S4,S4,K
+  vxor      S5,S5,K
+  vxor      S6,S6,K
+  vxor      S7,S7,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+  vperm  S4,S4,S4,swap_mask
+  vperm  S5,S5,S5,swap_mask
+  vperm  S6,S6,S6,swap_mask
+  vperm  S7,S7,S7,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L8x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vcipher   S0,S0,K
+  vcipher   S1,S1,K
+  vcipher   S2,S2,K
+  vcipher   S3,S3,K
+  vcipher   S4,S4,K
+  vcipher   S5,S5,K
+  vcipher   S6,S6,K
+  vcipher   S7,S7,K
+  addi      10,10,0x10
+  bdnz      L8x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vcipherlast   S0,S0,K
+  vcipherlast   S1,S1,K
+  vcipherlast   S2,S2,K
+  vcipherlast   S3,S3,K
+  vcipherlast   S4,S4,K
+  vcipherlast   S5,S5,K
+  vcipherlast   S6,S6,K
+  vcipherlast   S7,S7,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+  vperm  S4,S4,S4,swap_mask
+  vperm  S5,S5,S5,swap_mask
+  vperm  S6,S6,S6,swap_mask
+  vperm  S7,S7,S7,swap_mask
+
+  stxvd2x S0X,0,DST
+  li        9,0x10
+  stxvd2x S1X,9,DST
+  addi      9,9,0x10
+  stxvd2x S2X,9,DST
+  addi      9,9,0x10
+  stxvd2x S3X,9,DST
+  addi      9,9,0x10
+  stxvd2x S4X,9,DST
+  addi      9,9,0x10
+  stxvd2x S5X,9,DST
+  addi      9,9,0x10
+  stxvd2x S6X,9,DST
+  addi      9,9,0x10
+  stxvd2x S7X,9,DST
+
+  addi      SRC,SRC,0x80
+  addi      DST,DST,0x80
+
+  clrldi   LENGTH,LENGTH,61
+
+L4x:
+  srdi      5,LENGTH,2
+  cmpldi 5,0
+  beq       L2x
+
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+  li        9,0x10
+  lxvd2x S1X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S2X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S3X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L4x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vcipher   S0,S0,K
+  vcipher   S1,S1,K
+  vcipher   S2,S2,K
+  vcipher   S3,S3,K
+  addi      10,10,0x10
+  bdnz      L4x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vcipherlast   S0,S0,K
+  vcipherlast   S1,S1,K
+  vcipherlast   S2,S2,K
+  vcipherlast   S3,S3,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+
+  stxvd2x S0X,0,DST
+  li        9,0x10
+  stxvd2x S1X,9,DST
+  addi      9,9,0x10
+  stxvd2x S2X,9,DST
+  addi      9,9,0x10
+  stxvd2x S3X,9,DST
+
+  addi      SRC,SRC,0x40
+  addi      DST,DST,0x40
+
+  clrldi   LENGTH,LENGTH,62
+
+L2x:
+  srdi      5,LENGTH,1
+  cmpldi 5,0
+  beq       L1x
+
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+  li        9,0x10
+  lxvd2x S1X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L2x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vcipher   S0,S0,K
+  vcipher   S1,S1,K
+  addi      10,10,0x10
+  bdnz      L2x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vcipherlast   S0,S0,K
+  vcipherlast   S1,S1,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+
+  stxvd2x S0X,0,DST
+  li        9,0x10
+  stxvd2x S1X,9,DST
+
+  addi      SRC,SRC,0x20
+  addi      DST,DST,0x20
+
+  clrldi   LENGTH,LENGTH,63
+
+L1x:
+  cmpldi LENGTH,0
+  beq       Ldone
+
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+
+  vxor      S0,S0,K
+
+  vperm  S0,S0,S0,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L1x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vcipher   S0,S0,K
+  addi      10,10,0x10
+  bdnz      L1x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vcipherlast   S0,S0,K
+
+  vperm  S0,S0,S0,swap_mask
+
+  stxvd2x S0X,0,DST
+
+Ldone:
+  blr
+EPILOGUE(_nettle_aes_encrypt)
+
+  .data
+  .align 4
+.swap_mask:
+ .byte 8,9,10,11,12,13,14,15,0,1,2,3,4,5,6,7
diff --git a/powerpc64le/gcm-hash8.asm b/powerpc64le/gcm-hash8.asm
new file mode 100644
index 00000000..a809f6ef
--- /dev/null
+++ b/powerpc64le/gcm-hash8.asm
@@ -0,0 +1,992 @@
+C powerpc64le/gcm-hash8.asm
+
+ifelse(&lt;
+   Copyright (C) 2020 Mamone Tarsha
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+&gt;)
+
+C Register usage:
+C VSX instructions is used to load and store data to memory "lxvd2x,
stxvd2x"
+C instead of VR instructions "lvx, stvx" as a workaround to access
unaligned data
+C VSX registers are defined with "X" suffix
+
+define(&lt;SP&gt;, &lt;1&gt;)
+define(&lt;TOCP&gt;, &lt;2&gt;)
+
+define(&lt;TABLE&gt;, &lt;3&gt;)
+define(&lt;X&gt;, &lt;4&gt;)
+define(&lt;LENGTH&gt;, &lt;5&gt;)
+define(&lt;DATA&gt;, &lt;6&gt;)
+
+define(&lt;zero&gt;, &lt;0&gt;)
+define(&lt;swap_mask&gt;, &lt;1&gt;)
+define(&lt;hidw_mask&gt;, &lt;2&gt;)
+define(&lt;lodw_mask&gt;, &lt;3&gt;)
+define(&lt;poly&gt;, &lt;4&gt;)
+define(&lt;poly_h&gt;, &lt;4&gt;)
+define(&lt;poly_l&gt;, &lt;5&gt;)
+define(&lt;RP&gt;, &lt;6&gt;)
+define(&lt;Mh&gt;, &lt;7&gt;)
+define(&lt;Ml&gt;, &lt;8&gt;)
+define(&lt;H&gt;, &lt;9&gt;)
+define(&lt;Hh&gt;, &lt;10&gt;)
+define(&lt;Hl&gt;, &lt;11&gt;)
+define(&lt;RP2&gt;, &lt;9&gt;)
+define(&lt;M2h&gt;, &lt;10&gt;)
+define(&lt;M2l&gt;, &lt;11&gt;)
+
+define(&lt;HX&gt;, &lt;41&gt;)
+define(&lt;HhX&gt;, &lt;42&gt;)
+define(&lt;HlX&gt;, &lt;43&gt;)
+define(&lt;H_HhX&gt;, &lt;44&gt;)
+define(&lt;H_HX&gt;, &lt;45&gt;)
+define(&lt;H_HlX&gt;, &lt;46&gt;)
+
+define(&lt;sl1&gt;, &lt;1&gt;)
+define(&lt;msb&gt;, &lt;5&gt;)
+define(&lt;H2&gt;, &lt;6&gt;)
+define(&lt;H2h&gt;, &lt;7&gt;)
+define(&lt;H2l&gt;, &lt;8&gt;)
+define(&lt;H_h&gt;, &lt;12&gt;)
+define(&lt;H_m&gt;, &lt;13&gt;)
+define(&lt;H_l&gt;, &lt;14&gt;)
+define(&lt;H_Hh&gt;, &lt;12&gt;)
+define(&lt;H_H&gt;, &lt;13&gt;)
+define(&lt;H_Hl&gt;, &lt;14&gt;)
+define(&lt;H_t&gt;, &lt;15&gt;)
+define(&lt;H2_h&gt;, &lt;16&gt;)
+define(&lt;H2_m&gt;, &lt;17&gt;)
+define(&lt;H2_l&gt;, &lt;18&gt;)
+define(&lt;H2_t&gt;, &lt;19&gt;)
+
+define(&lt;C0X&gt;, &lt;38&gt;)
+define(&lt;C1X&gt;, &lt;39&gt;)
+define(&lt;C2X&gt;, &lt;40&gt;)
+define(&lt;C3X&gt;, &lt;44&gt;)
+define(&lt;C4X&gt;, &lt;38&gt;)
+define(&lt;C5X&gt;, &lt;39&gt;)
+define(&lt;C6X&gt;, &lt;40&gt;)
+define(&lt;C7X&gt;, &lt;44&gt;)
+
+define(&lt;CX&gt;, &lt;45&gt;)
+
+define(&lt;C0&gt;, &lt;6&gt;)
+define(&lt;C1&gt;, &lt;7&gt;)
+define(&lt;C2&gt;, &lt;8&gt;)
+define(&lt;C3&gt;, &lt;12&gt;)
+define(&lt;C4&gt;, &lt;6&gt;)
+define(&lt;C5&gt;, &lt;7&gt;)
+define(&lt;C6&gt;, &lt;8&gt;)
+define(&lt;C7&gt;, &lt;12&gt;)
+
+define(&lt;C&gt;, &lt;13&gt;)
+
+define(&lt;Ch&gt;, &lt;14&gt;)
+define(&lt;Cl&gt;, &lt;15&gt;)
+define(&lt;Cm&gt;, &lt;16&gt;)
+
+define(&lt;C01h&gt;, &lt;14&gt;)
+define(&lt;C01l&gt;, &lt;15&gt;)
+define(&lt;C01&gt;, &lt;16&gt;)
+define(&lt;C23h&gt;, &lt;17&gt;)
+define(&lt;C23l&gt;, &lt;18&gt;)
+define(&lt;C23&gt;, &lt;19&gt;)
+define(&lt;C45h&gt;, &lt;20&gt;)
+define(&lt;C45l&gt;, &lt;21&gt;)
+define(&lt;C45&gt;, &lt;22&gt;)
+define(&lt;C67h&gt;, &lt;6&gt;)
+define(&lt;C67l&gt;, &lt;7&gt;)
+define(&lt;C67&gt;, &lt;8&gt;)
+
+define(&lt;H21&gt;, &lt;9&gt;)
+define(&lt;H21h&gt;, &lt;10&gt;)
+define(&lt;H21l&gt;, &lt;11&gt;)
+define(&lt;H43&gt;, &lt;23&gt;)
+define(&lt;H43h&gt;, &lt;24&gt;)
+define(&lt;H43l&gt;, &lt;25&gt;)
+define(&lt;H65&gt;, &lt;26&gt;)
+define(&lt;H65h&gt;, &lt;27&gt;)
+define(&lt;H65l&gt;, &lt;28&gt;)
+define(&lt;H87&gt;, &lt;29&gt;)
+define(&lt;H87h&gt;, &lt;30&gt;)
+define(&lt;H87l&gt;, &lt;31&gt;)
+
+define(&lt;H21X&gt;, &lt;41&gt;)
+define(&lt;H21hX&gt;, &lt;42&gt;)
+define(&lt;H21lX&gt;, &lt;43&gt;)
+define(&lt;H43X&gt;, &lt;55&gt;)
+define(&lt;H43hX&gt;, &lt;56&gt;)
+define(&lt;H43lX&gt;, &lt;57&gt;)
+define(&lt;H65X&gt;, &lt;58&gt;)
+define(&lt;H65hX&gt;, &lt;59&gt;)
+define(&lt;H65lX&gt;, &lt;60&gt;)
+define(&lt;H87X&gt;, &lt;61&gt;)
+define(&lt;H87hX&gt;, &lt;62&gt;)
+define(&lt;H87lX&gt;, &lt;63&gt;)
+
+# gcm_fill registers:
+
+define(&lt;CTR&gt;, &lt;3&gt;)
+define(&lt;BLOCKS&gt;, &lt;4&gt;)
+define(&lt;BUFFER&gt;, &lt;5&gt;)
+
+define(&lt;CTR0&gt;, &lt;2&gt;)
+define(&lt;CTR0S&gt;, &lt;3&gt;)
+define(&lt;CTR1&gt;, &lt;4&gt;)
+define(&lt;CTR2&gt;, &lt;5&gt;)
+define(&lt;CTR3&gt;, &lt;6&gt;)
+define(&lt;CTR4&gt;, &lt;7&gt;)
+define(&lt;CTR5&gt;, &lt;8&gt;)
+define(&lt;CTR6&gt;, &lt;9&gt;)
+define(&lt;CTR7&gt;, &lt;10&gt;)
+
+define(&lt;CTR0X&gt;, &lt;34&gt;)
+define(&lt;CTR0SX&gt;, &lt;35&gt;)
+define(&lt;CTR1X&gt;, &lt;36&gt;)
+define(&lt;CTR2X&gt;, &lt;37&gt;)
+define(&lt;CTR3X&gt;, &lt;38&gt;)
+define(&lt;CTR4X&gt;, &lt;39&gt;)
+define(&lt;CTR5X&gt;, &lt;40&gt;)
+define(&lt;CTR6X&gt;, &lt;41&gt;)
+define(&lt;CTR7X&gt;, &lt;42&gt;)
+
+define(&lt;I1&gt;, &lt;11&gt;)
+define(&lt;I2&gt;, &lt;12&gt;)
+define(&lt;I3&gt;, &lt;13&gt;)
+define(&lt;I4&gt;, &lt;14&gt;)
+define(&lt;I5&gt;, &lt;15&gt;)
+define(&lt;I6&gt;, &lt;16&gt;)
+define(&lt;I7&gt;, &lt;17&gt;)
+define(&lt;I8&gt;, &lt;18&gt;)
+
+ .file "gcm-hash8.asm"
+
+ # void gcm_init_key (union gcm_block *table)
+
+    .text
+.align 5
+PROLOGUE(_nettle_gcm_init_key8)
+    ld     7,.polynomial@got(TOCP)
+ lvx   poly,0,7
+ ld     7,.swap_mask@got(TOCP)
+ lvx   swap_mask,0,7
+ ld     7,.hidw_mask@got(TOCP)
+ lvx     hidw_mask,0,7
+ ld     7,.lodw_mask@got(TOCP)
+ lvx   lodw_mask,0,7
+
+ li    10,0x800
+    lxvd2x HX,10,TABLE # load H
+ vperm H,H,H,swap_mask
+
+ # --- calculate H = H shift left 1 modulo polynomial ---
+
+ vupkhsw    msb,H # most significant bit word-extend
+ vspltisb sl1,1 # splat 1 for shift left
+ vspltw      msb,msb,0 # most significant bit extend
+ vsl    H,H,sl1 # H shift left 1
+ vand msb,msb,poly
+ vxor zero,zero,zero
+ vxor H_t,H,msb
+
+ vsldoi H,H_t,H_t,8 # doubleword swap
+ vsldoi Hh,H,zero,8
+ vsldoi Hl,zero,H,8
+
+ # --- calculate H^2 = H*H ---
+
+ # reduction pre-processing
+ vsldoi poly_h,zero,poly,8
+ vsldoi poly_l,poly_h,poly_h,8
+
+ # polynomial multiplication "classical"
+ vpmsumd H_h,H_t,Hh # H^1h*H^1h
+ vpmsumd H_l,H_t,Hl # H^1l*H^1l
+ vpmsumd H_m,H_t,H # H^1h*H^1l⊕H^1l*H^1h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h   # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8   # [2]
+ vsldoi Ml,H_m,zero,8 # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor H_h,H_h,Mh       # [2]
+ vxor H_l,H_l,Ml       # [2]
+ vxor H_l,H_l,RP       # [1]
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l
+ vxor H_h,H_l,H_h
+ vxor H2_t,H_h,RP
+
+ vsldoi H2,H2_t,H2_t,8
+ vsldoi H2h,H2,zero,8
+ vsldoi H2l,zero,H2,8
+
+ # --- calculate [H^2.Hi⊕H^2.Lo:H^1.Hi⊕H^1.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store H,[H^2.Hi⊕H^2.Lo:H^1.Hi⊕H^1.Lo] ---
+
+ li    8,0x00
+ li    9,0x100
+ li    10,0x200
+ stxvd2x HlX,8,TABLE
+ stxvd2x HX,9,TABLE
+ stxvd2x HhX,10,TABLE
+
+ li    8,0x300
+ li    9,0x400
+ li    10,0x500
+ stxvd2x H_HhX,8,TABLE
+ stxvd2x H_HX,9,TABLE
+ stxvd2x H_HlX,10,TABLE
+
+ # --- calculate H^3,H^4 ---
+
+ # polynomial multiplication "classical"
+ vpmsumd H_l,H_t,H2l # H^1l*H^2l
+ vpmsumd H_m,H_t,H2 # H^1h*H^2l⊕H^1l*H^2h
+ vpmsumd H_h,H_t,H2h # H^1h*H^2h
+ vpmsumd H2_l,H2_t,H2l # H^2l*H^2l
+ vpmsumd H2_m,H2_t,H2 # H^2h*H^2l⊕H^2l*H^2h
+ vpmsumd H2_h,H2_t,H2h # H^2h*H^2h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h # [1] H^3
+ vpmsumd    RP2,H2_l,poly_h # [1] H^4
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8 # [2] H^3
+ vsldoi M2h,zero,H2_m,8 # [2] H^4
+ vsldoi Ml,H_m,zero,8 # [2] H^3
+ vsldoi M2l,H2_m,zero,8 # [2] H^4
+ vsldoi RP,RP,RP,8 # [1] H^3
+ vsldoi RP2,RP2,RP2,8 # [1] H^4
+ vxor H_h,H_h,Mh # [2] H^3
+ vxor H2_h,H2_h,M2h # [2] H^4
+ vxor H_l,H_l,Ml # [2] H^3
+ vxor H2_l,H2_l,M2l # [2] H^4
+ vxor H_l,H_l,RP # [1] H^3
+ vxor H2_l,H2_l,RP2 # [1] H^4
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l # H^3
+ vpmsumd RP2,H2_l,poly_l # H^4
+ vxor H_h,H_l,H_h # H^3
+ vxor H2_h,H2_l,H2_h # H^4
+ vxor H_h,H_h,RP # H^3
+ vxor H2_h,H2_h,RP2 # H^4
+
+ vsldoi H2,H2_h,H2_h,8 # H^4
+ vsldoi H,H_h,H_h,8 # H^3
+ vsldoi H2l,zero,H2,8 # H^4
+ vsldoi H2h,H2,zero,8 # H^4
+
+ # --- calculate [H^4.Hi⊕H^4.Lo:H^3.Hi⊕H^3.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store [H^4.Hi⊕H^4.Lo:H^3.Hi⊕H^3.Lo] ---
+
+ li    8,0x600
+ li    9,0x700
+ li    10,0x800
+ stxvd2x H_HhX,8,TABLE
+ stxvd2x H_HX,9,TABLE
+ stxvd2x H_HlX,10,TABLE
+
+ # --- calculate H^5,H^6 ---
+
+ # polynomial multiplication "classical"
+ vpmsumd H_l,H_t,H2l # H^1l*H^4l
+ vpmsumd H_m,H_t,H2 # H^1h*H^4l⊕H^1l*H^4h
+ vpmsumd H_h,H_t,H2h # H^1h*H^4h
+ vpmsumd H2_l,H2_t,H2l # H^2l*H^4l
+ vpmsumd H2_m,H2_t,H2 # H^2h*H^4l⊕H^2l*H^4h
+ vpmsumd H2_h,H2_t,H2h # H^2h*H^4h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h # [1] H^5
+ vpmsumd    RP2,H2_l,poly_h # [1] H^6
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8 # [2] H^5
+ vsldoi M2h,zero,H2_m,8 # [2] H^6
+ vsldoi Ml,H_m,zero,8 # [2] H^5
+ vsldoi M2l,H2_m,zero,8 # [2] H^6
+ vsldoi RP,RP,RP,8 # [1] H^5
+ vsldoi RP2,RP2,RP2,8 # [1] H^6
+ vxor H_h,H_h,Mh # [2] H^5
+ vxor H2_h,H2_h,M2h # [2] H^6
+ vxor H_l,H_l,Ml # [2] H^5
+ vxor H2_l,H2_l,M2l # [2] H^6
+ vxor H_l,H_l,RP # [1] H^5
+ vxor H2_l,H2_l,RP2 # [1] H^6
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l # H^5
+ vpmsumd RP2,H2_l,poly_l # H^6
+ vxor H_h,H_l,H_h # H^5
+ vxor H2_h,H2_l,H2_h # H^6
+ vxor H_h,H_h,RP # H^5
+ vxor H2_h,H2_h,RP2 # H^6
+
+ vsldoi H2,H2_h,H2_h,8 # H^6
+ vsldoi H,H_h,H_h,8 # H^5
+ vsldoi H2l,zero,H2,8 # H^6
+ vsldoi H2h,H2,zero,8 # H^6
+
+ # --- calculate [H^6.Hi⊕H^6.Lo:H^5.Hi⊕H^5.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store [H^6.Hi⊕H^6.Lo:H^5.Hi⊕H^5.Lo] ---
+
+ li    8,0x900
+ li    9,0xA00
+ li    10,0xB00
+ stxvd2x H_HhX,8,TABLE
+ stxvd2x H_HX,9,TABLE
+ stxvd2x H_HlX,10,TABLE
+
+ # --- calculate H^7,H^8 ---
+
+ # polynomial multiplication "classical"
+ vpmsumd H_l,H_t,H2l # H^1l*H^6l
+ vpmsumd H_m,H_t,H2 # H^1h*H^6l⊕H^1l*H^6h
+ vpmsumd H_h,H_t,H2h # H^1h*H^6h
+ vpmsumd H2_l,H2_t,H2l # H^2l*H^6l
+ vpmsumd H2_m,H2_t,H2 # H^2h*H^6l⊕H^2l*H^6h
+ vpmsumd H2_h,H2_t,H2h # H^2h*H^6h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h # [1] H^7
+ vpmsumd    RP2,H2_l,poly_h # [1] H^8
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8 # [2] H^7
+ vsldoi M2h,zero,H2_m,8 # [2] H^8
+ vsldoi Ml,H_m,zero,8 # [2] H^7
+ vsldoi M2l,H2_m,zero,8 # [2] H^8
+ vsldoi RP,RP,RP,8 # [1] H^7
+ vsldoi RP2,RP2,RP2,8 # [1] H^8
+ vxor H_h,H_h,Mh # [2] H^7
+ vxor H2_h,H2_h,M2h # [2] H^8
+ vxor H_l,H_l,Ml # [2] H^7
+ vxor H2_l,H2_l,M2l # [2] H^8
+ vxor H_l,H_l,RP # [1] H^7
+ vxor H2_l,H2_l,RP2 # [1] H^8
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l # H^7
+ vpmsumd RP2,H2_l,poly_l # H^8
+ vxor H_h,H_l,H_h # H^7
+ vxor H2_h,H2_l,H2_h # H^8
+ vxor H_h,H_h,RP # H^7
+ vxor H2_h,H2_h,RP2 # H^8
+
+ vsldoi H,H_h,H_h,8 # H^7
+ vsldoi H2,H2_h,H2_h,8 # H^8
+
+ # --- calculate [H^8.Hi⊕H^8.Lo:H^7.Hi⊕H^7.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store [H^8.Hi⊕H^8.Lo:H^7.Hi⊕H^7.Lo] ---
+
+ li    8,0xC00
+ li    9,0xD00
+ li    10,0xE00
+ stxvd2x H_HhX,8,TABLE
+ stxvd2x H_HX,9,TABLE
+ stxvd2x H_HlX,10,TABLE
+
+    blr
+EPILOGUE(_nettle_gcm_init_key8)
+
+ # void gcm_hash (const struct gcm_key *key, union gcm_block *x,
+ #                size_t length, const uint8_t *data)
+
+.align 5
+PROLOGUE(_nettle_gcm_hash8)
+    vxor zero,zero,zero
+
+ ld     7,.polynomial@got(TOCP)
+ lvx   poly,0,7
+ ld     7,.swap_mask@got(TOCP)
+ lvx   swap_mask,0,7
+ ld      7,.hidw_mask@got(TOCP)
+ lvx     hidw_mask,0,7
+ ld     7,.lodw_mask@got(TOCP)
+ lvx   lodw_mask,0,7
+
+ vsldoi poly_h,zero,poly,8
+ vsldoi poly_l,poly_h,poly_h,8
+
+ lxvd2x CX,0,X # load X
+ vperm C,C,C,swap_mask
+
+ srdi 7,LENGTH,7 # 8x loop count
+ cmpldi 7,0
+ beq L2x
+
+ # backup registers
+ stdu SP,-224(SP)
+ std 28,216(SP)
+ std 29,208(SP)
+ std 30,200(SP)
+ std 31,192(SP)
+    li 8,176
+    stvx 20,8,SP
+    subi 8,8,16
+    stvx 21,8,SP
+    subi 8,8,16
+    stvx 22,8,SP
+    subi 8,8,16
+    stvx 23,8,SP
+    subi 8,8,16
+    stvx 24,8,SP
+    subi 8,8,16
+    stvx 25,8,SP
+    subi 8,8,16
+    stvx 26,8,SP
+    subi 8,8,16
+    stvx 27,8,SP
+    subi 8,8,16
+    stvx 28,8,SP
+    subi 8,8,16
+    stvx 29,8,SP
+    subi 8,8,16
+    stvx 30,8,SP
+    subi 8,8,16
+    stvx 31,8,SP
+
+ # table loading
+ li 8,0x300
+ li 9,0x400
+ li 10,0x500
+ lxvd2x H21hX,8,TABLE
+ lxvd2x H21X,9,TABLE
+ lxvd2x H21lX,10,TABLE
+ li 8,0x600
+ li 9,0x700
+ li 10,0x800
+ lxvd2x H43hX,8,TABLE
+ lxvd2x H43X,9,TABLE
+ lxvd2x H43lX,10,TABLE
+ li 8,0x900
+ li 9,0xA00
+ li 10,0xB00
+ lxvd2x H65hX,8,TABLE
+ lxvd2x H65X,9,TABLE
+ lxvd2x H65lX,10,TABLE
+ li 8,0xC00
+ li 9,0xD00
+ li 10,0xE00
+ lxvd2x H87hX,8,TABLE
+ lxvd2x H87X,9,TABLE
+ lxvd2x H87lX,10,TABLE
+
+ li 8,0x10
+ li 9,0x20
+ li 10,0x30
+ li 28,0x40
+ li 29,0x50
+ li 30,0x60
+ li 31,0x70
+
+ mtctr     7
+.align 5
+L8x_loop:
+ # input loading
+ lxvd2x C0X,0,DATA # load C0
+ lxvd2x C1X,8,DATA # load C1
+ lxvd2x C2X,9,DATA # load C2
+ lxvd2x C3X,10,DATA # load C3
+
+ # swap permuting
+ vperm C0,C0,C0,swap_mask
+ vperm C1,C1,C1,swap_mask
+ vperm C2,C2,C2,swap_mask
+ vperm C3,C3,C3,swap_mask
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ # polynomial multiplication "karatsuba" pre-processing
+ vperm C23h,C2,C3,hidw_mask
+ vperm C23l,C2,C3,lodw_mask
+ vperm C01h,C0,C1,hidw_mask
+ vperm C01l,C0,C1,lodw_mask
+
+ # input loading
+ lxvd2x C4X,28,DATA # load C4
+ lxvd2x C5X,29,DATA # load C5
+ lxvd2x C6X,30,DATA # load C6
+ lxvd2x C7X,31,DATA # load C7
+
+ # swap permuting
+ vperm C4,C4,C4,swap_mask
+ vperm C5,C5,C5,swap_mask
+ vperm C6,C6,C6,swap_mask
+ vperm C7,C7,C7,swap_mask
+
+ # polynomial multiplication "karatsuba" pre-processing
+ vperm C45h,C4,C5,hidw_mask
+ vperm C45l,C4,C5,lodw_mask
+ vperm C67h,C6,C7,hidw_mask
+ vperm C67l,C6,C7,lodw_mask
+ vxor C23,C23h,C23l
+ vxor C01,C01h,C01l
+ vxor C45,C45h,C45l
+ vxor C67,C67h,C67l
+
+ # polynomial multiplication "karatsuba"
+ vpmsumd C23h,C23h,H65h # H23 = H^6h*C2h⊕H^5h*C3h
+ vpmsumd C23l,C23l,H65l # L23 = H^6l*C2l⊕H^5l*C3l
+ vpmsumd C01h,C01h,H87h # H01 = H^8h*C0h⊕H^7h*C1h
+ vpmsumd C01l,C01l,H87l # L01 = H^8l*C0l⊕H^7l*C1l
+ vpmsumd C67h,C67h,H21h # H67 = H^2h*C6h⊕H^1h*C7h
+ vpmsumd C67l,C67l,H21l # L67 = H^2l*C6l⊕H^1l*C7l
+ vpmsumd C45h,C45h,H43h # H45 = H^4h*C4h⊕H^3h*C5h
+ vpmsumd C45l,C45l,H43l # L45 = H^4l*C4l⊕H^3l*C5l
+ vpmsumd C23,C23,H65 # M23 = (H^6h⊕H^5h)*(C2h⊕C3h)⊕(H^6l⊕H^5l)*(C2l⊕C3l)
+ vpmsumd C01,C01,H87 # M01 = (H^8h⊕H^7h)*(C0h⊕C1h)⊕(H^8l⊕H^7l)*(C0l⊕C1l)
+ vpmsumd C45,C45,H43 # M45 = (H^4h⊕H^3h)*(C4h⊕C5h)⊕(H^4l⊕H^3l)*(C4l⊕C5l)
+ vpmsumd C67,C67,H21 # M67 = (H^2h⊕H^1h)*(C6h⊕C7h)⊕(H^2l⊕H^1l)*(C6l⊕C7l)
+
+ # polynomial multiplication "karatsuba" post-processing
+ vxor C23,C23,C23h
+ vxor C01,C01,C01h
+ vxor C45,C45,C45h
+ vxor C67,C67,C67h
+ vxor C23,C23,C23l
+ vxor C01,C01,C01l
+ vxor C45,C45,C45l
+ vxor C67,C67,C67l
+
+ # deferred recombination of partial products
+ vxor C01h,C01h,C23h # H0 = H01⊕H23
+ vxor C45h,C45h,C67h # H1 = H45⊕H67
+ vxor C01l,C01l,C23l # L0 = L01⊕L23
+ vxor C45l,C45l,C67l # L1 = L45⊕L45
+ vxor C01,C01,C23 # M0 = M01⊕M23
+ vxor C45,C45,C67 # M1 = M45⊕M45
+ vxor C01h,C01h,C45h # H = H0⊕H1
+ vxor C01l,C01l,C45l # L = L0⊕L1
+ vxor C01,C01,C45 # M = M0⊕M1
+
+ # reduction first phase # [1]
+ vpmsumd RP,C01l,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,C01,8   # [2]
+ vsldoi Ml,C01,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor C01h,C01h,Mh     # [2]
+ vxor C01l,C01l,Ml     # [2]
+ vxor C01l,C01l,RP     # [1]
+
+ # reduction second phase
+ vpmsumd RP,C01l,poly_l
+ vxor C01h,C01l,C01h
+ vxor C,C01h,RP
+
+ addi DATA,DATA,0x80
+ bdnz L8x_loop
+
+    # restore registers
+ li 8,0
+    lvx 31,8,SP
+    addi 8,8,16
+    lvx 30,8,SP
+    addi 8,8,16
+    lvx 29,8,SP
+    addi 8,8,16
+    lvx 28,8,SP
+    addi 8,8,16
+    lvx 27,8,SP
+    addi 8,8,16
+    lvx 26,8,SP
+    addi 8,8,16
+    lvx 25,8,SP
+    addi 8,8,16
+    lvx 24,8,SP
+    addi 8,8,16
+    lvx 23,8,SP
+    addi 8,8,16
+    lvx 22,8,SP
+    addi 8,8,16
+    lvx 21,8,SP
+    addi 8,8,16
+    lvx 20,8,SP
+ ld 31,192(SP)
+ ld 30,200(SP)
+ ld 29,208(SP)
+ ld 28,216(SP)
+ addi SP,SP,224
+
+ clrldi   LENGTH,LENGTH,57
+L2x:
+ srdi 7,LENGTH,5
+ cmpldi 7,0
+ beq L1x
+
+ # table loading
+ li 8,0x300
+ li 9,0x400
+ li 10,0x500
+ lxvd2x H21hX,8,TABLE
+ lxvd2x H21X,9,TABLE
+ lxvd2x H21lX,10,TABLE
+
+ li 10,0x10
+
+ mtctr     7
+.align 5
+L2x_loop:
+ # input loading
+ lxvd2x C0X,0,DATA # load C0
+ lxvd2x C1X,10,DATA # load C1
+
+ # swap permuting
+ vperm C0,C0,C0,swap_mask
+ vperm C1,C1,C1,swap_mask
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ # polynomial multiplication "karatsuba" pre-processing
+ vperm C01h,C0,C1,hidw_mask
+ vperm C01l,C0,C1,lodw_mask
+ vxor C01,C01h,C01l
+
+ # polynomial multiplication "karatsuba"
+ vpmsumd C01h,C01h,H21h # H01 = H^2h*C0h⊕H^1h*C1h
+ vpmsumd C01l,C01l,H21l # L01 = H^2l*C0l⊕H^1l*C1l
+ vpmsumd C01,C01,H21 # M01 = (H^2h⊕H^1h)*(C0h⊕C1h)⊕(H^2l⊕H^1l)*(C0l⊕C1l)
+
+ # polynomial multiplication "karatsuba" post-processing
+ vxor C01,C01,C01h
+ vxor C01,C01,C01l
+
+ # reduction first phase # [1]
+ vpmsumd RP,C01l,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,C01,8   # [2]
+ vsldoi Ml,C01,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor C01h,C01h,Mh     # [2]
+ vxor C01l,C01l,Ml     # [2]
+ vxor C01l,C01l,RP     # [1]
+
+ # reduction second phase
+ vpmsumd RP,C01l,poly_l
+ vxor C01h,C01l,C01h
+ vxor C,C01h,RP
+
+ addi DATA,DATA,0x20
+ bdnz L2x_loop
+
+ clrldi   LENGTH,LENGTH,59
+L1x:
+ srdi 7,LENGTH,4
+ cmpldi 7,0
+ beq Lrem
+
+ # table loading
+ li 9,0x100
+ li 10,0x200
+ lxvd2x HlX,0,TABLE
+ lxvd2x HX, 9,TABLE
+ lxvd2x HhX,10,TABLE
+
+ # input loading
+ lxvd2x C0X,0,DATA # load C0
+
+ # swap permuting
+ vperm C0,C0,C0,swap_mask
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ vpmsumd Cl,C0,Hl # L = Hl*Cl
+ vpmsumd Cm,C0,H # M = Hh*Cl⊕Hl*Ch
+ vpmsumd Ch,C0,Hh # H = Hh*Ch
+
+ # reduction first phase # [1]
+ vpmsumd RP,Cl,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,Cm,8   # [2]
+ vsldoi Ml,Cm,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor Ch,Ch,Mh   # [2]
+ vxor Cl,Cl,Ml       # [2]
+ vxor Cl,Cl,RP   # [1]
+
+ # reduction second phase
+ vpmsumd RP,Cl,poly_l
+ vxor Ch,Cl,Ch
+ vxor C,Ch,RP
+
+ addi DATA,DATA,0x10
+ clrldi   LENGTH,LENGTH,60
+Lrem:
+ cmpldi LENGTH,0
+ beq Ldone
+
+ # table loading
+ li 9,0x100
+ li 10,0x200
+ lxvd2x HlX,0,TABLE
+ lxvd2x HX, 9,TABLE
+ lxvd2x HhX,10,TABLE
+
+ # input loading
+ stdu SP,-16(SP)
+ stvx zero,0,SP
+Lst_loop:
+ subic.      LENGTH,LENGTH,1
+ lbzx 7,LENGTH,DATA
+ stbx 7,LENGTH,SP
+ bne Lst_loop
+ lxvd2x   C0X,0,SP
+ addi SP,SP,16
+
+ # swap permuting
+ vperm C0,C0,C0,swap_mask
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ vpmsumd Cl,C0,Hl # L = Hl*Cl
+ vpmsumd Cm,C0,H # M = Hh*Cl⊕Hl*Ch
+ vpmsumd Ch,C0,Hh # H = Hh*Ch
+
+ # reduction first phase # [1]
+ vpmsumd RP,Cl,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,Cm,8   # [2]
+ vsldoi Ml,Cm,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor Ch,Ch,Mh   # [2]
+ vxor Cl,Cl,Ml     # [2]
+ vxor Cl,Cl,RP   # [1]
+
+ # reduction second phase
+ vpmsumd RP,Cl,poly_l
+ vxor Ch,Cl,Ch
+ vxor C,Ch,RP
+
+Ldone:
+ vperm C,C,C,swap_mask
+ stxvd2x CX,0,X # store C
+ blr
+EPILOGUE(_nettle_gcm_hash8)
+
+ # gcm_fill (uint8_t *ctr, size_t blocks, union gcm_block *buffer)
+
+.align 5
+PROLOGUE(_nettle_gcm_fill)
+  ld     6,.swap_mask@got(TOCP)
+  lvx   swap_mask,0,6
+
+  vxor zero,zero,zero
+  vspltisb I1,1
+  vspltisb I2,2
+  vspltisb I3,3
+  vspltisb I4,4
+  vspltisb I5,5
+  vspltisb I6,6
+  vspltisb I7,7
+  vspltisb I8,8
+  vsldoi I1,zero,I1,1
+  vsldoi I2,zero,I2,1
+  vsldoi I3,zero,I3,1
+  vsldoi I4,zero,I4,1
+  vsldoi I5,zero,I5,1
+  vsldoi I6,zero,I6,1
+  vsldoi I7,zero,I7,1
+  vsldoi I8,zero,I8,1
+
+  lxvd2x CTR0X,0,CTR
+  vperm CTR0,CTR0,CTR0,swap_mask
+
+  srdi      6,BLOCKS,3              # 8x loop count
+  cmpldi 6,0
+  beq       Lfill_4x
+
+  std       25,-56(SP);
+  std       26,-48(SP);
+  std       27,-40(SP);
+  std       28,-32(SP);
+  std       29,-24(SP);
+  std       30,-16(SP);
+  std       31,-8(SP);
+
+  li        25,0x10
+  li        26,0x20
+  li        27,0x30
+  li        28,0x40
+  li        29,0x50
+  li        30,0x60
+  li        31,0x70
+
+  mtctr     6
+L8x_fill_loop:
+  vadduwm CTR1,CTR0,I1
+  vadduwm CTR2,CTR0,I2
+  vadduwm CTR3,CTR0,I3
+  vadduwm CTR4,CTR0,I4
+  vadduwm CTR5,CTR0,I5
+  vadduwm CTR6,CTR0,I6
+  vadduwm CTR7,CTR0,I7
+
+  vperm CTR0S,CTR0,CTR0,swap_mask
+  vperm CTR1,CTR1,CTR1,swap_mask
+  vperm CTR2,CTR2,CTR2,swap_mask
+  vperm CTR3,CTR3,CTR3,swap_mask
+  vperm CTR4,CTR4,CTR4,swap_mask
+  vperm CTR5,CTR5,CTR5,swap_mask
+  vperm CTR6,CTR6,CTR6,swap_mask
+  vperm CTR7,CTR7,CTR7,swap_mask
+
+  stxvd2x CTR0SX,0,BUFFER
+  stxvd2x CTR1X,25,BUFFER
+  stxvd2x CTR2X,26,BUFFER
+  stxvd2x CTR3X,27,BUFFER
+  stxvd2x CTR4X,28,BUFFER
+  stxvd2x CTR5X,29,BUFFER
+  stxvd2x CTR6X,30,BUFFER
+  stxvd2x CTR7X,31,BUFFER
+
+  vadduwm CTR0,CTR0,I8
+  addi BUFFER,BUFFER,0x80
+  bdnz      L8x_fill_loop
+
+  ld        25,-56(SP);
+  ld        26,-48(SP);
+  ld        27,-40(SP);
+  ld        28,-32(SP);
+  ld        29,-24(SP);
+  ld        30,-16(SP);
+  ld        31,-8(SP);
+
+  clrldi   BLOCKS,BLOCKS,61
+
+Lfill_4x:
+  srdi      6,BLOCKS,2
+  cmpldi 6,0
+  beq       Lfill_2x
+
+  li        8,0x10
+  li        9,0x20
+  li        10,0x30
+
+  vadduwm CTR1,CTR0,I1
+  vadduwm CTR2,CTR0,I2
+  vadduwm CTR3,CTR0,I3
+
+  vperm CTR0S,CTR0,CTR0,swap_mask
+  vperm CTR1,CTR1,CTR1,swap_mask
+  vperm CTR2,CTR2,CTR2,swap_mask
+  vperm CTR3,CTR3,CTR3,swap_mask
+
+  stxvd2x CTR0SX,0,BUFFER
+  stxvd2x CTR1X,8,BUFFER
+  stxvd2x CTR2X,9,BUFFER
+  stxvd2x CTR3X,10,BUFFER
+
+  vadduwm CTR0,CTR0,I4
+  addi BUFFER,BUFFER,0x40
+
+  clrldi   BLOCKS,BLOCKS,62
+
+Lfill_2x:
+  srdi      6,BLOCKS,1
+  cmpldi 6,0
+  beq       Lfill_1x
+
+  li        10,0x10
+
+  vadduwm CTR1,CTR0,I1
+
+  vperm CTR0S,CTR0,CTR0,swap_mask
+  vperm CTR1,CTR1,CTR1,swap_mask
+
+  stxvd2x CTR0SX,0,BUFFER
+  stxvd2x CTR1X,10,BUFFER
+
+  vadduwm CTR0,CTR0,I2
+  addi BUFFER,BUFFER,0x20
+
+  clrldi   BLOCKS,BLOCKS,63
+
+Lfill_1x:
+  cmpldi BLOCKS,0
+  beq       Lfill_done
+
+  vperm CTR0S,CTR0,CTR0,swap_mask
+
+  stxvd2x CTR0SX,0,BUFFER
+
+  vadduwm CTR0,CTR0,I1
+
+Lfill_done:
+  vperm CTR0,CTR0,CTR0,swap_mask
+  stxvd2x CTR0X,0,CTR
+
+  blr
+EPILOGUE(_nettle_gcm_fill)
+
+    .data
+    .align 4
+.polynomial:
+ .byte 1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0xc2
+    .align 4
+.swap_mask:
+ .byte 8,9,10,11,12,13,14,15,0,1,2,3,4,5,6,7
+    .align 4
+.hidw_mask:
+ .byte 23,22,21,20,19,18,17,16,7,6,5,4,3,2,1,0
+    .align 4
+.lodw_mask:
+ .byte 31,30,29,28,27,26,25,24,15,14,13,12,11,10,9,8
diff --git a/powerpc64le/machine.m4 b/powerpc64le/machine.m4
new file mode 100644
index 00000000..e69de29b
diff --git a/testsuite/gcm-test.c b/testsuite/gcm-test.c
index c8174019..df1fc94a 100644
--- a/testsuite/gcm-test.c
+++ b/testsuite/gcm-test.c
@@ -170,6 +170,29 @@ test_main(void)
  "16aedbf5a0de6a57a637b39b"),
     SHEX("619cc5aefffe0bfa462af43c1699d050"));

+  /* Test 128 bytes */
+  test_aead(&amp;nettle_gcm_aes128, NULL,
+    SHEX("feffe9928665731c6d6a8f9467308308"),
+    SHEX(""),
+    SHEX("d9313225f88406e5a55909c5aff5269a"
+ "86a7a9531534f7da2e4c303d8a318a72"
+ "1c3c0c95956809532fcf0e2449a6b525"
+ "b16aedf5aa0de657ba637b391aafd255"
+ "5ae376bc5e9f6a1b08e34db7a6ee0736"
+ "9ba662ea12f6f197e6bc3ed69d2480f3"
+ "ea5691347f2ba69113eb37910ebc18c8"
+ "0f697234582016fa956ca8f63ae6b473"),
+    SHEX("42831ec2217774244b7221b784d0d49c"
+ "e3aa212f2c02a4e035c17e2329aca12e"
+ "21d514b25466931c7d8f6a5aac84aa05"
+ "1ba30b396a0aac973d58e091473f5985"
+ "874b1178906ddbeab04ab2fe6cce8c57"
+ "8d7e961bd13fd6a8c56b66ca5e576492"
+ "1a48cd8bda04e66343e73055118b69b9"
+ "ced486813846958a11e602c03cfc232b"),
+    SHEX("cafebabefacedbaddecaf888"),
+    SHEX("796836f1246c9d735c5e1be0a715ccc3"));
+
   /* Test case 7 */
   test_aead(&amp;nettle_gcm_aes192, NULL,
     SHEX("00000000000000000000000000000000"
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200619110916</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-06-19 11:09:16-0400</timestampReceived><subject>[PATCH] optimizing AES and GHASH for PPC64LE</subject><body>

 Makefile.in                          |   2 +-
 configure.ac                         |   5 +
 gcm.c                                |  19 +-
 powerpc64le/aes-decrypt-internal.asm | 573 ++++++++++++++++++++
 powerpc64le/aes-encrypt-internal.asm | 534 +++++++++++++++++++
 powerpc64le/gcm-hash8.asm            | 992
+++++++++++++++++++++++++++++++++++
 powerpc64le/machine.m4               |   0
 testsuite/gcm-test.c                 |  23 +
 8 files changed, 2146 insertions(+), 2 deletions(-)
 create mode 100644 powerpc64le/aes-decrypt-internal.asm
 create mode 100644 powerpc64le/aes-encrypt-internal.asm
 create mode 100644 powerpc64le/gcm-hash8.asm
 create mode 100644 powerpc64le/machine.m4

diff --git a/Makefile.in b/Makefile.in
index 64ff1001..5bbc0f79 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -603,7 +603,7 @@ distdir: $(DISTFILES)
  done
  set -e; for d in sparc32 sparc64 x86 \
  x86_64 x86_64/aesni x86_64/sha_ni x86_64/fat \
- arm arm/neon arm/v6 arm/fat ; do \
+ arm arm/neon arm/v6 arm/fat powerpc64le ; do \
   mkdir "$(distdir)/$$d" ; \
   find "$(srcdir)/$$d" -maxdepth 1 '(' -name '*.asm' -o -name '*.m4' ')' \
     -exec cp '{}' "$(distdir)/$$d" ';' ; \
diff --git a/configure.ac b/configure.ac
index 90ea1ea8..1ea54ce8 100644
--- a/configure.ac
+++ b/configure.ac
@@ -435,6 +435,9 @@ if test "x$enable_assembler" = xyes ; then
  esac
       fi
       ;;
+    *powerpc64le*)
+  asm_path=powerpc64le
+      ;;
     *)
       enable_assembler=no
       ;;
@@ -572,7 +575,9 @@ AH_VERBATIM([HAVE_NATIVE],
 #undef HAVE_NATIVE_ecc_secp384r1_redc
 #undef HAVE_NATIVE_ecc_secp521r1_modp
 #undef HAVE_NATIVE_ecc_secp521r1_redc
+#undef HAVE_NATIVE_gcm_init_key8
 #undef HAVE_NATIVE_gcm_hash8
+#undef HAVE_NATIVE_gcm_fill
 #undef HAVE_NATIVE_salsa20_core
 #undef HAVE_NATIVE_sha1_compress
 #undef HAVE_NATIVE_sha256_compress
diff --git a/gcm.c b/gcm.c
index cf615daf..809c03bc 100644
--- a/gcm.c
+++ b/gcm.c
@@ -140,6 +140,12 @@ gcm_gf_mul (union nettle_block16 *x, const union
nettle_block16 *table)
   memcpy (x-&gt;b, Z.b, sizeof(Z));
 }
 # elif GCM_TABLE_BITS == 8
+#  if HAVE_NATIVE_gcm_init_key8
+
+#define gcm_init_key _nettle_gcm_init_key8
+void
+_nettle_gcm_init_key8 (union nettle_block16 *table);
+#  endif /* HAVE_NATIVE_gcm_init_key8 */
 #  if HAVE_NATIVE_gcm_hash8

 #define gcm_hash _nettle_gcm_hash8
@@ -225,6 +231,13 @@ gcm_gf_mul (union nettle_block16 *x, const union
nettle_block16 *table)

 #endif /* GCM_TABLE_BITS */

+#if HAVE_NATIVE_gcm_fill
+
+#define gcm_fill _nettle_gcm_fill
+void
+_nettle_gcm_fill (uint8_t *ctr, size_t blocks, union nettle_block16
*buffer);
+#endif /* HAVE_NATIVE_gcm_fill */
+
 /* Increment the rightmost 32 bits. */
 #define INC32(block) INCREMENT(4, (block.b) + GCM_BLOCK_SIZE - 4)

@@ -245,7 +258,9 @@ gcm_set_key(struct gcm_key *key,
   memset(key-&gt;h[0].b, 0, GCM_BLOCK_SIZE);
   f (cipher, GCM_BLOCK_SIZE, key-&gt;h[i].b, key-&gt;h[0].b);

-#if GCM_TABLE_BITS
+#ifdef gcm_init_key
+  gcm_init_key(key-&gt;h);
+#elif GCM_TABLE_BITS
   /* Algorithm 3 from the gcm paper. First do powers of two, then do
      the rest by adding. */
   while (i /= 2)
@@ -333,6 +348,7 @@ gcm_update(struct gcm_ctx *ctx, const struct gcm_key
*key,
   ctx-&gt;auth_size += length;
 }

+#ifndef gcm_fill
 static nettle_fill16_func gcm_fill;
 static void
 gcm_fill(uint8_t *ctr, size_t blocks, union nettle_block16 *buffer)
@@ -349,6 +365,7 @@ gcm_fill(uint8_t *ctr, size_t blocks, union
nettle_block16 *buffer)

   WRITE_UINT32(ctr + GCM_BLOCK_SIZE - 4, c);
 }
+#endif /* !gcm_fill */

 void
 gcm_encrypt (struct gcm_ctx *ctx, const struct gcm_key *key,
diff --git a/powerpc64le/aes-decrypt-internal.asm
b/powerpc64le/aes-decrypt-internal.asm
new file mode 100644
index 00000000..bde34779
--- /dev/null
+++ b/powerpc64le/aes-decrypt-internal.asm
@@ -0,0 +1,573 @@
+C powerpc64le/aes-decrypt-internal.asm
+
+ifelse(&lt;
+   Copyright (C) 2020 Mamone Tarsha
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+&gt;)
+
+C Register usage:
+
+define(&lt;SP&gt;, &lt;1&gt;)
+define(&lt;TOCP&gt;, &lt;2&gt;)
+
+define(&lt;ROUNDS&gt;, &lt;3&gt;)
+define(&lt;KEYS&gt;, &lt;4&gt;)
+define(&lt;LENGTH&gt;, &lt;6&gt;)
+define(&lt;DST&gt;, &lt;7&gt;)
+define(&lt;SRC&gt;, &lt;8&gt;)
+
+define(&lt;swap_mask&gt;, &lt;0&gt;)
+
+define(&lt;K&gt;, &lt;1&gt;)
+define(&lt;S0&gt;, &lt;2&gt;)
+define(&lt;S1&gt;, &lt;3&gt;)
+define(&lt;S2&gt;, &lt;4&gt;)
+define(&lt;S3&gt;, &lt;5&gt;)
+define(&lt;S4&gt;, &lt;6&gt;)
+define(&lt;S5&gt;, &lt;7&gt;)
+define(&lt;S6&gt;, &lt;8&gt;)
+define(&lt;S7&gt;, &lt;9&gt;)
+define(&lt;S8&gt;, &lt;10&gt;)
+define(&lt;S9&gt;, &lt;11&gt;)
+define(&lt;S10&gt;, &lt;12&gt;)
+define(&lt;S11&gt;, &lt;13&gt;)
+define(&lt;S12&gt;, &lt;14&gt;)
+define(&lt;S13&gt;, &lt;15&gt;)
+define(&lt;S14&gt;, &lt;16&gt;)
+define(&lt;S15&gt;, &lt;17&gt;)
+
+define(&lt;KX&gt;, &lt;33&gt;)
+define(&lt;S0X&gt;, &lt;34&gt;)
+define(&lt;S1X&gt;, &lt;35&gt;)
+define(&lt;S2X&gt;, &lt;36&gt;)
+define(&lt;S3X&gt;, &lt;37&gt;)
+define(&lt;S4X&gt;, &lt;38&gt;)
+define(&lt;S5X&gt;, &lt;39&gt;)
+define(&lt;S6X&gt;, &lt;40&gt;)
+define(&lt;S7X&gt;, &lt;41&gt;)
+define(&lt;S8X&gt;, &lt;42&gt;)
+define(&lt;S9X&gt;, &lt;43&gt;)
+define(&lt;S10X&gt;, &lt;44&gt;)
+define(&lt;S11X&gt;, &lt;45&gt;)
+define(&lt;S12X&gt;, &lt;46&gt;)
+define(&lt;S13X&gt;, &lt;47&gt;)
+define(&lt;S14X&gt;, &lt;48&gt;)
+define(&lt;S15X&gt;, &lt;49&gt;)
+
+C ZERO vector register is used in place of RoundKey
+C for vncipher instruction because the order of InvMixColumns
+C and Xor processes are flipped in that instruction.
+C The Xor process with RoundKey is executed afterward.
+define(&lt;ZERO&gt;, &lt;18&gt;)
+
+ .file "aes-decrypt-internal.asm"
+
+ C _aes_decrypt(unsigned rounds, const uint32_t *keys,
+ C       const struct aes_table *T,
+ C       size_t length, uint8_t *dst,
+ C       uint8_t *src)
+
+ .text
+.align 5
+PROLOGUE(_nettle_aes_decrypt)
+  vxor      ZERO,ZERO,ZERO
+
+  ld     5,.swap_mask@got(TOCP)
+ lvx   swap_mask,0,5
+
+  subi      ROUNDS,ROUNDS,1
+  srdi      LENGTH,LENGTH,4
+
+  srdi      5,LENGTH,4              # 16x loop count
+  cmpldi 5,0
+  beq       L8x
+
+  std       17,-120(SP);
+  std       18,-112(SP);
+  std       19,-104(SP);
+  std       20,-96(SP);
+  std       21,-88(SP);
+  std       22,-80(SP);
+  std       23,-72(SP);
+  std       24,-64(SP);
+  std       25,-56(SP);
+  std       26,-48(SP);
+  std       27,-40(SP);
+  std       28,-32(SP);
+  std       29,-24(SP);
+  std       30,-16(SP);
+  std       31,-8(SP);
+
+  li        17,0x10
+  li        18,0x20
+  li        19,0x30
+  li        20,0x40
+  li        21,0x50
+  li        22,0x60
+  li        23,0x70
+  li        24,0x80
+  li        25,0x90
+  li        26,0xA0
+  li        27,0xB0
+  li        28,0xC0
+  li        29,0xD0
+  li        30,0xE0
+  li        31,0xF0
+
+.align 5
+Lx16_loop:
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+  lxvd2x S1X,17,SRC
+  lxvd2x S2X,18,SRC
+  lxvd2x S3X,19,SRC
+  lxvd2x S4X,20,SRC
+  lxvd2x S5X,21,SRC
+  lxvd2x S6X,22,SRC
+  lxvd2x S7X,23,SRC
+  lxvd2x S8X,24,SRC
+  lxvd2x S9X,25,SRC
+  lxvd2x S10X,26,SRC
+  lxvd2x S11X,27,SRC
+  lxvd2x S12X,28,SRC
+  lxvd2x S13X,29,SRC
+  lxvd2x S14X,30,SRC
+  lxvd2x S15X,31,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+  vxor      S4,S4,K
+  vxor      S5,S5,K
+  vxor      S6,S6,K
+  vxor      S7,S7,K
+  vxor      S8,S8,K
+  vxor      S9,S9,K
+  vxor      S10,S10,K
+  vxor      S11,S11,K
+  vxor      S12,S12,K
+  vxor      S13,S13,K
+  vxor      S14,S14,K
+  vxor      S15,S15,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+  vperm  S4,S4,S4,swap_mask
+  vperm  S5,S5,S5,swap_mask
+  vperm  S6,S6,S6,swap_mask
+  vperm  S7,S7,S7,swap_mask
+  vperm  S8,S8,S8,swap_mask
+  vperm  S9,S9,S9,swap_mask
+  vperm  S10,S10,S10,swap_mask
+  vperm  S11,S11,S11,swap_mask
+  vperm  S12,S12,S12,swap_mask
+  vperm  S13,S13,S13,swap_mask
+  vperm  S14,S14,S14,swap_mask
+  vperm  S15,S15,S15,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L16x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vncipher   S0,S0,ZERO
+  vncipher   S1,S1,ZERO
+  vncipher   S2,S2,ZERO
+  vncipher   S3,S3,ZERO
+  vncipher   S4,S4,ZERO
+  vncipher   S5,S5,ZERO
+  vncipher   S6,S6,ZERO
+  vncipher   S7,S7,ZERO
+  vncipher   S8,S8,ZERO
+  vncipher   S9,S9,ZERO
+  vncipher   S10,S10,ZERO
+  vncipher   S11,S11,ZERO
+  vncipher   S12,S12,ZERO
+  vncipher   S13,S13,ZERO
+  vncipher   S14,S14,ZERO
+  vncipher   S15,S15,ZERO
+  vxor       S0,S0,K
+  vxor       S1,S1,K
+  vxor       S2,S2,K
+  vxor       S3,S3,K
+  vxor       S4,S4,K
+  vxor       S5,S5,K
+  vxor       S6,S6,K
+  vxor       S7,S7,K
+  vxor       S8,S8,K
+  vxor       S9,S9,K
+  vxor       S10,S10,K
+  vxor       S11,S11,K
+  vxor       S12,S12,K
+  vxor       S13,S13,K
+  vxor       S14,S14,K
+  vxor       S15,S15,K
+  addi      10,10,0x10
+  bdnz      L16x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vncipherlast   S0,S0,K
+  vncipherlast   S1,S1,K
+  vncipherlast   S2,S2,K
+  vncipherlast   S3,S3,K
+  vncipherlast   S4,S4,K
+  vncipherlast   S5,S5,K
+  vncipherlast   S6,S6,K
+  vncipherlast   S7,S7,K
+  vncipherlast   S8,S8,K
+  vncipherlast   S9,S9,K
+  vncipherlast   S10,S10,K
+  vncipherlast   S11,S11,K
+  vncipherlast   S12,S12,K
+  vncipherlast   S13,S13,K
+  vncipherlast   S14,S14,K
+  vncipherlast   S15,S15,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+  vperm  S4,S4,S4,swap_mask
+  vperm  S5,S5,S5,swap_mask
+  vperm  S6,S6,S6,swap_mask
+  vperm  S7,S7,S7,swap_mask
+  vperm  S8,S8,S8,swap_mask
+  vperm  S9,S9,S9,swap_mask
+  vperm  S10,S10,S10,swap_mask
+  vperm  S11,S11,S11,swap_mask
+  vperm  S12,S12,S12,swap_mask
+  vperm  S13,S13,S13,swap_mask
+  vperm  S14,S14,S14,swap_mask
+  vperm  S15,S15,S15,swap_mask
+
+  stxvd2x S0X,0,DST
+  stxvd2x S1X,17,DST
+  stxvd2x S2X,18,DST
+  stxvd2x S3X,19,DST
+  stxvd2x S4X,20,DST
+  stxvd2x S5X,21,DST
+  stxvd2x S6X,22,DST
+  stxvd2x S7X,23,DST
+  stxvd2x S8X,24,DST
+  stxvd2x S9X,25,DST
+  stxvd2x S10X,26,DST
+  stxvd2x S11X,27,DST
+  stxvd2x S12X,28,DST
+  stxvd2x S13X,29,DST
+  stxvd2x S14X,30,DST
+  stxvd2x S15X,31,DST
+
+  addi      SRC,SRC,0x100
+  addi      DST,DST,0x100
+  subic.    5,5,1
+  bne       Lx16_loop
+
+  ld        17,-120(SP);
+  ld        18,-112(SP);
+  ld        19,-104(SP);
+  ld        20,-96(SP);
+  ld        21,-88(SP);
+  ld        22,-80(SP);
+  ld        23,-72(SP);
+  ld        24,-64(SP);
+  ld        25,-56(SP);
+  ld        26,-48(SP);
+  ld        27,-40(SP);
+  ld        28,-32(SP);
+  ld        29,-24(SP);
+  ld        30,-16(SP);
+  ld        31,-8(SP);
+
+  clrldi   LENGTH,LENGTH,60
+
+L8x:
+  srdi      5,LENGTH,3
+  cmpldi 5,0
+  beq       L4x
+
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+  li        9,0x10
+  lxvd2x S1X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S2X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S3X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S4X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S5X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S6X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S7X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+  vxor      S4,S4,K
+  vxor      S5,S5,K
+  vxor      S6,S6,K
+  vxor      S7,S7,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+  vperm  S4,S4,S4,swap_mask
+  vperm  S5,S5,S5,swap_mask
+  vperm  S6,S6,S6,swap_mask
+  vperm  S7,S7,S7,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L8x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vncipher   S0,S0,ZERO
+  vncipher   S1,S1,ZERO
+  vncipher   S2,S2,ZERO
+  vncipher   S3,S3,ZERO
+  vncipher   S4,S4,ZERO
+  vncipher   S5,S5,ZERO
+  vncipher   S6,S6,ZERO
+  vncipher   S7,S7,ZERO
+  vxor       S0,S0,K
+  vxor       S1,S1,K
+  vxor       S2,S2,K
+  vxor       S3,S3,K
+  vxor       S4,S4,K
+  vxor       S5,S5,K
+  vxor       S6,S6,K
+  vxor       S7,S7,K
+  addi      10,10,0x10
+  bdnz      L8x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vncipherlast   S0,S0,K
+  vncipherlast   S1,S1,K
+  vncipherlast   S2,S2,K
+  vncipherlast   S3,S3,K
+  vncipherlast   S4,S4,K
+  vncipherlast   S5,S5,K
+  vncipherlast   S6,S6,K
+  vncipherlast   S7,S7,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+  vperm  S4,S4,S4,swap_mask
+  vperm  S5,S5,S5,swap_mask
+  vperm  S6,S6,S6,swap_mask
+  vperm  S7,S7,S7,swap_mask
+
+  stxvd2x S0X,0,DST
+  li        9,0x10
+  stxvd2x S1X,9,DST
+  addi      9,9,0x10
+  stxvd2x S2X,9,DST
+  addi      9,9,0x10
+  stxvd2x S3X,9,DST
+  addi      9,9,0x10
+  stxvd2x S4X,9,DST
+  addi      9,9,0x10
+  stxvd2x S5X,9,DST
+  addi      9,9,0x10
+  stxvd2x S6X,9,DST
+  addi      9,9,0x10
+  stxvd2x S7X,9,DST
+
+  addi      SRC,SRC,0x80
+  addi      DST,DST,0x80
+
+  clrldi   LENGTH,LENGTH,61
+
+L4x:
+  srdi      5,LENGTH,2
+  cmpldi 5,0
+  beq       L2x
+
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+  li        9,0x10
+  lxvd2x S1X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S2X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S3X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L4x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vncipher   S0,S0,ZERO
+  vncipher   S1,S1,ZERO
+  vncipher   S2,S2,ZERO
+  vncipher   S3,S3,ZERO
+  vxor       S0,S0,K
+  vxor       S1,S1,K
+  vxor       S2,S2,K
+  vxor       S3,S3,K
+  addi      10,10,0x10
+  bdnz      L4x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vncipherlast   S0,S0,K
+  vncipherlast   S1,S1,K
+  vncipherlast   S2,S2,K
+  vncipherlast   S3,S3,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+
+  stxvd2x S0X,0,DST
+  li        9,0x10
+  stxvd2x S1X,9,DST
+  addi      9,9,0x10
+  stxvd2x S2X,9,DST
+  addi      9,9,0x10
+  stxvd2x S3X,9,DST
+
+  addi      SRC,SRC,0x40
+  addi      DST,DST,0x40
+
+  clrldi   LENGTH,LENGTH,62
+
+L2x:
+  srdi      5,LENGTH,1
+  cmpldi 5,0
+  beq       L1x
+
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+  li        9,0x10
+  lxvd2x S1X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L2x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vncipher   S0,S0,ZERO
+  vncipher   S1,S1,ZERO
+  vxor       S0,S0,K
+  vxor       S1,S1,K
+  addi      10,10,0x10
+  bdnz      L2x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vncipherlast   S0,S0,K
+  vncipherlast   S1,S1,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+
+  stxvd2x S0X,0,DST
+  li        9,0x10
+  stxvd2x S1X,9,DST
+
+  addi      SRC,SRC,0x20
+  addi      DST,DST,0x20
+
+  clrldi   LENGTH,LENGTH,63
+
+L1x:
+  cmpldi LENGTH,0
+  beq       Ldone
+
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+
+  vxor      S0,S0,K
+
+  vperm  S0,S0,S0,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L1x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vncipher   S0,S0,ZERO
+  vxor       S0,S0,K
+  addi      10,10,0x10
+  bdnz      L1x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vncipherlast   S0,S0,K
+
+  vperm  S0,S0,S0,swap_mask
+
+  stxvd2x S0X,0,DST
+
+Ldone:
+  blr
+EPILOGUE(_nettle_aes_decrypt)
+
+  .data
+  .align 4
+.swap_mask:
+ .byte 8,9,10,11,12,13,14,15,0,1,2,3,4,5,6,7
diff --git a/powerpc64le/aes-encrypt-internal.asm
b/powerpc64le/aes-encrypt-internal.asm
new file mode 100644
index 00000000..1bbd86a8
--- /dev/null
+++ b/powerpc64le/aes-encrypt-internal.asm
@@ -0,0 +1,534 @@
+C powerpc64le/aes-encrypt-internal.asm
+
+ifelse(&lt;
+   Copyright (C) 2020 Mamone Tarsha
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+&gt;)
+
+C Register usage:
+
+define(&lt;SP&gt;, &lt;1&gt;)
+define(&lt;TOCP&gt;, &lt;2&gt;)
+
+define(&lt;ROUNDS&gt;, &lt;3&gt;)
+define(&lt;KEYS&gt;, &lt;4&gt;)
+define(&lt;LENGTH&gt;, &lt;6&gt;)
+define(&lt;DST&gt;, &lt;7&gt;)
+define(&lt;SRC&gt;, &lt;8&gt;)
+
+define(&lt;swap_mask&gt;, &lt;0&gt;)
+
+define(&lt;K&gt;, &lt;1&gt;)
+define(&lt;S0&gt;, &lt;2&gt;)
+define(&lt;S1&gt;, &lt;3&gt;)
+define(&lt;S2&gt;, &lt;4&gt;)
+define(&lt;S3&gt;, &lt;5&gt;)
+define(&lt;S4&gt;, &lt;6&gt;)
+define(&lt;S5&gt;, &lt;7&gt;)
+define(&lt;S6&gt;, &lt;8&gt;)
+define(&lt;S7&gt;, &lt;9&gt;)
+define(&lt;S8&gt;, &lt;10&gt;)
+define(&lt;S9&gt;, &lt;11&gt;)
+define(&lt;S10&gt;, &lt;12&gt;)
+define(&lt;S11&gt;, &lt;13&gt;)
+define(&lt;S12&gt;, &lt;14&gt;)
+define(&lt;S13&gt;, &lt;15&gt;)
+define(&lt;S14&gt;, &lt;16&gt;)
+define(&lt;S15&gt;, &lt;17&gt;)
+
+define(&lt;KX&gt;, &lt;33&gt;)
+define(&lt;S0X&gt;, &lt;34&gt;)
+define(&lt;S1X&gt;, &lt;35&gt;)
+define(&lt;S2X&gt;, &lt;36&gt;)
+define(&lt;S3X&gt;, &lt;37&gt;)
+define(&lt;S4X&gt;, &lt;38&gt;)
+define(&lt;S5X&gt;, &lt;39&gt;)
+define(&lt;S6X&gt;, &lt;40&gt;)
+define(&lt;S7X&gt;, &lt;41&gt;)
+define(&lt;S8X&gt;, &lt;42&gt;)
+define(&lt;S9X&gt;, &lt;43&gt;)
+define(&lt;S10X&gt;, &lt;44&gt;)
+define(&lt;S11X&gt;, &lt;45&gt;)
+define(&lt;S12X&gt;, &lt;46&gt;)
+define(&lt;S13X&gt;, &lt;47&gt;)
+define(&lt;S14X&gt;, &lt;48&gt;)
+define(&lt;S15X&gt;, &lt;49&gt;)
+
+ .file "aes-encrypt-internal.asm"
+
+ C _aes_encrypt(unsigned rounds, const uint32_t *keys,
+ C       const struct aes_table *T,
+ C       size_t length, uint8_t *dst,
+ C       uint8_t *src)
+
+ .text
+.align 5
+PROLOGUE(_nettle_aes_encrypt)
+  ld     5,.swap_mask@got(TOCP)
+ lvx   swap_mask,0,5
+
+  subi      ROUNDS,ROUNDS,1
+  srdi      LENGTH,LENGTH,4
+
+  srdi      5,LENGTH,4              # 16x loop count
+  cmpldi 5,0
+  beq       L8x
+
+  std       17,-120(SP);
+  std       18,-112(SP);
+  std       19,-104(SP);
+  std       20,-96(SP);
+  std       21,-88(SP);
+  std       22,-80(SP);
+  std       23,-72(SP);
+  std       24,-64(SP);
+  std       25,-56(SP);
+  std       26,-48(SP);
+  std       27,-40(SP);
+  std       28,-32(SP);
+  std       29,-24(SP);
+  std       30,-16(SP);
+  std       31,-8(SP);
+
+  li        17,0x10
+  li        18,0x20
+  li        19,0x30
+  li        20,0x40
+  li        21,0x50
+  li        22,0x60
+  li        23,0x70
+  li        24,0x80
+  li        25,0x90
+  li        26,0xA0
+  li        27,0xB0
+  li        28,0xC0
+  li        29,0xD0
+  li        30,0xE0
+  li        31,0xF0
+
+.align 5
+Lx16_loop:
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+  lxvd2x S1X,17,SRC
+  lxvd2x S2X,18,SRC
+  lxvd2x S3X,19,SRC
+  lxvd2x S4X,20,SRC
+  lxvd2x S5X,21,SRC
+  lxvd2x S6X,22,SRC
+  lxvd2x S7X,23,SRC
+  lxvd2x S8X,24,SRC
+  lxvd2x S9X,25,SRC
+  lxvd2x S10X,26,SRC
+  lxvd2x S11X,27,SRC
+  lxvd2x S12X,28,SRC
+  lxvd2x S13X,29,SRC
+  lxvd2x S14X,30,SRC
+  lxvd2x S15X,31,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+  vxor      S4,S4,K
+  vxor      S5,S5,K
+  vxor      S6,S6,K
+  vxor      S7,S7,K
+  vxor      S8,S8,K
+  vxor      S9,S9,K
+  vxor      S10,S10,K
+  vxor      S11,S11,K
+  vxor      S12,S12,K
+  vxor      S13,S13,K
+  vxor      S14,S14,K
+  vxor      S15,S15,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+  vperm  S4,S4,S4,swap_mask
+  vperm  S5,S5,S5,swap_mask
+  vperm  S6,S6,S6,swap_mask
+  vperm  S7,S7,S7,swap_mask
+  vperm  S8,S8,S8,swap_mask
+  vperm  S9,S9,S9,swap_mask
+  vperm  S10,S10,S10,swap_mask
+  vperm  S11,S11,S11,swap_mask
+  vperm  S12,S12,S12,swap_mask
+  vperm  S13,S13,S13,swap_mask
+  vperm  S14,S14,S14,swap_mask
+  vperm  S15,S15,S15,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L16x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vcipher   S0,S0,K
+  vcipher   S1,S1,K
+  vcipher   S2,S2,K
+  vcipher   S3,S3,K
+  vcipher   S4,S4,K
+  vcipher   S5,S5,K
+  vcipher   S6,S6,K
+  vcipher   S7,S7,K
+  vcipher   S8,S8,K
+  vcipher   S9,S9,K
+  vcipher   S10,S10,K
+  vcipher   S11,S11,K
+  vcipher   S12,S12,K
+  vcipher   S13,S13,K
+  vcipher   S14,S14,K
+  vcipher   S15,S15,K
+  addi      10,10,0x10
+  bdnz      L16x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vcipherlast   S0,S0,K
+  vcipherlast   S1,S1,K
+  vcipherlast   S2,S2,K
+  vcipherlast   S3,S3,K
+  vcipherlast   S4,S4,K
+  vcipherlast   S5,S5,K
+  vcipherlast   S6,S6,K
+  vcipherlast   S7,S7,K
+  vcipherlast   S8,S8,K
+  vcipherlast   S9,S9,K
+  vcipherlast   S10,S10,K
+  vcipherlast   S11,S11,K
+  vcipherlast   S12,S12,K
+  vcipherlast   S13,S13,K
+  vcipherlast   S14,S14,K
+  vcipherlast   S15,S15,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+  vperm  S4,S4,S4,swap_mask
+  vperm  S5,S5,S5,swap_mask
+  vperm  S6,S6,S6,swap_mask
+  vperm  S7,S7,S7,swap_mask
+  vperm  S8,S8,S8,swap_mask
+  vperm  S9,S9,S9,swap_mask
+  vperm  S10,S10,S10,swap_mask
+  vperm  S11,S11,S11,swap_mask
+  vperm  S12,S12,S12,swap_mask
+  vperm  S13,S13,S13,swap_mask
+  vperm  S14,S14,S14,swap_mask
+  vperm  S15,S15,S15,swap_mask
+
+  stxvd2x S0X,0,DST
+  stxvd2x S1X,17,DST
+  stxvd2x S2X,18,DST
+  stxvd2x S3X,19,DST
+  stxvd2x S4X,20,DST
+  stxvd2x S5X,21,DST
+  stxvd2x S6X,22,DST
+  stxvd2x S7X,23,DST
+  stxvd2x S8X,24,DST
+  stxvd2x S9X,25,DST
+  stxvd2x S10X,26,DST
+  stxvd2x S11X,27,DST
+  stxvd2x S12X,28,DST
+  stxvd2x S13X,29,DST
+  stxvd2x S14X,30,DST
+  stxvd2x S15X,31,DST
+
+  addi      SRC,SRC,0x100
+  addi      DST,DST,0x100
+  subic.    5,5,1
+  bne       Lx16_loop
+
+  ld        17,-120(SP);
+  ld        18,-112(SP);
+  ld        19,-104(SP);
+  ld        20,-96(SP);
+  ld        21,-88(SP);
+  ld        22,-80(SP);
+  ld        23,-72(SP);
+  ld        24,-64(SP);
+  ld        25,-56(SP);
+  ld        26,-48(SP);
+  ld        27,-40(SP);
+  ld        28,-32(SP);
+  ld        29,-24(SP);
+  ld        30,-16(SP);
+  ld        31,-8(SP);
+
+  clrldi   LENGTH,LENGTH,60
+
+L8x:
+  srdi      5,LENGTH,3
+  cmpldi 5,0
+  beq       L4x
+
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+  li        9,0x10
+  lxvd2x S1X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S2X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S3X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S4X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S5X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S6X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S7X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+  vxor      S4,S4,K
+  vxor      S5,S5,K
+  vxor      S6,S6,K
+  vxor      S7,S7,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+  vperm  S4,S4,S4,swap_mask
+  vperm  S5,S5,S5,swap_mask
+  vperm  S6,S6,S6,swap_mask
+  vperm  S7,S7,S7,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L8x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vcipher   S0,S0,K
+  vcipher   S1,S1,K
+  vcipher   S2,S2,K
+  vcipher   S3,S3,K
+  vcipher   S4,S4,K
+  vcipher   S5,S5,K
+  vcipher   S6,S6,K
+  vcipher   S7,S7,K
+  addi      10,10,0x10
+  bdnz      L8x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vcipherlast   S0,S0,K
+  vcipherlast   S1,S1,K
+  vcipherlast   S2,S2,K
+  vcipherlast   S3,S3,K
+  vcipherlast   S4,S4,K
+  vcipherlast   S5,S5,K
+  vcipherlast   S6,S6,K
+  vcipherlast   S7,S7,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+  vperm  S4,S4,S4,swap_mask
+  vperm  S5,S5,S5,swap_mask
+  vperm  S6,S6,S6,swap_mask
+  vperm  S7,S7,S7,swap_mask
+
+  stxvd2x S0X,0,DST
+  li        9,0x10
+  stxvd2x S1X,9,DST
+  addi      9,9,0x10
+  stxvd2x S2X,9,DST
+  addi      9,9,0x10
+  stxvd2x S3X,9,DST
+  addi      9,9,0x10
+  stxvd2x S4X,9,DST
+  addi      9,9,0x10
+  stxvd2x S5X,9,DST
+  addi      9,9,0x10
+  stxvd2x S6X,9,DST
+  addi      9,9,0x10
+  stxvd2x S7X,9,DST
+
+  addi      SRC,SRC,0x80
+  addi      DST,DST,0x80
+
+  clrldi   LENGTH,LENGTH,61
+
+L4x:
+  srdi      5,LENGTH,2
+  cmpldi 5,0
+  beq       L2x
+
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+  li        9,0x10
+  lxvd2x S1X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S2X,9,SRC
+  addi      9,9,0x10
+  lxvd2x S3X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+  vxor      S2,S2,K
+  vxor      S3,S3,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L4x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vcipher   S0,S0,K
+  vcipher   S1,S1,K
+  vcipher   S2,S2,K
+  vcipher   S3,S3,K
+  addi      10,10,0x10
+  bdnz      L4x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vcipherlast   S0,S0,K
+  vcipherlast   S1,S1,K
+  vcipherlast   S2,S2,K
+  vcipherlast   S3,S3,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+  vperm  S2,S2,S2,swap_mask
+  vperm  S3,S3,S3,swap_mask
+
+  stxvd2x S0X,0,DST
+  li        9,0x10
+  stxvd2x S1X,9,DST
+  addi      9,9,0x10
+  stxvd2x S2X,9,DST
+  addi      9,9,0x10
+  stxvd2x S3X,9,DST
+
+  addi      SRC,SRC,0x40
+  addi      DST,DST,0x40
+
+  clrldi   LENGTH,LENGTH,62
+
+L2x:
+  srdi      5,LENGTH,1
+  cmpldi 5,0
+  beq       L1x
+
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+  li        9,0x10
+  lxvd2x S1X,9,SRC
+
+  vxor      S0,S0,K
+  vxor      S1,S1,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L2x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vcipher   S0,S0,K
+  vcipher   S1,S1,K
+  addi      10,10,0x10
+  bdnz      L2x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vcipherlast   S0,S0,K
+  vcipherlast   S1,S1,K
+
+  vperm  S0,S0,S0,swap_mask
+  vperm  S1,S1,S1,swap_mask
+
+  stxvd2x S0X,0,DST
+  li        9,0x10
+  stxvd2x S1X,9,DST
+
+  addi      SRC,SRC,0x20
+  addi      DST,DST,0x20
+
+  clrldi   LENGTH,LENGTH,63
+
+L1x:
+  cmpldi LENGTH,0
+  beq       Ldone
+
+  lxvd2x KX,0,KEYS
+
+  lxvd2x S0X,0,SRC
+
+  vxor      S0,S0,K
+
+  vperm  S0,S0,S0,swap_mask
+
+  mtctr     ROUNDS
+  li        10,0x10
+.align 5
+L1x_round_loop:
+  lxvd2x KX,10,KEYS
+ vperm  K,K,K,swap_mask
+  vcipher   S0,S0,K
+  addi      10,10,0x10
+  bdnz      L1x_round_loop
+
+  lxvd2x    KX,10,KEYS
+ vperm      K,K,K,swap_mask
+  vcipherlast   S0,S0,K
+
+  vperm  S0,S0,S0,swap_mask
+
+  stxvd2x S0X,0,DST
+
+Ldone:
+  blr
+EPILOGUE(_nettle_aes_encrypt)
+
+  .data
+  .align 4
+.swap_mask:
+ .byte 8,9,10,11,12,13,14,15,0,1,2,3,4,5,6,7
diff --git a/powerpc64le/gcm-hash8.asm b/powerpc64le/gcm-hash8.asm
new file mode 100644
index 00000000..a809f6ef
--- /dev/null
+++ b/powerpc64le/gcm-hash8.asm
@@ -0,0 +1,992 @@
+C powerpc64le/gcm-hash8.asm
+
+ifelse(&lt;
+   Copyright (C) 2020 Mamone Tarsha
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+&gt;)
+
+C Register usage:
+C VSX instructions is used to load and store data to memory "lxvd2x,
stxvd2x"
+C instead of VR instructions "lvx, stvx" as a workaround to access
unaligned data
+C VSX registers are defined with "X" suffix
+
+define(&lt;SP&gt;, &lt;1&gt;)
+define(&lt;TOCP&gt;, &lt;2&gt;)
+
+define(&lt;TABLE&gt;, &lt;3&gt;)
+define(&lt;X&gt;, &lt;4&gt;)
+define(&lt;LENGTH&gt;, &lt;5&gt;)
+define(&lt;DATA&gt;, &lt;6&gt;)
+
+define(&lt;zero&gt;, &lt;0&gt;)
+define(&lt;swap_mask&gt;, &lt;1&gt;)
+define(&lt;hidw_mask&gt;, &lt;2&gt;)
+define(&lt;lodw_mask&gt;, &lt;3&gt;)
+define(&lt;poly&gt;, &lt;4&gt;)
+define(&lt;poly_h&gt;, &lt;4&gt;)
+define(&lt;poly_l&gt;, &lt;5&gt;)
+define(&lt;RP&gt;, &lt;6&gt;)
+define(&lt;Mh&gt;, &lt;7&gt;)
+define(&lt;Ml&gt;, &lt;8&gt;)
+define(&lt;H&gt;, &lt;9&gt;)
+define(&lt;Hh&gt;, &lt;10&gt;)
+define(&lt;Hl&gt;, &lt;11&gt;)
+define(&lt;RP2&gt;, &lt;9&gt;)
+define(&lt;M2h&gt;, &lt;10&gt;)
+define(&lt;M2l&gt;, &lt;11&gt;)
+
+define(&lt;HX&gt;, &lt;41&gt;)
+define(&lt;HhX&gt;, &lt;42&gt;)
+define(&lt;HlX&gt;, &lt;43&gt;)
+define(&lt;H_HhX&gt;, &lt;44&gt;)
+define(&lt;H_HX&gt;, &lt;45&gt;)
+define(&lt;H_HlX&gt;, &lt;46&gt;)
+
+define(&lt;sl1&gt;, &lt;1&gt;)
+define(&lt;msb&gt;, &lt;5&gt;)
+define(&lt;H2&gt;, &lt;6&gt;)
+define(&lt;H2h&gt;, &lt;7&gt;)
+define(&lt;H2l&gt;, &lt;8&gt;)
+define(&lt;H_h&gt;, &lt;12&gt;)
+define(&lt;H_m&gt;, &lt;13&gt;)
+define(&lt;H_l&gt;, &lt;14&gt;)
+define(&lt;H_Hh&gt;, &lt;12&gt;)
+define(&lt;H_H&gt;, &lt;13&gt;)
+define(&lt;H_Hl&gt;, &lt;14&gt;)
+define(&lt;H_t&gt;, &lt;15&gt;)
+define(&lt;H2_h&gt;, &lt;16&gt;)
+define(&lt;H2_m&gt;, &lt;17&gt;)
+define(&lt;H2_l&gt;, &lt;18&gt;)
+define(&lt;H2_t&gt;, &lt;19&gt;)
+
+define(&lt;C0X&gt;, &lt;38&gt;)
+define(&lt;C1X&gt;, &lt;39&gt;)
+define(&lt;C2X&gt;, &lt;40&gt;)
+define(&lt;C3X&gt;, &lt;44&gt;)
+define(&lt;C4X&gt;, &lt;38&gt;)
+define(&lt;C5X&gt;, &lt;39&gt;)
+define(&lt;C6X&gt;, &lt;40&gt;)
+define(&lt;C7X&gt;, &lt;44&gt;)
+
+define(&lt;CX&gt;, &lt;45&gt;)
+
+define(&lt;C0&gt;, &lt;6&gt;)
+define(&lt;C1&gt;, &lt;7&gt;)
+define(&lt;C2&gt;, &lt;8&gt;)
+define(&lt;C3&gt;, &lt;12&gt;)
+define(&lt;C4&gt;, &lt;6&gt;)
+define(&lt;C5&gt;, &lt;7&gt;)
+define(&lt;C6&gt;, &lt;8&gt;)
+define(&lt;C7&gt;, &lt;12&gt;)
+
+define(&lt;C&gt;, &lt;13&gt;)
+
+define(&lt;Ch&gt;, &lt;14&gt;)
+define(&lt;Cl&gt;, &lt;15&gt;)
+define(&lt;Cm&gt;, &lt;16&gt;)
+
+define(&lt;C01h&gt;, &lt;14&gt;)
+define(&lt;C01l&gt;, &lt;15&gt;)
+define(&lt;C01&gt;, &lt;16&gt;)
+define(&lt;C23h&gt;, &lt;17&gt;)
+define(&lt;C23l&gt;, &lt;18&gt;)
+define(&lt;C23&gt;, &lt;19&gt;)
+define(&lt;C45h&gt;, &lt;20&gt;)
+define(&lt;C45l&gt;, &lt;21&gt;)
+define(&lt;C45&gt;, &lt;22&gt;)
+define(&lt;C67h&gt;, &lt;6&gt;)
+define(&lt;C67l&gt;, &lt;7&gt;)
+define(&lt;C67&gt;, &lt;8&gt;)
+
+define(&lt;H21&gt;, &lt;9&gt;)
+define(&lt;H21h&gt;, &lt;10&gt;)
+define(&lt;H21l&gt;, &lt;11&gt;)
+define(&lt;H43&gt;, &lt;23&gt;)
+define(&lt;H43h&gt;, &lt;24&gt;)
+define(&lt;H43l&gt;, &lt;25&gt;)
+define(&lt;H65&gt;, &lt;26&gt;)
+define(&lt;H65h&gt;, &lt;27&gt;)
+define(&lt;H65l&gt;, &lt;28&gt;)
+define(&lt;H87&gt;, &lt;29&gt;)
+define(&lt;H87h&gt;, &lt;30&gt;)
+define(&lt;H87l&gt;, &lt;31&gt;)
+
+define(&lt;H21X&gt;, &lt;41&gt;)
+define(&lt;H21hX&gt;, &lt;42&gt;)
+define(&lt;H21lX&gt;, &lt;43&gt;)
+define(&lt;H43X&gt;, &lt;55&gt;)
+define(&lt;H43hX&gt;, &lt;56&gt;)
+define(&lt;H43lX&gt;, &lt;57&gt;)
+define(&lt;H65X&gt;, &lt;58&gt;)
+define(&lt;H65hX&gt;, &lt;59&gt;)
+define(&lt;H65lX&gt;, &lt;60&gt;)
+define(&lt;H87X&gt;, &lt;61&gt;)
+define(&lt;H87hX&gt;, &lt;62&gt;)
+define(&lt;H87lX&gt;, &lt;63&gt;)
+
+# gcm_fill registers:
+
+define(&lt;CTR&gt;, &lt;3&gt;)
+define(&lt;BLOCKS&gt;, &lt;4&gt;)
+define(&lt;BUFFER&gt;, &lt;5&gt;)
+
+define(&lt;CTR0&gt;, &lt;2&gt;)
+define(&lt;CTR0S&gt;, &lt;3&gt;)
+define(&lt;CTR1&gt;, &lt;4&gt;)
+define(&lt;CTR2&gt;, &lt;5&gt;)
+define(&lt;CTR3&gt;, &lt;6&gt;)
+define(&lt;CTR4&gt;, &lt;7&gt;)
+define(&lt;CTR5&gt;, &lt;8&gt;)
+define(&lt;CTR6&gt;, &lt;9&gt;)
+define(&lt;CTR7&gt;, &lt;10&gt;)
+
+define(&lt;CTR0X&gt;, &lt;34&gt;)
+define(&lt;CTR0SX&gt;, &lt;35&gt;)
+define(&lt;CTR1X&gt;, &lt;36&gt;)
+define(&lt;CTR2X&gt;, &lt;37&gt;)
+define(&lt;CTR3X&gt;, &lt;38&gt;)
+define(&lt;CTR4X&gt;, &lt;39&gt;)
+define(&lt;CTR5X&gt;, &lt;40&gt;)
+define(&lt;CTR6X&gt;, &lt;41&gt;)
+define(&lt;CTR7X&gt;, &lt;42&gt;)
+
+define(&lt;I1&gt;, &lt;11&gt;)
+define(&lt;I2&gt;, &lt;12&gt;)
+define(&lt;I3&gt;, &lt;13&gt;)
+define(&lt;I4&gt;, &lt;14&gt;)
+define(&lt;I5&gt;, &lt;15&gt;)
+define(&lt;I6&gt;, &lt;16&gt;)
+define(&lt;I7&gt;, &lt;17&gt;)
+define(&lt;I8&gt;, &lt;18&gt;)
+
+ .file "gcm-hash8.asm"
+
+ # void gcm_init_key (union gcm_block *table)
+
+    .text
+.align 5
+PROLOGUE(_nettle_gcm_init_key8)
+    ld     7,.polynomial@got(TOCP)
+ lvx   poly,0,7
+ ld     7,.swap_mask@got(TOCP)
+ lvx   swap_mask,0,7
+ ld     7,.hidw_mask@got(TOCP)
+ lvx     hidw_mask,0,7
+ ld     7,.lodw_mask@got(TOCP)
+ lvx   lodw_mask,0,7
+
+ li    10,0x800
+    lxvd2x HX,10,TABLE # load H
+ vperm H,H,H,swap_mask
+
+ # --- calculate H = H shift left 1 modulo polynomial ---
+
+ vupkhsw    msb,H # most significant bit word-extend
+ vspltisb sl1,1 # splat 1 for shift left
+ vspltw      msb,msb,0 # most significant bit extend
+ vsl    H,H,sl1 # H shift left 1
+ vand msb,msb,poly
+ vxor zero,zero,zero
+ vxor H_t,H,msb
+
+ vsldoi H,H_t,H_t,8 # doubleword swap
+ vsldoi Hh,H,zero,8
+ vsldoi Hl,zero,H,8
+
+ # --- calculate H^2 = H*H ---
+
+ # reduction pre-processing
+ vsldoi poly_h,zero,poly,8
+ vsldoi poly_l,poly_h,poly_h,8
+
+ # polynomial multiplication "classical"
+ vpmsumd H_h,H_t,Hh # H^1h*H^1h
+ vpmsumd H_l,H_t,Hl # H^1l*H^1l
+ vpmsumd H_m,H_t,H # H^1h*H^1l⊕H^1l*H^1h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h   # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8   # [2]
+ vsldoi Ml,H_m,zero,8 # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor H_h,H_h,Mh       # [2]
+ vxor H_l,H_l,Ml       # [2]
+ vxor H_l,H_l,RP       # [1]
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l
+ vxor H_h,H_l,H_h
+ vxor H2_t,H_h,RP
+
+ vsldoi H2,H2_t,H2_t,8
+ vsldoi H2h,H2,zero,8
+ vsldoi H2l,zero,H2,8
+
+ # --- calculate [H^2.Hi⊕H^2.Lo:H^1.Hi⊕H^1.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store H,[H^2.Hi⊕H^2.Lo:H^1.Hi⊕H^1.Lo] ---
+
+ li    8,0x00
+ li    9,0x100
+ li    10,0x200
+ stxvd2x HlX,8,TABLE
+ stxvd2x HX,9,TABLE
+ stxvd2x HhX,10,TABLE
+
+ li    8,0x300
+ li    9,0x400
+ li    10,0x500
+ stxvd2x H_HhX,8,TABLE
+ stxvd2x H_HX,9,TABLE
+ stxvd2x H_HlX,10,TABLE
+
+ # --- calculate H^3,H^4 ---
+
+ # polynomial multiplication "classical"
+ vpmsumd H_l,H_t,H2l # H^1l*H^2l
+ vpmsumd H_m,H_t,H2 # H^1h*H^2l⊕H^1l*H^2h
+ vpmsumd H_h,H_t,H2h # H^1h*H^2h
+ vpmsumd H2_l,H2_t,H2l # H^2l*H^2l
+ vpmsumd H2_m,H2_t,H2 # H^2h*H^2l⊕H^2l*H^2h
+ vpmsumd H2_h,H2_t,H2h # H^2h*H^2h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h # [1] H^3
+ vpmsumd    RP2,H2_l,poly_h # [1] H^4
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8 # [2] H^3
+ vsldoi M2h,zero,H2_m,8 # [2] H^4
+ vsldoi Ml,H_m,zero,8 # [2] H^3
+ vsldoi M2l,H2_m,zero,8 # [2] H^4
+ vsldoi RP,RP,RP,8 # [1] H^3
+ vsldoi RP2,RP2,RP2,8 # [1] H^4
+ vxor H_h,H_h,Mh # [2] H^3
+ vxor H2_h,H2_h,M2h # [2] H^4
+ vxor H_l,H_l,Ml # [2] H^3
+ vxor H2_l,H2_l,M2l # [2] H^4
+ vxor H_l,H_l,RP # [1] H^3
+ vxor H2_l,H2_l,RP2 # [1] H^4
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l # H^3
+ vpmsumd RP2,H2_l,poly_l # H^4
+ vxor H_h,H_l,H_h # H^3
+ vxor H2_h,H2_l,H2_h # H^4
+ vxor H_h,H_h,RP # H^3
+ vxor H2_h,H2_h,RP2 # H^4
+
+ vsldoi H2,H2_h,H2_h,8 # H^4
+ vsldoi H,H_h,H_h,8 # H^3
+ vsldoi H2l,zero,H2,8 # H^4
+ vsldoi H2h,H2,zero,8 # H^4
+
+ # --- calculate [H^4.Hi⊕H^4.Lo:H^3.Hi⊕H^3.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store [H^4.Hi⊕H^4.Lo:H^3.Hi⊕H^3.Lo] ---
+
+ li    8,0x600
+ li    9,0x700
+ li    10,0x800
+ stxvd2x H_HhX,8,TABLE
+ stxvd2x H_HX,9,TABLE
+ stxvd2x H_HlX,10,TABLE
+
+ # --- calculate H^5,H^6 ---
+
+ # polynomial multiplication "classical"
+ vpmsumd H_l,H_t,H2l # H^1l*H^4l
+ vpmsumd H_m,H_t,H2 # H^1h*H^4l⊕H^1l*H^4h
+ vpmsumd H_h,H_t,H2h # H^1h*H^4h
+ vpmsumd H2_l,H2_t,H2l # H^2l*H^4l
+ vpmsumd H2_m,H2_t,H2 # H^2h*H^4l⊕H^2l*H^4h
+ vpmsumd H2_h,H2_t,H2h # H^2h*H^4h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h # [1] H^5
+ vpmsumd    RP2,H2_l,poly_h # [1] H^6
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8 # [2] H^5
+ vsldoi M2h,zero,H2_m,8 # [2] H^6
+ vsldoi Ml,H_m,zero,8 # [2] H^5
+ vsldoi M2l,H2_m,zero,8 # [2] H^6
+ vsldoi RP,RP,RP,8 # [1] H^5
+ vsldoi RP2,RP2,RP2,8 # [1] H^6
+ vxor H_h,H_h,Mh # [2] H^5
+ vxor H2_h,H2_h,M2h # [2] H^6
+ vxor H_l,H_l,Ml # [2] H^5
+ vxor H2_l,H2_l,M2l # [2] H^6
+ vxor H_l,H_l,RP # [1] H^5
+ vxor H2_l,H2_l,RP2 # [1] H^6
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l # H^5
+ vpmsumd RP2,H2_l,poly_l # H^6
+ vxor H_h,H_l,H_h # H^5
+ vxor H2_h,H2_l,H2_h # H^6
+ vxor H_h,H_h,RP # H^5
+ vxor H2_h,H2_h,RP2 # H^6
+
+ vsldoi H2,H2_h,H2_h,8 # H^6
+ vsldoi H,H_h,H_h,8 # H^5
+ vsldoi H2l,zero,H2,8 # H^6
+ vsldoi H2h,H2,zero,8 # H^6
+
+ # --- calculate [H^6.Hi⊕H^6.Lo:H^5.Hi⊕H^5.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store [H^6.Hi⊕H^6.Lo:H^5.Hi⊕H^5.Lo] ---
+
+ li    8,0x900
+ li    9,0xA00
+ li    10,0xB00
+ stxvd2x H_HhX,8,TABLE
+ stxvd2x H_HX,9,TABLE
+ stxvd2x H_HlX,10,TABLE
+
+ # --- calculate H^7,H^8 ---
+
+ # polynomial multiplication "classical"
+ vpmsumd H_l,H_t,H2l # H^1l*H^6l
+ vpmsumd H_m,H_t,H2 # H^1h*H^6l⊕H^1l*H^6h
+ vpmsumd H_h,H_t,H2h # H^1h*H^6h
+ vpmsumd H2_l,H2_t,H2l # H^2l*H^6l
+ vpmsumd H2_m,H2_t,H2 # H^2h*H^6l⊕H^2l*H^6h
+ vpmsumd H2_h,H2_t,H2h # H^2h*H^6h
+
+ # reduction first phase     # [1]
+ vpmsumd RP,H_l,poly_h # [1] H^7
+ vpmsumd    RP2,H2_l,poly_h # [1] H^8
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,H_m,8 # [2] H^7
+ vsldoi M2h,zero,H2_m,8 # [2] H^8
+ vsldoi Ml,H_m,zero,8 # [2] H^7
+ vsldoi M2l,H2_m,zero,8 # [2] H^8
+ vsldoi RP,RP,RP,8 # [1] H^7
+ vsldoi RP2,RP2,RP2,8 # [1] H^8
+ vxor H_h,H_h,Mh # [2] H^7
+ vxor H2_h,H2_h,M2h # [2] H^8
+ vxor H_l,H_l,Ml # [2] H^7
+ vxor H2_l,H2_l,M2l # [2] H^8
+ vxor H_l,H_l,RP # [1] H^7
+ vxor H2_l,H2_l,RP2 # [1] H^8
+
+ # reduction second phase
+ vpmsumd RP,H_l,poly_l # H^7
+ vpmsumd RP2,H2_l,poly_l # H^8
+ vxor H_h,H_l,H_h # H^7
+ vxor H2_h,H2_l,H2_h # H^8
+ vxor H_h,H_h,RP # H^7
+ vxor H2_h,H2_h,RP2 # H^8
+
+ vsldoi H,H_h,H_h,8 # H^7
+ vsldoi H2,H2_h,H2_h,8 # H^8
+
+ # --- calculate [H^8.Hi⊕H^8.Lo:H^7.Hi⊕H^7.Lo] ---
+
+ vperm H_Hh,H2,H,lodw_mask
+ vperm H_Hl,H2,H,hidw_mask
+ vxor H_H,H_Hh,H_Hl
+
+ # --- store [H^8.Hi⊕H^8.Lo:H^7.Hi⊕H^7.Lo] ---
+
+ li    8,0xC00
+ li    9,0xD00
+ li    10,0xE00
+ stxvd2x H_HhX,8,TABLE
+ stxvd2x H_HX,9,TABLE
+ stxvd2x H_HlX,10,TABLE
+
+    blr
+EPILOGUE(_nettle_gcm_init_key8)
+
+ # void gcm_hash (const struct gcm_key *key, union gcm_block *x,
+ #                size_t length, const uint8_t *data)
+
+.align 5
+PROLOGUE(_nettle_gcm_hash8)
+    vxor zero,zero,zero
+
+ ld     7,.polynomial@got(TOCP)
+ lvx   poly,0,7
+ ld     7,.swap_mask@got(TOCP)
+ lvx   swap_mask,0,7
+ ld      7,.hidw_mask@got(TOCP)
+ lvx     hidw_mask,0,7
+ ld     7,.lodw_mask@got(TOCP)
+ lvx   lodw_mask,0,7
+
+ vsldoi poly_h,zero,poly,8
+ vsldoi poly_l,poly_h,poly_h,8
+
+ lxvd2x CX,0,X # load X
+ vperm C,C,C,swap_mask
+
+ srdi 7,LENGTH,7 # 8x loop count
+ cmpldi 7,0
+ beq L2x
+
+ # backup registers
+ stdu SP,-224(SP)
+ std 28,216(SP)
+ std 29,208(SP)
+ std 30,200(SP)
+ std 31,192(SP)
+    li 8,176
+    stvx 20,8,SP
+    subi 8,8,16
+    stvx 21,8,SP
+    subi 8,8,16
+    stvx 22,8,SP
+    subi 8,8,16
+    stvx 23,8,SP
+    subi 8,8,16
+    stvx 24,8,SP
+    subi 8,8,16
+    stvx 25,8,SP
+    subi 8,8,16
+    stvx 26,8,SP
+    subi 8,8,16
+    stvx 27,8,SP
+    subi 8,8,16
+    stvx 28,8,SP
+    subi 8,8,16
+    stvx 29,8,SP
+    subi 8,8,16
+    stvx 30,8,SP
+    subi 8,8,16
+    stvx 31,8,SP
+
+ # table loading
+ li 8,0x300
+ li 9,0x400
+ li 10,0x500
+ lxvd2x H21hX,8,TABLE
+ lxvd2x H21X,9,TABLE
+ lxvd2x H21lX,10,TABLE
+ li 8,0x600
+ li 9,0x700
+ li 10,0x800
+ lxvd2x H43hX,8,TABLE
+ lxvd2x H43X,9,TABLE
+ lxvd2x H43lX,10,TABLE
+ li 8,0x900
+ li 9,0xA00
+ li 10,0xB00
+ lxvd2x H65hX,8,TABLE
+ lxvd2x H65X,9,TABLE
+ lxvd2x H65lX,10,TABLE
+ li 8,0xC00
+ li 9,0xD00
+ li 10,0xE00
+ lxvd2x H87hX,8,TABLE
+ lxvd2x H87X,9,TABLE
+ lxvd2x H87lX,10,TABLE
+
+ li 8,0x10
+ li 9,0x20
+ li 10,0x30
+ li 28,0x40
+ li 29,0x50
+ li 30,0x60
+ li 31,0x70
+
+ mtctr     7
+.align 5
+L8x_loop:
+ # input loading
+ lxvd2x C0X,0,DATA # load C0
+ lxvd2x C1X,8,DATA # load C1
+ lxvd2x C2X,9,DATA # load C2
+ lxvd2x C3X,10,DATA # load C3
+
+ # swap permuting
+ vperm C0,C0,C0,swap_mask
+ vperm C1,C1,C1,swap_mask
+ vperm C2,C2,C2,swap_mask
+ vperm C3,C3,C3,swap_mask
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ # polynomial multiplication "karatsuba" pre-processing
+ vperm C23h,C2,C3,hidw_mask
+ vperm C23l,C2,C3,lodw_mask
+ vperm C01h,C0,C1,hidw_mask
+ vperm C01l,C0,C1,lodw_mask
+
+ # input loading
+ lxvd2x C4X,28,DATA # load C4
+ lxvd2x C5X,29,DATA # load C5
+ lxvd2x C6X,30,DATA # load C6
+ lxvd2x C7X,31,DATA # load C7
+
+ # swap permuting
+ vperm C4,C4,C4,swap_mask
+ vperm C5,C5,C5,swap_mask
+ vperm C6,C6,C6,swap_mask
+ vperm C7,C7,C7,swap_mask
+
+ # polynomial multiplication "karatsuba" pre-processing
+ vperm C45h,C4,C5,hidw_mask
+ vperm C45l,C4,C5,lodw_mask
+ vperm C67h,C6,C7,hidw_mask
+ vperm C67l,C6,C7,lodw_mask
+ vxor C23,C23h,C23l
+ vxor C01,C01h,C01l
+ vxor C45,C45h,C45l
+ vxor C67,C67h,C67l
+
+ # polynomial multiplication "karatsuba"
+ vpmsumd C23h,C23h,H65h # H23 = H^6h*C2h⊕H^5h*C3h
+ vpmsumd C23l,C23l,H65l # L23 = H^6l*C2l⊕H^5l*C3l
+ vpmsumd C01h,C01h,H87h # H01 = H^8h*C0h⊕H^7h*C1h
+ vpmsumd C01l,C01l,H87l # L01 = H^8l*C0l⊕H^7l*C1l
+ vpmsumd C67h,C67h,H21h # H67 = H^2h*C6h⊕H^1h*C7h
+ vpmsumd C67l,C67l,H21l # L67 = H^2l*C6l⊕H^1l*C7l
+ vpmsumd C45h,C45h,H43h # H45 = H^4h*C4h⊕H^3h*C5h
+ vpmsumd C45l,C45l,H43l # L45 = H^4l*C4l⊕H^3l*C5l
+ vpmsumd C23,C23,H65 # M23 = (H^6h⊕H^5h)*(C2h⊕C3h)⊕(H^6l⊕H^5l)*(C2l⊕C3l)
+ vpmsumd C01,C01,H87 # M01 = (H^8h⊕H^7h)*(C0h⊕C1h)⊕(H^8l⊕H^7l)*(C0l⊕C1l)
+ vpmsumd C45,C45,H43 # M45 = (H^4h⊕H^3h)*(C4h⊕C5h)⊕(H^4l⊕H^3l)*(C4l⊕C5l)
+ vpmsumd C67,C67,H21 # M67 = (H^2h⊕H^1h)*(C6h⊕C7h)⊕(H^2l⊕H^1l)*(C6l⊕C7l)
+
+ # polynomial multiplication "karatsuba" post-processing
+ vxor C23,C23,C23h
+ vxor C01,C01,C01h
+ vxor C45,C45,C45h
+ vxor C67,C67,C67h
+ vxor C23,C23,C23l
+ vxor C01,C01,C01l
+ vxor C45,C45,C45l
+ vxor C67,C67,C67l
+
+ # deferred recombination of partial products
+ vxor C01h,C01h,C23h # H0 = H01⊕H23
+ vxor C45h,C45h,C67h # H1 = H45⊕H67
+ vxor C01l,C01l,C23l # L0 = L01⊕L23
+ vxor C45l,C45l,C67l # L1 = L45⊕L45
+ vxor C01,C01,C23 # M0 = M01⊕M23
+ vxor C45,C45,C67 # M1 = M45⊕M45
+ vxor C01h,C01h,C45h # H = H0⊕H1
+ vxor C01l,C01l,C45l # L = L0⊕L1
+ vxor C01,C01,C45 # M = M0⊕M1
+
+ # reduction first phase # [1]
+ vpmsumd RP,C01l,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,C01,8   # [2]
+ vsldoi Ml,C01,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor C01h,C01h,Mh     # [2]
+ vxor C01l,C01l,Ml     # [2]
+ vxor C01l,C01l,RP     # [1]
+
+ # reduction second phase
+ vpmsumd RP,C01l,poly_l
+ vxor C01h,C01l,C01h
+ vxor C,C01h,RP
+
+ addi DATA,DATA,0x80
+ bdnz L8x_loop
+
+    # restore registers
+ li 8,0
+    lvx 31,8,SP
+    addi 8,8,16
+    lvx 30,8,SP
+    addi 8,8,16
+    lvx 29,8,SP
+    addi 8,8,16
+    lvx 28,8,SP
+    addi 8,8,16
+    lvx 27,8,SP
+    addi 8,8,16
+    lvx 26,8,SP
+    addi 8,8,16
+    lvx 25,8,SP
+    addi 8,8,16
+    lvx 24,8,SP
+    addi 8,8,16
+    lvx 23,8,SP
+    addi 8,8,16
+    lvx 22,8,SP
+    addi 8,8,16
+    lvx 21,8,SP
+    addi 8,8,16
+    lvx 20,8,SP
+ ld 31,192(SP)
+ ld 30,200(SP)
+ ld 29,208(SP)
+ ld 28,216(SP)
+ addi SP,SP,224
+
+ clrldi   LENGTH,LENGTH,57
+L2x:
+ srdi 7,LENGTH,5
+ cmpldi 7,0
+ beq L1x
+
+ # table loading
+ li 8,0x300
+ li 9,0x400
+ li 10,0x500
+ lxvd2x H21hX,8,TABLE
+ lxvd2x H21X,9,TABLE
+ lxvd2x H21lX,10,TABLE
+
+ li 10,0x10
+
+ mtctr     7
+.align 5
+L2x_loop:
+ # input loading
+ lxvd2x C0X,0,DATA # load C0
+ lxvd2x C1X,10,DATA # load C1
+
+ # swap permuting
+ vperm C0,C0,C0,swap_mask
+ vperm C1,C1,C1,swap_mask
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ # polynomial multiplication "karatsuba" pre-processing
+ vperm C01h,C0,C1,hidw_mask
+ vperm C01l,C0,C1,lodw_mask
+ vxor C01,C01h,C01l
+
+ # polynomial multiplication "karatsuba"
+ vpmsumd C01h,C01h,H21h # H01 = H^2h*C0h⊕H^1h*C1h
+ vpmsumd C01l,C01l,H21l # L01 = H^2l*C0l⊕H^1l*C1l
+ vpmsumd C01,C01,H21 # M01 = (H^2h⊕H^1h)*(C0h⊕C1h)⊕(H^2l⊕H^1l)*(C0l⊕C1l)
+
+ # polynomial multiplication "karatsuba" post-processing
+ vxor C01,C01,C01h
+ vxor C01,C01,C01l
+
+ # reduction first phase # [1]
+ vpmsumd RP,C01l,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,C01,8   # [2]
+ vsldoi Ml,C01,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor C01h,C01h,Mh     # [2]
+ vxor C01l,C01l,Ml     # [2]
+ vxor C01l,C01l,RP     # [1]
+
+ # reduction second phase
+ vpmsumd RP,C01l,poly_l
+ vxor C01h,C01l,C01h
+ vxor C,C01h,RP
+
+ addi DATA,DATA,0x20
+ bdnz L2x_loop
+
+ clrldi   LENGTH,LENGTH,59
+L1x:
+ srdi 7,LENGTH,4
+ cmpldi 7,0
+ beq Lrem
+
+ # table loading
+ li 9,0x100
+ li 10,0x200
+ lxvd2x HlX,0,TABLE
+ lxvd2x HX, 9,TABLE
+ lxvd2x HhX,10,TABLE
+
+ # input loading
+ lxvd2x C0X,0,DATA # load C0
+
+ # swap permuting
+ vperm C0,C0,C0,swap_mask
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ vpmsumd Cl,C0,Hl # L = Hl*Cl
+ vpmsumd Cm,C0,H # M = Hh*Cl⊕Hl*Ch
+ vpmsumd Ch,C0,Hh # H = Hh*Ch
+
+ # reduction first phase # [1]
+ vpmsumd RP,Cl,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,Cm,8   # [2]
+ vsldoi Ml,Cm,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor Ch,Ch,Mh   # [2]
+ vxor Cl,Cl,Ml       # [2]
+ vxor Cl,Cl,RP   # [1]
+
+ # reduction second phase
+ vpmsumd RP,Cl,poly_l
+ vxor Ch,Cl,Ch
+ vxor C,Ch,RP
+
+ addi DATA,DATA,0x10
+ clrldi   LENGTH,LENGTH,60
+Lrem:
+ cmpldi LENGTH,0
+ beq Ldone
+
+ # table loading
+ li 9,0x100
+ li 10,0x200
+ lxvd2x HlX,0,TABLE
+ lxvd2x HX, 9,TABLE
+ lxvd2x HhX,10,TABLE
+
+ # input loading
+ stdu SP,-16(SP)
+ stvx zero,0,SP
+Lst_loop:
+ subic.      LENGTH,LENGTH,1
+ lbzx 7,LENGTH,DATA
+ stbx 7,LENGTH,SP
+ bne Lst_loop
+ lxvd2x   C0X,0,SP
+ addi SP,SP,16
+
+ # swap permuting
+ vperm C0,C0,C0,swap_mask
+
+ # previous digest combining
+ vxor C0,C0,C
+
+ vpmsumd Cl,C0,Hl # L = Hl*Cl
+ vpmsumd Cm,C0,H # M = Hh*Cl⊕Hl*Ch
+ vpmsumd Ch,C0,Hh # H = Hh*Ch
+
+ # reduction first phase # [1]
+ vpmsumd RP,Cl,poly_h # [1]
+
+ # polynomial multiplication post-processing # [2]
+ vsldoi Mh,zero,Cm,8   # [2]
+ vsldoi Ml,Cm,zero,8   # [2]
+ vsldoi RP,RP,RP,8     # [1]
+ vxor Ch,Ch,Mh   # [2]
+ vxor Cl,Cl,Ml     # [2]
+ vxor Cl,Cl,RP   # [1]
+
+ # reduction second phase
+ vpmsumd RP,Cl,poly_l
+ vxor Ch,Cl,Ch
+ vxor C,Ch,RP
+
+Ldone:
+ vperm C,C,C,swap_mask
+ stxvd2x CX,0,X # store C
+ blr
+EPILOGUE(_nettle_gcm_hash8)
+
+ # gcm_fill (uint8_t *ctr, size_t blocks, union gcm_block *buffer)
+
+.align 5
+PROLOGUE(_nettle_gcm_fill)
+  ld     6,.swap_mask@got(TOCP)
+  lvx   swap_mask,0,6
+
+  vxor zero,zero,zero
+  vspltisb I1,1
+  vspltisb I2,2
+  vspltisb I3,3
+  vspltisb I4,4
+  vspltisb I5,5
+  vspltisb I6,6
+  vspltisb I7,7
+  vspltisb I8,8
+  vsldoi I1,zero,I1,1
+  vsldoi I2,zero,I2,1
+  vsldoi I3,zero,I3,1
+  vsldoi I4,zero,I4,1
+  vsldoi I5,zero,I5,1
+  vsldoi I6,zero,I6,1
+  vsldoi I7,zero,I7,1
+  vsldoi I8,zero,I8,1
+
+  lxvd2x CTR0X,0,CTR
+  vperm CTR0,CTR0,CTR0,swap_mask
+
+  srdi      6,BLOCKS,3              # 8x loop count
+  cmpldi 6,0
+  beq       Lfill_4x
+
+  std       25,-56(SP);
+  std       26,-48(SP);
+  std       27,-40(SP);
+  std       28,-32(SP);
+  std       29,-24(SP);
+  std       30,-16(SP);
+  std       31,-8(SP);
+
+  li        25,0x10
+  li        26,0x20
+  li        27,0x30
+  li        28,0x40
+  li        29,0x50
+  li        30,0x60
+  li        31,0x70
+
+  mtctr     6
+L8x_fill_loop:
+  vadduwm CTR1,CTR0,I1
+  vadduwm CTR2,CTR0,I2
+  vadduwm CTR3,CTR0,I3
+  vadduwm CTR4,CTR0,I4
+  vadduwm CTR5,CTR0,I5
+  vadduwm CTR6,CTR0,I6
+  vadduwm CTR7,CTR0,I7
+
+  vperm CTR0S,CTR0,CTR0,swap_mask
+  vperm CTR1,CTR1,CTR1,swap_mask
+  vperm CTR2,CTR2,CTR2,swap_mask
+  vperm CTR3,CTR3,CTR3,swap_mask
+  vperm CTR4,CTR4,CTR4,swap_mask
+  vperm CTR5,CTR5,CTR5,swap_mask
+  vperm CTR6,CTR6,CTR6,swap_mask
+  vperm CTR7,CTR7,CTR7,swap_mask
+
+  stxvd2x CTR0SX,0,BUFFER
+  stxvd2x CTR1X,25,BUFFER
+  stxvd2x CTR2X,26,BUFFER
+  stxvd2x CTR3X,27,BUFFER
+  stxvd2x CTR4X,28,BUFFER
+  stxvd2x CTR5X,29,BUFFER
+  stxvd2x CTR6X,30,BUFFER
+  stxvd2x CTR7X,31,BUFFER
+
+  vadduwm CTR0,CTR0,I8
+  addi BUFFER,BUFFER,0x80
+  bdnz      L8x_fill_loop
+
+  ld        25,-56(SP);
+  ld        26,-48(SP);
+  ld        27,-40(SP);
+  ld        28,-32(SP);
+  ld        29,-24(SP);
+  ld        30,-16(SP);
+  ld        31,-8(SP);
+
+  clrldi   BLOCKS,BLOCKS,61
+
+Lfill_4x:
+  srdi      6,BLOCKS,2
+  cmpldi 6,0
+  beq       Lfill_2x
+
+  li        8,0x10
+  li        9,0x20
+  li        10,0x30
+
+  vadduwm CTR1,CTR0,I1
+  vadduwm CTR2,CTR0,I2
+  vadduwm CTR3,CTR0,I3
+
+  vperm CTR0S,CTR0,CTR0,swap_mask
+  vperm CTR1,CTR1,CTR1,swap_mask
+  vperm CTR2,CTR2,CTR2,swap_mask
+  vperm CTR3,CTR3,CTR3,swap_mask
+
+  stxvd2x CTR0SX,0,BUFFER
+  stxvd2x CTR1X,8,BUFFER
+  stxvd2x CTR2X,9,BUFFER
+  stxvd2x CTR3X,10,BUFFER
+
+  vadduwm CTR0,CTR0,I4
+  addi BUFFER,BUFFER,0x40
+
+  clrldi   BLOCKS,BLOCKS,62
+
+Lfill_2x:
+  srdi      6,BLOCKS,1
+  cmpldi 6,0
+  beq       Lfill_1x
+
+  li        10,0x10
+
+  vadduwm CTR1,CTR0,I1
+
+  vperm CTR0S,CTR0,CTR0,swap_mask
+  vperm CTR1,CTR1,CTR1,swap_mask
+
+  stxvd2x CTR0SX,0,BUFFER
+  stxvd2x CTR1X,10,BUFFER
+
+  vadduwm CTR0,CTR0,I2
+  addi BUFFER,BUFFER,0x20
+
+  clrldi   BLOCKS,BLOCKS,63
+
+Lfill_1x:
+  cmpldi BLOCKS,0
+  beq       Lfill_done
+
+  vperm CTR0S,CTR0,CTR0,swap_mask
+
+  stxvd2x CTR0SX,0,BUFFER
+
+  vadduwm CTR0,CTR0,I1
+
+Lfill_done:
+  vperm CTR0,CTR0,CTR0,swap_mask
+  stxvd2x CTR0X,0,CTR
+
+  blr
+EPILOGUE(_nettle_gcm_fill)
+
+    .data
+    .align 4
+.polynomial:
+ .byte 1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0xc2
+    .align 4
+.swap_mask:
+ .byte 8,9,10,11,12,13,14,15,0,1,2,3,4,5,6,7
+    .align 4
+.hidw_mask:
+ .byte 23,22,21,20,19,18,17,16,7,6,5,4,3,2,1,0
+    .align 4
+.lodw_mask:
+ .byte 31,30,29,28,27,26,25,24,15,14,13,12,11,10,9,8
diff --git a/powerpc64le/machine.m4 b/powerpc64le/machine.m4
new file mode 100644
index 00000000..e69de29b
diff --git a/testsuite/gcm-test.c b/testsuite/gcm-test.c
index c8174019..df1fc94a 100644
--- a/testsuite/gcm-test.c
+++ b/testsuite/gcm-test.c
@@ -170,6 +170,29 @@ test_main(void)
  "16aedbf5a0de6a57a637b39b"),
     SHEX("619cc5aefffe0bfa462af43c1699d050"));

+  /* Test 128 bytes */
+  test_aead(&amp;nettle_gcm_aes128, NULL,
+    SHEX("feffe9928665731c6d6a8f9467308308"),
+    SHEX(""),
+    SHEX("d9313225f88406e5a55909c5aff5269a"
+ "86a7a9531534f7da2e4c303d8a318a72"
+ "1c3c0c95956809532fcf0e2449a6b525"
+ "b16aedf5aa0de657ba637b391aafd255"
+ "5ae376bc5e9f6a1b08e34db7a6ee0736"
+ "9ba662ea12f6f197e6bc3ed69d2480f3"
+ "ea5691347f2ba69113eb37910ebc18c8"
+ "0f697234582016fa956ca8f63ae6b473"),
+    SHEX("42831ec2217774244b7221b784d0d49c"
+ "e3aa212f2c02a4e035c17e2329aca12e"
+ "21d514b25466931c7d8f6a5aac84aa05"
+ "1ba30b396a0aac973d58e091473f5985"
+ "874b1178906ddbeab04ab2fe6cce8c57"
+ "8d7e961bd13fd6a8c56b66ca5e576492"
+ "1a48cd8bda04e66343e73055118b69b9"
+ "ced486813846958a11e602c03cfc232b"),
+    SHEX("cafebabefacedbaddecaf888"),
+    SHEX("796836f1246c9d735c5e1be0a715ccc3"));
+
   /* Test case 7 */
   test_aead(&amp;nettle_gcm_aes192, NULL,
     SHEX("00000000000000000000000000000000"
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200620084151</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-06-20 08:41:51-0400</timestampReceived><subject>Re: Post patch on nettle-bugs list</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; Is there a limit to the number of lines of a message posted on the
&gt; list or special
&gt; option that should be passed to git diff?

There's moderation for emails exceeding 100 KB in size. 

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200620085439</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-06-20 08:54:39-0400</timestampReceived><subject>Re: PPC64LE optimizing AES and GHASH</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; I added a PowerPC64LE optimized version of AES and GHASH to nettle.

Cool. I haven't yet looked at the patches, but some general comments:

&gt;    - The main equation: The main equation for 4 block (128-bit each) can be
&gt;    seen in reference [1]  Digest = (((((((Digest⊕C0)*H)⊕C1)*H)⊕C2)*H)⊕C3)*H
&gt;    = ((Digest⊕C0)*H4)⊕(C1*H3)⊕(C2*H2)⊕(C3*H) to achieve more parallelism,
&gt;    this equation can be modified to address 8 blocks per one loop. It looks
&gt;    like as follows Digest =
&gt;    ((Digest⊕C0)*H8)⊕(C1*H7)⊕(C2*H6)⊕(C3*H5)⊕(C4*H4)⊕(C5*H3)⊕(C6*H2)⊕(C7*H)

Have you measured speedup when going from 4 to 8 blocks? We shouldn't
add larger loops than needed.

&gt;    - Handling Bit-reflection of the multiplication product [1]: This
&gt;    technique moves part of the workload inside the loop to the init function
&gt;    so it is executed only once.

The "carry less" multiplication is symmetric under bit reversal. So
great to get it out of the main loops.

&gt;    - Karatsuba Algorithm: This algorithm allows to perform three
&gt;    multiplication instructions instead of four, in exchange for two additional
&gt;    Xor. This technique is well explained with figures in reference [1]

Do you measure a speedup from this? Karatsuba usually pays off only for
a bit larger sizes (but I guess overhead is a little less here than for
standard multiplication).

&gt;    - Test 128 bytes is added to gcm-test in testsuite to test 8x loop in
&gt;    GHASH optimized function.

Good!

&gt;    - Since the functionality of gcm_set_key() is replaced with
&gt;    gcm_init_key() for PowerPC64LE, two warnings will pop up: [‘gcm_gf_shift'
&gt;    defined but not used] and [‘gcm_gf_add' defined but not used]

You can perhaps solve this by adding

#if HAVE_NATIVE_...
#endif

around the related functions.

To test PPC code, I wonder if it's easy to add a PPC build to
.gitlab-ci, in the same way as arm and mips tests. These are based on
Debian packaged cross compilers and qemu-user. I'm also not that familiar
with the variants within the Power and PowerPC family of processors.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200622130428</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-06-22 13:04:28-0400</timestampReceived><subject>Fwd: PPC64LE optimizing AES and GHASH</subject><body>

On Sat, Jun 20, 2020 at 11:54 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Have you measured speedup when going from 4 to 8 blocks? We shouldn't
&gt; add larger loops than needed.
&gt;

The 8x loop has x~1.15 performance boost over 4x loop, if you think it's
not worth it, I can add only 4x loop to make the code simpler.


&gt; Do you measure a speedup from this? Karatsuba usually pays off only for
&gt; a bit larger sizes (but I guess overhead is a little less here than for
&gt; standard multiplication).
&gt;

Actually, I considered the Karatsuba algorithm not only for performance but
to reduce the number of registers used. However, I believe that using the
Karatsuba algorithm in my case performs better or similar to classical
multiplication.


&gt; &gt;    - Since the functionality of gcm_set_key() is replaced with
&gt; &gt;    gcm_init_key() for PowerPC64LE, two warnings will pop up:
&gt; [‘gcm_gf_shift'
&gt; &gt;    defined but not used] and [‘gcm_gf_add' defined but not used]
&gt;

  When I applied the patch to the last upstream, these warnings did not
appear,        some changes have occurred to gcm.c, I will look at it.


&gt; To test PPC code, I wonder if it's easy to add a PPC build to
&gt; .gitlab-ci, in the same way as arm and mips tests. These are based on
&gt; Debian packaged cross compilers and qemu-user. I'm also not that familiar
&gt; with the variants within the Power and PowerPC family of processors.
&gt;

I will see what I can do.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200623120831</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-06-23 12:08:31-0400</timestampReceived><subject>Re: Add ppc64le arch to Gitlab CI</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; I made a workaround by installing the required packages for ppc64el via
&gt; .gitlab-ci.yml
&gt; I will post the patch with big endian support for the optimized functions.

I think it would be good to have the patch for ppc testing first, so we
can have it up and running before getting to the more interesting parts.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200623150110</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-06-23 15:01:10-0400</timestampReceived><subject>[PATCH 3/3] v4.2 Blowfish: Supply lengths instead of C-strings.</subject><body>

Fixed errors in the v4.1 version pertaining to the selftests.

---
 blowfish-bcrypt.c | 100 +++++++++++++++++++++++++---------------------
 blowfish.h        |  14 ++++---
 nettle.texinfo    |  27 +++++++------
 3 files changed, 77 insertions(+), 64 deletions(-)

diff --git a/blowfish-bcrypt.c b/blowfish-bcrypt.c
index c06f9e90..64858880 100644
--- a/blowfish-bcrypt.c
+++ b/blowfish-bcrypt.c
@@ -76,14 +76,15 @@ static const char radix64_encode_table[64] =
     "0123456789";
 
 int
-blowfish_bcrypt_verify(const char *key,
-                       const char *hashed)
+blowfish_bcrypt_verify(size_t lenkey, const uint8_t *key,
+                       size_t lenhashed, const uint8_t *hashed)
 {
-  char newhash[BLOWFISH_BCRYPT_HASH_SIZE];
+  uint8_t newhash[BLOWFISH_BCRYPT_HASH_SIZE];
 
-  return blowfish_bcrypt_hash(sizeof newhash,
-                              newhash, key, hashed, -1, (void*)0)
-   &amp;&amp; !strcmp(newhash, hashed);
+  return blowfish_bcrypt_hash(newhash,
+                              lenkey, key, lenhashed, hashed,
+                              -1, (void*)0)
+   &amp;&amp; !strcmp((const char*)newhash, (const char*)hashed);
 }
 
 static char *encode_radix64(char *dst, size_t len, const uint8_t *src)
@@ -159,10 +160,12 @@ static void swap32(uint32_t *x, int count)
 #endif
 }
 
-static void set_xkey(const char *key, bf_key expanded, bf_key initial,
-    unsigned bug, uint32_t safety)
+static void set_xkey(size_t lenkey, const uint8_t *key,
+                     bf_key expanded, bf_key initial,
+		     unsigned bug, uint32_t safety)
 {
-  const char *ptr = key;
+  const uint8_t *ptr = key;
+  size_t n = lenkey;
   unsigned i, j;
   uint32_t sign, diff, tmp[2];
 
@@ -219,10 +222,10 @@ static void set_xkey(const char *key, bf_key expanded, bf_key \
                initial,
  */
       if (j)
         sign |= tmp[1] &amp; 0x80;
-      if (!*ptr)
-        ptr = key;
-      else
+      if (n--)
         ptr++;
+      else
+        ptr = key, n = lenkey;
     }
     diff |= tmp[0] ^ tmp[1]; /* Non-zero on any differences */
 
@@ -259,8 +262,9 @@ static void set_xkey(const char *key, bf_key expanded, bf_key \
initial,  initial[0] ^= sign;
 }
 
-static int ibcrypt(size_t length, char *dst,
-                   const char *key, const char *scheme,
+static int ibcrypt(uint8_t *dst,
+                   size_t lenkey, const uint8_t *key,
+		   size_t lenscheme, const uint8_t *scheme,
 		   int minlog2rounds,
 		   int log2rounds, const uint8_t *salt)
 {
@@ -277,12 +281,10 @@ static int ibcrypt(size_t length, char *dst,
   uint32_t *ptr;
   uint32_t count;
   int i;
-  size_t lenscheme = strlen(scheme);
   unsigned cscheme;
   unsigned bug = 0;
   uint32_t safety = 0;
-  if (length &lt; BLOWFISH_BCRYPT_HASH_SIZE ||
-      lenscheme &lt; 2)
+  if (lenscheme &lt; 2)
     return 0;
 
   if (lenscheme &gt;= 3 &amp;&amp; *scheme++ != '$')
@@ -305,9 +307,17 @@ static int ibcrypt(size_t length, char *dst,
     if (*scheme++ != '$')
       return 0;
     if (lenscheme &gt;= 6) {
-      if (log2rounds &lt; 0)
-        log2rounds = atoi(scheme);
-      scheme += 2;
+      if (log2rounds &lt; 0) {
+        unsigned c = *scheme++ - '0';
+	if (c &gt; 9)
+	  return 0;
+	log2rounds = c * 10;
+        c = *scheme++ - '0';
+	if (c &gt; 9)
+	  return 0;
+	log2rounds += c;
+      } else
+        scheme += 2;
       if (lenscheme &gt;= CRYPTPLEN &amp;&amp; *scheme++ != '$')
 	return 0;
       if (lenscheme &gt;= HASHOFFSET &amp;&amp; !salt) {
@@ -318,7 +328,7 @@ static int ibcrypt(size_t length, char *dst,
         ctx.table = radix64_decode_table;
 
         if (!base64_decode_update(&amp;ctx, &amp;saltlen, (uint8_t *) data.binary.salt,
-                                  SALTLEN, scheme)
+                                  SALTLEN, (const char*) scheme)
          || saltlen != BLOWFISH_BCRYPT_BINSALT_SIZE)
           return 0;
       }
@@ -336,7 +346,7 @@ static int ibcrypt(size_t length, char *dst,
     return 0;
   count = (uint32_t)1 &lt;&lt; log2rounds;
 
-  set_xkey(key, data.expanded_key, data.ctx.p, bug, safety);
+  set_xkey(lenkey, key, data.expanded_key, data.ctx.p, bug, safety);
   memcpy(data.ctx.s, _nettle_blowfish_initial_ctx.s, sizeof(data.ctx.s));
 
   L = R = 0;
@@ -432,12 +442,13 @@ static int ibcrypt(size_t length, char *dst,
   *dst++ = '0' + log2rounds / 10;
   *dst++ = '0' + log2rounds % 10;
   *dst++ = '$';
-  dst = encode_radix64(dst, BLOWFISH_BCRYPT_BINSALT_SIZE, psalt) - 1;
+  dst = (uint8_t*)
+        encode_radix64((char*) dst, BLOWFISH_BCRYPT_BINSALT_SIZE, psalt) - 1;
 
   swap32(data.binary.output, 6);
 /* This has to be bug-compatible with the original implementation, so
    only encode 23 of the 24 bytes. */
-  encode_radix64(dst, 23, (uint8_t *) data.binary.output);
+  encode_radix64((char*) dst, 23, (uint8_t *) data.binary.output);
   return cscheme;
 }
 
@@ -461,27 +472,25 @@ static int ibcrypt(size_t length, char *dst,
  * The performance cost of this quick self-test is around 0.6% at the "$2a$08"
  * setting.
  */
-int blowfish_bcrypt_hash(size_t length, char *dst,
-                         const char *key, const char *scheme,
+int blowfish_bcrypt_hash(uint8_t *dst,
+                         size_t lenkey, const uint8_t *key,
+			 size_t lenscheme, const uint8_t *scheme,
 			 int log2rounds, const uint8_t *salt)
 {
-  const char *test_pw = "8b \xd0\xc1\xd2\xcf\xcc\xd8";
-  const char *test_scheme = "$2a$00$abcdefghijklmnopqrstuu";
+  const uint8_t test_pw[] = "8b \xd0\xc1\xd2\xcf\xcc\xd8";
+  const uint8_t test_scheme[] = "$2a$00$abcdefghijklmnopqrstuu";
   static const char * const test_hashes[2] =
     {"i1D709vfamulimlGcq0qq3UvuUasvEa\0\x55",  /* 'a', 'b', 'y' */
      "VUrPmXD6q/nVSSp7pNDhCR9071IfIRe\0\x55"}; /* 'x' */
   const char *test_hash = test_hashes[0];
   int cscheme;
   int ok;
-  struct {
-    char s[HASHOFFSET + 1];
-    char o[HASHOFFSET + 31 + 1 + 1 + 1];
-  } buf;
+  uint8_t bufs[sizeof(test_scheme) - 1];
+  uint8_t bufo[BLOWFISH_BCRYPT_HASH_SIZE];
 
-  if (length)
-    *dst = '\0';
+  *dst = '\0';
 /* Hash the supplied password */
-  cscheme = ibcrypt(length, dst, key, scheme, 4, log2rounds, salt);
+  cscheme = ibcrypt(dst, lenkey, key, lenscheme, scheme, 4, log2rounds, salt);
 
 /*
  * Do a quick self-test. It is important that we make both calls to ibcrypt()
@@ -490,25 +499,24 @@ int blowfish_bcrypt_hash(size_t length, char *dst,
  * stack and makes it more likely that any alignment related issues would be
  * detected by the self-test.
  */
-  memcpy(buf.s, test_scheme, sizeof(buf.s));
+  memcpy(bufs, test_scheme, sizeof(test_scheme) - 1);
 
   if (cscheme)
-    test_hash = test_hashes[(buf.s[2] = cscheme) == 'x'];
+    test_hash = test_hashes[(bufs[2] = cscheme) == 'x'];
 
-  memset(buf.o, 0x55, sizeof(buf.o));
-  buf.o[sizeof(buf.o) - 1] = 0;
-  ok = ibcrypt(sizeof(buf.o) - (1 + 1), buf.o, test_pw,
-               buf.s, 0, -1, (void*)0);
+  *bufo = 0;
+  ok = ibcrypt(bufo, sizeof(test_pw) - 1, test_pw,
+               sizeof(bufs), bufs, 0, -1, (void*)0);
 
   ok = (ok &amp;&amp;
-      !memcmp(buf.o, buf.s, HASHOFFSET) &amp;&amp;
-      !memcmp(buf.o + HASHOFFSET, test_hash, 31 + 1 + 1 + 1));
+      !memcmp(bufo, bufs, sizeof(bufs)) &amp;&amp;
+      !memcmp(bufo + HASHOFFSET, test_hash, sizeof(test_hash) - 1));
 
   {
-    const char *k = "\xff\xa3" "34" "\xff\xff\xff\xa3" "345";
+    const uint8_t k[] = "\xff\xa3" "34" "\xff\xff\xff\xa3" "345";
     bf_key ae, ai, ye, yi;
-    set_xkey(k, ae, ai, 0, 0x10000); /* $2a$ */
-    set_xkey(k, ye, yi, 0, 0); /* $2y$ */
+    set_xkey(sizeof(k) - 1, k, ae, ai, 0, 0x10000); /* $2a$ */
+    set_xkey(sizeof(k) - 1, k, ye, yi, 0, 0); /* $2y$ */
     ai[0] ^= 0x10000; /* undo the safety (for comparison) */
     ok = ok &amp;&amp; ai[0] == 0xdb9c59bc &amp;&amp; ye[17] == 0x33343500 &amp;&amp;
         !memcmp(ae, ye, sizeof(ae)) &amp;&amp;
diff --git a/blowfish.h b/blowfish.h
index af48e20f..01813cbc 100644
--- a/blowfish.h
+++ b/blowfish.h
@@ -86,16 +86,18 @@ void
 blowfish_decrypt(const struct blowfish_ctx *ctx,
                  size_t length, uint8_t *dst,
                  const uint8_t *src);
+
+/* dst parameter must point to a buffer of minimally
+ * BLOWFISH_BCRYPT_HASH_SIZE bytes */
 int
-blowfish_bcrypt_hash(size_t length,
-                     char *dst,
-                     const char *key,
-                     const char *scheme,
+blowfish_bcrypt_hash(uint8_t *dst,
+                     size_t lenkey, const uint8_t *key,
+                     size_t lenscheme, const uint8_t *scheme,
 		     int log2rounds,
 		     const uint8_t *salt);
 int
-blowfish_bcrypt_verify(const char *key,
-                       const char *hashed);
+blowfish_bcrypt_verify(size_t lenkey, const uint8_t *key,
+                       size_t lenhashed, const uint8_t *hashed);
 
 #ifdef __cplusplus
 }
diff --git a/nettle.texinfo b/nettle.texinfo
index 75e18b58..2269e11d 100644
--- a/nettle.texinfo
+++ b/nettle.texinfo
@@ -1513,7 +1513,7 @@ in any other way.
 Analogous to @code{blowfish_encrypt}
 @end deftypefun
 
-@deftypefun int blowfish_bcrypt_hash (size_t @var{length}, char *@var{dst}, const \
char *@var{key}, const char *@var{scheme}, int @var{log2rounds}, const uint8_t \
*@var{salt}) +@deftypefun int blowfish_bcrypt_hash (char *@var{dst}, size_t \
@var{lenkey}, const char *@var{key}, size_t @var{lenscheme}, const char \
*@var{scheme}, int @var{log2rounds}, const uint8_t *@var{salt})  Compute the bcrypt \
password hash.  The function will return @code{0} if the hash cannot be computed
 due to invalid input.
@@ -1522,13 +1522,13 @@ in the array pointed to by @var{dst}.  The hash is computed \
based  on the chosen @var{scheme}, number of rounds @var{log2rounds} and
 specified @var{salt}.
 
-@var{length} must be at least @code{BLOWFISH_BCRYPT_HASH_SIZE}.
+@var{dst} must point to a character array of at least
+ @code{BLOWFISH_BCRYPT_HASH_SIZE} bytes.
 
-@var{dst} must point to a character array of the specified @var{length}.
+@var{key} contains the plaintext password string of size @var{lenkey}.
 
-@var{key} contains the zero terminated plaintext password string.
-
-@var{scheme} contains either just the chosen scheme (valid schemes
+@var{scheme} is of size @var{lenscheme} and contains either just the
+chosen scheme (valid schemes
 are: @code{2a}, @code{2b}, @code{2x} or @code{2y}), or
 (the prefix of) an existing hashed password (typically @code{$2b$10$...}).
 
@@ -1543,26 +1543,28 @@ the salt will be extracted from @var{scheme}.
 Sample code to generate a bcrypt hash:
 @example
 char cleartxtpassword[] = "ExamplePassword";
+char scheme[] = "2b";
 uint8_t salt[BLOWFISH_BCRYPT_BINSALT_SIZE];
 @dots{}
 /* Make sure that salt is filled with random bytes */
 @dots{}
 char hashedresult[BLOWFISH_BCRYPT_HASH_SIZE];
-int result = blowfish_bcrypt(sizeof(hashedresult), hashedresult,
-                             cleartxtpassword, "2b", 10, salt);
+int result = blowfish_bcrypt(hashedresult,
+                             sizeof(cleartxtpassword), cleartxtpassword,
+                             sizeof(scheme), scheme, 10, salt);
 if (result)
   printf("%s\n", hashedresult);
 @end example
 @end deftypefun
 
-@deftypefun int blowfish_bcrypt_verify (const char *@var{key}, const char \
*@var{hashed}) +@deftypefun int blowfish_bcrypt_verify (size_t @var{lenkey}, const \
char *@var{key}, size_t @var{lenhashed}, const char *@var{hashed})  Verifies the \
bcrypt password hash against the supplied plaintext password.  The function will \
return @code{0} if the password does not match.  The function will return @code{1} if \
the password matches.  
-@var{key} contains the zero terminated plaintext password string.
+@var{key} contains the plaintext password string of size @var{lenkey}.
 
-@var{hashed} contains the zero terminated hashed string to compare with.
+@var{hashed} contains the hashed string of size @var{lenhashed} to compare with.
 
 Sample code to verify a bcrypt hash:
 @example
@@ -1573,7 +1575,8 @@ char existinghashed[] =
            "$"   /* separator */
            "1b2lPgo4XumibnJGN3r3sO" /* base64 encoded 16-byte salt */
            "u7wE7xNfYDKlAxZffJDCJdVfFTAyevu"; /* Hashedpart */
-if (blowfish_bcrypt_verify(cleartxtpassword, existinghashed))
+if (blowfish_bcrypt_verify(sizeof(cleartxtpassword), cleartxtpassword,
+                           sizeof(existinghashed), existinghashed))
   printf("Password is correct.");
 else
   printf("Password is incorrect.");
-- 
2.20.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200623164427</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-06-23 16:44:27-0400</timestampReceived><subject>Re: [PATCH] (revision 3.2) Added bcrypt() support.</subject><body>

Stephen R. van den Berg wrote:
&gt;Stephen R. van den Berg wrote:
&gt;&gt;The v4.0 patches have just been submitted.  They're a three patch set now:
&gt;&gt;3. The amended binary string interface (no C-strings).

The 3rd set has been resent as v4.3.

Fixed examples in the docs.
-- 
Stephen.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200627141051</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-06-27 14:10:51-0400</timestampReceived><subject>FYI: Forced update of master-updates</subject><body>

Hi, I tried out a microoptimization of the arm neon implementation of
chacha and salsa20. Gave a 10% speedup on the older Cortex-A5 core, but
unclear if it's an improvement overall, so I don't want to push it to
master, and I've removed that commit from master-updates (now on its own
branch arm-salsa20-chacha-vsra instead, in case anyone is curious). I'm
considering changing the internal _salsa20_core and _chacha_core to do
more than one block at a time, since processing a few blocks in parallel
has a great potential for performance improvements.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200627162908</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-06-27 16:29:08-0400</timestampReceived><subject>Re: [PATCH v2 8/8] test/gostdsa-vko: add hashed test vectors from RFC 7836</subject><body>

сб, 20 июн. 2020 г. в 11:38, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt;
&gt; Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:
&gt;
&gt; &gt; It was not possible to check gostdsa_vko test vectors with the outputs
&gt; &gt; from RFC 7836 because Nettle lacked Streebog hash function. Now as the
&gt; &gt; function is supported, add full test vectors.
&gt;
&gt; I've now merged this and preceding patches to master-updates. I think
&gt; that is all of the changes needed for streebog hashes (except the docs,
&gt; which should go into an other section, as discussed in a different
&gt; thread). Let me know if there's anything I've missed.

Thank you!

&gt; After this, my next priority will be to review and merge the latest
&gt; round of bcrypt patches.

On my side the major chunks are:
 - Support for the rest of GOST ECC curves (which requires changes to
ecc core). They are gaining more and more use and lack of support in
Nettle means lack of support in GnuTLS also.
 - Support for GOST 28147-89/34.12-2015 64-bit cipher (Magma).

The rest of the patchset is less important from my point of view.

-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200630111222</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-06-30 11:12:22-0400</timestampReceived><subject>Re: [PATCH v2 3/8] nettle.texinfo: add documentation for Streebog hash function</subject><body>

Hello,

вт, 30 июн. 2020 г. в 14:04, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt;
&gt; Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:
&gt;
&gt; &gt; I wouldn't call it legacy (since it is an actual standard). What about
&gt; &gt; adding the "Other hash functions" section? It can further receive
&gt; &gt; algorithms such as SM3 (if somebody submits it)?
&gt;
&gt; I've now committed your docs, in a "Miscellaneous hash functions"
&gt; section.

Sorry, got overloaded by the work.

-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200630120822</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-06-30 12:08:22-0400</timestampReceived><subject>Re: [PATCH] Add ppc64 and ppc64el to Gitlab CI</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt;  It's needed for both, I just give ppc64 as an example.

I see.

And I just pushed the change to enable big-endian too.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200630195551</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-06-30 19:55:51-0400</timestampReceived><subject>Re: [PATCH 3/3] v4.3 Blowfish: Supply lengths instead of C-strings.</subject><body>

"Stephen R. van den Berg" &lt;srb@cuci.nl&gt; writes:

&gt; Fix examples in the docs relative to v4.2.

Thanks.

I've now merged this (squashed together with part 2/3) to the bcrypt
branch in the repository. Before merging to master, I'd need some basic
tests for the testsuite, preferably based on authoritative test vectors.

For tests of the _verify function, it's important to include tests also
for inputs that should be rejected.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200630215433</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-06-30 21:54:33-0400</timestampReceived><subject>Re: [Patch] Optimize AES and GHASH for PowerPC64 (support little-endian and big-endian)</subject><body>

On Tue, Jun 30, 2020 at 11:06 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

Can you explain a bit more what's special with the powerpc64 prologue
&gt; and epilogue? What are the .C_NAME($1) symbols?

This is ELFv1 ABI stuff that is still required to get the function working
for PowerPC64 big-endian systems. PowerPC64 little-endian systems is
compatible with ELFv2 ABI which has the classical prologue along with other
features.

If possible, definitions could be moved to powerpc64/machine.m4 instead,
&gt; avoiding ifelse(ASM_POWERPC64,...).

Is it possible to override the PROLOGUE definition in powerpc64/machine.m4?

It would also be nice with a powerpc64/README summarizing register usage
&gt; and calling conventions.

I will follow the README for other architectures to make this one.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200504173450</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-05-04 17:34:50-0400</timestampReceived><subject>Re: ANNOUNCE: Nettle-3.6</subject><body>

Thank you!

-- 
With best wishes
Dmitry

пн, 4 мая 2020 г., 20:24 Niels Möller &lt;nisse@lysator.liu.se&gt;:

&gt; Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:
&gt;
&gt; &gt; I just wanted to point that git tree was not updated for the release.
&gt;
&gt; Thanks for telling me! Should be up to date now.
&gt;
&gt; I think the way it happened, was that I ran git push --tags under the
&gt; assumption that it would push tags in addition to the current branch,
&gt; and I didn't pay close attention.
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200506153327</emailId><senderName>Emil Velikov</senderName><senderEmail>emil.l.velikov@gmail.com</senderEmail><timestampReceived>2020-05-06 15:33:27-0400</timestampReceived><subject>[PATCH 2/2] examples: add more openssl sha2 digests to the benchmark</subject><body>

In particular, this commit adds sha256, sha384 and sha512.

Rough numbers from my system:

         Algorithm         mode Mbyte/s
              sha1       update  462.05
      openssl sha1       update  804.90
            sha256       update  222.32
    openssl sha256       update  369.49
            sha384       update  355.34
    openssl sha384       update  536.05
            sha512       update  355.90
    openssl sha512       update  546.07

Signed-off-by: Emil Velikov &lt;emil.l.velikov@gmail.com&gt;
---
 examples/nettle-benchmark.c | 6 ++++--
 examples/nettle-openssl.c   | 3 +++
 nettle-internal.h           | 3 +++
 3 files changed, 10 insertions(+), 2 deletions(-)

diff --git a/examples/nettle-benchmark.c b/examples/nettle-benchmark.c
index 5d0e649e..b6e550cf 100644
--- a/examples/nettle-benchmark.c
+++ b/examples/nettle-benchmark.c
@@ -912,8 +912,10 @@ main(int argc, char **argv)
       &amp;nettle_md2, &amp;nettle_md4, &amp;nettle_md5,
       OPENSSL(&amp;nettle_openssl_md5)
       &amp;nettle_sha1, OPENSSL(&amp;nettle_openssl_sha1)
-      &amp;nettle_sha224, &amp;nettle_sha256,
-      &amp;nettle_sha384, &amp;nettle_sha512,
+      &amp;nettle_sha224,
+      &amp;nettle_sha256, OPENSSL(&amp;nettle_openssl_sha256)
+      &amp;nettle_sha384, OPENSSL(&amp;nettle_openssl_sha384)
+      &amp;nettle_sha512, OPENSSL(&amp;nettle_openssl_sha512)
       &amp;nettle_sha512_224, &amp;nettle_sha512_256,
       &amp;nettle_sha3_224, &amp;nettle_sha3_256,
       &amp;nettle_sha3_384, &amp;nettle_sha3_512,
diff --git a/examples/nettle-openssl.c b/examples/nettle-openssl.c
index 19da06fd..f92d77a4 100644
--- a/examples/nettle-openssl.c
+++ b/examples/nettle-openssl.c
@@ -425,5 +425,8 @@ nettle_openssl_##name = {						\
 
 OPENSSL_HASH(MD5, md5)
 OPENSSL_HASH(SHA, sha1)
+OPENSSL_HASH(SHA256, sha256)
+OPENSSL_HASH(SHA512, sha384) // NOTE: SHA512 here is not a typo
+OPENSSL_HASH(SHA512, sha512)
 
 #endif /* WITH_OPENSSL */
diff --git a/nettle-internal.h b/nettle-internal.h
index dc379f1f..f1a27f49 100644
--- a/nettle-internal.h
+++ b/nettle-internal.h
@@ -114,6 +114,9 @@ extern const struct nettle_aead nettle_openssl_arcfour128;
 
 extern const struct nettle_hash nettle_openssl_md5;
 extern const struct nettle_hash nettle_openssl_sha1;
+extern const struct nettle_hash nettle_openssl_sha256;
+extern const struct nettle_hash nettle_openssl_sha384;
+extern const struct nettle_hash nettle_openssl_sha512;
 
 extern const struct nettle_hash * const _nettle_hashes[];
 
-- 
2.25.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200507070659</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-05-07 07:06:59-0400</timestampReceived><subject>Re: [PATCH 0/2] Updating the nettle-benchmark</subject><body>

Emil Velikov &lt;emil.l.velikov@gmail.com&gt; writes:

&gt; As you can see from the second patch, nettle performance is a little low
&gt; wrt OpenSSL - ~55% for sha1, and ~65% for sha2.

I think Nettle's assembly code for sha1 is quite old, and hasn'd been
tuned for current processors with lots of parallelism.

If you analyze the data dependencies of sha1 carefully (I haven't looked
into that for quite a while, though), I think the critical dependency
path requires only 2-3 cycles per round, if instruction issue and
execution can keep up with doing all the instructions not on the
critical path in parallel.

If you look at round function, 

C   e += a &lt;&lt;&lt; 5 + f( b, c, d ) + k + w;
C   b &lt;&lt;&lt;= 30

what this means in practice is that we ought to identify the one of the
a, b, c, d inputs which was updated in the previous round, and arrange
the computation of the round function to use that input last, to
minimize the chain of depending instructions from using that input until
the new e is ready, since that will be the critical path of the round.

If you want to play with that, I would start experimenting with the C
implementation and see what improvements can be made there, and then use
a similar organization for the the assembly implementation(s).

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200508111126</emailId><senderName>Emil Velikov</senderName><senderEmail>emil.l.velikov@gmail.com</senderEmail><timestampReceived>2020-05-08 11:11:26-0400</timestampReceived><subject>Re: [PATCH 1/2] examples: don't use deprecated OpenSSL hashing API</subject><body>

On Thu, 7 May 2020 at 07:51, Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; Emil Velikov &lt;emil.l.velikov@gmail.com&gt; writes:
&gt;
&gt; &gt; The direct $HASH_{Init,Update,Final} has been discouraged for a while.
&gt; &gt; With the upcoming OpenSSL 3.0 it will be officially deprecated.
&gt; &gt;
&gt; &gt; Add a handy macro, to avoid repetition and mistakes like in the current
&gt; &gt; code. Namely - we're using SHA cblock/digest_len for md5 :-\
&gt;
&gt; Thanks. Reducing code duplication with the macro is nice, but I think
&gt; the handling of the context is a bit confusing. In the definiton of the
&gt; nettle_hash structs, you use sizeof (NAME##_CTX), but in the functions
&gt; you cast like (EVP_MD_CTX **)ctx. I think it will de clearer with
&gt; something like
&gt;
&gt; struct openssl_hash_ctx {
&gt;   EVP_MD_CTX *evp;
&gt; };
&gt;
&gt; analogous to struct openssl_cipher_ctx, and use that for all the hash
&gt; functions. And it looks like the update function can be the same for all
&gt; hashes, no need to have the macro define it.
&gt;
Thanks for the suggestions Niels. Will try to update the series in a
couple of days.

-Emil
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200508112747</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-05-08 11:27:47-0400</timestampReceived><subject>Re: [PATCH 1/2] Change ecc_mod_*mul_1 to be per-module callbacks</subject><body>

Hello,

вс, 16 февр. 2020 г. в 00:00, &lt;dbaryshkov@gmail.com&gt;:
&gt;
&gt; From: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
&gt;
&gt; GOST curves will require different "fixups" for fast (mul X mod p)
&gt; operations. Move these operations to ecc_modulo structure and call them
&gt; via function pointer.

These two patches were postponed till 3.6 release. Any chance to get
them reviewed/merged?

-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200510173041</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-05-10 17:30:41-0400</timestampReceived><subject>Re: [PATCH] gitlab-ci: reenable GOST compilation</subject><body>

Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:

&gt;&gt; From: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
&gt;&gt;
&gt;&gt; GnuTLS is now compatible again with Nettle master branch. Remove
&gt;&gt; --disable-gost.
&gt;
&gt; Is there a chance to get this applied? We have corresponding test in
&gt; GnuTLS CI, but it would be nice to have it on both sides.

Pushed to master-updates branch now.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200522150213</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-05-22 15:02:13-0400</timestampReceived><subject>[PATCH 2/2] test/gostdsa-vko: add hashed test vectors from RFC 7836</subject><body>

It was not possible to check gostdsa_vko test vectors with the outputs
from RFC 7836 because Nettle lacked Streebog hash function. Now as the
function is supported, add full test vectors.

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 testsuite/gostdsa-vko-test.c | 45 ++++++++++++++++++++++++++++++++++++
 1 file changed, 45 insertions(+)

diff --git a/testsuite/gostdsa-vko-test.c b/testsuite/gostdsa-vko-test.c
index c8a762b125c2..5d65cd4d15d6 100644
--- a/testsuite/gostdsa-vko-test.c
+++ b/testsuite/gostdsa-vko-test.c
@@ -1,5 +1,6 @@
 #include "testutils.h"
 #include "gostdsa.h"
+#include "streebog.h"
 
 static void
 test_vko (const struct ecc_curve *ecc,
@@ -57,6 +58,9 @@ test_vko (const struct ecc_curve *ecc,
 void
 test_main (void)
 {
+    struct streebog256_ctx ctx_256;
+    struct streebog256_ctx ctx_512;
+
     /* RFC 7836, App B, provides test vectors, values there are little endian.
      *
      * However those test vectors depend on the availability of Streebog hash
@@ -88,4 +92,45 @@ test_main (void)
 		  "3b8e53a1ea920eb1 d7f3d08aa9e47595 4a53ac018c210b48 15451b7accc4a797"
 		  "a2b8faf3d89ee717 d07a857794b9b053 f8e0fd5456ccfcc2 2fd081c873416a3f"));
 
+    /* RFC 7836, App B, 7), values there are little endian, calculation for size A \
*/ +    test_vko(nettle_get_gost_gc512a(),
+	     "67b63ca4ac8d2bb32618d89296c7476dbeb9f9048496f202b1902cf2ce41dbc2f847712d960483458d4b380867f426c7ca0ff5782702dbc44ee8fc72d9ec90c9",
 +	     "51a6d54ee932d176e87591121cce5f395cb2f2f147114d95f463c8a7ed74a9fc5ecd2325a35fb6387831ea66bc3d2aa42ede35872cc75372073a71b983e12f19",
 +	     "793bde5bf72840ad22b02a363ae4772d4a52fc08ba1a20f7458a222a13bf98b53be002d1973f1e398ce46c17da6d00d9b6d0076f8284dcc42e599b4c413b8804",
 +	     SHEX("1d 80 60 3c 85 44 c7 27"),
+	     &amp;nettle_streebog256,
+	     &amp;ctx_256,
+	     SHEX("c9 a9 a7 73 20 e2 cc 55 9e d7 2d ce 6f 47 e2 19 2c ce a9 5f a6 48 67 05 \
82 c0 54 c0 ef 36 c2 21")); +
+    /* RFC 7836, App B, 7), values there are little endian, calculation for size B \
*/ +    test_vko(nettle_get_gost_gc512a(),
+	     "dbd09213a592da5bbfd8ed068cccccbbfbeda4feac96b9b4908591440b0714803b9eb763ef932266d4c0181a9b73eacf9013efc65ec07c888515f1b6f759c848",
 +	     "a7c0adb12743c10c3c1beb97c8f631242f7937a1deb6bce5e664e49261baccd3f5dc56ec53b2abb90ca1eb703078ba546655a8b99f79188d2021ffaba4edb0aa",
 +	     "5adb1c63a4e4465e0bbefd897fb9016475934cfa0f8c95f992ea402d47921f46382d00481b720314b19d8c878e75d81b9763358dd304b2ed3a364e07a3134691",
 +	     SHEX("1d 80 60 3c 85 44 c7 27"),
+	     &amp;nettle_streebog256,
+	     &amp;ctx_256,
+	     SHEX("c9 a9 a7 73 20 e2 cc 55 9e d7 2d ce 6f 47 e2 19 2c ce a9 5f a6 48 67 05 \
82 c0 54 c0 ef 36 c2 21")); +
+    /* RFC 7836, App B, 8), values there are little endian, calculation for size A \
*/ +    test_vko(nettle_get_gost_gc512a(),
+	     "67b63ca4ac8d2bb32618d89296c7476dbeb9f9048496f202b1902cf2ce41dbc2f847712d960483458d4b380867f426c7ca0ff5782702dbc44ee8fc72d9ec90c9",
 +	     "51a6d54ee932d176e87591121cce5f395cb2f2f147114d95f463c8a7ed74a9fc5ecd2325a35fb6387831ea66bc3d2aa42ede35872cc75372073a71b983e12f19",
 +	     "793bde5bf72840ad22b02a363ae4772d4a52fc08ba1a20f7458a222a13bf98b53be002d1973f1e398ce46c17da6d00d9b6d0076f8284dcc42e599b4c413b8804",
 +	     SHEX("1d 80 60 3c 85 44 c7 27"),
+	     &amp;nettle_streebog512,
+	     &amp;ctx_512,
+	     SHEX("79 f0 02 a9 69 40 ce 7b de 32 59 a5 2e 01 52 97 ad aa d8 45 97 a0 d2 05 \
b5 0e 3e 17 19 f9 7b fa" +		  "7e e1 d2 66 1f a9 97 9a 5a a2 35 b5 58 a7 e6 d9 f8 8f \
98 2d d6 3f c3 5a 8e c0 dd 5e 24 2d 3b df")); +
+    /* RFC 7836, App B, 8), values there are little endian, calculation for size B \
*/ +    test_vko(nettle_get_gost_gc512a(),
+	     "dbd09213a592da5bbfd8ed068cccccbbfbeda4feac96b9b4908591440b0714803b9eb763ef932266d4c0181a9b73eacf9013efc65ec07c888515f1b6f759c848",
 +	     "a7c0adb12743c10c3c1beb97c8f631242f7937a1deb6bce5e664e49261baccd3f5dc56ec53b2abb90ca1eb703078ba546655a8b99f79188d2021ffaba4edb0aa",
 +	     "5adb1c63a4e4465e0bbefd897fb9016475934cfa0f8c95f992ea402d47921f46382d00481b720314b19d8c878e75d81b9763358dd304b2ed3a364e07a3134691",
 +	     SHEX("1d 80 60 3c 85 44 c7 27"),
+	     &amp;nettle_streebog512,
+	     &amp;ctx_512,
+	     SHEX("79 f0 02 a9 69 40 ce 7b de 32 59 a5 2e 01 52 97 ad aa d8 45 97 a0 d2 05 \
b5 0e 3e 17 19 f9 7b fa" +		  "7e e1 d2 66 1f a9 97 9a 5a a2 35 b5 58 a7 e6 d9 f8 8f \
98 2d d6 3f c3 5a 8e c0 dd 5e 24 2d 3b df"));  }
-- 
2.26.2

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200528195143</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-05-28 19:51:43-0400</timestampReceived><subject>Re: [PATCH libdrm v2 1/2] examples: don't use deprecated OpenSSL hashing API</subject><body>

Emil Velikov &lt;emil.l.velikov@gmail.com&gt; writes:

&gt; Hope that Niels and the nettle team are OK. It seems strange to have
&gt; ~2 weeks of silence, when the original patches got immediate feedback.

I'm usually a bit busy and tired during the weeks, and it's not all
weekends when I get any hacking time either. And then my attention can
appear a bit bipolar.

It's perfectly fine to ping me, on or off list.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200528204557</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-05-28 20:45:57-0400</timestampReceived><subject>Re: [PATCH libdrm v2 2/2] external: add more openssl sha2 digests to the benchmark</subject><body>

Emil Velikov &lt;emil.l.velikov@gmail.com&gt; writes:

&gt; In particular, this commit adds sha256, sha384 and sha512.

I've pushed the previous part.

&gt; --- a/examples/nettle-openssl.c
&gt; +++ b/examples/nettle-openssl.c
&gt; @@ -432,5 +432,8 @@ nettle_openssl_##name = {						\
&gt;  
&gt;  OPENSSL_HASH(MD5, md5)
&gt;  OPENSSL_HASH(SHA, sha1)
&gt; +OPENSSL_HASH(SHA256, sha256)
&gt; +OPENSSL_HASH(SHA512, sha384) // NOTE: SHA512 here is not a typo

Why doesn't 

  OPENSSL_HASH(SHA384, sha384)

work? Would it help to replace

  NAME##_CBLOCK  

which I guess expands to an openssl constant, with

  NAME##_BLOCK_SIZE

which should be defined by Nettle? In the definition of the OPENSSL_HASH
macro, that is.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200529002511</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-05-29 00:25:11-0400</timestampReceived><subject>Re: [PATCH] (revision 3.2) Added bcrypt() support.</subject><body>

On Thu, May 28, 2020 at 10:22 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; If I get it right, the parameters log2rounds and salt can either be
&gt; provided as explicit arguments, or derived from the scheme string. In
&gt; some way, it would be clenaer with one function taking all parameters as
&gt; explicit arguments (without any scheme string to parse at all), and a
&gt; different one taking it all from the scheme string. Do we need anything
&gt; in the middle, like parsing log2rounds from the scheme string, but the
&gt; salt as a separate binary string?
&gt;

Cleaner, yes.  Easier to use, no.  If we split it up, it becomes cleaner,
but
people using the interface will have more work to do and can mess things
up (more than now).  So, in this case I would prefer ease of use.

It's unusual in the Nettle API to use NUL-terminated strings, we usually
&gt; pass length and data. E.g., the pbkdf2 functions take the input password
&gt; as size_t key_length, const uint8_t *key, even though it's usually an
&gt; ascii string. It's not clear what's best here. Will the algorithm break
&gt; down if we let it process a key input with NUL character in the middle?
&gt;

I don't think it will break down, but I'd need to verify the code.
I understand that this would keep it consistent with the rest of the Nettle
conventions.  I'll see what I can do.


&gt; The length input (first argument) seems redundant, since its only use
&gt; is to check that it's &gt;= BLOWFISH_BCRYPT_HASH_SIZE. When the sie really
&gt; is fixed, it's better to document that and drop that argument.
&gt;

Yes, this can be done.  But here I specifically chose to do it this way so
that
anyway needing to program to the interface has to look up less reference
docs
(more consistent with the other Nettle conventions).
But if you insist, I can change this, of course.


&gt; If you would like to make some easy progress, you could split out the
&gt; patch to create blowfish-internal.h and declare
&gt; _nettle_blowfish_encround in that file. That has no api implications and
&gt; would reduce the size of the main patch.
&gt;

I'll see what I can do.
-- 
Stephen.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200529134512</emailId><senderName>Daniel =?utf-8?B?UC4gQmVycmFuZ8Op?=</senderName><senderEmail>berrange@redhat.com</senderEmail><timestampReceived>2020-05-29 13:45:12-0400</timestampReceived><subject>Re: nettle-benchmark hangs at startup w/ 100% cpu</subject><body>

On Fri, May 29, 2020 at 02:59:26PM +0200, Niels Möller wrote:
&gt; Daniel P. Berrangé &lt;berrange@redhat.com&gt; writes:
&gt; 
&gt; &gt; The elapsed time is the same regardless of ncalls, so I'm thinking that
&gt; &gt; the compiler as been clever and optimized bench_nothing() into literally
&gt; &gt; nothing.  If I modify it to
&gt; &gt;
&gt; &gt; static void
&gt; &gt; bench_nothing(void *arg UNUSED)
&gt; &gt; {
&gt; &gt;   static int i = 0;
&gt; &gt;   i++;
&gt; &gt;   return;
&gt; &gt; }
&gt; &gt;
&gt; &gt; then things work, but of course we're not benchmarking "nothing" anymore.
&gt; 
&gt; Maybe simplest to just delete this part of the benchmark? I don't think
&gt; it's that useful.

After more debugging I found this is due to GCC 10 introdicing the
-finline-functions arg at -O2.

Using -fno-inline-functions fixes the problem.

Alternatively adding __attribute__((noinline))  to "time_function"
fixes it - nb noinline on "bench_nothing" does NOT fix it.

Alternatively adding   assert(ncalls != 0);  in the loop in time_function
fixes it, because causing GCC to stop inlining it. That's largely luck,
but it probably makes sense to have that assert() added regardless as
this loop is inherantly susceptible to this wraparound problem as written.

Regards,
Daniel
-- 
|: https://berrange.com      -o-    https://www.flickr.com/photos/dberrange :|
|: https://libvirt.org         -o-            https://fstop138.berrange.com :|
|: https://entangle-photo.org    -o-    https://www.instagram.com/dberrange :|

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200531081146</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-05-31 08:11:46-0400</timestampReceived><subject>Re: [PATCH 1/2] Implement GOST R 34.11-2012 (Streebog) hash function</subject><body>

Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:

&gt; From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;

This is a bit too large to be easy to review in one go. Could you split
it into a patch with the streebog hash and basic tests only, and hmac
and pbkdf2-related tests as followups? Otherwise, I could try to review
and apply one piece at a time, not sure what process would be most
efficient.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200531084814</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-05-31 08:48:14-0400</timestampReceived><subject>Intel AES-NI perforamnce</subject><body>

I've spent an evening taking a closer look at intel AES performance,
after it was pointed out to me by Torbjörn that the Intel AESNI
instructions are highly pipelined on most or all processors supporting
them. Meaning that the processor can start execution of one even two
instructions per cycle, provided that they are independent, while it
takes several cycles until the results become available for depending
instructions.

Out-of-order (OoO) execution can help to run things in parallel, even if
the instruction stream locally is a sequence of dependent instructions.

E.g., my main development machine has a broadwell processor, and it can
issue one aesni instruction per cycle, and I think the latency is 7 cycles.
Encrypting one block needs 10 aesni instructions (one per round, and then
there's a eleventh subkey applied with plain xor which can issue in
parallel with another instruction in the same cycle).

When I benchmark, aes128 ECB runs in 10.2 cycles per block, which means
that out-of-order execution is very successful, executing many
iterations of the loop in parallel. CBC encrypt, which is inherently
non-parallel, runs *much* slower, I get 91 cycles per block, where the
latency of just the aes encyption wold be 71 cycles (if 7 cycles latency
per aesni instruction is correct, and then one more cycle for the xor
subkey, the remaining 20 cycles for the CBC processing which seems to be
a bit slow in itself).

I'm considering rearranging the loops to interleave multiple blocks. See
below code which implements 4-way interleaving (a drop-in replacement
for x86_64/aesni/aes-encrypt-internal). If this approach turns out to be
useful, might be beneficial to extend to 8-way interleaving: That would
allow instructions to run nicely in parallel even without any
out-of-order-execution.

However, the interleaved code makes no change to performance in my
benchmarks on my machine. Since the old code is close to 10 cycles /
block, which is a hard limit from instruction issue of the aesni
instructions, and it seems almost all other instructions are already
executing in parallel with them.

But it might be an improvement on other processors, or for applications
that process a small number of blocks at a time (in the middle between
CBC which always does one block at a time, and the ECB benchmark which
does 10 KB, or 640 blocks, at a time), by making things easier for the
processor's OoO-machinery.

If you have any application benchmarks it would be interesting if you
could try out the interleaved version. I'm also thinking that maybe we
should add benchmarks for various message sizes?

Regards,
/Niels

C x86_64/aesni/aes-encrypt-internal.asm


ifelse(&lt;
   Copyright (C) 2015, 2018 Niels Möller

   This file is part of GNU Nettle.

   GNU Nettle is free software: you can redistribute it and/or
   modify it under the terms of either:

     * the GNU Lesser General Public License as published by the Free
       Software Foundation; either version 3 of the License, or (at your
       option) any later version.

   or

     * the GNU General Public License as published by the Free
       Software Foundation; either version 2 of the License, or (at your
       option) any later version.

   or both in parallel, as here.

   GNU Nettle is distributed in the hope that it will be useful,
   but WITHOUT ANY WARRANTY; without even the implied warranty of
   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
   General Public License for more details.

   You should have received copies of the GNU General Public License and
   the GNU Lesser General Public License along with this program.  If
   not, see http://www.gnu.org/licenses/.
&gt;)

C Input argument
define(&lt;ROUNDS&gt;, &lt;%rdi&gt;)
define(&lt;KEYS&gt;,	&lt;%rsi&gt;)
C define(&lt;TABLE&gt;,	&lt;%rdx&gt;) C Unused here
define(&lt;LENGTH&gt;,&lt;%rcx&gt;)
define(&lt;DST&gt;,	&lt;%r8&gt;)
define(&lt;SRC&gt;,	&lt;%r9&gt;)
define(&lt;CNT&gt;, &lt;%r10&gt;)
define(&lt;TMP&gt;, &lt;%r10&gt;) C Can overlap CNT
define(&lt;TAB&gt;, &lt;%rdx&gt;)

define(&lt;SUBKEY&gt;, &lt;%xmm0&gt;)
define(&lt;B0&gt;, &lt;%xmm1&gt;)
define(&lt;B1&gt;, &lt;%xmm2&gt;)
define(&lt;B2&gt;, &lt;%xmm3&gt;)
define(&lt;B3&gt;, &lt;%xmm4&gt;)

	.file "aes-encrypt-internal.asm"

	C _aes_encrypt(unsigned rounds, const uint32_t *keys,
	C	       const struct aes_table *T,
	C	       size_t length, uint8_t *dst,
	C	       uint8_t *src)
	.text
	ALIGN(16)
PROLOGUE(_nettle_aes_encrypt)
	W64_ENTRY(6, 5)
	shr	$4, LENGTH
	test	LENGTH, LENGTH
	jz	.Lend

	C Each round uses 16 bytes of subkeys, i.e., 16 bytes. We have
	C an initial xor round, rounds-1 regular rounds, and one final
	C round. Adjust so that ROUNDS reflects the number of regular
	C rounds, KEYS points to the key for the final round, and KEYS
	C + ROUNDS points to the key for the first regular round.

	dec	XREG(ROUNDS)
	shl	$4, XREG(ROUNDS)
	lea	16(ROUNDS, KEYS), KEYS
	neg	ROUNDS

	jmp 	.Loop_end

.Lloop_4w:
	mov 	ROUNDS, CNT
	movups	-16(KEYS, ROUNDS), SUBKEY
	movups	(SRC), B0
	movups	16(SRC), B1
	movups	32(SRC), B2
	movups	48(SRC), B3
	pxor	SUBKEY, B0
	pxor	SUBKEY, B1
	pxor	SUBKEY, B2
	pxor	SUBKEY, B3

.Lround_loop_4w:
	movups	(KEYS, CNT), SUBKEY
	add	$16, CNT
	aesenc	SUBKEY, B0
	aesenc	SUBKEY, B1
	aesenc	SUBKEY, B2
	aesenc	SUBKEY, B3
	jne	.Lround_loop_4w

	movups	(KEYS), SUBKEY
	aesenclast SUBKEY, B0
	aesenclast SUBKEY, B1
	aesenclast SUBKEY, B2
	aesenclast SUBKEY, B3

	movups	B0, (DST)
	movups	B1, 16(DST)
	movups	B2, 32(DST)
	movups	B3, 48(DST)

	add	$64, SRC
	add	$64, DST

	sub	$4, LENGTH

.Loop_end:
	cmp	$4, LENGTH
	jnc	.Lloop_4w

	lea	.Ljmptab(%rip), TAB
	movslq	(TAB, LENGTH, 4), TMP
	lea	(TAB, TMP), TMP
	jmp	*TMP

.Ltail3:
	mov 	ROUNDS, CNT
	movups	-16(KEYS, ROUNDS), SUBKEY
	movups	(SRC), B0
	movups	16(SRC), B1
	movups	32(SRC), B2
	pxor	SUBKEY, B0
	pxor	SUBKEY, B1
	pxor	SUBKEY, B2

.Lround_loop_3w:
	movups	(KEYS, CNT), SUBKEY
	add	$16, CNT
	aesenc	SUBKEY, B0
	aesenc	SUBKEY, B1
	aesenc	SUBKEY, B2
	jne	.Lround_loop_3w

	movups	(KEYS), SUBKEY
	aesenclast SUBKEY, B0
	aesenclast SUBKEY, B1
	aesenclast SUBKEY, B2

	movups	B0, (DST)
	movups	B1, 16(DST)
	movups	B2, 32(DST)
	jmp	.Lend

.Ltail2:
	mov 	ROUNDS, CNT
	movups	-16(KEYS, ROUNDS), SUBKEY
	movups	(SRC), B0
	movups	16(SRC), B1
	pxor	SUBKEY, B0
	pxor	SUBKEY, B1

.Lround_loop_2w:
	movups	(KEYS, CNT), SUBKEY
	add	$16, CNT
	aesenc	SUBKEY, B0
	aesenc	SUBKEY, B1
	jne	.Lround_loop_2w

	movups	(KEYS), SUBKEY
	aesenclast SUBKEY, B0
	aesenclast SUBKEY, B1

	movups	B0, (DST)
	movups	B1, 16(DST)
	jmp	.Lend

.Ltail1:
	mov 	ROUNDS, CNT
	movups	-16(KEYS, ROUNDS), SUBKEY
	movups	(SRC), B0
	pxor	SUBKEY, B0


.Lround_loop_1w:
	movups	(KEYS, CNT), SUBKEY
	add	$16, CNT
	aesenc	SUBKEY, B0
	jne	.Lround_loop_1w

	movups	(KEYS), SUBKEY
	aesenclast SUBKEY, B0

	movups	B0, (DST)

.Lend:
	W64_EXIT(6, 5)
	ret
EPILOGUE(_nettle_aes_encrypt)

C FIXME: Put in rodata?
	ALIGN(4)
.Ljmptab:
	.long .Lend - .Ljmptab
	.long .Ltail1 - .Ljmptab
	.long .Ltail2 - .Ljmptab
	.long .Ltail3 - .Ljmptab

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200506153325</emailId><senderName>Emil Velikov</senderName><senderEmail>emil.l.velikov@gmail.com</senderEmail><timestampReceived>2020-05-06 15:33:25-0400</timestampReceived><subject>[PATCH 0/2] Updating the nettle-benchmark</subject><body>

Hi all,

Here are a couple of small patches for nettle-benchmark:
 - removes the deprecated OpenSSL hash API
 - adds more OpenSSL sha2 hashes into the mix

Kindly merge or let me know of your concerns :-)



Related question:

As you can see from the second patch, nettle performance is a little low
wrt OpenSSL - ~55% for sha1, and ~65% for sha2.

Is that normal, or there is something off with my system/build?

I'm using the default "--enable-assembler" and "-O2" as seen in the
configure.ac, plus my processor lacks the SHA_NI ISA.


Thanks
Emil
P.S. More misc patches coming shortly, so stay tuned :-P


Emil Velikov (2):
  examples: don't use deprecated OpenSSL hashing API
  external: add more openssl sha2 digests to the benchmark

 examples/nettle-benchmark.c |   6 +-
 examples/nettle-openssl.c   | 112 ++++++++++++++----------------------
 nettle-internal.h           |   3 +
 3 files changed, 50 insertions(+), 71 deletions(-)

-- 
2.25.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200506153326</emailId><senderName>Emil Velikov</senderName><senderEmail>emil.l.velikov@gmail.com</senderEmail><timestampReceived>2020-05-06 15:33:26-0400</timestampReceived><subject>[PATCH 1/2] examples: don't use deprecated OpenSSL hashing API</subject><body>

The direct $HASH_{Init,Update,Final} has been discouraged for a while.
With the upcoming OpenSSL 3.0 it will be officially deprecated.

Add a handy macro, to avoid repetition and mistakes like in the current
code. Namely - we're using SHA cblock/digest_len for md5 :-\

The macro will also make it easier to add more, as seen with next patch.

Signed-off-by: Emil Velikov &lt;emil.l.velikov@gmail.com&gt;
---
 examples/nettle-openssl.c | 109 ++++++++++++++------------------------
 1 file changed, 40 insertions(+), 69 deletions(-)

diff --git a/examples/nettle-openssl.c b/examples/nettle-openssl.c
index bb2e6627..19da06fd 100644
--- a/examples/nettle-openssl.c
+++ b/examples/nettle-openssl.c
@@ -383,76 +383,47 @@ nettle_openssl_cast128 = {
 
 /* Hash functions */
 
-/* md5 */
-static nettle_hash_init_func openssl_md5_init;
-static void
-openssl_md5_init(void *ctx)
-{
-  MD5_Init(ctx);
-}
-
-static nettle_hash_update_func openssl_md5_update;
-static void
-openssl_md5_update(void *ctx,
-		   size_t length,
-		   const uint8_t *src)
-{
-  MD5_Update(ctx, src, length);
-}
-
-static nettle_hash_digest_func openssl_md5_digest;
-static void
-openssl_md5_digest(void *ctx,
-		   size_t length, uint8_t *dst)
-{
-  assert(length == SHA_DIGEST_LENGTH);
-  MD5_Final(dst, ctx);
-  MD5_Init(ctx);
-}
-
-const struct nettle_hash
-nettle_openssl_md5 = {
-  "openssl md5", sizeof(SHA_CTX),
-  SHA_DIGEST_LENGTH, SHA_CBLOCK,
-  openssl_md5_init,
-  openssl_md5_update,
-  openssl_md5_digest
+#define OPENSSL_HASH(NAME, name)					\
+static nettle_hash_init_func openssl_##name##_init;			\
+static void								\
+openssl_##name##_init(void *ctx)					\
+{									\
+  if ((*(EVP_MD_CTX **)ctx = EVP_MD_CTX_new()) == NULL)			\
+    return;								\
+									\
+  EVP_DigestInit(*(EVP_MD_CTX **)ctx, EVP_##name());			\
+}									\
+									\
+static nettle_hash_update_func openssl_##name##_update;			\
+static void								\
+openssl_##name##_update(void *ctx,					\
+		    size_t length,					\
+		    const uint8_t *src)					\
+{									\
+  EVP_DigestUpdate(*(EVP_MD_CTX **)ctx, src, length);			\
+}									\
+									\
+static nettle_hash_digest_func openssl_##name##_digest;			\
+static void								\
+openssl_##name##_digest(void *ctx,					\
+		    size_t length, uint8_t *dst)			\
+{									\
+  assert(length == NAME##_DIGEST_LENGTH);				\
+									\
+  EVP_DigestFinal(*(EVP_MD_CTX **)ctx, dst, NULL);			\
+  EVP_DigestInit(*(EVP_MD_CTX **)ctx, EVP_##name());			\
+}									\
+									\
+const struct nettle_hash						\
+nettle_openssl_##name = {						\
+  "openssl " #name, sizeof(NAME##_CTX),					\
+  NAME##_DIGEST_LENGTH, NAME##_CBLOCK,					\
+  openssl_##name##_init,						\
+  openssl_##name##_update,						\
+  openssl_##name##_digest						\
 };
 
-/* sha1 */
-static nettle_hash_init_func openssl_sha1_init;
-static void
-openssl_sha1_init(void *ctx)
-{
-  SHA1_Init(ctx);
-}
-
-static nettle_hash_update_func openssl_sha1_update;
-static void
-openssl_sha1_update(void *ctx,
-		    size_t length,
-		    const uint8_t *src)
-{
-  SHA1_Update(ctx, src, length);
-}
-
-static nettle_hash_digest_func openssl_sha1_digest;
-static void
-openssl_sha1_digest(void *ctx,
-		    size_t length, uint8_t *dst)
-{
-  assert(length == SHA_DIGEST_LENGTH);
-  SHA1_Final(dst, ctx);
-  SHA1_Init(ctx);
-}
+OPENSSL_HASH(MD5, md5)
+OPENSSL_HASH(SHA, sha1)
 
-const struct nettle_hash
-nettle_openssl_sha1 = {
-  "openssl sha1", sizeof(SHA_CTX),
-  SHA_DIGEST_LENGTH, SHA_CBLOCK,
-  openssl_sha1_init,
-  openssl_sha1_update,
-  openssl_sha1_digest
-};
-  
 #endif /* WITH_OPENSSL */
-- 
2.25.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200508112538</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-05-08 11:25:38-0400</timestampReceived><subject>Re: [PATCH] gitlab-ci: reenable GOST compilation</subject><body>

вт, 11 февр. 2020 г. в 22:58, &lt;dbaryshkov@gmail.com&gt;:
&gt;
&gt; From: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
&gt;
&gt; GnuTLS is now compatible again with Nettle master branch. Remove
&gt; --disable-gost.

Is there a chance to get this applied? We have corresponding test in
GnuTLS CI, but it would be nice to have it on both sides.

&gt; Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
&gt; ---
&gt;  .gitlab-ci.yml | 2 +-
&gt;  1 file changed, 1 insertion(+), 1 deletion(-)
&gt;
&gt; diff --git a/.gitlab-ci.yml b/.gitlab-ci.yml
&gt; index 663f98f5cb8e..5b348f38568f 100644
&gt; --- a/.gitlab-ci.yml
&gt; +++ b/.gitlab-ci.yml
&gt; @@ -100,7 +100,7 @@ build/gnutls:
&gt;      make -j4 &amp;&amp; make install
&gt;    - git clone --depth 1 --branch master https://gitlab.com/gnutls/gnutls.git gnutls-git
&gt;    - cd gnutls-git &amp;&amp; git submodule update --init &amp;&amp; ./bootstrap &amp;&amp;
&gt; -    ./configure --disable-gost --disable-cxx --disable-guile --disable-doc &amp;&amp; make -j$(nproc) &amp;&amp;
&gt; +    ./configure --disable-cxx --disable-guile --disable-doc &amp;&amp; make -j$(nproc) &amp;&amp;
&gt;      make -j $(nproc) check
&gt;    tags:
&gt;    - shared
&gt; --
&gt; 2.25.0
&gt;


-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200511084322</emailId><senderName>Emil Velikov</senderName><senderEmail>emil.l.velikov@gmail.com</senderEmail><timestampReceived>2020-05-11 08:43:22-0400</timestampReceived><subject>[PATCH libdrm v2 1/2] examples: don't use deprecated OpenSSL hashing API</subject><body>

The direct $HASH_{Init,Update,Final} has been discouraged for a while.
With the upcoming OpenSSL 3.0 it will be officially deprecated.

Add a handy macro, to avoid repetition and mistakes like in the current
code. Namely - we're using SHA cblock/digest_len for md5 :-\

The macro will also make it easier to add more, as seen with next patch.

v2: Align it with the crypto implementations, namely:
 - use openssh_hash_ctx::evp, use correct sizeof()
 - move hash_update out of the macro
 - remove forward declarations for hash functions

Signed-off-by: Emil Velikov &lt;emil.l.velikov@gmail.com&gt;
---
 examples/nettle-openssl.c | 110 +++++++++++++++-----------------------
 1 file changed, 44 insertions(+), 66 deletions(-)

diff --git a/examples/nettle-openssl.c b/examples/nettle-openssl.c
index bb2e6627..3c487013 100644
--- a/examples/nettle-openssl.c
+++ b/examples/nettle-openssl.c
@@ -62,6 +62,13 @@ struct openssl_cipher_ctx {
   EVP_CIPHER_CTX *evp;
 };
 
+/* We use Openssl's EVP api for all openssl hashes. This API selects
+   platform-specific implementations if appropriate, e.g., using x86
+   AES-NI instructions. */
+struct openssl_hash_ctx {
+  EVP_MD_CTX *evp;
+};
+
 void
 nettle_openssl_init(void)
 {
@@ -383,76 +390,47 @@ nettle_openssl_cast128 = {
 
 /* Hash functions */
 
-/* md5 */
-static nettle_hash_init_func openssl_md5_init;
-static void
-openssl_md5_init(void *ctx)
-{
-  MD5_Init(ctx);
-}
-
-static nettle_hash_update_func openssl_md5_update;
-static void
-openssl_md5_update(void *ctx,
-		   size_t length,
-		   const uint8_t *src)
-{
-  MD5_Update(ctx, src, length);
-}
-
-static nettle_hash_digest_func openssl_md5_digest;
-static void
-openssl_md5_digest(void *ctx,
-		   size_t length, uint8_t *dst)
-{
-  assert(length == SHA_DIGEST_LENGTH);
-  MD5_Final(dst, ctx);
-  MD5_Init(ctx);
-}
-
-const struct nettle_hash
-nettle_openssl_md5 = {
-  "openssl md5", sizeof(SHA_CTX),
-  SHA_DIGEST_LENGTH, SHA_CBLOCK,
-  openssl_md5_init,
-  openssl_md5_update,
-  openssl_md5_digest
-};
-
-/* sha1 */
-static nettle_hash_init_func openssl_sha1_init;
-static void
-openssl_sha1_init(void *ctx)
-{
-  SHA1_Init(ctx);
-}
-
-static nettle_hash_update_func openssl_sha1_update;
 static void
-openssl_sha1_update(void *ctx,
+openssl_hash_update(void *p,
 		    size_t length,
 		    const uint8_t *src)
 {
-  SHA1_Update(ctx, src, length);
-}
+  struct openssl_hash_ctx *ctx = p;
+  EVP_DigestUpdate(ctx-&gt;evp, src, length);
+}
+
+#define OPENSSL_HASH(NAME, name)					\
+static void								\
+openssl_##name##_init(void *p)						\
+{									\
+  struct openssl_hash_ctx *ctx = p;					\
+  if ((ctx-&gt;evp = EVP_MD_CTX_new()) == NULL)			\
+    return;								\
+									\
+  EVP_DigestInit(ctx-&gt;evp, EVP_##name());				\
+}									\
+									\
+static void								\
+openssl_##name##_digest(void *p,					\
+		    size_t length, uint8_t *dst)			\
+{									\
+  struct openssl_hash_ctx *ctx = p;					\
+  assert(length == NAME##_DIGEST_LENGTH);				\
+									\
+  EVP_DigestFinal(ctx-&gt;evp, dst, NULL);					\
+  EVP_DigestInit(ctx-&gt;evp, EVP_##name());				\
+}									\
+									\
+const struct nettle_hash						\
+nettle_openssl_##name = {						\
+  "openssl " #name, sizeof(struct openssl_hash_ctx),			\
+  NAME##_DIGEST_LENGTH, NAME##_CBLOCK,					\
+  openssl_##name##_init,						\
+  openssl_hash_update,							\
+  openssl_##name##_digest						\
+};
 
-static nettle_hash_digest_func openssl_sha1_digest;
-static void
-openssl_sha1_digest(void *ctx,
-		    size_t length, uint8_t *dst)
-{
-  assert(length == SHA_DIGEST_LENGTH);
-  SHA1_Final(dst, ctx);
-  SHA1_Init(ctx);
-}
+OPENSSL_HASH(MD5, md5)
+OPENSSL_HASH(SHA, sha1)
 
-const struct nettle_hash
-nettle_openssl_sha1 = {
-  "openssl sha1", sizeof(SHA_CTX),
-  SHA_DIGEST_LENGTH, SHA_CBLOCK,
-  openssl_sha1_init,
-  openssl_sha1_update,
-  openssl_sha1_digest
-};
-  
 #endif /* WITH_OPENSSL */
-- 
2.25.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200511084323</emailId><senderName>Emil Velikov</senderName><senderEmail>emil.l.velikov@gmail.com</senderEmail><timestampReceived>2020-05-11 08:43:23-0400</timestampReceived><subject>[PATCH libdrm v2 2/2] external: add more openssl sha2 digests to the benchmark</subject><body>

In particular, this commit adds sha256, sha384 and sha512.

Rough numbers from my system:

         Algorithm         mode Mbyte/s
              sha1       update  462.05
      openssl sha1       update  804.90
            sha256       update  222.32
    openssl sha256       update  369.49
            sha384       update  355.34
    openssl sha384       update  536.05
            sha512       update  355.90
    openssl sha512       update  546.07

Signed-off-by: Emil Velikov &lt;emil.l.velikov@gmail.com&gt;
---
 examples/nettle-benchmark.c | 6 ++++--
 examples/nettle-openssl.c   | 3 +++
 nettle-internal.h           | 3 +++
 3 files changed, 10 insertions(+), 2 deletions(-)

diff --git a/examples/nettle-benchmark.c b/examples/nettle-benchmark.c
index 5d0e649e..b6e550cf 100644
--- a/examples/nettle-benchmark.c
+++ b/examples/nettle-benchmark.c
@@ -912,8 +912,10 @@ main(int argc, char **argv)
       &amp;nettle_md2, &amp;nettle_md4, &amp;nettle_md5,
       OPENSSL(&amp;nettle_openssl_md5)
       &amp;nettle_sha1, OPENSSL(&amp;nettle_openssl_sha1)
-      &amp;nettle_sha224, &amp;nettle_sha256,
-      &amp;nettle_sha384, &amp;nettle_sha512,
+      &amp;nettle_sha224,
+      &amp;nettle_sha256, OPENSSL(&amp;nettle_openssl_sha256)
+      &amp;nettle_sha384, OPENSSL(&amp;nettle_openssl_sha384)
+      &amp;nettle_sha512, OPENSSL(&amp;nettle_openssl_sha512)
       &amp;nettle_sha512_224, &amp;nettle_sha512_256,
       &amp;nettle_sha3_224, &amp;nettle_sha3_256,
       &amp;nettle_sha3_384, &amp;nettle_sha3_512,
diff --git a/examples/nettle-openssl.c b/examples/nettle-openssl.c
index 3c487013..517ed724 100644
--- a/examples/nettle-openssl.c
+++ b/examples/nettle-openssl.c
@@ -432,5 +432,8 @@ nettle_openssl_##name = {						\
 
 OPENSSL_HASH(MD5, md5)
 OPENSSL_HASH(SHA, sha1)
+OPENSSL_HASH(SHA256, sha256)
+OPENSSL_HASH(SHA512, sha384) // NOTE: SHA512 here is not a typo
+OPENSSL_HASH(SHA512, sha512)
 
 #endif /* WITH_OPENSSL */
diff --git a/nettle-internal.h b/nettle-internal.h
index dc379f1f..f1a27f49 100644
--- a/nettle-internal.h
+++ b/nettle-internal.h
@@ -114,6 +114,9 @@ extern const struct nettle_aead nettle_openssl_arcfour128;
 
 extern const struct nettle_hash nettle_openssl_md5;
 extern const struct nettle_hash nettle_openssl_sha1;
+extern const struct nettle_hash nettle_openssl_sha256;
+extern const struct nettle_hash nettle_openssl_sha384;
+extern const struct nettle_hash nettle_openssl_sha512;
 
 extern const struct nettle_hash * const _nettle_hashes[];
 
-- 
2.25.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200511090610</emailId><senderName>Emil Velikov</senderName><senderEmail>emil.l.velikov@gmail.com</senderEmail><timestampReceived>2020-05-11 09:06:10-0400</timestampReceived><subject>Re: [PATCH libdrm v2 1/2] examples: don't use deprecated OpenSSL hashing API</subject><body>

Hi all,

Please ignore the "libdrm" in the header. Not sure how it got there.

-Emil
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200522112931</emailId><senderName>Emil Velikov</senderName><senderEmail>emil.l.velikov@gmail.com</senderEmail><timestampReceived>2020-05-22 11:29:31-0400</timestampReceived><subject>Re: [PATCH libdrm v2 1/2] examples: don't use deprecated OpenSSL hashing API</subject><body>

On Mon, 11 May 2020 at 09:46, Emil Velikov &lt;emil.l.velikov@gmail.com&gt; wrote:
&gt;
&gt; The direct $HASH_{Init,Update,Final} has been discouraged for a while.
&gt; With the upcoming OpenSSL 3.0 it will be officially deprecated.
&gt;
&gt; Add a handy macro, to avoid repetition and mistakes like in the current
&gt; code. Namely - we're using SHA cblock/digest_len for md5 :-\
&gt;
&gt; The macro will also make it easier to add more, as seen with next patch.
&gt;
&gt; v2: Align it with the crypto implementations, namely:
&gt;  - use openssh_hash_ctx::evp, use correct sizeof()
&gt;  - move hash_update out of the macro
&gt;  - remove forward declarations for hash functions
&gt;
Humble poke?

Hope that Niels and the nettle team are OK. It seems strange to have
~2 weeks of silence, when the original patches got immediate feedback.

-Emil
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200504174710</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-05-04 17:47:10-0400</timestampReceived><subject>Re: [PATCH] (revision 3.2) Added bcrypt() support.</subject><body>

Changes since 3.1: Took out the tablesize optimisations.

---
 Makefile.in                       |   2 +-
 blowfish-bcrypt.c                 | 519 ++++++++++++++++++++++++++++++
 blowfish.h =&gt; blowfish-internal.h |  51 +--
 blowfish.c                        |  23 +-
 blowfish.h                        |  15 +
 nettle.texinfo                    |  67 ++++
 6 files changed, 621 insertions(+), 56 deletions(-)
 create mode 100644 blowfish-bcrypt.c
 copy blowfish.h =&gt; blowfish-internal.h (50%)

diff --git a/Makefile.in b/Makefile.in
index e5ccfc76..4ddbb32e 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -73,7 +73,7 @@ nettle_SOURCES = aes-decrypt-internal.c aes-decrypt.c \
 		 aes256-set-encrypt-key.c aes256-set-decrypt-key.c \
 		 aes256-meta.c \
 		 arcfour.c arcfour-crypt.c \
-		 arctwo.c arctwo-meta.c blowfish.c \
+		 arctwo.c arctwo-meta.c blowfish.c blowfish-bcrypt.c \
 		 base16-encode.c base16-decode.c base16-meta.c \
 		 base64-encode.c base64-decode.c base64-meta.c \
 		 base64url-encode.c base64url-decode.c base64url-meta.c \
diff --git a/blowfish-bcrypt.c b/blowfish-bcrypt.c
new file mode 100644
index 00000000..0354dbe6
--- /dev/null
+++ b/blowfish-bcrypt.c
@@ -0,0 +1,519 @@
+/* blowfish-bcrypt.c
+
+   The blowfish bcrypt implementation.
+
+   Copyright (c) 2020 Stephen R. van den Berg
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+#include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;string.h&gt;
+#include &lt;stdlib.h&gt;
+
+#include "blowfish.h"
+#include "blowfish-internal.h"
+#include "base64.h"
+
+#include "macros.h"
+
+#define CRYPTPLEN 7
+#define SALTLEN ((BLOWFISH_BCRYPT_BINSALT_SIZE*8+5) / 6)
+
+#define HASHOFFSET (CRYPTPLEN + SALTLEN)
+
+static const signed char radix64_decode_table[0x100] = {
+  /* White space is HT, VT, FF, CR, LF and SPC */
+  -1, -1, -1, -1, -1, -1, -1, -1, -1, -2, -2, -2, -2, -2, -1, -1,
+  -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+  -2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  1,
+  54, 55, 56, 57, 58, 59, 60, 61, 62, 63, -1, -1, -1, -3, -1, -1,
+  -1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,
+  17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, -1, -1, -1, -1, -1,
+  -1, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42,
+  43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, -1, -1, -1, -1, -1,
+  -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+  -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+  -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+  -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+  -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+  -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+  -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+  -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+};
+
+static const char radix64_encode_table[64] =
+  "./ABCDEFGHIJKLMNOPQRSTUVWXYZ"
+    "abcdefghijklmnopqrstuvwxyz"
+    "0123456789";
+
+int
+blowfish_bcrypt_verify(const char *key,
+                       const char *hashed)
+{
+  char newhash[BLOWFISH_BCRYPT_HASH_SIZE];
+
+  return blowfish_bcrypt_hash(sizeof newhash,
+                              newhash, key, hashed, -1, (void*)0)
+   &amp;&amp; !strcmp(newhash, hashed);
+}
+
+static char *encode_radix64(char *dst, size_t len, const uint8_t *src)
+{
+  struct base64_encode_ctx ctx;
+  base64_encode_init(&amp;ctx);
+  ctx.alphabet = radix64_encode_table;
+  dst += base64_encode_update(&amp;ctx, dst, len, src);
+  dst += base64_encode_final(&amp;ctx, dst);
+  *--dst = '\0';	    /* Strip the trailing = */
+  return dst;
+}
+
+/*
+ * Large parts of the code below are based on public domain sources.
+ * The comments and copyright notices have been preserved.
+ * Any code added or modified by me is licensed under the
+ * licenses listed above.  --  Stephen R. van den Berg
+ */
+
+/*
+ * This code comes from John the Ripper password cracker, with reentrant
+ * and crypt(3) interfaces added, but optimizations specific to password
+ * cracking removed.
+ *
+ * Written by Solar Designer &lt;solar at openwall.com&gt; in 1998-2015.
+ * No copyright is claimed, and the software is hereby placed in the public
+ * domain. In case this attempt to disclaim copyright and place the software
+ * in the public domain is deemed null and void, then the software is
+ * Copyright (c) 1998-2015 Solar Designer and it is hereby released to the
+ * general public under the following terms:
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted.
+ *
+ * There's ABSOLUTELY NO WARRANTY, express or implied.
+ *
+ * It is my intent that you should be able to use this on your system,
+ * as part of a software package, or anywhere else to improve security,
+ * ensure compatibility, or for any other purpose. I would appreciate
+ * it if you give credit where it is due and keep your modifications in
+ * the public domain as well, but I don't require that in order to let
+ * you place this code and any modifications you make under a license
+ * of your choice.
+ *
+ * This implementation is fully compatible with OpenBSD's bcrypt.c for prefix
+ * "$2b$", originally by Niels Provos &lt;provos at citi.umich.edu&gt;, and it uses
+ * some of his ideas. The password hashing algorithm was designed by David
+ * Mazieres &lt;dm at lcs.mit.edu&gt;. For information on the level of
+ * compatibility for bcrypt hash prefixes other than "$2b$", please refer to
+ * the comments in set_key() below and to the included crypt(3) man page.
+ */
+
+typedef uint32_t bf_key[_BLOWFISH_ROUNDS + 2];
+
+/*
+ * Magic IV for 64 Blowfish encryptions that we do at the end.
+ * The string is "OrpheanBeholderScryDoubt" on big-endian.
+ */
+static uint32_t magic_w[6] = {
+  0x4F727068, 0x65616E42, 0x65686F6C,
+  0x64657253, 0x63727944, 0x6F756274
+};
+
+static void swap32(uint32_t *x, int count)
+{
+#if !WORDS_BIGENDIAN
+  do {
+    uint32_t tmp = *x;
+    tmp = (tmp &lt;&lt; 16) | (tmp &gt;&gt; 16);
+    *x++ = ((tmp &amp; 0x00FF00FF) &lt;&lt; 8) | ((tmp &gt;&gt; 8) &amp; 0x00FF00FF);
+  } while (--count);
+#endif
+}
+
+static void set_xkey(const char *key, bf_key expanded, bf_key initial,
+    unsigned bug, uint32_t safety)
+{
+  const char *ptr = key;
+  unsigned i, j;
+  uint32_t sign, diff, tmp[2];
+
+/*
+ * There was a sign extension bug in older revisions of this function. While
+ * we would have liked to simply fix the bug and move on, we have to provide
+ * a backwards compatibility feature (essentially the bug) for some systems and
+ * a safety measure for some others. The latter is needed because for certain
+ * multiple inputs to the buggy algorithm there exist easily found inputs to
+ * the correct algorithm that produce the same hash. Thus, we optionally
+ * deviate from the correct algorithm just enough to avoid such collisions.
+ * While the bug itself affected the majority of passwords containing
+ * characters with the 8th bit set (although only a percentage of those in a
+ * collision-producing way), the anti-collision safety measure affects
+ * only a subset of passwords containing the '\xff' character (not even all of
+ * those passwords, just some of them). This character is not found in valid
+ * UTF-8 sequences and is rarely used in popular 8-bit character encodings.
+ * Thus, the safety measure is unlikely to cause much annoyance, and is a
+ * reasonable tradeoff to use when authenticating against existing hashes that
+ * are not reliably known to have been computed with the correct algorithm.
+ *
+ * We use an approach that tries to minimize side-channel leaks of password
+ * information - that is, we mostly use fixed-cost bitwise operations instead
+ * of branches or table lookups. (One conditional branch based on password
+ * length remains. It is not part of the bug aftermath, though, and is
+ * difficult and possibly unreasonable to avoid given the use of C strings by
+ * the caller, which results in similar timing leaks anyway.)
+ *
+ * For actual implementation, we set an array index in the variable "bug"
+ * (0 means no bug, 1 means sign extension bug emulation) and a flag in the
+ * variable "safety" (bit 16 is set when the safety measure is requested).
+ * Valid combinations of settings are:
+ *
+ * Prefix "$2a$": bug = 0, safety = 0x10000
+ * Prefix "$2b$": bug = 0, safety = 0
+ * Prefix "$2x$": bug = 1, safety = 0
+ * Prefix "$2y$": bug = 0, safety = 0
+ */
+
+  sign = diff = 0;
+
+  for (i = 0; i &lt; _BLOWFISH_ROUNDS + 2; i++) {
+    tmp[0] = tmp[1] = 0;
+    for (j = 0; j &lt; 4; j++) {
+      tmp[0] &lt;&lt;= 8;
+      tmp[0] |= (unsigned char)*ptr; /* correct */
+      tmp[1] &lt;&lt;= 8;
+      tmp[1] |= (signed char)*ptr; /* bug */
+/*
+ * Sign extension in the first char has no effect - nothing to overwrite yet,
+ * and those extra 24 bits will be fully shifted out of the 32-bit word. For
+ * chars 2, 3, 4 in each four-char block, we set bit 7 of "sign" if sign
+ * extension in tmp[1] occurs. Once this flag is set, it remains set.
+ */
+      if (j)
+        sign |= tmp[1] &amp; 0x80;
+      if (!*ptr)
+        ptr = key;
+      else
+        ptr++;
+    }
+    diff |= tmp[0] ^ tmp[1]; /* Non-zero on any differences */
+
+    expanded[i] = tmp[bug];
+    initial[i] = _nettle_blowfish_initial_ctx.p[i] ^ tmp[bug];
+  }
+
+/*
+ * At this point, "diff" is zero if the correct and buggy algorithms produced
+ * exactly the same result. If so and if "sign" is non-zero, which indicates
+ * that there was a non-benign sign extension, this means that we have a
+ * collision between the correctly computed hash for this password and a set of
+ * passwords that could be supplied to the buggy algorithm. Our safety measure
+ * is meant to protect from such many-buggy to one-correct collisions, by
+ * deviating from the correct algorithm in such cases. Let's check for this.
+ */
+  diff |= diff &gt;&gt; 16; /* still zero if exact match */
+  diff &amp;= 0xffff; /* ditto */
+  diff += 0xffff; /* bit 16 set if "diff" was non-zero (on non-match) */
+  sign &lt;&lt;= 9; /* move the non-benign sign extension flag to bit 16 */
+  sign &amp;= ~diff &amp; safety; /* action needed? */
+
+/*
+ * If we have determined that we need to deviate from the correct algorithm,
+ * flip bit 16 in initial expanded key. (The choice of 16 is arbitrary, but
+ * let's stick to it now. It came out of the approach we used above, and it's
+ * not any worse than any other choice we could make.)
+ *
+ * It is crucial that we don't do the same to the expanded key used in the main
+ * Eksblowfish loop. By doing it to only one of these two, we deviate from a
+ * state that could be directly specified by a password to the buggy algorithm
+ * (and to the fully correct one as well, but that's a side-effect).
+ */
+  initial[0] ^= sign;
+}
+
+static int ibcrypt(size_t length, char *dst,
+                   const char *key, const char *scheme,
+		   int minlog2rounds,
+		   int log2rounds, const uint8_t *salt)
+{
+  struct {
+    struct blowfish_ctx ctx;
+    bf_key expanded_key;
+    union {
+      uint32_t salt[4];
+      uint32_t output[6];
+    } binary;
+  } data;
+  uint8_t psalt[BLOWFISH_BCRYPT_BINSALT_SIZE];
+  uint32_t L, R;
+  uint32_t *ptr;
+  uint32_t count;
+  int i;
+  size_t schemelen = strlen(scheme);
+  unsigned cscheme;
+  unsigned bug = 0;
+  uint32_t safety = 0;
+  if (length &lt; BLOWFISH_BCRYPT_HASH_SIZE ||
+      schemelen &lt; 2)
+    return 0;
+
+  if (schemelen &gt;= 3 &amp;&amp; *scheme++ != '$')
+    return 0;
+  if (*scheme++ != '2')
+    return 0;
+
+  switch (cscheme = *scheme++) {
+    default:
+      return 0;
+    case 'a': safety = 0x10000;
+      break;
+    case 'x': bug = 1;
+      break;
+    case 'b': case 'y':
+      break;
+  }
+
+  if (schemelen &gt;= 4) {
+    if (*scheme++ != '$')
+      return 0;
+    if (schemelen &gt;= 6) {
+      if (log2rounds &lt; 0)
+        log2rounds = atoi(scheme);
+      scheme += 2;
+      if (schemelen &gt;= CRYPTPLEN &amp;&amp; *scheme++ != '$')
+	return 0;
+      if (schemelen &gt;= HASHOFFSET &amp;&amp; !salt) {
+        struct base64_decode_ctx ctx;
+        size_t saltlen = BLOWFISH_BCRYPT_BINSALT_SIZE;
+
+        base64_decode_init(&amp;ctx);
+        ctx.table = radix64_decode_table;
+
+        if (!base64_decode_update(&amp;ctx, &amp;saltlen, (uint8_t *) data.binary.salt,
+                                  SALTLEN, scheme)
+         || saltlen != BLOWFISH_BCRYPT_BINSALT_SIZE)
+          return 0;
+      }
+    }
+  }
+
+  if (salt)
+    memcpy(data.binary.salt, salt, BLOWFISH_BCRYPT_BINSALT_SIZE);
+  else if (schemelen &lt; HASHOFFSET)
+    return 0;
+  memcpy(psalt, data.binary.salt, BLOWFISH_BCRYPT_BINSALT_SIZE);
+  swap32(data.binary.salt, 4);
+
+  if (log2rounds &lt; minlog2rounds || log2rounds &gt; 31)
+    return 0;
+  count = (uint32_t)1 &lt;&lt; log2rounds;
+
+  set_xkey(key, data.expanded_key, data.ctx.p, bug, safety);
+  memcpy(data.ctx.s, _nettle_blowfish_initial_ctx.s, sizeof(data.ctx.s));
+
+  L = R = 0;
+  for (i = 0; i &lt; _BLOWFISH_ROUNDS + 2; i += 2) {
+    L ^= data.binary.salt[i &amp; 2];
+    R ^= data.binary.salt[(i &amp; 2) + 1];
+    _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+    data.ctx.p[i] = L;
+    data.ctx.p[i + 1] = R;
+  }
+
+  ptr = data.ctx.s[0];
+  do {
+    ptr += 4;
+    L ^= data.binary.salt[(_BLOWFISH_ROUNDS + 2) &amp; 3];
+    R ^= data.binary.salt[(_BLOWFISH_ROUNDS + 3) &amp; 3];
+    _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+    *(ptr - 4) = L;
+    *(ptr - 3) = R;
+
+    L ^= data.binary.salt[(_BLOWFISH_ROUNDS + 4) &amp; 3];
+    R ^= data.binary.salt[(_BLOWFISH_ROUNDS + 5) &amp; 3];
+    _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+    *(ptr - 2) = L;
+    *(ptr - 1) = R;
+  } while (ptr &lt; &amp;data.ctx.s[3][0xFF]);
+
+  do {
+    int done;
+
+    for (i = 0; i &lt; _BLOWFISH_ROUNDS + 2; i += 2) {
+      data.ctx.p[i] ^= data.expanded_key[i];
+      data.ctx.p[i + 1] ^= data.expanded_key[i + 1];
+    }
+
+    done = 0;
+    do {
+      uint32_t tmp1, tmp2, tmp3, tmp4;
+
+      L = R = 0;
+      ptr = data.ctx.p;
+      do {
+        ptr += 2;
+        _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+        *(ptr - 2) = L;
+        *(ptr - 1) = R;
+      } while (ptr &lt; &amp;data.ctx.p[_BLOWFISH_ROUNDS + 2]);
+
+      ptr = data.ctx.s[0];
+      do {
+        ptr += 2;
+        _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+        *(ptr - 2) = L;
+        *(ptr - 1) = R;
+      } while (ptr &lt; &amp;data.ctx.s[3][0xFF]);
+
+      if (done)
+        break;
+      done = 1;
+
+      tmp1 = data.binary.salt[0];
+      tmp2 = data.binary.salt[1];
+      tmp3 = data.binary.salt[2];
+      tmp4 = data.binary.salt[3];
+      for (i = 0; i &lt; _BLOWFISH_ROUNDS; i += 4) {
+        data.ctx.p[i] ^= tmp1;
+        data.ctx.p[i + 1] ^= tmp2;
+        data.ctx.p[i + 2] ^= tmp3;
+        data.ctx.p[i + 3] ^= tmp4;
+      }
+      data.ctx.p[16] ^= tmp1;
+      data.ctx.p[17] ^= tmp2;
+    } while (1);
+  } while (--count);
+
+  for (i = 0; i &lt; 6; i += 2) {
+    L = magic_w[i];
+    R = magic_w[i + 1];
+
+    count = 64;
+    do
+      _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+    while (--count);
+
+    data.binary.output[i] = L;
+    data.binary.output[i + 1] = R;
+  }
+
+  *dst++ = '$';
+  *dst++ = '2';
+  *dst++ = cscheme;
+  *dst++ = '$';
+  *dst++ = '0' + log2rounds / 10;
+  *dst++ = '0' + log2rounds % 10;
+  *dst++ = '$';
+  dst = encode_radix64(dst, BLOWFISH_BCRYPT_BINSALT_SIZE, psalt) - 1;
+
+  swap32(data.binary.output, 6);
+/* This has to be bug-compatible with the original implementation, so
+   only encode 23 of the 24 bytes. */
+  encode_radix64(dst, 23, (uint8_t *) data.binary.output);
+  return cscheme;
+}
+
+/*
+ * Please preserve the runtime self-test. It serves two purposes at once:
+ *
+ * 1. We really can't afford the risk of producing incompatible hashes e.g.
+ * when there's something like gcc bug 26587 again, whereas an application or
+ * library integrating this code might not also integrate our external tests or
+ * it might not run them after every build. Even if it does, the miscompile
+ * might only occur on the production build, but not on a testing build (such
+ * as because of different optimization settings). It is painful to recover
+ * from incorrectly-computed hashes - merely fixing whatever broke is not
+ * enough. Thus, a proactive measure like this self-test is needed.
+ *
+ * 2. We don't want to leave sensitive data from our actual password hash
+ * computation on the stack or in registers. Previous revisions of the code
+ * would do explicit cleanups, but simply running the self-test after hash
+ * computation is more reliable.
+ *
+ * The performance cost of this quick self-test is around 0.6% at the "$2a$08"
+ * setting.
+ */
+int blowfish_bcrypt_hash(size_t length, char *dst,
+                         const char *key, const char *scheme,
+			 int log2rounds, const uint8_t *salt)
+{
+  const char *test_pw = "8b \xd0\xc1\xd2\xcf\xcc\xd8";
+  const char *test_scheme = "$2a$00$abcdefghijklmnopqrstuu";
+  static const char * const test_hashes[2] =
+    {"i1D709vfamulimlGcq0qq3UvuUasvEa\0\x55",  /* 'a', 'b', 'y' */
+     "VUrPmXD6q/nVSSp7pNDhCR9071IfIRe\0\x55"}; /* 'x' */
+  const char *test_hash = test_hashes[0];
+  int cscheme;
+  int ok;
+  struct {
+    char s[HASHOFFSET + 1];
+    char o[HASHOFFSET + 31 + 1 + 1 + 1];
+  } buf;
+
+  if (length)
+    *dst = '\0';
+/* Hash the supplied password */
+  cscheme = ibcrypt(length, dst, key, scheme, 4, log2rounds, salt);
+
+/*
+ * Do a quick self-test. It is important that we make both calls to ibcrypt()
+ * from the same scope such that they likely use the same stack locations,
+ * which makes the second call overwrite the first call's sensitive data on the
+ * stack and makes it more likely that any alignment related issues would be
+ * detected by the self-test.
+ */
+  memcpy(buf.s, test_scheme, sizeof(buf.s));
+
+  if (cscheme)
+    test_hash = test_hashes[(buf.s[2] = cscheme) == 'x'];
+
+  memset(buf.o, 0x55, sizeof(buf.o));
+  buf.o[sizeof(buf.o) - 1] = 0;
+  ok = ibcrypt(sizeof(buf.o) - (1 + 1), buf.o, test_pw,
+               buf.s, 0, -1, (void*)0);
+
+  ok = (ok &amp;&amp;
+      !memcmp(buf.o, buf.s, HASHOFFSET) &amp;&amp;
+      !memcmp(buf.o + HASHOFFSET, test_hash, 31 + 1 + 1 + 1));
+
+  {
+    const char *k = "\xff\xa3" "34" "\xff\xff\xff\xa3" "345";
+    bf_key ae, ai, ye, yi;
+    set_xkey(k, ae, ai, 0, 0x10000); /* $2a$ */
+    set_xkey(k, ye, yi, 0, 0); /* $2y$ */
+    ai[0] ^= 0x10000; /* undo the safety (for comparison) */
+    ok = ok &amp;&amp; ai[0] == 0xdb9c59bc &amp;&amp; ye[17] == 0x33343500 &amp;&amp;
+        !memcmp(ae, ye, sizeof(ae)) &amp;&amp;
+        !memcmp(ai, yi, sizeof(ai));
+  }
+
+  return ok &amp;&amp; !!cscheme;
+}
diff --git a/blowfish.h b/blowfish-internal.h
similarity index 50%
copy from blowfish.h
copy to blowfish-internal.h
index bcdc7cb6..da28fa34 100644
--- a/blowfish.h
+++ b/blowfish-internal.h
@@ -1,4 +1,4 @@
-/* blowfish.h
+/* blowfish-internal.h
 
    Blowfish block cipher.
 
@@ -32,8 +32,8 @@
    not, see http://www.gnu.org/licenses/.
 */
  
-#ifndef NETTLE_BLOWFISH_H_INCLUDED
-#define NETTLE_BLOWFISH_H_INCLUDED
+#ifndef NETTLE_BLOWFISH_INTERNAL_H_INCLUDED
+#define NETTLE_BLOWFISH_INTERNAL_H_INCLUDED
 
 #include "nettle-types.h"
 
@@ -41,49 +41,12 @@
 extern "C" {
 #endif
 
-/* Name mangling */
-#define blowfish_set_key nettle_blowfish_set_key
-#define blowfish128_set_key nettle_blowfish128_set_key
-#define blowfish_encrypt nettle_blowfish_encrypt
-#define blowfish_decrypt nettle_blowfish_decrypt
-
-#define BLOWFISH_BLOCK_SIZE 8
-
-/* Variable key size between 64 and 448 bits. */
-#define BLOWFISH_MIN_KEY_SIZE 8
-#define BLOWFISH_MAX_KEY_SIZE 56
-
-/* Default to 128 bits */
-#define BLOWFISH_KEY_SIZE 16
-
-#define BLOWFISH128_KEY_SIZE 16
-
-#define _BLOWFISH_ROUNDS 16
-
-struct blowfish_ctx
-{
-  uint32_t s[4][256];
-  uint32_t p[_BLOWFISH_ROUNDS+2];
-};
-
-/* Returns 0 for weak keys, otherwise 1. */
-int
-blowfish_set_key(struct blowfish_ctx *ctx,
-                 size_t length, const uint8_t *key);
-int
-blowfish128_set_key(struct blowfish_ctx *ctx, const uint8_t *key);
-
-void
-blowfish_encrypt(const struct blowfish_ctx *ctx,
-                 size_t length, uint8_t *dst,
-                 const uint8_t *src);
-void
-blowfish_decrypt(const struct blowfish_ctx *ctx,
-                 size_t length, uint8_t *dst,
-                 const uint8_t *src);
+extern const struct blowfish_ctx _nettle_blowfish_initial_ctx;
+extern void _nettle_blowfish_encround (const struct blowfish_ctx *ctx,
+                                       uint32_t * ret_xl, uint32_t * ret_xr);
 
 #ifdef __cplusplus
 }
 #endif
 
-#endif /* NETTLE_BLOWFISH_H_INCLUDED */
+#endif /* NETTLE_BLOWFISH_INTERNAL_H_INCLUDED */
diff --git a/blowfish.c b/blowfish.c
index 52040f13..e73caffe 100644
--- a/blowfish.c
+++ b/blowfish.c
@@ -54,12 +54,13 @@
 #include &lt;assert.h&gt;
 
 #include "blowfish.h"
+#include "blowfish-internal.h"
 
 #include "macros.h"
 
 /* precomputed S boxes */
-static const struct blowfish_ctx
-initial_ctx = {
+const struct blowfish_ctx
+_nettle_blowfish_initial_ctx = {
   {
     { /* ks0 */
       0xD1310BA6, 0x98DFB5AC, 0x2FFD72DB, 0xD01ADFB7, 0xB8E1AFED, 0x6A267E96,
@@ -261,8 +262,8 @@ initial_ctx = {
 
 #define R(c, l,r,i)  do { l ^= c-&gt;p[i]; r ^= F(c,l); } while(0)
 
-static void
-encrypt (const struct blowfish_ctx *ctx, uint32_t * ret_xl,
+void
+_nettle_blowfish_encround (const struct blowfish_ctx *ctx, uint32_t * ret_xl,
 	    uint32_t * ret_xr)
 {
   uint32_t xl, xr;
@@ -295,7 +296,7 @@ encrypt (const struct blowfish_ctx *ctx, uint32_t * ret_xl,
 }
 
 static void
-decrypt (const struct blowfish_ctx *ctx, uint32_t * ret_xl, uint32_t * ret_xr)
+decround (const struct blowfish_ctx *ctx, uint32_t * ret_xl, uint32_t * ret_xr)
 {
   uint32_t xl, xr;
 
@@ -339,7 +340,7 @@ blowfish_encrypt (const struct blowfish_ctx *ctx,
 
       d1 = READ_UINT32(src);
       d2 = READ_UINT32(src+4);
-      encrypt (ctx, &amp;d1, &amp;d2);
+      _nettle_blowfish_encround (ctx, &amp;d1, &amp;d2);
       dst[0] = (d1 &gt;&gt; 24) &amp; 0xff;
       dst[1] = (d1 &gt;&gt; 16) &amp; 0xff;
       dst[2] = (d1 &gt;&gt; 8) &amp; 0xff;
@@ -361,7 +362,7 @@ blowfish_decrypt (const struct blowfish_ctx *ctx,
 
       d1 = READ_UINT32(src);
       d2 = READ_UINT32(src+4);
-      decrypt (ctx, &amp;d1, &amp;d2);
+      decround (ctx, &amp;d1, &amp;d2);
       dst[0] = (d1 &gt;&gt; 24) &amp; 0xff;
       dst[1] = (d1 &gt;&gt; 16) &amp; 0xff;
       dst[2] = (d1 &gt;&gt; 8) &amp; 0xff;
@@ -380,7 +381,7 @@ blowfish_set_key (struct blowfish_ctx *ctx,
   int i, j;
   uint32_t data, datal, datar;
 
-  *ctx = initial_ctx;
+  *ctx = _nettle_blowfish_initial_ctx;
 
   for (i = j = 0; i &lt; _BLOWFISH_ROUNDS + 2; i++)
     {
@@ -393,15 +394,15 @@ blowfish_set_key (struct blowfish_ctx *ctx,
   datal = datar = 0;
   for (i = 0; i &lt; _BLOWFISH_ROUNDS + 2; i += 2)
     {
-      encrypt (ctx, &amp;datal, &amp;datar);
+      _nettle_blowfish_encround (ctx, &amp;datal, &amp;datar);
       ctx-&gt;p[i] = datal;
       ctx-&gt;p[i + 1] = datar;
     }
-  
+
   for (j = 0; j &lt; 4; j++)
     for (i = 0; i &lt; 256; i += 2)
       {
-	encrypt (ctx, &amp;datal, &amp;datar);
+	_nettle_blowfish_encround (ctx, &amp;datal, &amp;datar);
 	ctx-&gt;s[j][i] = datal;
 	ctx-&gt;s[j][i + 1] = datar;
     }
diff --git a/blowfish.h b/blowfish.h
index bcdc7cb6..af48e20f 100644
--- a/blowfish.h
+++ b/blowfish.h
@@ -46,6 +46,8 @@ extern "C" {
 #define blowfish128_set_key nettle_blowfish128_set_key
 #define blowfish_encrypt nettle_blowfish_encrypt
 #define blowfish_decrypt nettle_blowfish_decrypt
+#define blowfish_bcrypt_hash nettle_blowfish_bcrypt_hash
+#define blowfish_bcrypt_verify nettle_blowfish_bcrypt_verify
 
 #define BLOWFISH_BLOCK_SIZE 8
 
@@ -60,6 +62,9 @@ extern "C" {
 
 #define _BLOWFISH_ROUNDS 16
 
+#define BLOWFISH_BCRYPT_HASH_SIZE (60 + 1) /* Including null-terminator */
+#define BLOWFISH_BCRYPT_BINSALT_SIZE 16    /* Binary string size */
+
 struct blowfish_ctx
 {
   uint32_t s[4][256];
@@ -81,6 +86,16 @@ void
 blowfish_decrypt(const struct blowfish_ctx *ctx,
                  size_t length, uint8_t *dst,
                  const uint8_t *src);
+int
+blowfish_bcrypt_hash(size_t length,
+                     char *dst,
+                     const char *key,
+                     const char *scheme,
+		     int log2rounds,
+		     const uint8_t *salt);
+int
+blowfish_bcrypt_verify(const char *key,
+                       const char *hashed);
 
 #ifdef __cplusplus
 }
diff --git a/nettle.texinfo b/nettle.texinfo
index 995d5de8..75e18b58 100644
--- a/nettle.texinfo
+++ b/nettle.texinfo
@@ -1513,6 +1513,73 @@ in any other way.
 Analogous to @code{blowfish_encrypt}
 @end deftypefun
 
+@deftypefun int blowfish_bcrypt_hash (size_t @var{length}, char *@var{dst}, const \
char *@var{key}, const char *@var{scheme}, int @var{log2rounds}, const uint8_t \
*@var{salt}) +Compute the bcrypt password hash.
+The function will return @code{0} if the hash cannot be computed
+due to invalid input.
+The function will return @code{1} and store the computed hash
+in the array pointed to by @var{dst}.  The hash is computed based
+on the chosen @var{scheme}, number of rounds @var{log2rounds} and
+specified @var{salt}.
+
+@var{length} must be at least @code{BLOWFISH_BCRYPT_HASH_SIZE}.
+
+@var{dst} must point to a character array of the specified @var{length}.
+
+@var{key} contains the zero terminated plaintext password string.
+
+@var{scheme} contains either just the chosen scheme (valid schemes
+are: @code{2a}, @code{2b}, @code{2x} or @code{2y}), or
+(the prefix of) an existing hashed password (typically @code{$2b$10$...}).
+
+@var{log2rounds} contains the log2 of the number of encryption rounds
+that must be used to compute the hash.  If it is @code{-1} the value
+will be extracted from @var{scheme}.
+
+@var{salt} should point to an array of @code{BLOWFISH_BCRYPT_BINSALT_SIZE}
+random bytes to be used to perturb the hash computation.  If it is @code{NULL}
+the salt will be extracted from @var{scheme}.
+
+Sample code to generate a bcrypt hash:
+@example
+char cleartxtpassword[] = "ExamplePassword";
+uint8_t salt[BLOWFISH_BCRYPT_BINSALT_SIZE];
+@dots{}
+/* Make sure that salt is filled with random bytes */
+@dots{}
+char hashedresult[BLOWFISH_BCRYPT_HASH_SIZE];
+int result = blowfish_bcrypt(sizeof(hashedresult), hashedresult,
+                             cleartxtpassword, "2b", 10, salt);
+if (result)
+  printf("%s\n", hashedresult);
+@end example
+@end deftypefun
+
+@deftypefun int blowfish_bcrypt_verify (const char *@var{key}, const char \
*@var{hashed}) +Verifies the bcrypt password hash against the supplied plaintext \
password. +The function will return @code{0} if the password does not match.
+The function will return @code{1} if the password matches.
+
+@var{key} contains the zero terminated plaintext password string.
+
+@var{hashed} contains the zero terminated hashed string to compare with.
+
+Sample code to verify a bcrypt hash:
+@example
+char cleartxtpassword[] = "ExamplePassword";
+char existinghashed[] =
+           "$2y$"  /* Hash algorithm version */
+           "10"   /* 2^10 hash rounds (strength) */
+           "$"   /* separator */
+           "1b2lPgo4XumibnJGN3r3sO" /* base64 encoded 16-byte salt */
+           "u7wE7xNfYDKlAxZffJDCJdVfFTAyevu"; /* Hashedpart */
+if (blowfish_bcrypt_verify(cleartxtpassword, existinghashed))
+  printf("Password is correct.");
+else
+  printf("Password is incorrect.");
+@end example
+@end deftypefun
+
 @subsection Camellia
 @cindex Camellia
 
-- 
2.20.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200529114300</emailId><senderName>Daniel =?utf-8?B?UC4gQmVycmFuZ8Op?=</senderName><senderEmail>berrange@redhat.com</senderEmail><timestampReceived>2020-05-29 11:43:00-0400</timestampReceived><subject>nettle-benchmark hangs at startup w/ 100% cpu</subject><body>

I was trying the nettle-benchmark program and found that it hangs at
startup burning 100% CPU.

Debugging shows this is when measuring benchmark overhead. With a quick
printf of the "ncalls" variable in time_function(), I can see that it
overflows:

time_function ncalls=100 elapsed=0.000010
time_function ncalls=1000 elapsed=0.000003
time_function ncalls=10000 elapsed=0.000002
time_function ncalls=100000 elapsed=0.000002
time_function ncalls=1000000 elapsed=0.000002
time_function ncalls=10000000 elapsed=0.000002
time_function ncalls=100000000 elapsed=0.000002
time_function ncalls=1000000000 elapsed=0.000002
time_function ncalls=1410065408 elapsed=0.000002
time_function ncalls=1215752192 elapsed=0.000002
time_function ncalls=-727379968 elapsed=0.000002
time_function ncalls=1316134912 elapsed=0.000002
time_function ncalls=276447232 elapsed=0.000002
time_function ncalls=-1530494976 elapsed=0.000002
time_function ncalls=1874919424 elapsed=0.000002
time_function ncalls=1569325056 elapsed=0.000002
time_function ncalls=-1486618624 elapsed=0.000002
time_function ncalls=-1981284352 elapsed=0.000002
time_function ncalls=1661992960 elapsed=0.000002
time_function ncalls=-559939584 elapsed=0.000002
time_function ncalls=-1304428544 elapsed=0.000002
time_function ncalls=-159383552 elapsed=0.000002
time_function ncalls=-1593835520 elapsed=0.000002
time_function ncalls=1241513984 elapsed=0.000002
time_function ncalls=-469762048 elapsed=0.000002
time_function ncalls=-402653184 elapsed=0.000002
time_function ncalls=268435456 elapsed=0.000002
time_function ncalls=-1610612736 elapsed=0.000002
time_function ncalls=1073741824 elapsed=0.000002
time_function ncalls=-2147483648 elapsed=0.000002
time_function ncalls=0 elapsed=0.000002
time_function ncalls=0 elapsed=0.000002
time_function ncalls=0 elapsed=0.000002

The elapsed time is the same regardless of ncalls, so I'm thinking that
the compiler as been clever and optimized bench_nothing() into literally
nothing.  If I modify it to

static void
bench_nothing(void *arg UNUSED)
{
  static int i = 0;
  i++;
  return;
}

then things work, but of course we're not benchmarking "nothing" anymore.

This is on Fedora 32 with  gcc-10.1.1-1.fc32.x86_64

Regards,
Daniel
-- 
|: https://berrange.com      -o-    https://www.flickr.com/photos/dberrange :|
|: https://libvirt.org         -o-            https://fstop138.berrange.com :|
|: https://entangle-photo.org    -o-    https://www.instagram.com/dberrange :|

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200529125926</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-05-29 12:59:26-0400</timestampReceived><subject>Re: nettle-benchmark hangs at startup w/ 100% cpu</subject><body>

Daniel P. Berrangé &lt;berrange@redhat.com&gt; writes:

&gt; The elapsed time is the same regardless of ncalls, so I'm thinking that
&gt; the compiler as been clever and optimized bench_nothing() into literally
&gt; nothing.  If I modify it to
&gt;
&gt; static void
&gt; bench_nothing(void *arg UNUSED)
&gt; {
&gt;   static int i = 0;
&gt;   i++;
&gt;   return;
&gt; }
&gt;
&gt; then things work, but of course we're not benchmarking "nothing" anymore.

Maybe simplest to just delete this part of the benchmark? I don't think
it's that useful.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200519073315</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-05-19 07:33:15-0400</timestampReceived><subject>Re: [PATCH] (revision 3.2) Added bcrypt() support.</subject><body>

Stephen R. van den Berg wrote:
&gt;Changes since 3.1: Took out the tablesize optimisations.

&gt;---
&gt; Makefile.in                       |   2 +-
&gt; blowfish-bcrypt.c                 | 519 ++++++++++++++++++++++++++++++
&gt; blowfish.h =&gt; blowfish-internal.h |  51 +--
&gt; blowfish.c                        |  23 +-
&gt; blowfish.h                        |  15 +
&gt; nettle.texinfo                    |  67 ++++
&gt; 6 files changed, 621 insertions(+), 56 deletions(-)
&gt; create mode 100644 blowfish-bcrypt.c
&gt; copy blowfish.h =&gt; blowfish-internal.h (50%)

Anything I still need to change, or can this be committed to the
main development branch as is?
-- 
Stephen.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200528202230</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-05-28 20:22:30-0400</timestampReceived><subject>Re: [PATCH] (revision 3.2) Added bcrypt() support.</subject><body>

"Stephen R. van den Berg" &lt;srb@cuci.nl&gt; writes:

&gt; +int
&gt; +blowfish_bcrypt_hash(size_t length,
&gt; +                     char *dst,
&gt; +                     const char *key,
&gt; +                     const char *scheme,
&gt; +		     int log2rounds,
&gt; +		     const uint8_t *salt);
&gt; +int
&gt; +blowfish_bcrypt_verify(const char *key,
&gt; +                       const char *hashed);

I think it's nice with separate hash/verify functions. Code looks
reasonable, but I still have a few questions on the interface:

If I get it right, the parameters log2rounds and salt can either be
provided as explicit arguments, or derived from the scheme string. In
some way, it would be clenaer with one function taking all parameters as
explicit arguments (without any scheme string to parse at all), and a
different one taking it all from the scheme string. Do we need anything
in the middle, like parsing log2rounds from the scheme string, but the
salt as a separate binary string?

It's unusual in the Nettle API to use NUL-terminated strings, we usually
pass length and data. E.g., the pbkdf2 functions take the input password
as size_t key_length, const uint8_t *key, even though it's usually an
ascii string. It's not clear what's best here. Will the algorithm break
down if we let it process a key input with NUL character in the middle?

The length input (first argument) seems redundant, since its only use
is to check that it's &gt;= BLOWFISH_BCRYPT_HASH_SIZE. When the sie really
is fixed, it's better to document that and drop that argument.

If you would like to make some easy progress, you could split out the
patch to create blowfish-internal.h and declare
_nettle_blowfish_encround in that file. That has no api implications and
would reduce the size of the main patch.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200612091925</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-06-12 09:19:25-0400</timestampReceived><subject>Re: [PATCH] (revision 3.2) Added bcrypt() support.</subject><body>

Stephen R. van den Berg wrote:
&gt;On Thu, May 28, 2020 at 10:22 PM Niels M??ller &lt;nisse@lysator.liu.se&gt; wrote:

&gt;&gt; If I get it right, the parameters log2rounds and salt can either be
&gt;&gt; provided as explicit arguments, or derived from the scheme string. In
&gt;&gt; some way, it would be clenaer with one function taking all parameters as
&gt;&gt; explicit arguments (without any scheme string to parse at all), and a
&gt;&gt; different one taking it all from the scheme string. Do we need anything
&gt;&gt; in the middle, like parsing log2rounds from the scheme string, but the
&gt;&gt; salt as a separate binary string?

&gt;Cleaner, yes.  Easier to use, no.  If we split it up, it becomes cleaner,
&gt;but
&gt;people using the interface will have more work to do and can mess things
&gt;up (more than now).  So, in this case I would prefer ease of use.

This one I did not change.  I'd vote against it for more complicated usage.

&gt;It's unusual in the Nettle API to use NUL-terminated strings, we usually
&gt;&gt; pass length and data. E.g., the pbkdf2 functions take the input password
&gt;&gt; as size_t key_length, const uint8_t *key, even though it's usually an
&gt;&gt; ascii string. It's not clear what's best here. Will the algorithm break
&gt;&gt; down if we let it process a key input with NUL character in the middle?

&gt;I don't think it will break down, but I'd need to verify the code.
&gt;I understand that this would keep it consistent with the rest of the Nettle
&gt;conventions.  I'll see what I can do.

Changed in v4.0.

&gt;&gt; The length input (first argument) seems redundant, since its only use
&gt;&gt; is to check that it's &gt;= BLOWFISH_BCRYPT_HASH_SIZE. When the sie really
&gt;&gt; is fixed, it's better to document that and drop that argument.

&gt;Yes, this can be done.  But here I specifically chose to do it this way so
&gt;that
&gt;anyway needing to program to the interface has to look up less reference
&gt;docs
&gt;(more consistent with the other Nettle conventions).
&gt;But if you insist, I can change this, of course.

Changed in v4.0.

&gt;&gt; If you would like to make some easy progress, you could split out the
&gt;&gt; patch to create blowfish-internal.h and declare
&gt;&gt; _nettle_blowfish_encround in that file. That has no api implications and
&gt;&gt; would reduce the size of the main patch.

&gt;I'll see what I can do.

Separated out in v4.0.

The v4.0 patches have just been submitted.  They're a three patch set now:
1. The harmless preparation patch.
2. The actual code, old style, with C-strings (I left it in, for documentation
   and verification purposes).
3. The amended binary string interface (no C-strings).
-- 
Stephen.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200612104208</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-06-12 10:42:08-0400</timestampReceived><subject>Re: [PATCH] (revision 3.2) Added bcrypt() support.</subject><body>

Stephen R. van den Berg wrote:
&gt;The v4.0 patches have just been submitted.  They're a three patch set now:
&gt;3. The amended binary string interface (no C-strings).

The 3rd set has been resent as v4.1.
Should be complete now.
The result has been end-to-end tested in Pike's testsuite.
-- 
Stephen.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200623150320</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-06-23 15:03:20-0400</timestampReceived><subject>Re: [PATCH] (revision 3.2) Added bcrypt() support.</subject><body>

Stephen R. van den Berg wrote:
&gt;The v4.0 patches have just been submitted.  They're a three patch set now:
&gt;3. The amended binary string interface (no C-strings).

The 3rd set has been resent as v4.2.

&gt;The result has been end-to-end tested in Pike's testsuite.

That's what I said, but as it turns out, I confused libraries during linking.
Now it has been tested properly.
-- 
Stephen.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200522232540</emailId><senderName>Amos Jeffries</senderName><senderEmail>squid3@treenet.co.nz</senderEmail><timestampReceived>2020-05-22 23:25:40-0400</timestampReceived><subject>Re: [PATCH libdrm v2 1/2] examples: don't use deprecated OpenSSL hashing API</subject><body>

On 22/05/20 11:29 pm, Emil Velikov wrote:
&gt; On Mon, 11 May 2020 at 09:46, Emil Velikov wrote:
&gt;&gt;
&gt;&gt; The direct $HASH_{Init,Update,Final} has been discouraged for a while.
&gt;&gt; With the upcoming OpenSSL 3.0 it will be officially deprecated.
&gt;&gt;
&gt;&gt; Add a handy macro, to avoid repetition and mistakes like in the current
&gt;&gt; code. Namely - we're using SHA cblock/digest_len for md5 :-\
&gt;&gt;
&gt;&gt; The macro will also make it easier to add more, as seen with next patch.
&gt;&gt;
&gt;&gt; v2: Align it with the crypto implementations, namely:
&gt;&gt;  - use openssh_hash_ctx::evp, use correct sizeof()
&gt;&gt;  - move hash_update out of the macro
&gt;&gt;  - remove forward declarations for hash functions
&gt;&gt;
&gt; Humble poke?
&gt; 
&gt; Hope that Niels and the nettle team are OK. It seems strange to have
&gt; ~2 weeks of silence, when the original patches got immediate feedback.
&gt; 


Niels takes breaks (at least from list related work) occasionally
without notice. Given the recent release focus I suspect a short
holiday. Even with the current world situation I'd give it 4-5 weeks
before getting worried.

HTH
AYJ
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200528143925</emailId><senderName>Emil Velikov</senderName><senderEmail>emil.l.velikov@gmail.com</senderEmail><timestampReceived>2020-05-28 14:39:25-0400</timestampReceived><subject>Re: [PATCH libdrm v2 1/2] examples: don't use deprecated OpenSSL hashing API</subject><body>

On Sat, 23 May 2020 at 00:33, Amos Jeffries &lt;squid3@treenet.co.nz&gt; wrote:
&gt;
&gt; On 22/05/20 11:29 pm, Emil Velikov wrote:
&gt; &gt; On Mon, 11 May 2020 at 09:46, Emil Velikov wrote:
&gt; &gt;&gt;
&gt; &gt;&gt; The direct $HASH_{Init,Update,Final} has been discouraged for a while.
&gt; &gt;&gt; With the upcoming OpenSSL 3.0 it will be officially deprecated.
&gt; &gt;&gt;
&gt; &gt;&gt; Add a handy macro, to avoid repetition and mistakes like in the current
&gt; &gt;&gt; code. Namely - we're using SHA cblock/digest_len for md5 :-\
&gt; &gt;&gt;
&gt; &gt;&gt; The macro will also make it easier to add more, as seen with next patch.
&gt; &gt;&gt;
&gt; &gt;&gt; v2: Align it with the crypto implementations, namely:
&gt; &gt;&gt;  - use openssh_hash_ctx::evp, use correct sizeof()
&gt; &gt;&gt;  - move hash_update out of the macro
&gt; &gt;&gt;  - remove forward declarations for hash functions
&gt; &gt;&gt;
&gt; &gt; Humble poke?
&gt; &gt;
&gt; &gt; Hope that Niels and the nettle team are OK. It seems strange to have
&gt; &gt; ~2 weeks of silence, when the original patches got immediate feedback.
&gt; &gt;
&gt;
&gt;
&gt; Niels takes breaks (at least from list related work) occasionally
&gt; without notice. Given the recent release focus I suspect a short
&gt; holiday. Even with the current world situation I'd give it 4-5 weeks
&gt; before getting worried.
&gt;
Thanks Amos. I'll send some patches for CONTRIBUTING.md mentioning
this + mandatory ML subscription.

-Emil
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200507065120</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-05-07 06:51:20-0400</timestampReceived><subject>Re: [PATCH 1/2] examples: don't use deprecated OpenSSL hashing API</subject><body>

Emil Velikov &lt;emil.l.velikov@gmail.com&gt; writes:

&gt; The direct $HASH_{Init,Update,Final} has been discouraged for a while.
&gt; With the upcoming OpenSSL 3.0 it will be officially deprecated.
&gt;
&gt; Add a handy macro, to avoid repetition and mistakes like in the current
&gt; code. Namely - we're using SHA cblock/digest_len for md5 :-\

Thanks. Reducing code duplication with the macro is nice, but I think
the handling of the context is a bit confusing. In the definiton of the
nettle_hash structs, you use sizeof (NAME##_CTX), but in the functions
you cast like (EVP_MD_CTX **)ctx. I think it will de clearer with
something like

struct openssl_hash_ctx {
  EVP_MD_CTX *evp;
};

analogous to struct openssl_cipher_ctx, and use that for all the hash
functions. And it looks like the update function can be the same for all
hashes, no need to have the macro define it.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200328144047</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-03-28 14:40:47-0400</timestampReceived><subject>Failure of gnutls ci build</subject><body>

Hi,

I committed a change to update nettle version numbers, which implies a
new symbol version for internal symbols.

That seems to break the gnutls ci build,
https://gitlab.com/gnutls/nettle/-/jobs/487360242

The error is 

1217 ./bootstrap: getting translations into po/.reference for gnutls...
1218 wget: /lib64/libhogweed.so.5: version `HOGWEED_INTERNAL_5_0' not found (required \
by /lib64/libgnutls.so.30) 1219 wget: /lib64/libnettle.so.7: version \
`NETTLE_INTERNAL_7_0' not found (required by /lib64/libgnutls.so.30) 

I don't quite understand all details. This job buils and installs
nettle, as

  ./configure --disable-documentation --prefix=/usr --libdir=/usr/lib64 &amp;&amp;
    make -j4 &amp;&amp; make install

replacing any previously instaled version with the same soname. So
that's a somewhat broader test than I had expected. That explains why
linking of wget is affected.

The more worring part is that the installed gnutls library seems to
depend on internal nettle symbols (it would have been nice if the error
message named the offending symbols). Is that intended? 

It's not necessarily wrong, but any packaged version of gnutls built
that way *must* be marked to depend on exactly the same versions of
nettle with which it was built. And the ci rule would need to use a
different prefix and some other way to tell the gnutls build to use the
newly built nettle library instead of the system version.

On my own debian machine I have libgnutls.so.30, but apparently an older
version. According to

  objdump -T /usr/lib/x86_64-linux-gnu/libgnutls.so.30

the version I have refers only to symbols with version NETTLE_6 and
HOGWEED_4, i.e., nettle version older than 3.5. And no mention of
NETTLE_INTERNAL or HOGWEED_INTERNAL.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200329073904</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-03-29 07:39:04-0400</timestampReceived><subject>Failure of gnutls ci build</subject><body>

Hi,

I committed a change to update nettle version numbers, which implies a
new symbol version for internal symbols.

That seems to break the gnutls ci build,
https://gitlab.com/gnutls/nettle/-/jobs/487360242

The error is 

1217 ./bootstrap: getting translations into po/.reference for gnutls...
1218 wget: /lib64/libhogweed.so.5: version `HOGWEED_INTERNAL_5_0' not found (required \
by /lib64/libgnutls.so.30) 1219 wget: /lib64/libnettle.so.7: version \
`NETTLE_INTERNAL_7_0' not found (required by /lib64/libgnutls.so.30) 

I don't quite understand all details. This job buils and installs
nettle, as

  ./configure --disable-documentation --prefix=/usr --libdir=/usr/lib64 &amp;&amp;
    make -j4 &amp;&amp; make install

replacing any previously installed version with the same soname. So
that's a somewhat broader test than I had expected. That explains why
linking of wget is affected.

The more worring part is that the installed gnutls library seems to
depend on internal nettle symbols (it would have been nice if the error
message named the offending symbols). Is that intended? 

It's not necessarily wrong, but any packaged version of gnutls built
that way *must* be marked to depend on exactly the same versions of
nettle with which it was built. And the ci rule would need to use a
different prefix and some other way to tell the gnutls build to use the
newly built nettle library instead of the system version.

On my own debian machine I have libgnutls.so.30, but apparently an older
version. According to

  objdump -T /usr/lib/x86_64-linux-gnu/libgnutls.so.30

the version I have refers only to symbols with version NETTLE_6 and
HOGWEED_4, i.e., nettle version older than 3.5. And no mention of
NETTLE_INTERNAL or HOGWEED_INTERNAL.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200330054151</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-03-30 05:41:51-0400</timestampReceived><subject>Failure of gnutls ci build</subject><body>

Hi,

I committed a change to update nettle version numbers, which implies a
new symbol version for internal symbols.

That seems to break the gnutls ci build,
https://gitlab.com/gnutls/nettle/-/jobs/487360242

The error is 

1217 ./bootstrap: getting translations into po/.reference for gnutls...
1218 wget: /lib64/libhogweed.so.5: version `HOGWEED_INTERNAL_5_0' not found (required \
by /lib64/libgnutls.so.30) 1219 wget: /lib64/libnettle.so.7: version \
`NETTLE_INTERNAL_7_0' not found (required by /lib64/libgnutls.so.30) 

I don't quite understand all details. This job buils and installs
nettle, as

  ./configure --disable-documentation --prefix=/usr --libdir=/usr/lib64 &amp;&amp;
    make -j4 &amp;&amp; make install

replacing any previously installed version with the same soname. So
that's a somewhat broader test than I had expected. That explains why
linking of wget is affected.

The more worring part is that the installed gnutls library seems to
depend on internal nettle symbols (it would have been nice if the error
message named the offending symbols). Is that intended? 

It's not necessarily wrong, but any packaged version of gnutls built
that way *must* be marked to depend on exactly the same versions of
nettle with which it was built. And the ci rule would need to use a
different prefix and some other way to tell the gnutls build to use the
newly built nettle library instead of the system version.

On my own debian machine I have libgnutls.so.30, but apparently an older
version. According to

  objdump -T /usr/lib/x86_64-linux-gnu/libgnutls.so.30

the version I have refers only to symbols with version NETTLE_6 and
HOGWEED_4, i.e., nettle version older than 3.5. And no mention of
NETTLE_INTERNAL or HOGWEED_INTERNAL.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200323093602</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-03-23 09:36:02-0400</timestampReceived><subject>[PATCH] (revision 3.1) Added bcrypt() support.</subject><body>

---
 Makefile.in                       |   2 +-
 base64-decode.c                   |  17 +-
 blowfish-bcrypt.c                 | 511 ++++++++++++++++++++++++++++++
 blowfish.h =&gt; blowfish-internal.h |  51 +--
 blowfish.c                        |  23 +-
 blowfish.h                        |  15 +
 nettle.texinfo                    |  67 ++++
 7 files changed, 620 insertions(+), 66 deletions(-)
 create mode 100644 blowfish-bcrypt.c
 copy blowfish.h =&gt; blowfish-internal.h (50%)

diff --git a/Makefile.in b/Makefile.in
index ddc30428..bfb7ac57 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -73,7 +73,7 @@ nettle_SOURCES = aes-decrypt-internal.c aes-decrypt.c \
 		 aes256-set-encrypt-key.c aes256-set-decrypt-key.c \
 		 aes256-meta.c \
 		 arcfour.c arcfour-crypt.c \
-		 arctwo.c arctwo-meta.c blowfish.c \
+		 arctwo.c arctwo-meta.c blowfish.c blowfish-bcrypt.c \
 		 base16-encode.c base16-decode.c base16-meta.c \
 		 base64-encode.c base64-decode.c base64-meta.c \
 		 base64url-encode.c base64url-decode.c base64url-meta.c \
diff --git a/base64-decode.c b/base64-decode.c
index b993117a..9273224a 100644
--- a/base64-decode.c
+++ b/base64-decode.c
@@ -45,7 +45,7 @@
 void
 base64_decode_init(struct base64_decode_ctx *ctx)
 {
-  static const signed char base64_decode_table[0x100] =
+  static const signed char base64_decode_table[0x80] =
     {
       /* White space is HT, VT, FF, CR, LF and SPC */
       -1, -1, -1, -1, -1, -1, -1, -1, -1, -2, -2, -2, -2, -2, -1, -1, 
@@ -56,14 +56,6 @@ base64_decode_init(struct base64_decode_ctx *ctx)
       15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, -1, -1, -1, -1, -1,
       -1, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,
       41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
     };
 
   ctx-&gt;word = ctx-&gt;bits = ctx-&gt;padding = 0;
@@ -75,7 +67,12 @@ base64_decode_single(struct base64_decode_ctx *ctx,
 		     uint8_t *dst,
 		     char src)
 {
-  int data = ctx-&gt;table[(uint8_t) src];
+  int data;
+
+  if ((uint8_t) src &gt; 0x7f)
+    return -1;
+
+  data = ctx-&gt;table[(uint8_t) src];
 
   switch(data)
     {
diff --git a/blowfish-bcrypt.c b/blowfish-bcrypt.c
new file mode 100644
index 00000000..e573c86e
--- /dev/null
+++ b/blowfish-bcrypt.c
@@ -0,0 +1,511 @@
+/* blowfish-bcrypt.c
+
+   The blowfish bcrypt implementation.
+
+   Copyright (c) 2020 Stephen R. van den Berg
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+#include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;string.h&gt;
+#include &lt;stdlib.h&gt;
+
+#include "blowfish.h"
+#include "blowfish-internal.h"
+#include "base64.h"
+
+#include "macros.h"
+
+#define CRYPTPLEN 7
+#define SALTLEN ((BLOWFISH_BCRYPT_BINSALT_SIZE*8+5) / 6)
+
+#define HASHOFFSET (CRYPTPLEN + SALTLEN)
+
+static const signed char radix64_decode_table[0x80] = {
+  /* White space is HT, VT, FF, CR, LF and SPC */
+  -1, -1, -1, -1, -1, -1, -1, -1, -1, -2, -2, -2, -2, -2, -1, -1,
+  -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+  -2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  1,
+  54, 55, 56, 57, 58, 59, 60, 61, 62, 63, -1, -1, -1, -3, -1, -1,
+  -1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,
+  17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, -1, -1, -1, -1, -1,
+  -1, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42,
+  43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, -1, -1, -1, -1, -1,
+};
+
+static const char radix64_encode_table[64] =
+  "./ABCDEFGHIJKLMNOPQRSTUVWXYZ"
+    "abcdefghijklmnopqrstuvwxyz"
+    "0123456789";
+
+int
+blowfish_bcrypt_verify(const char *key,
+                       const char *hashed)
+{
+  char newhash[BLOWFISH_BCRYPT_HASH_SIZE];
+
+  return blowfish_bcrypt_hash(sizeof newhash,
+                              newhash, key, hashed, -1, (void*)0)
+   &amp;&amp; !strcmp(newhash, hashed);
+}
+
+static char *encode_radix64(char *dst, size_t len, const uint8_t *src)
+{
+  struct base64_encode_ctx ctx;
+  base64_encode_init(&amp;ctx);
+  ctx.alphabet = radix64_encode_table;
+  dst += base64_encode_update(&amp;ctx, dst, len, src);
+  dst += base64_encode_final(&amp;ctx, dst);
+  *--dst = '\0';	    /* Strip the trailing = */
+  return dst;
+}
+
+/*
+ * Large parts of the code below are based on public domain sources.
+ * The comments and copyright notices have been preserved.
+ * Any code added or modified by me is licensed under the
+ * licenses listed above.  --  Stephen R. van den Berg
+ */
+
+/*
+ * This code comes from John the Ripper password cracker, with reentrant
+ * and crypt(3) interfaces added, but optimizations specific to password
+ * cracking removed.
+ *
+ * Written by Solar Designer &lt;solar at openwall.com&gt; in 1998-2015.
+ * No copyright is claimed, and the software is hereby placed in the public
+ * domain. In case this attempt to disclaim copyright and place the software
+ * in the public domain is deemed null and void, then the software is
+ * Copyright (c) 1998-2015 Solar Designer and it is hereby released to the
+ * general public under the following terms:
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted.
+ *
+ * There's ABSOLUTELY NO WARRANTY, express or implied.
+ *
+ * It is my intent that you should be able to use this on your system,
+ * as part of a software package, or anywhere else to improve security,
+ * ensure compatibility, or for any other purpose. I would appreciate
+ * it if you give credit where it is due and keep your modifications in
+ * the public domain as well, but I don't require that in order to let
+ * you place this code and any modifications you make under a license
+ * of your choice.
+ *
+ * This implementation is fully compatible with OpenBSD's bcrypt.c for prefix
+ * "$2b$", originally by Niels Provos &lt;provos at citi.umich.edu&gt;, and it uses
+ * some of his ideas. The password hashing algorithm was designed by David
+ * Mazieres &lt;dm at lcs.mit.edu&gt;. For information on the level of
+ * compatibility for bcrypt hash prefixes other than "$2b$", please refer to
+ * the comments in set_key() below and to the included crypt(3) man page.
+ */
+
+typedef uint32_t bf_key[_BLOWFISH_ROUNDS + 2];
+
+/*
+ * Magic IV for 64 Blowfish encryptions that we do at the end.
+ * The string is "OrpheanBeholderScryDoubt" on big-endian.
+ */
+static uint32_t magic_w[6] = {
+  0x4F727068, 0x65616E42, 0x65686F6C,
+  0x64657253, 0x63727944, 0x6F756274
+};
+
+static void swap32(uint32_t *x, int count)
+{
+#if !WORDS_BIGENDIAN
+  do {
+    uint32_t tmp = *x;
+    tmp = (tmp &lt;&lt; 16) | (tmp &gt;&gt; 16);
+    *x++ = ((tmp &amp; 0x00FF00FF) &lt;&lt; 8) | ((tmp &gt;&gt; 8) &amp; 0x00FF00FF);
+  } while (--count);
+#endif
+}
+
+static void set_xkey(const char *key, bf_key expanded, bf_key initial,
+    unsigned bug, uint32_t safety)
+{
+  const char *ptr = key;
+  unsigned i, j;
+  uint32_t sign, diff, tmp[2];
+
+/*
+ * There was a sign extension bug in older revisions of this function. While
+ * we would have liked to simply fix the bug and move on, we have to provide
+ * a backwards compatibility feature (essentially the bug) for some systems and
+ * a safety measure for some others. The latter is needed because for certain
+ * multiple inputs to the buggy algorithm there exist easily found inputs to
+ * the correct algorithm that produce the same hash. Thus, we optionally
+ * deviate from the correct algorithm just enough to avoid such collisions.
+ * While the bug itself affected the majority of passwords containing
+ * characters with the 8th bit set (although only a percentage of those in a
+ * collision-producing way), the anti-collision safety measure affects
+ * only a subset of passwords containing the '\xff' character (not even all of
+ * those passwords, just some of them). This character is not found in valid
+ * UTF-8 sequences and is rarely used in popular 8-bit character encodings.
+ * Thus, the safety measure is unlikely to cause much annoyance, and is a
+ * reasonable tradeoff to use when authenticating against existing hashes that
+ * are not reliably known to have been computed with the correct algorithm.
+ *
+ * We use an approach that tries to minimize side-channel leaks of password
+ * information - that is, we mostly use fixed-cost bitwise operations instead
+ * of branches or table lookups. (One conditional branch based on password
+ * length remains. It is not part of the bug aftermath, though, and is
+ * difficult and possibly unreasonable to avoid given the use of C strings by
+ * the caller, which results in similar timing leaks anyway.)
+ *
+ * For actual implementation, we set an array index in the variable "bug"
+ * (0 means no bug, 1 means sign extension bug emulation) and a flag in the
+ * variable "safety" (bit 16 is set when the safety measure is requested).
+ * Valid combinations of settings are:
+ *
+ * Prefix "$2a$": bug = 0, safety = 0x10000
+ * Prefix "$2b$": bug = 0, safety = 0
+ * Prefix "$2x$": bug = 1, safety = 0
+ * Prefix "$2y$": bug = 0, safety = 0
+ */
+
+  sign = diff = 0;
+
+  for (i = 0; i &lt; _BLOWFISH_ROUNDS + 2; i++) {
+    tmp[0] = tmp[1] = 0;
+    for (j = 0; j &lt; 4; j++) {
+      tmp[0] &lt;&lt;= 8;
+      tmp[0] |= (unsigned char)*ptr; /* correct */
+      tmp[1] &lt;&lt;= 8;
+      tmp[1] |= (signed char)*ptr; /* bug */
+/*
+ * Sign extension in the first char has no effect - nothing to overwrite yet,
+ * and those extra 24 bits will be fully shifted out of the 32-bit word. For
+ * chars 2, 3, 4 in each four-char block, we set bit 7 of "sign" if sign
+ * extension in tmp[1] occurs. Once this flag is set, it remains set.
+ */
+      if (j)
+        sign |= tmp[1] &amp; 0x80;
+      if (!*ptr)
+        ptr = key;
+      else
+        ptr++;
+    }
+    diff |= tmp[0] ^ tmp[1]; /* Non-zero on any differences */
+
+    expanded[i] = tmp[bug];
+    initial[i] = _nettle_blowfish_initial_ctx.p[i] ^ tmp[bug];
+  }
+
+/*
+ * At this point, "diff" is zero if the correct and buggy algorithms produced
+ * exactly the same result. If so and if "sign" is non-zero, which indicates
+ * that there was a non-benign sign extension, this means that we have a
+ * collision between the correctly computed hash for this password and a set of
+ * passwords that could be supplied to the buggy algorithm. Our safety measure
+ * is meant to protect from such many-buggy to one-correct collisions, by
+ * deviating from the correct algorithm in such cases. Let's check for this.
+ */
+  diff |= diff &gt;&gt; 16; /* still zero if exact match */
+  diff &amp;= 0xffff; /* ditto */
+  diff += 0xffff; /* bit 16 set if "diff" was non-zero (on non-match) */
+  sign &lt;&lt;= 9; /* move the non-benign sign extension flag to bit 16 */
+  sign &amp;= ~diff &amp; safety; /* action needed? */
+
+/*
+ * If we have determined that we need to deviate from the correct algorithm,
+ * flip bit 16 in initial expanded key. (The choice of 16 is arbitrary, but
+ * let's stick to it now. It came out of the approach we used above, and it's
+ * not any worse than any other choice we could make.)
+ *
+ * It is crucial that we don't do the same to the expanded key used in the main
+ * Eksblowfish loop. By doing it to only one of these two, we deviate from a
+ * state that could be directly specified by a password to the buggy algorithm
+ * (and to the fully correct one as well, but that's a side-effect).
+ */
+  initial[0] ^= sign;
+}
+
+static int ibcrypt(size_t length, char *dst,
+                   const char *key, const char *scheme,
+		   int minlog2rounds,
+		   int log2rounds, const uint8_t *salt)
+{
+  struct {
+    struct blowfish_ctx ctx;
+    bf_key expanded_key;
+    union {
+      uint32_t salt[4];
+      uint32_t output[6];
+    } binary;
+  } data;
+  uint8_t psalt[BLOWFISH_BCRYPT_BINSALT_SIZE];
+  uint32_t L, R;
+  uint32_t *ptr;
+  uint32_t count;
+  int i;
+  size_t schemelen = strlen(scheme);
+  unsigned cscheme;
+  unsigned bug = 0;
+  uint32_t safety = 0;
+  if (length &lt; BLOWFISH_BCRYPT_HASH_SIZE ||
+      schemelen &lt; 2)
+    return 0;
+
+  if (schemelen &gt;= 3 &amp;&amp; *scheme++ != '$')
+    return 0;
+  if (*scheme++ != '2')
+    return 0;
+
+  switch (cscheme = *scheme++) {
+    default:
+      return 0;
+    case 'a': safety = 0x10000;
+      break;
+    case 'x': bug = 1;
+      break;
+    case 'b': case 'y':
+      break;
+  }
+
+  if (schemelen &gt;= 4) {
+    if (*scheme++ != '$')
+      return 0;
+    if (schemelen &gt;= 6) {
+      if (log2rounds &lt; 0)
+        log2rounds = atoi(scheme);
+      scheme += 2;
+      if (schemelen &gt;= CRYPTPLEN &amp;&amp; *scheme++ != '$')
+	return 0;
+      if (schemelen &gt;= HASHOFFSET &amp;&amp; !salt) {
+        struct base64_decode_ctx ctx;
+        size_t saltlen = BLOWFISH_BCRYPT_BINSALT_SIZE;
+
+        base64_decode_init(&amp;ctx);
+        ctx.table = radix64_decode_table;
+
+        if (!base64_decode_update(&amp;ctx, &amp;saltlen, (uint8_t *) data.binary.salt,
+                                  SALTLEN, scheme)
+         || saltlen != BLOWFISH_BCRYPT_BINSALT_SIZE)
+          return 0;
+      }
+    }
+  }
+
+  if (salt)
+    memcpy(data.binary.salt, salt, BLOWFISH_BCRYPT_BINSALT_SIZE);
+  else if (schemelen &lt; HASHOFFSET)
+    return 0;
+  memcpy(psalt, data.binary.salt, BLOWFISH_BCRYPT_BINSALT_SIZE);
+  swap32(data.binary.salt, 4);
+
+  if (log2rounds &lt; minlog2rounds || log2rounds &gt; 31)
+    return 0;
+  count = (uint32_t)1 &lt;&lt; log2rounds;
+
+  set_xkey(key, data.expanded_key, data.ctx.p, bug, safety);
+  memcpy(data.ctx.s, _nettle_blowfish_initial_ctx.s, sizeof(data.ctx.s));
+
+  L = R = 0;
+  for (i = 0; i &lt; _BLOWFISH_ROUNDS + 2; i += 2) {
+    L ^= data.binary.salt[i &amp; 2];
+    R ^= data.binary.salt[(i &amp; 2) + 1];
+    _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+    data.ctx.p[i] = L;
+    data.ctx.p[i + 1] = R;
+  }
+
+  ptr = data.ctx.s[0];
+  do {
+    ptr += 4;
+    L ^= data.binary.salt[(_BLOWFISH_ROUNDS + 2) &amp; 3];
+    R ^= data.binary.salt[(_BLOWFISH_ROUNDS + 3) &amp; 3];
+    _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+    *(ptr - 4) = L;
+    *(ptr - 3) = R;
+
+    L ^= data.binary.salt[(_BLOWFISH_ROUNDS + 4) &amp; 3];
+    R ^= data.binary.salt[(_BLOWFISH_ROUNDS + 5) &amp; 3];
+    _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+    *(ptr - 2) = L;
+    *(ptr - 1) = R;
+  } while (ptr &lt; &amp;data.ctx.s[3][0xFF]);
+
+  do {
+    int done;
+
+    for (i = 0; i &lt; _BLOWFISH_ROUNDS + 2; i += 2) {
+      data.ctx.p[i] ^= data.expanded_key[i];
+      data.ctx.p[i + 1] ^= data.expanded_key[i + 1];
+    }
+
+    done = 0;
+    do {
+      uint32_t tmp1, tmp2, tmp3, tmp4;
+
+      L = R = 0;
+      ptr = data.ctx.p;
+      do {
+        ptr += 2;
+        _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+        *(ptr - 2) = L;
+        *(ptr - 1) = R;
+      } while (ptr &lt; &amp;data.ctx.p[_BLOWFISH_ROUNDS + 2]);
+
+      ptr = data.ctx.s[0];
+      do {
+        ptr += 2;
+        _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+        *(ptr - 2) = L;
+        *(ptr - 1) = R;
+      } while (ptr &lt; &amp;data.ctx.s[3][0xFF]);
+
+      if (done)
+        break;
+      done = 1;
+
+      tmp1 = data.binary.salt[0];
+      tmp2 = data.binary.salt[1];
+      tmp3 = data.binary.salt[2];
+      tmp4 = data.binary.salt[3];
+      for (i = 0; i &lt; _BLOWFISH_ROUNDS; i += 4) {
+        data.ctx.p[i] ^= tmp1;
+        data.ctx.p[i + 1] ^= tmp2;
+        data.ctx.p[i + 2] ^= tmp3;
+        data.ctx.p[i + 3] ^= tmp4;
+      }
+      data.ctx.p[16] ^= tmp1;
+      data.ctx.p[17] ^= tmp2;
+    } while (1);
+  } while (--count);
+
+  for (i = 0; i &lt; 6; i += 2) {
+    L = magic_w[i];
+    R = magic_w[i + 1];
+
+    count = 64;
+    do
+      _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+    while (--count);
+
+    data.binary.output[i] = L;
+    data.binary.output[i + 1] = R;
+  }
+
+  *dst++ = '$';
+  *dst++ = '2';
+  *dst++ = cscheme;
+  *dst++ = '$';
+  *dst++ = '0' + log2rounds / 10;
+  *dst++ = '0' + log2rounds % 10;
+  *dst++ = '$';
+  dst = encode_radix64(dst, BLOWFISH_BCRYPT_BINSALT_SIZE, psalt) - 1;
+
+  swap32(data.binary.output, 6);
+/* This has to be bug-compatible with the original implementation, so
+   only encode 23 of the 24 bytes. */
+  encode_radix64(dst, 23, (uint8_t *) data.binary.output);
+  return cscheme;
+}
+
+/*
+ * Please preserve the runtime self-test. It serves two purposes at once:
+ *
+ * 1. We really can't afford the risk of producing incompatible hashes e.g.
+ * when there's something like gcc bug 26587 again, whereas an application or
+ * library integrating this code might not also integrate our external tests or
+ * it might not run them after every build. Even if it does, the miscompile
+ * might only occur on the production build, but not on a testing build (such
+ * as because of different optimization settings). It is painful to recover
+ * from incorrectly-computed hashes - merely fixing whatever broke is not
+ * enough. Thus, a proactive measure like this self-test is needed.
+ *
+ * 2. We don't want to leave sensitive data from our actual password hash
+ * computation on the stack or in registers. Previous revisions of the code
+ * would do explicit cleanups, but simply running the self-test after hash
+ * computation is more reliable.
+ *
+ * The performance cost of this quick self-test is around 0.6% at the "$2a$08"
+ * setting.
+ */
+int blowfish_bcrypt_hash(size_t length, char *dst,
+                         const char *key, const char *scheme,
+			 int log2rounds, const uint8_t *salt)
+{
+  const char *test_pw = "8b \xd0\xc1\xd2\xcf\xcc\xd8";
+  const char *test_scheme = "$2a$00$abcdefghijklmnopqrstuu";
+  static const char * const test_hashes[2] =
+    {"i1D709vfamulimlGcq0qq3UvuUasvEa\0\x55",  /* 'a', 'b', 'y' */
+     "VUrPmXD6q/nVSSp7pNDhCR9071IfIRe\0\x55"}; /* 'x' */
+  const char *test_hash = test_hashes[0];
+  int cscheme;
+  int ok;
+  struct {
+    char s[HASHOFFSET + 1];
+    char o[HASHOFFSET + 31 + 1 + 1 + 1];
+  } buf;
+
+  if (length)
+    *dst = '\0';
+/* Hash the supplied password */
+  cscheme = ibcrypt(length, dst, key, scheme, 4, log2rounds, salt);
+
+/*
+ * Do a quick self-test. It is important that we make both calls to ibcrypt()
+ * from the same scope such that they likely use the same stack locations,
+ * which makes the second call overwrite the first call's sensitive data on the
+ * stack and makes it more likely that any alignment related issues would be
+ * detected by the self-test.
+ */
+  memcpy(buf.s, test_scheme, sizeof(buf.s));
+
+  if (cscheme)
+    test_hash = test_hashes[(buf.s[2] = cscheme) == 'x'];
+
+  memset(buf.o, 0x55, sizeof(buf.o));
+  buf.o[sizeof(buf.o) - 1] = 0;
+  ok = ibcrypt(sizeof(buf.o) - (1 + 1), buf.o, test_pw,
+               buf.s, 0, -1, (void*)0);
+
+  ok = (ok &amp;&amp;
+      !memcmp(buf.o, buf.s, HASHOFFSET) &amp;&amp;
+      !memcmp(buf.o + HASHOFFSET, test_hash, 31 + 1 + 1 + 1));
+
+  {
+    const char *k = "\xff\xa3" "34" "\xff\xff\xff\xa3" "345";
+    bf_key ae, ai, ye, yi;
+    set_xkey(k, ae, ai, 0, 0x10000); /* $2a$ */
+    set_xkey(k, ye, yi, 0, 0); /* $2y$ */
+    ai[0] ^= 0x10000; /* undo the safety (for comparison) */
+    ok = ok &amp;&amp; ai[0] == 0xdb9c59bc &amp;&amp; ye[17] == 0x33343500 &amp;&amp;
+        !memcmp(ae, ye, sizeof(ae)) &amp;&amp;
+        !memcmp(ai, yi, sizeof(ai));
+  }
+
+  return ok &amp;&amp; !!cscheme;
+}
diff --git a/blowfish.h b/blowfish-internal.h
similarity index 50%
copy from blowfish.h
copy to blowfish-internal.h
index bcdc7cb6..da28fa34 100644
--- a/blowfish.h
+++ b/blowfish-internal.h
@@ -1,4 +1,4 @@
-/* blowfish.h
+/* blowfish-internal.h
 
    Blowfish block cipher.
 
@@ -32,8 +32,8 @@
    not, see http://www.gnu.org/licenses/.
 */
  
-#ifndef NETTLE_BLOWFISH_H_INCLUDED
-#define NETTLE_BLOWFISH_H_INCLUDED
+#ifndef NETTLE_BLOWFISH_INTERNAL_H_INCLUDED
+#define NETTLE_BLOWFISH_INTERNAL_H_INCLUDED
 
 #include "nettle-types.h"
 
@@ -41,49 +41,12 @@
 extern "C" {
 #endif
 
-/* Name mangling */
-#define blowfish_set_key nettle_blowfish_set_key
-#define blowfish128_set_key nettle_blowfish128_set_key
-#define blowfish_encrypt nettle_blowfish_encrypt
-#define blowfish_decrypt nettle_blowfish_decrypt
-
-#define BLOWFISH_BLOCK_SIZE 8
-
-/* Variable key size between 64 and 448 bits. */
-#define BLOWFISH_MIN_KEY_SIZE 8
-#define BLOWFISH_MAX_KEY_SIZE 56
-
-/* Default to 128 bits */
-#define BLOWFISH_KEY_SIZE 16
-
-#define BLOWFISH128_KEY_SIZE 16
-
-#define _BLOWFISH_ROUNDS 16
-
-struct blowfish_ctx
-{
-  uint32_t s[4][256];
-  uint32_t p[_BLOWFISH_ROUNDS+2];
-};
-
-/* Returns 0 for weak keys, otherwise 1. */
-int
-blowfish_set_key(struct blowfish_ctx *ctx,
-                 size_t length, const uint8_t *key);
-int
-blowfish128_set_key(struct blowfish_ctx *ctx, const uint8_t *key);
-
-void
-blowfish_encrypt(const struct blowfish_ctx *ctx,
-                 size_t length, uint8_t *dst,
-                 const uint8_t *src);
-void
-blowfish_decrypt(const struct blowfish_ctx *ctx,
-                 size_t length, uint8_t *dst,
-                 const uint8_t *src);
+extern const struct blowfish_ctx _nettle_blowfish_initial_ctx;
+extern void _nettle_blowfish_encround (const struct blowfish_ctx *ctx,
+                                       uint32_t * ret_xl, uint32_t * ret_xr);
 
 #ifdef __cplusplus
 }
 #endif
 
-#endif /* NETTLE_BLOWFISH_H_INCLUDED */
+#endif /* NETTLE_BLOWFISH_INTERNAL_H_INCLUDED */
diff --git a/blowfish.c b/blowfish.c
index 52040f13..e73caffe 100644
--- a/blowfish.c
+++ b/blowfish.c
@@ -54,12 +54,13 @@
 #include &lt;assert.h&gt;
 
 #include "blowfish.h"
+#include "blowfish-internal.h"
 
 #include "macros.h"
 
 /* precomputed S boxes */
-static const struct blowfish_ctx
-initial_ctx = {
+const struct blowfish_ctx
+_nettle_blowfish_initial_ctx = {
   {
     { /* ks0 */
       0xD1310BA6, 0x98DFB5AC, 0x2FFD72DB, 0xD01ADFB7, 0xB8E1AFED, 0x6A267E96,
@@ -261,8 +262,8 @@ initial_ctx = {
 
 #define R(c, l,r,i)  do { l ^= c-&gt;p[i]; r ^= F(c,l); } while(0)
 
-static void
-encrypt (const struct blowfish_ctx *ctx, uint32_t * ret_xl,
+void
+_nettle_blowfish_encround (const struct blowfish_ctx *ctx, uint32_t * ret_xl,
 	    uint32_t * ret_xr)
 {
   uint32_t xl, xr;
@@ -295,7 +296,7 @@ encrypt (const struct blowfish_ctx *ctx, uint32_t * ret_xl,
 }
 
 static void
-decrypt (const struct blowfish_ctx *ctx, uint32_t * ret_xl, uint32_t * ret_xr)
+decround (const struct blowfish_ctx *ctx, uint32_t * ret_xl, uint32_t * ret_xr)
 {
   uint32_t xl, xr;
 
@@ -339,7 +340,7 @@ blowfish_encrypt (const struct blowfish_ctx *ctx,
 
       d1 = READ_UINT32(src);
       d2 = READ_UINT32(src+4);
-      encrypt (ctx, &amp;d1, &amp;d2);
+      _nettle_blowfish_encround (ctx, &amp;d1, &amp;d2);
       dst[0] = (d1 &gt;&gt; 24) &amp; 0xff;
       dst[1] = (d1 &gt;&gt; 16) &amp; 0xff;
       dst[2] = (d1 &gt;&gt; 8) &amp; 0xff;
@@ -361,7 +362,7 @@ blowfish_decrypt (const struct blowfish_ctx *ctx,
 
       d1 = READ_UINT32(src);
       d2 = READ_UINT32(src+4);
-      decrypt (ctx, &amp;d1, &amp;d2);
+      decround (ctx, &amp;d1, &amp;d2);
       dst[0] = (d1 &gt;&gt; 24) &amp; 0xff;
       dst[1] = (d1 &gt;&gt; 16) &amp; 0xff;
       dst[2] = (d1 &gt;&gt; 8) &amp; 0xff;
@@ -380,7 +381,7 @@ blowfish_set_key (struct blowfish_ctx *ctx,
   int i, j;
   uint32_t data, datal, datar;
 
-  *ctx = initial_ctx;
+  *ctx = _nettle_blowfish_initial_ctx;
 
   for (i = j = 0; i &lt; _BLOWFISH_ROUNDS + 2; i++)
     {
@@ -393,15 +394,15 @@ blowfish_set_key (struct blowfish_ctx *ctx,
   datal = datar = 0;
   for (i = 0; i &lt; _BLOWFISH_ROUNDS + 2; i += 2)
     {
-      encrypt (ctx, &amp;datal, &amp;datar);
+      _nettle_blowfish_encround (ctx, &amp;datal, &amp;datar);
       ctx-&gt;p[i] = datal;
       ctx-&gt;p[i + 1] = datar;
     }
-  
+
   for (j = 0; j &lt; 4; j++)
     for (i = 0; i &lt; 256; i += 2)
       {
-	encrypt (ctx, &amp;datal, &amp;datar);
+	_nettle_blowfish_encround (ctx, &amp;datal, &amp;datar);
 	ctx-&gt;s[j][i] = datal;
 	ctx-&gt;s[j][i + 1] = datar;
     }
diff --git a/blowfish.h b/blowfish.h
index bcdc7cb6..af48e20f 100644
--- a/blowfish.h
+++ b/blowfish.h
@@ -46,6 +46,8 @@ extern "C" {
 #define blowfish128_set_key nettle_blowfish128_set_key
 #define blowfish_encrypt nettle_blowfish_encrypt
 #define blowfish_decrypt nettle_blowfish_decrypt
+#define blowfish_bcrypt_hash nettle_blowfish_bcrypt_hash
+#define blowfish_bcrypt_verify nettle_blowfish_bcrypt_verify
 
 #define BLOWFISH_BLOCK_SIZE 8
 
@@ -60,6 +62,9 @@ extern "C" {
 
 #define _BLOWFISH_ROUNDS 16
 
+#define BLOWFISH_BCRYPT_HASH_SIZE (60 + 1) /* Including null-terminator */
+#define BLOWFISH_BCRYPT_BINSALT_SIZE 16    /* Binary string size */
+
 struct blowfish_ctx
 {
   uint32_t s[4][256];
@@ -81,6 +86,16 @@ void
 blowfish_decrypt(const struct blowfish_ctx *ctx,
                  size_t length, uint8_t *dst,
                  const uint8_t *src);
+int
+blowfish_bcrypt_hash(size_t length,
+                     char *dst,
+                     const char *key,
+                     const char *scheme,
+		     int log2rounds,
+		     const uint8_t *salt);
+int
+blowfish_bcrypt_verify(const char *key,
+                       const char *hashed);
 
 #ifdef __cplusplus
 }
diff --git a/nettle.texinfo b/nettle.texinfo
index ff64889c..13b1df39 100644
--- a/nettle.texinfo
+++ b/nettle.texinfo
@@ -1512,6 +1512,73 @@ in any other way.
 Analogous to @code{blowfish_encrypt}
 @end deftypefun
 
+@deftypefun int blowfish_bcrypt_hash (size_t @var{length}, char *@var{dst}, const \
char *@var{key}, const char *@var{scheme}, int @var{log2rounds}, const uint8_t \
*@var{salt}) +Compute the bcrypt password hash.
+The function will return @code{0} if the hash cannot be computed
+due to invalid input.
+The function will return @code{1} and store the computed hash
+in the array pointed to by @var{dst}.  The hash is computed based
+on the chosen @var{scheme}, number of rounds @var{log2rounds} and
+specified @var{salt}.
+
+@var{length} must be at least @code{BLOWFISH_BCRYPT_HASH_SIZE}.
+
+@var{dst} must point to a character array of the specified @var{length}.
+
+@var{key} contains the zero terminated plaintext password string.
+
+@var{scheme} contains either just the chosen scheme (valid schemes
+are: @code{2a}, @code{2b}, @code{2x} or @code{2y}), or
+(the prefix of) an existing hashed password (typically @code{$2b$10$...}).
+
+@var{log2rounds} contains the log2 of the number of encryption rounds
+that must be used to compute the hash.  If it is @code{-1} the value
+will be extracted from @var{scheme}.
+
+@var{salt} should point to an array of @code{BLOWFISH_BCRYPT_BINSALT_SIZE}
+random bytes to be used to perturb the hash computation.  If it is @code{NULL}
+the salt will be extracted from @var{scheme}.
+
+Sample code to generate a bcrypt hash:
+@example
+char cleartxtpassword[] = "ExamplePassword";
+uint8_t salt[BLOWFISH_BCRYPT_BINSALT_SIZE];
+@dots{}
+/* Make sure that salt is filled with random bytes */
+@dots{}
+char hashedresult[BLOWFISH_BCRYPT_HASH_SIZE];
+int result = blowfish_bcrypt(sizeof(hashedresult), hashedresult,
+                             cleartxtpassword, "2b", 10, salt);
+if (result)
+  printf("%s\n", hashedresult);
+@end example
+@end deftypefun
+
+@deftypefun int blowfish_bcrypt_verify (const char *@var{key}, const char \
*@var{hashed}) +Verifies the bcrypt password hash against the supplied plaintext \
password. +The function will return @code{0} if the password does not match.
+The function will return @code{1} if the password matches.
+
+@var{key} contains the zero terminated plaintext password string.
+
+@var{hashed} contains the zero terminated hashed string to compare with.
+
+Sample code to verify a bcrypt hash:
+@example
+char cleartxtpassword[] = "ExamplePassword";
+char existinghashed[] =
+           "$2y$"  /* Hash algorithm version */
+           "10"   /* 2^10 hash rounds (strength) */
+           "$"   /* separator */
+           "1b2lPgo4XumibnJGN3r3sO" /* base64 encoded 16-byte salt */
+           "u7wE7xNfYDKlAxZffJDCJdVfFTAyevu"; /* Hashedpart */
+if (blowfish_bcrypt_verify(cleartxtpassword, existinghashed))
+  printf("Password is correct.");
+else
+  printf("Password is incorrect.");
+@end example
+@end deftypefun
+
 @subsection Camellia
 @cindex Camellia
 
-- 
2.20.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200405175713</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-05 17:57:13-0400</timestampReceived><subject>Re: [PATCH] (revision 3.1) Added bcrypt() support.</subject><body>

Sorry for the delay in review. This is a fairly large change, and I
think it has to wait until after the Nettle-3.6 release. Maybe it could
be split into smaller pieces, e.g, a separate patch to introduce
blowfish-internal.h and move needed declaratinos there.

Only one comment for now:

&gt; --- a/base64-decode.c
&gt; +++ b/base64-decode.c
&gt; @@ -45,7 +45,7 @@
&gt;  void
&gt;  base64_decode_init(struct base64_decode_ctx *ctx)
&gt;  {
&gt; -  static const signed char base64_decode_table[0x100] =
&gt; +  static const signed char base64_decode_table[0x80] =
&gt;      {
&gt;        /* White space is HT, VT, FF, CR, LF and SPC */
&gt;        -1, -1, -1, -1, -1, -1, -1, -1, -1, -2, -2, -2, -2, -2, -1, -1, 
&gt; @@ -56,14 +56,6 @@ base64_decode_init(struct base64_decode_ctx *ctx)
&gt;        15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, -1, -1, -1, -1, -1,
&gt;        -1, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,
&gt;        41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, -1, -1, -1, -1, -1,
&gt; -      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
&gt; -      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
&gt; -      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
&gt; -      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
&gt; -      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
&gt; -      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
&gt; -      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
&gt; -      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
&gt;      };
&gt;  
&gt;    ctx-&gt;word = ctx-&gt;bits = ctx-&gt;padding = 0;
&gt; @@ -75,7 +67,12 @@ base64_decode_single(struct base64_decode_ctx *ctx,
&gt;  		     uint8_t *dst,
&gt;  		     char src)
&gt;  {
&gt; -  int data = ctx-&gt;table[(uint8_t) src];
&gt; +  int data;
&gt; +
&gt; +  if ((uint8_t) src &gt; 0x7f)
&gt; +    return -1;
&gt; +
&gt; +  data = ctx-&gt;table[(uint8_t) src];

I'm not entirely sure halving the table size is a good tradeoff. If we
want to do it, that should be a separete change. And
base64url_decode_init should be updated too.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200406005731</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-04-06 00:57:31-0400</timestampReceived><subject>Re: [PATCH] (revision 3.1) Added bcrypt() support.</subject><body>

On Sun, Apr 5, 2020 at 7:57 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Sorry for the delay in review. This is a fairly large change, and I
&gt; think it has to wait until after the Nettle-3.6 release. Maybe it could
&gt; be split into smaller pieces, e.g, a separate patch to introduce
&gt; blowfish-internal.h and move needed declaratinos there.
&gt;

I'll split it up, and resubmit.  No problem.


&gt; Only one comment for now:
&gt; &gt; --- a/base64-decode.c
&gt; &gt; +++ b/base64-decode.c
&gt;
&gt; &gt; -      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
&gt; &gt; -      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
&gt;
&gt;
&gt; &gt; +  if ((uint8_t) src &gt; 0x7f)
&gt; &gt; +    return -1;
&gt; &gt; +
&gt; &gt; +  data = ctx-&gt;table[(uint8_t) src];
&gt;


&gt; I'm not entirely sure halving the table size is a good tradeoff. If we
&gt; want to do it, that should be a separete change.


You mean because it will cost an extra clockcycle on decode per character?
That will only be relevant for very large sequences of base64 characters.
And the sequences are that large, the speed to decode becomes RAM-access
bound; in which case there will be plenty of spare CPU cycles.  This
essentially makes the extra "if" cost-free.

-- 
Stephen.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200407072534</emailId><senderName>Amos Jeffries</senderName><senderEmail>squid3@treenet.co.nz</senderEmail><timestampReceived>2020-04-07 07:25:34-0400</timestampReceived><subject>Re: [PATCH] (revision 3.1) Added bcrypt() support.</subject><body>

On 6/04/20 12:57 pm, Stephen R. van den Berg wrote:
&gt; On Sun, Apr 5, 2020 at 7:57 PM Niels Möller wrote:
&gt; 
&gt;&gt; I'm not entirely sure halving the table size is a good tradeoff. If we
&gt;&gt; want to do it, that should be a separete change.
&gt; 
&gt; 
&gt; You mean because it will cost an extra clockcycle on decode per character?
&gt; That will only be relevant for very large sequences of base64 characters.

How are you defining "large" here?

Base64 data inputs can be any size. Megabytes are not uncommon in
network messaging.


&gt; And the sequences are that large, the speed to decode becomes RAM-access
&gt; bound; in which case there will be plenty of spare CPU cycles.  This
&gt; essentially makes the extra "if" cost-free.
&gt; 

This assumes that the CPU is waiting for data to load. Which is
typically not the case in modern CPUs. Pre-fetching is typically used
when processing sequential data such as long strings.

For this type of situation we should expect the L1/L2 cache lines to be
loaded by the time they are needed. Delays will most likely be from
interruptions to the decode thread, or less likely; code or table size
causing swapouts from the L1/L2 caches.


AYJ
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200330192515</emailId><senderName>Nikos Mavrogiannopoulos</senderName><senderEmail>n.mavrogiannopoulos@gmail.com</senderEmail><timestampReceived>2020-03-30 19:25:15-0400</timestampReceived><subject>Re: Failure of gnutls ci build</subject><body>

On Mon, Mar 30, 2020 at 1:23 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt; 
&gt; Hi,
&gt; 
&gt; I committed a change to update nettle version numbers, which implies a
&gt; new symbol version for internal symbols.
&gt; 
&gt; That seems to break the gnutls ci build,
&gt; https://gitlab.com/gnutls/nettle/-/jobs/487360242
&gt; 
&gt; The error is
&gt; 
&gt; 1217 ./bootstrap: getting translations into po/.reference for gnutls...
&gt; 1218 wget: /lib64/libhogweed.so.5: version `HOGWEED_INTERNAL_5_0' not found \
&gt; (required by /lib64/libgnutls.so.30) 1219 wget: /lib64/libnettle.so.7: version \
&gt; `NETTLE_INTERNAL_7_0' not found (required by /lib64/libgnutls.so.30) 
&gt; I don't quite understand all details. This job buils and installs
&gt; nettle, as
&gt; 
&gt; ./configure --disable-documentation --prefix=/usr --libdir=/usr/lib64 &amp;&amp;
&gt; make -j4 &amp;&amp; make install

That works well as long as binary compatibility is kept. As nettle
breaks it, applications in the system will be unable to run. We may
want to install nettle somewhere separately and instruct gnutls to use
it from there rather than the default locations.

regards,
Nikos
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200331074137</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-03-31 07:41:37-0400</timestampReceived><subject>Re: Failure of gnutls ci build</subject><body>

Nikos Mavrogiannopoulos &lt;n.mavrogiannopoulos@gmail.com&gt; writes:

&gt; On Mon, Mar 30, 2020 at 1:23 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt; &gt; 
&gt; &gt; The error is
&gt; &gt; 
&gt; &gt; 1217 ./bootstrap: getting translations into po/.reference for gnutls...
&gt; &gt; 1218 wget: /lib64/libhogweed.so.5: version `HOGWEED_INTERNAL_5_0' not found \
&gt; &gt; (required by /lib64/libgnutls.so.30) 1219 wget: /lib64/libnettle.so.7: version \
&gt; &gt; `NETTLE_INTERNAL_7_0' not found (required by /lib64/libgnutls.so.30) 
&gt; &gt; I don't quite understand all details. This job buils and installs
&gt; &gt; nettle, as
&gt; &gt; 
&gt; &gt; ./configure --disable-documentation --prefix=/usr --libdir=/usr/lib64 &amp;&amp;
&gt; &gt; make -j4 &amp;&amp; make install
&gt; 
&gt; That works well as long as binary compatibility is kept. As nettle
&gt; breaks it, applications in the system will be unable to run.

But advertised binary compatibility between Nettle releases considers
only the symbols related to the public api, not the symbols with
*INTERNAL* as version. When gnutls refers to internal symbols, there's
no binary compatibility at all between nettle versions.

I would strongly recommend that the default configuration of gnutls
don't refer to internal nettle symbols. And any packaging of a version
with a non-default configuration enabling use of nettle internals (e.g,
to support more gost curves) needs to depend on a particular version of
nettle, rather than on the soname, which only captures binary
compatibility of the public ABI.

&gt; We may want to install nettle somewhere separately and instruct gnutls
&gt; to use it from there rather than the default locations.

That seems to be the right solution to the immediate problem.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200331105313</emailId><senderName>Nikos Mavrogiannopoulos</senderName><senderEmail>nmav@redhat.com</senderEmail><timestampReceived>2020-03-31 10:53:13-0400</timestampReceived><subject>Re: Failure of gnutls ci build</subject><body>

On Tue, Mar 31, 2020 at 9:41 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt; 
&gt; Nikos Mavrogiannopoulos &lt;n.mavrogiannopoulos@gmail.com&gt; writes:
&gt; 
&gt; &gt; On Mon, Mar 30, 2020 at 1:23 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt; &gt; &gt; 
&gt; &gt; &gt; The error is
&gt; &gt; &gt; 
&gt; &gt; &gt; 1217 ./bootstrap: getting translations into po/.reference for gnutls...
&gt; &gt; &gt; 1218 wget: /lib64/libhogweed.so.5: version `HOGWEED_INTERNAL_5_0' not found \
&gt; &gt; &gt; (required by /lib64/libgnutls.so.30) 1219 wget: /lib64/libnettle.so.7: version \
&gt; &gt; &gt; `NETTLE_INTERNAL_7_0' not found (required by /lib64/libgnutls.so.30) 
&gt; &gt; &gt; I don't quite understand all details. This job buils and installs
&gt; &gt; &gt; nettle, as
&gt; &gt; &gt; 
&gt; &gt; &gt; ./configure --disable-documentation --prefix=/usr --libdir=/usr/lib64 &amp;&amp;
&gt; &gt; &gt; make -j4 &amp;&amp; make install
&gt; &gt; 
&gt; &gt; That works well as long as binary compatibility is kept. As nettle
&gt; &gt; breaks it, applications in the system will be unable to run.
&gt; 
&gt; But advertised binary compatibility between Nettle releases considers
&gt; only the symbols related to the public api, not the symbols with
&gt; *INTERNAL* as version. When gnutls refers to internal symbols, there's
&gt; no binary compatibility at all between nettle versions.
&gt; 
&gt; I would strongly recommend that the default configuration of gnutls
&gt; don't refer to internal nettle symbols. And any packaging of a version
&gt; with a non-default configuration enabling use of nettle internals (e.g,
&gt; to support more gost curves) needs to depend on a particular version of
&gt; nettle, rather than on the soname, which only captures binary
&gt; compatibility of the public ABI.

That is not possible as we are introducing features into gnutls in a
faster pace than they are introduced in nettle (e.g., x448 or gost).
Without a predictable cadence of nettle releases we have to duplicate
and bundle a lot of code into gnutls because it is unknown when the
next nettle release will be. The options we have considered were
bundling nettle into gnutls or backporting selected features even when
depending on nettle's ABI. The latter is the approach we currently
take as it still keeps separation between the projects. The main
problem lies however with the unpredictability and long delay of
nettle's releases. If that could be addressed it would solve the
dependency issue as well.

regards,
Nikos

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200402060351</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-02 06:03:51-0400</timestampReceived><subject>Re: Failure of gnutls ci build</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; Nikos Mavrogiannopoulos &lt;n.mavrogiannopoulos@gmail.com&gt; writes:
&gt; 
&gt; &gt; We may want to install nettle somewhere separately and instruct gnutls
&gt; &gt; to use it from there rather than the default locations.
&gt; 
&gt; That seems to be the right solution to the immediate problem.

Below patch seems to work. See
https://gitlab.com/gnutls/nettle/-/jobs/495327357. Does it look right?
Some questions:

1. Gnutls' configure uses pkg-config to check for existence and version
   of nettle, but it doesn't use flags provided by pkg-config. We
   therefore need to set *both* PKG_CONFIG_PATH and CPPFLAGS/LDFLAGS to
   use a Nettle library in a custom location. Is it supposed to work
   that way? I would expect most things to either rely exclusively on
   pkg-config, or use other means of configuration. Except that I don't
   know if pkg-config can or should be used to supply options like
   -Wl,-rpath,...

2. What's the right way to add line breaks for the very long configure
   command in .gitlab-ci.yml?

Regards,
/Niels

diff --git a/.gitlab-ci.yml b/.gitlab-ci.yml
index 663f98f5..c215f850 100644
--- a/.gitlab-ci.yml
+++ b/.gitlab-ci.yml
@@ -96,11 +96,11 @@ build/gnutls:
   image: $CI_REGISTRY/$BUILD_IMAGES_PROJECT:$FEDORA_BUILD
   script:
   - ./.bootstrap &amp;&amp;
-  - ./configure --disable-documentation --prefix=/usr --libdir=/usr/lib64 &amp;&amp;
+    ./configure --disable-documentation --prefix="$(pwd)/local" \
--libdir="$(pwd)/local/lib" &amp;&amp;  make -j4 &amp;&amp; make install
   - git clone --depth 1 --branch master https://gitlab.com/gnutls/gnutls.git \
                gnutls-git
   - cd gnutls-git &amp;&amp; git submodule update --init &amp;&amp; ./bootstrap &amp;&amp;
-    ./configure --disable-gost --disable-cxx --disable-guile --disable-doc &amp;&amp; make \
-j$(nproc) &amp;&amp; +    ./configure PKG_CONFIG_PATH="$(pwd)/../local/lib/pkgconfig" \
CPPFLAGS="-I$(pwd)/../local/include" LDFLAGS="-L$(pwd)/../local/lib \
-Wl,-rpath,$(pwd)/../local/lib" --disable-gost --disable-cxx --disable-guile \
--disable-doc &amp;&amp; make -j$(nproc) &amp;&amp;  make -j $(nproc) check
   tags:
   - shared


-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200402081957</emailId><senderName>Tim_Rühsen</senderName><senderEmail>tim.ruehsen@gmx.de</senderEmail><timestampReceived>2020-04-02 08:19:57-0400</timestampReceived><subject>Re: Failure of gnutls ci build</subject><body>

On 4/2/20 8:03 AM, Niels Möller wrote:
&gt; nisse@lysator.liu.se (Niels Möller) writes:
&gt;
&gt;&gt; Nikos Mavrogiannopoulos &lt;n.mavrogiannopoulos@gmail.com&gt; writes:
&gt;&gt;
&gt;&gt;&gt; We may want to install nettle somewhere separately and instruct gnutls
&gt;&gt;&gt; to use it from there rather than the default locations.
&gt;&gt;
&gt;&gt; That seems to be the right solution to the immediate problem.
&gt;
&gt; Below patch seems to work. See
&gt; https://gitlab.com/gnutls/nettle/-/jobs/495327357. Does it look right?
&gt; Some questions:
&gt;
&gt; 1. Gnutls' configure uses pkg-config to check for existence and version
&gt;     of nettle, but it doesn't use flags provided by pkg-config. We
&gt;     therefore need to set *both* PKG_CONFIG_PATH and CPPFLAGS/LDFLAGS to
&gt;     use a Nettle library in a custom location. Is it supposed to work
&gt;     that way? I would expect most things to either rely exclusively on
&gt;     pkg-config, or use other means of configuration. Except that I don't
&gt;     know if pkg-config can or should be used to supply options like
&gt;     -Wl,-rpath,...

When installed to a custom location, you have to set PKG_CONFIG_PATH
correctly. And the configure.ac code for nettle should be something like
(taken from wget2):
   PKG_CHECK_MODULES([NETTLE], nettle, [
     with_libnettle=yes
     LIBS="$NETTLE_LIBS $LIBS"
     CFLAGS="$NETTLE_CFLAGS $CFLAGS"
     AC_DEFINE([WITH_LIBNETTLE], [1], [Use libnettle])
   ], [
      with_libnettle=no
      AC_MSG_WARN(*** LIBNETTLE was not found. Fallback to libgcrypt for
hashing and checksumming.)
   ])


*BUT* I had some issues with just setting PKG_CONFIG_PATH alone on
Debian unstable a while ago. I had to adjust to something different.

This is from my current MinGW recipe:
unset CC
unset CXX

PREFIX=x86_64-w64-mingw32

export PATH="/usr/$PREFIX/bin:$PATH"
export INSTALLDIR="$PWD/$PREFIX"
export PKG_CONFIG_PATH=$INSTALLDIR/lib/pkgconfig:/usr/$PREFIX/lib/pkgconfig
export PKG_CONFIG_LIBDIR="$INSTALLDIR/lib/pkgconfig"
export PKG_CONFIG="/usr/bin/${PREFIX}-pkg-config"
export CPPFLAGS="-I$INSTALLDIR/include"
export LDFLAGS="-L$INSTALLDIR/lib"

cd nettle
bash .bootstrap
./configure --build=x86_64-pc-linux-gnu --host=$PREFIX --enable-mini-gmp
--enable-shared --disable-documentation --prefix=$INSTALLDIR
make clean
make -j$(nproc)
make install


Hope that helps a bit.

&gt; 2. What's the right way to add line breaks for the very long configure
&gt;     command in .gitlab-ci.yml?

Just breaking the line (linefeed) is enough, as long as the continuation
line doesn't start with a dash '-'. What is also ok and used in many
places is adding a '\' plus linefeed.

Regards, Tim
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200402134234</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-02 13:42:34-0400</timestampReceived><subject>Re: Failure of gnutls ci build</subject><body>

Tim Rühsen &lt;tim.ruehsen@gmx.de&gt; writes:

&gt; When installed to a custom location, you have to set PKG_CONFIG_PATH
&gt; correctly. And the configure.ac code for nettle should be something like
&gt; (taken from wget2):
&gt;   PKG_CHECK_MODULES([NETTLE], nettle, [
&gt;     with_libnettle=yes
&gt;     LIBS="$NETTLE_LIBS $LIBS"
&gt;     CFLAGS="$NETTLE_CFLAGS $CFLAGS"
&gt;     AC_DEFINE([WITH_LIBNETTLE], [1], [Use libnettle])
&gt;   ], [
&gt;      with_libnettle=no
&gt;      AC_MSG_WARN(*** LIBNETTLE was not found. Fallback to libgcrypt for
&gt; hashing and checksumming.)
&gt;   ])
&gt;
&gt;
&gt; *BUT* I had some issues with just setting PKG_CONFIG_PATH alone on
&gt; Debian unstable a while ago. I had to adjust to something different.

This is the failure I got when setting PKG_CONFIG_PATH but not CPPFLAGS:
https://gitlab.com/gnutls/nettle/-/jobs/494919451

 In file included from iov.c:26:
 ../lib/gnutls_int.h:56:10: fatal error: nettle/memxor.h: No such file or directory
    56 | #include &lt;nettle/memxor.h&gt;
       |          ^~~~~~~~~~~~~~~~~
 compilation terminated.

So either gnutls doesn't use pkg-config include flags, or there's
something wrong with nettle's .pc files. I can't investigate that right
now.

&gt;&gt; 2. What's the right way to add line breaks for the very long configure
&gt;&gt;     command in .gitlab-ci.yml?
&gt;
&gt; Just breaking the line (linefeed) is enough, as long as the continuation
&gt; line doesn't start with a dash '-'.

I see, thanks.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200403082936</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-04-03 08:29:36-0400</timestampReceived><subject>Re: Failure of gnutls ci build</subject><body>

On Tue, Mar 31, 2020 at 7:42 AM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:
&gt; 
&gt; On Mon, Mar 30, 2020 at 7:23 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt; &gt; 
&gt; &gt; I committed a change to update nettle version numbers, which implies a
&gt; &gt; new symbol version for internal symbols.
&gt; &gt; 
&gt; &gt; That seems to break the gnutls ci build,
&gt; &gt; https://gitlab.com/gnutls/nettle/-/jobs/487360242
&gt; &gt; 
&gt; &gt; The error is
&gt; &gt; 
&gt; &gt; 1217 ./bootstrap: getting translations into po/.reference for gnutls...
&gt; &gt; 1218 wget: /lib64/libhogweed.so.5: version `HOGWEED_INTERNAL_5_0' not found \
&gt; &gt; (required by /lib64/libgnutls.so.30) 1219 wget: /lib64/libnettle.so.7: version \
&gt; &gt; `NETTLE_INTERNAL_7_0' not found (required by /lib64/libgnutls.so.30) 
&gt; &gt; I don't quite understand all details. This job buils and installs
&gt; &gt; nettle, as
&gt; &gt; 
&gt; &gt; ./configure --disable-documentation --prefix=/usr --libdir=/usr/lib64 &amp;&amp;
&gt; &gt; make -j4 &amp;&amp; make install
&gt; &gt; 
&gt; &gt; replacing any previously instaled version with the same soname. So
&gt; &gt; that's a somewhat broader test than I had expected. That explains why
&gt; &gt; linking of wget is affected.
&gt; &gt; 
&gt; &gt; The more worring part is that the installed gnutls library seems to
&gt; &gt; depend on internal nettle symbols (it would have been nice if the error
&gt; &gt; message named the offending symbols). Is that intended?
&gt; &gt; 
&gt; &gt; It's not necessarily wrong, but any packaged version of gnutls built
&gt; &gt; that way *must* be marked to depend on exactly the same versions of
&gt; &gt; nettle with which it was built. And the ci rule would need to use a
&gt; &gt; different prefix and some other way to tell the gnutls build to use the
&gt; &gt; newly built nettle library instead of the system version.
&gt; &gt; 
&gt; &gt; On my own debian machine I have libgnutls.so.30, but apparently an older
&gt; &gt; version. According to
&gt; &gt; 
&gt; &gt; objdump -T /usr/lib/x86_64-linux-gnu/libgnutls.so.30
&gt; &gt; 
&gt; &gt; the version I have refers only to symbols with version NETTLE_6 and
&gt; &gt; HOGWEED_4, i.e., nettle version older than 3.5. And no mention of
&gt; &gt; NETTLE_INTERNAL or HOGWEED_INTERNAL.
&gt; 
&gt; It is not limited to Nettle.
&gt; 
&gt; Last week, /usr/lib/x86_64-linux-gnu/libgnutls.so.30 could not find a
&gt; symbol in libidn2.so I had installed into /usr/local or /opt/local.
&gt; The problem cascaded to the point I could not open a Terminal to fix
&gt; things.

My problem appeared again. I'm going to have to boot into recovery
mode, delete /usr/local, and reboot to fix it.

System libraries have no business going into my directories. I don't
mess with /bin, /usr/bin, /lib and /usr/lib. The system should stay
out of our directories.

$ sudo apt-get update
...
/usr/lib/apt/methods/http: relocation error:
/usr/lib/x86_64-linux-gnu/libgnutls.so.30: symbol
_idn2_punycode_decode version IDN2_0.0.0 not defined in file
libidn2.so.0 with link time reference
E: Method http has died unexpectedly!
E: Sub-process http returned an error code (127)
E: Method /usr/lib/apt/methods/http did not start correctly
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200414005855</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-04-14 00:58:55-0400</timestampReceived><subject>[PATCH] poly1305: make internal symbols internal</subject><body>

Make low-level poly1305 functions that were marked as "internal" in
public header file really internal. Change their prefix from nettle to
_nettle.

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 chacha-poly1305.c            |  5 +++--
 poly1305-aes.c               |  5 +++--
 poly1305-internal.c          |  5 +++--
 poly1305.h                   | 12 ------------
 x86_64/poly1305-internal.asm | 12 ++++++------
 5 files changed, 15 insertions(+), 24 deletions(-)

diff --git a/chacha-poly1305.c b/chacha-poly1305.c
index a15fef0cd742..47ca86bb360d 100644
--- a/chacha-poly1305.c
+++ b/chacha-poly1305.c
@@ -54,6 +54,7 @@
 
 #include "chacha-internal.h"
 #include "chacha-poly1305.h"
+#include "poly1305-internal.h"
 
 #include "macros.h"
 
@@ -80,7 +81,7 @@ chacha_poly1305_set_nonce (struct chacha_poly1305_ctx *ctx,
   chacha_set_nonce96 (&amp;ctx-&gt;chacha, nonce);
   /* Generate authentication key */
   _chacha_core (u.x, ctx-&gt;chacha.state, CHACHA_ROUNDS);
-  poly1305_set_key (&amp;ctx-&gt;poly1305, u.subkey);  
+  _poly1305_set_key (&amp;ctx-&gt;poly1305, u.subkey);
   /* For final poly1305 processing */
   memcpy (ctx-&gt;s.b, u.subkey + 16, 16);
   /* Increment block count */
@@ -162,6 +163,6 @@ chacha_poly1305_digest (struct chacha_poly1305_ctx *ctx,
 
   _poly1305_block (&amp;ctx-&gt;poly1305, buf, 1);
 
-  poly1305_digest (&amp;ctx-&gt;poly1305, &amp;ctx-&gt;s);
+  _poly1305_digest (&amp;ctx-&gt;poly1305, &amp;ctx-&gt;s);
   memcpy (digest, &amp;ctx-&gt;s.b, length);
 }
diff --git a/poly1305-aes.c b/poly1305-aes.c
index 1a27b1d85523..85a6d2ae138b 100644
--- a/poly1305-aes.c
+++ b/poly1305-aes.c
@@ -38,13 +38,14 @@
 #include &lt;string.h&gt;
 
 #include "poly1305.h"
+#include "poly1305-internal.h"
 #include "macros.h"
 
 void
 poly1305_aes_set_key (struct poly1305_aes_ctx *ctx, const uint8_t * key)
 {
   aes128_set_encrypt_key(&amp;ctx-&gt;aes, (key));
-  poly1305_set_key(&amp;ctx-&gt;pctx, (key+16));
+  _poly1305_set_key(&amp;ctx-&gt;pctx, (key+16));
   ctx-&gt;index = 0;
 }
 
@@ -82,7 +83,7 @@ poly1305_aes_digest (struct poly1305_aes_ctx *ctx,
     }
   aes128_encrypt(&amp;ctx-&gt;aes, POLY1305_BLOCK_SIZE, s.b, ctx-&gt;nonce);
   
-  poly1305_digest (&amp;ctx-&gt;pctx, &amp;s);
+  _poly1305_digest (&amp;ctx-&gt;pctx, &amp;s);
   memcpy (digest, s.b, length);
 
   INCREMENT (16, ctx-&gt;nonce);
diff --git a/poly1305-internal.c b/poly1305-internal.c
index 2ee16807c514..8713fcb68894 100644
--- a/poly1305-internal.c
+++ b/poly1305-internal.c
@@ -63,6 +63,7 @@
 #include &lt;string.h&gt;
 
 #include "poly1305.h"
+#include "poly1305-internal.h"
 
 #include "macros.h"
 
@@ -85,7 +86,7 @@
 #define h4 hh
 
 void
-poly1305_set_key(struct poly1305_ctx *ctx, const uint8_t key[16])
+_poly1305_set_key(struct poly1305_ctx *ctx, const uint8_t key[16])
 {
   uint32_t t0,t1,t2,t3;
 
@@ -148,7 +149,7 @@ _poly1305_block (struct poly1305_ctx *ctx, const uint8_t *m, unsigned t4)
 
 /* Adds digest to the nonce */
 void
-poly1305_digest (struct poly1305_ctx *ctx, union nettle_block16 *s)
+_poly1305_digest (struct poly1305_ctx *ctx, union nettle_block16 *s)
 {
   uint32_t b, nb;
   uint64_t f0,f1,f2,f3;
diff --git a/poly1305.h b/poly1305.h
index eadc4057fe89..e569808665aa 100644
--- a/poly1305.h
+++ b/poly1305.h
@@ -42,10 +42,6 @@ extern "C" {
 #endif
 
 /* Name mangling */
-#define poly1305_set_key nettle_poly1305_set_key
-#define poly1305_digest nettle_poly1305_digest
-#define _poly1305_block _nettle_poly1305_block
-
 #define poly1305_aes_set_key nettle_poly1305_aes_set_key
 #define poly1305_aes_set_nonce nettle_poly1305_aes_set_nonce
 #define poly1305_aes_update nettle_poly1305_aes_update
@@ -76,14 +72,6 @@ struct poly1305_ctx {
   } h;
 };
 
-/* Low-level internal interface. */
-void poly1305_set_key(struct poly1305_ctx *ctx, const uint8_t key[POLY1305_KEY_SIZE]);
-/* Extracts digest, and adds it to s, the encrypted nonce. */
-void poly1305_digest (struct poly1305_ctx *ctx, union nettle_block16 *s);
-/* Internal function. Process one block. */
-void _poly1305_block (struct poly1305_ctx *ctx, const uint8_t *m,
-		      unsigned high);
-
 /* poly1305-aes */
 
 #define POLY1305_AES_KEY_SIZE 32
diff --git a/x86_64/poly1305-internal.asm b/x86_64/poly1305-internal.asm
index 98159ad391ec..8012e49f3781 100644
--- a/x86_64/poly1305-internal.asm
+++ b/x86_64/poly1305-internal.asm
@@ -41,14 +41,14 @@ define(&lt;H0&gt;, &lt;%r9&gt;)
 define(&lt;H1&gt;, &lt;%r10&gt;)
 define(&lt;H2&gt;, &lt;%r11&gt;)
 	
-	C poly1305_set_key(struct poly1305_ctx *ctx, const uint8_t key[16])
+	C _poly1305_set_key(struct poly1305_ctx *ctx, const uint8_t key[16])
 	.text
 	C Registers:
 	C  %rdi: ctx
 	C  %rsi: key
 	C  %r8: mask
 	ALIGN(16)
-PROLOGUE(nettle_poly1305_set_key)
+PROLOGUE(_nettle_poly1305_set_key)
 	W64_ENTRY(2,0)
 	mov	$0x0ffffffc0fffffff, %r8
 	mov	(%rsi), %rax
@@ -69,7 +69,7 @@ PROLOGUE(nettle_poly1305_set_key)
 	W64_EXIT(2,0)
 	ret
 
-EPILOGUE(nettle_poly1305_set_key)
+EPILOGUE(_nettle_poly1305_set_key)
 
 C 64-bit multiplication mod 2^130 - 5
 C
@@ -142,12 +142,12 @@ PROLOGUE(_nettle_poly1305_block)
 	ret
 EPILOGUE(_nettle_poly1305_block)
 
-	C poly1305_digest (struct poly1305_ctx *ctx, uint8_t *s)
+	C _poly1305_digest (struct poly1305_ctx *ctx, uint8_t *s)
 	C Registers:
 	C   %rdi: ctx
 	C   %rsi: s
 	
-PROLOGUE(nettle_poly1305_digest)
+PROLOGUE(_nettle_poly1305_digest)
 	W64_ENTRY(2, 0)
 
 	mov	P1305_H0 (CTX), H0
@@ -182,5 +182,5 @@ define(&lt;T1&gt;, &lt;%rax&gt;)
 	mov	XREG(%rax), P1305_H2 (CTX)
 	W64_EXIT(2, 0)
 	ret
-EPILOGUE(nettle_poly1305_digest)
+EPILOGUE(_nettle_poly1305_digest)
 
-- 
2.25.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200414184546</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-14 18:45:46-0400</timestampReceived><subject>Re: [PATCH] Implement GOST VKO key derivation algorithm</subject><body>

Hi, at last I've had a closer look at this patch you posted mid
February.

dbaryshkov@gmail.com writes:

&gt; +int
&gt; +gostdsa_vko(const struct ecc_scalar *key,
&gt; +	    const struct ecc_point *pub,
&gt; +	    size_t ukm_length, const uint8_t *ukm,
&gt; +	    size_t out_length, uint8_t *out)

It would be good with some docs, and a link to the spec, either in the
manual, or at least comments in the header file. And what's the relation
between pub and key? The usual, pub = key * generator, or somethign
different?

For the interface, return value is a size, and should probably have the
size_t type. It fails (and returns zero) of out_length is too small, but
there's no good way for the caller to know what's the needed size.

I think it would make sense with either some other function get let the
application query for the appropriate size (and then one could delete
the return value), or use the awkward but common interface that calling
with a NULL out argument returns the needed output size.

&gt; +{
&gt; +  const struct ecc_curve *ecc = key-&gt;ecc;
&gt; +  unsigned bsize = (ecc_bit_size(ecc) + 7) / 8;
&gt; +  mp_size_t size = ecc-&gt;p.size;
&gt; +  mp_size_t itch = 4*size + ecc-&gt;mul_itch;
&gt; +  mp_limb_t *scratch;
&gt; +
&gt; +  if (itch &lt; 5*size + ecc-&gt;h_to_a_itch)
&gt; +      itch = 5*size + ecc-&gt;h_to_a_itch;
&gt; +
&gt; +  if (pub-&gt;ecc != ecc)
&gt; +      return 0;

I think other functions taking both a ecc_scalar and an ecc_point assert
that the correspond to the same curve.

&gt; +  if (out_length &lt; 2 * bsize) {
&gt; +      return 0;
&gt; +  }
&gt; +
&gt; +  scratch = gmp_alloc_limbs (itch);
&gt; +  mpn_set_base256_le (scratch, size, ukm, ukm_length);

If ukm_length is large, the ukm input is silently truncated (if I read
mpn_set_base256_le correctly). Is that good?

&gt; +  if (mpn_zero_p (scratch, size))
&gt; +    mpn_add_1 (scratch, scratch, size, 1);

This is a bit odd, I guess it's required by the spec? mpn_add_1 is
overkill, scratch[0] = 1 should do the same thing, right (or skip the
below ecc_mod_mul, which becomes a nop)? It's not side-channel silent,
does it need to be (i.e., is the ukm input considered secret?)

&gt; +  ecc_mod_mul (&amp;ecc-&gt;q, scratch + 3*size, key-&gt;p, scratch);
&gt; +  ecc-&gt;mul (ecc, scratch, scratch + 3*size, pub-&gt;p, scratch + 4*size);
&gt; +  ecc-&gt;h_to_a (ecc, 0, scratch + 3*size, scratch, scratch + 5*size);

This is also looks a bit strange to me, but I don't have the background.
If key represents a scalar k, and pub represents a point P = k G, where
G is the generator (that's the usual relation between private and public
key in ecc context), then we compute another point Q = u k P = u k^2 G,
where u is the number represented by the ukm input. That square (k^2)
looks a bit weird, maybe I'm misunderstanding. And if I have the math
right, then it's probably more efficient to compute k^2 using
ecc_mod_sqr and use ecc-&gt;mul_g (and then the pub input argument becomes
unused).

I also wonder if this really has to be a new primitive, or if it could
be implemented in terms of ecc_point_mul, or if we should provide an
ecc_scalar_mul wrapping ecc_mod_mul (&amp;ecc-&gt;q, ...) ?

&gt; +void
&gt; +test_main (void)
&gt; +{
&gt; +    struct streebog256_ctx ctx_256;
&gt; +    struct streebog256_ctx ctx_512;
&gt; +
&gt; +    test_vko(nettle_get_gost_gc512a(),
&gt; +	     "67b63ca4ac8d2bb32618d89296c7476dbeb9f9048496f202b1902cf2ce41dbc2f847712d960483458d4b380867f426c7ca0ff5782702dbc44ee8fc72d9ec90c9",
&gt;  +	     "51a6d54ee932d176e87591121cce5f395cb2f2f147114d95f463c8a7ed74a9fc5ecd2325a35fb6387831ea66bc3d2aa42ede35872cc75372073a71b983e12f19",
&gt;  +	     "793bde5bf72840ad22b02a363ae4772d4a52fc08ba1a20f7458a222a13bf98b53be002d1973f1e398ce46c17da6d00d9b6d0076f8284dcc42e599b4c413b8804",
&gt;  +	     SHEX("1d 80 60 3c 85 44 c7 27"),
&gt; +	     &amp;nettle_streebog256,
&gt; +	     &amp;ctx_256,
&gt; +	     SHEX("c9 a9 a7 73 20 e2 cc 55 9e d7 2d ce 6f 47 e2 19 2c ce a9 5f a6 48 67 \
&gt; 05 82 c0 54 c0 ef 36 c2 21"));

What's the source of these test vectors?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200415011035</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-04-15 01:10:35-0400</timestampReceived><subject>[PATCH] ecc-random: don't apply bitwise operation to boolean arguments</subject><body>

ecdsa_in_range applies bitwise and to int and boolean arguments, which
can result in unpredictable behaviour. Use logical and instead.

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 ecc-random.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/ecc-random.c b/ecc-random.c
index 79df511cb6b6..e80405fe46fd 100644
--- a/ecc-random.c
+++ b/ecc-random.c
@@ -60,7 +60,7 @@ ecdsa_in_range (const struct ecc_modulo *m,
 {
   /* Check if 0 &lt; x &lt; q, with data independent timing. */
   return !zero_p (m, xp)
-    &amp; (mpn_sub_n (scratch, xp, m-&gt;m, m-&gt;size) != 0);
+    &amp;&amp; (mpn_sub_n (scratch, xp, m-&gt;m, m-&gt;size) != 0);
 }
 
 void
-- 
2.25.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200406055944</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-06 05:59:44-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

"Stephen R. van den Berg" &lt;srb@cuci.nl&gt; writes:

&gt; Niels Möller wrote:
&gt;&gt;I've updated the NEWS file, and I don't think there are any easy changes
&gt;&gt;pending. Please let me know ASAP if there's anything missing in NEWS, or
&gt;&gt;if there are additional changes you think ought to be included before
&gt;&gt;release.
&gt;
&gt; I presume that the bcrypt support is intentionally left out?

Yes, I don't consider it an "easy" change. And it's not the only ongoing
improvement that's postponed to after the release.

&gt; I did not get any feedback on v3.1.

I did send a short message, just a minute or two earlier. Sorry it has
to take some time.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200406125020</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-04-06 12:50:20-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

Hello,

вс, 5 апр. 2020 г. в 23:27, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt; Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:
&gt;
&gt; &gt; GnuTLS project would like to ask you to bump libhogweed soname as a
&gt; &gt; way to enforce recompilation because of the ecc-internal.h usage.
&gt;
&gt; I guess that makes sense. It will inconvenience all other packages which
&gt; don't access internals and which could benefit from ABI compatibility
&gt; and unchanged soname, though.

Thank you.

&gt; That said, I would wish a default gnutls build did *not* use internal
&gt; functions, and had a configure option to enable use of internals, for
&gt; users and packagers who understand the consequences. That would be
&gt; analogous to the --enable-gmp-internals configure argument for MPFR.

Heh. We all would wish for a better world. I'd wish for feedback on
the patches. VKO has been sent on February, 15th. Two merge requests
on git.lysator.liu.se also do not any feedback except FUD.

&gt; &gt; Other than that it would be nice to get GOST VKO key derivation
&gt; &gt; algorithm to supplement GOST digital signatures algorithm.
&gt;
&gt; I don't want to delay the release for that. Ok?

That's fine.

--
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200406174638</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-06 17:46:38-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:

&gt; вс, 5 апр. 2020 г. в 23:27, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt;&gt; Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:
&gt;&gt;
&gt;&gt; &gt; GnuTLS project would like to ask you to bump libhogweed soname as a
&gt;&gt; &gt; way to enforce recompilation because of the ecc-internal.h usage.
&gt;&gt;
&gt;&gt; I guess that makes sense. It will inconvenience all other packages which
&gt;&gt; don't access internals and which could benefit from ABI compatibility
&gt;&gt; and unchanged soname, though.
&gt;
&gt; Thank you.

Done. And it's sufficient to bump the hogweed soname, right? I updated
the description in NEWS as follows:

	The shared library names are libnettle.so.7.1 and
	libhogweed.so.6.0. The libnettle.so library is intended to be
	fully binary compatible with nettle-3.5.

	The libhogweed.so library was also intended to be fully binary
	compatible with nettle-3.5. However, the major version and the
	soname are incremented anyway, to avoid upgrade problems with
	recent Gnutls versions that depend on Nettle internals outside
	of the advertised ABI.

Is that a fair description? I don't think there's any need to mention
any gnutls version numbers here, do you agree?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200407112944</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-04-07 11:29:44-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

пн, 6 апр. 2020 г. в 20:46, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt;
&gt; Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:
&gt;
&gt; &gt; вс, 5 апр. 2020 г. в 23:27, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt; &gt;&gt; Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:
&gt; &gt;&gt;
&gt; &gt;&gt; &gt; GnuTLS project would like to ask you to bump libhogweed soname as a
&gt; &gt;&gt; &gt; way to enforce recompilation because of the ecc-internal.h usage.
&gt; &gt;&gt;
&gt; &gt;&gt; I guess that makes sense. It will inconvenience all other packages which
&gt; &gt;&gt; don't access internals and which could benefit from ABI compatibility
&gt; &gt;&gt; and unchanged soname, though.
&gt; &gt;
&gt; &gt; Thank you.
&gt;
&gt; Done. And it's sufficient to bump the hogweed soname, right? I updated
&gt; the description in NEWS as follows:
&gt;
&gt;         The shared library names are libnettle.so.7.1 and
&gt;         libhogweed.so.6.0. The libnettle.so library is intended to be
&gt;         fully binary compatible with nettle-3.5.
&gt;
&gt;         The libhogweed.so library was also intended to be fully binary
&gt;         compatible with nettle-3.5. However, the major version and the
&gt;         soname are incremented anyway, to avoid upgrade problems with
&gt;         recent Gnutls versions that depend on Nettle internals outside
&gt;         of the advertised ABI.
&gt;
&gt; Is that a fair description? I don't think there's any need to mention
&gt; any gnutls version numbers here, do you agree?

Yes, I think it is fine. Thank you!

-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200414105310</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-04-14 10:53:10-0400</timestampReceived><subject>[PATCH v2] poly1305: make internal symbols internal</subject><body>

Make low-level poly1305 functions that were marked as "internal" in
public header file really internal. Change their prefix from nettle to
_nettle.

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 chacha-poly1305.c            |  5 +--
 poly1305-aes.c               |  5 +--
 poly1305-internal.c          |  5 +--
 poly1305-internal.h          | 66 ++++++++++++++++++++++++++++++++++++
 poly1305.h                   | 14 --------
 x86_64/poly1305-internal.asm | 12 +++----
 6 files changed, 81 insertions(+), 26 deletions(-)
 create mode 100644 poly1305-internal.h

diff --git a/chacha-poly1305.c b/chacha-poly1305.c
index a15fef0cd742..47ca86bb360d 100644
--- a/chacha-poly1305.c
+++ b/chacha-poly1305.c
@@ -54,6 +54,7 @@
 
 #include "chacha-internal.h"
 #include "chacha-poly1305.h"
+#include "poly1305-internal.h"
 
 #include "macros.h"
 
@@ -80,7 +81,7 @@ chacha_poly1305_set_nonce (struct chacha_poly1305_ctx *ctx,
   chacha_set_nonce96 (&amp;ctx-&gt;chacha, nonce);
   /* Generate authentication key */
   _chacha_core (u.x, ctx-&gt;chacha.state, CHACHA_ROUNDS);
-  poly1305_set_key (&amp;ctx-&gt;poly1305, u.subkey);  
+  _poly1305_set_key (&amp;ctx-&gt;poly1305, u.subkey);
   /* For final poly1305 processing */
   memcpy (ctx-&gt;s.b, u.subkey + 16, 16);
   /* Increment block count */
@@ -162,6 +163,6 @@ chacha_poly1305_digest (struct chacha_poly1305_ctx *ctx,
 
   _poly1305_block (&amp;ctx-&gt;poly1305, buf, 1);
 
-  poly1305_digest (&amp;ctx-&gt;poly1305, &amp;ctx-&gt;s);
+  _poly1305_digest (&amp;ctx-&gt;poly1305, &amp;ctx-&gt;s);
   memcpy (digest, &amp;ctx-&gt;s.b, length);
 }
diff --git a/poly1305-aes.c b/poly1305-aes.c
index 1a27b1d85523..85a6d2ae138b 100644
--- a/poly1305-aes.c
+++ b/poly1305-aes.c
@@ -38,13 +38,14 @@
 #include &lt;string.h&gt;
 
 #include "poly1305.h"
+#include "poly1305-internal.h"
 #include "macros.h"
 
 void
 poly1305_aes_set_key (struct poly1305_aes_ctx *ctx, const uint8_t * key)
 {
   aes128_set_encrypt_key(&amp;ctx-&gt;aes, (key));
-  poly1305_set_key(&amp;ctx-&gt;pctx, (key+16));
+  _poly1305_set_key(&amp;ctx-&gt;pctx, (key+16));
   ctx-&gt;index = 0;
 }
 
@@ -82,7 +83,7 @@ poly1305_aes_digest (struct poly1305_aes_ctx *ctx,
     }
   aes128_encrypt(&amp;ctx-&gt;aes, POLY1305_BLOCK_SIZE, s.b, ctx-&gt;nonce);
   
-  poly1305_digest (&amp;ctx-&gt;pctx, &amp;s);
+  _poly1305_digest (&amp;ctx-&gt;pctx, &amp;s);
   memcpy (digest, s.b, length);
 
   INCREMENT (16, ctx-&gt;nonce);
diff --git a/poly1305-internal.c b/poly1305-internal.c
index 2ee16807c514..8713fcb68894 100644
--- a/poly1305-internal.c
+++ b/poly1305-internal.c
@@ -63,6 +63,7 @@
 #include &lt;string.h&gt;
 
 #include "poly1305.h"
+#include "poly1305-internal.h"
 
 #include "macros.h"
 
@@ -85,7 +86,7 @@
 #define h4 hh
 
 void
-poly1305_set_key(struct poly1305_ctx *ctx, const uint8_t key[16])
+_poly1305_set_key(struct poly1305_ctx *ctx, const uint8_t key[16])
 {
   uint32_t t0,t1,t2,t3;
 
@@ -148,7 +149,7 @@ _poly1305_block (struct poly1305_ctx *ctx, const uint8_t *m, unsigned t4)
 
 /* Adds digest to the nonce */
 void
-poly1305_digest (struct poly1305_ctx *ctx, union nettle_block16 *s)
+_poly1305_digest (struct poly1305_ctx *ctx, union nettle_block16 *s)
 {
   uint32_t b, nb;
   uint64_t f0,f1,f2,f3;
diff --git a/poly1305-internal.h b/poly1305-internal.h
new file mode 100644
index 000000000000..edb80f7fa011
--- /dev/null
+++ b/poly1305-internal.h
@@ -0,0 +1,66 @@
+/* poly1305.h
+
+   Poly1305 message authentication code.
+
+   Copyright (C) 2013 Nikos Mavrogiannopoulos
+   Copyright (C) 2013, 2014 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#ifndef NETTLE_POLY1305_INTERNAL_H_INCLUDED
+#define NETTLE_POLY1305_INTERNAL_H_INCLUDED
+
+#include "aes.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/* Name mangling */
+#define _poly1305_set_key _nettle_poly1305_set_key
+#define _poly1305_digest _nettle_poly1305_digest
+#define _poly1305_block _nettle_poly1305_block
+
+/* Low level functions/macros for the poly1305 construction. */
+
+#define POLY1305_DIGEST_SIZE 16
+#define POLY1305_KEY_SIZE 16
+
+/* Low-level internal interface. */
+void _poly1305_set_key(struct poly1305_ctx *ctx, const uint8_t key[POLY1305_KEY_SIZE]);
+/* Extracts digest, and adds it to s, the encrypted nonce. */
+void _poly1305_digest (struct poly1305_ctx *ctx, union nettle_block16 *s);
+/* Internal function. Process one block. */
+void _poly1305_block (struct poly1305_ctx *ctx, const uint8_t *m,
+		      unsigned high);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* NETTLE_POLY1305_INTERNAL_H_INCLUDED */
diff --git a/poly1305.h b/poly1305.h
index eadc4057fe89..99c63c8a8288 100644
--- a/poly1305.h
+++ b/poly1305.h
@@ -42,10 +42,6 @@ extern "C" {
 #endif
 
 /* Name mangling */
-#define poly1305_set_key nettle_poly1305_set_key
-#define poly1305_digest nettle_poly1305_digest
-#define _poly1305_block _nettle_poly1305_block
-
 #define poly1305_aes_set_key nettle_poly1305_aes_set_key
 #define poly1305_aes_set_nonce nettle_poly1305_aes_set_nonce
 #define poly1305_aes_update nettle_poly1305_aes_update
@@ -53,9 +49,7 @@ extern "C" {
 
 /* Low level functions/macros for the poly1305 construction. */
 
-#define POLY1305_DIGEST_SIZE 16
 #define POLY1305_BLOCK_SIZE 16
-#define POLY1305_KEY_SIZE 16
 
 struct poly1305_ctx {
   /* Key, 128-bit value and some cached multiples. */
@@ -76,14 +70,6 @@ struct poly1305_ctx {
   } h;
 };
 
-/* Low-level internal interface. */
-void poly1305_set_key(struct poly1305_ctx *ctx, const uint8_t key[POLY1305_KEY_SIZE]);
-/* Extracts digest, and adds it to s, the encrypted nonce. */
-void poly1305_digest (struct poly1305_ctx *ctx, union nettle_block16 *s);
-/* Internal function. Process one block. */
-void _poly1305_block (struct poly1305_ctx *ctx, const uint8_t *m,
-		      unsigned high);
-
 /* poly1305-aes */
 
 #define POLY1305_AES_KEY_SIZE 32
diff --git a/x86_64/poly1305-internal.asm b/x86_64/poly1305-internal.asm
index 98159ad391ec..8012e49f3781 100644
--- a/x86_64/poly1305-internal.asm
+++ b/x86_64/poly1305-internal.asm
@@ -41,14 +41,14 @@ define(&lt;H0&gt;, &lt;%r9&gt;)
 define(&lt;H1&gt;, &lt;%r10&gt;)
 define(&lt;H2&gt;, &lt;%r11&gt;)
 	
-	C poly1305_set_key(struct poly1305_ctx *ctx, const uint8_t key[16])
+	C _poly1305_set_key(struct poly1305_ctx *ctx, const uint8_t key[16])
 	.text
 	C Registers:
 	C  %rdi: ctx
 	C  %rsi: key
 	C  %r8: mask
 	ALIGN(16)
-PROLOGUE(nettle_poly1305_set_key)
+PROLOGUE(_nettle_poly1305_set_key)
 	W64_ENTRY(2,0)
 	mov	$0x0ffffffc0fffffff, %r8
 	mov	(%rsi), %rax
@@ -69,7 +69,7 @@ PROLOGUE(nettle_poly1305_set_key)
 	W64_EXIT(2,0)
 	ret
 
-EPILOGUE(nettle_poly1305_set_key)
+EPILOGUE(_nettle_poly1305_set_key)
 
 C 64-bit multiplication mod 2^130 - 5
 C
@@ -142,12 +142,12 @@ PROLOGUE(_nettle_poly1305_block)
 	ret
 EPILOGUE(_nettle_poly1305_block)
 
-	C poly1305_digest (struct poly1305_ctx *ctx, uint8_t *s)
+	C _poly1305_digest (struct poly1305_ctx *ctx, uint8_t *s)
 	C Registers:
 	C   %rdi: ctx
 	C   %rsi: s
 	
-PROLOGUE(nettle_poly1305_digest)
+PROLOGUE(_nettle_poly1305_digest)
 	W64_ENTRY(2, 0)
 
 	mov	P1305_H0 (CTX), H0
@@ -182,5 +182,5 @@ define(&lt;T1&gt;, &lt;%rax&gt;)
 	mov	XREG(%rax), P1305_H2 (CTX)
 	W64_EXIT(2, 0)
 	ret
-EPILOGUE(nettle_poly1305_digest)
+EPILOGUE(_nettle_poly1305_digest)
 
-- 
2.25.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200410131735</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-10 13:17:35-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; I've updated the NEWS file, and I don't think there are any easy changes
&gt; pending. Please let me know ASAP if there's anything missing in NEWS, or
&gt; if there are additional changes you think ought to be included before
&gt; release.

I've created a tarball at

http://www.lysator.liu.se/~nisse/archive/nettle-3.6rc1.tar.gz
http://www.lysator.liu.se/~nisse/archive/nettle-3.6rc1.tar.gz.sig

Only recent change is the updated libhogweed soname, requested by
Dmitry. Both testing and review of the NEWS file highly appreciated.
Please report test results, both positive and negative, to the list.

I intend to run basic ./configure &amp;&amp; make &amp;&amp; make check tests on a few
of the machines available in the gcc farm and on some of the (private)
gmp test systems, and make the release next week, maybe as early as
Tuesday.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200412061618</emailId><senderName>Daiki Ueno</senderName><senderEmail>ueno@gnu.org</senderEmail><timestampReceived>2020-04-12 06:16:18-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

Hello Niels,

nisse@lysator.liu.se (Niels Möller) writes:

&gt; nisse@lysator.liu.se (Niels Möller) writes:
&gt;
&gt;&gt; I've updated the NEWS file, and I don't think there are any easy changes
&gt;&gt; pending. Please let me know ASAP if there's anything missing in NEWS, or
&gt;&gt; if there are additional changes you think ought to be included before
&gt;&gt; release.
&gt;
&gt; I've created a tarball at
&gt;
&gt; http://www.lysator.liu.se/~nisse/archive/nettle-3.6rc1.tar.gz
&gt; http://www.lysator.liu.se/~nisse/archive/nettle-3.6rc1.tar.gz.sig
&gt;
&gt; Only recent change is the updated libhogweed soname, requested by
&gt; Dmitry. Both testing and review of the NEWS file highly appreciated.
&gt; Please report test results, both positive and negative, to the list.

It builds fine on all arches running Fedora rawhide (with GCC 10):
https://koji.fedoraproject.org/koji/taskinfo?taskID=43267967

I suggest a couple of minor improvements on the NEWS entry as attached.

[Attachment #3 (text/x-patch)]

diff --git a/NEWS b/NEWS
index 0d31dbc3..46f97fb1 100644
--- a/NEWS
+++ b/NEWS
@@ -23,13 +23,13 @@ NEWS for the Nettle 3.6 release
 	  enabled via CFLAGS (gcc --fcf-protection=full). Contributed
 	  by H.J. Lu and Simo Sorce.
 
-	* A few new functions to improve support the Chacha variant
+	* A few new functions to improve support for the Chacha variant
 	  with 96-bit nonce and 32-bit block counter (the existing
 	  functions use nonce and counter of 64-bit each), and
 	  functions to set the counter. Contributed by Daiki Ueno.
 
 	* New interface, struct nettle_mac, for MAC (message
-	  authentication) algorithms. This abstraction is only for
+	  authentication code) algorithms. This abstraction is only for
 	  MACs that don't require a per-message nonce. For HMAC, the
 	  key size is fixed, and equal the digest size of the
 	  underlying hash function.
@@ -42,7 +42,7 @@ NEWS for the Nettle 3.6 release
 
 	* Fix configure check for __builtin_bswap64, the incorrect
 	  check would result in link errors on platforms missing this
-	  function. Patch contributed by by George Koehler.
+	  function. Patch contributed by George Koehler.
 
 	* All use of old-fashioned suffix rules in the Makefiles have
 	  been replaced with %-pattern rules. Nettle's use of suffix
@@ -73,7 +73,7 @@ NEWS for the Nettle 3.6 release
 	The libhogweed.so library was also intended to be fully binary
 	compatible with nettle-3.5. However, the major version and the
 	soname are incremented anyway, to avoid upgrade problems with
-	recent Gnutls versions that depend on Nettle internals outside
+	recent GnuTLS versions that depend on Nettle internals outside
 	of the advertised ABI.
 
 NEWS for the Nettle 3.5.1 release


Regards,
-- 
Daiki Ueno




[Attachment #5 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200412102858</emailId><senderName>Andreas Metzler</senderName><senderEmail>ametzler@bebt.de</senderEmail><timestampReceived>2020-04-12 10:28:58-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

On 2020-04-05 Niels Möller &lt;nisse-SamgB31n2u5IcsJQ0EH25Q@public.gmane.org&gt; wrote:
&gt; Hi,

&gt; I've updated the NEWS file, and I don't think there are any easy changes
&gt; pending. Please let me know ASAP if there's anything missing in NEWS, or
&gt; if there are additional changes you think ought to be included before
&gt; release.

Hello,

I am not totally sure but think the non-lockstep soname bump of
libhogweed and libnettle is quite painful:

According to objdump -R GnuTLS uses internal symbols of both libhogweed
and libnettle (e.g.  _nettle_mpn_set_base256_le@HOGWEED_INTERNAL_5_0 and
_nettle_write_le64@NETTLE_INTERNAL_7_0). These nettle *internal* symbols
seem to be incompatible in 3.6, at least they are versioned differently
(@NETTLE_INTERNAL_7_1).

This makes to impossible install nettle-3.6 development files
(libhogweed6/libnettle7/nettle-dev) while keeping gnutls runtime
(libgnutls30, which requires libnettle7 [not 3.6] and libhogweed5)
working. One can co-install libhogweed6 in addition to libhogweed5,
but upgrading libnettle7 to 3.6 breaks gnutls runtime due to unresolved
symbols.

Having non-working gnutls is quite a big issue, since e.g. apt depends
on it.

cu Andreas

PS: On top of this the Debian nettle *packaging* currently is broken
with respect to unsynced soname bumps of libhogweed/libnettle runtime
packages, which is a different issue, probably a bug.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200412111526</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-04-12 11:15:26-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

nettle-benchmark freezes on Android, because clang optimized away the
bench_nothing function. Attached the proposed patch.

-- 
With best wishes
Dmitry

вс, 5 апр. 2020 г., 21:03 Niels Möller &lt;nisse@lysator.liu.se&gt;:

&gt; Hi,
&gt;
&gt; I've updated the NEWS file, and I don't think there are any easy changes
&gt; pending. Please let me know ASAP if there's anything missing in NEWS, or
&gt; if there are additional changes you think ought to be included before
&gt; release.
&gt;
&gt; I intend to create a release-candidate tarball in a day or two for final
&gt; testing.
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt;
&gt; _______________________________________________
&gt; nettle-bugs mailing list
&gt; nettle-bugs@lists.lysator.liu.se
&gt; http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs
&gt;

["bench.diff" (text/plain)]

diff --git a/examples/nettle-benchmark.c b/examples/nettle-benchmark.c
index 5d0e649e..2808f70d 100644
--- a/examples/nettle-benchmark.c
+++ b/examples/nettle-benchmark.c
@@ -152,9 +152,11 @@ time_function(void (*f)(void *arg), void *arg)
   return elapsed / ncalls - overhead;
 }
 
+volatile int unused = 0;
 static void
 bench_nothing(void *arg UNUSED)
 {
+  unused = 1;
   return;
 }
 

[Attachment #4 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200412143746</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-12 14:37:46-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

Andreas Metzler &lt;ametzler@bebt.de&gt; writes:

&gt; According to objdump -R GnuTLS uses internal symbols of both libhogweed
&gt; and libnettle (e.g.  _nettle_mpn_set_base256_le@HOGWEED_INTERNAL_5_0 and
&gt; _nettle_write_le64@NETTLE_INTERNAL_7_0). These nettle *internal* symbols
&gt; seem to be incompatible in 3.6, at least they are versioned differently
&gt; (@NETTLE_INTERNAL_7_1).

Can you post a complete list of the references to internal symbols? 

&gt; Having non-working gnutls is quite a big issue, since e.g. apt depends
&gt; on it.

Indeed. What options do we have? The ones I see are

1. Simply bump the soname of libnettle too. I think that's ok in this
   case, since there are no major fixes or improvements to old features
   in this release. But I wouldn't want to make it a habit.

2. Fix GnuTLS to not refer to internal libnettle symbols. Mark the
   nettle-3.6 package including libnettle.so.7 as conflicting with the
   non-fixed GnuTLS package.

I don't know how practical option (2) is. But for the example of
nettle_write_le64, it would be a simple improvement to just include a
copy in GnuTLS if it needs it. The nettle implementation is not
particularly clever, and it's not intended to be part of the ABI. E.g,
one todo item is to replace it with a macro expanding to memcpy, on
platforms that are natively little-endian, in which case the symbol
would simply disappear from the library.

&gt; PS: On top of this the Debian nettle *packaging* currently is broken
&gt; with respect to unsynced soname bumps of libhogweed/libnettle runtime
&gt; packages, which is a different issue, probably a bug.

I think it's a bug. Independent of the current issues with GnuTLS, I
think it's reasonable to occasionally make ABI-incompatible changes to
libhogweed, without breaking the libnettle ABI at the same time. (The
opposite is also possible, but less likely to happen). In which case
only one of the sonames would be bumped. There's currently no testing of
libhogweed from nettle-X linking at runtime with a libnettle.so built
from nettle-(X+1) or nettle-(X-1). Seems a bit tricky to set up.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200412172343</emailId><senderName>Andreas Metzler</senderName><senderEmail>ametzler@bebt.de</senderEmail><timestampReceived>2020-04-12 17:23:43-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

On 2020-04-12 Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt; Andreas Metzler &lt;ametzler@bebt.de&gt; writes:

&gt;&gt; According to objdump -R GnuTLS uses internal symbols of both libhogweed
&gt;&gt; and libnettle (e.g.  _nettle_mpn_set_base256_le@HOGWEED_INTERNAL_5_0 and
&gt;&gt; _nettle_write_le64@NETTLE_INTERNAL_7_0). These nettle *internal* symbols
&gt;&gt; seem to be incompatible in 3.6, at least they are versioned differently
&gt;&gt; (@NETTLE_INTERNAL_7_1).

&gt; Can you post a complete list of the references to internal symbols?

Hello Niels,

I am attaching 

objdump -R path/to/so | grep INTERNAL

for x86_64-linux-gnu gnutls builds against nettle 3.5 and 3.6 (the
latter patched to bump nettle soname, too). I am not an expert in this
area - I think this generates the correct list.

&gt;&gt; Having non-working gnutls is quite a big issue, since e.g. apt depends
&gt;&gt; on it.

&gt; Indeed. What options do we have? The ones I see are

&gt; 1. Simply bump the soname of libnettle too. I think that's ok in this
&gt;    case, since there are no major fixes or improvements to old features
&gt;    in this release. But I wouldn't want to make it a habit.

I agree that this "less than optimal". :-(

&gt; 2. Fix GnuTLS to not refer to internal libnettle symbols. Mark the
&gt;    nettle-3.6 package including libnettle.so.7 as conflicting with the
&gt;    non-fixed GnuTLS package.

&gt; I don't know how practical option (2) is. But for the example of
&gt; nettle_write_le64, it would be a simple improvement to just include a
&gt; copy in GnuTLS if it needs it. The nettle implementation is not
&gt; particularly clever, and it's not intended to be part of the ABI. E.g,
&gt; one todo item is to replace it with a macro expanding to memcpy, on
&gt; platforms that are natively little-endian, in which case the symbol
&gt; would simply disappear from the library.

I do not know either how feasible this is but the current situation,
where GnuTLS relies on functions not part of the API, that could break
anytime *IMHO* is not feasible either. [1]

In the medium term nettle might start enforcing saner usage
by not exporting *INTERNAL* in libraries shipped in "make install"

cu Andreas

[1]
(The current trigger, changing LIBNETTLE_MINOR which in turn 
breaks the ABI could be undone, if the affected internal symbols were
compatible. But this does not solve the deeper problem.)

["libgnutls.so.30-builtnettle35-internalsymbols" (text/plain)]

00000000001d3a58 R_X86_64_64       _nettle_ecc_mod@HOGWEED_INTERNAL_5_0
00000000001d3a60 R_X86_64_64       _nettle_ecc_mod@HOGWEED_INTERNAL_5_0
00000000001d3ab0 R_X86_64_64       _nettle_ecc_mod@HOGWEED_INTERNAL_5_0
00000000001d3ab8 R_X86_64_64       _nettle_ecc_mod@HOGWEED_INTERNAL_5_0
00000000001d3b78 R_X86_64_64       _nettle_ecc_mod@HOGWEED_INTERNAL_5_0
00000000001d3b80 R_X86_64_64       _nettle_ecc_mod@HOGWEED_INTERNAL_5_0
00000000001d3bd0 R_X86_64_64       _nettle_ecc_mod@HOGWEED_INTERNAL_5_0
00000000001d3bd8 R_X86_64_64       _nettle_ecc_mod@HOGWEED_INTERNAL_5_0
00000000001d3a68 R_X86_64_64       _nettle_ecc_mod_inv@HOGWEED_INTERNAL_5_0
00000000001d3ac0 R_X86_64_64       _nettle_ecc_mod_inv@HOGWEED_INTERNAL_5_0
00000000001d3b88 R_X86_64_64       _nettle_ecc_mod_inv@HOGWEED_INTERNAL_5_0
00000000001d3be0 R_X86_64_64       _nettle_ecc_mod_inv@HOGWEED_INTERNAL_5_0
00000000001d3ae0 R_X86_64_64       _nettle_ecc_add_jjj@HOGWEED_INTERNAL_5_0
00000000001d3c00 R_X86_64_64       _nettle_ecc_add_jjj@HOGWEED_INTERNAL_5_0
00000000001d3ae8 R_X86_64_64       _nettle_ecc_mul_a@HOGWEED_INTERNAL_5_0
00000000001d3c08 R_X86_64_64       _nettle_ecc_mul_a@HOGWEED_INTERNAL_5_0
00000000001d3af0 R_X86_64_64       _nettle_ecc_mul_g@HOGWEED_INTERNAL_5_0
00000000001d3c10 R_X86_64_64       _nettle_ecc_mul_g@HOGWEED_INTERNAL_5_0
00000000001d3af8 R_X86_64_64       _nettle_ecc_j_to_a@HOGWEED_INTERNAL_5_0
00000000001d3c18 R_X86_64_64       _nettle_ecc_j_to_a@HOGWEED_INTERNAL_5_0
00000000001d4328 R_X86_64_JUMP_SLOT  _nettle_mpn_set_base256_le@HOGWEED_INTERNAL_5_0
00000000001d4668 R_X86_64_JUMP_SLOT  _nettle_write_le64@NETTLE_INTERNAL_7_0
00000000001d4698 R_X86_64_JUMP_SLOT  _nettle_write_le32@NETTLE_INTERNAL_7_0
00000000001d48f8 R_X86_64_JUMP_SLOT  _nettle_poly1305_block@NETTLE_INTERNAL_7_0
00000000001d4940 R_X86_64_JUMP_SLOT  _nettle_gmp_free_limbs@HOGWEED_INTERNAL_5_0
00000000001d4a88 R_X86_64_JUMP_SLOT  _nettle_ecc_mod_mul@HOGWEED_INTERNAL_5_0
00000000001d4d68 R_X86_64_JUMP_SLOT  _nettle_cnd_copy@HOGWEED_INTERNAL_5_0
00000000001d4e90 R_X86_64_JUMP_SLOT  _nettle_gmp_alloc_limbs@HOGWEED_INTERNAL_5_0
00000000001d5690 R_X86_64_JUMP_SLOT  _nettle_mpz_limbs_copy@HOGWEED_INTERNAL_5_0
00000000001d5958 R_X86_64_JUMP_SLOT  _nettle_ecc_mod_random@HOGWEED_INTERNAL_5_0
00000000001d5a40 R_X86_64_JUMP_SLOT  _nettle_ecc_mod_add@HOGWEED_INTERNAL_5_0
00000000001d5b40 R_X86_64_JUMP_SLOT  _nettle_mpn_get_base256_le@HOGWEED_INTERNAL_5_0

["libgnutls.so.30-builtnettle36-internalsymbols" (text/plain)]

00000000001bf310 R_X86_64_JUMP_SLOT  _nettle_gmp_alloc_limbs@HOGWEED_INTERNAL_6_0
00000000001bfb48 R_X86_64_JUMP_SLOT  _nettle_mpn_get_base256_le@HOGWEED_INTERNAL_6_0
00000000001c0450 R_X86_64_JUMP_SLOT  _nettle_gmp_free_limbs@HOGWEED_INTERNAL_6_0
00000000001c0680 R_X86_64_JUMP_SLOT  _nettle_mpn_set_base256_le@HOGWEED_INTERNAL_6_0
00000000001c0840 R_X86_64_JUMP_SLOT  _nettle_write_le32@NETTLE_INTERNAL_8_0
00000000001c0bb0 R_X86_64_JUMP_SLOT  _nettle_ecc_mod_mul@HOGWEED_INTERNAL_6_0

[Attachment #5 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200412183745</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-12 18:37:45-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

Andreas Metzler &lt;ametzler@bebt.de&gt; writes:

&gt; In the medium term nettle might start enforcing saner usage
&gt; by not exporting *INTERNAL* in libraries shipped in "make install"

They're now accessible at link-time, with intended usage being low-level
tests, and experimental code. The intention is that they should *not* be
declared in installed header files, to make accidental use unlikely.

&gt; 00000000001d4668 R_X86_64_JUMP_SLOT  _nettle_write_le64@NETTLE_INTERNAL_7_0
&gt; 00000000001d4698 R_X86_64_JUMP_SLOT  _nettle_write_le32@NETTLE_INTERNAL_7_0
&gt; 00000000001d48f8 R_X86_64_JUMP_SLOT  _nettle_poly1305_block@NETTLE_INTERNAL_7_0

These seem to be the only references to NETTLE_INTERNAL. The first two
are fairly trivial functions. I guess it would be easy to copy them into
gnutls, maybe even in a debian patch.

The last is non-trivial, and it seems it is declared in the installed
header poly1305.h (which is a mistake; other internal declarations were
moved to foo-internal.h files a while ago, and never installed). I don't
know why GnuTLS needs it; if there's a reasonable use-case, maybe it
should be documented and made public.

&gt; 00000000001d4940 R_X86_64_JUMP_SLOT  _nettle_gmp_free_limbs@HOGWEED_INTERNAL_5_0
&gt; 00000000001d4a88 R_X86_64_JUMP_SLOT  _nettle_ecc_mod_mul@HOGWEED_INTERNAL_5_0
&gt; 00000000001d4d68 R_X86_64_JUMP_SLOT  _nettle_cnd_copy@HOGWEED_INTERNAL_5_0
&gt; 00000000001d4e90 R_X86_64_JUMP_SLOT  _nettle_gmp_alloc_limbs@HOGWEED_INTERNAL_5_0
&gt; 00000000001d5690 R_X86_64_JUMP_SLOT  _nettle_mpz_limbs_copy@HOGWEED_INTERNAL_5_0
&gt; 00000000001d5958 R_X86_64_JUMP_SLOT  _nettle_ecc_mod_random@HOGWEED_INTERNAL_5_0
&gt; 00000000001d5a40 R_X86_64_JUMP_SLOT  _nettle_ecc_mod_add@HOGWEED_INTERNAL_5_0
&gt; 00000000001d5b40 R_X86_64_JUMP_SLOT  _nettle_mpn_get_base256_le@HOGWEED_INTERNAL_5_0
&gt;
&gt; 00000000001bf310 R_X86_64_JUMP_SLOT  _nettle_gmp_alloc_limbs@HOGWEED_INTERNAL_6_0
&gt; 00000000001bfb48 R_X86_64_JUMP_SLOT  _nettle_mpn_get_base256_le@HOGWEED_INTERNAL_6_0
&gt; 00000000001c0450 R_X86_64_JUMP_SLOT  _nettle_gmp_free_limbs@HOGWEED_INTERNAL_6_0
&gt; 00000000001c0680 R_X86_64_JUMP_SLOT  _nettle_mpn_set_base256_le@HOGWEED_INTERNAL_6_0
&gt; 00000000001c0bb0 R_X86_64_JUMP_SLOT  _nettle_ecc_mod_mul@HOGWEED_INTERNAL_6_0

The HOGWEED_INTERNAL references are more expected, since GnuTLS wants to
support more curves than are in Nettle, and hook into the
implementation. And not visible in this list, GnuTLS also depends on the
layout of the internal struct ecc_curve. As I've said before, I'd wish
this usage was (i) controlled by a GnuTLS ./configure argument, and (ii)
disabled by default.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200413021924</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-04-13 02:19:24-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

Hello,

вс, 12 апр. 2020 г. в 20:23, Andreas Metzler &lt;ametzler@bebt.de&gt;:
&gt;
&gt; On 2020-04-12 Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt; &gt; Andreas Metzler &lt;ametzler@bebt.de&gt; writes:
&gt;
&gt; &gt;&gt; According to objdump -R GnuTLS uses internal symbols of both libhogweed
&gt; &gt;&gt; and libnettle (e.g.  _nettle_mpn_set_base256_le@HOGWEED_INTERNAL_5_0 and
&gt; &gt;&gt; _nettle_write_le64@NETTLE_INTERNAL_7_0). These nettle *internal* symbols
&gt; &gt;&gt; seem to be incompatible in 3.6, at least they are versioned differently
&gt; &gt;&gt; (@NETTLE_INTERNAL_7_1).
&gt;
&gt; &gt; Can you post a complete list of the references to internal symbols?
&gt;
&gt; Hello Niels,
&gt;
&gt; I am attaching
&gt;
&gt; objdump -R path/to/so | grep INTERNAL
&gt;
&gt; for x86_64-linux-gnu gnutls builds against nettle 3.5 and 3.6 (the
&gt; latter patched to bump nettle soname, too). I am not an expert in this
&gt; area - I think this generates the correct list.

It looks correct to me. If nobody takes a step, I'm going to look on
this in the next few days.

&gt;
&gt; &gt;&gt; Having non-working gnutls is quite a big issue, since e.g. apt depends
&gt; &gt;&gt; on it.
&gt;
&gt; &gt; Indeed. What options do we have? The ones I see are
&gt;
&gt; &gt; 1. Simply bump the soname of libnettle too. I think that's ok in this
&gt; &gt;    case, since there are no major fixes or improvements to old features
&gt; &gt;    in this release. But I wouldn't want to make it a habit.
&gt;
&gt; I agree that this "less than optimal". :-(
&gt;
&gt; &gt; 2. Fix GnuTLS to not refer to internal libnettle symbols. Mark the
&gt; &gt;    nettle-3.6 package including libnettle.so.7 as conflicting with the
&gt; &gt;    non-fixed GnuTLS package.
&gt;
&gt; &gt; I don't know how practical option (2) is. But for the example of
&gt; &gt; nettle_write_le64, it would be a simple improvement to just include a
&gt; &gt; copy in GnuTLS if it needs it. The nettle implementation is not
&gt; &gt; particularly clever, and it's not intended to be part of the ABI. E.g,
&gt; &gt; one todo item is to replace it with a macro expanding to memcpy, on
&gt; &gt; platforms that are natively little-endian, in which case the symbol
&gt; &gt; would simply disappear from the library.
&gt;
&gt; I do not know either how feasible this is but the current situation,
&gt; where GnuTLS relies on functions not part of the API, that could break
&gt; anytime *IMHO* is not feasible either. [1]
&gt;
&gt; In the medium term nettle might start enforcing saner usage
&gt; by not exporting *INTERNAL* in libraries shipped in "make install"
&gt;
&gt; cu Andreas
&gt;
&gt; [1]
&gt; (The current trigger, changing LIBNETTLE_MINOR which in turn
&gt; breaks the ABI could be undone, if the affected internal symbols were
&gt; compatible. But this does not solve the deeper problem.)
&gt; _______________________________________________
&gt; nettle-bugs mailing list
&gt; nettle-bugs@lists.lysator.liu.se
&gt; http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs



-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200413065210</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-13 06:52:10-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:

&gt;&gt; for x86_64-linux-gnu gnutls builds against nettle 3.5 and 3.6 (the
&gt;&gt; latter patched to bump nettle soname, too). I am not an expert in this
&gt;&gt; area - I think this generates the correct list.
&gt;
&gt; It looks correct to me. If nobody takes a step, I'm going to look on
&gt; this in the next few days.

Thanks. 

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200413090053</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-04-13 09:00:53-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

Hello,

пн, 13 апр. 2020 г. в 09:52, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt;
&gt; Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:
&gt;
&gt; &gt;&gt; for x86_64-linux-gnu gnutls builds against nettle 3.5 and 3.6 (the
&gt; &gt;&gt; latter patched to bump nettle soname, too). I am not an expert in this
&gt; &gt;&gt; area - I think this generates the correct list.
&gt; &gt;
&gt; &gt; It looks correct to me. If nobody takes a step, I'm going to look on
&gt; &gt; this in the next few days.

I remember your answer about not delaying the release. Any chance of
getting VKO patch in? That would simplify things a bit.

-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200405180341</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-05 18:03:41-0400</timestampReceived><subject>Nettle-3.6 soon</subject><body>

Hi,

I've updated the NEWS file, and I don't think there are any easy changes
pending. Please let me know ASAP if there's anything missing in NEWS, or
if there are additional changes you think ought to be included before
release.

I intend to create a release-candidate tarball in a day or two for final
testing.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200405195551</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-04-05 19:55:51-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

Hi,

вс, 5 апр. 2020 г. в 21:03, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt;
&gt; Hi,
&gt;
&gt; I've updated the NEWS file, and I don't think there are any easy changes
&gt; pending. Please let me know ASAP if there's anything missing in NEWS, or
&gt; if there are additional changes you think ought to be included before
&gt; release.

GnuTLS project would like to ask you to bump libhogweed soname as a
way to enforce recompilation because of the ecc-internal.h usage.
Other than that it would be nice to get GOST VKO key derivation
algorithm to supplement GOST digital signatures algorithm.


--
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200405202711</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-05 20:27:11-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:

&gt; GnuTLS project would like to ask you to bump libhogweed soname as a
&gt; way to enforce recompilation because of the ecc-internal.h usage.

I guess that makes sense. It will inconvenience all other packages which
don't access internals and which could benefit from ABI compatibility
and unchanged soname, though.

But for this release, the changes are mainly new features and a bug fix
for cfb8_decrypt. And, e.g., no major optimizations of existing
functions. So probably fairly harmless to force recompile to be able to
use a new version.

Any other opinions?

That said, I would wish a default gnutls build did *not* use internal
functions, and had a configure option to enable use of internals, for
users and packagers who understand the consequences. That would be
analogous to the --enable-gmp-internals configure argument for MPFR.

&gt; Other than that it would be nice to get GOST VKO key derivation
&gt; algorithm to supplement GOST digital signatures algorithm.

I don't want to delay the release for that. Ok?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200406002752</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-04-06 00:27:52-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

Niels M??ller wrote:
&gt;I've updated the NEWS file, and I don't think there are any easy changes
&gt;pending. Please let me know ASAP if there's anything missing in NEWS, or
&gt;if there are additional changes you think ought to be included before
&gt;release.

I presume that the bcrypt support is intentionally left out?
Or did you just forget to include it?
I did not get any feedback on v3.1.
-- 
Stephen.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200413102428</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-13 10:24:28-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:

&gt; I remember your answer about not delaying the release.

We can wait a few days to understand the references to NETTLE_INTERNAL.
But if there's no other easy fix, I'll just bump the libnettle soname
too, which should solve the immediate problem, right? Then we can still
release this week.

&gt; Any chance of getting VKO patch in? That would simplify things a bit.

I'm not sure I understand the implications. Getting it in would let
GnuTLS drop some of the references to HOGWEED_INTERNAL, is that what you
mean with simplify, or something different? But all of them? And it
doesn't look like it would affect references to NETTLE_INTERNAL. 

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200413111051</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-04-13 11:10:51-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

On Sun, Apr 5, 2020 at 2:03 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; I've updated the NEWS file, and I don't think there are any easy changes
&gt; pending. Please let me know ASAP if there's anything missing in NEWS, or
&gt; if there are additional changes you think ought to be included before
&gt; release.
&gt;
&gt; I intend to create a release-candidate tarball in a day or two for final
&gt; testing.

nettle-3.6rc1.tar.gz tested OK on an old PowerMac with OS X 10.5 and
an Intel Mac Mini with OS X 10.12.6 with SIP.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200413113112</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-04-13 11:31:12-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

On Mon, Apr 13, 2020 at 7:10 AM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:
&gt;
&gt; On Sun, Apr 5, 2020 at 2:03 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt; &gt;
&gt; &gt; I've updated the NEWS file, and I don't think there are any easy changes
&gt; &gt; pending. Please let me know ASAP if there's anything missing in NEWS, or
&gt; &gt; if there are additional changes you think ought to be included before
&gt; &gt; release.
&gt; &gt;
&gt; &gt; I intend to create a release-candidate tarball in a day or two for final
&gt; &gt; testing.
&gt;
&gt; nettle-3.6rc1.tar.gz tested OK on an old PowerMac with OS X 10.5 and
&gt; an Intel Mac Mini with OS X 10.12.6 with SIP.

My bad... The Mac-Mini failed. I accidentally applied the nettle-3.5
patch to the nettle-3.6 RC.

Maybe you can switch to static linking for the tests and be done these
stupid path problems that have plagued Unix and Linux for decades.

PASS: gostdsa-keygen
PASS: cxx
dyld: Library not loaded: /Users/jwalton/tmp/ok_to_delete/lib/libnettle.7.dylib
  Referenced from:
/Users/jwalton/Build-Scripts/nettle-3.6rc1/testsuite/../tools/sexp-conv
  Reason: image not found
cmp: EOF on test1.out
FAIL: sexp-conv
dyld: Library not loaded: /Users/jwalton/tmp/ok_to_delete/lib/libhogweed.6.dylib
  Referenced from:
/Users/jwalton/Build-Scripts/nettle-3.6rc1/testsuite/../tools/pkcs1-conv
  Reason: image not found
./pkcs1-conv-test: line 26:  2890 Abort trap: 6           $EMULATOR
../tools/pkcs1-conv &gt; testkey.priv  &lt;&lt;EOF
-----BEGIN RSA PRIVATE KEY-----
MIICXQIBAAKBgQC3792bBgQ/mc8aYOFaLEJES/JipmLAeVgznob/Vrzvdcx+bl6L
6gTphctU9ToOLC049dZYW3DJ53owUmbQgqB0vvLTjM9lGSEw4oXLrp7x/XVo/fZM
UcRWq5H8Z0l6KANXHwcVcsjjqPBJ6WD/Is3o9rb58GU9GZcsMO2Zoh8z6wIDAQAB
AoGABP+iwRS/xs6yPyBE34N2ZY6+zomBA4QIrpZvSr8bsVI9NW5gaWL5sTLunKdx
ZXMz42li4tHRVdtRicCjhKUYIShH6J3ACKnBsCHwK6MgEyuDifxhmVt/b5xQNdOL
bckwBXCL/XwkIkSgrvgUk/cXcvDXSdf7cRX+tgEHlbGjWGkCQQDaS9Xm3ZTIJ1CO
/chlET2Cf/e5GzC79njzeg5oDyTG7qlXZudpZv5D6NatVoIDF4gfey6NKB7DNehT
ff+v9wztAkEA17TN+cuFBuZX+KT3K7J1uavGqWOypDUy/h7PINODJLzoWAWnw94H
NSu6/pXo1Q1WBMQa1jB1qxJaLpBp56iBNwJAUp6JIouSl/5pOvVKNxZDVXThaSml
VD6AoIX9ldzFapVBelb0FqxoZ4NkXM50/n6VgnS4tawNmIx6lb8GWq8CMQJBAM5S
lMofzyggX3jnYbycQFrOYYFYaWEDubi0A27koYYcYyj+j8+bqc1D/OLSxRg0X1jD
st+5DnQJY9UyMPpyhNUCQQChMjCAamJP3xC7bOoza//k7E9kvx5IZcEsQWqok5BO
PSVKy/gGBeN1Q7Rj+XoybQ/SqLpfgTYRI9UpbKmpkNuq
-----END RSA PRIVATE KEY-----
EOF

FAIL: pkcs1-conv
dyld: Library not loaded: /Users/jwalton/tmp/ok_to_delete/lib/libnettle.7.dylib
  Referenced from:
/Users/jwalton/Build-Scripts/nettle-3.6rc1/testsuite/../tools/nettle-pbkdf2
  Reason: image not found
cmp: EOF on test1.out
FAIL: nettle-pbkdf2
PASS: symbols
PASS: dlopen
=====================
3 of 107 tests failed
=====================
make[1]: *** [check] Error 1
make: *** [check] Error 2
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200413115112</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-04-13 11:51:12-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

Hello,

пн, 13 апр. 2020 г. в 13:24, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt;
&gt; Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:
&gt;
&gt; &gt; I remember your answer about not delaying the release.
&gt;
&gt; We can wait a few days to understand the references to NETTLE_INTERNAL.
&gt; But if there's no other easy fix, I'll just bump the libnettle soname
&gt; too, which should solve the immediate problem, right? Then we can still
&gt; release this week.

MR against GnuTLS will be open in a few hours.

&gt;
&gt; &gt; Any chance of getting VKO patch in? That would simplify things a bit.
&gt;
&gt; I'm not sure I understand the implications. Getting it in would let
&gt; GnuTLS drop some of the references to HOGWEED_INTERNAL, is that what you
&gt; mean with simplify, or something different? But all of them? And it
&gt; doesn't look like it would affect references to NETTLE_INTERNAL.

This would allow dropping all HOGWEED_INTERNAL dependencies for GnuTLS
compiled against new Nettle library.

-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200413120850</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-13 12:08:50-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:

&gt;&gt; We can wait a few days to understand the references to NETTLE_INTERNAL.
&gt;&gt; But if there's no other easy fix, I'll just bump the libnettle soname
&gt;&gt; too, which should solve the immediate problem, right? Then we can still
&gt;&gt; release this week.
&gt;
&gt; MR against GnuTLS will be open in a few hours.

Excellent!

&gt;&gt; I'm not sure I understand the implications. Getting it in would let
&gt;&gt; GnuTLS drop some of the references to HOGWEED_INTERNAL, is that what you
&gt;&gt; mean with simplify, or something different? But all of them? And it
&gt;&gt; doesn't look like it would affect references to NETTLE_INTERNAL.
&gt;
&gt; This would allow dropping all HOGWEED_INTERNAL dependencies for GnuTLS
&gt; compiled against new Nettle library.

Nice. My understanding was that GnuTLS also includes additional GOST
curves, and depends in the internal struct ecc_curve layout. Is that
wrong? I can have a renewed look at the patch, but my gut feeling is to
not add new features at this point.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200415214430</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-04-15 21:44:30-0400</timestampReceived><subject>Nettle backup maintainers?</subject><body>

Hi Everyone/Niels,

Forgive me for asking...

Does Nettle have backup maintainers? If so, can you name them and
provide their public keys in case something happens to Niels.

Sweden has been criticized for its handling of the coronavirus. The
country seems to be engaging in relatively risky behavior. [1]

[1] https://time.com/5817412/sweden-coronavirus/

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200416073401</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-16 07:34:01-0400</timestampReceived><subject>Re: Nettle backup maintainers?</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; Does Nettle have backup maintainers? If so, can you name them and
&gt; provide their public keys in case something happens to Niels.

I don't think the current situation warrants other preparations than the
everyday risks of accidents and sudden illness. And I'm not aware of any
practical preparations.

&gt; Sweden has been criticized for its handling of the coronavirus.

I'm aware that there's some debate, but I'm not really following that
politics. In case the list is curious, I can describe what it's like
from my perspective.

I live in the Stockholm region (roughly 2 million people). Current
numbers are 210 confirmed infections (cumulative) per 100 000
inhabitants, which is third highest in the country. Last week roughly
200 new cases per day in the region, and there's some hope we're past
the peak of that curve, but still unclear. 400 people (cumulative) in
intensive care, 700 dead (still numbers for the region, for all of
Sweden, 950 intensive care cases, 1200 dead). Official numbers here:
https://experience.arcgis.com/experience/09f821667ce64bf7be6f9f87457ed9aa.

I've been working from home since March 11, when google started to
generally close down the European offices. My partner has been working
from home almost as long; we now have one living room office and one
bedroom office. I haven't been to the city center since then, but I've
been told that traffic is like a Sunday morning all week. We've
cancelled all our planned travel. We still have local errands, maybe
twice a week. Both grocery store and hardware store are within walking
distance.

Kids go to school, and can also go to other activities and visit their
friends. Child care and schools up to roughly grade 6 are generally
open, but with fewer staff and children since anyone with the slightest
symptoms is asked to stay home. Shops are open, but calmer than usual.
Most nearby restaurants are open, but have appeared mostly empty when
I've walked past. My guess is that they're having a hard time and trying
to survive on take-away.

I take a walk outdoor almost every day, I think that's quite important
for both physical and mental health. It's spring, and a lot of people
walking or running outdoors, in particular on the paths close to the
water. The outdoor café by the water has been somewhat busy, but not
overly crowded.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200416075813</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-04-16 07:58:13-0400</timestampReceived><subject>Re: Nettle backup maintainers?</subject><body>

On Thu, Apr 16, 2020 at 3:34 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; Jeffrey Walton &lt;noloader@gmail.com&gt; writes:
&gt;
&gt; &gt; Does Nettle have backup maintainers? If so, can you name them and
&gt; &gt; provide their public keys in case something happens to Niels.
&gt;
&gt; I don't think the current situation warrants other preparations than the
&gt; everyday risks of accidents and sudden illness. And I'm not aware of any
&gt; practical preparations.

I think that's a very bad idea. It is certainly not a good risk based approach.

Consider, companies have Disaster Recovery and Business Continuity
programs that plan for events with probabilities 1/11M (airplane
crash) or 1/500,000 (bus crash).

You're claiming DR/BC is not needed for an event with a probability of
1/14 (death in Sweden) or 1/24 (death in US). Those probability are
better odds then some games at a casino.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200416104859</emailId><senderName>Tim_Rühsen</senderName><senderEmail>tim.ruehsen@gmx.de</senderEmail><timestampReceived>2020-04-16 10:48:59-0400</timestampReceived><subject>Re: Nettle backup maintainers?</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


On 16.04.20 09:58, Jeffrey Walton wrote:
&gt; On Thu, Apr 16, 2020 at 3:34 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;&gt;
&gt;&gt; Jeffrey Walton &lt;noloader@gmail.com&gt; writes:
&gt;&gt;
&gt;&gt;&gt; Does Nettle have backup maintainers? If so, can you name them and
&gt;&gt;&gt; provide their public keys in case something happens to Niels.
&gt;&gt;
&gt;&gt; I don't think the current situation warrants other preparations than the
&gt;&gt; everyday risks of accidents and sudden illness. And I'm not aware of any
&gt;&gt; practical preparations.
&gt; 
&gt; I think that's a very bad idea. It is certainly not a good risk based approach.
&gt; 
&gt; Consider, companies have Disaster Recovery and Business Continuity
&gt; programs that plan for events with probabilities 1/11M (airplane
&gt; crash) or 1/500,000 (bus crash).
&gt; 
&gt; You're claiming DR/BC is not needed for an event with a probability of
&gt; 1/14 (death in Sweden) or 1/24 (death in US). Those probability are
&gt; better odds then some games at a casino.

Jeff,

if I get you correctly, you are concerned about what happens to the
project in case Niels stops maintaining it, be it on purpose or
accidentally.

The answer is the same as for many projects with just one
driver/maintainer - *anybody* is able to jump in and take over by
forking the git repository.

If Niels has resources (docs, web pages, etc) outside a public place, he
could consider putting those into a public repository as well (his
personal choice).

That is one of the *huge* advantages of open source in comparison to
closed source (e.g. companies that you cite).

@Niels Thanks for giving insight to your living with the current
situation. Sounds like pretty much the same as here in northern Germany.

Wishing the best for everybody !

Regards, Tim


["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200416164956</emailId><senderName>Aapo Talvensaari</senderName><senderEmail>aapo.talvensaari@gmail.com</senderEmail><timestampReceived>2020-04-16 16:49:56-0400</timestampReceived><subject>Re: Nettle backup maintainers?</subject><body>

On Thu, Apr 16, 2020 at 12:44 AM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:

&gt; Sweden has been criticized for its handling of the coronavirus. The
&gt; country seems to be engaging in relatively risky behavior. [1]
&gt;

It is a way too early to make any conclusion. There is no winner strategy
here.
Basically Finland where I live uses "slow it down" approach. Sweden uses a
bit
more relaxed approach. Spain and Italy uses "slow it down" approach too with
severe limitations. While Sweden has a more relaxed way they do much better
than
Italy or Spain (perhaps because cultural difference). While their current
numbers
look worse than here in Finland, the numbers might get closer with time.
What I
see is that Sweden's strategy has gotten closer to Finland's, and
vice-versa.
Then there are countries like South Korea that use surveillance, tracing,
and strict
guarantines. The South Korea's strategy may also end up bad as they
basically
rely on vaccination that may or may not happen or takes very long as with
that
they might not gain herd immunity (if that is possible to gain). There are
other factors
too, Sweden might end up a bit more deaths than Finland (per million), but
Finland
may endup with a more severe economic disaster. Or we may endup with same
number of deaths, but here in Finland it just takes longer (and perhaps
health care
it not that overloaded). Recent numbers from Sweden already show declining
rate of
new infections. So perhaps their strategy can work. But as said, too early
to make
any conclusion about it.

I agree with Tim. If project is of any importance, as I think Nettle is,
there is no
problem in finding a new maintainer in case it is needed.


Regards
Aapo
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200416175436</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-04-16 17:54:36-0400</timestampReceived><subject>Re: Nettle backup maintainers?</subject><body>

On Thu, Apr 16, 2020 at 12:50 PM Aapo Talvensaari
&lt;aapo.talvensaari@gmail.com&gt; wrote:
&gt;
&gt; On Thu, Apr 16, 2020 at 12:44 AM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:
&gt;&gt; ...
&gt; I agree with Tim. If project is of any importance, as I think Nettle is, there is no
&gt; problem in finding a new maintainer in case it is needed.

If Niels dies then here is what happens (sorry Niels)...

Nettle at Lysator becomes stale over time and bugs won't get fixed
because no one has access to the sources. Most users will continue to
use Lysator because that is what search engines return.

I'll fork and fix OS X. Some users will use my fork.

Tim will fork and add curve448 stuff. Some users will use Tim's fork.

Now you have three different forks and the only official source is
proverbially dead. Forking has turned the Maven [in]security problem
into hundreds of additional problems.

The loader is brain dead and can't figure out which library a program
compiled/linked against. The shared objects are not interchangeable so
users get enjoy a DoS.

Planning to avoid problems like these are usually outside of a
developers forte. Folks like Management, Security Engineers and
Security Architects worry about the big picture items, like ensuring
continuity.

Peter Gutmann has a really good book that discusses topics like these,
see Engineering Security,
https://www.cs.auckland.ac.nz/~pgut001/pubs/book.pdf. Another good
book is Ross Anderson's Security Engineering,
https://www.cl.cam.ac.uk/~rja14/book.html.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200413121153</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-13 12:11:53-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; Andreas Metzler &lt;ametzler@bebt.de&gt; writes:
&gt;
&gt;&gt; PS: On top of this the Debian nettle *packaging* currently is broken
&gt;&gt; with respect to unsynced soname bumps of libhogweed/libnettle runtime
&gt;&gt; packages, which is a different issue, probably a bug.
&gt;
&gt; I think it's a bug. Independent of the current issues with GnuTLS, I
&gt; think it's reasonable to occasionally make ABI-incompatible changes to
&gt; libhogweed, without breaking the libnettle ABI at the same time. (The
&gt; opposite is also possible, but less likely to happen). In which case
&gt; only one of the sonames would be bumped. There's currently no testing of
&gt; libhogweed from nettle-X linking at runtime with a libnettle.so built
&gt; from nettle-(X+1) or nettle-(X-1). Seems a bit tricky to set up.

This made me realize that also references to NETTLE_INTERNAL symbols
from libhogweed.so would be a problem. In my closest shared build,

  objdump -R libhogweed.so |grep NETTLE_INTERNAL

returns empty, but we ought to have a testcase to verify that we don't
regress. Any such reference would imply that libhogweed must link to an
exactly matching version of libnettle.se

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200413121602</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-13 12:16:02-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; nettle-3.6rc1.tar.gz tested OK on an old PowerMac with OS X 10.5 and
&gt; an Intel Mac Mini with OS X 10.12.6 with SIP.

Thanks for testing. Regarding the remaining DYLD_LIBRARY_PATH problem
with tests on the the mac mini, I think we'll have to live with that for
now. The proper solution is likely to move setting of these enviroment
variables to the same place where $EMULATOR is expanded.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200413123220</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-04-13 12:32:20-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

пн, 13 апр. 2020 г. в 15:08, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt; &gt;&gt; I'm not sure I understand the implications. Getting it in would let
&gt; &gt;&gt; GnuTLS drop some of the references to HOGWEED_INTERNAL, is that what you
&gt; &gt;&gt; mean with simplify, or something different? But all of them? And it
&gt; &gt;&gt; doesn't look like it would affect references to NETTLE_INTERNAL.
&gt; &gt;
&gt; &gt; This would allow dropping all HOGWEED_INTERNAL dependencies for GnuTLS
&gt; &gt; compiled against new Nettle library.
&gt;
&gt; Nice. My understanding was that GnuTLS also includes additional GOST
&gt; curves, and depends in the internal struct ecc_curve layout. Is that
&gt; wrong? I can have a renewed look at the patch, but my gut feeling is to
&gt; not add new features at this point.

GnuTLS includes only those two curves that are present in Nettle.
Daiki did a great job on importing curve448 code into nettle. I'm
reusing his script to bundle ecc code necessary for GOST. Two things
remaining are gostdsa-vko (depends on ecc internals, etc) and
gostdsa-mask (uses gmp and depends only on ecc-&gt;q.m). I can rework
gostdsa-mask to remove this dependency afterwards. Thus the only
significant problem is gostdsa-vko.

--
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200413125538</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-04-13 12:55:38-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

On Mon, Apr 13, 2020 at 8:16 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; Jeffrey Walton &lt;noloader@gmail.com&gt; writes:
&gt;
&gt; &gt; nettle-3.6rc1.tar.gz tested OK on an old PowerMac with OS X 10.5 and
&gt; &gt; an Intel Mac Mini with OS X 10.12.6 with SIP.
&gt;
&gt; Thanks for testing. Regarding the remaining DYLD_LIBRARY_PATH problem
&gt; with tests on the the mac mini, I think we'll have to live with that for
&gt; now. The proper solution is likely to move setting of these enviroment
&gt; variables to the same place where $EMULATOR is expanded.

The failure will also affect some of the BSDs. I know it affects NetBSD, too.

Why live with the failure when you have a patch that fixes it at
https://github.com/noloader/Build-Scripts/blob/master/patch/nettle.patch?

dirname is Posix. It should be present just about everywhere.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200413140943</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-13 14:09:43-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; The failure will also affect some of the BSDs. I know it affects NetBSD, too.

I made a commit a while ago to always use an absolute name (based on
autoconf's abs_top_builddir). See
https://git.lysator.liu.se/nettle/nettle/-/commit/b3474802b81df6db83492adf251503d86b48299c

As far as I'm aware, that should fix BSDs and other systems disliking
relative names in LD_LIRBARY_PATH. If you can verify the rc1 tarball on
NetBSD (I only have FreeBSD nearby), that would be nice.

The remaining problem I'm aware of is the security "feature" to
sometimes discard DYLD_LIBRARY_PATH completely. My understanding is that
problem is limited to MacOS.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200413150200</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-04-13 15:02:00-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

On Mon, Apr 13, 2020 at 10:09 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; Jeffrey Walton &lt;noloader@gmail.com&gt; writes:
&gt;
&gt; &gt; The failure will also affect some of the BSDs. I know it affects NetBSD, too.
&gt;
&gt; I made a commit a while ago to always use an absolute name (based on
&gt; autoconf's abs_top_builddir). See
&gt; https://git.lysator.liu.se/nettle/nettle/-/commit/b3474802b81df6db83492adf251503d86b48299c
&gt;
&gt; As far as I'm aware, that should fix BSDs and other systems disliking
&gt; relative names in LD_LIRBARY_PATH. If you can verify the rc1 tarball on
&gt; NetBSD (I only have FreeBSD nearby), that would be nice.

I'll have to take your word for it. I upgraded to NetBSD 9, and now
iConv is broken. I can't get beyond its install recipe. A broken iConv
or Gettext means I can't build the necessary dependencies to test
Nettle.

&gt; The remaining problem I'm aware of is the security "feature" to
&gt; sometimes discard DYLD_LIBRARY_PATH completely. My understanding is that
&gt; problem is limited to MacOS.

Actually a lot of software works with SIP on OS X. Nearly all software
I use and test works as expected, which is about 120 packages. The
problem seems to be limited to Git, GMP and Nettle. I think you want
to get on the other side of the fence with all the software that works
as expected.

Is there any reason you refuse to fix things? I'd be interested in knowing it.

You are also welcomed to an account on my Mac Mini. Send over your
authorized_keys file.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200413151108</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-04-13 15:11:08-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

Hello,

вс, 12 апр. 2020 г. в 21:37, Niels Möller &lt;nisse@lysator.liu.se&gt;:

&gt; &gt; 00000000001d48f8 R_X86_64_JUMP_SLOT  _nettle_poly1305_block@NETTLE_INTERNAL_7_0
&gt;
&gt; The last is non-trivial, and it seems it is declared in the installed
&gt; header poly1305.h (which is a mistake; other internal declarations were
&gt; moved to foo-internal.h files a while ago, and never installed). I don't
&gt; know why GnuTLS needs it; if there's a reasonable use-case, maybe it
&gt; should be documented and made public.

This one is an interesting topic. GnuTLS uses _poly_1305 as a part of
chacha backport (so there should be no need to export it just for
GnuTLS). However maybe it should be exported to counterpart public
poly1305_set_key() and poly1305_digest().

Regarding the MR for GnuTLS. The code is ready. I'll submit it after
you decide upon _poly1305_block() and gostdsa vko.

-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200413165425</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-13 16:54:25-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; On Mon, Apr 13, 2020 at 10:09 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;&gt;
&gt;&gt; As far as I'm aware, that should fix BSDs and other systems disliking
&gt;&gt; relative names in LD_LIRBARY_PATH. If you can verify the rc1 tarball on
&gt;&gt; NetBSD (I only have FreeBSD nearby), that would be nice.
&gt;
&gt; I'll have to take your word for it. I upgraded to NetBSD 9, and now
&gt; iConv is broken. I can't get beyond its install recipe. A broken iConv
&gt; or Gettext means I can't build the necessary dependencies to test
&gt; Nettle.

Sounds a bit frustrating... Building the tarball shouldn't need more
than a C compiler, GNU make and m4 (if you configure with
--enable-mini-gmp, you can get reasonable test coverage without
installing the GMP library).

&gt; Actually a lot of software works with SIP on OS X. Nearly all software
&gt; I use and test works as expected, which is about 120 packages. The
&gt; problem seems to be limited to Git, GMP and Nettle. I think you want
&gt; to get on the other side of the fence with all the software that works
&gt; as expected.

As I see it, it's a problem affecting a few of Nettle's test. Once
installed, it should work fine. It might be a valid fix to just disable
those tests. 

I mean, DYLD_LIBRARY_PATH is useful mainly for developers, and it's not
unreasonable to configure the system differently on a developer machine
than on a vanilla server or desktop. On GNU/Linux, e.g, I'd recommend
developers to enable traditional core dumps and use a liberal setting
for sysctl kernel.yama.ptrace_scope.

&gt; Is there any reason you refuse to fix things?

Just that (i) it's going to take me a few hours to test and fix this
properly, and I don't want to allocate those hours before the release,
and (ii) I generally give lower priority to supporting proprietary
systems.

&gt; You are also welcomed to an account on my Mac Mini. Send over your
&gt; authorized_keys file.

Thanks for the offer, but by (ii), I don't want to spend my time working
on mac os.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200413175459</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-04-13 17:54:59-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

On Mon, Apr 13, 2020 at 12:54 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; Jeffrey Walton &lt;noloader@gmail.com&gt; writes:
&gt;
&gt; &gt; On Mon, Apr 13, 2020 at 10:09 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt; &gt;&gt;
&gt; &gt;&gt; As far as I'm aware, that should fix BSDs and other systems disliking
&gt; &gt;&gt; relative names in LD_LIRBARY_PATH. If you can verify the rc1 tarball on
&gt; &gt;&gt; NetBSD (I only have FreeBSD nearby), that would be nice.
&gt; &gt;
&gt; &gt; I'll have to take your word for it. I upgraded to NetBSD 9, and now
&gt; &gt; iConv is broken. I can't get beyond its install recipe. A broken iConv
&gt; &gt; or Gettext means I can't build the necessary dependencies to test
&gt; &gt; Nettle.
&gt;
&gt; Sounds a bit frustrating... Building the tarball shouldn't need more
&gt; than a C compiler, GNU make and m4 (if you configure with
&gt; --enable-mini-gmp, you can get reasonable test coverage without
&gt; installing the GMP library).

It is Nettle's OpenSSL dependency that is causing the trouble. OpenSSL
depends on Unistring and Unbound, and they bring in the extra gear.

&gt; &gt; Actually a lot of software works with SIP on OS X. Nearly all software
&gt; &gt; I use and test works as expected, which is about 120 packages. The
&gt; &gt; problem seems to be limited to Git, GMP and Nettle. I think you want
&gt; &gt; to get on the other side of the fence with all the software that works
&gt; &gt; as expected.
&gt;
&gt; As I see it, it's a problem affecting a few of Nettle's test. Once
&gt; installed, it should work fine. It might be a valid fix to just disable
&gt; those tests.

Then maybe you can drop the unneeded test?

It is important that folks can do a 'make &amp;&amp; make check' and have
things "just work". I know some organizations that needs stuff to
work, or it requires a management sign-off complete with change
control entries. It is an administrative nightmare.

&gt; I mean, DYLD_LIBRARY_PATH is useful mainly for developers, and it's not
&gt; unreasonable to configure the system differently on a developer machine
&gt; than on a vanilla server or desktop. On GNU/Linux, e.g, I'd recommend
&gt; developers to enable traditional core dumps and use a liberal setting
&gt; for sysctl kernel.yama.ptrace_scope.
&gt;
&gt; &gt; Is there any reason you refuse to fix things?
&gt;
&gt; Just that (i) it's going to take me a few hours to test and fix this
&gt; properly, and I don't want to allocate those hours before the release,
&gt; and (ii) I generally give lower priority to supporting proprietary
&gt; systems.

I don't think copy/paste is going to take several hours. And a good CI
pipeline should handle the testing for you. If you need hours of
testing, then that probably points to a defect in the engineering
process. The process has gaps where CI testing should occur.

Apple is mostly open sourced. You can find the source code at
opensource.apple.com. I believe that's how distros like Hackintosh
make their stuff work. They start with Apple sources and massage them.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200413183344</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-13 18:33:44-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; It is Nettle's OpenSSL dependency that is causing the trouble. OpenSSL
&gt; depends on Unistring and Unbound, and they bring in the extra gear.

That's for benchmarking only. It's supposed to be autodetected and used
only if available on the build system, but you can also run configure
with --disable-openssl to explicitly disable it.

&gt; I don't think copy/paste is going to take several hours. And a good CI
&gt; pipeline should handle the testing for you. If you need hours of
&gt; testing, then that probably points to a defect in the engineering
&gt; process. The process has gaps where CI testing should occur.

You asked "Is there any reason you refuse to fix things?" (which is kind
of provocative). I tried to answer honestly. I refuse to argue this
further.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200414220610</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-04-14 22:06:10-0400</timestampReceived><subject>Re: [PATCH] Implement GOST VKO key derivation algorithm</subject><body>

вт, 14 апр. 2020 г. в 21:45, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt; 
&gt; Hi, at last I've had a closer look at this patch you posted mid
&gt; February.
&gt; 
&gt; dbaryshkov@gmail.com writes:
&gt; 
&gt; &gt; +int
&gt; &gt; +gostdsa_vko(const struct ecc_scalar *key,
&gt; &gt; +         const struct ecc_point *pub,
&gt; &gt; +         size_t ukm_length, const uint8_t *ukm,
&gt; &gt; +         size_t out_length, uint8_t *out)
&gt; 
&gt; It would be good with some docs, and a link to the spec, either in the
&gt; manual, or at least comments in the header file. And what's the relation
&gt; between pub and key? The usual, pub = key * generator, or somethign
&gt; different?

I will rename key to priv to remove this confusion. VKO is a variant of DH:

VKO = cofactor * ukm * priv * pub;
For supported curves cofactor is always 1.

&gt; For the interface, return value is a size, and should probably have the
&gt; size_t type. It fails (and returns zero) of out_length is too small, but
&gt; there's no good way for the caller to know what's the needed size.
&gt; 
&gt; I think it would make sense with either some other function get let the
&gt; application query for the appropriate size (and then one could delete
&gt; the return value), or use the awkward but common interface that calling
&gt; with a NULL out argument returns the needed output size.

The result size is always 2 * curve size. Changing return value to be
boolean 0/1.

&gt; 
&gt; &gt; +{
&gt; &gt; +  const struct ecc_curve *ecc = key-&gt;ecc;
&gt; &gt; +  unsigned bsize = (ecc_bit_size(ecc) + 7) / 8;
&gt; &gt; +  mp_size_t size = ecc-&gt;p.size;
&gt; &gt; +  mp_size_t itch = 4*size + ecc-&gt;mul_itch;
&gt; &gt; +  mp_limb_t *scratch;
&gt; &gt; +
&gt; &gt; +  if (itch &lt; 5*size + ecc-&gt;h_to_a_itch)
&gt; &gt; +      itch = 5*size + ecc-&gt;h_to_a_itch;
&gt; &gt; +
&gt; &gt; +  if (pub-&gt;ecc != ecc)
&gt; &gt; +      return 0;
&gt; 
&gt; I think other functions taking both a ecc_scalar and an ecc_point assert
&gt; that the correspond to the same curve.
&gt; 
&gt; &gt; +  if (out_length &lt; 2 * bsize) {
&gt; &gt; +      return 0;
&gt; &gt; +  }
&gt; &gt; +
&gt; &gt; +  scratch = gmp_alloc_limbs (itch);
&gt; &gt; +  mpn_set_base256_le (scratch, size, ukm, ukm_length);
&gt; 
&gt; If ukm_length is large, the ukm input is silently truncated (if I read
&gt; mpn_set_base256_le correctly). Is that good?
&gt; 
&gt; &gt; +  if (mpn_zero_p (scratch, size))
&gt; &gt; +    mpn_add_1 (scratch, scratch, size, 1);
&gt; 
&gt; This is a bit odd, I guess it's required by the spec? mpn_add_1 is
&gt; overkill, scratch[0] = 1 should do the same thing, right (or skip the
&gt; below ecc_mod_mul, which becomes a nop)? It's not side-channel silent,
&gt; does it need to be (i.e., is the ukm input considered secret?)
&gt; 
&gt; &gt; +  ecc_mod_mul (&amp;ecc-&gt;q, scratch + 3*size, key-&gt;p, scratch);
&gt; &gt; +  ecc-&gt;mul (ecc, scratch, scratch + 3*size, pub-&gt;p, scratch + 4*size);
&gt; &gt; +  ecc-&gt;h_to_a (ecc, 0, scratch + 3*size, scratch, scratch + 5*size);
&gt; 
&gt; This is also looks a bit strange to me, but I don't have the background.
&gt; If key represents a scalar k, and pub represents a point P = k G, where
&gt; G is the generator (that's the usual relation between private and public
&gt; key in ecc context), then we compute another point Q = u k P = u k^2 G,
&gt; where u is the number represented by the ukm input. That square (k^2)
&gt; looks a bit weird, maybe I'm misunderstanding. And if I have the math
&gt; right, then it's probably more efficient to compute k^2 using
&gt; ecc_mod_sqr and use ecc-&gt;mul_g (and then the pub input argument becomes
&gt; unused).
&gt; 
&gt; I also wonder if this really has to be a new primitive, or if it could
&gt; be implemented in terms of ecc_point_mul, or if we should provide an
&gt; ecc_scalar_mul wrapping ecc_mod_mul (&amp;ecc-&gt;q, ...) ?

It can be implemented using ecc_scalar_mul and ecc_point_mul (like
GnuTLS does for ecc_shared_secret). But then cofactor will come to
play, so it is much easier to hide this behind API function.

&gt; 
&gt; &gt; +void
&gt; &gt; +test_main (void)
&gt; &gt; +{
&gt; &gt; +    struct streebog256_ctx ctx_256;
&gt; &gt; +    struct streebog256_ctx ctx_512;
&gt; &gt; +
&gt; &gt; +    test_vko(nettle_get_gost_gc512a(),
&gt; &gt; +          "67b63ca4ac8d2bb32618d89296c7476dbeb9f9048496f202b1902cf2ce41dbc2f847712d960483458d4b380867f426c7ca0ff5782702dbc44ee8fc72d9ec90c9",
&gt; &gt;  +          "51a6d54ee932d176e87591121cce5f395cb2f2f147114d95f463c8a7ed74a9fc5ecd2325a35fb6387831ea66bc3d2aa42ede35872cc75372073a71b983e12f19",
&gt; &gt;  +          "793bde5bf72840ad22b02a363ae4772d4a52fc08ba1a20f7458a222a13bf98b53be002d1973f1e398ce46c17da6d00d9b6d0076f8284dcc42e599b4c413b8804",
&gt; &gt;  +          SHEX("1d 80 60 3c 85 44 c7 27"),
&gt; &gt; +          &amp;nettle_streebog256,
&gt; &gt; +          &amp;ctx_256,
&gt; &gt; +          SHEX("c9 a9 a7 73 20 e2 cc 55 9e d7 2d ce 6f 47 e2 19 2c ce a9 5f a6 \
&gt; &gt; 48 67 05 82 c0 54 c0 ef 36 c2 21"));
&gt; 
&gt; What's the source of these test vectors?

RFC 7836, adding reference.

-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200414051918</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-14 05:19:18-0400</timestampReceived><subject>Re: [PATCH] poly1305: make internal symbols internal</subject><body>

Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:

&gt; Make low-level poly1305 functions that were marked as "internal" in
&gt; public header file really internal. Change their prefix from nettle to
&gt; _nettle.

Thanks. But it looks like the a file poly1305-internal.h is
missing in the patch?

This is a kind of ABI break, in that it removes symbols previously
exposed (even by accident) in an installed header file. But it seems we
may have to bump libnettle soname anyway, to not break existing gnutls
installs on upgrading nettle. 

IIRC, you also had a small cleanup for gosthash, which I didn't merge
for ABI reasons? 

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200401073924</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2020-04-01 07:39:24-0400</timestampReceived><subject>Re: Nettle 3.5.1 and OS X 10.12 patch</subject><body>

Hello Niels,

On Tue, Mar 31, 2020 at 08:08:35PM +0200, Niels Möller wrote:

&gt; &gt; I think a reasonable way is to add 
&gt; &gt;
&gt; &gt; abs_top_builddir = @abs_top_builddir@
&gt; &gt;
&gt; &gt; TEST_SHLIB_DIR = "${abs_top_builddir}/.lib"
&gt; &gt;
&gt; &gt; to config.make.in, and use that to set LD_LIBRARY_PATH. And possibly
&gt; &gt; only pass TEST_SHLIB_DIR to the run-tests script, and move the logic to
&gt; &gt; setup the environment.
&gt; I've pushed a change like that to the branch test-shlib-dir. Please try
&gt; it out.

The change also makes the testsuite work with uClibc in default
configuration where relative paths are not allowed in LD_LIBRARY_PATH.

I have reverted the uclibc armeb CI image to the default configuration
of not allowing relative paths in LD_LIBRARY_PATH.

I can confirm that the testsuite now fails for branch master-updates
(https://gitlab.com/michaelweiser/nettle/-/jobs/493643301) and works for
branch test-shlib-dir
(https://gitlab.com/michaelweiser/nettle/-/jobs/493645063).

BTW: Should we have a note in the code or commit message as to *why*
we're changing it? Nobody will remember in a few months time. ;)
-- 
Thanks,
Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200403100219</emailId><senderName>Tim_Rühsen</senderName><senderEmail>tim.ruehsen@gmx.de</senderEmail><timestampReceived>2020-04-03 10:02:19-0400</timestampReceived><subject>Re: Failure of gnutls ci build</subject><body>

On 4/3/20 10:29 AM, Jeffrey Walton wrote:
&gt; On Tue, Mar 31, 2020 at 7:42 AM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:
&gt; &gt; 
&gt; &gt; On Mon, Mar 30, 2020 at 7:23 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt; &gt; &gt; 
&gt; &gt; &gt; I committed a change to update nettle version numbers, which implies a
&gt; &gt; &gt; new symbol version for internal symbols.
&gt; &gt; &gt; 
&gt; &gt; &gt; That seems to break the gnutls ci build,
&gt; &gt; &gt; https://gitlab.com/gnutls/nettle/-/jobs/487360242
&gt; &gt; &gt; 
&gt; &gt; &gt; The error is
&gt; &gt; &gt; 
&gt; &gt; &gt; 1217 ./bootstrap: getting translations into po/.reference for gnutls...
&gt; &gt; &gt; 1218 wget: /lib64/libhogweed.so.5: version `HOGWEED_INTERNAL_5_0' not found \
&gt; &gt; &gt; (required by /lib64/libgnutls.so.30) 1219 wget: /lib64/libnettle.so.7: version \
&gt; &gt; &gt; `NETTLE_INTERNAL_7_0' not found (required by /lib64/libgnutls.so.30) 
&gt; &gt; &gt; I don't quite understand all details. This job buils and installs
&gt; &gt; &gt; nettle, as
&gt; &gt; &gt; 
&gt; &gt; &gt; ./configure --disable-documentation --prefix=/usr --libdir=/usr/lib64 &amp;&amp;
&gt; &gt; &gt; make -j4 &amp;&amp; make install
&gt; &gt; &gt; 
&gt; &gt; &gt; replacing any previously instaled version with the same soname. So
&gt; &gt; &gt; that's a somewhat broader test than I had expected. That explains why
&gt; &gt; &gt; linking of wget is affected.
&gt; &gt; &gt; 
&gt; &gt; &gt; The more worring part is that the installed gnutls library seems to
&gt; &gt; &gt; depend on internal nettle symbols (it would have been nice if the error
&gt; &gt; &gt; message named the offending symbols). Is that intended?
&gt; &gt; &gt; 
&gt; &gt; &gt; It's not necessarily wrong, but any packaged version of gnutls built
&gt; &gt; &gt; that way *must* be marked to depend on exactly the same versions of
&gt; &gt; &gt; nettle with which it was built. And the ci rule would need to use a
&gt; &gt; &gt; different prefix and some other way to tell the gnutls build to use the
&gt; &gt; &gt; newly built nettle library instead of the system version.
&gt; &gt; &gt; 
&gt; &gt; &gt; On my own debian machine I have libgnutls.so.30, but apparently an older
&gt; &gt; &gt; version. According to
&gt; &gt; &gt; 
&gt; &gt; &gt; objdump -T /usr/lib/x86_64-linux-gnu/libgnutls.so.30
&gt; &gt; &gt; 
&gt; &gt; &gt; the version I have refers only to symbols with version NETTLE_6 and
&gt; &gt; &gt; HOGWEED_4, i.e., nettle version older than 3.5. And no mention of
&gt; &gt; &gt; NETTLE_INTERNAL or HOGWEED_INTERNAL.
&gt; &gt; 
&gt; &gt; It is not limited to Nettle.
&gt; &gt; 
&gt; &gt; Last week, /usr/lib/x86_64-linux-gnu/libgnutls.so.30 could not find a
&gt; &gt; symbol in libidn2.so I had installed into /usr/local or /opt/local.
&gt; &gt; The problem cascaded to the point I could not open a Terminal to fix
&gt; &gt; things.
&gt; 
&gt; My problem appeared again. I'm going to have to boot into recovery
&gt; mode, delete /usr/local, and reboot to fix it.
&gt; 
&gt; System libraries have no business going into my directories. I don't
&gt; mess with /bin, /usr/bin, /lib and /usr/lib. The system should stay
&gt; out of our directories.

IMO, you have that in your hand. Check /etc/ld.so.conf.d/* for
/usr/local/lib. Prefix that file to be included as last one (or even
remove it). Execute 'ldconfig' when done.

That *should* change your library search path as wanted.

Regards, Tim
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200407200019</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-04-07 20:00:19-0400</timestampReceived><subject>Re: [PATCH] (revision 3.1) Added bcrypt() support.</subject><body>

Amos Jeffries wrote:
&gt;On 6/04/20 12:57 pm, Stephen R. van den Berg wrote:
&gt;&gt; You mean because it will cost an extra clockcycle on decode per character?
&gt;&gt; That will only be relevant for very large sequences of base64 characters.

&gt;How are you defining "large" here?

&gt;Base64 data inputs can be any size. Megabytes are not uncommon in
&gt;network messaging.

That's what I meant.

&gt;&gt; And the sequences are that large, the speed to decode becomes RAM-access
&gt;&gt; bound; in which case there will be plenty of spare CPU cycles.  This
&gt;&gt; essentially makes the extra "if" cost-free.

&gt;For this type of situation we should expect the L1/L2 cache lines to be
&gt;loaded by the time they are needed. Delays will most likely be from
&gt;interruptions to the decode thread, or less likely; code or table size
&gt;causing swapouts from the L1/L2 caches.

Ok, I stand corrected.  I just checked the RAM subsystem speeds of current
systems, and I find that 250GB/s is not uncommon.  In that case, every
extra clockcycle will hurt.  I'll retract the tablesize optimisation.
-- 
Stephen.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200414105022</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-04-14 10:50:22-0400</timestampReceived><subject>Re: [PATCH] poly1305: make internal symbols internal</subject><body>

Hello,

вт, 14 апр. 2020 г. в 08:19, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt;
&gt; Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:
&gt;
&gt; &gt; Make low-level poly1305 functions that were marked as "internal" in
&gt; &gt; public header file really internal. Change their prefix from nettle to
&gt; &gt; _nettle.
&gt;
&gt; Thanks. But it looks like the a file poly1305-internal.h is
&gt; missing in the patch?

Oh. I should not be sending patches at 4 a.m. I'll send V2 soon.

&gt;
&gt; This is a kind of ABI break, in that it removes symbols previously
&gt; exposed (even by accident) in an installed header file. But it seems we
&gt; may have to bump libnettle soname anyway, to not break existing gnutls
&gt; installs on upgrading nettle.
&gt;
&gt; IIRC, you also had a small cleanup for gosthash, which I didn't merge
&gt; for ABI reasons?

Yes, "[PATCH v2 3/6] gosthash94: switch to using MD_UPDATE() macro".
It was sent in July of 2019.

-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200414222841</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-04-14 22:28:41-0400</timestampReceived><subject>Re: [PATCH] Implement GOST VKO key derivation algorithm</subject><body>

Hello,

вт, 14 апр. 2020 г. в 21:45, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt;
&gt; Hi, at last I've had a closer look at this patch you posted mid
&gt; February.

On the second consideration this patch depends on
https://git.lysator.liu.se/nettle/nettle/-/merge_requests/6, which
also was never reviewed. So let's drop it for now. You probably won't
like so many changes for the release.

-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200415054145</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-15 05:41:45-0400</timestampReceived><subject>Re: [PATCH] ecc-random: don't apply bitwise operation to boolean arguments</subject><body>

Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:

&gt; diff --git a/ecc-random.c b/ecc-random.c
&gt; index 79df511cb6b6..e80405fe46fd 100644
&gt; --- a/ecc-random.c
&gt; +++ b/ecc-random.c
&gt; @@ -60,7 +60,7 @@ ecdsa_in_range (const struct ecc_modulo *m,
&gt;  {
&gt;    /* Check if 0 &lt; x &lt; q, with data independent timing. */
&gt;    return !zero_p (m, xp)
&gt; -    &amp; (mpn_sub_n (scratch, xp, m-&gt;m, m-&gt;size) != 0);
&gt; +    &amp;&amp; (mpn_sub_n (scratch, xp, m-&gt;m, m-&gt;size) != 0);
&gt;  }

The use of &amp; rather than the short-circuiting &amp;&amp; here is intentional.
Using &amp;&amp; would imply a data dependant branch, and we can't have that,
since this function is intended to be be side-channel silent. 

The arguments to &amp; are both 0 or 1, so the return value should be the
same as with &amp;&amp;.

I haven't looked the generated code, though. I hope the compiler inlines
zero_p and doesn't generate branches for t == 0 or for the logical
negation in !zero_p(...). And the local variable t should probably be
marked volatile. But on the other hand, maybe it doesn't matter if it's
side-channel silent in the case that it returns false. These things are
a bit more subtle than I like.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200415171300</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-04-15 17:13:00-0400</timestampReceived><subject>Re: Nettle-3.6 soon</subject><body>

пн, 13 апр. 2020 г. в 18:11, Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;:
&gt;
&gt; Hello,
&gt;
&gt; вс, 12 апр. 2020 г. в 21:37, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt;
&gt; &gt; &gt; 00000000001d48f8 R_X86_64_JUMP_SLOT  _nettle_poly1305_block@NETTLE_INTERNAL_7_0
&gt; &gt;
&gt; &gt; The last is non-trivial, and it seems it is declared in the installed
&gt; &gt; header poly1305.h (which is a mistake; other internal declarations were
&gt; &gt; moved to foo-internal.h files a while ago, and never installed). I don't
&gt; &gt; know why GnuTLS needs it; if there's a reasonable use-case, maybe it
&gt; &gt; should be documented and made public.
&gt;
&gt; This one is an interesting topic. GnuTLS uses _poly_1305 as a part of
&gt; chacha backport (so there should be no need to export it just for
&gt; GnuTLS). However maybe it should be exported to counterpart public
&gt; poly1305_set_key() and poly1305_digest().
&gt;
&gt; Regarding the MR for GnuTLS. The code is ready. I'll submit it after
&gt; you decide upon _poly1305_block() and gostdsa vko.


MR is merged.

-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200415181053</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-15 18:10:53-0400</timestampReceived><subject>Re: [PATCH v2] poly1305: make internal symbols internal</subject><body>

Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:

&gt; Make low-level poly1305 functions that were marked as "internal" in
&gt; public header file really internal. Change their prefix from nettle to
&gt; _nettle.

Merged to master-updates, with some minor fixes (poly1305-internal.h
should include poly1305.h, not aes.h). Thanks!

When merged to master, this means that we should bump the libnettle
soname too.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200418104009</emailId><senderName>Tim_Rühsen</senderName><senderEmail>tim.ruehsen@gmx.de</senderEmail><timestampReceived>2020-04-18 10:40:09-0400</timestampReceived><subject>Re: Nettle backup maintainers?</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


On 16.04.20 19:54, Jeffrey Walton wrote:
&gt; On Thu, Apr 16, 2020 at 12:50 PM Aapo Talvensaari
&gt; &lt;aapo.talvensaari@gmail.com&gt; wrote:
&gt;&gt;
&gt;&gt; On Thu, Apr 16, 2020 at 12:44 AM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:
&gt;&gt;&gt; ...
&gt;&gt; I agree with Tim. If project is of any importance, as I think Nettle is, there is no
&gt;&gt; problem in finding a new maintainer in case it is needed.
&gt; 
&gt; If Niels dies then here is what happens (sorry Niels)...
&gt; 
&gt; Nettle at Lysator becomes stale over time and bugs won't get fixed
&gt; because no one has access to the sources. Most users will continue to
&gt; use Lysator because that is what search engines return.

https://www.lysator.liu.se/foreningen/kontakt/


&gt; I'll fork and fix OS X. Some users will use my fork.
&gt; 
&gt; Tim will fork and add curve448 stuff. Some users will use Tim's fork.

Given that we have some sort of communication skill, we can publicly
talk about our plans on this mailing list and agree upon future
maintenance. I really don't see any problems as long as *at least* one
person is willing to become maintainer. Everything else is details.

Tim


["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200419150400</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-19 15:04:00-0400</timestampReceived><subject>Re: [PATCH 6/6] gosthash94: switch to using MD_UPDATE() macro</subject><body>

Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt; writes:

&gt; Signed-off-by: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;
&gt; ---
&gt;  gosthash94.c | 43 +++++++++----------------------------------
&gt;  gosthash94.h |  5 +++--
&gt;  2 files changed, 12 insertions(+), 36 deletions(-)

Merged to master-updates branch (since we're going to bump the libnettle
soname).

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200421111309</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-21 11:13:09-0400</timestampReceived><subject>Re: [PATCH v2] Implement GOST VKO key derivation algorithm</subject><body>

Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:

&gt;&gt; So the caller must compute bsize (in the same way, from ecc_bit_size),
&gt;&gt; to be able to call this function correctly. That makes the out_length
&gt;&gt; argument a bit redundant.
&gt;
&gt; I preferred to be on a safe side here, but if you wish, I can change it.
&gt; VKO is used only with Streebog (or legacy gosthash94cp) hash functions.

Please document the output size, and the valid range for ukm_length, and
delete the out_length argument.

&gt;&gt; Not quite sure what to do. If it is essential to get away from access to
&gt;&gt; internal symbols, I could merge as is.
&gt;
&gt; Let's beat it into agreeable shape if possible, so that we won't have
&gt; to change it right after the release.

I think it's good enough with above changes. I can see two approaches to
improve the interface: either add hashing (that could be a new function
gost_vko_hash or so), or add primitives to make the function not needed.
And neither way requires any changes to this gost_vko function.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200421232915</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-04-21 23:29:15-0400</timestampReceived><subject>Re: [PATCH v3] Implement GOST VKO key derivation algorithm</subject><body>

вт, 21 апр. 2020 г. в 19:42, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt;
&gt; Merged patch onto the master-updates branch.

Thank you!

-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200423193735</emailId><senderName>Eli Zaretskii</senderName><senderEmail>eliz@gnu.org</senderEmail><timestampReceived>2020-04-23 19:37:35-0400</timestampReceived><subject>Re: Windows dll test failures</subject><body>

&gt; From: nisse@lysator.liu.se (Niels Möller)
&gt; Cc: nettle-bugs@lists.lysator.liu.se
&gt; Date: Thu, 23 Apr 2020 17:10:54 +0200
&gt; 
&gt; The "ecc" variable is a local defined like
&gt; 
&gt;   const struct ecc_curve *ecc = ecc_curves[i];
&gt; 
&gt; (where ecc_curves is the array quoted below). And ecc_dup_jj is a
&gt; top-level function, declared as
&gt; 
&gt;   void
&gt;   ecc_dup_jj (const struct ecc_curve *ecc,
&gt;               mp_limb_t *r, const mp_limb_t *p,
&gt;               mp_limb_t *scratch);
&gt; 
&gt; The implementation is in the dll, so it is resolved by the dynamic
&gt; linker. I've found this stackoverflow question which also asks about
&gt; pointer equality with dlls:
&gt; https://stackoverflow.com/questions/20517589/function-pointer-values-inside-and-outside-a-dll
&gt; 
&gt; And by "symbol", I mean a name that is handled in the linking process.

Then yes, you need to use GetProcAddress to obtain the real address of
a function in a DLL.  Then you can compare that with your table of
function pointers.  When you write code that directly calls a function
whose implementation is in a DLL, you actually call through a jump
table.  You can clearly see that if you disassemble the code around
such call.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200425084850</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-25 08:48:50-0400</timestampReceived><subject>Nettle-3.6rc2</subject><body>

I've made another tarball,

http://www.lysator.liu.se/~nisse/archive/nettle-3.6rc2.tar.gz
http://www.lysator.liu.se/~nisse/archive/nettle-3.6rc1.tar.gz.sig

Changes some rc1: 

 * Sonames of *both* libnettle and libhogweed are updated.

 * Merged gost_vko. 

 * Other api/abi cleanups, affecting gosthash and poly1305.

 * Deleted the test asserts that failed when linking
   hogweed.dll in wine (and presumably on windows too).

 * Some more Makefile and test cleanups, deleted the .testrules.make
   file (replaced with %-pattern rules in the main
   testsuite/Makefile.in), deleted workaround with extra dll symlinks,
   and instead set WINEPATH.

 * NEWS edits.

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200429200547</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-29 20:05:47-0400</timestampReceived><subject>ANNOUNCE: Nettle-3.6</subject><body>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

I'm happy to announce a new release of GNU Nettle, a low-level
cryptographics library. This version includes several new features, and
a couple of bug fixes, see NEWS entries below.

The Nettle home page can be found at
https://www.lysator.liu.se/~nisse/nettle/, and the manual at
https://www.lysator.liu.se/~nisse/nettle/nettle.html.

The release can be downloaded from

  https://ftp.gnu.org/gnu/nettle/nettle-3.6.tar.gz
  ftp://ftp.gnu.org/gnu/nettle/nettle-3.6.tar.gz
  https://www.lysator.liu.se/~nisse/archive/nettle-3.6.tar.gz

Happy hacking,
/Niels Möller

NEWS for the Nettle 3.6 release

	This release adds a couple of new features, most notable being
	support for ED448 signatures.

	It is not binary compatible with earlier releases. The shared
	library names are libnettle.so.8.0 and libhogweed.so.6.0, with
	sonames nibnettle.so.8 and libhogweed.so.6. The changed
	sonames are mainly to avoid upgrade problems with recent
	GnuTLS versions, that depend on Nettle internals outside of
	the advertised ABI. But also because of the removal of
	internal poly1305 functions which were undocumented but
	declared in an installed header file, see Interface changes
	below.

	New features:

	* Support for Curve448 and ED448 signatures. Contributed by
	  Daiki Ueno.

	* Support for SHAKE256 (SHA3 variant with arbitrary output
	  size). Contributed by Daiki Ueno.

	* Support for SIV-CMAC (Synthetic Initialization Vector) mode,
	  contributed by Nikos Mavrogiannopoulos.

	* Support for CMAC64, contributed by Dmitry Baryshkov.

	* Support for the "CryptoPro" variant of the GOST hash
	  function, as gosthash94cp. Contributed by Dmitry Baryshkov.

	* Support for GOST DSA signatures, including GOST curves
	  gc256b and gc512a. Contributed by Dmitry Baryshkov.

	* Support for Intel CET in x86 and x86_64 assembly files, if
	  enabled via CFLAGS (gcc --fcf-protection=full). Contributed
	  by H.J. Lu and Simo Sorce.

	* A few new functions to improve support for the Chacha
	  variant with 96-bit nonce and 32-bit block counter (the
	  existing functions use nonce and counter of 64-bit each),
	  and functions to set the counter. Contributed by Daiki Ueno.

	* New interface, struct nettle_mac, for MAC (message
	  authentication code) algorithms. This abstraction is only
	  for MACs that don't require a per-message nonce. For HMAC,
	  the key size is fixed, and equal the digest size of the
	  underlying hash function.

	Bug fixes:

	* Fix bug in cfb8_decrypt. Previously, the IV was not updated
	  correctly in the case of input data shorter than the block
	  size. Reported by Stephan Mueller, fixed by Daiki Ueno.

	* Fix configure check for __builtin_bswap64, the incorrect
	  check would result in link errors on platforms missing this
	  function. Patch contributed by George Koehler.

	* All use of old-fashioned suffix rules in the Makefiles have
	  been replaced with %-pattern rules. Nettle's use of suffix
	  rules in earlier versions depended on undocumented GNU make
	  behavior, which is being deprecated in GNU make 4.3.

	  Building with other make programs than GNU make is untested
	  and unsupported. (Building with BSD make or Solaris make
	  used to work years ago, but has not been tested recently).

	Interface changes:

	* Declarations of internal poly1305.h functions have been
	  removed from the header file poly1305.h, to make it clear
	  that they are not part of the advertised API or ABI.

	Miscellaneous:

	* Building the public key support of nettle now requires GMP
	  version 6.1.0 or later (unless --enable-mini-gmp is used).

	* A fair amount of changes to ECC internals, with a few
	  deleted and a few new fields in the internal struct
	  ecc_curve. Files and functions have been renamed to more
	  consistently match the curve name, e.g., ecc-256.c has been
	  renamed to ecc-secp256r1.c.

	* Documentation for chacha-poly1305 updated. It is no longer
	  experimental. The implementation was updated to follow RFC
	  8439 in Nettle-3.1, but that was not documented or announced
	  at the time.

- -- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.

-----BEGIN PGP SIGNATURE-----

iQEzBAEBCAAdFiEEy0li0HDXfX/Li6Nicdjx/zaMZncFAl6p3hsACgkQcdjx/zaM
ZneC5gf7BZuz13jnIzETuRCtqwcV8BaFZOhBrDmqPxHeCVL2BVZwUxVpIVZAhqKu
ngj5i4GEQBHLg5BRJk/97gyn4YCbWfr7397tqBdUWO2VWFKaG+5QGCG3pjjxyjgm
hECNrRpSLHHVzUFi2bLCo4Ur+R2d52I1l+hI7CekTxAk1c01xhpobs0pSUDUCfco
/c8gNbbrNZc/KxUq1qtaWucxvysa4BsfnqucnhjAftMrmishFdr282gWNrnK3q9K
kHIxCL01bYIQVQmYdH0VglGtq7rYCkL870Ip21OOaL+LIHm1FMaDpXHbXi/GkGqK
Ukre//RxgMbwPMsM7eh5rp7pOAqdug==
=QvUR
-----END PGP SIGNATURE-----
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200417181547</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-04-17 18:15:47-0400</timestampReceived><subject>[PATCH v2] Implement GOST VKO key derivation algorithm</subject><body>

From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 Makefile.in                  |  2 +-
 gostdsa-vko.c                | 94 ++++++++++++++++++++++++++++++++++++
 gostdsa.h                    |  7 +++
 testsuite/.gitignore         |  1 +
 testsuite/.test-rules.make   |  3 ++
 testsuite/Makefile.in        |  2 +-
 testsuite/gostdsa-vko-test.c | 91 ++++++++++++++++++++++++++++++++++
 7 files changed, 198 insertions(+), 2 deletions(-)
 create mode 100644 gostdsa-vko.c
 create mode 100644 testsuite/gostdsa-vko-test.c

-- 
- Added internal documentation
- Dropped dependency of tests on Streebog

diff --git a/Makefile.in b/Makefile.in
index ddc304285321..29b3cfb4aafe 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -194,7 +194,7 @@ hogweed_SOURCES = sexp.c sexp-format.c \
 		  ecc-ecdsa-sign.c ecdsa-sign.c \
 		  ecc-ecdsa-verify.c ecdsa-verify.c ecdsa-keygen.c \
 		  ecc-gostdsa-sign.c gostdsa-sign.c \
-		  ecc-gostdsa-verify.c gostdsa-verify.c \
+		  ecc-gostdsa-verify.c gostdsa-verify.c gostdsa-vko.c \
 		  curve25519-mul-g.c curve25519-mul.c curve25519-eh-to-x.c \
 		  curve448-mul-g.c curve448-mul.c curve448-eh-to-x.c \
 		  eddsa-compress.c eddsa-decompress.c eddsa-expand.c \
diff --git a/gostdsa-vko.c b/gostdsa-vko.c
new file mode 100644
index 000000000000..0c027014e5ea
--- /dev/null
+++ b/gostdsa-vko.c
@@ -0,0 +1,94 @@
+/* gostdsa-vko.c
+
+   Copyright (C) 2016 Dmitry Eremin-Solenikov
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;stdlib.h&gt;
+
+#include "ecc-internal.h"
+#include "gostdsa.h"
+
+/*
+ * Shared key derivation/key agreement for GOST DSA algorithm.
+ * It is defined in RFC 4357 Section 5.2 and RFC 7836 Section 4.3.1
+ *
+ * Basically shared key is equal to hash(cofactor * ukm * priv * pub). This
+ * function does multiplication. Caller should do hashing on his own.
+ *
+ * UKM is not a secret value (consider it as a nonce).
+ *
+ * For supported GOST curves cofactor is equal to 1.
+ */
+void
+gostdsa_vko(const struct ecc_scalar *priv,
+	    const struct ecc_point *pub,
+	    size_t ukm_length, const uint8_t *ukm,
+	    size_t out_length, uint8_t *out)
+{
+  const struct ecc_curve *ecc = priv-&gt;ecc;
+  unsigned bsize = (ecc_bit_size(ecc) + 7) / 8;
+  mp_size_t size = ecc-&gt;p.size;
+  mp_size_t itch = 4*size + ecc-&gt;mul_itch;
+  mp_limb_t *scratch;
+
+  if (itch &lt; 5*size + ecc-&gt;h_to_a_itch)
+      itch = 5*size + ecc-&gt;h_to_a_itch;
+
+  assert (pub-&gt;ecc == ecc);
+  assert (priv-&gt;ecc == ecc);
+  assert (out_length == 2 * bsize);
+  assert (ukm_length &lt;= bsize);
+
+  scratch = gmp_alloc_limbs (itch);
+
+#define UKM scratch
+#define TEMP (scratch + 3*size)
+#define XYZ scratch
+#define TEMP_Y (scratch + 4*size)
+
+  mpn_set_base256_le (UKM, size, ukm, ukm_length);
+
+  /* If ukm is 0, set it to 1, otherwise the result will be allways equal to 0,
+   * no matter what private and public keys are. See RFC 4357 referencing GOST
+   * R 34.10-2001 (RFC 5832) Section 6.1 step 2. */
+  if (mpn_zero_p (UKM, size))
+    UKM[0] = 1;
+
+  ecc_mod_mul (&amp;ecc-&gt;q, TEMP, priv-&gt;p, UKM); /* TEMP = UKM * priv */
+  ecc-&gt;mul (ecc, XYZ, TEMP, pub-&gt;p, scratch + 4*size); /* XYZ = UKM * priv * pub */
+  ecc-&gt;h_to_a (ecc, 0, TEMP, XYZ, scratch + 5*size); /* TEMP = XYZ */
+  mpn_get_base256_le (out, bsize, TEMP, size);
+  mpn_get_base256_le (out+bsize, bsize, TEMP_Y, size);
+  gmp_free_limbs (scratch, itch);
+}
diff --git a/gostdsa.h b/gostdsa.h
index c92dfd1e1dd6..5ccf35a767a8 100644
--- a/gostdsa.h
+++ b/gostdsa.h
@@ -44,6 +44,7 @@ extern "C" {
 /* Name mangling */
 #define gostdsa_sign nettle_gostdsa_sign
 #define gostdsa_verify nettle_gostdsa_verify
+#define gostdsa_vko nettle_gostdsa_vko
 #define ecc_gostdsa_sign nettle_ecc_gostdsa_sign
 #define ecc_gostdsa_sign_itch nettle_ecc_gostdsa_sign_itch
 #define ecc_gostdsa_verify nettle_ecc_gostdsa_verify
@@ -68,6 +69,12 @@ gostdsa_verify (const struct ecc_point *pub,
 	        size_t length, const uint8_t *digest,
 	        const struct dsa_signature *signature);
 
+void
+gostdsa_vko(const struct ecc_scalar *key,
+	    const struct ecc_point *pub,
+	    size_t ukm_length, const uint8_t *ukm,
+	    size_t out_length, uint8_t *out);
+
 /* Low-level GOSTDSA functions. */
 mp_size_t
 ecc_gostdsa_sign_itch (const struct ecc_curve *ecc);
diff --git a/testsuite/.gitignore b/testsuite/.gitignore
index b8b36c2accc2..a2b3d52312cd 100644
--- a/testsuite/.gitignore
+++ b/testsuite/.gitignore
@@ -46,6 +46,7 @@
 /gostdsa-keygen-test
 /gostdsa-sign-test
 /gostdsa-verify-test
+/gostdsa-vko-test
 /gosthash94-test
 /hkdf-test
 /hmac-test
diff --git a/testsuite/.test-rules.make b/testsuite/.test-rules.make
index 9de8f4125079..fdcde6cb9748 100644
--- a/testsuite/.test-rules.make
+++ b/testsuite/.test-rules.make
@@ -304,6 +304,9 @@ gostdsa-verify-test$(EXEEXT): gostdsa-verify-test.$(OBJEXT)
 gostdsa-keygen-test$(EXEEXT): gostdsa-keygen-test.$(OBJEXT)
 	$(LINK) gostdsa-keygen-test.$(OBJEXT) $(TEST_OBJS) -o gostdsa-keygen-test$(EXEEXT)
 
+gostdsa-vko-test$(EXEEXT): gostdsa-vko-test.$(OBJEXT)
+	$(LINK) gostdsa-vko-test.$(OBJEXT) $(TEST_OBJS) -o gostdsa-vko-test$(EXEEXT)
+
 sha1-huge-test$(EXEEXT): sha1-huge-test.$(OBJEXT)
 	$(LINK) sha1-huge-test.$(OBJEXT) $(TEST_OBJS) -o sha1-huge-test$(EXEEXT)
 
diff --git a/testsuite/Makefile.in b/testsuite/Makefile.in
index 89b52efad9df..025f3ea18040 100644
--- a/testsuite/Makefile.in
+++ b/testsuite/Makefile.in
@@ -56,7 +56,7 @@ TS_HOGWEED_SOURCES = sexp-test.c sexp-format-test.c \
 		     eddsa-compress-test.c eddsa-sign-test.c \
 		     eddsa-verify-test.c ed25519-test.c ed448-test.c \
 		     gostdsa-sign-test.c gostdsa-verify-test.c \
-		     gostdsa-keygen-test.c
+		     gostdsa-keygen-test.c gostdsa-vko-test.c
 
 TS_SOURCES = $(TS_NETTLE_SOURCES) $(TS_HOGWEED_SOURCES)
 CXX_SOURCES = cxx-test.cxx
diff --git a/testsuite/gostdsa-vko-test.c b/testsuite/gostdsa-vko-test.c
new file mode 100644
index 000000000000..5d77f2efced5
--- /dev/null
+++ b/testsuite/gostdsa-vko-test.c
@@ -0,0 +1,91 @@
+#include "testutils.h"
+#include "gostdsa.h"
+
+static void
+test_vko (const struct ecc_curve *ecc,
+	  const char *priv,
+	  const char *x,
+	  const char *y,
+	  const struct tstring *ukm,
+	  const struct nettle_hash *hash,
+	  void * hash_ctx,
+	  const struct tstring *res)
+{
+    struct ecc_scalar ecc_key;
+    struct ecc_point ecc_pub;
+    mpz_t temp1, temp2;
+    uint8_t out[128];
+    size_t out_len = ((ecc_bit_size(ecc) + 7) / 8) * 2;
+
+    ASSERT(out_len &lt;= sizeof(out));
+
+    ecc_point_init (&amp;ecc_pub, ecc);
+    mpz_init_set_str (temp1, x, 16);
+    mpz_init_set_str (temp2, y, 16);
+    ASSERT (ecc_point_set (&amp;ecc_pub, temp1, temp2) != 0);
+
+    ecc_scalar_init (&amp;ecc_key, ecc);
+    mpz_set_str (temp1, priv, 16);
+    ASSERT (ecc_scalar_set (&amp;ecc_key, temp1) != 0);
+
+    mpz_clear (temp1);
+    mpz_clear (temp2);
+
+    gostdsa_vko (&amp;ecc_key, &amp;ecc_pub,
+		       ukm-&gt;length, ukm-&gt;data,
+		       out_len, out);
+
+    ecc_scalar_clear (&amp;ecc_key);
+    ecc_point_clear (&amp;ecc_pub);
+
+    if (hash)
+      {
+	hash-&gt;init (hash_ctx);
+	hash-&gt;update (hash_ctx, out_len, out);
+	hash-&gt;digest (hash_ctx, hash-&gt;digest_size, out);
+
+	ASSERT (hash-&gt;digest_size == res-&gt;length);
+	ASSERT (MEMEQ (res-&gt;length, out, res-&gt;data));
+      }
+    else
+      {
+	ASSERT (out_len == res-&gt;length);
+	ASSERT (MEMEQ (res-&gt;length, out, res-&gt;data));
+      }
+}
+
+void
+test_main (void)
+{
+    /* RFC 7836, App B, provides test vectors, values there are little endian.
+     *
+     * However those test vectors depend on the availability of Streebog hash
+     * functions, which is not available (yet). So these test vectors capture
+     * the VKO value just before hash function. One can verify them by
+     * calculating the Streeebog function and comparing the result with RFC
+     * 7836, App B. */
+    test_vko(nettle_get_gost_gc512a(),
+	     "67b63ca4ac8d2bb32618d89296c7476dbeb9f9048496f202b1902cf2ce41dbc2f847712d960483458d4b380867f426c7ca0ff5782702dbc44ee8fc72d9ec90c9",
 +	     "51a6d54ee932d176e87591121cce5f395cb2f2f147114d95f463c8a7ed74a9fc5ecd2325a35fb6387831ea66bc3d2aa42ede35872cc75372073a71b983e12f19",
 +	     "793bde5bf72840ad22b02a363ae4772d4a52fc08ba1a20f7458a222a13bf98b53be002d1973f1e398ce46c17da6d00d9b6d0076f8284dcc42e599b4c413b8804",
 +	     SHEX("1d 80 60 3c 85 44 c7 27"),
+	     NULL,
+	     NULL,
+	     SHEX("5fb5261b61e872f9 3efc03200f47378e f039aa89b993a274 a25dec5e5d49ed59"
+		  "84b7dfdf5970c3f7 3059a26d08f7bbc5 0830799bda18b533 499c4f00c21cff3e"
+		  "3b8e53a1ea920eb1 d7f3d08aa9e47595 4a53ac018c210b48 15451b7accc4a797"
+		  "a2b8faf3d89ee717 d07a857794b9b053 f8e0fd5456ccfcc2 2fd081c873416a3f"));
+
+    test_vko(nettle_get_gost_gc512a(),
+	     "dbd09213a592da5bbfd8ed068cccccbbfbeda4feac96b9b4908591440b0714803b9eb763ef932266d4c0181a9b73eacf9013efc65ec07c888515f1b6f759c848",
 +	     "a7c0adb12743c10c3c1beb97c8f631242f7937a1deb6bce5e664e49261baccd3f5dc56ec53b2abb90ca1eb703078ba546655a8b99f79188d2021ffaba4edb0aa",
 +	     "5adb1c63a4e4465e0bbefd897fb9016475934cfa0f8c95f992ea402d47921f46382d00481b720314b19d8c878e75d81b9763358dd304b2ed3a364e07a3134691",
 +	     SHEX("1d 80 60 3c 85 44 c7 27"),
+	     NULL,
+	     NULL,
+	     SHEX("5fb5261b61e872f9 3efc03200f47378e f039aa89b993a274 a25dec5e5d49ed59"
+		  "84b7dfdf5970c3f7 3059a26d08f7bbc5 0830799bda18b533 499c4f00c21cff3e"
+		  "3b8e53a1ea920eb1 d7f3d08aa9e47595 4a53ac018c210b48 15451b7accc4a797"
+		  "a2b8faf3d89ee717 d07a857794b9b053 f8e0fd5456ccfcc2 2fd081c873416a3f"));
+
+}
-- 
2.25.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200419141303</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-19 14:13:03-0400</timestampReceived><subject>Re: [PATCH v2] Implement GOST VKO key derivation algorithm</subject><body>

Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:

&gt; From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;

Thanks for the update and explanation.

&gt; +/*
&gt; + * Shared key derivation/key agreement for GOST DSA algorithm.
&gt; + * It is defined in RFC 4357 Section 5.2 and RFC 7836 Section 4.3.1
&gt; + *
&gt; + * Basically shared key is equal to hash(cofactor * ukm * priv * pub). This
&gt; + * function does multiplication. Caller should do hashing on his own.

So this could be implemented as a (mod q) multiplication of scalars
(there's no public api to do that) and an ecc_point_mul, at least as
long as the cofactor is 1.

For the hashing, one could consider pass in a hashing context and a
nettle_hash_update_func, instead of the {out, out_length} arguments.

&gt; +void
&gt; +gostdsa_vko(const struct ecc_scalar *priv,
&gt; +	    const struct ecc_point *pub,
&gt; +	    size_t ukm_length, const uint8_t *ukm,
&gt; +	    size_t out_length, uint8_t *out)
&gt; +{
&gt; +  const struct ecc_curve *ecc = priv-&gt;ecc;
&gt; +  unsigned bsize = (ecc_bit_size(ecc) + 7) / 8;
&gt; +  mp_size_t size = ecc-&gt;p.size;
&gt; +  mp_size_t itch = 4*size + ecc-&gt;mul_itch;
&gt; +  mp_limb_t *scratch;
&gt; +
&gt; +  if (itch &lt; 5*size + ecc-&gt;h_to_a_itch)
&gt; +      itch = 5*size + ecc-&gt;h_to_a_itch;
&gt; +
&gt; +  assert (pub-&gt;ecc == ecc);
&gt; +  assert (priv-&gt;ecc == ecc);
&gt; +  assert (out_length == 2 * bsize);
&gt; +  assert (ukm_length &lt;= bsize);

So the caller must compute bsize (in the same way, from ecc_bit_size),
to be able to call this function correctly. That makes the out_length
argument a bit redundant. 

Not quite sure what to do. If it is essential to get away from access to
internal symbols, I could merge as is.

But longer term, I think it would be better if we could add needed
primitives, e.g., mod q operations, so that applications can do things
like this themselves, using more general primitives. Like there's no
Nettle functions specifically for doing non-gost ECC DH for TLS.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200419164353</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-04-19 16:43:53-0400</timestampReceived><subject>Re: [PATCH v2] Implement GOST VKO key derivation algorithm</subject><body>

Hello,

вс, 19 апр. 2020 г. в 17:13, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt;
&gt; Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt; writes:
&gt;
&gt; &gt; From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;
&gt;
&gt; Thanks for the update and explanation.
&gt;
&gt; &gt; +/*
&gt; &gt; + * Shared key derivation/key agreement for GOST DSA algorithm.
&gt; &gt; + * It is defined in RFC 4357 Section 5.2 and RFC 7836 Section 4.3.1
&gt; &gt; + *
&gt; &gt; + * Basically shared key is equal to hash(cofactor * ukm * priv * pub). This
&gt; &gt; + * function does multiplication. Caller should do hashing on his own.
&gt;
&gt; So this could be implemented as a (mod q) multiplication of scalars
&gt; (there's no public api to do that) and an ecc_point_mul, at least as
&gt; long as the cofactor is 1.

For the two curves defined in RFC 7836 cofactor is equal to 4.
Basically to keep all these details in single place I'd prefer to have
single API rather than low level functions.

&gt; For the hashing, one could consider pass in a hashing context and a
&gt; nettle_hash_update_func, instead of the {out, out_length} arguments.

Possible change, yes.

&gt; &gt; +void
&gt; &gt; +gostdsa_vko(const struct ecc_scalar *priv,
&gt; &gt; +         const struct ecc_point *pub,
&gt; &gt; +         size_t ukm_length, const uint8_t *ukm,
&gt; &gt; +         size_t out_length, uint8_t *out)
&gt; &gt; +{
&gt; &gt; +  const struct ecc_curve *ecc = priv-&gt;ecc;
&gt; &gt; +  unsigned bsize = (ecc_bit_size(ecc) + 7) / 8;
&gt; &gt; +  mp_size_t size = ecc-&gt;p.size;
&gt; &gt; +  mp_size_t itch = 4*size + ecc-&gt;mul_itch;
&gt; &gt; +  mp_limb_t *scratch;
&gt; &gt; +
&gt; &gt; +  if (itch &lt; 5*size + ecc-&gt;h_to_a_itch)
&gt; &gt; +      itch = 5*size + ecc-&gt;h_to_a_itch;
&gt; &gt; +
&gt; &gt; +  assert (pub-&gt;ecc == ecc);
&gt; &gt; +  assert (priv-&gt;ecc == ecc);
&gt; &gt; +  assert (out_length == 2 * bsize);
&gt; &gt; +  assert (ukm_length &lt;= bsize);
&gt;
&gt; So the caller must compute bsize (in the same way, from ecc_bit_size),
&gt; to be able to call this function correctly. That makes the out_length
&gt; argument a bit redundant.

I preferred to be on a safe side here, but if you wish, I can change it.
VKO is used only with Streebog (or legacy gosthash94cp) hash functions.

&gt; Not quite sure what to do. If it is essential to get away from access to
&gt; internal symbols, I could merge as is.

Let's beat it into agreeable shape if possible, so that we won't have
to change it right after the release.

&gt; But longer term, I think it would be better if we could add needed
&gt; primitives, e.g., mod q operations, so that applications can do things
&gt; like this themselves, using more general primitives. Like there's no
&gt; Nettle functions specifically for doing non-gost ECC DH for TLS.

For ECC DH it is quite simple: ecc_point_mul. For GOST VKO there are
too many details (in my opinion).
-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200421115048</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-04-21 11:50:48-0400</timestampReceived><subject>[PATCH v3] Implement GOST VKO key derivation algorithm</subject><body>

From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 Makefile.in                  |  2 +-
 gostdsa-vko.c                | 96 ++++++++++++++++++++++++++++++++++++
 gostdsa.h                    |  7 +++
 nettle.texinfo               | 15 ++++++
 testsuite/.gitignore         |  1 +
 testsuite/.test-rules.make   |  3 ++
 testsuite/Makefile.in        |  2 +-
 testsuite/gostdsa-vko-test.c | 91 ++++++++++++++++++++++++++++++++++
 8 files changed, 215 insertions(+), 2 deletions(-)
 create mode 100644 gostdsa-vko.c
 create mode 100644 testsuite/gostdsa-vko-test.c

diff --git a/Makefile.in b/Makefile.in
index ddc304285321..29b3cfb4aafe 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -194,7 +194,7 @@ hogweed_SOURCES = sexp.c sexp-format.c \
 		  ecc-ecdsa-sign.c ecdsa-sign.c \
 		  ecc-ecdsa-verify.c ecdsa-verify.c ecdsa-keygen.c \
 		  ecc-gostdsa-sign.c gostdsa-sign.c \
-		  ecc-gostdsa-verify.c gostdsa-verify.c \
+		  ecc-gostdsa-verify.c gostdsa-verify.c gostdsa-vko.c \
 		  curve25519-mul-g.c curve25519-mul.c curve25519-eh-to-x.c \
 		  curve448-mul-g.c curve448-mul.c curve448-eh-to-x.c \
 		  eddsa-compress.c eddsa-decompress.c eddsa-expand.c \
diff --git a/gostdsa-vko.c b/gostdsa-vko.c
new file mode 100644
index 000000000000..7bdcdfc3fa16
--- /dev/null
+++ b/gostdsa-vko.c
@@ -0,0 +1,96 @@
+/* gostdsa-vko.c
+
+   Copyright (C) 2016 Dmitry Eremin-Solenikov
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;stdlib.h&gt;
+
+#include "ecc-internal.h"
+#include "gostdsa.h"
+
+/*
+ * Shared key derivation/key agreement for GOST DSA algorithm.
+ * It is defined in RFC 4357 Section 5.2 and RFC 7836 Section 4.3.1
+ *
+ * output is 2 * curve size:
+ * 64 bytes for 256 bit curves and 128 bytes for 512 bit ones
+ *
+ * Basically shared key is equal to hash(cofactor * ukm * priv * pub). This
+ * function does multiplication. Caller should do hashing on his own.
+ *
+ * UKM is not a secret value (consider it as a nonce).
+ *
+ * For supported GOST curves cofactor is equal to 1.
+ */
+void
+gostdsa_vko (const struct ecc_scalar *priv,
+		const struct ecc_point *pub,
+		size_t ukm_length, const uint8_t *ukm,
+		uint8_t *out)
+{
+  const struct ecc_curve *ecc = priv-&gt;ecc;
+  unsigned bsize = (ecc_bit_size (ecc) + 7) / 8;
+  mp_size_t size = ecc-&gt;p.size;
+  mp_size_t itch = 4*size + ecc-&gt;mul_itch;
+  mp_limb_t *scratch;
+
+  if (itch &lt; 5*size + ecc-&gt;h_to_a_itch)
+      itch = 5*size + ecc-&gt;h_to_a_itch;
+
+  assert (pub-&gt;ecc == ecc);
+  assert (priv-&gt;ecc == ecc);
+  assert (ukm_length &lt;= bsize);
+
+  scratch = gmp_alloc_limbs (itch);
+
+#define UKM scratch
+#define TEMP (scratch + 3*size)
+#define XYZ scratch
+#define TEMP_Y (scratch + 4*size)
+
+  mpn_set_base256_le (UKM, size, ukm, ukm_length);
+
+  /* If ukm is 0, set it to 1, otherwise the result will be allways equal to 0,
+   * no matter what private and public keys are. See RFC 4357 referencing GOST
+   * R 34.10-2001 (RFC 5832) Section 6.1 step 2. */
+  if (mpn_zero_p (UKM, size))
+    UKM[0] = 1;
+
+  ecc_mod_mul (&amp;ecc-&gt;q, TEMP, priv-&gt;p, UKM); /* TEMP = UKM * priv */
+  ecc-&gt;mul (ecc, XYZ, TEMP, pub-&gt;p, scratch + 4*size); /* XYZ = UKM * priv * pub */
+  ecc-&gt;h_to_a (ecc, 0, TEMP, XYZ, scratch + 5*size); /* TEMP = XYZ */
+  mpn_get_base256_le (out, bsize, TEMP, size);
+  mpn_get_base256_le (out+bsize, bsize, TEMP_Y, size);
+  gmp_free_limbs (scratch, itch);
+}
diff --git a/gostdsa.h b/gostdsa.h
index c92dfd1e1dd6..d479201e3295 100644
--- a/gostdsa.h
+++ b/gostdsa.h
@@ -44,6 +44,7 @@ extern "C" {
 /* Name mangling */
 #define gostdsa_sign nettle_gostdsa_sign
 #define gostdsa_verify nettle_gostdsa_verify
+#define gostdsa_vko nettle_gostdsa_vko
 #define ecc_gostdsa_sign nettle_ecc_gostdsa_sign
 #define ecc_gostdsa_sign_itch nettle_ecc_gostdsa_sign_itch
 #define ecc_gostdsa_verify nettle_ecc_gostdsa_verify
@@ -68,6 +69,12 @@ gostdsa_verify (const struct ecc_point *pub,
 	        size_t length, const uint8_t *digest,
 	        const struct dsa_signature *signature);
 
+void
+gostdsa_vko (const struct ecc_scalar *key,
+	     const struct ecc_point *pub,
+	     size_t ukm_length, const uint8_t *ukm,
+	     uint8_t *out);
+
 /* Low-level GOSTDSA functions. */
 mp_size_t
 ecc_gostdsa_sign_itch (const struct ecc_curve *ecc);
diff --git a/nettle.texinfo b/nettle.texinfo
index ff64889c4169..995d5de80813 100644
--- a/nettle.texinfo
+++ b/nettle.texinfo
@@ -1065,6 +1065,7 @@ This function also resets the context in the same way as
 @subsubsection @acronym{GOSTHASH94 and GOSTHASH94CP}
 @cindex GOST hash
 
+@anchor{GOSTHASH94CP}
 The GOST94 or GOST R 34.11-94 hash algorithm is a Soviet-era algorithm 
 used in Russian government standards (see @cite{RFC 4357}).
 It outputs message digests of 256 bits, or 32 octets. The standard itself
@@ -5157,6 +5158,20 @@ Returns curve corresponding to following identifiers:
 @end itemize
 @end deftypefun
 
+For GOST key pairs key derivation/key agreement function (VKO) is defined in
+@cite{RFC 4357} and @cite{RFC 7836}.  Basically shared key is equal to
+hash(cofactor * ukm * priv * pub). Nettle library provides a function that does
+multiplication. Caller should do hashing on his own (it will be either
+GOST R 34.11-94 (@pxref{GOSTHASH94CP}) or GOST R 34.11-2012, Streebog, which nor \
part of the library yet). +
+@deftypefun void gostdsa_vko (const struct ecc_scalar *@var{priv}, const struct \
ecc_point *@var{pub}, size_t @var{ukm_length}, const uint8_t *@var{ukm}, uint8_t \
*@var{out}) +Uses private key @var{priv}, public ket @var{pub} and shared key \
material +@var{ukm} to generate shared secret, written to buffer @var{out}. The \
buffer +should be of the size equal to 2 private key lengths: 64 bytes for 256 bit
+curves and 128 bytes for 512 bit ones. UKM is a shared key material, usually
+transferred in cleartext. It does not have to be secret.
+@end deftypefun
+
 @node Curve 25519 and Curve 448, , ECDSA, Elliptic curves
 @comment  node-name,  next,  previous,  up
 @subsubsection Curve25519 and Curve448
diff --git a/testsuite/.gitignore b/testsuite/.gitignore
index b8b36c2accc2..a2b3d52312cd 100644
--- a/testsuite/.gitignore
+++ b/testsuite/.gitignore
@@ -46,6 +46,7 @@
 /gostdsa-keygen-test
 /gostdsa-sign-test
 /gostdsa-verify-test
+/gostdsa-vko-test
 /gosthash94-test
 /hkdf-test
 /hmac-test
diff --git a/testsuite/.test-rules.make b/testsuite/.test-rules.make
index 9de8f4125079..fdcde6cb9748 100644
--- a/testsuite/.test-rules.make
+++ b/testsuite/.test-rules.make
@@ -304,6 +304,9 @@ gostdsa-verify-test$(EXEEXT): gostdsa-verify-test.$(OBJEXT)
 gostdsa-keygen-test$(EXEEXT): gostdsa-keygen-test.$(OBJEXT)
 	$(LINK) gostdsa-keygen-test.$(OBJEXT) $(TEST_OBJS) -o gostdsa-keygen-test$(EXEEXT)
 
+gostdsa-vko-test$(EXEEXT): gostdsa-vko-test.$(OBJEXT)
+	$(LINK) gostdsa-vko-test.$(OBJEXT) $(TEST_OBJS) -o gostdsa-vko-test$(EXEEXT)
+
 sha1-huge-test$(EXEEXT): sha1-huge-test.$(OBJEXT)
 	$(LINK) sha1-huge-test.$(OBJEXT) $(TEST_OBJS) -o sha1-huge-test$(EXEEXT)
 
diff --git a/testsuite/Makefile.in b/testsuite/Makefile.in
index 89b52efad9df..025f3ea18040 100644
--- a/testsuite/Makefile.in
+++ b/testsuite/Makefile.in
@@ -56,7 +56,7 @@ TS_HOGWEED_SOURCES = sexp-test.c sexp-format-test.c \
 		     eddsa-compress-test.c eddsa-sign-test.c \
 		     eddsa-verify-test.c ed25519-test.c ed448-test.c \
 		     gostdsa-sign-test.c gostdsa-verify-test.c \
-		     gostdsa-keygen-test.c
+		     gostdsa-keygen-test.c gostdsa-vko-test.c
 
 TS_SOURCES = $(TS_NETTLE_SOURCES) $(TS_HOGWEED_SOURCES)
 CXX_SOURCES = cxx-test.cxx
diff --git a/testsuite/gostdsa-vko-test.c b/testsuite/gostdsa-vko-test.c
new file mode 100644
index 000000000000..c8a762b125c2
--- /dev/null
+++ b/testsuite/gostdsa-vko-test.c
@@ -0,0 +1,91 @@
+#include "testutils.h"
+#include "gostdsa.h"
+
+static void
+test_vko (const struct ecc_curve *ecc,
+	  const char *priv,
+	  const char *x,
+	  const char *y,
+	  const struct tstring *ukm,
+	  const struct nettle_hash *hash,
+	  void * hash_ctx,
+	  const struct tstring *res)
+{
+    struct ecc_scalar ecc_key;
+    struct ecc_point ecc_pub;
+    mpz_t temp1, temp2;
+    uint8_t out[128];
+    size_t out_len = ((ecc_bit_size(ecc) + 7) / 8) * 2;
+
+    ASSERT(out_len &lt;= sizeof(out));
+
+    ecc_point_init (&amp;ecc_pub, ecc);
+    mpz_init_set_str (temp1, x, 16);
+    mpz_init_set_str (temp2, y, 16);
+    ASSERT (ecc_point_set (&amp;ecc_pub, temp1, temp2) != 0);
+
+    ecc_scalar_init (&amp;ecc_key, ecc);
+    mpz_set_str (temp1, priv, 16);
+    ASSERT (ecc_scalar_set (&amp;ecc_key, temp1) != 0);
+
+    mpz_clear (temp1);
+    mpz_clear (temp2);
+
+    gostdsa_vko (&amp;ecc_key, &amp;ecc_pub,
+		 ukm-&gt;length, ukm-&gt;data,
+		 out);
+
+    ecc_scalar_clear (&amp;ecc_key);
+    ecc_point_clear (&amp;ecc_pub);
+
+    if (hash)
+      {
+	hash-&gt;init (hash_ctx);
+	hash-&gt;update (hash_ctx, out_len, out);
+	hash-&gt;digest (hash_ctx, hash-&gt;digest_size, out);
+
+	ASSERT (hash-&gt;digest_size == res-&gt;length);
+	ASSERT (MEMEQ (res-&gt;length, out, res-&gt;data));
+      }
+    else
+      {
+	ASSERT (out_len == res-&gt;length);
+	ASSERT (MEMEQ (res-&gt;length, out, res-&gt;data));
+      }
+}
+
+void
+test_main (void)
+{
+    /* RFC 7836, App B, provides test vectors, values there are little endian.
+     *
+     * However those test vectors depend on the availability of Streebog hash
+     * functions, which is not available (yet). So these test vectors capture
+     * the VKO value just before hash function. One can verify them by
+     * calculating the Streeebog function and comparing the result with RFC
+     * 7836, App B. */
+    test_vko(nettle_get_gost_gc512a(),
+	     "67b63ca4ac8d2bb32618d89296c7476dbeb9f9048496f202b1902cf2ce41dbc2f847712d960483458d4b380867f426c7ca0ff5782702dbc44ee8fc72d9ec90c9",
 +	     "51a6d54ee932d176e87591121cce5f395cb2f2f147114d95f463c8a7ed74a9fc5ecd2325a35fb6387831ea66bc3d2aa42ede35872cc75372073a71b983e12f19",
 +	     "793bde5bf72840ad22b02a363ae4772d4a52fc08ba1a20f7458a222a13bf98b53be002d1973f1e398ce46c17da6d00d9b6d0076f8284dcc42e599b4c413b8804",
 +	     SHEX("1d 80 60 3c 85 44 c7 27"),
+	     NULL,
+	     NULL,
+	     SHEX("5fb5261b61e872f9 3efc03200f47378e f039aa89b993a274 a25dec5e5d49ed59"
+		  "84b7dfdf5970c3f7 3059a26d08f7bbc5 0830799bda18b533 499c4f00c21cff3e"
+		  "3b8e53a1ea920eb1 d7f3d08aa9e47595 4a53ac018c210b48 15451b7accc4a797"
+		  "a2b8faf3d89ee717 d07a857794b9b053 f8e0fd5456ccfcc2 2fd081c873416a3f"));
+
+    test_vko(nettle_get_gost_gc512a(),
+	     "dbd09213a592da5bbfd8ed068cccccbbfbeda4feac96b9b4908591440b0714803b9eb763ef932266d4c0181a9b73eacf9013efc65ec07c888515f1b6f759c848",
 +	     "a7c0adb12743c10c3c1beb97c8f631242f7937a1deb6bce5e664e49261baccd3f5dc56ec53b2abb90ca1eb703078ba546655a8b99f79188d2021ffaba4edb0aa",
 +	     "5adb1c63a4e4465e0bbefd897fb9016475934cfa0f8c95f992ea402d47921f46382d00481b720314b19d8c878e75d81b9763358dd304b2ed3a364e07a3134691",
 +	     SHEX("1d 80 60 3c 85 44 c7 27"),
+	     NULL,
+	     NULL,
+	     SHEX("5fb5261b61e872f9 3efc03200f47378e f039aa89b993a274 a25dec5e5d49ed59"
+		  "84b7dfdf5970c3f7 3059a26d08f7bbc5 0830799bda18b533 499c4f00c21cff3e"
+		  "3b8e53a1ea920eb1 d7f3d08aa9e47595 4a53ac018c210b48 15451b7accc4a797"
+		  "a2b8faf3d89ee717 d07a857794b9b053 f8e0fd5456ccfcc2 2fd081c873416a3f"));
+
+}
-- 
2.25.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200422194831</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-22 19:48:31-0400</timestampReceived><subject>Windows dll test failures</subject><body>

I have a question to the list, if anyone here knows details of how
windows dlls work.

I cross compile for windows with 

  ./configure --host=x86_64-w64-mingw32 --enable-mini-gmp CXX=/bin/false
  make

and run tests with 

  make check EMULATOR=wine64

It fails the ecc-dup and ecc-add tests, in this and similar asserts:

  ASSERT (ecc-&gt;dup == ecc_dup_jj);

Here, the right hand side is a symbol from libhogweed-x.dll, and on the
left hand side, ecc refers to a constant struct in the same dll.

My guess us that dynamic linking on windows doesn't provide function
pointer comparisons as specified by the C standard. Maybe left-hand side
is the real function entry point, and the right hand side is the address
of some glue code related to dynamic linking. Is that right? If so, I
can just disable this assert for windows, but I'd like to understand
what'g going on.

I think the reason it works with ELF, is that ELF dynamic linking tries
harder to make all references point to the same PLT glue code, but I
don't fully understand the details there either.

Somewhat related to this: The ecc pointer is taken from this array in
testutils.c:

const struct ecc_curve * const ecc_curves[] = {
  &amp;_nettle_secp_192r1,
  &amp;_nettle_secp_224r1,
  &amp;_nettle_secp_256r1,
  &amp;_nettle_secp_384r1,
  &amp;_nettle_secp_521r1,
  &amp;_nettle_curve25519,
  &amp;_nettle_curve448,
  &amp;_nettle_gost_gc256b,
  &amp;_nettle_gost_gc512a,
  NULL
};

The entries are references to data objects in the dll. I'm a bit
surprised that works at all, is it expected to work? I had the
impression that dlls only exported functions. Should the test code be
changed to use the advertised getter functions, nettle_get_secp_256r1
and friends?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200423142927</emailId><senderName>Eli Zaretskii</senderName><senderEmail>eliz@gnu.org</senderEmail><timestampReceived>2020-04-23 14:29:27-0400</timestampReceived><subject>Re: Windows dll test failures</subject><body>

&gt; From: nisse@lysator.liu.se (Niels Möller)
&gt; Date: Wed, 22 Apr 2020 21:48:31 +0200
&gt; 
&gt; I have a question to the list, if anyone here knows details of how
&gt; windows dlls work.
&gt; 
&gt; I cross compile for windows with 
&gt; 
&gt;   ./configure --host=x86_64-w64-mingw32 --enable-mini-gmp CXX=/bin/false
&gt;   make
&gt; 
&gt; and run tests with 
&gt; 
&gt;   make check EMULATOR=wine64
&gt; 
&gt; It fails the ecc-dup and ecc-add tests, in this and similar asserts:
&gt; 
&gt;   ASSERT (ecc-&gt;dup == ecc_dup_jj);
&gt; 
&gt; Here, the right hand side is a symbol from libhogweed-x.dll, and on the
&gt; left hand side, ecc refers to a constant struct in the same dll.

Please tell more details, perhaps showing the code which obtains the
values of these variables.  In particular, I don't understand what do
you mean by "symbol": this is C, and C doesn't have symbols as one of
its data types.  And what is the purpose of this assertion?

&gt; My guess us that dynamic linking on windows doesn't provide function
&gt; pointer comparisons as specified by the C standard. Maybe left-hand side
&gt; is the real function entry point, and the right hand side is the address
&gt; of some glue code related to dynamic linking. Is that right? If so, I
&gt; can just disable this assert for windows, but I'd like to understand
&gt; what'g going on.

Yes, a DLL call is an indirect call through a function address in a
table, but to give you a detailed enough answer, I'd like to
understand the situation better.

&gt; Somewhat related to this: The ecc pointer is taken from this array in
&gt; testutils.c:
&gt; 
&gt; const struct ecc_curve * const ecc_curves[] = {
&gt;   &amp;_nettle_secp_192r1,
&gt;   &amp;_nettle_secp_224r1,
&gt;   &amp;_nettle_secp_256r1,
&gt;   &amp;_nettle_secp_384r1,
&gt;   &amp;_nettle_secp_521r1,
&gt;   &amp;_nettle_curve25519,
&gt;   &amp;_nettle_curve448,
&gt;   &amp;_nettle_gost_gc256b,
&gt;   &amp;_nettle_gost_gc512a,
&gt;   NULL
&gt; };
&gt; 
&gt; The entries are references to data objects in the dll. I'm a bit
&gt; surprised that works at all, is it expected to work? I had the
&gt; impression that dlls only exported functions.

No, DLLs can export variables as well, and programs linked against it
can import them.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200423151054</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-23 15:10:54-0400</timestampReceived><subject>Re: Windows dll test failures</subject><body>

Eli Zaretskii &lt;eliz@gnu.org&gt; writes:

&gt;&gt; It fails the ecc-dup and ecc-add tests, in this and similar asserts:
&gt;&gt; 
&gt;&gt;   ASSERT (ecc-&gt;dup == ecc_dup_jj);
&gt;&gt; 
&gt;&gt; Here, the right hand side is a symbol from libhogweed-x.dll, and on the
&gt;&gt; left hand side, ecc refers to a constant struct in the same dll.
&gt;
&gt; Please tell more details, perhaps showing the code which obtains the
&gt; values of these variables.  In particular, I don't understand what do
&gt; you mean by "symbol": this is C, and C doesn't have symbols as one of
&gt; its data types.  

The "ecc" variable is a local defined like

  const struct ecc_curve *ecc = ecc_curves[i];

(where ecc_curves is the array quoted below). And ecc_dup_jj is a
top-level function, declared as

  void
  ecc_dup_jj (const struct ecc_curve *ecc,
              mp_limb_t *r, const mp_limb_t *p,
              mp_limb_t *scratch);

The implementation is in the dll, so it is resolved by the dynamic
linker. I've found this stackoverflow question which also asks about
pointer equality with dlls:
https://stackoverflow.com/questions/20517589/function-pointer-values-inside-and-outside-a-dll

And by "symbol", I mean a name that is handled in the linking process.

&gt; And what is the purpose of this assertion?

To check that the ecc_curve points to an appropriate implementation of
the point duplication function (different curves uses different
functions). To get a clearer error than just unexpected output numbers
if the wrong function is used.

But maybe value is quite small, I'll consider deleting the assert.

&gt;&gt; Somewhat related to this: The ecc pointer is taken from this array in
&gt;&gt; testutils.c:
&gt;&gt; 
&gt;&gt; const struct ecc_curve * const ecc_curves[] = {
&gt;&gt;   &amp;_nettle_secp_192r1,
&gt;&gt;   &amp;_nettle_secp_224r1,
&gt;&gt;   &amp;_nettle_secp_256r1,
&gt;&gt;   &amp;_nettle_secp_384r1,
&gt;&gt;   &amp;_nettle_secp_521r1,
&gt;&gt;   &amp;_nettle_curve25519,
&gt;&gt;   &amp;_nettle_curve448,
&gt;&gt;   &amp;_nettle_gost_gc256b,
&gt;&gt;   &amp;_nettle_gost_gc512a,
&gt;&gt;   NULL
&gt;&gt; };
&gt;&gt; 
&gt;&gt; The entries are references to data objects in the dll. I'm a bit
&gt;&gt; surprised that works at all, is it expected to work? I had the
&gt;&gt; impression that dlls only exported functions.
&gt;
&gt; No, DLLs can export variables as well, and programs linked against it
&gt; can import them.

Thanks, that's good to know.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200421164222</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-04-21 16:42:22-0400</timestampReceived><subject>Re: [PATCH v3] Implement GOST VKO key derivation algorithm</subject><body>

Merged patch onto the master-updates branch.

Thanks,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200217232850</emailId><senderName>Андрей Аладьев</senderName><senderEmail>aladjev.andrew@gmail.com</senderEmail><timestampReceived>2020-02-17 23:28:50-0400</timestampReceived><subject>Armeb is broken</subject><body>

Hello, please see the following gnutls issue
https://gitlab.com/gnutls/gnutls/issues/941.

Nettle today is working on aarch64, aarch64_be and arm, but broken on armeb.

You can test it using the following way:
1. Enable CONFIG_X86_X32=y in kernel.
2. Install qemu-user with required arch and start qemu-binfmt service.

Run commands:
docker run -it puchuu/test_aarch64-unknown-linux-gnu bash
env-update &amp;&amp; source /etc/profile
MAKEOPTS='-j16' FEATURES='test' emerge -v1 dev-libs/nettle

Unfortunately I can't provide complete armeb image, because its build
depends on working nettle. I can provide only armeb results:

FAIL: chacha
FAIL: memxor
FAIL: ccm
FAIL: pss
FAIL: rsa-pss-sign-tr

5 of 98 tests failed

I am launching "./testsuite/chacha-test" directly, result:
Error, length 7, expected:

76b8e0ada0f13d
Got:

ade0a9f13d9076
qemu: uncaught target signal 6 (Aborted) - core dumped

So it looks like armeb is completely broken today.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200306164058</emailId><senderName>Daiki Ueno</senderName><senderEmail>ueno@gnu.org</senderEmail><timestampReceived>2020-03-06 16:40:58-0400</timestampReceived><subject>[PATCH 2/2] doc: match ChaCha-Poly1305 documentation to the implementation</subject><body>

From: Daiki Ueno &lt;dueno@redhat.com&gt;

While the documentation said the nonce size is 16 octets, the
implementation actually assumed 12 octets following RFC 7539.

Signed-off-by: Daiki Ueno &lt;dueno@redhat.com&gt;
---
 nettle.texinfo | 17 +++++------------
 1 file changed, 5 insertions(+), 12 deletions(-)

diff --git a/nettle.texinfo b/nettle.texinfo
index 0b339f51..7d5e1780 100644
--- a/nettle.texinfo
+++ b/nettle.texinfo
@@ -3292,17 +3292,10 @@ except that @var{cipher} and @var{f} are replaced with a context structure.
 ChaCha-Poly1305 is a combination of the ChaCha stream cipher and the
 poly1305 message authentication code (@pxref{Poly1305}). It originates
 from the NaCl cryptographic library by D. J. Bernstein et al, which
-defines a similar construction but with Salsa20 instead of ChaCha. 
-
-Nettle's implementation ChaCha-Poly1305 should be considered
-@strong{experimental}. At the time of this writing, there is no
-authoritative specification for ChaCha-Poly1305, and a couple of
-different incompatible variants. Nettle implements it using the original
-definition of ChaCha, with 64 bits (8 octets) each for the nonce and the
-block counter. Some protocols prefer to use nonces of 12 bytes, and it's
-a small change to ChaCha to use the upper 32 bits of the block counter
-as a nonce, instead limiting message size to @math{2^32} blocks or 256
-GBytes, but that variant is currently not supported.
+defines a similar construction but with Salsa20 instead of ChaCha.
+
+Nettle's implementation of ChaCha-Poly1305 follows @cite{RFC 7539}.
+Unlike the original definition of ChaCha, the nonces are of 12 bytes.
 
 For ChaCha-Poly1305, the ChaCha cipher is initialized with a key, of 256
 bits, and a per-message nonce. The first block of the key stream
@@ -3331,7 +3324,7 @@ ChaCha-Poly1305 key size, 32.
 @end defvr
 
 @defvr Constant CHACHA_POLY1305_NONCE_SIZE
-Same as the ChaCha nonce size, 16.
+ChaCha-Poly1305 nonce size, 12.
 @end defvr
 
 @defvr Constant CHACHA_POLY1305_DIGEST_SIZE
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200306164057</emailId><senderName>Daiki Ueno</senderName><senderEmail>ueno@gnu.org</senderEmail><timestampReceived>2020-03-06 16:40:57-0400</timestampReceived><subject>[PATCH 1/2] chacha: add function to set initial block counter</subject><body>

From: Daiki Ueno &lt;dueno@redhat.com&gt;

The ChaCha20 based header protection algorithm in QUIC requires a way
to set the initial value of counter:
https://quicwg.org/base-drafts/draft-ietf-quic-tls.html#name-chacha20-based-header-prote


This will add a new function chacha_set_counter, which takes an
8-octet initial value of the block counter.

Signed-off-by: Daiki Ueno &lt;dueno@redhat.com&gt;
---
 chacha-set-nonce.c      |  7 +++++++
 chacha.h                |  5 +++++
 nettle.texinfo          | 12 ++++++++++++
 testsuite/chacha-test.c | 37 +++++++++++++++++++++++++++++++++++--
 4 files changed, 59 insertions(+), 2 deletions(-)

diff --git a/chacha-set-nonce.c b/chacha-set-nonce.c
index 607f176b..2c34e498 100644
--- a/chacha-set-nonce.c
+++ b/chacha-set-nonce.c
@@ -68,3 +68,10 @@ chacha_set_nonce96(struct chacha_ctx *ctx, const uint8_t *nonce)
   ctx-&gt;state[14] = LE_READ_UINT32(nonce + 4);
   ctx-&gt;state[15] = LE_READ_UINT32(nonce + 8);
 }
+
+void
+chacha_set_counter(struct chacha_ctx *ctx, const uint8_t *counter)
+{
+  ctx-&gt;state[12] = LE_READ_UINT32(counter + 0);
+  ctx-&gt;state[13] = LE_READ_UINT32(counter + 4);
+}
diff --git a/chacha.h b/chacha.h
index 429a55b6..440fe968 100644
--- a/chacha.h
+++ b/chacha.h
@@ -46,6 +46,7 @@ extern "C" {
 #define chacha_set_key nettle_chacha_set_key
 #define chacha_set_nonce nettle_chacha_set_nonce
 #define chacha_set_nonce96 nettle_chacha_set_nonce96
+#define chacha_set_counter nettle_chacha_set_counter
 #define chacha_crypt nettle_chacha_crypt
 
 /* Currently, only 256-bit keys are supported. */
@@ -53,6 +54,7 @@ extern "C" {
 #define CHACHA_BLOCK_SIZE 64
 #define CHACHA_NONCE_SIZE 8
 #define CHACHA_NONCE96_SIZE 12
+#define CHACHA_COUNTER_SIZE 8
 
 #define _CHACHA_STATE_LENGTH 16
 
@@ -81,6 +83,9 @@ chacha_set_nonce(struct chacha_ctx *ctx, const uint8_t *nonce);
 void
 chacha_set_nonce96(struct chacha_ctx *ctx, const uint8_t *nonce);
 
+void
+chacha_set_counter(struct chacha_ctx *ctx, const uint8_t *counter);
+
 void
 chacha_crypt(struct chacha_ctx *ctx, size_t length, 
              uint8_t *dst, const uint8_t *src);
diff --git a/nettle.texinfo b/nettle.texinfo
index 19eb6d34..0b339f51 100644
--- a/nettle.texinfo
+++ b/nettle.texinfo
@@ -1669,6 +1669,10 @@ ChaCha block size, 64.
 Size of the nonce, 8.
 @end defvr
 
+@defvr Constant CHACHA_COUNTER_SIZE
+Size of the counter, 8.
+@end defvr
+
 @deftypefun void chacha_set_key (struct chacha_ctx *@var{ctx}, const uint8_t \
*@var{key})  Initialize the cipher. The same function is used for both encryption and
 decryption. Before using the cipher,
@@ -1681,6 +1685,14 @@ octets. This function also initializes the block counter, \
setting it to  zero.
 @end deftypefun
 
+@deftypefun void chacha_set_counter (struct chacha_ctx *@var{ctx}, const uint8_t \
*@var{counter}) +Sets the block counter. It is always of size \
@code{CHACHA_COUNTER_SIZE}, +8 octets. This is rarely needed since \
@code{chacha_set_nonce} +initializes the block counter to zero. When it is still \
necessary, this +function must be called after @code{chacha_set_nonce}.
+
+@end deftypefun
+
 @deftypefun void chacha_crypt (struct chacha_ctx *@var{ctx}, size_t @var{length}, \
uint8_t *@var{dst}, const uint8_t *@var{src})  Encrypts or decrypts the data of a \
message, using ChaCha. When a  message is encrypted using a sequence of calls to \
                @code{chacha_crypt},
diff --git a/testsuite/chacha-test.c b/testsuite/chacha-test.c
index d6489e9c..6875d4bb 100644
--- a/testsuite/chacha-test.c
+++ b/testsuite/chacha-test.c
@@ -38,8 +38,9 @@
 #include "chacha-internal.h"
 
 static void
-test_chacha(const struct tstring *key, const struct tstring *nonce,
-	    const struct tstring *expected, unsigned rounds)
+_test_chacha(const struct tstring *key, const struct tstring *nonce,
+	     const struct tstring *expected, unsigned rounds,
+	     const struct tstring *counter)
 {
   struct chacha_ctx ctx;
 
@@ -69,6 +70,9 @@ test_chacha(const struct tstring *key, const struct tstring *nonce,
 	  else
 	    die ("Bad nonce size %u.\n", (unsigned) nonce-&gt;length);
 
+	  if (counter)
+	    chacha_set_counter(&amp;ctx, counter-&gt;data);
+
 	  chacha_crypt (&amp;ctx, length, data, data);
 
 	  ASSERT (data[-1] == 17);
@@ -98,6 +102,8 @@ test_chacha(const struct tstring *key, const struct tstring \
*nonce,  ASSERT (nonce-&gt;length == CHACHA_NONCE_SIZE);
 
       chacha_set_nonce(&amp;ctx, nonce-&gt;data);
+      if (counter)
+	    chacha_set_counter(&amp;ctx, counter-&gt;data);
       _chacha_core (out, ctx.state, rounds);
 
       if (!MEMEQ(CHACHA_BLOCK_SIZE, out, expected-&gt;data))
@@ -117,6 +123,21 @@ test_chacha(const struct tstring *key, const struct tstring \
*nonce,  }
 }
 
+static void
+test_chacha(const struct tstring *key, const struct tstring *nonce,
+	    const struct tstring *expected, unsigned rounds)
+{
+  _test_chacha(key, nonce, expected, rounds, NULL);
+}
+
+static void
+test_chacha_with_counter(const struct tstring *key, const struct tstring *nonce,
+			 const struct tstring *expected, unsigned rounds,
+			 const struct tstring *counter)
+{
+  _test_chacha(key, nonce, expected, rounds, counter);
+}
+
 void
 test_main(void)
 {
@@ -644,4 +665,16 @@ test_main(void)
 		   "d2826446079faa09 14c2d705d98b02a2"
 		   "b5129cd1de164eb9 cbd083e8a2503c4e"),
 	      20);
+
+  /* This is identical to the 96-bit nonce test, but it manually sets
+     the counter value */
+  test_chacha_with_counter(SHEX("0001020304050607 08090a0b0c0d0e0f"
+				"1011121314151617 18191a1b1c1d1e1f"),
+			   SHEX("0000004a00000000"),
+			   SHEX("10f1e7e4d13b5915 500fdd1fa32071c4"
+				"c7d1f4c733c06803 0422aa9ac3d46c4e"
+				"d2826446079faa09 14c2d705d98b02a2"
+				"b5129cd1de164eb9 cbd083e8a2503c4e"),
+			   20,
+			   SHEX("0100000000000009"));
 }
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200309120117</emailId><senderName>Daiki Ueno</senderName><senderEmail>ueno@gnu.org</senderEmail><timestampReceived>2020-03-09 12:01:17-0400</timestampReceived><subject>[PATCH v2 1/3] chacha: add function to set initial block counter</subject><body>

From: Daiki Ueno &lt;dueno@redhat.com&gt;

The ChaCha20 based header protection algorithm in QUIC requires a way
to set the initial value of counter:
https://quicwg.org/base-drafts/draft-ietf-quic-tls.html#name-chacha20-based-header-prote


This will add a new function chacha_set_counter, which takes an
8-octet initial value of the block counter.

Signed-off-by: Daiki Ueno &lt;dueno@redhat.com&gt;
---
 chacha-set-nonce.c      |  7 +++++++
 chacha.h                |  5 +++++
 nettle.texinfo          | 12 ++++++++++++
 testsuite/chacha-test.c | 37 +++++++++++++++++++++++++++++++++++--
 4 files changed, 59 insertions(+), 2 deletions(-)

diff --git a/chacha-set-nonce.c b/chacha-set-nonce.c
index 607f176b..2c34e498 100644
--- a/chacha-set-nonce.c
+++ b/chacha-set-nonce.c
@@ -68,3 +68,10 @@ chacha_set_nonce96(struct chacha_ctx *ctx, const uint8_t *nonce)
   ctx-&gt;state[14] = LE_READ_UINT32(nonce + 4);
   ctx-&gt;state[15] = LE_READ_UINT32(nonce + 8);
 }
+
+void
+chacha_set_counter(struct chacha_ctx *ctx, const uint8_t *counter)
+{
+  ctx-&gt;state[12] = LE_READ_UINT32(counter + 0);
+  ctx-&gt;state[13] = LE_READ_UINT32(counter + 4);
+}
diff --git a/chacha.h b/chacha.h
index 429a55b6..440fe968 100644
--- a/chacha.h
+++ b/chacha.h
@@ -46,6 +46,7 @@ extern "C" {
 #define chacha_set_key nettle_chacha_set_key
 #define chacha_set_nonce nettle_chacha_set_nonce
 #define chacha_set_nonce96 nettle_chacha_set_nonce96
+#define chacha_set_counter nettle_chacha_set_counter
 #define chacha_crypt nettle_chacha_crypt
 
 /* Currently, only 256-bit keys are supported. */
@@ -53,6 +54,7 @@ extern "C" {
 #define CHACHA_BLOCK_SIZE 64
 #define CHACHA_NONCE_SIZE 8
 #define CHACHA_NONCE96_SIZE 12
+#define CHACHA_COUNTER_SIZE 8
 
 #define _CHACHA_STATE_LENGTH 16
 
@@ -81,6 +83,9 @@ chacha_set_nonce(struct chacha_ctx *ctx, const uint8_t *nonce);
 void
 chacha_set_nonce96(struct chacha_ctx *ctx, const uint8_t *nonce);
 
+void
+chacha_set_counter(struct chacha_ctx *ctx, const uint8_t *counter);
+
 void
 chacha_crypt(struct chacha_ctx *ctx, size_t length, 
              uint8_t *dst, const uint8_t *src);
diff --git a/nettle.texinfo b/nettle.texinfo
index 19eb6d34..0b339f51 100644
--- a/nettle.texinfo
+++ b/nettle.texinfo
@@ -1669,6 +1669,10 @@ ChaCha block size, 64.
 Size of the nonce, 8.
 @end defvr
 
+@defvr Constant CHACHA_COUNTER_SIZE
+Size of the counter, 8.
+@end defvr
+
 @deftypefun void chacha_set_key (struct chacha_ctx *@var{ctx}, const uint8_t \
*@var{key})  Initialize the cipher. The same function is used for both encryption and
 decryption. Before using the cipher,
@@ -1681,6 +1685,14 @@ octets. This function also initializes the block counter, \
setting it to  zero.
 @end deftypefun
 
+@deftypefun void chacha_set_counter (struct chacha_ctx *@var{ctx}, const uint8_t \
*@var{counter}) +Sets the block counter. It is always of size \
@code{CHACHA_COUNTER_SIZE}, +8 octets. This is rarely needed since \
@code{chacha_set_nonce} +initializes the block counter to zero. When it is still \
necessary, this +function must be called after @code{chacha_set_nonce}.
+
+@end deftypefun
+
 @deftypefun void chacha_crypt (struct chacha_ctx *@var{ctx}, size_t @var{length}, \
uint8_t *@var{dst}, const uint8_t *@var{src})  Encrypts or decrypts the data of a \
message, using ChaCha. When a  message is encrypted using a sequence of calls to \
                @code{chacha_crypt},
diff --git a/testsuite/chacha-test.c b/testsuite/chacha-test.c
index d6489e9c..6875d4bb 100644
--- a/testsuite/chacha-test.c
+++ b/testsuite/chacha-test.c
@@ -38,8 +38,9 @@
 #include "chacha-internal.h"
 
 static void
-test_chacha(const struct tstring *key, const struct tstring *nonce,
-	    const struct tstring *expected, unsigned rounds)
+_test_chacha(const struct tstring *key, const struct tstring *nonce,
+	     const struct tstring *expected, unsigned rounds,
+	     const struct tstring *counter)
 {
   struct chacha_ctx ctx;
 
@@ -69,6 +70,9 @@ test_chacha(const struct tstring *key, const struct tstring *nonce,
 	  else
 	    die ("Bad nonce size %u.\n", (unsigned) nonce-&gt;length);
 
+	  if (counter)
+	    chacha_set_counter(&amp;ctx, counter-&gt;data);
+
 	  chacha_crypt (&amp;ctx, length, data, data);
 
 	  ASSERT (data[-1] == 17);
@@ -98,6 +102,8 @@ test_chacha(const struct tstring *key, const struct tstring \
*nonce,  ASSERT (nonce-&gt;length == CHACHA_NONCE_SIZE);
 
       chacha_set_nonce(&amp;ctx, nonce-&gt;data);
+      if (counter)
+	    chacha_set_counter(&amp;ctx, counter-&gt;data);
       _chacha_core (out, ctx.state, rounds);
 
       if (!MEMEQ(CHACHA_BLOCK_SIZE, out, expected-&gt;data))
@@ -117,6 +123,21 @@ test_chacha(const struct tstring *key, const struct tstring \
*nonce,  }
 }
 
+static void
+test_chacha(const struct tstring *key, const struct tstring *nonce,
+	    const struct tstring *expected, unsigned rounds)
+{
+  _test_chacha(key, nonce, expected, rounds, NULL);
+}
+
+static void
+test_chacha_with_counter(const struct tstring *key, const struct tstring *nonce,
+			 const struct tstring *expected, unsigned rounds,
+			 const struct tstring *counter)
+{
+  _test_chacha(key, nonce, expected, rounds, counter);
+}
+
 void
 test_main(void)
 {
@@ -644,4 +665,16 @@ test_main(void)
 		   "d2826446079faa09 14c2d705d98b02a2"
 		   "b5129cd1de164eb9 cbd083e8a2503c4e"),
 	      20);
+
+  /* This is identical to the 96-bit nonce test, but it manually sets
+     the counter value */
+  test_chacha_with_counter(SHEX("0001020304050607 08090a0b0c0d0e0f"
+				"1011121314151617 18191a1b1c1d1e1f"),
+			   SHEX("0000004a00000000"),
+			   SHEX("10f1e7e4d13b5915 500fdd1fa32071c4"
+				"c7d1f4c733c06803 0422aa9ac3d46c4e"
+				"d2826446079faa09 14c2d705d98b02a2"
+				"b5129cd1de164eb9 cbd083e8a2503c4e"),
+			   20,
+			   SHEX("0100000000000009"));
 }
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200218101845</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2020-02-18 10:18:45-0400</timestampReceived><subject>Re: Armeb is broken</subject><body>

Hi Андрей,

On Tue, Feb 18, 2020 at 02:28:50AM +0300, Андрей Аладьев wrote:

&gt; Hello, please see the following gnutls issue
&gt; https://gitlab.com/gnutls/gnutls/issues/941.

&gt; Nettle today is working on aarch64, aarch64_be and arm, but broken on armeb.

Nice to see that someone other than me is doing armeb. :)

&gt; FAIL: chacha
&gt; FAIL: memxor
&gt; FAIL: ccm
&gt; FAIL: pss
&gt; FAIL: rsa-pss-sign-tr

The asm for arm certainly needed adjustment to work on armeb. See
https://lists.lysator.liu.se/pipermail/nettle-bugs/2018/007280.html.

&gt; So it looks like armeb is completely broken today.

I have had this running on actual armeb hardware with nettle-3.4 and 3.5
for a couple of years and there are no issues with the testsuite or in
production.

configure: summary of build options:

  Version:           nettle 3.5.1
  Host type:         armv7veb-unknown-linux-gnueabihf
  ABI:               standard
  Assembly files:    arm/v6 arm
  Install prefix:    /usr
  Library directory: /usr/lib
  Compiler:          armv7veb-unknown-linux-gnueabihf-gcc
  Static libraries:  no
  Shared libraries:  yes
  Public key crypto: yes
  Using mini-gmp:    no
  Documentation:     no

Linux b 5.5.2-gentoo-r1 #1 SMP Wed Feb 5 22:52:04 CET 2020
armv7b ARMv7 Processor rev 4 (v7b) Allwinner sun7i (A20) Family
GNU/Linux

LD_LIBRARY_PATH=../.lib PATH="../.lib:$PATH" DYLD_LIBRARY_PATH=../.lib \
  srcdir="/var/tmp/portage/dev-libs/nettle-3.5.1/work/nettle-3.5.1/testsuite"
\
  EMULATOR="" NM="armv7veb-unknown-linux-gnueabihf-nm" EXEEXT="" \
          /var/tmp/portage/dev-libs/nettle-3.5.1/work/nettle-3.5.1/run-tests
[...]
PASS: aes
[...]
PASS: chacha
[...]
PASS: memxor
[...]
PASS: ccm
[...]
PASS: pss
PASS: rsa-sign-tr
PASS: pss-mgf1
PASS: rsa-pss-sign-tr
[...]
PASS: nettle-pbkdf2
armv7veb-unknown-linux-gnueabihf-nm: '../libnettle.a': No such file
armv7veb-unknown-linux-gnueabihf-nm: '../libnettle.a': No such file
PASS: symbols
PASS: dlopen
===================
All 99 tests passed
===================

@Niels: Sorry for falling off the face of the earth after the CI
extravaganza. I hadn't even noticed that armeb made it into
nettle-3.5. A working version just fell out of the package manager.
Let me know if there are any outstanding issues regarding armeb and I'll
look into them.

BTW: libressl recently added arm optimized asm and now poses the same
problem for armeb.
-- 
Micha
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200218112505</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-02-18 11:25:05-0400</timestampReceived><subject>Re: Armeb is broken</subject><body>

Michael Weiser &lt;michael.weiser@gmx.de&gt; writes:

&gt; @Niels: Sorry for falling off the face of the earth after the CI
&gt; extravaganza. 

I'm afraid I don't remember the conclusions of our earlier discussions
on CI.

&gt; I hadn't even noticed that armeb made it into
&gt; nettle-3.5. A working version just fell out of the package manager.

Nice that it's working out of the box.

&gt; Let me know if there are any outstanding issues regarding armeb and I'll
&gt; look into them.

To keep it in working shape, it would help a lot with additional tests
in .gitlab-ci. I'm not really familiar with the cross setup used for
arm, mips, and aarch64, Nikos helped with all that. But maybe armeb can
be added in the same way?

I'm not aware of any issues, but on the other hand, I don't do any
testing on armeb.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200307164916</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-03-07 16:49:16-0400</timestampReceived><subject>Re: [PATCH] x86: Add X86_ENDBR and CET marker to config.m4.in</subject><body>

"H.J. Lu" &lt;hjl.tools@gmail.com&gt; writes:

&gt; Intel Control-flow Enforcement Technology (CET):
&gt;
&gt; https://software.intel.com/en-us/articles/intel-sdm
&gt;
&gt; contains shadow stack (SHSTK) and indirect branch tracking (IBT).  When
&gt; CET is enabled, ELF object files must be marked with .note.gnu.property
&gt; section.  Also when IBT is enabled, all indirect branch targets must
&gt; start with ENDBR instruction.
&gt;
&gt; This patch adds X86_ENDBR and the CET marker to config.m4.in when CET
&gt; is enabled.  It updates PROLOGUE with X86_ENDBR.

I'd like to have a look at what gcc produces. How is it enabled with
gcc? In the docs, I find

  -mshstk

    The -mshstk option enables shadow stack built-in functions from x86
    Control-flow Enforcement Technology (CET).

but when I try compiling a trivial function,

  $ cat foo-cet.c 
  int foo(void) {return 0;}
  $ gcc -save-temps -c -mshstk foo-cet.c 

I get no endbr instruction and no note in the foo-cet.s. I'm using
gcc-8.3. I do get an

  .section .note.GNU-stack,"",@progbits

corresponding to Nettle's ASM_MARK_NOEXEC_STACK

&gt; --- a/config.m4.in
&gt; +++ b/config.m4.in
&gt; @@ -8,6 +8,10 @@ define(&lt;ALIGN_LOG&gt;, &lt;@ASM_ALIGN_LOG@&gt;)dnl
&gt;  define(&lt;W64_ABI&gt;, &lt;@W64_ABI@&gt;)dnl
&gt;  define(&lt;RODATA&gt;, &lt;@ASM_RODATA@&gt;)dnl
&gt;  define(&lt;WORDS_BIGENDIAN&gt;, &lt;@ASM_WORDS_BIGENDIAN@&gt;)dnl
&gt; +define(&lt;X86_ENDBR&gt;,&lt;@X86_ENDBR@&gt;)dnl
&gt; +divert(1)
&gt; +@X86_GNU_PROPERTY@
&gt; +divert
&gt;  divert(1)
&gt;  @ASM_MARK_NOEXEC_STACK@
&gt;  divert

You can put the two properties in the same m4 divert. Also, please
rename the autoconf substitutions with ASM_ prefix, and something more
descriptive than X64_GNU_PROPERTY. E.g., ASM_X86_ENDBR and
ASM_X86_MARK_CET.

&gt; diff --git a/configure.ac b/configure.ac
&gt; index ba3ab7c6..e9ed630c 100644
&gt; --- a/configure.ac
&gt; +++ b/configure.ac
&gt; @@ -803,6 +803,82 @@ EOF
&gt;    ASM_ALIGN_LOG="$nettle_cv_asm_align_log"
&gt;  fi
&gt;  
&gt; +dnl  Define
&gt; +dnl  1. X86_ENDBR for endbr32/endbr64.
&gt; +dnl  2. X86_GNU_PROPERTY to add a .note.gnu.property section to mark
&gt; +dnl  Intel CET support if needed.
&gt; +dnl	.section ".note.gnu.property", "a"
&gt; +dnl	.p2align POINTER-ALIGN
&gt; +dnl	.long 1f - 0f
&gt; +dnl	.long 4f - 1f
&gt; +dnl	.long 5
&gt; +dnl 0:
&gt; +dnl	.asciz "GNU"
&gt; +dnl 1:
&gt; +dnl	.p2align POINTER-ALIGN
&gt; +dnl	.long 0xc0000002
&gt; +dnl	.long 3f - 2f
&gt; +dnl 2:
&gt; +dnl	.long 3
&gt; +dnl 3:
&gt; +dnl	.p2align POINTER-ALIGN
&gt; +dnl 4:

No need to repeat the definition in full in this comment. And as I think
I've said before, I'm a bit surprised that it needs to be this verbose.

&gt; +AC_CACHE_CHECK([if Intel CET is enabled],
&gt; +  [nettle_cv_asm_x86_intel_cet],
&gt; +  [AC_TRY_COMPILE([
&gt; +#ifndef __CET__
&gt; +#error Intel CET is not enabled
&gt; +#endif
&gt; +  ], [],
&gt; +  [nettle_cv_asm_x86_intel_cet=yes],
&gt; +  [nettle_cv_asm_x86_intel_cet=no])])
&gt; +if test "$nettle_cv_asm_x86_intel_cet" = yes; then
&gt; +  case $ABI in
&gt; +  32|standard)
&gt; +    X86_ENDBR=endbr32
&gt; +    p2align=2
&gt; +    ;;
&gt; +  64)
&gt; +    X86_ENDBR=endbr64
&gt; +    p2align=3
&gt; +    ;;
&gt; +  x32)
&gt; +    X86_ENDBR=endbr64
&gt; +    p2align=2
&gt; +    ;;
&gt; +  esac
&gt; +  AC_CACHE_CHECK([if .note.gnu.property section is needed],
&gt; +    [nettle_cv_asm_x86_gnu_property],
&gt; +    [AC_TRY_COMPILE([
&gt; +#if !defined __ELF__ || !defined __CET__
&gt; +#error GNU property is not needed
&gt; +#endif
&gt; +    ], [],
&gt; +    [nettle_cv_asm_x86_gnu_property=yes],
&gt; +    [nettle_cv_asm_x86_gnu_property=no])])
&gt; +else
&gt; +  nettle_cv_asm_x86_gnu_property=no
&gt; +fi
&gt; +if test "$nettle_cv_asm_x86_gnu_property" = yes; then
&gt; +  X86_GNU_PROPERTY="
&gt; +	.section \".note.gnu.property\", \"a\"
&gt; +	.p2align $p2align
&gt; +	.long 1f - 0f
&gt; +	.long 4f - 1f
&gt; +	.long 5
&gt; +0:
&gt; +	.asciz \"GNU\"
&gt; +1:
&gt; +	.p2align $p2align
&gt; +	.long 0xc0000002
&gt; +	.long 3f - 2f
&gt; +2:
&gt; +	.long 3
&gt; +3:
&gt; +	.p2align $p2align
&gt; +4:"
&gt; +fi

Maybe a bit easier to read if you use single quotes for
X86_GNU_PROPERTY='...', don't escape the inner double quotes. That
leaves the expansion of $p2align, maybe it's better to define a separate
substituted variable for pointer alignment? (If there's no easier way to
enforce pointer-alignment).

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200305191307</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2020-03-05 19:13:07-0400</timestampReceived><subject>[PATCH 1/1] arm: Fix memxor for non-armv6+ big-endian systems</subject><body>

ARM assembly adjustments for big-endian systems contained armv6+-only
instructions (rev) in generic arm memxor code. Replace those with an
actual conversion of the leftover byte store routines for big-endian
systems. This also provides a slight optimisation by removing the
additional instruction as well as increased symmetry between little- and
big-endian implementations.

Signed-off-by: Michael Weiser &lt;michael.weiser@gmx.de&gt;
---
 arm/memxor.asm  | 13 +++++++------
 arm/memxor3.asm | 31 ++++++++++++++++++-------------
 2 files changed, 25 insertions(+), 19 deletions(-)

diff --git a/arm/memxor.asm b/arm/memxor.asm
index 239a4034..e4619629 100644
--- a/arm/memxor.asm
+++ b/arm/memxor.asm
@@ -138,24 +138,25 @@ PROLOGUE(nettle_memxor)
 	adds	N, #8
 	beq	.Lmemxor_odd_done
 
-	C We have TNC/8 left-over bytes in r4, high end
+	C We have TNC/8 left-over bytes in r4, high end on LE and low end on
+	C BE, excess bits to be discarded by alignment adjustment at the other
 	S0ADJ	r4, CNT
+	C now byte-aligned at low end on LE and high end on BE
 	ldr	r3, [DST]
 	eor	r3, r4
 
-	C memxor_leftover does an LSB store
-	C so we need to reverse if actually BE
-IF_BE(&lt;	rev	r3, r3&gt;)
-
 	pop	{r4,r5,r6}
 
 	C Store bytes, one by one.
 .Lmemxor_leftover:
+	C bring uppermost byte down for saving while preserving lower ones
+IF_BE(&lt;	ror	r3, #24&gt;)
 	strb	r3, [DST], #+1
 	subs	N, #1
 	beq	.Lmemxor_done
 	subs	TNC, #8
-	lsr	r3, #8
+	C bring down next byte, no need to preserve
+IF_LE(&lt;	lsr	r3, #8&gt;)
 	bne	.Lmemxor_leftover
 	b	.Lmemxor_bytes
 .Lmemxor_odd_done:
diff --git a/arm/memxor3.asm b/arm/memxor3.asm
index 69598e1c..b6c6da49 100644
--- a/arm/memxor3.asm
+++ b/arm/memxor3.asm
@@ -159,21 +159,23 @@ PROLOGUE(nettle_memxor3)
 	adds	N, #8
 	beq	.Lmemxor3_done
 
-	C Leftover bytes in r4, low end
+	C Leftover bytes in r4, low end on LE and high end on BE before
+	C preparatory alignment correction
 	ldr	r5, [AP, #-4]
 	eor	r4, r5, r4, S1ADJ ATNC
-
-	C leftover does an LSB store
-	C so we need to reverse if actually BE
-IF_BE(&lt;	rev	r4, r4&gt;)
+	C now byte-aligned in high end on LE and low end on BE because we're
+	C working downwards in saving the very first bytes of the buffer
 
 .Lmemxor3_au_leftover:
 	C Store a byte at a time
-	ror	r4, #24
+	C bring uppermost byte down for saving while preserving lower ones
+IF_LE(&lt;	ror	r4, #24&gt;)
 	strb	r4, [DST, #-1]!
 	subs	N, #1
 	beq	.Lmemxor3_done
 	subs	ACNT, #8
+	C bring down next byte, no need to preserve
+IF_BE(&lt;	lsr	r4, #8&gt;)
 	sub	AP, #1
 	bne	.Lmemxor3_au_leftover
 	b	.Lmemxor3_bytes
@@ -273,18 +275,21 @@ IF_BE(&lt;	rev	r4, r4&gt;)
 	adds	N, #8
 	beq	.Lmemxor3_done
 
-	C leftover does an LSB store
-	C so we need to reverse if actually BE
-IF_BE(&lt;	rev	r4, r4&gt;)
-
-	C Leftover bytes in a4, low end
-	ror	r4, ACNT
+	C Leftover bytes in r4, low end on LE and high end on BE before
+	C preparatory alignment correction
+IF_LE(&lt;	ror	r4, ACNT&gt;)
+IF_BE(&lt;	ror	r4, ATNC&gt;)
+	C now byte-aligned in high end on LE and low end on BE because we're
+	C working downwards in saving the very first bytes of the buffer
 .Lmemxor3_uu_leftover:
-	ror	r4, #24
+	C bring uppermost byte down for saving while preserving lower ones
+IF_LE(&lt;	ror	r4, #24&gt;)
 	strb	r4, [DST, #-1]!
 	subs	N, #1
 	beq	.Lmemxor3_done
 	subs	ACNT, #8
+	C bring down next byte, no need to preserve
+IF_BE(&lt;	lsr	r4, #8&gt;)
 	bne	.Lmemxor3_uu_leftover
 	b	.Lmemxor3_bytes
 
-- 
2.25.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200309211534</emailId><senderName>Simo Sorce</senderName><senderEmail>simo@redhat.com</senderEmail><timestampReceived>2020-03-09 21:15:34-0400</timestampReceived><subject>Re: V3 [PATCH] x86: Add X86_ENDBR and CET marker to config.m4.in</subject><body>

On Mon, 2020-03-09 at 12:46 -0700, H.J. Lu wrote:
&gt; On Mon, Mar 9, 2020 at 12:22 PM Simo Sorce &lt;simo@redhat.com&gt; wrote:
&gt; &gt; On Mon, 2020-03-09 at 15:19 -0400, Simo Sorce wrote:
&gt; &gt; &gt; On Mon, 2020-03-09 at 11:56 -0700, H.J. Lu wrote:
&gt; &gt; &gt; &gt; On Mon, Mar 9, 2020 at 11:19 AM Simo Sorce &lt;simo@redhat.com&gt; wrote:
&gt; &gt; &gt; &gt; &gt; On Mon, 2020-03-09 at 19:03 +0100, Niels Möller wrote:
&gt; &gt; &gt; &gt; &gt; &gt; Simo Sorce &lt;simo@redhat.com&gt; writes:
&gt; &gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; &gt; &gt; The patchset i solder than I did remember, April 2019
&gt; &gt; &gt; &gt; &gt; &gt; &gt; But I recall running at least one version of it on our CET emulator @
&gt; &gt; &gt; &gt; &gt; &gt; &gt; Red Hat.
&gt; &gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; &gt; Sorry I forgot to followup on that. It seems only the first easy cleanup
&gt; &gt; &gt; &gt; &gt; &gt; patch, "Add missing EPILOGUEs in assembly files", was applied back then.
&gt; &gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; &gt; Do you remember why you used GNU_CET_SECTION() explicitly in .asm files,
&gt; &gt; &gt; &gt; &gt; &gt; rather than using an m4 divert?
&gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; Not really I do not recall anymore, but I think there was a reason, as
&gt; &gt; &gt; &gt; &gt; I recall you made that comment back then and it "didn't work out" when
&gt; &gt; &gt; &gt; &gt; I tried is the memory I have of it.
&gt; &gt; &gt; &gt; &gt; Might have to do with differences in how it lays out the code when done
&gt; &gt; &gt; &gt; &gt; via m4 divert, but not 100% sure.
&gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; m4 divert  requires much less changes.   Here is the updated patch with
&gt; &gt; &gt; &gt; ASM_X86_ENDBR, ASM_X86_MARK_CET_ALIGN and ASM_X86_MARK_CET.
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; 
&gt; &gt; &gt; Two comments on your patch.
&gt; &gt; &gt; 
&gt; &gt; &gt; 1. It is an error to align based on architecture. All GNU Notes MUST be
&gt; &gt; &gt; aligned 8 bytes. Since 2018 GNU Libc ignores misaligned notes.
&gt; &gt; 
&gt; &gt; Ah nevermind this point, misunderstanding with my libc expert, the 4
&gt; &gt; bytes alignment is ok on 32 bit code.
&gt; &gt; 
&gt; &gt; &gt; 2. It is better to use .pushsection .popsection pairs around the note
&gt; &gt; &gt; instead of .section because of the side effects of using .section
&gt; 
&gt; Done.
&gt; 
&gt; &gt; &gt; The m4 divert looks smaller impact, feel free to lift the Gnu Note
&gt; &gt; &gt; section in my patch #3 and place it into your patch if you want. My
&gt; &gt; &gt; code also made it more explicit what all the sections values actually
&gt; &gt; &gt; mean which will help in long term maintenance if someone else need to
&gt; &gt; &gt; change anything (like for example changing to enable only ShadowStack
&gt; &gt; &gt; vs IBT).
&gt; &gt; &gt; 
&gt; 
&gt; Since CET support requires all objects are marked for CET,  CET marker on
&gt; assembly sources is controlled by compiler options, not by configure option.
&gt; Also linker can merge multiple .note.gnu.property sections in a single
&gt; input file:
&gt; 
&gt; [hjl@gnu-cfl-1 tmp]$ cat p.s
&gt; .pushsection ".note.gnu.property", "a"
&gt; .p2align 3
&gt; .long 1f - 0f
&gt; .long 4f - 1f
&gt; .long 5
&gt; 0:
&gt; .asciz "GNU"
&gt; 1:
&gt; .p2align 3
&gt; .long 0xc0000002
&gt; .long 3f - 2f
&gt; 2:
&gt; .long 1
&gt; 3:
&gt; .p2align 3
&gt; 4:
&gt; .popsection
&gt; .pushsection ".note.gnu.property", "a"
&gt; .p2align 3
&gt; .long 1f - 0f
&gt; .long 4f - 1f
&gt; .long 5
&gt; 0:
&gt; .asciz "GNU"
&gt; 1:
&gt; .p2align 3
&gt; .long 0xc0000002
&gt; .long 3f - 2f
&gt; 2:
&gt; .long 2
&gt; 3:
&gt; .p2align 3
&gt; 4:
&gt; .popsection
&gt; [hjl@gnu-cfl-1 tmp]$ as -o p.o p.s -mx86-used-note=no
&gt; [hjl@gnu-cfl-1 tmp]$ readelf -n p.o
&gt; 
&gt; Displaying notes found in: .note.gnu.property
&gt;   Owner                Data size Description
&gt;   GNU                  0x00000010 NT_GNU_PROPERTY_TYPE_0
&gt;       Properties: x86 feature: IBT
&gt;   GNU                  0x00000010 NT_GNU_PROPERTY_TYPE_0
&gt;       Properties: x86 feature: SHSTK
&gt; [hjl@gnu-cfl-1 tmp]$ ld -r p.o
&gt; [hjl@gnu-cfl-1 tmp]$ readelf -n a.out
&gt; 
&gt; Displaying notes found in: .note.gnu.property
&gt;   Owner                Data size Description
&gt;   GNU                  0x00000010 NT_GNU_PROPERTY_TYPE_0
&gt;       Properties: x86 feature: IBT, SHSTK
&gt; [hjl@gnu-cfl-1 tmp]$
&gt; 
&gt; New properties can be added without changing CET marker.
&gt; 
&gt; Here is the updated patch.

This patch looks good to me.
Unfortunately I never received the original email creating the thred,
did you send other patches too ?
Or is the prologue stuff sufficient to pass test suite in CET emulator?

-- 
Simo Sorce
RHEL Crypto Team
Red Hat, Inc




_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200317084017</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-03-17 08:40:17-0400</timestampReceived><subject>Adding code to support bcrypt-hash password verification</subject><body>

I tried to implement bcrypt-hash password verification using the
existing Nettle library.  As it seems, that is impossible without
messing with the internal state of the Blowfish encryption engine.

If I were to contribute some code that supports this, what are my chances
of getting it included in the Nettle library proper?
-- 
Stephen.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200318143857</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-03-18 14:38:57-0400</timestampReceived><subject>Re: Adding code to support bcrypt-hash password verification</subject><body>

I just submitted a patch for bcrypt support to Nettle.
Can this be included in Nettle?
If not, do I need to change anything in the patch to make it more
acceptable?

I need something like this in Nettle in order to be able to add code
to the standard libs of Pike which will support decoding of bcrypt-hashed
passwords.

P.S. I tried putting the code in a different C file; but then there are
some slight issues because the bcrypt code does refer to some (two)
internal identifiers in blowfish.c.  In order for this to work, the
two identifiers would need to be made externally visible; I considered
it namespace pollution and decided not to do it that way.
-- 
Stephen.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200309214208</emailId><senderName>Simo Sorce</senderName><senderEmail>simo@redhat.com</senderEmail><timestampReceived>2020-03-09 21:42:08-0400</timestampReceived><subject>Re: V3 [PATCH] x86: Add X86_ENDBR and CET marker to config.m4.in</subject><body>

On Mon, 2020-03-09 at 14:31 -0700, H.J. Lu wrote:
&gt; On Mon, Mar 9, 2020 at 2:15 PM Simo Sorce &lt;simo@redhat.com&gt; wrote:
&gt; &gt; On Mon, 2020-03-09 at 12:46 -0700, H.J. Lu wrote:
&gt; &gt; &gt; On Mon, Mar 9, 2020 at 12:22 PM Simo Sorce &lt;simo@redhat.com&gt; wrote:
&gt; &gt; &gt; &gt; On Mon, 2020-03-09 at 15:19 -0400, Simo Sorce wrote:
&gt; &gt; &gt; &gt; &gt; On Mon, 2020-03-09 at 11:56 -0700, H.J. Lu wrote:
&gt; &gt; &gt; &gt; &gt; &gt; On Mon, Mar 9, 2020 at 11:19 AM Simo Sorce &lt;simo@redhat.com&gt; wrote:
&gt; &gt; &gt; &gt; &gt; &gt; &gt; On Mon, 2020-03-09 at 19:03 +0100, Niels Möller wrote:
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Simo Sorce &lt;simo@redhat.com&gt; writes:
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; The patchset i solder than I did remember, April 2019
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; But I recall running at least one version of it on our CET emulator @
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Red Hat.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Sorry I forgot to followup on that. It seems only the first easy cleanup
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; patch, "Add missing EPILOGUEs in assembly files", was applied back then.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Do you remember why you used GNU_CET_SECTION() explicitly in .asm files,
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; rather than using an m4 divert?
&gt; &gt; &gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; &gt; &gt; Not really I do not recall anymore, but I think there was a reason, as
&gt; &gt; &gt; &gt; &gt; &gt; &gt; I recall you made that comment back then and it "didn't work out" when
&gt; &gt; &gt; &gt; &gt; &gt; &gt; I tried is the memory I have of it.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; Might have to do with differences in how it lays out the code when done
&gt; &gt; &gt; &gt; &gt; &gt; &gt; via m4 divert, but not 100% sure.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; &gt; m4 divert  requires much less changes.   Here is the updated patch with
&gt; &gt; &gt; &gt; &gt; &gt; ASM_X86_ENDBR, ASM_X86_MARK_CET_ALIGN and ASM_X86_MARK_CET.
&gt; &gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; Two comments on your patch.
&gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; 1. It is an error to align based on architecture. All GNU Notes MUST be
&gt; &gt; &gt; &gt; &gt; aligned 8 bytes. Since 2018 GNU Libc ignores misaligned notes.
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; Ah nevermind this point, misunderstanding with my libc expert, the 4
&gt; &gt; &gt; &gt; bytes alignment is ok on 32 bit code.
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; 2. It is better to use .pushsection .popsection pairs around the note
&gt; &gt; &gt; &gt; &gt; instead of .section because of the side effects of using .section
&gt; &gt; &gt; 
&gt; &gt; &gt; Done.
&gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; The m4 divert looks smaller impact, feel free to lift the Gnu Note
&gt; &gt; &gt; &gt; &gt; section in my patch #3 and place it into your patch if you want. My
&gt; &gt; &gt; &gt; &gt; code also made it more explicit what all the sections values actually
&gt; &gt; &gt; &gt; &gt; mean which will help in long term maintenance if someone else need to
&gt; &gt; &gt; &gt; &gt; change anything (like for example changing to enable only ShadowStack
&gt; &gt; &gt; &gt; &gt; vs IBT).
&gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; 
&gt; &gt; &gt; Since CET support requires all objects are marked for CET,  CET marker on
&gt; &gt; &gt; assembly sources is controlled by compiler options, not by configure option.
&gt; &gt; &gt; Also linker can merge multiple .note.gnu.property sections in a single
&gt; &gt; &gt; input file:
&gt; &gt; &gt; 
&gt; &gt; &gt; [hjl@gnu-cfl-1 tmp]$ cat p.s
&gt; &gt; &gt; .pushsection ".note.gnu.property", "a"
&gt; &gt; &gt; .p2align 3
&gt; &gt; &gt; .long 1f - 0f
&gt; &gt; &gt; .long 4f - 1f
&gt; &gt; &gt; .long 5
&gt; &gt; &gt; 0:
&gt; &gt; &gt; .asciz "GNU"
&gt; &gt; &gt; 1:
&gt; &gt; &gt; .p2align 3
&gt; &gt; &gt; .long 0xc0000002
&gt; &gt; &gt; .long 3f - 2f
&gt; &gt; &gt; 2:
&gt; &gt; &gt; .long 1
&gt; &gt; &gt; 3:
&gt; &gt; &gt; .p2align 3
&gt; &gt; &gt; 4:
&gt; &gt; &gt; .popsection
&gt; &gt; &gt; .pushsection ".note.gnu.property", "a"
&gt; &gt; &gt; .p2align 3
&gt; &gt; &gt; .long 1f - 0f
&gt; &gt; &gt; .long 4f - 1f
&gt; &gt; &gt; .long 5
&gt; &gt; &gt; 0:
&gt; &gt; &gt; .asciz "GNU"
&gt; &gt; &gt; 1:
&gt; &gt; &gt; .p2align 3
&gt; &gt; &gt; .long 0xc0000002
&gt; &gt; &gt; .long 3f - 2f
&gt; &gt; &gt; 2:
&gt; &gt; &gt; .long 2
&gt; &gt; &gt; 3:
&gt; &gt; &gt; .p2align 3
&gt; &gt; &gt; 4:
&gt; &gt; &gt; .popsection
&gt; &gt; &gt; [hjl@gnu-cfl-1 tmp]$ as -o p.o p.s -mx86-used-note=no
&gt; &gt; &gt; [hjl@gnu-cfl-1 tmp]$ readelf -n p.o
&gt; &gt; &gt; 
&gt; &gt; &gt; Displaying notes found in: .note.gnu.property
&gt; &gt; &gt;   Owner                Data size Description
&gt; &gt; &gt;   GNU                  0x00000010 NT_GNU_PROPERTY_TYPE_0
&gt; &gt; &gt;       Properties: x86 feature: IBT
&gt; &gt; &gt;   GNU                  0x00000010 NT_GNU_PROPERTY_TYPE_0
&gt; &gt; &gt;       Properties: x86 feature: SHSTK
&gt; &gt; &gt; [hjl@gnu-cfl-1 tmp]$ ld -r p.o
&gt; &gt; &gt; [hjl@gnu-cfl-1 tmp]$ readelf -n a.out
&gt; &gt; &gt; 
&gt; &gt; &gt; Displaying notes found in: .note.gnu.property
&gt; &gt; &gt;   Owner                Data size Description
&gt; &gt; &gt;   GNU                  0x00000010 NT_GNU_PROPERTY_TYPE_0
&gt; &gt; &gt;       Properties: x86 feature: IBT, SHSTK
&gt; &gt; &gt; [hjl@gnu-cfl-1 tmp]$
&gt; &gt; &gt; 
&gt; &gt; &gt; New properties can be added without changing CET marker.
&gt; &gt; &gt; 
&gt; &gt; &gt; Here is the updated patch.
&gt; &gt; 
&gt; &gt; This patch looks good to me.
&gt; &gt; Unfortunately I never received the original email creating the thred,
&gt; &gt; did you send other patches too ?
&gt; 
&gt; This is the only patch needed to enable CET.
&gt; 
&gt; &gt; Or is the prologue stuff sufficient to pass test suite in CET emulator?
&gt; &gt; 
&gt; 
&gt; It is sufficient to pass all tests on real CET processors with
&gt; 
&gt; $ CC="gcc -Wl,-z,cet-report=error -fcf-protection" CXX="g++
&gt; -Wl,-z,cet-report=error -fcf-protection"
&gt; /home/hjl/work/git/gitlab/nettle/configure

Excellent!

I wonder if we should create a negative test with an actual incorrect
jmp instruction to verify that CET is enabled, given it is very easy to
get the linker to disable CET if any dependency is not CET enabled.

When I ran the code in the emulator I manually added a jump to a non
endbr instruction to make sure it would fail, and it did :-)

-- 
Simo Sorce
RHEL Crypto Team
Red Hat, Inc




_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200309220935</emailId><senderName>Simo Sorce</senderName><senderEmail>simo@redhat.com</senderEmail><timestampReceived>2020-03-09 22:09:35-0400</timestampReceived><subject>Re: V3 [PATCH] x86: Add X86_ENDBR and CET marker to config.m4.in</subject><body>

On Mon, 2020-03-09 at 14:59 -0700, H.J. Lu wrote:
&gt; On Mon, Mar 9, 2020 at 2:42 PM Simo Sorce &lt;simo@redhat.com&gt; wrote:
&gt; &gt; On Mon, 2020-03-09 at 14:31 -0700, H.J. Lu wrote:
&gt; &gt; &gt; On Mon, Mar 9, 2020 at 2:15 PM Simo Sorce &lt;simo@redhat.com&gt; wrote:
&gt; &gt; &gt; &gt; On Mon, 2020-03-09 at 12:46 -0700, H.J. Lu wrote:
&gt; &gt; &gt; &gt; &gt; On Mon, Mar 9, 2020 at 12:22 PM Simo Sorce &lt;simo@redhat.com&gt; wrote:
&gt; &gt; &gt; &gt; &gt; &gt; On Mon, 2020-03-09 at 15:19 -0400, Simo Sorce wrote:
&gt; &gt; &gt; &gt; &gt; &gt; &gt; On Mon, 2020-03-09 at 11:56 -0700, H.J. Lu wrote:
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; On Mon, Mar 9, 2020 at 11:19 AM Simo Sorce &lt;simo@redhat.com&gt; wrote:
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; On Mon, 2020-03-09 at 19:03 +0100, Niels Möller wrote:
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Simo Sorce &lt;simo@redhat.com&gt; writes:
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; The patchset i solder than I did remember, April 2019
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; But I recall running at least one version of it on our CET emulator @
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Red Hat.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Sorry I forgot to followup on that. It seems only the first easy cleanup
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; patch, "Add missing EPILOGUEs in assembly files", was applied back then.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Do you remember why you used GNU_CET_SECTION() explicitly in .asm files,
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; rather than using an m4 divert?
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Not really I do not recall anymore, but I think there was a reason, as
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; I recall you made that comment back then and it "didn't work out" when
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; I tried is the memory I have of it.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Might have to do with differences in how it lays out the code when done
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; via m4 divert, but not 100% sure.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; m4 divert  requires much less changes.   Here is the updated patch with
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; ASM_X86_ENDBR, ASM_X86_MARK_CET_ALIGN and ASM_X86_MARK_CET.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; &gt; &gt; Two comments on your patch.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; &gt; &gt; 1. It is an error to align based on architecture. All GNU Notes MUST be
&gt; &gt; &gt; &gt; &gt; &gt; &gt; aligned 8 bytes. Since 2018 GNU Libc ignores misaligned notes.
&gt; &gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; &gt; Ah nevermind this point, misunderstanding with my libc expert, the 4
&gt; &gt; &gt; &gt; &gt; &gt; bytes alignment is ok on 32 bit code.
&gt; &gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; &gt; &gt; 2. It is better to use .pushsection .popsection pairs around the note
&gt; &gt; &gt; &gt; &gt; &gt; &gt; instead of .section because of the side effects of using .section
&gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; Done.
&gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; &gt; &gt; The m4 divert looks smaller impact, feel free to lift the Gnu Note
&gt; &gt; &gt; &gt; &gt; &gt; &gt; section in my patch #3 and place it into your patch if you want. My
&gt; &gt; &gt; &gt; &gt; &gt; &gt; code also made it more explicit what all the sections values actually
&gt; &gt; &gt; &gt; &gt; &gt; &gt; mean which will help in long term maintenance if someone else need to
&gt; &gt; &gt; &gt; &gt; &gt; &gt; change anything (like for example changing to enable only ShadowStack
&gt; &gt; &gt; &gt; &gt; &gt; &gt; vs IBT).
&gt; &gt; &gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; Since CET support requires all objects are marked for CET,  CET marker on
&gt; &gt; &gt; &gt; &gt; assembly sources is controlled by compiler options, not by configure option.
&gt; &gt; &gt; &gt; &gt; Also linker can merge multiple .note.gnu.property sections in a single
&gt; &gt; &gt; &gt; &gt; input file:
&gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; [hjl@gnu-cfl-1 tmp]$ cat p.s
&gt; &gt; &gt; &gt; &gt; .pushsection ".note.gnu.property", "a"
&gt; &gt; &gt; &gt; &gt; .p2align 3
&gt; &gt; &gt; &gt; &gt; .long 1f - 0f
&gt; &gt; &gt; &gt; &gt; .long 4f - 1f
&gt; &gt; &gt; &gt; &gt; .long 5
&gt; &gt; &gt; &gt; &gt; 0:
&gt; &gt; &gt; &gt; &gt; .asciz "GNU"
&gt; &gt; &gt; &gt; &gt; 1:
&gt; &gt; &gt; &gt; &gt; .p2align 3
&gt; &gt; &gt; &gt; &gt; .long 0xc0000002
&gt; &gt; &gt; &gt; &gt; .long 3f - 2f
&gt; &gt; &gt; &gt; &gt; 2:
&gt; &gt; &gt; &gt; &gt; .long 1
&gt; &gt; &gt; &gt; &gt; 3:
&gt; &gt; &gt; &gt; &gt; .p2align 3
&gt; &gt; &gt; &gt; &gt; 4:
&gt; &gt; &gt; &gt; &gt; .popsection
&gt; &gt; &gt; &gt; &gt; .pushsection ".note.gnu.property", "a"
&gt; &gt; &gt; &gt; &gt; .p2align 3
&gt; &gt; &gt; &gt; &gt; .long 1f - 0f
&gt; &gt; &gt; &gt; &gt; .long 4f - 1f
&gt; &gt; &gt; &gt; &gt; .long 5
&gt; &gt; &gt; &gt; &gt; 0:
&gt; &gt; &gt; &gt; &gt; .asciz "GNU"
&gt; &gt; &gt; &gt; &gt; 1:
&gt; &gt; &gt; &gt; &gt; .p2align 3
&gt; &gt; &gt; &gt; &gt; .long 0xc0000002
&gt; &gt; &gt; &gt; &gt; .long 3f - 2f
&gt; &gt; &gt; &gt; &gt; 2:
&gt; &gt; &gt; &gt; &gt; .long 2
&gt; &gt; &gt; &gt; &gt; 3:
&gt; &gt; &gt; &gt; &gt; .p2align 3
&gt; &gt; &gt; &gt; &gt; 4:
&gt; &gt; &gt; &gt; &gt; .popsection
&gt; &gt; &gt; &gt; &gt; [hjl@gnu-cfl-1 tmp]$ as -o p.o p.s -mx86-used-note=no
&gt; &gt; &gt; &gt; &gt; [hjl@gnu-cfl-1 tmp]$ readelf -n p.o
&gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; Displaying notes found in: .note.gnu.property
&gt; &gt; &gt; &gt; &gt;   Owner                Data size Description
&gt; &gt; &gt; &gt; &gt;   GNU                  0x00000010 NT_GNU_PROPERTY_TYPE_0
&gt; &gt; &gt; &gt; &gt;       Properties: x86 feature: IBT
&gt; &gt; &gt; &gt; &gt;   GNU                  0x00000010 NT_GNU_PROPERTY_TYPE_0
&gt; &gt; &gt; &gt; &gt;       Properties: x86 feature: SHSTK
&gt; &gt; &gt; &gt; &gt; [hjl@gnu-cfl-1 tmp]$ ld -r p.o
&gt; &gt; &gt; &gt; &gt; [hjl@gnu-cfl-1 tmp]$ readelf -n a.out
&gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; Displaying notes found in: .note.gnu.property
&gt; &gt; &gt; &gt; &gt;   Owner                Data size Description
&gt; &gt; &gt; &gt; &gt;   GNU                  0x00000010 NT_GNU_PROPERTY_TYPE_0
&gt; &gt; &gt; &gt; &gt;       Properties: x86 feature: IBT, SHSTK
&gt; &gt; &gt; &gt; &gt; [hjl@gnu-cfl-1 tmp]$
&gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; New properties can be added without changing CET marker.
&gt; &gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; Here is the updated patch.
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; This patch looks good to me.
&gt; &gt; &gt; &gt; Unfortunately I never received the original email creating the thred,
&gt; &gt; &gt; &gt; did you send other patches too ?
&gt; &gt; &gt; 
&gt; &gt; &gt; This is the only patch needed to enable CET.
&gt; &gt; &gt; 
&gt; &gt; &gt; &gt; Or is the prologue stuff sufficient to pass test suite in CET emulator?
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; 
&gt; &gt; &gt; It is sufficient to pass all tests on real CET processors with
&gt; &gt; &gt; 
&gt; &gt; &gt; $ CC="gcc -Wl,-z,cet-report=error -fcf-protection" CXX="g++
&gt; &gt; &gt; -Wl,-z,cet-report=error -fcf-protection"
&gt; &gt; &gt; /home/hjl/work/git/gitlab/nettle/configure
&gt; &gt; 
&gt; &gt; Excellent!
&gt; &gt; 
&gt; &gt; I wonder if we should create a negative test with an actual incorrect
&gt; &gt; jmp instruction to verify that CET is enabled, given it is very easy to
&gt; &gt; get the linker to disable CET if any dependency is not CET enabled.
&gt; &gt; 
&gt; &gt; When I ran the code in the emulator I manually added a jump to a non
&gt; &gt; endbr instruction to make sure it would fail, and it did :-)
&gt; &gt; 
&gt; 
&gt; I have some CET smoke tests in violations directory at
&gt; 
&gt; https://gitlab.com/cet-software/cet-smoke-test

I meant as part of Nettle, so hopefully we do not regress (once CET
enabled machines become available in CI systems).
We can have a simple binary that links to libnettle and libhogweed and
has inline assembly that jumps to a non ENDBR instruction. The test
will SUCCEED if the binary crashes... The test should run only if the
HW supports CET of course, I assume this is something that can be
tested via /proc/cpuinfo or similar methods ? 

Simo.

-- 
Simo Sorce
RHEL Crypto Team
Red Hat, Inc




_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200312205309</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-03-12 20:53:09-0400</timestampReceived><subject>Re: V3 [PATCH] x86: Add X86_ENDBR and CET marker to config.m4.in</subject><body>

"H.J. Lu" &lt;hjl.tools@gmail.com&gt; writes:

&gt; Here is the updated patch.

This V3 patch looks pretty nice to me. 

But I'm a bit confused by the use of ASM_X86_ENDBR. The instruction is
added to entry points, via the PROLOGUE macro, but not to other branch
targets, e.g., loop labels in the assembly files. Is that not needed
(because branches are direct, without going via PLT indirection)? Or
will the assembler insert some ENDBR instructions automatically?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200313125117</emailId><senderName>Simo Sorce</senderName><senderEmail>simo@redhat.com</senderEmail><timestampReceived>2020-03-13 12:51:17-0400</timestampReceived><subject>Re: V3 [PATCH] x86: Add X86_ENDBR and CET marker to config.m4.in</subject><body>

On Thu, 2020-03-12 at 21:53 +0100, Niels Möller wrote:
&gt; "H.J. Lu" &lt;hjl.tools@gmail.com&gt; writes:
&gt; 
&gt; &gt; Here is the updated patch.
&gt; 
&gt; This V3 patch looks pretty nice to me. 
&gt; 
&gt; But I'm a bit confused by the use of ASM_X86_ENDBR. The instruction is
&gt; added to entry points, via the PROLOGUE macro, but not to other branch
&gt; targets, e.g., loop labels in the assembly files. Is that not needed
&gt; (because branches are direct, without going via PLT indirection)? Or
&gt; will the assembler insert some ENDBR instructions automatically?

Hi Niels,
ENDBR is only needed at CALL targets or indirect jump targets, so not
needed for direct call. Actually theoretical harmful to add any ENDBR
you do not need, as you give more landing sites.

Simo.

-- 
Simo Sorce
RHEL Crypto Team
Red Hat, Inc




_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200314184711</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-03-14 18:47:11-0400</timestampReceived><subject>Re: V3 [PATCH] x86: Add X86_ENDBR and CET marker to config.m4.in</subject><body>

Simo Sorce &lt;simo@redhat.com&gt; writes:

&gt; On Thu, 2020-03-12 at 21:53 +0100, Niels Möller wrote:
&gt;&gt; But I'm a bit confused by the use of ASM_X86_ENDBR. The instruction is
&gt;&gt; added to entry points, via the PROLOGUE macro, but not to other branch
&gt;&gt; targets, e.g., loop labels in the assembly files. Is that not needed
&gt;&gt; (because branches are direct, without going via PLT indirection)? Or
&gt;&gt; will the assembler insert some ENDBR instructions automatically?
&gt;
&gt; ENDBR is only needed at CALL targets or indirect jump targets, so not
&gt; needed for direct call. Actually theoretical harmful to add any ENDBR
&gt; you do not need, as you give more landing sites.

Thanks for the explanation. Patch merged to master now.

Regards,
/Niels


-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200312210151</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-03-12 21:01:51-0400</timestampReceived><subject>Re: [PATCH 1/1] arm: Fix memxor for non-armv6+ big-endian systems</subject><body>

Michael Weiser &lt;michael.weiser@gmx.de&gt; writes:

&gt; ARM assembly adjustments for big-endian systems contained armv6+-only
&gt; instructions (rev) in generic arm memxor code. Replace those with an
&gt; actual conversion of the leftover byte store routines for big-endian
&gt; systems. This also provides a slight optimisation by removing the
&gt; additional instruction as well as increased symmetry between little- and
&gt; big-endian implementations.

Merged onto the master-update branch (to let the ci system verify that
ARM LE isn't broken). Thanks.

It would be nice to have arm be in the ci as well, but you need to
coordinate with Nikos. I have a somewhat fuzzy understanding of how it's
set up, and know very little about the various system images being used.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200307172951</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-03-07 17:29:51-0400</timestampReceived><subject>Re: [PATCH] x86: Add X86_ENDBR and CET marker to config.m4.in</subject><body>

On Sat, Mar 7, 2020 at 11:49 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; "H.J. Lu" &lt;hjl.tools@gmail.com&gt; writes:
&gt;
&gt; &gt; Intel Control-flow Enforcement Technology (CET):
&gt; &gt;
&gt; &gt; https://software.intel.com/en-us/articles/intel-sdm
&gt; &gt;
&gt; &gt; contains shadow stack (SHSTK) and indirect branch tracking (IBT).  When
&gt; &gt; CET is enabled, ELF object files must be marked with .note.gnu.property
&gt; &gt; section.  Also when IBT is enabled, all indirect branch targets must
&gt; &gt; start with ENDBR instruction.
&gt; &gt;
&gt; &gt; This patch adds X86_ENDBR and the CET marker to config.m4.in when CET
&gt; &gt; is enabled.  It updates PROLOGUE with X86_ENDBR.
&gt;
&gt; I'd like to have a look at what gcc produces. How is it enabled with
&gt; gcc? In the docs, I find
&gt;
&gt;   -mshstk
&gt;
&gt;     The -mshstk option enables shadow stack built-in functions from x86
&gt;     Control-flow Enforcement Technology (CET).
&gt;
&gt; but when I try compiling a trivial function,
&gt;
&gt;   $ cat foo-cet.c
&gt;   int foo(void) {return 0;}
&gt;   $ gcc -save-temps -c -mshstk foo-cet.c
&gt;
&gt; I get no endbr instruction and no note in the foo-cet.s. I'm using
&gt; gcc-8.3. I do get an
&gt;
&gt;   .section .note.GNU-stack,"",@progbits

I use -fcf-protection=full -mcet to determine if CET is available in
the compiler. (And subsequently run a test with the shadow stack
enabled).

I have not used -mshstk, but I may be testing for CET incorrectly.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200307173236</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-03-07 17:32:36-0400</timestampReceived><subject>Re: [PATCH] x86: Add X86_ENDBR and CET marker to config.m4.in</subject><body>

On Sat, Mar 7, 2020 at 12:29 PM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:
&gt;
&gt; On Sat, Mar 7, 2020 at 11:49 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt; &gt;
&gt; &gt; "H.J. Lu" &lt;hjl.tools@gmail.com&gt; writes:
&gt; &gt;
&gt; &gt; &gt; Intel Control-flow Enforcement Technology (CET):
&gt; &gt; &gt;
&gt; &gt; &gt; https://software.intel.com/en-us/articles/intel-sdm
&gt; &gt; &gt;
&gt; &gt; &gt; contains shadow stack (SHSTK) and indirect branch tracking (IBT).  When
&gt; &gt; &gt; CET is enabled, ELF object files must be marked with .note.gnu.property
&gt; &gt; &gt; section.  Also when IBT is enabled, all indirect branch targets must
&gt; &gt; &gt; start with ENDBR instruction.
&gt; &gt; &gt;
&gt; &gt; &gt; This patch adds X86_ENDBR and the CET marker to config.m4.in when CET
&gt; &gt; &gt; is enabled.  It updates PROLOGUE with X86_ENDBR.
&gt; &gt;
&gt; &gt; I'd like to have a look at what gcc produces. How is it enabled with
&gt; &gt; gcc? In the docs, I find
&gt; &gt;
&gt; &gt;   -mshstk
&gt; &gt;
&gt; &gt;     The -mshstk option enables shadow stack built-in functions from x86
&gt; &gt;     Control-flow Enforcement Technology (CET).
&gt; &gt;
&gt; &gt; but when I try compiling a trivial function,
&gt; &gt;
&gt; &gt;   $ cat foo-cet.c
&gt; &gt;   int foo(void) {return 0;}
&gt; &gt;   $ gcc -save-temps -c -mshstk foo-cet.c
&gt; &gt;
&gt; &gt; I get no endbr instruction and no note in the foo-cet.s. I'm using
&gt; &gt; gcc-8.3. I do get an
&gt; &gt;
&gt; &gt;   .section .note.GNU-stack,"",@progbits
&gt;
&gt; I use -fcf-protection=full -mcet to determine if CET is available in
&gt; the compiler. (And subsequently run a test with the shadow stack
&gt; enabled).
&gt;
&gt; I have not used -mshstk, but I may be testing for CET incorrectly.

By the way, I think I lifted those flags from
https://developers.redhat.com/blog/2018/03/21/compiler-and-linker-flags-gcc/
. I enabled it several years ago, so I could be mistaken.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200309123614</emailId><senderName>Simo Sorce</senderName><senderEmail>simo@redhat.com</senderEmail><timestampReceived>2020-03-09 12:36:14-0400</timestampReceived><subject>Re: [PATCH] x86: Add X86_ENDBR and CET marker to config.m4.in</subject><body>

On Sat, 2020-03-07 at 17:49 +0100, Niels Möller wrote:
&gt; "H.J. Lu" &lt;hjl.tools@gmail.com&gt; writes:
&gt; 
&gt; &gt; Intel Control-flow Enforcement Technology (CET):
&gt; &gt; 
&gt; &gt; https://software.intel.com/en-us/articles/intel-sdm
&gt; &gt; 
&gt; &gt; contains shadow stack (SHSTK) and indirect branch tracking (IBT).  When
&gt; &gt; CET is enabled, ELF object files must be marked with .note.gnu.property
&gt; &gt; section.  Also when IBT is enabled, all indirect branch targets must
&gt; &gt; start with ENDBR instruction.
&gt; &gt; 
&gt; &gt; This patch adds X86_ENDBR and the CET marker to config.m4.in when CET
&gt; &gt; is enabled.  It updates PROLOGUE with X86_ENDBR.
&gt; 
&gt; I'd like to have a look at what gcc produces. How is it enabled with
&gt; gcc? In the docs, I find
&gt; 
&gt;   -mshstk
&gt; 
&gt;     The -mshstk option enables shadow stack built-in functions from x86
&gt;     Control-flow Enforcement Technology (CET).
&gt; 
&gt; but when I try compiling a trivial function,
&gt; 
&gt;   $ cat foo-cet.c 
&gt;   int foo(void) {return 0;}
&gt;   $ gcc -save-temps -c -mshstk foo-cet.c 
&gt; 
&gt; I get no endbr instruction and no note in the foo-cet.s. I'm using
&gt; gcc-8.3. I do get an
&gt; 
&gt;   .section .note.GNU-stack,"",@progbits
&gt; 
&gt; corresponding to Nettle's ASM_MARK_NOEXEC_STACK
&gt; 
&gt; &gt; --- a/config.m4.in
&gt; &gt; +++ b/config.m4.in
&gt; &gt; @@ -8,6 +8,10 @@ define(&lt;ALIGN_LOG&gt;, &lt;@ASM_ALIGN_LOG@&gt;)dnl
&gt; &gt;  define(&lt;W64_ABI&gt;, &lt;@W64_ABI@&gt;)dnl
&gt; &gt;  define(&lt;RODATA&gt;, &lt;@ASM_RODATA@&gt;)dnl
&gt; &gt;  define(&lt;WORDS_BIGENDIAN&gt;, &lt;@ASM_WORDS_BIGENDIAN@&gt;)dnl
&gt; &gt; +define(&lt;X86_ENDBR&gt;,&lt;@X86_ENDBR@&gt;)dnl
&gt; &gt; +divert(1)
&gt; &gt; +@X86_GNU_PROPERTY@
&gt; &gt; +divert
&gt; &gt;  divert(1)
&gt; &gt;  @ASM_MARK_NOEXEC_STACK@
&gt; &gt;  divert
&gt; 
&gt; You can put the two properties in the same m4 divert. Also, please
&gt; rename the autoconf substitutions with ASM_ prefix, and something more
&gt; descriptive than X64_GNU_PROPERTY. E.g., ASM_X86_ENDBR and
&gt; ASM_X86_MARK_CET.
&gt; 
&gt; &gt; diff --git a/configure.ac b/configure.ac
&gt; &gt; index ba3ab7c6..e9ed630c 100644
&gt; &gt; --- a/configure.ac
&gt; &gt; +++ b/configure.ac
&gt; &gt; @@ -803,6 +803,82 @@ EOF
&gt; &gt;    ASM_ALIGN_LOG="$nettle_cv_asm_align_log"
&gt; &gt;  fi
&gt; &gt;  
&gt; &gt; +dnl  Define
&gt; &gt; +dnl  1. X86_ENDBR for endbr32/endbr64.
&gt; &gt; +dnl  2. X86_GNU_PROPERTY to add a .note.gnu.property section to mark
&gt; &gt; +dnl  Intel CET support if needed.
&gt; &gt; +dnl	.section ".note.gnu.property", "a"
&gt; &gt; +dnl	.p2align POINTER-ALIGN
&gt; &gt; +dnl	.long 1f - 0f
&gt; &gt; +dnl	.long 4f - 1f
&gt; &gt; +dnl	.long 5
&gt; &gt; +dnl 0:
&gt; &gt; +dnl	.asciz "GNU"
&gt; &gt; +dnl 1:
&gt; &gt; +dnl	.p2align POINTER-ALIGN
&gt; &gt; +dnl	.long 0xc0000002
&gt; &gt; +dnl	.long 3f - 2f
&gt; &gt; +dnl 2:
&gt; &gt; +dnl	.long 3
&gt; &gt; +dnl 3:
&gt; &gt; +dnl	.p2align POINTER-ALIGN
&gt; &gt; +dnl 4:
&gt; 
&gt; No need to repeat the definition in full in this comment. And as I think
&gt; I've said before, I'm a bit surprised that it needs to be this verbose.
&gt; 
&gt; &gt; +AC_CACHE_CHECK([if Intel CET is enabled],
&gt; &gt; +  [nettle_cv_asm_x86_intel_cet],
&gt; &gt; +  [AC_TRY_COMPILE([
&gt; &gt; +#ifndef __CET__
&gt; &gt; +#error Intel CET is not enabled
&gt; &gt; +#endif
&gt; &gt; +  ], [],
&gt; &gt; +  [nettle_cv_asm_x86_intel_cet=yes],
&gt; &gt; +  [nettle_cv_asm_x86_intel_cet=no])])
&gt; &gt; +if test "$nettle_cv_asm_x86_intel_cet" = yes; then
&gt; &gt; +  case $ABI in
&gt; &gt; +  32|standard)
&gt; &gt; +    X86_ENDBR=endbr32
&gt; &gt; +    p2align=2
&gt; &gt; +    ;;
&gt; &gt; +  64)
&gt; &gt; +    X86_ENDBR=endbr64
&gt; &gt; +    p2align=3
&gt; &gt; +    ;;
&gt; &gt; +  x32)
&gt; &gt; +    X86_ENDBR=endbr64
&gt; &gt; +    p2align=2
&gt; &gt; +    ;;
&gt; &gt; +  esac
&gt; &gt; +  AC_CACHE_CHECK([if .note.gnu.property section is needed],
&gt; &gt; +    [nettle_cv_asm_x86_gnu_property],
&gt; &gt; +    [AC_TRY_COMPILE([
&gt; &gt; +#if !defined __ELF__ || !defined __CET__
&gt; &gt; +#error GNU property is not needed
&gt; &gt; +#endif
&gt; &gt; +    ], [],
&gt; &gt; +    [nettle_cv_asm_x86_gnu_property=yes],
&gt; &gt; +    [nettle_cv_asm_x86_gnu_property=no])])
&gt; &gt; +else
&gt; &gt; +  nettle_cv_asm_x86_gnu_property=no
&gt; &gt; +fi
&gt; &gt; +if test "$nettle_cv_asm_x86_gnu_property" = yes; then
&gt; &gt; +  X86_GNU_PROPERTY="
&gt; &gt; +	.section \".note.gnu.property\", \"a\"
&gt; &gt; +	.p2align $p2align
&gt; &gt; +	.long 1f - 0f
&gt; &gt; +	.long 4f - 1f
&gt; &gt; +	.long 5
&gt; &gt; +0:
&gt; &gt; +	.asciz \"GNU\"
&gt; &gt; +1:
&gt; &gt; +	.p2align $p2align
&gt; &gt; +	.long 0xc0000002
&gt; &gt; +	.long 3f - 2f
&gt; &gt; +2:
&gt; &gt; +	.long 3
&gt; &gt; +3:
&gt; &gt; +	.p2align $p2align
&gt; &gt; +4:"
&gt; &gt; +fi
&gt; 
&gt; Maybe a bit easier to read if you use single quotes for
&gt; X86_GNU_PROPERTY='...', don't escape the inner double quotes. That
&gt; leaves the expansion of $p2align, maybe it's better to define a separate
&gt; substituted variable for pointer alignment? (If there's no easier way to
&gt; enforce pointer-alignment).

Niels,
I sent patches longa few months ago on the list to enable CET, they
already went through review, any reason why we are looking at a
different set and restarting review from scratch now?

(sorry for not catching earlier, we seem to be having some delivery
issues and sometimes mailing list post are not reaching me, please keep
me in direct CC for now, hopefully that will help :-/ )

Simo.

-- 
Simo Sorce
RHEL Crypto Team
Red Hat, Inc




_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200316185013</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-03-16 18:50:13-0400</timestampReceived><subject>Re: [PATCH] x86: Build with -z ibt -z shstk if possible</subject><body>

"H.J. Lu" &lt;hjl.tools@gmail.com&gt; writes:

&gt; Here is the patch.
&gt;
&gt; -- 
&gt; H.J.
&gt;
&gt; From 6ba393c2e4eafc90d4e50365e740a1eeb04522d3 Mon Sep 17 00:00:00 2001
&gt; From: "H.J. Lu" &lt;hjl.tools@gmail.com&gt;
&gt; Date: Mon, 16 Mar 2020 05:17:34 -0700
&gt; Subject: [PATCH] x86: Build with -z ibt -z shstk if possible
&gt;
&gt; On Linux/x86, -fcf-protection must be used with GCC to enabele CET.  In
&gt; assembly sources, which must be properly marked wuth .note.gnu.property
&gt; section, all indirect branch targets must start with ENDBR instruction.
&gt; Linker can enable CET support in executable and shared library with
&gt; -z ibt -z shstk option even if CET isn't properly enabled in all input
&gt; files.  This has no impact on non-CET Linux OS.  On CET Linux OS, tests
&gt; will fail if any sources aren't properly CET enabled.

Hi, this confuses me a bit, in two ways:

1. Why do we need to pass linker flags with -Wl,...? Isn't it enough to
   pass appropriate flags to the gcc frontend, and let it pass them
   through?

2. What I tried to ask about in the message you reply to, was how to
   write a test within the Nettle testsuite, to verify that enabling CET
   really has effect on a test executable (on systems where it is
   expected to have effect). It's not obvious to me if and how the patch
   improves that.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200322182201</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-03-22 18:22:01-0400</timestampReceived><subject>Re: [PATCH] x86: Add x86-ibt-test.c</subject><body>

"H.J. Lu" &lt;hjl.tools@gmail.com&gt; writes:

&gt; Here is the updated patch.

Thanks!

&gt; +#ifdef __i386__
&gt; +static unsigned int
&gt; +_get_ssp(void)
&gt; +{
&gt; +  unsigned int ssp;
&gt; +  asm volatile("xor %0, %0\n\trdsspd %0" : "=r" (ssp));
&gt; +  return ssp;
&gt; +}
&gt; +#else

I take it the rdssp instruction is a nop on older processors? I had a
quick look at
https://software.intel.com/sites/default/files/managed/4d/2a/control-flow-enforcement-technology-preview.pdf
 and I don't find any mention of a cpuid bit to check before using this
instruction.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200323025353</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-03-23 02:53:53-0400</timestampReceived><subject>[PATCH] (revision 3.0) Added bcrypt() support.</subject><body>

---
 Makefile.in                       |   2 +-
 base64-decode.c                   |  17 +-
 blowfish-bcrypt.c                 | 531 ++++++++++++++++++++++++++++++
 blowfish.h =&gt; blowfish-internal.h |  51 +--
 blowfish.c                        |  23 +-
 blowfish.h                        |  15 +
 nettle.texinfo                    |  67 ++++
 7 files changed, 640 insertions(+), 66 deletions(-)
 create mode 100644 blowfish-bcrypt.c
 copy blowfish.h =&gt; blowfish-internal.h (50%)

diff --git a/Makefile.in b/Makefile.in
index ddc30428..bfb7ac57 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -73,7 +73,7 @@ nettle_SOURCES = aes-decrypt-internal.c aes-decrypt.c \
 		 aes256-set-encrypt-key.c aes256-set-decrypt-key.c \
 		 aes256-meta.c \
 		 arcfour.c arcfour-crypt.c \
-		 arctwo.c arctwo-meta.c blowfish.c \
+		 arctwo.c arctwo-meta.c blowfish.c blowfish-bcrypt.c \
 		 base16-encode.c base16-decode.c base16-meta.c \
 		 base64-encode.c base64-decode.c base64-meta.c \
 		 base64url-encode.c base64url-decode.c base64url-meta.c \
diff --git a/base64-decode.c b/base64-decode.c
index b993117a..9273224a 100644
--- a/base64-decode.c
+++ b/base64-decode.c
@@ -45,7 +45,7 @@
 void
 base64_decode_init(struct base64_decode_ctx *ctx)
 {
-  static const signed char base64_decode_table[0x100] =
+  static const signed char base64_decode_table[0x80] =
     {
       /* White space is HT, VT, FF, CR, LF and SPC */
       -1, -1, -1, -1, -1, -1, -1, -1, -1, -2, -2, -2, -2, -2, -1, -1, 
@@ -56,14 +56,6 @@ base64_decode_init(struct base64_decode_ctx *ctx)
       15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, -1, -1, -1, -1, -1,
       -1, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,
       41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
     };
 
   ctx-&gt;word = ctx-&gt;bits = ctx-&gt;padding = 0;
@@ -75,7 +67,12 @@ base64_decode_single(struct base64_decode_ctx *ctx,
 		     uint8_t *dst,
 		     char src)
 {
-  int data = ctx-&gt;table[(uint8_t) src];
+  int data;
+
+  if ((uint8_t) src &gt; 0x7f)
+    return -1;
+
+  data = ctx-&gt;table[(uint8_t) src];
 
   switch(data)
     {
diff --git a/blowfish-bcrypt.c b/blowfish-bcrypt.c
new file mode 100644
index 00000000..60bbd090
--- /dev/null
+++ b/blowfish-bcrypt.c
@@ -0,0 +1,531 @@
+/* blowfish-bcrypt.c
+
+   The blowfish bcrypt implementation.
+
+   Copyright (c) 2020 Stephen R. van den Berg
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+#include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;string.h&gt;
+#include &lt;stdlib.h&gt;
+
+#include "blowfish.h"
+#include "blowfish-internal.h"
+#include "base64.h"
+
+#include "macros.h"
+
+#define CRYPTPLEN 7
+#define SALTLEN ((BLOWFISH_BCRYPT_BINSALT_SIZE*8+5) / 6)
+
+#define HASHOFFSET (CRYPTPLEN + SALTLEN)
+
+static const signed char radix64_decode_table[0x80] = {
+  /* White space is HT, VT, FF, CR, LF and SPC */
+  -1, -1, -1, -1, -1, -1, -1, -1, -1, -2, -2, -2, -2, -2, -1, -1,
+  -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+  -2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  1,
+  54, 55, 56, 57, 58, 59, 60, 61, 62, 63, -1, -1, -1, -3, -1, -1,
+  -1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,
+  17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, -1, -1, -1, -1, -1,
+  -1, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42,
+  43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, -1, -1, -1, -1, -1,
+};
+
+static const char radix64_encode_table[64] =
+  "./ABCDEFGHIJKLMNOPQRSTUVWXYZ"
+    "abcdefghijklmnopqrstuvwxyz"
+    "0123456789";
+
+int
+blowfish_bcrypt_verify(const char *key,
+                       const char *hashed)
+{
+  char newhash[BLOWFISH_BCRYPT_HASH_SIZE];
+
+  return blowfish_bcrypt_hash(sizeof newhash,
+                              newhash, key, hashed, -1, (void*)0)
+   &amp;&amp; !strcmp(newhash, hashed);
+}
+
+static char *encode_radix64(char *dst, size_t len, const uint8_t *src)
+{
+  struct base64_encode_ctx ctx;
+  base64_encode_init(&amp;ctx);
+  ctx.alphabet = radix64_encode_table;
+  dst += base64_encode_update(&amp;ctx, dst, len, src);
+  dst += base64_encode_final(&amp;ctx, dst);
+  *--dst = '\0';	    /* Strip the trailing = */
+  return dst;
+}
+
+/*
+ * Large parts of the code below are based on public domain sources.
+ * The comments and copyright notices have been preserved.
+ * Any code added or modified by me is licensed under the
+ * licenses listed above.  --  Stephen R. van den Berg
+ */
+
+/*
+ * This code comes from John the Ripper password cracker, with reentrant
+ * and crypt(3) interfaces added, but optimizations specific to password
+ * cracking removed.
+ *
+ * Written by Solar Designer &lt;solar at openwall.com&gt; in 1998-2015.
+ * No copyright is claimed, and the software is hereby placed in the public
+ * domain. In case this attempt to disclaim copyright and place the software
+ * in the public domain is deemed null and void, then the software is
+ * Copyright (c) 1998-2015 Solar Designer and it is hereby released to the
+ * general public under the following terms:
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted.
+ *
+ * There's ABSOLUTELY NO WARRANTY, express or implied.
+ *
+ * It is my intent that you should be able to use this on your system,
+ * as part of a software package, or anywhere else to improve security,
+ * ensure compatibility, or for any other purpose. I would appreciate
+ * it if you give credit where it is due and keep your modifications in
+ * the public domain as well, but I don't require that in order to let
+ * you place this code and any modifications you make under a license
+ * of your choice.
+ *
+ * This implementation is fully compatible with OpenBSD's bcrypt.c for prefix
+ * "$2b$", originally by Niels Provos &lt;provos at citi.umich.edu&gt;, and it uses
+ * some of his ideas. The password hashing algorithm was designed by David
+ * Mazieres &lt;dm at lcs.mit.edu&gt;. For information on the level of
+ * compatibility for bcrypt hash prefixes other than "$2b$", please refer to
+ * the comments in set_key() below and to the included crypt(3) man page.
+ */
+
+typedef uint32_t bf_key[_BLOWFISH_ROUNDS + 2];
+
+/*
+ * Magic IV for 64 Blowfish encryptions that we do at the end.
+ * The string is "OrpheanBeholderScryDoubt" on big-endian.
+ */
+static uint32_t magic_w[6] = {
+  0x4F727068, 0x65616E42, 0x65686F6C,
+  0x64657253, 0x63727944, 0x6F756274
+};
+
+static void swap32(uint32_t *x, int count)
+{
+#if !WORDS_BIGENDIAN
+  do {
+    uint32_t tmp = *x;
+    tmp = (tmp &lt;&lt; 16) | (tmp &gt;&gt; 16);
+    *x++ = ((tmp &amp; 0x00FF00FF) &lt;&lt; 8) | ((tmp &gt;&gt; 8) &amp; 0x00FF00FF);
+  } while (--count);
+#endif
+}
+
+static void set_xkey(const char *key, bf_key expanded, bf_key initial,
+    unsigned bug, uint32_t safety)
+{
+  const char *ptr = key;
+  unsigned i, j;
+  uint32_t sign, diff, tmp[2];
+
+/*
+ * There was a sign extension bug in older revisions of this function. While
+ * we would have liked to simply fix the bug and move on, we have to provide
+ * a backwards compatibility feature (essentially the bug) for some systems and
+ * a safety measure for some others. The latter is needed because for certain
+ * multiple inputs to the buggy algorithm there exist easily found inputs to
+ * the correct algorithm that produce the same hash. Thus, we optionally
+ * deviate from the correct algorithm just enough to avoid such collisions.
+ * While the bug itself affected the majority of passwords containing
+ * characters with the 8th bit set (although only a percentage of those in a
+ * collision-producing way), the anti-collision safety measure affects
+ * only a subset of passwords containing the '\xff' character (not even all of
+ * those passwords, just some of them). This character is not found in valid
+ * UTF-8 sequences and is rarely used in popular 8-bit character encodings.
+ * Thus, the safety measure is unlikely to cause much annoyance, and is a
+ * reasonable tradeoff to use when authenticating against existing hashes that
+ * are not reliably known to have been computed with the correct algorithm.
+ *
+ * We use an approach that tries to minimize side-channel leaks of password
+ * information - that is, we mostly use fixed-cost bitwise operations instead
+ * of branches or table lookups. (One conditional branch based on password
+ * length remains. It is not part of the bug aftermath, though, and is
+ * difficult and possibly unreasonable to avoid given the use of C strings by
+ * the caller, which results in similar timing leaks anyway.)
+ *
+ * For actual implementation, we set an array index in the variable "bug"
+ * (0 means no bug, 1 means sign extension bug emulation) and a flag in the
+ * variable "safety" (bit 16 is set when the safety measure is requested).
+ * Valid combinations of settings are:
+ *
+ * Prefix "$2a$": bug = 0, safety = 0x10000
+ * Prefix "$2b$": bug = 0, safety = 0
+ * Prefix "$2x$": bug = 1, safety = 0
+ * Prefix "$2y$": bug = 0, safety = 0
+ */
+
+  sign = diff = 0;
+
+  for (i = 0; i &lt; _BLOWFISH_ROUNDS + 2; i++) {
+    tmp[0] = tmp[1] = 0;
+    for (j = 0; j &lt; 4; j++) {
+      tmp[0] &lt;&lt;= 8;
+      tmp[0] |= (unsigned char)*ptr; /* correct */
+      tmp[1] &lt;&lt;= 8;
+      tmp[1] |= (signed char)*ptr; /* bug */
+/*
+ * Sign extension in the first char has no effect - nothing to overwrite yet,
+ * and those extra 24 bits will be fully shifted out of the 32-bit word. For
+ * chars 2, 3, 4 in each four-char block, we set bit 7 of "sign" if sign
+ * extension in tmp[1] occurs. Once this flag is set, it remains set.
+ */
+      if (j)
+        sign |= tmp[1] &amp; 0x80;
+      if (!*ptr)
+        ptr = key;
+      else
+        ptr++;
+    }
+    diff |= tmp[0] ^ tmp[1]; /* Non-zero on any differences */
+
+    expanded[i] = tmp[bug];
+    initial[i] = _nettle_blowfish_initial_ctx.p[i] ^ tmp[bug];
+  }
+
+/*
+ * At this point, "diff" is zero if the correct and buggy algorithms produced
+ * exactly the same result. If so and if "sign" is non-zero, which indicates
+ * that there was a non-benign sign extension, this means that we have a
+ * collision between the correctly computed hash for this password and a set of
+ * passwords that could be supplied to the buggy algorithm. Our safety measure
+ * is meant to protect from such many-buggy to one-correct collisions, by
+ * deviating from the correct algorithm in such cases. Let's check for this.
+ */
+  diff |= diff &gt;&gt; 16; /* still zero if exact match */
+  diff &amp;= 0xffff; /* ditto */
+  diff += 0xffff; /* bit 16 set if "diff" was non-zero (on non-match) */
+  sign &lt;&lt;= 9; /* move the non-benign sign extension flag to bit 16 */
+  sign &amp;= ~diff &amp; safety; /* action needed? */
+
+/*
+ * If we have determined that we need to deviate from the correct algorithm,
+ * flip bit 16 in initial expanded key. (The choice of 16 is arbitrary, but
+ * let's stick to it now. It came out of the approach we used above, and it's
+ * not any worse than any other choice we could make.)
+ *
+ * It is crucial that we don't do the same to the expanded key used in the main
+ * Eksblowfish loop. By doing it to only one of these two, we deviate from a
+ * state that could be directly specified by a password to the buggy algorithm
+ * (and to the fully correct one as well, but that's a side-effect).
+ */
+  initial[0] ^= sign;
+}
+
+static int ibcrypt(size_t length, char *dst,
+                   const char *key, const char *scheme,
+		   int minlog2rounds,
+		   int log2rounds, const uint8_t *salt)
+{
+  struct {
+    struct blowfish_ctx ctx;
+    bf_key expanded_key;
+    union {
+      uint32_t salt[4];
+      uint32_t output[6];
+    } binary;
+  } data;
+  uint8_t psalt[BLOWFISH_BCRYPT_BINSALT_SIZE];
+  uint32_t L, R;
+  uint32_t *ptr;
+  uint32_t count;
+  int i;
+  size_t schemelen = strlen(scheme);
+  unsigned cscheme;
+  unsigned bug = 0;
+  uint32_t safety = 0;
+  if (length &lt; BLOWFISH_BCRYPT_HASH_SIZE ||
+      schemelen &lt; 2)
+    return 0;
+
+  if (schemelen &gt;= 3 &amp;&amp; *scheme++ != '$')
+    return 0;
+  if (*scheme++ != '2')
+    return 0;
+
+  switch (cscheme = *scheme++) {
+    default:
+      return 0;
+    case 'a': safety = 0x10000;
+      break;
+    case 'x': bug = 1;
+      break;
+    case 'b': case 'y':
+      break;
+  }
+
+  if (schemelen &gt;= 4) {
+    if (*scheme++ != '$')
+      return 0;
+    if (schemelen &gt;= 6) {
+      if (log2rounds &lt; 0)
+        log2rounds = atoi(scheme);
+      scheme += 2;
+      if (schemelen &gt;= CRYPTPLEN &amp;&amp; *scheme++ != '$')
+	return 0;
+      if (schemelen &gt;= HASHOFFSET &amp;&amp; !salt) {
+        struct base64_decode_ctx ctx;
+        size_t saltlen = BLOWFISH_BCRYPT_BINSALT_SIZE;
+
+        base64_decode_init(&amp;ctx);
+        ctx.table = radix64_decode_table;
+
+        if (!base64_decode_update(&amp;ctx, &amp;saltlen, (uint8_t *) data.binary.salt,
+                                  SALTLEN, scheme)
+         || saltlen != BLOWFISH_BCRYPT_BINSALT_SIZE)
+          return 0;
+      }
+    }
+  }
+
+  if (salt)
+    memcpy(data.binary.salt, salt, BLOWFISH_BCRYPT_BINSALT_SIZE);
+  else if (schemelen &lt; HASHOFFSET)
+    return 0;
+  memcpy(psalt, data.binary.salt, BLOWFISH_BCRYPT_BINSALT_SIZE);
+  swap32(data.binary.salt, 4);
+
+  if (log2rounds &lt; minlog2rounds || log2rounds &gt; 31)
+    return 0;
+  count = (uint32_t)1 &lt;&lt; log2rounds;
+
+  set_xkey(key, data.expanded_key, data.ctx.p, bug, safety);
+  memcpy(data.ctx.s, _nettle_blowfish_initial_ctx.s, sizeof(data.ctx.s));
+
+  L = R = 0;
+  for (i = 0; i &lt; _BLOWFISH_ROUNDS + 2; i += 2) {
+    L ^= data.binary.salt[i &amp; 2];
+    R ^= data.binary.salt[(i &amp; 2) + 1];
+    _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+    data.ctx.p[i] = L;
+    data.ctx.p[i + 1] = R;
+  }
+
+  ptr = data.ctx.s[0];
+  do {
+    ptr += 4;
+    L ^= data.binary.salt[(_BLOWFISH_ROUNDS + 2) &amp; 3];
+    R ^= data.binary.salt[(_BLOWFISH_ROUNDS + 3) &amp; 3];
+    _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+    *(ptr - 4) = L;
+    *(ptr - 3) = R;
+
+    L ^= data.binary.salt[(_BLOWFISH_ROUNDS + 4) &amp; 3];
+    R ^= data.binary.salt[(_BLOWFISH_ROUNDS + 5) &amp; 3];
+    _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+    *(ptr - 2) = L;
+    *(ptr - 1) = R;
+  } while (ptr &lt; &amp;data.ctx.s[3][0xFF]);
+
+  do {
+    int done;
+
+    for (i = 0; i &lt; _BLOWFISH_ROUNDS + 2; i += 2) {
+      data.ctx.p[i] ^= data.expanded_key[i];
+      data.ctx.p[i + 1] ^= data.expanded_key[i + 1];
+    }
+
+    done = 0;
+    do {
+      uint32_t tmp1, tmp2, tmp3, tmp4;
+
+      L = R = 0;
+      ptr = data.ctx.p;
+      do {
+        ptr += 2;
+        _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+        *(ptr - 2) = L;
+        *(ptr - 1) = R;
+      } while (ptr &lt; &amp;data.ctx.p[_BLOWFISH_ROUNDS + 2]);
+
+      ptr = data.ctx.s[0];
+      do {
+        ptr += 2;
+        _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+        *(ptr - 2) = L;
+        *(ptr - 1) = R;
+      } while (ptr &lt; &amp;data.ctx.s[3][0xFF]);
+
+      if (done)
+        break;
+      done = 1;
+
+      tmp1 = data.binary.salt[0];
+      tmp2 = data.binary.salt[1];
+      tmp3 = data.binary.salt[2];
+      tmp4 = data.binary.salt[3];
+      for (i = 0; i &lt; _BLOWFISH_ROUNDS; i += 4) {
+        data.ctx.p[i] ^= tmp1;
+        data.ctx.p[i + 1] ^= tmp2;
+        data.ctx.p[i + 2] ^= tmp3;
+        data.ctx.p[i + 3] ^= tmp4;
+      }
+      data.ctx.p[16] ^= tmp1;
+      data.ctx.p[17] ^= tmp2;
+    } while (1);
+  } while (--count);
+
+  for (i = 0; i &lt; 6; i += 2) {
+    L = magic_w[i];
+    R = magic_w[i + 1];
+
+    count = 64;
+    do
+      _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+    while (--count);
+
+    data.binary.output[i] = L;
+    data.binary.output[i + 1] = R;
+  }
+
+  *dst++ = '$';
+  *dst++ = '2';
+  *dst++ = cscheme;
+  *dst++ = '$';
+  *dst++ = '0' + log2rounds / 10;
+  *dst++ = '0' + log2rounds % 10;
+  *dst++ = '$';
+  dst = encode_radix64(dst, BLOWFISH_BCRYPT_BINSALT_SIZE, psalt) - 1;
+
+  swap32(data.binary.output, 6);
+/* This has to be bug-compatible with the original implementation, so
+   only encode 23 of the 24 bytes. */
+  encode_radix64(dst, 23, (uint8_t *) data.binary.output);
+  return cscheme;
+}
+
+static
+int bcrypt_output_magic(const char *settings, char *output, int size)
+{
+  if (size &lt; 3)
+    return -1;
+
+  output[0] = '*';
+  output[1] = '0';
+  output[2] = '\0';
+
+  if (settings[0] == '*' &amp;&amp; settings[1] == '0')
+    output[1] = '1';
+
+  return 0;
+}
+
+/*
+ * Please preserve the runtime self-test. It serves two purposes at once:
+ *
+ * 1. We really can't afford the risk of producing incompatible hashes e.g.
+ * when there's something like gcc bug 26587 again, whereas an application or
+ * library integrating this code might not also integrate our external tests or
+ * it might not run them after every build. Even if it does, the miscompile
+ * might only occur on the production build, but not on a testing build (such
+ * as because of different optimization settings). It is painful to recover
+ * from incorrectly-computed hashes - merely fixing whatever broke is not
+ * enough. Thus, a proactive measure like this self-test is needed.
+ *
+ * 2. We don't want to leave sensitive data from our actual password hash
+ * computation on the stack or in registers. Previous revisions of the code
+ * would do explicit cleanups, but simply running the self-test after hash
+ * computation is more reliable.
+ *
+ * The performance cost of this quick self-test is around 0.6% at the "$2a$08"
+ * setting.
+ */
+int blowfish_bcrypt_hash(size_t length, char *dst,
+                         const char *key, const char *scheme,
+			 int log2rounds, const uint8_t *salt)
+{
+  const char *test_pw = "8b \xd0\xc1\xd2\xcf\xcc\xd8";
+  const char *test_scheme = "$2a$00$abcdefghijklmnopqrstuu";
+  static const char * const test_hashes[2] =
+    {"i1D709vfamulimlGcq0qq3UvuUasvEa\0\x55",  /* 'a', 'b', 'y' */
+     "VUrPmXD6q/nVSSp7pNDhCR9071IfIRe\0\x55"}; /* 'x' */
+  const char *test_hash = test_hashes[0];
+  int cscheme;
+  int ok;
+  struct {
+    char s[HASHOFFSET + 1];
+    char o[HASHOFFSET + 31 + 1 + 1 + 1];
+  } buf;
+
+/* Hash the supplied password */
+  bcrypt_output_magic(scheme, dst, length);
+  cscheme = ibcrypt(length, dst, key, scheme, 4, log2rounds, salt);
+
+/*
+ * Do a quick self-test. It is important that we make both calls to ibcrypt()
+ * from the same scope such that they likely use the same stack locations,
+ * which makes the second call overwrite the first call's sensitive data on the
+ * stack and makes it more likely that any alignment related issues would be
+ * detected by the self-test.
+ */
+  memcpy(buf.s, test_scheme, sizeof(buf.s));
+
+  if (cscheme)
+    test_hash = test_hashes[(buf.s[2] = cscheme) == 'x'];
+
+  memset(buf.o, 0x55, sizeof(buf.o));
+  buf.o[sizeof(buf.o) - 1] = 0;
+  ok = ibcrypt(sizeof(buf.o) - (1 + 1), buf.o, test_pw,
+               buf.s, 0, -1, (void*)0);
+
+  ok = (ok &amp;&amp;
+      !memcmp(buf.o, buf.s, HASHOFFSET) &amp;&amp;
+      !memcmp(buf.o + HASHOFFSET, test_hash, 31 + 1 + 1 + 1));
+
+  {
+    const char *k = "\xff\xa3" "34" "\xff\xff\xff\xa3" "345";
+    bf_key ae, ai, ye, yi;
+    set_xkey(k, ae, ai, 0, 0x10000); /* $2a$ */
+    set_xkey(k, ye, yi, 0, 0); /* $2y$ */
+    ai[0] ^= 0x10000; /* undo the safety (for comparison) */
+    ok = ok &amp;&amp; ai[0] == 0xdb9c59bc &amp;&amp; ye[17] == 0x33343500 &amp;&amp;
+        !memcmp(ae, ye, sizeof(ae)) &amp;&amp;
+        !memcmp(ai, yi, sizeof(ai));
+  }
+
+  if (ok)
+    return !!cscheme;
+
+/* Should not happen */
+  bcrypt_output_magic(scheme, dst, length);
+  return 0;
+}
diff --git a/blowfish.h b/blowfish-internal.h
similarity index 50%
copy from blowfish.h
copy to blowfish-internal.h
index bcdc7cb6..da28fa34 100644
--- a/blowfish.h
+++ b/blowfish-internal.h
@@ -1,4 +1,4 @@
-/* blowfish.h
+/* blowfish-internal.h
 
    Blowfish block cipher.
 
@@ -32,8 +32,8 @@
    not, see http://www.gnu.org/licenses/.
 */
  
-#ifndef NETTLE_BLOWFISH_H_INCLUDED
-#define NETTLE_BLOWFISH_H_INCLUDED
+#ifndef NETTLE_BLOWFISH_INTERNAL_H_INCLUDED
+#define NETTLE_BLOWFISH_INTERNAL_H_INCLUDED
 
 #include "nettle-types.h"
 
@@ -41,49 +41,12 @@
 extern "C" {
 #endif
 
-/* Name mangling */
-#define blowfish_set_key nettle_blowfish_set_key
-#define blowfish128_set_key nettle_blowfish128_set_key
-#define blowfish_encrypt nettle_blowfish_encrypt
-#define blowfish_decrypt nettle_blowfish_decrypt
-
-#define BLOWFISH_BLOCK_SIZE 8
-
-/* Variable key size between 64 and 448 bits. */
-#define BLOWFISH_MIN_KEY_SIZE 8
-#define BLOWFISH_MAX_KEY_SIZE 56
-
-/* Default to 128 bits */
-#define BLOWFISH_KEY_SIZE 16
-
-#define BLOWFISH128_KEY_SIZE 16
-
-#define _BLOWFISH_ROUNDS 16
-
-struct blowfish_ctx
-{
-  uint32_t s[4][256];
-  uint32_t p[_BLOWFISH_ROUNDS+2];
-};
-
-/* Returns 0 for weak keys, otherwise 1. */
-int
-blowfish_set_key(struct blowfish_ctx *ctx,
-                 size_t length, const uint8_t *key);
-int
-blowfish128_set_key(struct blowfish_ctx *ctx, const uint8_t *key);
-
-void
-blowfish_encrypt(const struct blowfish_ctx *ctx,
-                 size_t length, uint8_t *dst,
-                 const uint8_t *src);
-void
-blowfish_decrypt(const struct blowfish_ctx *ctx,
-                 size_t length, uint8_t *dst,
-                 const uint8_t *src);
+extern const struct blowfish_ctx _nettle_blowfish_initial_ctx;
+extern void _nettle_blowfish_encround (const struct blowfish_ctx *ctx,
+                                       uint32_t * ret_xl, uint32_t * ret_xr);
 
 #ifdef __cplusplus
 }
 #endif
 
-#endif /* NETTLE_BLOWFISH_H_INCLUDED */
+#endif /* NETTLE_BLOWFISH_INTERNAL_H_INCLUDED */
diff --git a/blowfish.c b/blowfish.c
index 52040f13..e73caffe 100644
--- a/blowfish.c
+++ b/blowfish.c
@@ -54,12 +54,13 @@
 #include &lt;assert.h&gt;
 
 #include "blowfish.h"
+#include "blowfish-internal.h"
 
 #include "macros.h"
 
 /* precomputed S boxes */
-static const struct blowfish_ctx
-initial_ctx = {
+const struct blowfish_ctx
+_nettle_blowfish_initial_ctx = {
   {
     { /* ks0 */
       0xD1310BA6, 0x98DFB5AC, 0x2FFD72DB, 0xD01ADFB7, 0xB8E1AFED, 0x6A267E96,
@@ -261,8 +262,8 @@ initial_ctx = {
 
 #define R(c, l,r,i)  do { l ^= c-&gt;p[i]; r ^= F(c,l); } while(0)
 
-static void
-encrypt (const struct blowfish_ctx *ctx, uint32_t * ret_xl,
+void
+_nettle_blowfish_encround (const struct blowfish_ctx *ctx, uint32_t * ret_xl,
 	    uint32_t * ret_xr)
 {
   uint32_t xl, xr;
@@ -295,7 +296,7 @@ encrypt (const struct blowfish_ctx *ctx, uint32_t * ret_xl,
 }
 
 static void
-decrypt (const struct blowfish_ctx *ctx, uint32_t * ret_xl, uint32_t * ret_xr)
+decround (const struct blowfish_ctx *ctx, uint32_t * ret_xl, uint32_t * ret_xr)
 {
   uint32_t xl, xr;
 
@@ -339,7 +340,7 @@ blowfish_encrypt (const struct blowfish_ctx *ctx,
 
       d1 = READ_UINT32(src);
       d2 = READ_UINT32(src+4);
-      encrypt (ctx, &amp;d1, &amp;d2);
+      _nettle_blowfish_encround (ctx, &amp;d1, &amp;d2);
       dst[0] = (d1 &gt;&gt; 24) &amp; 0xff;
       dst[1] = (d1 &gt;&gt; 16) &amp; 0xff;
       dst[2] = (d1 &gt;&gt; 8) &amp; 0xff;
@@ -361,7 +362,7 @@ blowfish_decrypt (const struct blowfish_ctx *ctx,
 
       d1 = READ_UINT32(src);
       d2 = READ_UINT32(src+4);
-      decrypt (ctx, &amp;d1, &amp;d2);
+      decround (ctx, &amp;d1, &amp;d2);
       dst[0] = (d1 &gt;&gt; 24) &amp; 0xff;
       dst[1] = (d1 &gt;&gt; 16) &amp; 0xff;
       dst[2] = (d1 &gt;&gt; 8) &amp; 0xff;
@@ -380,7 +381,7 @@ blowfish_set_key (struct blowfish_ctx *ctx,
   int i, j;
   uint32_t data, datal, datar;
 
-  *ctx = initial_ctx;
+  *ctx = _nettle_blowfish_initial_ctx;
 
   for (i = j = 0; i &lt; _BLOWFISH_ROUNDS + 2; i++)
     {
@@ -393,15 +394,15 @@ blowfish_set_key (struct blowfish_ctx *ctx,
   datal = datar = 0;
   for (i = 0; i &lt; _BLOWFISH_ROUNDS + 2; i += 2)
     {
-      encrypt (ctx, &amp;datal, &amp;datar);
+      _nettle_blowfish_encround (ctx, &amp;datal, &amp;datar);
       ctx-&gt;p[i] = datal;
       ctx-&gt;p[i + 1] = datar;
     }
-  
+
   for (j = 0; j &lt; 4; j++)
     for (i = 0; i &lt; 256; i += 2)
       {
-	encrypt (ctx, &amp;datal, &amp;datar);
+	_nettle_blowfish_encround (ctx, &amp;datal, &amp;datar);
 	ctx-&gt;s[j][i] = datal;
 	ctx-&gt;s[j][i + 1] = datar;
     }
diff --git a/blowfish.h b/blowfish.h
index bcdc7cb6..af48e20f 100644
--- a/blowfish.h
+++ b/blowfish.h
@@ -46,6 +46,8 @@ extern "C" {
 #define blowfish128_set_key nettle_blowfish128_set_key
 #define blowfish_encrypt nettle_blowfish_encrypt
 #define blowfish_decrypt nettle_blowfish_decrypt
+#define blowfish_bcrypt_hash nettle_blowfish_bcrypt_hash
+#define blowfish_bcrypt_verify nettle_blowfish_bcrypt_verify
 
 #define BLOWFISH_BLOCK_SIZE 8
 
@@ -60,6 +62,9 @@ extern "C" {
 
 #define _BLOWFISH_ROUNDS 16
 
+#define BLOWFISH_BCRYPT_HASH_SIZE (60 + 1) /* Including null-terminator */
+#define BLOWFISH_BCRYPT_BINSALT_SIZE 16    /* Binary string size */
+
 struct blowfish_ctx
 {
   uint32_t s[4][256];
@@ -81,6 +86,16 @@ void
 blowfish_decrypt(const struct blowfish_ctx *ctx,
                  size_t length, uint8_t *dst,
                  const uint8_t *src);
+int
+blowfish_bcrypt_hash(size_t length,
+                     char *dst,
+                     const char *key,
+                     const char *scheme,
+		     int log2rounds,
+		     const uint8_t *salt);
+int
+blowfish_bcrypt_verify(const char *key,
+                       const char *hashed);
 
 #ifdef __cplusplus
 }
diff --git a/nettle.texinfo b/nettle.texinfo
index ff64889c..13b1df39 100644
--- a/nettle.texinfo
+++ b/nettle.texinfo
@@ -1512,6 +1512,73 @@ in any other way.
 Analogous to @code{blowfish_encrypt}
 @end deftypefun
 
+@deftypefun int blowfish_bcrypt_hash (size_t @var{length}, char *@var{dst}, const \
char *@var{key}, const char *@var{scheme}, int @var{log2rounds}, const uint8_t \
*@var{salt}) +Compute the bcrypt password hash.
+The function will return @code{0} if the hash cannot be computed
+due to invalid input.
+The function will return @code{1} and store the computed hash
+in the array pointed to by @var{dst}.  The hash is computed based
+on the chosen @var{scheme}, number of rounds @var{log2rounds} and
+specified @var{salt}.
+
+@var{length} must be at least @code{BLOWFISH_BCRYPT_HASH_SIZE}.
+
+@var{dst} must point to a character array of the specified @var{length}.
+
+@var{key} contains the zero terminated plaintext password string.
+
+@var{scheme} contains either just the chosen scheme (valid schemes
+are: @code{2a}, @code{2b}, @code{2x} or @code{2y}), or
+(the prefix of) an existing hashed password (typically @code{$2b$10$...}).
+
+@var{log2rounds} contains the log2 of the number of encryption rounds
+that must be used to compute the hash.  If it is @code{-1} the value
+will be extracted from @var{scheme}.
+
+@var{salt} should point to an array of @code{BLOWFISH_BCRYPT_BINSALT_SIZE}
+random bytes to be used to perturb the hash computation.  If it is @code{NULL}
+the salt will be extracted from @var{scheme}.
+
+Sample code to generate a bcrypt hash:
+@example
+char cleartxtpassword[] = "ExamplePassword";
+uint8_t salt[BLOWFISH_BCRYPT_BINSALT_SIZE];
+@dots{}
+/* Make sure that salt is filled with random bytes */
+@dots{}
+char hashedresult[BLOWFISH_BCRYPT_HASH_SIZE];
+int result = blowfish_bcrypt(sizeof(hashedresult), hashedresult,
+                             cleartxtpassword, "2b", 10, salt);
+if (result)
+  printf("%s\n", hashedresult);
+@end example
+@end deftypefun
+
+@deftypefun int blowfish_bcrypt_verify (const char *@var{key}, const char \
*@var{hashed}) +Verifies the bcrypt password hash against the supplied plaintext \
password. +The function will return @code{0} if the password does not match.
+The function will return @code{1} if the password matches.
+
+@var{key} contains the zero terminated plaintext password string.
+
+@var{hashed} contains the zero terminated hashed string to compare with.
+
+Sample code to verify a bcrypt hash:
+@example
+char cleartxtpassword[] = "ExamplePassword";
+char existinghashed[] =
+           "$2y$"  /* Hash algorithm version */
+           "10"   /* 2^10 hash rounds (strength) */
+           "$"   /* separator */
+           "1b2lPgo4XumibnJGN3r3sO" /* base64 encoded 16-byte salt */
+           "u7wE7xNfYDKlAxZffJDCJdVfFTAyevu"; /* Hashedpart */
+if (blowfish_bcrypt_verify(cleartxtpassword, existinghashed))
+  printf("Password is correct.");
+else
+  printf("Password is incorrect.");
+@end example
+@end deftypefun
+
 @subsection Camellia
 @cindex Camellia
 
-- 
2.20.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200316191201</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-03-16 19:12:01-0400</timestampReceived><subject>Re: [PATCH] x86: Build with -z ibt -z shstk if possible</subject><body>

On Mon, Mar 16, 2020 at 2:50 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt; 
&gt; ...
&gt; 2. What I tried to ask about in the message you reply to, was how to
&gt; write a test within the Nettle testsuite, to verify that enabling CET
&gt; really has effect on a test executable (on systems where it is
&gt; expected to have effect). It's not obvious to me if and how the patch
&gt; improves that.

One more time to the list this time....

For the CET patch on Linux, use objdump -d to disassemble a file built
with CET. Then grep for ENDBR:

    count=$(objdump -d some_source.o | grep -i -c endbr)
    if [ "$count" -eq 0 ]; then
        echo "Failed to enable CET"
    else
        echo "CET is enabled"
    fi

You need a modern Binutils that supports ENDBR and ENDBR64.

There are other instructions you can search for. See
https://i.blackhat.com/asia-19/Thu-March-28/bh-asia-Sun-How-to-Survive-the-Hardware-Assisted-Control-Flow-Integrity-Enforcement.pdf.
 For example to search for ENDBR, RDSSP and WRSSP"

    count=$(objdump -d some_source.o | grep -i -c -E 'endbr|rdssp|wrssp')

I don't know if/how to check for CET on other platforms, like the
BSDs, OS X or Solaris. I know the tools to perform the disassembly,
but I don't know the other details.

Also see https://stackoverflow.com/q/56120231.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200318174332</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-03-18 17:43:32-0400</timestampReceived><subject>Re: [PATCH] x86: Build with -z ibt -z shstk if possible</subject><body>

On Mon, Mar 16, 2020 at 3:12 PM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:
&gt; 
&gt; On Mon, Mar 16, 2020 at 2:50 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt; &gt; 
&gt; &gt; ...
&gt; &gt; 2. What I tried to ask about in the message you reply to, was how to
&gt; &gt; write a test within the Nettle testsuite, to verify that enabling CET
&gt; &gt; really has effect on a test executable (on systems where it is
&gt; &gt; expected to have effect). It's not obvious to me if and how the patch
&gt; &gt; improves that.
&gt; 
&gt; One more time to the list this time....
&gt; 
&gt; For the CET patch on Linux, use objdump -d to disassemble a file built
&gt; with CET. Then grep for ENDBR:
&gt; 
&gt; count=$(objdump -d some_source.o | grep -i -c endbr)
&gt; if [ "$count" -eq 0 ]; then
&gt; echo "Failed to enable CET"
&gt; else
&gt; echo "CET is enabled"
&gt; fi
&gt; 
&gt; You need a modern Binutils that supports ENDBR and ENDBR64.
&gt; 
&gt; There are other instructions you can search for. See
&gt; https://i.blackhat.com/asia-19/Thu-March-28/bh-asia-Sun-How-to-Survive-the-Hardware-Assisted-Control-Flow-Integrity-Enforcement.pdf.
&gt;  For example to search for ENDBR, RDSSP and WRSSP"
&gt; 
&gt; count=$(objdump -d some_source.o | grep -i -c -E 'endbr|rdssp|wrssp')
&gt; 
&gt; I don't know if/how to check for CET on other platforms, like the
&gt; BSDs, OS X or Solaris. I know the tools to perform the disassembly,
&gt; but I don't know the other details.

I just came across this from Checksec. There may be an elf section
named '.cfi' to inspect, too. Also see
https://github.com/slimm609/checksec.sh/issues/118 .

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200321154609</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-03-21 15:46:09-0400</timestampReceived><subject>Re: [PATCH] x86: Build with -z ibt -z shstk if possible</subject><body>

"H.J. Lu" &lt;hjl.tools@gmail.com&gt; writes:

&gt;&gt; 2. What I tried to ask about in the message you reply to, was how to
&gt;&gt;    write a test within the Nettle testsuite, to verify that enabling CET
&gt;&gt;    really has effect on a test executable (on systems where it is
&gt;&gt;    expected to have effect). It's not obvious to me if and how the patch
&gt;&gt;    improves that.
&gt;
&gt; The  -z ibt -z shstk linker option creates the output marked as CET
&gt; enabled regardless of input.  When it is used to build the Nettle libraries
&gt; and tests in the Nettle testsuite, tests will fail on CET Linux if ENDBR is
&gt; missing at indirect branch targets.

That will test that low-level cet is working (e.g., needed ENDBR
isntructions are there). I was asking for a different kind of test,
verifying that if a test executable is linked with nettle, and everything
is built with -fcf-protection=full passed to the gcc frontend, and run
on a cet enabled system, then a violation of cet will result in a crash. 
I outlined a way to write such a test, do you think it is feasible?

A test like that can give us confidence that cet is properly enabled all
the way. And then regular unit tests will cover the details, with a
./configure CC='gcc -fcf-protextion=full' &amp;&amp; make &amp;&amp; make check on a
CET-enabled system.

I'd prefer to not passing any special linker flags when linking the test
executables, they should as far as possible be linked the same way as
non-test programs using Nettle.

Regards,
/Niels


-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200309164433</emailId><senderName>Simo Sorce</senderName><senderEmail>simo@redhat.com</senderEmail><timestampReceived>2020-03-09 16:44:33-0400</timestampReceived><subject>Re: [PATCH] x86: Add X86_ENDBR and CET marker to config.m4.in</subject><body>

On Mon, 2020-03-09 at 08:33 -0700, H.J. Lu wrote:
&gt; On Mon, Mar 9, 2020 at 5:36 AM Simo Sorce &lt;simo@redhat.com&gt; wrote:
&gt; &gt; On Sat, 2020-03-07 at 17:49 +0100, Niels Möller wrote:
&gt; &gt; &gt; "H.J. Lu" &lt;hjl.tools@gmail.com&gt; writes:
&gt; &gt; &gt; 
&gt; &gt; &gt; &gt; Intel Control-flow Enforcement Technology (CET):
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; https://software.intel.com/en-us/articles/intel-sdm
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; contains shadow stack (SHSTK) and indirect branch tracking (IBT).  When
&gt; &gt; &gt; &gt; CET is enabled, ELF object files must be marked with .note.gnu.property
&gt; &gt; &gt; &gt; section.  Also when IBT is enabled, all indirect branch targets must
&gt; &gt; &gt; &gt; start with ENDBR instruction.
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; This patch adds X86_ENDBR and the CET marker to config.m4.in when CET
&gt; &gt; &gt; &gt; is enabled.  It updates PROLOGUE with X86_ENDBR.
&gt; &gt; &gt; 
&gt; &gt; &gt; I'd like to have a look at what gcc produces. How is it enabled with
&gt; &gt; &gt; gcc? In the docs, I find
&gt; &gt; &gt; 
&gt; &gt; &gt;   -mshstk
&gt; &gt; &gt; 
&gt; &gt; &gt;     The -mshstk option enables shadow stack built-in functions from x86
&gt; &gt; &gt;     Control-flow Enforcement Technology (CET).
&gt; &gt; &gt; 
&gt; &gt; &gt; but when I try compiling a trivial function,
&gt; &gt; &gt; 
&gt; &gt; &gt;   $ cat foo-cet.c
&gt; &gt; &gt;   int foo(void) {return 0;}
&gt; &gt; &gt;   $ gcc -save-temps -c -mshstk foo-cet.c
&gt; &gt; &gt; 
&gt; &gt; &gt; I get no endbr instruction and no note in the foo-cet.s. I'm using
&gt; &gt; &gt; gcc-8.3. I do get an
&gt; &gt; &gt; 
&gt; &gt; &gt;   .section .note.GNU-stack,"",@progbits
&gt; &gt; &gt; 
&gt; &gt; &gt; corresponding to Nettle's ASM_MARK_NOEXEC_STACK
&gt; &gt; &gt; 
&gt; &gt; &gt; &gt; --- a/config.m4.in
&gt; &gt; &gt; &gt; +++ b/config.m4.in
&gt; &gt; &gt; &gt; @@ -8,6 +8,10 @@ define(&lt;ALIGN_LOG&gt;, &lt;@ASM_ALIGN_LOG@&gt;)dnl
&gt; &gt; &gt; &gt;  define(&lt;W64_ABI&gt;, &lt;@W64_ABI@&gt;)dnl
&gt; &gt; &gt; &gt;  define(&lt;RODATA&gt;, &lt;@ASM_RODATA@&gt;)dnl
&gt; &gt; &gt; &gt;  define(&lt;WORDS_BIGENDIAN&gt;, &lt;@ASM_WORDS_BIGENDIAN@&gt;)dnl
&gt; &gt; &gt; &gt; +define(&lt;X86_ENDBR&gt;,&lt;@X86_ENDBR@&gt;)dnl
&gt; &gt; &gt; &gt; +divert(1)
&gt; &gt; &gt; &gt; +@X86_GNU_PROPERTY@
&gt; &gt; &gt; &gt; +divert
&gt; &gt; &gt; &gt;  divert(1)
&gt; &gt; &gt; &gt;  @ASM_MARK_NOEXEC_STACK@
&gt; &gt; &gt; &gt;  divert
&gt; &gt; &gt; 
&gt; &gt; &gt; You can put the two properties in the same m4 divert. Also, please
&gt; &gt; &gt; rename the autoconf substitutions with ASM_ prefix, and something more
&gt; &gt; &gt; descriptive than X64_GNU_PROPERTY. E.g., ASM_X86_ENDBR and
&gt; &gt; &gt; ASM_X86_MARK_CET.
&gt; &gt; &gt; 
&gt; &gt; &gt; &gt; diff --git a/configure.ac b/configure.ac
&gt; &gt; &gt; &gt; index ba3ab7c6..e9ed630c 100644
&gt; &gt; &gt; &gt; --- a/configure.ac
&gt; &gt; &gt; &gt; +++ b/configure.ac
&gt; &gt; &gt; &gt; @@ -803,6 +803,82 @@ EOF
&gt; &gt; &gt; &gt;    ASM_ALIGN_LOG="$nettle_cv_asm_align_log"
&gt; &gt; &gt; &gt;  fi
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; +dnl  Define
&gt; &gt; &gt; &gt; +dnl  1. X86_ENDBR for endbr32/endbr64.
&gt; &gt; &gt; &gt; +dnl  2. X86_GNU_PROPERTY to add a .note.gnu.property section to mark
&gt; &gt; &gt; &gt; +dnl  Intel CET support if needed.
&gt; &gt; &gt; &gt; +dnl        .section ".note.gnu.property", "a"
&gt; &gt; &gt; &gt; +dnl        .p2align POINTER-ALIGN
&gt; &gt; &gt; &gt; +dnl        .long 1f - 0f
&gt; &gt; &gt; &gt; +dnl        .long 4f - 1f
&gt; &gt; &gt; &gt; +dnl        .long 5
&gt; &gt; &gt; &gt; +dnl 0:
&gt; &gt; &gt; &gt; +dnl        .asciz "GNU"
&gt; &gt; &gt; &gt; +dnl 1:
&gt; &gt; &gt; &gt; +dnl        .p2align POINTER-ALIGN
&gt; &gt; &gt; &gt; +dnl        .long 0xc0000002
&gt; &gt; &gt; &gt; +dnl        .long 3f - 2f
&gt; &gt; &gt; &gt; +dnl 2:
&gt; &gt; &gt; &gt; +dnl        .long 3
&gt; &gt; &gt; &gt; +dnl 3:
&gt; &gt; &gt; &gt; +dnl        .p2align POINTER-ALIGN
&gt; &gt; &gt; &gt; +dnl 4:
&gt; &gt; &gt; 
&gt; &gt; &gt; No need to repeat the definition in full in this comment. And as I think
&gt; &gt; &gt; I've said before, I'm a bit surprised that it needs to be this verbose.
&gt; &gt; &gt; 
&gt; &gt; &gt; &gt; +AC_CACHE_CHECK([if Intel CET is enabled],
&gt; &gt; &gt; &gt; +  [nettle_cv_asm_x86_intel_cet],
&gt; &gt; &gt; &gt; +  [AC_TRY_COMPILE([
&gt; &gt; &gt; &gt; +#ifndef __CET__
&gt; &gt; &gt; &gt; +#error Intel CET is not enabled
&gt; &gt; &gt; &gt; +#endif
&gt; &gt; &gt; &gt; +  ], [],
&gt; &gt; &gt; &gt; +  [nettle_cv_asm_x86_intel_cet=yes],
&gt; &gt; &gt; &gt; +  [nettle_cv_asm_x86_intel_cet=no])])
&gt; &gt; &gt; &gt; +if test "$nettle_cv_asm_x86_intel_cet" = yes; then
&gt; &gt; &gt; &gt; +  case $ABI in
&gt; &gt; &gt; &gt; +  32|standard)
&gt; &gt; &gt; &gt; +    X86_ENDBR=endbr32
&gt; &gt; &gt; &gt; +    p2align=2
&gt; &gt; &gt; &gt; +    ;;
&gt; &gt; &gt; &gt; +  64)
&gt; &gt; &gt; &gt; +    X86_ENDBR=endbr64
&gt; &gt; &gt; &gt; +    p2align=3
&gt; &gt; &gt; &gt; +    ;;
&gt; &gt; &gt; &gt; +  x32)
&gt; &gt; &gt; &gt; +    X86_ENDBR=endbr64
&gt; &gt; &gt; &gt; +    p2align=2
&gt; &gt; &gt; &gt; +    ;;
&gt; &gt; &gt; &gt; +  esac
&gt; &gt; &gt; &gt; +  AC_CACHE_CHECK([if .note.gnu.property section is needed],
&gt; &gt; &gt; &gt; +    [nettle_cv_asm_x86_gnu_property],
&gt; &gt; &gt; &gt; +    [AC_TRY_COMPILE([
&gt; &gt; &gt; &gt; +#if !defined __ELF__ || !defined __CET__
&gt; &gt; &gt; &gt; +#error GNU property is not needed
&gt; &gt; &gt; &gt; +#endif
&gt; &gt; &gt; &gt; +    ], [],
&gt; &gt; &gt; &gt; +    [nettle_cv_asm_x86_gnu_property=yes],
&gt; &gt; &gt; &gt; +    [nettle_cv_asm_x86_gnu_property=no])])
&gt; &gt; &gt; &gt; +else
&gt; &gt; &gt; &gt; +  nettle_cv_asm_x86_gnu_property=no
&gt; &gt; &gt; &gt; +fi
&gt; &gt; &gt; &gt; +if test "$nettle_cv_asm_x86_gnu_property" = yes; then
&gt; &gt; &gt; &gt; +  X86_GNU_PROPERTY="
&gt; &gt; &gt; &gt; +   .section \".note.gnu.property\", \"a\"
&gt; &gt; &gt; &gt; +   .p2align $p2align
&gt; &gt; &gt; &gt; +   .long 1f - 0f
&gt; &gt; &gt; &gt; +   .long 4f - 1f
&gt; &gt; &gt; &gt; +   .long 5
&gt; &gt; &gt; &gt; +0:
&gt; &gt; &gt; &gt; +   .asciz \"GNU\"
&gt; &gt; &gt; &gt; +1:
&gt; &gt; &gt; &gt; +   .p2align $p2align
&gt; &gt; &gt; &gt; +   .long 0xc0000002
&gt; &gt; &gt; &gt; +   .long 3f - 2f
&gt; &gt; &gt; &gt; +2:
&gt; &gt; &gt; &gt; +   .long 3
&gt; &gt; &gt; &gt; +3:
&gt; &gt; &gt; &gt; +   .p2align $p2align
&gt; &gt; &gt; &gt; +4:"
&gt; &gt; &gt; &gt; +fi
&gt; &gt; &gt; 
&gt; &gt; &gt; Maybe a bit easier to read if you use single quotes for
&gt; &gt; &gt; X86_GNU_PROPERTY='...', don't escape the inner double quotes. That
&gt; &gt; &gt; leaves the expansion of $p2align, maybe it's better to define a separate
&gt; &gt; &gt; substituted variable for pointer alignment? (If there's no easier way to
&gt; &gt; &gt; enforce pointer-alignment).
&gt; &gt; 
&gt; &gt; Niels,
&gt; &gt; I sent patches longa few months ago on the list to enable CET, they
&gt; &gt; already went through review, any reason why we are looking at a
&gt; &gt; different set and restarting review from scratch now?
&gt; &gt; 
&gt; &gt; (sorry for not catching earlier, we seem to be having some delivery
&gt; &gt; issues and sometimes mailing list post are not reaching me, please keep
&gt; &gt; me in direct CC for now, hopefully that will help :-/ )
&gt; &gt; 
&gt; 
&gt; Hi Simo,
&gt; 
&gt; master branch doesn't contain any CET support.  Can you share your patch
&gt; with me?  I will give it a try on CET processor.
&gt; 
&gt; Thanks.

The patchset i solder than I did remember, April 2019
But I recall running at least one version of it on our CET emulator @
Red Hat.

HTH,
Simo.


-- 
Simo Sorce
RHEL Crypto Team
Red Hat, Inc




["0001-Add-missing-EPILOGUEs-in-assembly-files.patch" (0001-Add-missing-EPILOGUEs-in-assembly-files.patch)]

From dcf9de29114bb4137b12787685cebfcfd962ad5f Mon Sep 17 00:00:00 2001
From: Simo Sorce &lt;simo@redhat.com&gt;
Date: Fri, 26 Apr 2019 13:12:53 -0400
Subject: [PATCH 1/4] Add missing EPILOGUEs in assembly files

Signed-off-by: Simo Sorce &lt;simo@redhat.com&gt;
---
 x86_64/poly1305-internal.asm | 1 +
 x86_64/serpent-decrypt.asm   | 1 +
 x86_64/serpent-encrypt.asm   | 1 +
 3 files changed, 3 insertions(+)

diff --git a/x86_64/poly1305-internal.asm b/x86_64/poly1305-internal.asm
index c780d122..98159ad3 100644
--- a/x86_64/poly1305-internal.asm
+++ b/x86_64/poly1305-internal.asm
@@ -182,4 +182,5 @@ define(&lt;T1&gt;, &lt;%rax&gt;)
 	mov	XREG(%rax), P1305_H2 (CTX)
 	W64_EXIT(2, 0)
 	ret
+EPILOGUE(nettle_poly1305_digest)
 
diff --git a/x86_64/serpent-decrypt.asm b/x86_64/serpent-decrypt.asm
index ee4bf9ad..031c41c8 100644
--- a/x86_64/serpent-decrypt.asm
+++ b/x86_64/serpent-decrypt.asm
@@ -713,3 +713,4 @@ PROLOGUE(nettle_serpent_decrypt)
 	pop	%rbx
 	W64_EXIT(4, 13)
 	ret
+EPILOGUE(nettle_serpent_decrypt)
diff --git a/x86_64/serpent-encrypt.asm b/x86_64/serpent-encrypt.asm
index d6636537..99cba00c 100644
--- a/x86_64/serpent-encrypt.asm
+++ b/x86_64/serpent-encrypt.asm
@@ -748,3 +748,4 @@ C parallell.
 	pop	%rbx
 	W64_EXIT(4, 13)
 	ret
+EPILOGUE(nettle_serpent_encrypt)
-- 
2.20.1


["0002-Fix-generation-of-build-notes-if-supported.patch" (0002-Fix-generation-of-build-notes-if-supported.patch)]

From af9b9379fdad760589acddb186620dcc7d994e8e Mon Sep 17 00:00:00 2001
From: Simo Sorce &lt;simo@redhat.com&gt;
Date: Wed, 24 Apr 2019 16:13:59 -0400
Subject: [PATCH 2/4] Fix generation of build notes if supported

This is needed to build correctly on platfroms that use
hardening flags and build notes on .c files.

Signed-off-by: Simo Sorce &lt;simo@redhat.com&gt;
---
 Makefile.in  |  4 +++-
 configure.ac | 22 ++++++++++++++++++++++
 2 files changed, 25 insertions(+), 1 deletion(-)

diff --git a/Makefile.in b/Makefile.in
index 440de9f7..4e603047 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -17,6 +17,8 @@ OPT_HOGWEED_OBJS = @OPT_HOGWEED_OBJS@
 
 OPT_NETTLE_SOURCES = @OPT_NETTLE_SOURCES@
 
+ASM_GEN_BUILD_NOTES = @ASM_GEN_BUILD_NOTES@
+
 SUBDIRS = tools testsuite examples
 
 include config.make
@@ -396,7 +398,7 @@ ecc-25519.$(OBJEXT): ecc-25519.h
 
 .asm.$(OBJEXT): $(srcdir)/asm.m4 machine.m4 config.m4
 	$(M4) $(srcdir)/asm.m4 machine.m4 config.m4 $&lt; &gt;$*.s
-	$(COMPILE) -c $*.s
+	$(COMPILE) -c $*.s $(ASM_GEN_BUILD_NOTES)
 	@echo "$@ : $&lt; $(srcdir)/asm.m4 machine.m4 config.m4" &gt;$@.d 
 
 # Texinfo rules
diff --git a/configure.ac b/configure.ac
index 00d2bf5d..ac921df0 100644
--- a/configure.ac
+++ b/configure.ac
@@ -702,6 +702,7 @@ ASM_TYPE_FUNCTION='@function'
 ASM_TYPE_PROGBITS='@progbits'
 ASM_MARK_NOEXEC_STACK=''
 ASM_ALIGN_LOG=''
+ASM_GEN_BUILD_NOTES=''
 
 if test x$enable_assembler = xyes ; then
   AC_CACHE_CHECK([if globals are prefixed by underscore],
@@ -812,6 +813,26 @@ EOF
        [nettle_cv_asm_align_log=yes],
        [nettle_cv_asm_align_log=no])])
   ASM_ALIGN_LOG="$nettle_cv_asm_align_log"
+
+  AC_CACHE_CHECK([if --generate-missing-build-notes is supported],
+    nettle_cv_asm_build_notes,
+    [ # Default
+      nettle_cv_asm_build_notes=no
+
+      cat &gt;conftest.s &lt;&lt; EOF
+.text
+EOF
+      FLAG="-Wa,--generate-missing-build-notes=yes"
+      nettle_assemble="$CC $CFLAGS $CPPFLAGS -c conftest.s $FLAG &gt;conftest.out 2&gt;&amp;1"
+      if AC_TRY_EVAL(nettle_assemble); then
+        nettle_cv_asm_build_notes=yes
+      else
+       nettle_cv_asm_build_notes=no
+      fi
+    rm -f conftest.*])
+  if test x$nettle_cv_asm_build_notes = xyes ; then
+    ASM_GEN_BUILD_NOTES='-Wa,--generate-missing-build-notes=yes'
+  fi
 fi
 
 AC_SUBST(ASM_SYMBOL_PREFIX)
@@ -823,6 +844,7 @@ AC_SUBST(ASM_MARK_NOEXEC_STACK)
 AC_SUBST(ASM_ALIGN_LOG)
 AC_SUBST(W64_ABI)
 AC_SUBST(ASM_WORDS_BIGENDIAN)
+AC_SUBST(ASM_GEN_BUILD_NOTES)
 AC_SUBST(EMULATOR)
 
 AC_SUBST(LIBNETTLE_MAJOR)
-- 
2.20.1


["0003-Add-Intel-CET-protection-support.patch" (0003-Add-Intel-CET-protection-support.patch)]

From a11dd90fc89767609be7729973bf9be0f8809d20 Mon Sep 17 00:00:00 2001
From: Simo Sorce &lt;simo@redhat.com&gt;
Date: Tue, 23 Apr 2019 18:03:35 -0400
Subject: [PATCH 3/4] Add Intel CET protection support

In upcoming processors Intel will make available Control-Flow
Enforcement Technology, which is comprised of two hardware
countermeasures against Return-Oriented Programming attacks.

The first is called Shadow Stack and checks that return from function
calls are not tampered with by keeping a shadow stack that cannot be
modified by applications. This measure requires no code changes (except
for code that intentionally modifies the return pointer on the stack).

The second is called Indirect Branch Tracking and is used to insure only
targets of indirect jumps are actually jumped to. This requires
modification of code to insert a special instruction that identifies a
valid indirect jump target. When enforcement is turned on, if an indirect
jump does not end on this special instruction the cpu raises an exception.
These instructions are noops on older CPU models so it is safe to use
them in all x86(_64) code.

To enable these protections GCC also introduces a new GNU property note
section that marks a piece of code as CET ready.
If the note is in place the dynamic linker will be able to confirm that
all loaded libraries support CET and will turn on CET protection for the
binary.

The changes here consist mostly in adding the GNU property note section
to all x86(_64) assembly files and the proper ENDBRANCH instruction for
the function entrypoints which is where other code calls into via
indirect call.

Signed-off-by: Simo Sorce &lt;simo@redhat.com&gt;
---
 asm.m4                                |  3 ++-
 config.m4.in                          |  2 ++
 configure.ac                          | 17 +++++++++++++
 x86/aes-decrypt-internal.asm          |  1 +
 x86/aes-encrypt-internal.asm          |  1 +
 x86/arcfour-crypt.asm                 |  1 +
 x86/camellia-crypt-internal.asm       |  1 +
 x86/machine.m4                        | 35 +++++++++++++++++++++++++++
 x86/md5-compress.asm                  |  1 +
 x86/sha1-compress.asm                 |  1 +
 x86_64/aes-decrypt-internal.asm       |  1 +
 x86_64/aes-encrypt-internal.asm       |  1 +
 x86_64/aesni/aes-decrypt-internal.asm |  1 +
 x86_64/aesni/aes-encrypt-internal.asm |  1 +
 x86_64/camellia-crypt-internal.asm    |  1 +
 x86_64/chacha-core-internal.asm       |  1 +
 x86_64/fat/cpuid.asm                  |  2 +-
 x86_64/gcm-hash8.asm                  |  1 +
 x86_64/machine.m4                     | 35 +++++++++++++++++++++++++++
 x86_64/md5-compress.asm               |  1 +
 x86_64/memxor.asm                     |  1 +
 x86_64/memxor3.asm                    |  1 +
 x86_64/poly1305-internal.asm          |  1 +
 x86_64/salsa20-core-internal.asm      |  1 +
 x86_64/salsa20-crypt.asm              |  1 +
 x86_64/serpent-decrypt.asm            |  1 +
 x86_64/serpent-encrypt.asm            |  1 +
 x86_64/sha1-compress.asm              |  1 +
 x86_64/sha256-compress.asm            |  1 +
 x86_64/sha3-permute.asm               |  1 +
 x86_64/sha512-compress.asm            |  1 +
 x86_64/sha_ni/sha1-compress.asm       |  1 +
 x86_64/sha_ni/sha256-compress.asm     |  1 +
 x86_64/umac-nh-n.asm                  |  1 +
 x86_64/umac-nh.asm                    |  1 +
 35 files changed, 121 insertions(+), 2 deletions(-)

diff --git a/asm.m4 b/asm.m4
index 8da47201..5a5d4ac2 100644
--- a/asm.m4
+++ b/asm.m4
@@ -32,7 +32,8 @@ define(&lt;GMP_NUMB_BITS&gt;,&lt;&gt;)dnl
 define(&lt;PROLOGUE&gt;,
 &lt;.globl C_NAME($1)
 DECLARE_FUNC(C_NAME($1))
-C_NAME($1):&gt;)
+C_NAME($1):
+CET_ENDBR&gt;)
 
 define(&lt;EPILOGUE&gt;,
 &lt;ifelse(ELF_STYLE,yes,
diff --git a/config.m4.in b/config.m4.in
index 11f90a40..c3ebad60 100644
--- a/config.m4.in
+++ b/config.m4.in
@@ -8,6 +8,8 @@ define(&lt;ALIGN_LOG&gt;, &lt;@ASM_ALIGN_LOG@&gt;)dnl
 define(&lt;W64_ABI&gt;, &lt;@W64_ABI@&gt;)dnl
 define(&lt;RODATA&gt;, &lt;@ASM_RODATA@&gt;)dnl
 define(&lt;WORDS_BIGENDIAN&gt;, &lt;@ASM_WORDS_BIGENDIAN@&gt;)dnl
+define(&lt;CET_PROTECTION&gt;, &lt;@ASM_CET_PROTECTION@&gt;)dnl
+define(&lt;CET_ENDBR&gt;, &lt;@ASM_CET_ENDBR@&gt;)dnl
 divert(1)
 @ASM_MARK_NOEXEC_STACK@
 divert
diff --git a/configure.ac b/configure.ac
index ac921df0..7beb35d9 100644
--- a/configure.ac
+++ b/configure.ac
@@ -93,6 +93,10 @@ AC_ARG_ENABLE(mini-gmp,
   AC_HELP_STRING([--enable-mini-gmp], [Enable mini-gmp, used instead of libgmp.]),,
   [enable_mini_gmp=no])
 
+AC_ARG_ENABLE(cet-protection,
+  AC_HELP_STRING([--enable-cet-protection], [Enable intel CET protection \
instructions. (default=no)]),, +  [enable_cet_protection=no])
+
 if test "x$enable_mini_gmp" = xyes ; then
   NETTLE_USE_MINI_GMP=1
   HOGWEED_EXTRA_SYMBOLS="mpz_*;gmp_*;mpn_*;mp_*;"
@@ -701,6 +705,8 @@ ASM_COFF_STYLE='no'
 ASM_TYPE_FUNCTION='@function'
 ASM_TYPE_PROGBITS='@progbits'
 ASM_MARK_NOEXEC_STACK=''
+ASM_CET_PROTECTION='no'
+ASM_CET_ENDBR=''
 ASM_ALIGN_LOG=''
 ASM_GEN_BUILD_NOTES=''
 
@@ -833,6 +839,15 @@ EOF
   if test x$nettle_cv_asm_build_notes = xyes ; then
     ASM_GEN_BUILD_NOTES='-Wa,--generate-missing-build-notes=yes'
   fi
+
+  if test "x$enable_cet_protection" = xyes ; then
+    ASM_CET_PROTECTION=yes
+    if test "$ABI" = 64 ; then
+      ASM_CET_ENDBR=endbr64
+    else
+      ASM_CET_ENDBR=endbr32
+    fi
+  fi
 fi
 
 AC_SUBST(ASM_SYMBOL_PREFIX)
@@ -845,6 +860,8 @@ AC_SUBST(ASM_ALIGN_LOG)
 AC_SUBST(W64_ABI)
 AC_SUBST(ASM_WORDS_BIGENDIAN)
 AC_SUBST(ASM_GEN_BUILD_NOTES)
+AC_SUBST(ASM_CET_PROTECTION)
+AC_SUBST(ASM_CET_ENDBR)
 AC_SUBST(EMULATOR)
 
 AC_SUBST(LIBNETTLE_MAJOR)
diff --git a/x86/aes-decrypt-internal.asm b/x86/aes-decrypt-internal.asm
index ff535b6a..1d16f6db 100644
--- a/x86/aes-decrypt-internal.asm
+++ b/x86/aes-decrypt-internal.asm
@@ -175,3 +175,4 @@ PROLOGUE(_nettle_aes_decrypt)
 	popl	%ebx
 	ret
 EPILOGUE(_nettle_aes_decrypt)
+GNU_CET_SECTION()
diff --git a/x86/aes-encrypt-internal.asm b/x86/aes-encrypt-internal.asm
index 934158f7..d9579e04 100644
--- a/x86/aes-encrypt-internal.asm
+++ b/x86/aes-encrypt-internal.asm
@@ -175,3 +175,4 @@ PROLOGUE(_nettle_aes_encrypt)
 	popl	%ebx
 	ret
 EPILOGUE(_nettle_aes_encrypt)
+GNU_CET_SECTION()
diff --git a/x86/arcfour-crypt.asm b/x86/arcfour-crypt.asm
index df3fe869..11f592e7 100644
--- a/x86/arcfour-crypt.asm
+++ b/x86/arcfour-crypt.asm
@@ -123,3 +123,4 @@ C .Lloop_done:
 	popl	%ebx
 	ret
 EPILOGUE(nettle_arcfour_crypt)
+GNU_CET_SECTION()
diff --git a/x86/camellia-crypt-internal.asm b/x86/camellia-crypt-internal.asm
index ce8c57f0..afac1fcc 100644
--- a/x86/camellia-crypt-internal.asm
+++ b/x86/camellia-crypt-internal.asm
@@ -223,3 +223,4 @@ PROLOGUE(_nettle_camellia_crypt)
 	popl	%ebx
 	ret
 EPILOGUE(_nettle_camellia_crypt)
+GNU_CET_SECTION()
diff --git a/x86/machine.m4 b/x86/machine.m4
index 38bee366..1153c757 100644
--- a/x86/machine.m4
+++ b/x86/machine.m4
@@ -14,3 +14,38 @@ define(&lt;HREG&gt;,&lt;ifelse(
 	$1, %ebx, %bh,
 	$1, %ecx, %ch,
 	$1, %edx, %dh)&gt;)dnl
+
+dnl GNU properties section to enable CET protections macros
+dnl For more info on the technology:
+dnl https://software.intel.com/sites/default/files/managed/4d/2a/control-flow-enforcement-technology-preview.pdf
 +
+dnl GNU Poperty type
+define(&lt;NT_GNU_PROPERTY_TYPE_0&gt;, &lt;5&gt;)
+dnl GNU Program Property Type range
+define(GNU_PROPERTY_X86_UINT32_AND_LO, &lt;0xc0000002&gt;)
+dnl Indirect Branch Tracking
+define(&lt;GNU_PROPERTY_X86_FEATURE_1_IBT&gt;, &lt;0x01&gt;)
+dnl Shadow Stack
+define(&lt;GNU_PROPERTY_X86_FEATURE_1_SHSTK&gt;, &lt;0x02&gt;)
+
+dnl NOTE: GNU Property sections MUST have alignment of 8
+define(&lt;GNU_CET_SECTION&gt;,
+&lt;ifelse(CET_PROTECTION,yes,
+&lt;.pushsection .note.gnu.property,"a"
+ALIGN(8)
+.long 1f - 0f
+.long 4f - 1f
+.long NT_GNU_PROPERTY_TYPE_0()
+0:
+.string "GNU"
+1:
+ALIGN(8)
+.long GNU_PROPERTY_X86_UINT32_AND_LO()
+.long 3f - 2f
+2:
+.long eval(GNU_PROPERTY_X86_FEATURE_1_IBT() | GNU_PROPERTY_X86_FEATURE_1_SHSTK())
+3:
+ALIGN(8)
+4:
+.popsection
+&gt;,&lt;&gt;)&gt;)
diff --git a/x86/md5-compress.asm b/x86/md5-compress.asm
index c849c082..6293f052 100644
--- a/x86/md5-compress.asm
+++ b/x86/md5-compress.asm
@@ -185,3 +185,4 @@ PROLOGUE(nettle_md5_compress)
 	popl	%ebx
 	ret
 EPILOGUE(nettle_md5_compress)
+GNU_CET_SECTION()
diff --git a/x86/sha1-compress.asm b/x86/sha1-compress.asm
index 03bdcdc9..4e1f121c 100644
--- a/x86/sha1-compress.asm
+++ b/x86/sha1-compress.asm
@@ -1541,6 +1541,7 @@ C 	ROUND_F2(SB, SC, SD, SE, SA, 79, K4VALUE)
 	popl	%ebx
 	ret
 EPILOGUE(nettle_sha1_compress)
+GNU_CET_SECTION()
 
 C TODO:
 
diff --git a/x86_64/aes-decrypt-internal.asm b/x86_64/aes-decrypt-internal.asm
index 43f2f394..eedfaaf0 100644
--- a/x86_64/aes-decrypt-internal.asm
+++ b/x86_64/aes-decrypt-internal.asm
@@ -150,3 +150,4 @@ PROLOGUE(_nettle_aes_decrypt)
 	W64_EXIT(6, 0)
 	ret
 EPILOGUE(_nettle_aes_decrypt)
+GNU_CET_SECTION()
diff --git a/x86_64/aes-encrypt-internal.asm b/x86_64/aes-encrypt-internal.asm
index dfb498f5..3a5a1e86 100644
--- a/x86_64/aes-encrypt-internal.asm
+++ b/x86_64/aes-encrypt-internal.asm
@@ -151,3 +151,4 @@ PROLOGUE(_nettle_aes_encrypt)
 	W64_EXIT(6, 0)
 	ret
 EPILOGUE(_nettle_aes_encrypt)
+GNU_CET_SECTION()
diff --git a/x86_64/aesni/aes-decrypt-internal.asm \
b/x86_64/aesni/aes-decrypt-internal.asm index 3d6d6e30..1b1a1a4d 100644
--- a/x86_64/aesni/aes-decrypt-internal.asm
+++ b/x86_64/aesni/aes-decrypt-internal.asm
@@ -132,3 +132,4 @@ PROLOGUE(_nettle_aes_decrypt)
 	W64_EXIT(6, 16)
 	ret
 EPILOGUE(_nettle_aes_decrypt)
+GNU_CET_SECTION()
diff --git a/x86_64/aesni/aes-encrypt-internal.asm \
b/x86_64/aesni/aes-encrypt-internal.asm index 99caf1f8..f7338ef6 100644
--- a/x86_64/aesni/aes-encrypt-internal.asm
+++ b/x86_64/aesni/aes-encrypt-internal.asm
@@ -132,3 +132,4 @@ PROLOGUE(_nettle_aes_encrypt)
 	W64_EXIT(6, 16)
 	ret
 EPILOGUE(_nettle_aes_encrypt)
+GNU_CET_SECTION()
diff --git a/x86_64/camellia-crypt-internal.asm b/x86_64/camellia-crypt-internal.asm
index 040e030f..71750172 100644
--- a/x86_64/camellia-crypt-internal.asm
+++ b/x86_64/camellia-crypt-internal.asm
@@ -200,3 +200,4 @@ PROLOGUE(_nettle_camellia_crypt)
 	W64_EXIT(6, 0)
 	ret
 EPILOGUE(_nettle_camellia_crypt)
+GNU_CET_SECTION()
diff --git a/x86_64/chacha-core-internal.asm b/x86_64/chacha-core-internal.asm
index 9e5dc394..3125dee7 100644
--- a/x86_64/chacha-core-internal.asm
+++ b/x86_64/chacha-core-internal.asm
@@ -126,3 +126,4 @@ PROLOGUE(_nettle_chacha_core)
 	W64_EXIT(3, 6)
 	ret
 EPILOGUE(_nettle_chacha_core)
+GNU_CET_SECTION()
diff --git a/x86_64/fat/cpuid.asm b/x86_64/fat/cpuid.asm
index f317d56e..c4a5b538 100644
--- a/x86_64/fat/cpuid.asm
+++ b/x86_64/fat/cpuid.asm
@@ -56,4 +56,4 @@ PROLOGUE(_nettle_cpuid)
 	W64_EXIT(2)
 	ret
 EPILOGUE(_nettle_cpuid)
-
+GNU_CET_SECTION()
diff --git a/x86_64/gcm-hash8.asm b/x86_64/gcm-hash8.asm
index bfaa6ef8..54608ae8 100644
--- a/x86_64/gcm-hash8.asm
+++ b/x86_64/gcm-hash8.asm
@@ -199,6 +199,7 @@ ALIGN(16)
 	jnz	.Lread_loop
 	ret
 EPILOGUE(_nettle_gcm_hash8)
+GNU_CET_SECTION()
 
 define(&lt;W&gt;, &lt;0x$2$1&gt;)
 	RODATA
diff --git a/x86_64/machine.m4 b/x86_64/machine.m4
index 397e9b25..a64241ce 100644
--- a/x86_64/machine.m4
+++ b/x86_64/machine.m4
@@ -171,3 +171,38 @@ define(&lt;W64_EXIT&gt;, &lt;
   ])
   changequote(&lt;,&gt;)dnl
 &gt;)
+
+dnl GNU properties section to enable CET protections macros
+dnl For more info on the technology:
+dnl https://software.intel.com/sites/default/files/managed/4d/2a/control-flow-enforcement-technology-preview.pdf
 +
+dnl GNU Poperty type
+define(&lt;NT_GNU_PROPERTY_TYPE_0&gt;, &lt;5&gt;)
+dnl GNU Program Property Type range
+define(GNU_PROPERTY_X86_UINT32_AND_LO, &lt;0xc0000002&gt;)
+dnl Indirect Branch Tracking
+define(&lt;GNU_PROPERTY_X86_FEATURE_1_IBT&gt;, &lt;0x01&gt;)
+dnl Shadow Stack
+define(&lt;GNU_PROPERTY_X86_FEATURE_1_SHSTK&gt;, &lt;0x02&gt;)
+
+dnl NOTE: GNU Property sections MUST have alignment of 8
+define(&lt;GNU_CET_SECTION&gt;,
+&lt;ifelse(CET_PROTECTION,yes,
+&lt;.pushsection .note.gnu.property,"a"
+ALIGN(8)
+.long 1f - 0f
+.long 4f - 1f
+.long NT_GNU_PROPERTY_TYPE_0()
+0:
+.string "GNU"
+1:
+ALIGN(8)
+.long GNU_PROPERTY_X86_UINT32_AND_LO()
+.long 3f - 2f
+2:
+.long eval(GNU_PROPERTY_X86_FEATURE_1_IBT() | GNU_PROPERTY_X86_FEATURE_1_SHSTK())
+3:
+ALIGN(8)
+4:
+.popsection
+&gt;,&lt;&gt;)&gt;)
diff --git a/x86_64/md5-compress.asm b/x86_64/md5-compress.asm
index 182b8f18..ef1fcb89 100644
--- a/x86_64/md5-compress.asm
+++ b/x86_64/md5-compress.asm
@@ -174,3 +174,4 @@ PROLOGUE(nettle_md5_compress)
 
 	ret
 EPILOGUE(nettle_md5_compress)
+GNU_CET_SECTION()
diff --git a/x86_64/memxor.asm b/x86_64/memxor.asm
index f07f0017..a0ea94b4 100644
--- a/x86_64/memxor.asm
+++ b/x86_64/memxor.asm
@@ -171,3 +171,4 @@ ifdef(&lt;USE_SSE2&gt;, &lt;
 &gt;)	
 
 EPILOGUE(nettle_memxor)
+GNU_CET_SECTION()
diff --git a/x86_64/memxor3.asm b/x86_64/memxor3.asm
index 8ff3e79c..b0c0e35c 100644
--- a/x86_64/memxor3.asm
+++ b/x86_64/memxor3.asm
@@ -261,3 +261,4 @@ ifelse(USE_SSE2, yes, &lt;
 	
 
 EPILOGUE(nettle_memxor3)
+GNU_CET_SECTION()
diff --git a/x86_64/poly1305-internal.asm b/x86_64/poly1305-internal.asm
index 98159ad3..3737450f 100644
--- a/x86_64/poly1305-internal.asm
+++ b/x86_64/poly1305-internal.asm
@@ -184,3 +184,4 @@ define(&lt;T1&gt;, &lt;%rax&gt;)
 	ret
 EPILOGUE(nettle_poly1305_digest)
 
+GNU_CET_SECTION()
diff --git a/x86_64/salsa20-core-internal.asm b/x86_64/salsa20-core-internal.asm
index 4ef07be0..c1690880 100644
--- a/x86_64/salsa20-core-internal.asm
+++ b/x86_64/salsa20-core-internal.asm
@@ -109,3 +109,4 @@ PROLOGUE(_nettle_salsa20_core)
 	W64_EXIT(3, 9)
 	ret
 EPILOGUE(_nettle_salsa20_core)
+GNU_CET_SECTION()
diff --git a/x86_64/salsa20-crypt.asm b/x86_64/salsa20-crypt.asm
index cc1d58ca..e0348956 100644
--- a/x86_64/salsa20-crypt.asm
+++ b/x86_64/salsa20-crypt.asm
@@ -245,3 +245,4 @@ PROLOGUE(nettle_salsa20_crypt)
 	ret
 
 EPILOGUE(nettle_salsa20_crypt)
+GNU_CET_SECTION()
diff --git a/x86_64/serpent-decrypt.asm b/x86_64/serpent-decrypt.asm
index 031c41c8..5f03fa4b 100644
--- a/x86_64/serpent-decrypt.asm
+++ b/x86_64/serpent-decrypt.asm
@@ -714,3 +714,4 @@ PROLOGUE(nettle_serpent_decrypt)
 	W64_EXIT(4, 13)
 	ret
 EPILOGUE(nettle_serpent_decrypt)
+GNU_CET_SECTION()
diff --git a/x86_64/serpent-encrypt.asm b/x86_64/serpent-encrypt.asm
index 99cba00c..6bee5d18 100644
--- a/x86_64/serpent-encrypt.asm
+++ b/x86_64/serpent-encrypt.asm
@@ -749,3 +749,4 @@ C parallell.
 	W64_EXIT(4, 13)
 	ret
 EPILOGUE(nettle_serpent_encrypt)
+GNU_CET_SECTION()
diff --git a/x86_64/sha1-compress.asm b/x86_64/sha1-compress.asm
index dd48de0e..54dfa313 100644
--- a/x86_64/sha1-compress.asm
+++ b/x86_64/sha1-compress.asm
@@ -305,3 +305,4 @@ PROLOGUE(nettle_sha1_compress)
 	W64_EXIT(2, 0)
 	ret
 EPILOGUE(nettle_sha1_compress)
+GNU_CET_SECTION()
diff --git a/x86_64/sha256-compress.asm b/x86_64/sha256-compress.asm
index 5b7d0dcd..8dbccc5b 100644
--- a/x86_64/sha256-compress.asm
+++ b/x86_64/sha256-compress.asm
@@ -208,3 +208,4 @@ PROLOGUE(_nettle_sha256_compress)
 	W64_EXIT(3, 0)
 	ret
 EPILOGUE(_nettle_sha256_compress)
+GNU_CET_SECTION()
diff --git a/x86_64/sha3-permute.asm b/x86_64/sha3-permute.asm
index 805b59af..a4d0cf0b 100644
--- a/x86_64/sha3-permute.asm
+++ b/x86_64/sha3-permute.asm
@@ -107,6 +107,7 @@ define(&lt;ROTL64&gt;, &lt;
 	
 	C sha3_permute(struct sha3_state *ctx)
 	.text
+GNU_CET_SECTION()
 	ALIGN(16)
 PROLOGUE(nettle_sha3_permute)
 	W64_ENTRY(1, 16)
diff --git a/x86_64/sha512-compress.asm b/x86_64/sha512-compress.asm
index 4ff1f32a..37563e93 100644
--- a/x86_64/sha512-compress.asm
+++ b/x86_64/sha512-compress.asm
@@ -208,3 +208,4 @@ PROLOGUE(_nettle_sha512_compress)
 	W64_EXIT(3, 0)
 	ret
 EPILOGUE(_nettle_sha512_compress)
+GNU_CET_SECTION()
diff --git a/x86_64/sha_ni/sha1-compress.asm b/x86_64/sha_ni/sha1-compress.asm
index ab848fdd..3cbca5e2 100644
--- a/x86_64/sha_ni/sha1-compress.asm
+++ b/x86_64/sha_ni/sha1-compress.asm
@@ -146,3 +146,4 @@ PROLOGUE(nettle_sha1_compress)
 	W64_EXIT(2, 10)
 	ret
 EPILOGUE(nettle_sha1_compress)
+GNU_CET_SECTION()
diff --git a/x86_64/sha_ni/sha256-compress.asm b/x86_64/sha_ni/sha256-compress.asm
index f2a4bd32..f9fe3757 100644
--- a/x86_64/sha_ni/sha256-compress.asm
+++ b/x86_64/sha_ni/sha256-compress.asm
@@ -173,3 +173,4 @@ PROLOGUE(_nettle_sha256_compress)
 	W64_EXIT(3, 10)
 	ret
 EPILOGUE(_nettle_sha256_compress)
+GNU_CET_SECTION()
diff --git a/x86_64/umac-nh-n.asm b/x86_64/umac-nh-n.asm
index ecb6396a..195d5886 100644
--- a/x86_64/umac-nh-n.asm
+++ b/x86_64/umac-nh-n.asm
@@ -273,3 +273,4 @@ PROLOGUE(_nettle_umac_nh_n)
 	W64_EXIT(5, 14)
 	ret
 EPILOGUE(_nettle_umac_nh_n)
+GNU_CET_SECTION()
diff --git a/x86_64/umac-nh.asm b/x86_64/umac-nh.asm
index a6938e02..7bfc87ba 100644
--- a/x86_64/umac-nh.asm
+++ b/x86_64/umac-nh.asm
@@ -79,3 +79,4 @@ PROLOGUE(_nettle_umac_nh)
 	W64_EXIT(3, 7)
 	ret
 EPILOGUE(_nettle_umac_nh)
+GNU_CET_SECTION()
-- 
2.20.1


["0004-WIP.patch" (0004-WIP.patch)]

From aab5f9215cb23da631c3c988c7765b1790079f41 Mon Sep 17 00:00:00 2001
From: Simo Sorce &lt;simo@redhat.com&gt;
Date: Sat, 27 Apr 2019 10:44:27 -0400
Subject: [PATCH 4/4] WIP

---
 arm/machine.m4                        | 3 +++
 asm.m4                                | 2 +-
 config.m4.in                          | 2 +-
 configure.ac                          | 7 -------
 sparc32/machine.m4                    | 2 ++
 sparc64/machine.m4                    | 3 +++
 x86/aes-decrypt-internal.asm          | 1 -
 x86/aes-encrypt-internal.asm          | 1 -
 x86/arcfour-crypt.asm                 | 1 -
 x86/camellia-crypt-internal.asm       | 1 -
 x86/machine.m4                        | 4 +++-
 x86/md5-compress.asm                  | 1 -
 x86/sha1-compress.asm                 | 1 -
 x86_64/aes-decrypt-internal.asm       | 1 -
 x86_64/aes-encrypt-internal.asm       | 1 -
 x86_64/aesni/aes-decrypt-internal.asm | 1 -
 x86_64/aesni/aes-encrypt-internal.asm | 1 -
 x86_64/camellia-crypt-internal.asm    | 1 -
 x86_64/chacha-core-internal.asm       | 1 -
 x86_64/fat/cpuid.asm                  | 2 +-
 x86_64/gcm-hash8.asm                  | 1 -
 x86_64/machine.m4                     | 4 +++-
 x86_64/md5-compress.asm               | 1 -
 x86_64/memxor.asm                     | 1 -
 x86_64/memxor3.asm                    | 1 -
 x86_64/poly1305-internal.asm          | 1 -
 x86_64/salsa20-core-internal.asm      | 1 -
 x86_64/salsa20-crypt.asm              | 1 -
 x86_64/serpent-decrypt.asm            | 1 -
 x86_64/serpent-encrypt.asm            | 1 -
 x86_64/sha1-compress.asm              | 1 -
 x86_64/sha256-compress.asm            | 1 -
 x86_64/sha3-permute.asm               | 1 -
 x86_64/sha512-compress.asm            | 1 -
 x86_64/sha_ni/sha1-compress.asm       | 1 -
 x86_64/sha_ni/sha256-compress.asm     | 1 -
 x86_64/umac-nh-n.asm                  | 1 -
 x86_64/umac-nh.asm                    | 1 -
 38 files changed, 17 insertions(+), 41 deletions(-)

diff --git a/arm/machine.m4 b/arm/machine.m4
index f982a66a..6c4801ef 100644
--- a/arm/machine.m4
+++ b/arm/machine.m4
@@ -54,3 +54,6 @@ define(&lt;D1REG&gt;, &lt;ifelse(
 	$1, q14, d29,
 	$1, q15, d31,
 	&lt;NO REGISTER&gt;)&gt;)dnl
+
+define(&lt;GNU_PROPERTY_NOTES&gt;, &lt;&gt;)
+define(&lt;CODEFROM&gt;, &lt;&gt;)
diff --git a/asm.m4 b/asm.m4
index 5a5d4ac2..cc31d97c 100644
--- a/asm.m4
+++ b/asm.m4
@@ -33,7 +33,7 @@ define(&lt;PROLOGUE&gt;,
 &lt;.globl C_NAME($1)
 DECLARE_FUNC(C_NAME($1))
 C_NAME($1):
-CET_ENDBR&gt;)
+CODEFROM()&gt;)
 
 define(&lt;EPILOGUE&gt;,
 &lt;ifelse(ELF_STYLE,yes,
diff --git a/config.m4.in b/config.m4.in
index c3ebad60..90796f26 100644
--- a/config.m4.in
+++ b/config.m4.in
@@ -9,7 +9,7 @@ define(&lt;W64_ABI&gt;, &lt;@W64_ABI@&gt;)dnl
 define(&lt;RODATA&gt;, &lt;@ASM_RODATA@&gt;)dnl
 define(&lt;WORDS_BIGENDIAN&gt;, &lt;@ASM_WORDS_BIGENDIAN@&gt;)dnl
 define(&lt;CET_PROTECTION&gt;, &lt;@ASM_CET_PROTECTION@&gt;)dnl
-define(&lt;CET_ENDBR&gt;, &lt;@ASM_CET_ENDBR@&gt;)dnl
 divert(1)
 @ASM_MARK_NOEXEC_STACK@
+GNU_PROPERTY_NOTES()
 divert
diff --git a/configure.ac b/configure.ac
index 7beb35d9..aba942ce 100644
--- a/configure.ac
+++ b/configure.ac
@@ -706,7 +706,6 @@ ASM_TYPE_FUNCTION='@function'
 ASM_TYPE_PROGBITS='@progbits'
 ASM_MARK_NOEXEC_STACK=''
 ASM_CET_PROTECTION='no'
-ASM_CET_ENDBR=''
 ASM_ALIGN_LOG=''
 ASM_GEN_BUILD_NOTES=''
 
@@ -842,11 +841,6 @@ EOF
 
   if test "x$enable_cet_protection" = xyes ; then
     ASM_CET_PROTECTION=yes
-    if test "$ABI" = 64 ; then
-      ASM_CET_ENDBR=endbr64
-    else
-      ASM_CET_ENDBR=endbr32
-    fi
   fi
 fi
 
@@ -861,7 +855,6 @@ AC_SUBST(W64_ABI)
 AC_SUBST(ASM_WORDS_BIGENDIAN)
 AC_SUBST(ASM_GEN_BUILD_NOTES)
 AC_SUBST(ASM_CET_PROTECTION)
-AC_SUBST(ASM_CET_ENDBR)
 AC_SUBST(EMULATOR)
 
 AC_SUBST(LIBNETTLE_MAJOR)
diff --git a/sparc32/machine.m4 b/sparc32/machine.m4
index e69de29b..59b43f8a 100644
--- a/sparc32/machine.m4
+++ b/sparc32/machine.m4
@@ -0,0 +1,2 @@
+define(&lt;GNU_PROPERTY_NOTES&gt;, &lt;&gt;)
+define(&lt;CODEFROM&gt;, &lt;&gt;)
diff --git a/sparc64/machine.m4 b/sparc64/machine.m4
index 4c1c0e5a..fe5cf5ef 100644
--- a/sparc64/machine.m4
+++ b/sparc64/machine.m4
@@ -2,3 +2,6 @@ define(&lt;BIAS&gt;, 2047) C Magic stack bias for the Sparc64 ABI
 
 .register %g2,#scratch
 .register %g3,#scratch
+
+define(&lt;GNU_PROPERTY_NOTES&gt;, &lt;&gt;)
+define(&lt;CODEFROM&gt;, &lt;&gt;)
diff --git a/x86/aes-decrypt-internal.asm b/x86/aes-decrypt-internal.asm
index 1d16f6db..ff535b6a 100644
--- a/x86/aes-decrypt-internal.asm
+++ b/x86/aes-decrypt-internal.asm
@@ -175,4 +175,3 @@ PROLOGUE(_nettle_aes_decrypt)
 	popl	%ebx
 	ret
 EPILOGUE(_nettle_aes_decrypt)
-GNU_CET_SECTION()
diff --git a/x86/aes-encrypt-internal.asm b/x86/aes-encrypt-internal.asm
index d9579e04..934158f7 100644
--- a/x86/aes-encrypt-internal.asm
+++ b/x86/aes-encrypt-internal.asm
@@ -175,4 +175,3 @@ PROLOGUE(_nettle_aes_encrypt)
 	popl	%ebx
 	ret
 EPILOGUE(_nettle_aes_encrypt)
-GNU_CET_SECTION()
diff --git a/x86/arcfour-crypt.asm b/x86/arcfour-crypt.asm
index 11f592e7..df3fe869 100644
--- a/x86/arcfour-crypt.asm
+++ b/x86/arcfour-crypt.asm
@@ -123,4 +123,3 @@ C .Lloop_done:
 	popl	%ebx
 	ret
 EPILOGUE(nettle_arcfour_crypt)
-GNU_CET_SECTION()
diff --git a/x86/camellia-crypt-internal.asm b/x86/camellia-crypt-internal.asm
index afac1fcc..ce8c57f0 100644
--- a/x86/camellia-crypt-internal.asm
+++ b/x86/camellia-crypt-internal.asm
@@ -223,4 +223,3 @@ PROLOGUE(_nettle_camellia_crypt)
 	popl	%ebx
 	ret
 EPILOGUE(_nettle_camellia_crypt)
-GNU_CET_SECTION()
diff --git a/x86/machine.m4 b/x86/machine.m4
index 1153c757..9341d837 100644
--- a/x86/machine.m4
+++ b/x86/machine.m4
@@ -29,7 +29,7 @@ dnl Shadow Stack
 define(&lt;GNU_PROPERTY_X86_FEATURE_1_SHSTK&gt;, &lt;0x02&gt;)
 
 dnl NOTE: GNU Property sections MUST have alignment of 8
-define(&lt;GNU_CET_SECTION&gt;,
+define(&lt;GNU_PROPERTY_NOTES&gt;,
 &lt;ifelse(CET_PROTECTION,yes,
 &lt;.pushsection .note.gnu.property,"a"
 ALIGN(8)
@@ -49,3 +49,5 @@ ALIGN(8)
 4:
 .popsection
 &gt;,&lt;&gt;)&gt;)
+
+define(&lt;CODEFROM&gt;, &lt;ifelse(CET_PROTECTION,yes,&lt;endbr32&gt;,&lt;&gt;)&gt;)
diff --git a/x86/md5-compress.asm b/x86/md5-compress.asm
index 6293f052..c849c082 100644
--- a/x86/md5-compress.asm
+++ b/x86/md5-compress.asm
@@ -185,4 +185,3 @@ PROLOGUE(nettle_md5_compress)
 	popl	%ebx
 	ret
 EPILOGUE(nettle_md5_compress)
-GNU_CET_SECTION()
diff --git a/x86/sha1-compress.asm b/x86/sha1-compress.asm
index 4e1f121c..03bdcdc9 100644
--- a/x86/sha1-compress.asm
+++ b/x86/sha1-compress.asm
@@ -1541,7 +1541,6 @@ C 	ROUND_F2(SB, SC, SD, SE, SA, 79, K4VALUE)
 	popl	%ebx
 	ret
 EPILOGUE(nettle_sha1_compress)
-GNU_CET_SECTION()
 
 C TODO:
 
diff --git a/x86_64/aes-decrypt-internal.asm b/x86_64/aes-decrypt-internal.asm
index eedfaaf0..43f2f394 100644
--- a/x86_64/aes-decrypt-internal.asm
+++ b/x86_64/aes-decrypt-internal.asm
@@ -150,4 +150,3 @@ PROLOGUE(_nettle_aes_decrypt)
 	W64_EXIT(6, 0)
 	ret
 EPILOGUE(_nettle_aes_decrypt)
-GNU_CET_SECTION()
diff --git a/x86_64/aes-encrypt-internal.asm b/x86_64/aes-encrypt-internal.asm
index 3a5a1e86..dfb498f5 100644
--- a/x86_64/aes-encrypt-internal.asm
+++ b/x86_64/aes-encrypt-internal.asm
@@ -151,4 +151,3 @@ PROLOGUE(_nettle_aes_encrypt)
 	W64_EXIT(6, 0)
 	ret
 EPILOGUE(_nettle_aes_encrypt)
-GNU_CET_SECTION()
diff --git a/x86_64/aesni/aes-decrypt-internal.asm b/x86_64/aesni/aes-decrypt-internal.asm
index 1b1a1a4d..3d6d6e30 100644
--- a/x86_64/aesni/aes-decrypt-internal.asm
+++ b/x86_64/aesni/aes-decrypt-internal.asm
@@ -132,4 +132,3 @@ PROLOGUE(_nettle_aes_decrypt)
 	W64_EXIT(6, 16)
 	ret
 EPILOGUE(_nettle_aes_decrypt)
-GNU_CET_SECTION()
diff --git a/x86_64/aesni/aes-encrypt-internal.asm b/x86_64/aesni/aes-encrypt-internal.asm
index f7338ef6..99caf1f8 100644
--- a/x86_64/aesni/aes-encrypt-internal.asm
+++ b/x86_64/aesni/aes-encrypt-internal.asm
@@ -132,4 +132,3 @@ PROLOGUE(_nettle_aes_encrypt)
 	W64_EXIT(6, 16)
 	ret
 EPILOGUE(_nettle_aes_encrypt)
-GNU_CET_SECTION()
diff --git a/x86_64/camellia-crypt-internal.asm b/x86_64/camellia-crypt-internal.asm
index 71750172..040e030f 100644
--- a/x86_64/camellia-crypt-internal.asm
+++ b/x86_64/camellia-crypt-internal.asm
@@ -200,4 +200,3 @@ PROLOGUE(_nettle_camellia_crypt)
 	W64_EXIT(6, 0)
 	ret
 EPILOGUE(_nettle_camellia_crypt)
-GNU_CET_SECTION()
diff --git a/x86_64/chacha-core-internal.asm b/x86_64/chacha-core-internal.asm
index 3125dee7..9e5dc394 100644
--- a/x86_64/chacha-core-internal.asm
+++ b/x86_64/chacha-core-internal.asm
@@ -126,4 +126,3 @@ PROLOGUE(_nettle_chacha_core)
 	W64_EXIT(3, 6)
 	ret
 EPILOGUE(_nettle_chacha_core)
-GNU_CET_SECTION()
diff --git a/x86_64/fat/cpuid.asm b/x86_64/fat/cpuid.asm
index c4a5b538..f317d56e 100644
--- a/x86_64/fat/cpuid.asm
+++ b/x86_64/fat/cpuid.asm
@@ -56,4 +56,4 @@ PROLOGUE(_nettle_cpuid)
 	W64_EXIT(2)
 	ret
 EPILOGUE(_nettle_cpuid)
-GNU_CET_SECTION()
+
diff --git a/x86_64/gcm-hash8.asm b/x86_64/gcm-hash8.asm
index 54608ae8..bfaa6ef8 100644
--- a/x86_64/gcm-hash8.asm
+++ b/x86_64/gcm-hash8.asm
@@ -199,7 +199,6 @@ ALIGN(16)
 	jnz	.Lread_loop
 	ret
 EPILOGUE(_nettle_gcm_hash8)
-GNU_CET_SECTION()
 
 define(&lt;W&gt;, &lt;0x$2$1&gt;)
 	RODATA
diff --git a/x86_64/machine.m4 b/x86_64/machine.m4
index a64241ce..1c07665d 100644
--- a/x86_64/machine.m4
+++ b/x86_64/machine.m4
@@ -186,7 +186,7 @@ dnl Shadow Stack
 define(&lt;GNU_PROPERTY_X86_FEATURE_1_SHSTK&gt;, &lt;0x02&gt;)
 
 dnl NOTE: GNU Property sections MUST have alignment of 8
-define(&lt;GNU_CET_SECTION&gt;,
+define(&lt;GNU_PROPERTY_NOTES&gt;,
 &lt;ifelse(CET_PROTECTION,yes,
 &lt;.pushsection .note.gnu.property,"a"
 ALIGN(8)
@@ -206,3 +206,5 @@ ALIGN(8)
 4:
 .popsection
 &gt;,&lt;&gt;)&gt;)
+
+define(&lt;CODEFROM&gt;, &lt;ifelse(CET_PROTECTION,yes,&lt;endbr64&gt;,&lt;&gt;)&gt;)
diff --git a/x86_64/md5-compress.asm b/x86_64/md5-compress.asm
index ef1fcb89..182b8f18 100644
--- a/x86_64/md5-compress.asm
+++ b/x86_64/md5-compress.asm
@@ -174,4 +174,3 @@ PROLOGUE(nettle_md5_compress)
 
 	ret
 EPILOGUE(nettle_md5_compress)
-GNU_CET_SECTION()
diff --git a/x86_64/memxor.asm b/x86_64/memxor.asm
index a0ea94b4..f07f0017 100644
--- a/x86_64/memxor.asm
+++ b/x86_64/memxor.asm
@@ -171,4 +171,3 @@ ifdef(&lt;USE_SSE2&gt;, &lt;
 &gt;)	
 
 EPILOGUE(nettle_memxor)
-GNU_CET_SECTION()
diff --git a/x86_64/memxor3.asm b/x86_64/memxor3.asm
index b0c0e35c..8ff3e79c 100644
--- a/x86_64/memxor3.asm
+++ b/x86_64/memxor3.asm
@@ -261,4 +261,3 @@ ifelse(USE_SSE2, yes, &lt;
 	
 
 EPILOGUE(nettle_memxor3)
-GNU_CET_SECTION()
diff --git a/x86_64/poly1305-internal.asm b/x86_64/poly1305-internal.asm
index 3737450f..98159ad3 100644
--- a/x86_64/poly1305-internal.asm
+++ b/x86_64/poly1305-internal.asm
@@ -184,4 +184,3 @@ define(&lt;T1&gt;, &lt;%rax&gt;)
 	ret
 EPILOGUE(nettle_poly1305_digest)
 
-GNU_CET_SECTION()
diff --git a/x86_64/salsa20-core-internal.asm b/x86_64/salsa20-core-internal.asm
index c1690880..4ef07be0 100644
--- a/x86_64/salsa20-core-internal.asm
+++ b/x86_64/salsa20-core-internal.asm
@@ -109,4 +109,3 @@ PROLOGUE(_nettle_salsa20_core)
 	W64_EXIT(3, 9)
 	ret
 EPILOGUE(_nettle_salsa20_core)
-GNU_CET_SECTION()
diff --git a/x86_64/salsa20-crypt.asm b/x86_64/salsa20-crypt.asm
index e0348956..cc1d58ca 100644
--- a/x86_64/salsa20-crypt.asm
+++ b/x86_64/salsa20-crypt.asm
@@ -245,4 +245,3 @@ PROLOGUE(nettle_salsa20_crypt)
 	ret
 
 EPILOGUE(nettle_salsa20_crypt)
-GNU_CET_SECTION()
diff --git a/x86_64/serpent-decrypt.asm b/x86_64/serpent-decrypt.asm
index 5f03fa4b..031c41c8 100644
--- a/x86_64/serpent-decrypt.asm
+++ b/x86_64/serpent-decrypt.asm
@@ -714,4 +714,3 @@ PROLOGUE(nettle_serpent_decrypt)
 	W64_EXIT(4, 13)
 	ret
 EPILOGUE(nettle_serpent_decrypt)
-GNU_CET_SECTION()
diff --git a/x86_64/serpent-encrypt.asm b/x86_64/serpent-encrypt.asm
index 6bee5d18..99cba00c 100644
--- a/x86_64/serpent-encrypt.asm
+++ b/x86_64/serpent-encrypt.asm
@@ -749,4 +749,3 @@ C parallell.
 	W64_EXIT(4, 13)
 	ret
 EPILOGUE(nettle_serpent_encrypt)
-GNU_CET_SECTION()
diff --git a/x86_64/sha1-compress.asm b/x86_64/sha1-compress.asm
index 54dfa313..dd48de0e 100644
--- a/x86_64/sha1-compress.asm
+++ b/x86_64/sha1-compress.asm
@@ -305,4 +305,3 @@ PROLOGUE(nettle_sha1_compress)
 	W64_EXIT(2, 0)
 	ret
 EPILOGUE(nettle_sha1_compress)
-GNU_CET_SECTION()
diff --git a/x86_64/sha256-compress.asm b/x86_64/sha256-compress.asm
index 8dbccc5b..5b7d0dcd 100644
--- a/x86_64/sha256-compress.asm
+++ b/x86_64/sha256-compress.asm
@@ -208,4 +208,3 @@ PROLOGUE(_nettle_sha256_compress)
 	W64_EXIT(3, 0)
 	ret
 EPILOGUE(_nettle_sha256_compress)
-GNU_CET_SECTION()
diff --git a/x86_64/sha3-permute.asm b/x86_64/sha3-permute.asm
index a4d0cf0b..805b59af 100644
--- a/x86_64/sha3-permute.asm
+++ b/x86_64/sha3-permute.asm
@@ -107,7 +107,6 @@ define(&lt;ROTL64&gt;, &lt;
 	
 	C sha3_permute(struct sha3_state *ctx)
 	.text
-GNU_CET_SECTION()
 	ALIGN(16)
 PROLOGUE(nettle_sha3_permute)
 	W64_ENTRY(1, 16)
diff --git a/x86_64/sha512-compress.asm b/x86_64/sha512-compress.asm
index 37563e93..4ff1f32a 100644
--- a/x86_64/sha512-compress.asm
+++ b/x86_64/sha512-compress.asm
@@ -208,4 +208,3 @@ PROLOGUE(_nettle_sha512_compress)
 	W64_EXIT(3, 0)
 	ret
 EPILOGUE(_nettle_sha512_compress)
-GNU_CET_SECTION()
diff --git a/x86_64/sha_ni/sha1-compress.asm b/x86_64/sha_ni/sha1-compress.asm
index 3cbca5e2..ab848fdd 100644
--- a/x86_64/sha_ni/sha1-compress.asm
+++ b/x86_64/sha_ni/sha1-compress.asm
@@ -146,4 +146,3 @@ PROLOGUE(nettle_sha1_compress)
 	W64_EXIT(2, 10)
 	ret
 EPILOGUE(nettle_sha1_compress)
-GNU_CET_SECTION()
diff --git a/x86_64/sha_ni/sha256-compress.asm b/x86_64/sha_ni/sha256-compress.asm
index f9fe3757..f2a4bd32 100644
--- a/x86_64/sha_ni/sha256-compress.asm
+++ b/x86_64/sha_ni/sha256-compress.asm
@@ -173,4 +173,3 @@ PROLOGUE(_nettle_sha256_compress)
 	W64_EXIT(3, 10)
 	ret
 EPILOGUE(_nettle_sha256_compress)
-GNU_CET_SECTION()
diff --git a/x86_64/umac-nh-n.asm b/x86_64/umac-nh-n.asm
index 195d5886..ecb6396a 100644
--- a/x86_64/umac-nh-n.asm
+++ b/x86_64/umac-nh-n.asm
@@ -273,4 +273,3 @@ PROLOGUE(_nettle_umac_nh_n)
 	W64_EXIT(5, 14)
 	ret
 EPILOGUE(_nettle_umac_nh_n)
-GNU_CET_SECTION()
diff --git a/x86_64/umac-nh.asm b/x86_64/umac-nh.asm
index 7bfc87ba..a6938e02 100644
--- a/x86_64/umac-nh.asm
+++ b/x86_64/umac-nh.asm
@@ -79,4 +79,3 @@ PROLOGUE(_nettle_umac_nh)
 	W64_EXIT(3, 7)
 	ret
 EPILOGUE(_nettle_umac_nh)
-GNU_CET_SECTION()
-- 
2.20.1


[Attachment #7 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200309180324</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-03-09 18:03:24-0400</timestampReceived><subject>Re: [PATCH] x86: Add X86_ENDBR and CET marker to config.m4.in</subject><body>

Simo Sorce &lt;simo@redhat.com&gt; writes:

&gt; The patchset i solder than I did remember, April 2019
&gt; But I recall running at least one version of it on our CET emulator @
&gt; Red Hat.

Sorry I forgot to followup on that. It seems only the first easy cleanup
patch, "Add missing EPILOGUEs in assembly files", was applied back then.

Do you remember why you used GNU_CET_SECTION() explicitly in .asm files,
rather than using an m4 divert?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200309181917</emailId><senderName>Simo Sorce</senderName><senderEmail>simo@redhat.com</senderEmail><timestampReceived>2020-03-09 18:19:17-0400</timestampReceived><subject>Re: [PATCH] x86: Add X86_ENDBR and CET marker to config.m4.in</subject><body>

On Mon, 2020-03-09 at 19:03 +0100, Niels Möller wrote:
&gt; Simo Sorce &lt;simo@redhat.com&gt; writes:
&gt; 
&gt; &gt; The patchset i solder than I did remember, April 2019
&gt; &gt; But I recall running at least one version of it on our CET emulator @
&gt; &gt; Red Hat.
&gt; 
&gt; Sorry I forgot to followup on that. It seems only the first easy cleanup
&gt; patch, "Add missing EPILOGUEs in assembly files", was applied back then.
&gt; 
&gt; Do you remember why you used GNU_CET_SECTION() explicitly in .asm files,
&gt; rather than using an m4 divert?

Not really I do not recall anymore, but I think there was a reason, as
I recall you made that comment back then and it "didn't work out" when
I tried is the memory I have of it.
Might have to do with differences in how it lays out the code when done
via m4 divert, but not 100% sure.

Simo.

-- 
Simo Sorce
RHEL Crypto Team
Red Hat, Inc




_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200309191948</emailId><senderName>Simo Sorce</senderName><senderEmail>simo@redhat.com</senderEmail><timestampReceived>2020-03-09 19:19:48-0400</timestampReceived><subject>Re: [PATCH] x86: Add X86_ENDBR and CET marker to config.m4.in</subject><body>

On Mon, 2020-03-09 at 11:56 -0700, H.J. Lu wrote:
&gt; On Mon, Mar 9, 2020 at 11:19 AM Simo Sorce &lt;simo@redhat.com&gt; wrote:
&gt; &gt; On Mon, 2020-03-09 at 19:03 +0100, Niels Möller wrote:
&gt; &gt; &gt; Simo Sorce &lt;simo@redhat.com&gt; writes:
&gt; &gt; &gt; 
&gt; &gt; &gt; &gt; The patchset i solder than I did remember, April 2019
&gt; &gt; &gt; &gt; But I recall running at least one version of it on our CET emulator @
&gt; &gt; &gt; &gt; Red Hat.
&gt; &gt; &gt; 
&gt; &gt; &gt; Sorry I forgot to followup on that. It seems only the first easy cleanup
&gt; &gt; &gt; patch, "Add missing EPILOGUEs in assembly files", was applied back then.
&gt; &gt; &gt; 
&gt; &gt; &gt; Do you remember why you used GNU_CET_SECTION() explicitly in .asm files,
&gt; &gt; &gt; rather than using an m4 divert?
&gt; &gt; 
&gt; &gt; Not really I do not recall anymore, but I think there was a reason, as
&gt; &gt; I recall you made that comment back then and it "didn't work out" when
&gt; &gt; I tried is the memory I have of it.
&gt; &gt; Might have to do with differences in how it lays out the code when done
&gt; &gt; via m4 divert, but not 100% sure.
&gt; &gt; 
&gt; 
&gt; m4 divert  requires much less changes.   Here is the updated patch with
&gt; ASM_X86_ENDBR, ASM_X86_MARK_CET_ALIGN and ASM_X86_MARK_CET.
&gt; 
&gt; 

Two comments on your patch.

1. It is an error to align based on architecture. All GNU Notes MUST be
aligned 8 bytes. Since 2018 GNU Libc ignores misaligned notes.

2. It is better to use .pushsection .popsection pairs around the note
instead of .section because of the side effects of using .section

The m4 divert looks smaller impact, feel free to lift the Gnu Note
section in my patch #3 and place it into your patch if you want. My
code also made it more explicit what all the sections values actually
mean which will help in long term maintenance if someone else need to
change anything (like for example changing to enable only ShadowStack
vs IBT).

Simo.

-- 
Simo Sorce
RHEL Crypto Team
Red Hat, Inc




_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200218113120</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-02-18 11:31:20-0400</timestampReceived><subject>Re: Armeb is broken</subject><body>

Андрей Аладьев &lt;aladjev.andrew@gmail.com&gt; writes:

&gt; Hello, please see the following gnutls issue
&gt; https://gitlab.com/gnutls/gnutls/issues/941.
&gt;
&gt; Nettle today is working on aarch64, aarch64_be and arm, but broken on armeb.

As Michael Weiser said, he contributed changes to arm assembly a while
ago, to support armeb. I can't say why that fails in your setting.
Double check that big-endian is detected correctly by configure.

Also try to configure nettle --without-assembler, if that also fails,
then it maybe something else in the environment that is broken.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200218165905</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2020-02-18 16:59:05-0400</timestampReceived><subject>Re: Armeb is broken</subject><body>

Hello Niels,

On Tue, Feb 18, 2020 at 12:25:05PM +0100, Niels Möller wrote:

&gt; &gt; Let me know if there are any outstanding issues regarding armeb and I'll
&gt; &gt; look into them.
&gt; To keep it in working shape, it would help a lot with additional tests
&gt; in .gitlab-ci. I'm not really familiar with the cross setup used for
&gt; arm, mips, and aarch64, Nikos helped with all that. But maybe armeb can
&gt; be added in the same way?

That's exactly the rabbithole I went down and got lost in the last time:
armeb is so niche that I'm not aware of any ready-to-install mainstream
distribution for it. I am running Gentoo but that's not easy to maintain
in a CI setting. I got a Debian-based qemu-user-binfmt_misc-based image
working but that was very brittle as well because in the end it also
needed to bootstrap the necessary components from source. So as it
stands I cannot offer any improved CI for armeb that's maintainable with
reasonable effort.

On the other hand: The armeb asm changes (for the most part) are so
symmetric that any breakage would likely affect both armeb and armel.
-- 
Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200218204501</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-02-18 20:45:01-0400</timestampReceived><subject>Re: Armeb is broken</subject><body>

Michael Weiser &lt;michael.weiser@gmx.de&gt; writes:

&gt; That's exactly the rabbithole I went down and got lost in the last time:
&gt; armeb is so niche that I'm not aware of any ready-to-install mainstream
&gt; distribution for it. I am running Gentoo but that's not easy to maintain
&gt; in a CI setting. I got a Debian-based qemu-user-binfmt_misc-based image
&gt; working but that was very brittle as well because in the end it also
&gt; needed to bootstrap the necessary components from source.

I think there's been some effort to make debian easier to bootstrap for
new architectures, but I don't know current state. Gnu guix people are
also taking bootstrap very seriously.

&gt; So as it stands I cannot offer any improved CI for armeb that's
&gt; maintainable with reasonable effort.

Then you (or other volunteers with interest in armeb) needs to do manual
tests of Nettle from time to time, to keep it in working shape.

&gt; On the other hand: The armeb asm changes (for the most part) are so
&gt; symmetric that any breakage would likely affect both armeb and armel.

There's been very few changes to the arm files since you contributed the
armeb fixes (seems to be two years ago). But whenever there's some new
code or larger rewrites there, it's likely that armeb will be broken in
the process. Testing, be that ci or more manual, is essential.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200219174602</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2020-02-19 17:46:02-0400</timestampReceived><subject>Re: Armeb is broken</subject><body>

Hi Niels,

On Tue, Feb 18, 2020 at 09:45:01PM +0100, Niels Möller wrote:

&gt; &gt; That's exactly the rabbithole I went down and got lost in the last time:
&gt; &gt; armeb is so niche that I'm not aware of any ready-to-install mainstream
&gt; &gt; distribution for it. I am running Gentoo but that's not easy to maintain
&gt; &gt; in a CI setting. I got a Debian-based qemu-user-binfmt_misc-based image
&gt; &gt; working but that was very brittle as well because in the end it also
&gt; &gt; needed to bootstrap the necessary components from source.
&gt; I think there's been some effort to make debian easier to bootstrap for
&gt; new architectures, but I don't know current state. Gnu guix people are
&gt; also taking bootstrap very seriously.

I had been working with rebootstrap. But that's not really meant to be
able to reliably bootstrap from source at any given point in time but
instead to show up bootstrapping problems as a CI measure for the Debian
distribution iteself. That means that it breaks on an almost daily basis
and an armeb image built with it will need considerable attention to
build again after a couple of weeks or months.

&gt; &gt; So as it stands I cannot offer any improved CI for armeb that's
&gt; &gt; maintainable with reasonable effort.
&gt; Then you (or other volunteers with interest in armeb) needs to do manual
&gt; tests of Nettle from time to time, to keep it in working shape.

I will again look into some sort of CI for armeb.
-- 
Thanks,
Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200221160254</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-02-21 16:02:54-0400</timestampReceived><subject>Re: Armeb is broken</subject><body>

Hello,

вт, 18 февр. 2020 г. в 13:30, Michael Weiser &lt;michael.weiser@gmx.de&gt;:
&gt; On Tue, Feb 18, 2020 at 02:28:50AM +0300, Андрей Аладьев wrote:
&gt; &gt; Hello, please see the following gnutls issue
&gt; &gt; https://gitlab.com/gnutls/gnutls/issues/941.
&gt;
&gt; &gt; Nettle today is working on aarch64, aarch64_be and arm, but broken on armeb.
&gt;
&gt; Nice to see that someone other than me is doing armeb. :)
&gt;
&gt; The asm for arm certainly needed adjustment to work on armeb. See
&gt; https://lists.lysator.liu.se/pipermail/nettle-bugs/2018/007280.html.

What is the target hardware for armeb? I have tried building Nettle
for armv5teb (thinking about NSLU2) and got failures because of `rev`
instruction usage (present only on ARMv6/v7).

Andrew, if you are testing it with qemu, there well might be emulation
deficiencies.

-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200221191528</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2020-02-21 19:15:28-0400</timestampReceived><subject>Re: Armeb is broken</subject><body>

Hi Dmitry,

On Fri, Feb 21, 2020 at 07:02:54PM +0300, Dmitry Baryshkov wrote:

&gt; &gt; The asm for arm certainly needed adjustment to work on armeb. See
&gt; &gt; https://lists.lysator.liu.se/pipermail/nettle-bugs/2018/007280.html.
&gt; What is the target hardware for armeb?

I am *using* it on Cubieboard 2's which are armv7. I don't think there's
eveer been an actual hardware support statement.

&gt; I have tried building Nettle
&gt; for armv5teb (thinking about NSLU2) and got failures because of `rev`
&gt; instruction usage (present only on ARMv6/v7).

Huh, right. Most of the revs are in the v6 and neon subdirectories which
should be fine because they are only activated for v6+. So we'd need to
eliminate the revs in arm/memxor.asm and arm/memxor3.asm to support
armv5teb.

&gt; Andrew, if you are testing it with qemu, there well might be emulation
&gt; deficiencies.

I could dust off the old binfmt_misc setup for armv6veb and give that a
whirl if it's of any help. I'm quite certain I initially worked around
the asm problems on armeb by disabling asm when cross- and
binfmt_misc-qemu-natively-compiling the userland for my Cubies. So I
have likely never run the asm under qemu-user nor qemu-system.
-- 
Thanks,
Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200222065810</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-02-22 06:58:10-0400</timestampReceived><subject>Re: Armeb is broken</subject><body>

Michael Weiser &lt;michael.weiser@gmx.de&gt; writes:

&gt; I am *using* it on Cubieboard 2's which are armv7. I don't think there's
&gt; eveer been an actual hardware support statement.

Question is, what devices are out where, there armv5 support would be
useful?

&gt;&gt; I have tried building Nettle
&gt;&gt; for armv5teb (thinking about NSLU2) and got failures because of `rev`
&gt;&gt; instruction usage (present only on ARMv6/v7).

Lookingup NSLU2 on wikipedia, it seems it features a "Intel XScale cpu"
featuring an "ARMv5TE ISA without the floating point instructions." I
take it this can be run in BE mode?

&gt; Huh, right. Most of the revs are in the v6 and neon subdirectories which
&gt; should be fine because they are only activated for v6+. So we'd need to
&gt; eliminate the revs in arm/memxor.asm and arm/memxor3.asm to support
&gt; armv5teb.

Options are:

1. Do nothing, let armbe assembly require armv6, and recommend
   --disable-assembly for armv5be.

2. Eliminate use of rev in the armbe code.

3. Somehow arrange in configure so that the memxor files in particular
   aren't used when targetting armv5be. If you want to test the effects
   before hacking configure.ac, I think it should be as easy as removing
   the memxor*.asm symlinks after running configure.

&gt; I could dust off the old binfmt_misc setup for armv6veb and give that a
&gt; whirl if it's of any help. I'm quite certain I initially worked around
&gt; the asm problems on armeb by disabling asm when cross- and
&gt; binfmt_misc-qemu-natively-compiling the userland for my Cubies. So I
&gt; have likely never run the asm under qemu-user nor qemu-system.

Is there some problem with configuring qemu to emulate armv6? I think
that's what is used when testing non-BE ARM, but I'm not 100% sure about
that.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200222184318</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2020-02-22 18:43:18-0400</timestampReceived><subject>Re: Armeb is broken</subject><body>

Hi Niels,

On Sat, Feb 22, 2020 at 07:58:10AM +0100, Niels Möller wrote:

&gt; &gt; I am *using* it on Cubieboard 2's which are armv7. I don't think there's
&gt; &gt; eveer been an actual hardware support statement.
&gt; Question is, what devices are out where, there armv5 support would be
&gt; useful?

Well, arm devices are quite long-lived. I myself had my Marvel Kirkwood
based NASes (which were armv5 but never ran BE) running way longer than
I would have kept a similar x86 system around. These were 300Mhz and
128MiB of RAM, so totally underpowered, but they did their job. But with
the current hype about aarch64 I'd expect the armv5 installation base to
be shrinking.

&gt; &gt;&gt; I have tried building Nettle
&gt; &gt;&gt; for armv5teb (thinking about NSLU2) and got failures because of `rev`
&gt; &gt;&gt; instruction usage (present only on ARMv6/v7).
&gt; Lookingup NSLU2 on wikipedia, it seems it features a "Intel XScale cpu"
&gt; featuring an "ARMv5TE ISA without the floating point instructions." I
&gt; take it this can be run in BE mode?

The Intel XScale and IXP4xx are BE by default, IIRC. For them it's even
a bit of a hike to run them LE since all their companion controllers and
firmware blobs are BE as well.

&gt; &gt; Huh, right. Most of the revs are in the v6 and neon subdirectories which
&gt; &gt; should be fine because they are only activated for v6+. So we'd need to
&gt; &gt; eliminate the revs in arm/memxor.asm and arm/memxor3.asm to support
&gt; &gt; armv5teb.
&gt; Options are:

&gt; 1. Do nothing, let armbe assembly require armv6, and recommend
&gt;    --disable-assembly for armv5be.

asm was broken for *any* armeb platform before the changes. Now it's
working fine for armv6+, but, ...

&gt; 2. Eliminate use of rev in the armbe code.

... I've been looking at the revs and they now strike me as taking the
easy way out anyway. They work around the implicit LE order in which
some remaining bytes from a buffer are saved byte-wise. This should be
doable without the revs by making the store work in BE fashion in BE
mode. I plan to look into this but would certainly appreciate any help
Dmitry and Андрей might be able to give here since it's not as if I've
been doing nothing but arm asm the last couple of years - rather the
opposite.

&gt; 3. Somehow arrange in configure so that the memxor files in particular
&gt;    aren't used when targetting armv5be. If you want to test the effects
&gt;    before hacking configure.ac, I think it should be as easy as removing
&gt;    the memxor*.asm symlinks after running configure.

Nah, we can do better than that. :)

&gt; &gt; I could dust off the old binfmt_misc setup for armv6veb and give that a
That'd be armv7veb, BTW.

&gt; &gt; whirl if it's of any help. I'm quite certain I initially worked around
&gt; &gt; the asm problems on armeb by disabling asm when cross- and
&gt; &gt; binfmt_misc-qemu-natively-compiling the userland for my Cubies. So I
&gt; &gt; have likely never run the asm under qemu-user nor qemu-system.
&gt; Is there some problem with configuring qemu to emulate armv6? I think
&gt; that's what is used when testing non-BE ARM, but I'm not 100% sure about
&gt; that.

No, qemu-armeb should be able to do armv5eb and armv6eb just fine. It's
just that I have experience and existing configs for this armv7veb setup
since that's what I'm running on my cubies. Once I've sorted that, I
should be able to use it to compile to armv5 and armv6 to see what
breaks at the compilation stage already. I could also run these armv5
and armv6 binaries through qemu-armeb to see what breaks at runtime. I
should also be able to produce similar setups for armv5 and armv6 to
uncover any remaining incompatibilities which are somehow masked on the
more capable armv7veb setup.

As a ramble, since I wrote it up before re-reading and -interpreting
your question: That's exactly what I mean with "cross- and
binfmt_misc-qemu-natively-compiling" setup: With Gentoo I can quite
easily create a system-integrated cross-compiler toolchain for armeb and
the package manager can use it to cross-compile a rootfs containing a
native armeb toolchain, nettle and all its dependencies. This can be
taken just as far as cross-compiling nettle and then running the
testsuite under qemu-armeb, the user emulation mode where qemu-armeb
acts as interpreter for the foreign binary executable format via
binfmt_misc and emulates the Linux syscalls for the userland programs.
It can also go as far as chrooting into the rootfs with qemu-armb
executing a whole armeb userland via binfmt_misc and then using the
native toolchain installed therein to compile everything including
nettle natively (from its point of view).

The latter is what current arm CI is doing IIRC but based on Debian's
native support for arm combined with its capability of installing
multiple architectures into a single rootfs at once (multillib).

Something similar to the Gentoo-approach should be doable with buildroot
which I am currently looking into for armeb CI purposes: buildroot could
generate a cross-compiler toolchain and rootfs for nettle CI. This would
be much more maintainable than Debian's rebootstrap since armeb is an
actual supported target platform of buildroot. A minor problem with it
(and likely similar projects such as openwrt) is that they're focused
on cross-compilation for an embedded system. So AFAI{K,CT,CS} they are
not able to produce a native toolchain for the target platform which
rules out qemu variant 2 above.

If anyone knows any other project which produces an armeb binary
distribution or specializes in bootstrapping cross-compilers and
rootfses that support armeb natively, I'd very much appreciate the
pointer.
-- 
Thanks,
Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200223153406</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2020-02-23 15:34:06-0400</timestampReceived><subject>Re: Armeb is broken</subject><body>

Hi all,

On Sat, Feb 22, 2020 at 07:43:18PM +0100, Michael Weiser wrote:

&gt; &gt; 2. Eliminate use of rev in the armbe code.
&gt; ... I've been looking at the revs and they now strike me as taking the
&gt; easy way out anyway. They work around the implicit LE order in which

Updated code is now at
https://git.lysator.liu.se/michaelweiser/nettle/-/tree/arm-memxor-generic
and inline below for comments.

It now compiles and runs the testsuite fine on my native armv7veb when
configurd with:

CFLAGS="-march=armv6" LDFLAGS="-march=armv6" \
	../configure --disable-documentation \
		--host=armv6b-unknown-linux-gnueabihf
[...]
  Assembly files:    arm/neon arm/v6 arm

and:

CFLAGS="-march=armv5te" LDFLAGS="-march=armv5te -Wl,--be8" \
	../configure --disable-documentation \
		--host=armv5b-unknown-linux-gnueabihf
[...]
  Assembly files:    arm

LDFLAGS "-Wl,--be8" is necessary for armv5teb to work on my system
because it is BE8 which the gcc linker driver defaults to when run with
-march=armv6 but not for armv5 which causes the resuling binaries to be
BE32 and segfault or bus error in ld-linux.so.3 on startup. For a
(likely wrong) explanation of BE8 vs. BE32 see
https://lists.lysator.liu.se/pipermail/nettle-bugs/2018/007059.html.

A quick check can be done with file:

$ echo "int main(void) {}" &gt; t.c
$ gcc -march=armv5te -o t t.c
$ ./t
Segmentation fault
$ file t
t: ELF 32-bit MSB shared object, ARM, EABI5 version 1 (SYSV),
dynamically linked, interpreter /lib/ld-linux-armhf.so.3, for GNU/Linux
3.2.0, not stripped
$ gcc -march=armv5te -Wl,--be8 -o t t.c
$ ./t
$ file t
t: ELF 32-bit MSB shared object, ARM, EABI5 BE8 version 1 (SYSV),
dynamically linked, interpreter /lib/ld-linux-armhf.so.3, for GNU/Linux
3.2.0, not stripped

The qemu environment is churning along in compilation currently.

Previous assembler error for reference:

$ make -j4
[...]
/usr/bin/m4 ../asm.m4 machine.m4 config.m4 memxor.asm &gt;memxor.s
/usr/bin/m4 ../asm.m4 machine.m4 config.m4 memxor3.asm &gt;memxor3.s
gcc -I.  -DHAVE_CONFIG_H -march=armv5te -ggdb3 -Wall -W
-Wmissing-prototypes -Wmissing-declarations -Wstrict-prototypes
-Wpointer-arith -Wbad-function-cast -Wnested-externs -fpic -MT memxor.o
-MD -MP -MF memxor.o.d -c memxor.s
gcc -I.  -DHAVE_CONFIG_H -march=armv5te -ggdb3 -Wall -W
-Wmissing-prototypes -Wmissing-declarations -Wstrict-prototypes
-Wpointer-arith -Wbad-function-cast -Wnested-externs -fpic -MT memxor3.o
-MD -MP -MF memxor3.o.d -c memxor3.s
memxor.s: memxor3.s: Assembler messages:
memxor3.s:146: Error: selected processor does not support `rev r4,r4' in ARM mode
Assembler messages:
memxor3.s:256: Error: selected processor does not support `rev r4,r4' in ARM mode
memxor.s:126: Error: selected processor does not support `rev r3,r3' in ARM mode
-- 
Thanks,
Michael

From 3e2118d41472842c368bb5bb56d71023b861b59d Mon Sep 17 00:00:00 2001
From: Michael Weiser &lt;michael.weiser@gmx.de&gt;
Date: Sun, 23 Feb 2020 15:22:51 +0100
Subject: [PATCH] arm: Fix memxor for non-armv6+ big-endian systems

ARM assembly adjustments for big-endian systems contained armv6+-only
instructions (rev) in generic arm memxor code. Replace those with an
actual conversion of the leftover byte store routines for big-endian
systems. This also provides a slight optimisation by removing the
additional instruction as well as increased symmetry between little- and
big-endian implementations.

Signed-off-by: Michael Weiser &lt;michael.weiser@gmx.de&gt;
---
 arm/memxor.asm  | 12 ++++++------
 arm/memxor3.asm | 27 ++++++++++++++-------------
 2 files changed, 20 insertions(+), 19 deletions(-)

diff --git a/arm/memxor.asm b/arm/memxor.asm
index 239a4034..b802e95c 100644
--- a/arm/memxor.asm
+++ b/arm/memxor.asm
@@ -138,24 +138,24 @@ PROLOGUE(nettle_memxor)
 	adds	N, #8
 	beq	.Lmemxor_odd_done
 
-	C We have TNC/8 left-over bytes in r4, high end
+	C We have TNC/8 left-over bytes in r4, (since working upwards) low
+	C end on LE and high end on BE
 	S0ADJ	r4, CNT
 	ldr	r3, [DST]
 	eor	r3, r4
 
-	C memxor_leftover does an LSB store
-	C so we need to reverse if actually BE
-IF_BE(&lt;	rev	r3, r3&gt;)
-
 	pop	{r4,r5,r6}
 
 	C Store bytes, one by one.
 .Lmemxor_leftover:
+	C bring uppermost byte down for saving while preserving lower ones
+IF_BE(&lt;	ror	r3, #24&gt;)
 	strb	r3, [DST], #+1
 	subs	N, #1
 	beq	.Lmemxor_done
 	subs	TNC, #8
-	lsr	r3, #8
+	C bring down next byte, no need to preserve
+IF_LE(&lt;	lsr	r3, #8&gt;)
 	bne	.Lmemxor_leftover
 	b	.Lmemxor_bytes
 .Lmemxor_odd_done:
diff --git a/arm/memxor3.asm b/arm/memxor3.asm
index 69598e1c..76b8aae6 100644
--- a/arm/memxor3.asm
+++ b/arm/memxor3.asm
@@ -159,21 +159,21 @@ PROLOGUE(nettle_memxor3)
 	adds	N, #8
 	beq	.Lmemxor3_done
 
-	C Leftover bytes in r4, low end
+	C Leftover bytes in r4, (since working downwards) in high end on LE and
+	C low end on BE
 	ldr	r5, [AP, #-4]
 	eor	r4, r5, r4, S1ADJ ATNC
 
-	C leftover does an LSB store
-	C so we need to reverse if actually BE
-IF_BE(&lt;	rev	r4, r4&gt;)
-
 .Lmemxor3_au_leftover:
 	C Store a byte at a time
-	ror	r4, #24
+	C bring uppermost byte down for saving while preserving lower ones
+IF_LE(&lt;	ror	r4, #24&gt;)
 	strb	r4, [DST, #-1]!
 	subs	N, #1
 	beq	.Lmemxor3_done
 	subs	ACNT, #8
+	C bring down next byte, no need to preserve
+IF_BE(&lt;	lsr	r4, #8&gt;)
 	sub	AP, #1
 	bne	.Lmemxor3_au_leftover
 	b	.Lmemxor3_bytes
@@ -273,18 +273,19 @@ IF_BE(&lt;	rev	r4, r4&gt;)
 	adds	N, #8
 	beq	.Lmemxor3_done
 
-	C leftover does an LSB store
-	C so we need to reverse if actually BE
-IF_BE(&lt;	rev	r4, r4&gt;)
-
-	C Leftover bytes in a4, low end
-	ror	r4, ACNT
+	C Leftover bytes in r4, (since working downwards) in high end on LE and
+	C low end on BE after preparatory alignment correction
+IF_LE(&lt;	ror	r4, ACNT&gt;)
+IF_BE(&lt;	ror	r4, ATNC&gt;)
 .Lmemxor3_uu_leftover:
-	ror	r4, #24
+	C bring uppermost byte down for saving while preserving lower ones
+IF_LE(&lt;	ror	r4, #24&gt;)
 	strb	r4, [DST, #-1]!
 	subs	N, #1
 	beq	.Lmemxor3_done
 	subs	ACNT, #8
+	C bring down next byte, no need to preserve
+IF_BE(&lt;	lsr	r4, #8&gt;)
 	bne	.Lmemxor3_uu_leftover
 	b	.Lmemxor3_bytes
 
-- 
2.25.0

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200223160854</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-02-23 16:08:54-0400</timestampReceived><subject>Re: Armeb is broken</subject><body>

If I remember correctly, ARMv5 be was BE-32

-- 
With best wishes
Dmitry

вс, 23 февр. 2020 г., 18:45 Michael Weiser &lt;michael.weiser@gmx.de&gt;:

&gt; Hi all,
&gt;
&gt; On Sat, Feb 22, 2020 at 07:43:18PM +0100, Michael Weiser wrote:
&gt;
&gt; &gt; &gt; 2. Eliminate use of rev in the armbe code.
&gt; &gt; ... I've been looking at the revs and they now strike me as taking the
&gt; &gt; easy way out anyway. They work around the implicit LE order in which
&gt;
&gt; Updated code is now at
&gt; https://git.lysator.liu.se/michaelweiser/nettle/-/tree/arm-memxor-generic
&gt; and inline below for comments.
&gt;
&gt; It now compiles and runs the testsuite fine on my native armv7veb when
&gt; configurd with:
&gt;
&gt; CFLAGS="-march=armv6" LDFLAGS="-march=armv6" \
&gt;         ../configure --disable-documentation \
&gt;                 --host=armv6b-unknown-linux-gnueabihf
&gt; [...]
&gt;   Assembly files:    arm/neon arm/v6 arm
&gt;
&gt; and:
&gt;
&gt; CFLAGS="-march=armv5te" LDFLAGS="-march=armv5te -Wl,--be8" \
&gt;         ../configure --disable-documentation \
&gt;                 --host=armv5b-unknown-linux-gnueabihf
&gt; [...]
&gt;   Assembly files:    arm
&gt;
&gt; LDFLAGS "-Wl,--be8" is necessary for armv5teb to work on my system
&gt; because it is BE8 which the gcc linker driver defaults to when run with
&gt; -march=armv6 but not for armv5 which causes the resuling binaries to be
&gt; BE32 and segfault or bus error in ld-linux.so.3 on startup. For a
&gt; (likely wrong) explanation of BE8 vs. BE32 see
&gt; https://lists.lysator.liu.se/pipermail/nettle-bugs/2018/007059.html.
&gt;
&gt; A quick check can be done with file:
&gt;
&gt; $ echo "int main(void) {}" &gt; t.c
&gt; $ gcc -march=armv5te -o t t.c
&gt; $ ./t
&gt; Segmentation fault
&gt; $ file t
&gt; t: ELF 32-bit MSB shared object, ARM, EABI5 version 1 (SYSV),
&gt; dynamically linked, interpreter /lib/ld-linux-armhf.so.3, for GNU/Linux
&gt; 3.2.0, not stripped
&gt; $ gcc -march=armv5te -Wl,--be8 -o t t.c
&gt; $ ./t
&gt; $ file t
&gt; t: ELF 32-bit MSB shared object, ARM, EABI5 BE8 version 1 (SYSV),
&gt; dynamically linked, interpreter /lib/ld-linux-armhf.so.3, for GNU/Linux
&gt; 3.2.0, not stripped
&gt;
&gt; The qemu environment is churning along in compilation currently.
&gt;
&gt; Previous assembler error for reference:
&gt;
&gt; $ make -j4
&gt; [...]
&gt; /usr/bin/m4 ../asm.m4 machine.m4 config.m4 memxor.asm &gt;memxor.s
&gt; /usr/bin/m4 ../asm.m4 machine.m4 config.m4 memxor3.asm &gt;memxor3.s
&gt; gcc -I.  -DHAVE_CONFIG_H -march=armv5te -ggdb3 -Wall -W
&gt; -Wmissing-prototypes -Wmissing-declarations -Wstrict-prototypes
&gt; -Wpointer-arith -Wbad-function-cast -Wnested-externs -fpic -MT memxor.o
&gt; -MD -MP -MF memxor.o.d -c memxor.s
&gt; gcc -I.  -DHAVE_CONFIG_H -march=armv5te -ggdb3 -Wall -W
&gt; -Wmissing-prototypes -Wmissing-declarations -Wstrict-prototypes
&gt; -Wpointer-arith -Wbad-function-cast -Wnested-externs -fpic -MT memxor3.o
&gt; -MD -MP -MF memxor3.o.d -c memxor3.s
&gt; memxor.s: memxor3.s: Assembler messages:
&gt; memxor3.s:146: Error: selected processor does not support `rev r4,r4' in
&gt; ARM mode
&gt; Assembler messages:
&gt; memxor3.s:256: Error: selected processor does not support `rev r4,r4' in
&gt; ARM mode
&gt; memxor.s:126: Error: selected processor does not support `rev r3,r3' in
&gt; ARM mode
&gt; --
&gt; Thanks,
&gt; Michael
&gt;
&gt; From 3e2118d41472842c368bb5bb56d71023b861b59d Mon Sep 17 00:00:00 2001
&gt; From: Michael Weiser &lt;michael.weiser@gmx.de&gt;
&gt; Date: Sun, 23 Feb 2020 15:22:51 +0100
&gt; Subject: [PATCH] arm: Fix memxor for non-armv6+ big-endian systems
&gt;
&gt; ARM assembly adjustments for big-endian systems contained armv6+-only
&gt; instructions (rev) in generic arm memxor code. Replace those with an
&gt; actual conversion of the leftover byte store routines for big-endian
&gt; systems. This also provides a slight optimisation by removing the
&gt; additional instruction as well as increased symmetry between little- and
&gt; big-endian implementations.
&gt;
&gt; Signed-off-by: Michael Weiser &lt;michael.weiser@gmx.de&gt;
&gt; ---
&gt;  arm/memxor.asm  | 12 ++++++------
&gt;  arm/memxor3.asm | 27 ++++++++++++++-------------
&gt;  2 files changed, 20 insertions(+), 19 deletions(-)
&gt;
&gt; diff --git a/arm/memxor.asm b/arm/memxor.asm
&gt; index 239a4034..b802e95c 100644
&gt; --- a/arm/memxor.asm
&gt; +++ b/arm/memxor.asm
&gt; @@ -138,24 +138,24 @@ PROLOGUE(nettle_memxor)
&gt;         adds    N, #8
&gt;         beq     .Lmemxor_odd_done
&gt;
&gt; -       C We have TNC/8 left-over bytes in r4, high end
&gt; +       C We have TNC/8 left-over bytes in r4, (since working upwards) low
&gt; +       C end on LE and high end on BE
&gt;         S0ADJ   r4, CNT
&gt;         ldr     r3, [DST]
&gt;         eor     r3, r4
&gt;
&gt; -       C memxor_leftover does an LSB store
&gt; -       C so we need to reverse if actually BE
&gt; -IF_BE(&lt;        rev     r3, r3&gt;)
&gt; -
&gt;         pop     {r4,r5,r6}
&gt;
&gt;         C Store bytes, one by one.
&gt;  .Lmemxor_leftover:
&gt; +       C bring uppermost byte down for saving while preserving lower ones
&gt; +IF_BE(&lt;        ror     r3, #24&gt;)
&gt;         strb    r3, [DST], #+1
&gt;         subs    N, #1
&gt;         beq     .Lmemxor_done
&gt;         subs    TNC, #8
&gt; -       lsr     r3, #8
&gt; +       C bring down next byte, no need to preserve
&gt; +IF_LE(&lt;        lsr     r3, #8&gt;)
&gt;         bne     .Lmemxor_leftover
&gt;         b       .Lmemxor_bytes
&gt;  .Lmemxor_odd_done:
&gt; diff --git a/arm/memxor3.asm b/arm/memxor3.asm
&gt; index 69598e1c..76b8aae6 100644
&gt; --- a/arm/memxor3.asm
&gt; +++ b/arm/memxor3.asm
&gt; @@ -159,21 +159,21 @@ PROLOGUE(nettle_memxor3)
&gt;         adds    N, #8
&gt;         beq     .Lmemxor3_done
&gt;
&gt; -       C Leftover bytes in r4, low end
&gt; +       C Leftover bytes in r4, (since working downwards) in high end on
&gt; LE and
&gt; +       C low end on BE
&gt;         ldr     r5, [AP, #-4]
&gt;         eor     r4, r5, r4, S1ADJ ATNC
&gt;
&gt; -       C leftover does an LSB store
&gt; -       C so we need to reverse if actually BE
&gt; -IF_BE(&lt;        rev     r4, r4&gt;)
&gt; -
&gt;  .Lmemxor3_au_leftover:
&gt;         C Store a byte at a time
&gt; -       ror     r4, #24
&gt; +       C bring uppermost byte down for saving while preserving lower ones
&gt; +IF_LE(&lt;        ror     r4, #24&gt;)
&gt;         strb    r4, [DST, #-1]!
&gt;         subs    N, #1
&gt;         beq     .Lmemxor3_done
&gt;         subs    ACNT, #8
&gt; +       C bring down next byte, no need to preserve
&gt; +IF_BE(&lt;        lsr     r4, #8&gt;)
&gt;         sub     AP, #1
&gt;         bne     .Lmemxor3_au_leftover
&gt;         b       .Lmemxor3_bytes
&gt; @@ -273,18 +273,19 @@ IF_BE(&lt;   rev     r4, r4&gt;)
&gt;         adds    N, #8
&gt;         beq     .Lmemxor3_done
&gt;
&gt; -       C leftover does an LSB store
&gt; -       C so we need to reverse if actually BE
&gt; -IF_BE(&lt;        rev     r4, r4&gt;)
&gt; -
&gt; -       C Leftover bytes in a4, low end
&gt; -       ror     r4, ACNT
&gt; +       C Leftover bytes in r4, (since working downwards) in high end on
&gt; LE and
&gt; +       C low end on BE after preparatory alignment correction
&gt; +IF_LE(&lt;        ror     r4, ACNT&gt;)
&gt; +IF_BE(&lt;        ror     r4, ATNC&gt;)
&gt;  .Lmemxor3_uu_leftover:
&gt; -       ror     r4, #24
&gt; +       C bring uppermost byte down for saving while preserving lower ones
&gt; +IF_LE(&lt;        ror     r4, #24&gt;)
&gt;         strb    r4, [DST, #-1]!
&gt;         subs    N, #1
&gt;         beq     .Lmemxor3_done
&gt;         subs    ACNT, #8
&gt; +       C bring down next byte, no need to preserve
&gt; +IF_BE(&lt;        lsr     r4, #8&gt;)
&gt;         bne     .Lmemxor3_uu_leftover
&gt;         b       .Lmemxor3_bytes
&gt;
&gt; --
&gt; 2.25.0
&gt;
&gt; _______________________________________________
&gt; nettle-bugs mailing list
&gt; nettle-bugs@lists.lysator.liu.se
&gt; http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200223160943</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-02-23 16:09:43-0400</timestampReceived><subject>Re: Armeb is broken</subject><body>

I will check with fresh Yocto build later or tomorrow.

-- 
With best wishes
Dmitry

вс, 23 февр. 2020 г., 19:08 Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;:

&gt; If I remember correctly, ARMv5 be was BE-32
&gt;
&gt; --
&gt; With best wishes
&gt; Dmitry
&gt;
&gt; вс, 23 февр. 2020 г., 18:45 Michael Weiser &lt;michael.weiser@gmx.de&gt;:
&gt;
&gt;&gt; Hi all,
&gt;&gt;
&gt;&gt; On Sat, Feb 22, 2020 at 07:43:18PM +0100, Michael Weiser wrote:
&gt;&gt;
&gt;&gt; &gt; &gt; 2. Eliminate use of rev in the armbe code.
&gt;&gt; &gt; ... I've been looking at the revs and they now strike me as taking the
&gt;&gt; &gt; easy way out anyway. They work around the implicit LE order in which
&gt;&gt;
&gt;&gt; Updated code is now at
&gt;&gt; https://git.lysator.liu.se/michaelweiser/nettle/-/tree/arm-memxor-generic
&gt;&gt; and inline below for comments.
&gt;&gt;
&gt;&gt; It now compiles and runs the testsuite fine on my native armv7veb when
&gt;&gt; configurd with:
&gt;&gt;
&gt;&gt; CFLAGS="-march=armv6" LDFLAGS="-march=armv6" \
&gt;&gt;         ../configure --disable-documentation \
&gt;&gt;                 --host=armv6b-unknown-linux-gnueabihf
&gt;&gt; [...]
&gt;&gt;   Assembly files:    arm/neon arm/v6 arm
&gt;&gt;
&gt;&gt; and:
&gt;&gt;
&gt;&gt; CFLAGS="-march=armv5te" LDFLAGS="-march=armv5te -Wl,--be8" \
&gt;&gt;         ../configure --disable-documentation \
&gt;&gt;                 --host=armv5b-unknown-linux-gnueabihf
&gt;&gt; [...]
&gt;&gt;   Assembly files:    arm
&gt;&gt;
&gt;&gt; LDFLAGS "-Wl,--be8" is necessary for armv5teb to work on my system
&gt;&gt; because it is BE8 which the gcc linker driver defaults to when run with
&gt;&gt; -march=armv6 but not for armv5 which causes the resuling binaries to be
&gt;&gt; BE32 and segfault or bus error in ld-linux.so.3 on startup. For a
&gt;&gt; (likely wrong) explanation of BE8 vs. BE32 see
&gt;&gt; https://lists.lysator.liu.se/pipermail/nettle-bugs/2018/007059.html.
&gt;&gt;
&gt;&gt; A quick check can be done with file:
&gt;&gt;
&gt;&gt; $ echo "int main(void) {}" &gt; t.c
&gt;&gt; $ gcc -march=armv5te -o t t.c
&gt;&gt; $ ./t
&gt;&gt; Segmentation fault
&gt;&gt; $ file t
&gt;&gt; t: ELF 32-bit MSB shared object, ARM, EABI5 version 1 (SYSV),
&gt;&gt; dynamically linked, interpreter /lib/ld-linux-armhf.so.3, for GNU/Linux
&gt;&gt; 3.2.0, not stripped
&gt;&gt; $ gcc -march=armv5te -Wl,--be8 -o t t.c
&gt;&gt; $ ./t
&gt;&gt; $ file t
&gt;&gt; t: ELF 32-bit MSB shared object, ARM, EABI5 BE8 version 1 (SYSV),
&gt;&gt; dynamically linked, interpreter /lib/ld-linux-armhf.so.3, for GNU/Linux
&gt;&gt; 3.2.0, not stripped
&gt;&gt;
&gt;&gt; The qemu environment is churning along in compilation currently.
&gt;&gt;
&gt;&gt; Previous assembler error for reference:
&gt;&gt;
&gt;&gt; $ make -j4
&gt;&gt; [...]
&gt;&gt; /usr/bin/m4 ../asm.m4 machine.m4 config.m4 memxor.asm &gt;memxor.s
&gt;&gt; /usr/bin/m4 ../asm.m4 machine.m4 config.m4 memxor3.asm &gt;memxor3.s
&gt;&gt; gcc -I.  -DHAVE_CONFIG_H -march=armv5te -ggdb3 -Wall -W
&gt;&gt; -Wmissing-prototypes -Wmissing-declarations -Wstrict-prototypes
&gt;&gt; -Wpointer-arith -Wbad-function-cast -Wnested-externs -fpic -MT memxor.o
&gt;&gt; -MD -MP -MF memxor.o.d -c memxor.s
&gt;&gt; gcc -I.  -DHAVE_CONFIG_H -march=armv5te -ggdb3 -Wall -W
&gt;&gt; -Wmissing-prototypes -Wmissing-declarations -Wstrict-prototypes
&gt;&gt; -Wpointer-arith -Wbad-function-cast -Wnested-externs -fpic -MT memxor3.o
&gt;&gt; -MD -MP -MF memxor3.o.d -c memxor3.s
&gt;&gt; memxor.s: memxor3.s: Assembler messages:
&gt;&gt; memxor3.s:146: Error: selected processor does not support `rev r4,r4' in
&gt;&gt; ARM mode
&gt;&gt; Assembler messages:
&gt;&gt; memxor3.s:256: Error: selected processor does not support `rev r4,r4' in
&gt;&gt; ARM mode
&gt;&gt; memxor.s:126: Error: selected processor does not support `rev r3,r3' in
&gt;&gt; ARM mode
&gt;&gt; --
&gt;&gt; Thanks,
&gt;&gt; Michael
&gt;&gt;
&gt;&gt; From 3e2118d41472842c368bb5bb56d71023b861b59d Mon Sep 17 00:00:00 2001
&gt;&gt; From: Michael Weiser &lt;michael.weiser@gmx.de&gt;
&gt;&gt; Date: Sun, 23 Feb 2020 15:22:51 +0100
&gt;&gt; Subject: [PATCH] arm: Fix memxor for non-armv6+ big-endian systems
&gt;&gt;
&gt;&gt; ARM assembly adjustments for big-endian systems contained armv6+-only
&gt;&gt; instructions (rev) in generic arm memxor code. Replace those with an
&gt;&gt; actual conversion of the leftover byte store routines for big-endian
&gt;&gt; systems. This also provides a slight optimisation by removing the
&gt;&gt; additional instruction as well as increased symmetry between little- and
&gt;&gt; big-endian implementations.
&gt;&gt;
&gt;&gt; Signed-off-by: Michael Weiser &lt;michael.weiser@gmx.de&gt;
&gt;&gt; ---
&gt;&gt;  arm/memxor.asm  | 12 ++++++------
&gt;&gt;  arm/memxor3.asm | 27 ++++++++++++++-------------
&gt;&gt;  2 files changed, 20 insertions(+), 19 deletions(-)
&gt;&gt;
&gt;&gt; diff --git a/arm/memxor.asm b/arm/memxor.asm
&gt;&gt; index 239a4034..b802e95c 100644
&gt;&gt; --- a/arm/memxor.asm
&gt;&gt; +++ b/arm/memxor.asm
&gt;&gt; @@ -138,24 +138,24 @@ PROLOGUE(nettle_memxor)
&gt;&gt;         adds    N, #8
&gt;&gt;         beq     .Lmemxor_odd_done
&gt;&gt;
&gt;&gt; -       C We have TNC/8 left-over bytes in r4, high end
&gt;&gt; +       C We have TNC/8 left-over bytes in r4, (since working upwards) low
&gt;&gt; +       C end on LE and high end on BE
&gt;&gt;         S0ADJ   r4, CNT
&gt;&gt;         ldr     r3, [DST]
&gt;&gt;         eor     r3, r4
&gt;&gt;
&gt;&gt; -       C memxor_leftover does an LSB store
&gt;&gt; -       C so we need to reverse if actually BE
&gt;&gt; -IF_BE(&lt;        rev     r3, r3&gt;)
&gt;&gt; -
&gt;&gt;         pop     {r4,r5,r6}
&gt;&gt;
&gt;&gt;         C Store bytes, one by one.
&gt;&gt;  .Lmemxor_leftover:
&gt;&gt; +       C bring uppermost byte down for saving while preserving lower ones
&gt;&gt; +IF_BE(&lt;        ror     r3, #24&gt;)
&gt;&gt;         strb    r3, [DST], #+1
&gt;&gt;         subs    N, #1
&gt;&gt;         beq     .Lmemxor_done
&gt;&gt;         subs    TNC, #8
&gt;&gt; -       lsr     r3, #8
&gt;&gt; +       C bring down next byte, no need to preserve
&gt;&gt; +IF_LE(&lt;        lsr     r3, #8&gt;)
&gt;&gt;         bne     .Lmemxor_leftover
&gt;&gt;         b       .Lmemxor_bytes
&gt;&gt;  .Lmemxor_odd_done:
&gt;&gt; diff --git a/arm/memxor3.asm b/arm/memxor3.asm
&gt;&gt; index 69598e1c..76b8aae6 100644
&gt;&gt; --- a/arm/memxor3.asm
&gt;&gt; +++ b/arm/memxor3.asm
&gt;&gt; @@ -159,21 +159,21 @@ PROLOGUE(nettle_memxor3)
&gt;&gt;         adds    N, #8
&gt;&gt;         beq     .Lmemxor3_done
&gt;&gt;
&gt;&gt; -       C Leftover bytes in r4, low end
&gt;&gt; +       C Leftover bytes in r4, (since working downwards) in high end on
&gt;&gt; LE and
&gt;&gt; +       C low end on BE
&gt;&gt;         ldr     r5, [AP, #-4]
&gt;&gt;         eor     r4, r5, r4, S1ADJ ATNC
&gt;&gt;
&gt;&gt; -       C leftover does an LSB store
&gt;&gt; -       C so we need to reverse if actually BE
&gt;&gt; -IF_BE(&lt;        rev     r4, r4&gt;)
&gt;&gt; -
&gt;&gt;  .Lmemxor3_au_leftover:
&gt;&gt;         C Store a byte at a time
&gt;&gt; -       ror     r4, #24
&gt;&gt; +       C bring uppermost byte down for saving while preserving lower ones
&gt;&gt; +IF_LE(&lt;        ror     r4, #24&gt;)
&gt;&gt;         strb    r4, [DST, #-1]!
&gt;&gt;         subs    N, #1
&gt;&gt;         beq     .Lmemxor3_done
&gt;&gt;         subs    ACNT, #8
&gt;&gt; +       C bring down next byte, no need to preserve
&gt;&gt; +IF_BE(&lt;        lsr     r4, #8&gt;)
&gt;&gt;         sub     AP, #1
&gt;&gt;         bne     .Lmemxor3_au_leftover
&gt;&gt;         b       .Lmemxor3_bytes
&gt;&gt; @@ -273,18 +273,19 @@ IF_BE(&lt;   rev     r4, r4&gt;)
&gt;&gt;         adds    N, #8
&gt;&gt;         beq     .Lmemxor3_done
&gt;&gt;
&gt;&gt; -       C leftover does an LSB store
&gt;&gt; -       C so we need to reverse if actually BE
&gt;&gt; -IF_BE(&lt;        rev     r4, r4&gt;)
&gt;&gt; -
&gt;&gt; -       C Leftover bytes in a4, low end
&gt;&gt; -       ror     r4, ACNT
&gt;&gt; +       C Leftover bytes in r4, (since working downwards) in high end on
&gt;&gt; LE and
&gt;&gt; +       C low end on BE after preparatory alignment correction
&gt;&gt; +IF_LE(&lt;        ror     r4, ACNT&gt;)
&gt;&gt; +IF_BE(&lt;        ror     r4, ATNC&gt;)
&gt;&gt;  .Lmemxor3_uu_leftover:
&gt;&gt; -       ror     r4, #24
&gt;&gt; +       C bring uppermost byte down for saving while preserving lower ones
&gt;&gt; +IF_LE(&lt;        ror     r4, #24&gt;)
&gt;&gt;         strb    r4, [DST, #-1]!
&gt;&gt;         subs    N, #1
&gt;&gt;         beq     .Lmemxor3_done
&gt;&gt;         subs    ACNT, #8
&gt;&gt; +       C bring down next byte, no need to preserve
&gt;&gt; +IF_BE(&lt;        lsr     r4, #8&gt;)
&gt;&gt;         bne     .Lmemxor3_uu_leftover
&gt;&gt;         b       .Lmemxor3_bytes
&gt;&gt;
&gt;&gt; --
&gt;&gt; 2.25.0
&gt;&gt;
&gt;&gt; _______________________________________________
&gt;&gt; nettle-bugs mailing list
&gt;&gt; nettle-bugs@lists.lysator.liu.se
&gt;&gt; http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs
&gt;&gt;
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200223172643</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2020-02-23 17:26:43-0400</timestampReceived><subject>Re: Armeb is broken</subject><body>

Hi Dmitry,

On Sun, Feb 23, 2020 at 07:08:54PM +0300, Dmitry Baryshkov wrote:

&gt; If I remember correctly, ARMv5 be was BE-32

Yep. So is the buildroot output I get for arm926 armeb. I just need the
BE8 workaround on my BE8 armv7veb system to test the armv5 compilate.

On Sun, Feb 23, 2020 at 07:09:43PM +0300, Dmitry Baryshkov wrote:

&gt; I will check with fresh Yocto build later or tomorrow.

Thanks!

Could Yocto be used for CI then? Do they do any kind of binary releases
for armeb? How long and voluminous is a build of an armeb system with
and without a native toolchain?
-- 
Thanks,
Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200224175844</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-02-24 17:58:44-0400</timestampReceived><subject>Re: Armeb is broken</subject><body>

Hello,

вс, 23 февр. 2020 г. в 20:00, Michael Weiser &lt;michael@weiser.dinsnail.net&gt;:
&gt;
&gt; Hi Dmitry,
&gt;
&gt; On Sun, Feb 23, 2020 at 07:09:43PM +0300, Dmitry Baryshkov wrote:
&gt;
&gt; &gt; I will check with fresh Yocto build later or tomorrow.
&gt;
&gt; Thanks!

I have checked both armv7vet2b and armv5eb targets with qemu. Your
patch fixes the issue for me.

&gt; Could Yocto be used for CI then? Do they do any kind of binary releases
&gt; for armeb? How long and voluminous is a build of an armeb system with
&gt; and without a native toolchain?

No, I found no package feeds/binary releases for armeb. So to use
Yocto for CI, we'd have to build an image with Yocto SDK inside. I can
try implementing it.


-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200302184425</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-03-02 18:44:25-0400</timestampReceived><subject>Re: Armeb is broken</subject><body>

I've been offline, skiiing, for a week, and I haven't yet caught up we
email. http://www.lysator.liu.se/~nisse/misc/s%C3%A5nfj%C3%A4llet.jpg

Michael Weiser &lt;michael.weiser@gmx.de&gt; writes:

&gt; Hi Niels,
&gt;
&gt; On Sat, Feb 22, 2020 at 07:58:10AM +0100, Niels Möller wrote:
&gt;
&gt;&gt; Lookingup NSLU2 on wikipedia, it seems it features a "Intel XScale cpu"
&gt;&gt; featuring an "ARMv5TE ISA without the floating point instructions." I
&gt;&gt; take it this can be run in BE mode?
&gt;
&gt; The Intel XScale and IXP4xx are BE by default, IIRC. For them it's even
&gt; a bit of a hike to run them LE since all their companion controllers and
&gt; firmware blobs are BE as well.

Ok, so than ARM BE may be more relevant for these older chips than for
newer ones, which are almost always run in LE mode?

&gt;&gt; 2. Eliminate use of rev in the armbe code.
&gt;
&gt; ... I've been looking at the revs and they now strike me as taking the
&gt; easy way out anyway. They work around the implicit LE order in which
&gt; some remaining bytes from a buffer are saved byte-wise. This should be
&gt; doable without the revs by making the store work in BE fashion in BE
&gt; mode. I plan to look into this but would certainly appreciate any help
&gt; Dmitry and Андрей might be able to give here since it's not as if I've
&gt; been doing nothing but arm asm the last couple of years - rather the
&gt; opposite.

I've only had a quick look at the patch later in the thread, but I agree
that if we have a loop to store a byte at a time anyway, it should be
straight forward to "just" reverse the shifting direction depending on
byte order.

&gt;&gt; 3. Somehow arrange in configure so that the memxor files in particular
&gt;&gt;    aren't used when targetting armv5be. If you want to test the effects
&gt;&gt;    before hacking configure.ac, I think it should be as easy as removing
&gt;&gt;    the memxor*.asm symlinks after running configure.
&gt;
&gt; Nah, we can do better than that. :)

But relatedly, it looks like arm/v6/sha1-compress.asm and
arm/v6/sha256-compress.asm need ARMv6 only on little-endian hosts. So it
might be worthwhile to try to use these files on armv5be? I don't see an
obvious great way to set it up though. 

One way might be to add a arm/be/sha1-compress.asm file which simply
includes the v6 file, and then add arm/be to the asm_path where
appropriate.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200302224952</emailId><senderName>Dmitry Baryshkov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-03-02 22:49:52-0400</timestampReceived><subject>Re: Armeb is broken</subject><body>

Hello,

пн, 2 мар. 2020 г. в 21:44, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt;
&gt; I've been offline, skiiing, for a week, and I haven't yet caught up we
&gt; email. http://www.lysator.liu.se/~nisse/misc/s%C3%A5nfj%C3%A4llet.jpg
&gt;
&gt; Michael Weiser &lt;michael.weiser@gmx.de&gt; writes:
&gt;
&gt; &gt; Hi Niels,
&gt; &gt;
&gt; &gt; On Sat, Feb 22, 2020 at 07:58:10AM +0100, Niels Möller wrote:
&gt; &gt;
&gt; &gt;&gt; Lookingup NSLU2 on wikipedia, it seems it features a "Intel XScale cpu"
&gt; &gt;&gt; featuring an "ARMv5TE ISA without the floating point instructions." I
&gt; &gt;&gt; take it this can be run in BE mode?
&gt; &gt;
&gt; &gt; The Intel XScale and IXP4xx are BE by default, IIRC. For them it's even
&gt; &gt; a bit of a hike to run them LE since all their companion controllers and
&gt; &gt; firmware blobs are BE as well.
&gt;
&gt; Ok, so than ARM BE may be more relevant for these older chips than for
&gt; newer ones, which are almost always run in LE mode?

It has become mostly irrelevant after authors of SlugOS have invented
a way to run LE binaries on NSLU2. Working in embedded hardware area I
haven't seen an armeb project for ages.

&gt;
&gt; &gt;&gt; 2. Eliminate use of rev in the armbe code.
&gt; &gt;
&gt; &gt; ... I've been looking at the revs and they now strike me as taking the
&gt; &gt; easy way out anyway. They work around the implicit LE order in which
&gt; &gt; some remaining bytes from a buffer are saved byte-wise. This should be
&gt; &gt; doable without the revs by making the store work in BE fashion in BE
&gt; &gt; mode. I plan to look into this but would certainly appreciate any help
&gt; &gt; Dmitry and Андрей might be able to give here since it's not as if I've
&gt; &gt; been doing nothing but arm asm the last couple of years - rather the
&gt; &gt; opposite.
&gt;
&gt; I've only had a quick look at the patch later in the thread, but I agree
&gt; that if we have a loop to store a byte at a time anyway, it should be
&gt; straight forward to "just" reverse the shifting direction depending on
&gt; byte order.
&gt;
&gt; &gt;&gt; 3. Somehow arrange in configure so that the memxor files in particular
&gt; &gt;&gt;    aren't used when targetting armv5be. If you want to test the effects
&gt; &gt;&gt;    before hacking configure.ac, I think it should be as easy as removing
&gt; &gt;&gt;    the memxor*.asm symlinks after running configure.
&gt; &gt;
&gt; &gt; Nah, we can do better than that. :)
&gt;
&gt; But relatedly, it looks like arm/v6/sha1-compress.asm and
&gt; arm/v6/sha256-compress.asm need ARMv6 only on little-endian hosts. So it
&gt; might be worthwhile to try to use these files on armv5be? I don't see an
&gt; obvious great way to set it up though.
&gt;
&gt; One way might be to add a arm/be/sha1-compress.asm file which simply
&gt; includes the v6 file, and then add arm/be to the asm_path where
&gt; appropriate.

I will take a look on fixing the code for armv5. Replacing rev with
bit fiddling should be easy.

-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200303175725</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-03-03 17:57:25-0400</timestampReceived><subject>Re: Armeb is broken</subject><body>

Michael Weiser &lt;michael.weiser@gmx.de&gt; writes:

&gt; These comment changes are bugging me:
&gt;
&gt; diff --git a/arm/memxor.asm b/arm/memxor.asm
&gt; index 239a4034..b802e95c 100644
&gt; --- a/arm/memxor.asm
&gt; +++ b/arm/memxor.asm
&gt; @@ -138,24 +138,24 @@ PROLOGUE(nettle_memxor)
&gt;  	adds	N, #8
&gt;  	beq	.Lmemxor_odd_done
&gt;  
&gt; -	C We have TNC/8 left-over bytes in r4, high end
&gt; +	C We have TNC/8 left-over bytes in r4, (since working upwards) low
&gt; +	C end on LE and high end on BE
&gt;  	S0ADJ	r4, CNT
&gt;  	ldr	r3, [DST]
&gt;  	eor	r3, r4

The correctness in all cases is not that obvious to me now, but the idea
is that we write aligned words, and read aligned words. But since input
and output may have different alignment, src words are shifted around so
that matching bytes are xored together. The ascii art a bit higher up in
the file tries to illustrate that.

At this point in the code, r4 holds an aligned word read from the src
area (possibly reading to a word edge beyond the end of the input
bytes). The first bytes in this word (on LE, those are the least
significant "low end" bytes of r4) have already been xored with the
previous destination word and stored back. The "left-over" bytes
referred to in the comment are the bytes in r4 that have not yet been
processed, and those are the last bytes, and which in LE are the most
significant bytes of r4, located at the "high end" of the register.

And then not all of the left-over bytes should be stored back after
xoring, since they may be read from beyond the end of the input.

Does that make sense?

The C code does something similar, except that I think it avoids reading
anything beyond end of input, since that is undefined behavior in C.

&gt; Full patch for reference again below and at
&gt; https://git.lysator.liu.se/michaelweiser/nettle/-/tree/arm-memxor-generic.
&gt;
&gt; If it's acceptable shall I rather git send-email it or do a MR on
&gt; gitlab?

Either alternative is ok (although I'm still not that used to gitlab
MRs).

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200304220045</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2020-03-04 22:00:45-0400</timestampReceived><subject>Re: Armeb is broken</subject><body>

Hello Niels,

On Tue, Mar 03, 2020 at 06:57:25PM +0100, Niels Möller wrote:

&gt; The correctness in all cases is not that obvious to me now, but the idea
&gt; is that we write aligned words, and read aligned words. But since input
&gt; and output may have different alignment, src words are shifted around so
&gt; that matching bytes are xored together. The ascii art a bit higher up in
&gt; the file tries to illustrate that.

&gt; At this point in the code, r4 holds an aligned word read from the src
&gt; area (possibly reading to a word edge beyond the end of the input
&gt; bytes). The first bytes in this word (on LE, those are the least
&gt; significant "low end" bytes of r4) have already been xored with the
&gt; previous destination word and stored back. The "left-over" bytes
&gt; referred to in the comment are the bytes in r4 that have not yet been

Thanks for the explanation. It confirms my understanding so far.

&gt; processed, and those are the last bytes, and which in LE are the most
&gt; significant bytes of r4, located at the "high end" of the register.

This is where after a lot of scratching of my thinking cap I got to the
conclusion that in LE we're actually working with the least significant
bytes of r4 at the low end of the register. My guess is that it's just a
matter of interpretation what end of the register is "high" and most
significant. I just want to make sure I have a correct understanding of
what the code is doing while messing with it.

Rereading the ARM ARM[1] it says that register contents are
little-endian, i.e. the lowest numbered bits being least significant.
([1] D6.3.2) Also, higher bits are left and lower ones are right. ([1]
D6.5.3) Byte order is converted only on memory access ([1] A3.3). strb
stores the lowest (rightmost) byte of r4 (bits 7..0) to memory ([1]
A7.7.160).

This matches what the code is doing: On LE it's saving the lowest byte
to DST, incrementing by one (moving upward in memory) and then
right-shifts r4 down 8 bits and saves the next byte. So it's saving the
least significant byte first which on LE matches how ldr read the word
from memory into the register. For validation I'm infering that it must
be the least significant (rightmost) byte because lsr is discarding what
it shifts out of the register to the right which would result in data
loss if strb were to save the highest (leftmost) byte instead.

On BE we now do essentially a rotate-left by 8 bits (by doing a rotate
right by 24 bits) to get the highest byte (bits 31..24) down to bits
7..0 of the register while preserving the rest by shifting/rotating them
into the upper part (no discard as with lsr). Storing the the most
significant byte first again matches how ldr loaded it from memory.

momxor3 seems to do everything the other way around because it works
downward in memory.

Sorry if all this seems pedestrian but it isn't my daily fare. And sorry
for quoting regulation by paragraph but I really want to make sure that
I'm not misunderstanding all this miserably. :)

&gt; The C code does something similar, except that I think it avoids reading
&gt; anything beyond end of input, since that is undefined behavior in C.

Ah, but the C code of memxor works downward in memory, doesn't it?

Long story short: Let me know what to do with those comments based on
how much my thinking is off.

[1] ARM armv7-m Architecture Reference Manual
https://static.docs.arm.com/ddi0403/e/DDI0403E_B_armv7m_arm.pdf
(only one I could find publicly available)
-- 
Thanks,
Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200304150012</emailId><senderName>Daiki Ueno</senderName><senderEmail>ueno@gnu.org</senderEmail><timestampReceived>2020-03-04 15:00:12-0400</timestampReceived><subject>Re: [PATCH] chacha: add function to set the initial value of counter</subject><body>

Hello,

nisse@lysator.liu.se (Niels Möller) writes:

&gt; Daiki Ueno &lt;ueno@gnu.org&gt; writes:
&gt;
&gt;&gt; The ChaCha20 based header protection algorithm in QUIC requires a way
&gt;&gt; to set the initial value of counter:
&gt;&gt; https://quicwg.org/base-drafts/draft-ietf-quic-tls.html#name-chacha20-based-header-prote
&gt;
&gt; Out of curiosity, are you aware on any quic implementation using Nettle?

There is an ongoing effort to add an ngtcp2 backend based on GnuTLS,
which surely uses Nettle under the hood:
https://gitlab.com/gnutls/gnutls/-/merge_requests/1197

&gt;&gt; This will add a new function chacha_set_nonce128, which takes the
&gt;&gt; counter value embedded in the nonce.
&gt;
&gt; I see two issues with this change as is.
&gt;
&gt; First is purely an interface design issue. It may be more useful to have
&gt; a separate function to set the 32-bit counter. E.g., that would be
&gt; convenient for random access to a chacha-encrypted file.
&gt;
&gt; The other is more subtle and with interop implications. The way the
&gt; counter is currently updated in chacha_crypt still assumes a 64-bit
&gt; counter (as in the original chacha papers with 64 bits each for nonce
&gt; and counter). This is compatible with RFC 8439, as long as the counter
&gt; is initialized to a small value such as 0 or 1. But if counter is
&gt; initialized to a random 32-bit value, and is expected to wrap around mod
&gt; 2^32, then Nettle will not work as expected but propagate carry into the
&gt; first 32-bits of the nonce.
&gt;
&gt; Not sure how to best deal with this.
&gt;
&gt; It looks like chacha was added in Nettle-3.0, and chacha_set_nonce96
&gt; added in Nettle-3.1 (undocumented and used in the implementation of
&gt; ChaCha-Poly1305). The Nettle-3.1 release also updated chacha-poly1305 to
&gt; follow draft-irtf-cfrg-chacha20-poly1305-08 (which later evolved into
&gt; RFC 8439, if I understood the document history correstly). It seems this
&gt; change is not documented in the manual or in NEWS; the manual still says
&gt; that chacha-poly1305 use 64-bit nonce and is experimental.

For the QUIC use, I guess it would be acceptable that the 32-bit counter
value is only accessible from the chacha_poly1305_* interface (i.e.,
chacha_poly1305_set_counter), as we would just need to trim the Poly1305
tag at the end of the ciphertext.

Regards,
-- 
Daiki Ueno
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200305114347</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-03-05 11:43:47-0400</timestampReceived><subject>Re: Armeb is broken</subject><body>

Michael Weiser &lt;michael.weiser@gmx.de&gt; writes:

&gt; This is where after a lot of scratching of my thinking cap I got to the
&gt; conclusion that in LE we're actually working with the least significant
&gt; bytes of r4 at the low end of the register.

My understanding of LE here is that the least significant CNT bits
(first in memory) where processed earlier, and the remaining TNC bits we
need to process are at the high end. So we first shift right CNT bits to
discard the bits already processed, and then do eight bit a a time,
shifting right in the loop.

&gt; My guess is that it's just a matter of interpretation what end of the
&gt; register is "high" and most significant.

The way I think about it, a 32-bit register holds a binary integer. Each
bit has a weight, from 1 to 2^31 (let's stick to unsigned
interpretation). And then I try to stay with the widely used convention
that bits are numbered 0-31, with bit k having weight 2^k, and with
"right", "lower", "less significant", being synonymous, all meaning the
bits with smaller weight, and "left", "higher", "more significant"
meaning bits with higher weight.
 
Note this termonology is endian independent. It's only when storing the
integer in memory on a byte-addressed machine, that it becomes relevant
to ask which 8 bits get stored at which address, with "little-endian"
meaning that the lower/right/less significant bits in the register get
stored at lower addresses in memory.

Maybe it's illuminating to compare with bit order. On a byte-addressed
machine, we can't really talk about in which "order" individual bits of
a byte are stored in memory. But we'd have to care about bit order,
e.g., if transmitting a byte serially over a wire.

&gt; Long story short: Let me know what to do with those comments based on
&gt; how much my thinking is off.

You could maybe just say "We have TNC/8 left-over bytes in r4 (high end
if little endian, low end if big endian)". Or feel free to rephrase.

Also, I see the final 

	b .Lmemxor_bytes 

is slightly suboptimal, in that it will reread individual bytes from the
word at DST. It might be better to check if N &gt; TNC/8, and if so read
and xor one more source word.

	ldr r4, [SRC]
	eor r3, r4, S1ADJ TNC

And we can then have the byte-storing loop run until N == 0, without
updating or checking TNC. But that's a separate improvement.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200305191306</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2020-03-05 19:13:06-0400</timestampReceived><subject>[PATCH 0/1] Re: Armeb is broken</subject><body>

Hello Niels,

&gt; &gt; This is where after a lot of scratching of my thinking cap I got to the
&gt; &gt; conclusion that in LE we're actually working with the least significant
&gt; &gt; bytes of r4 at the low end of the register.

&gt; My understanding of LE here is that the least significant CNT bits
&gt; (first in memory) where processed earlier, and the remaining TNC bits we
&gt; need to process are at the high end. So we first shift right CNT bits to
&gt; discard the bits already processed, and then do eight bit a a time,
&gt; shifting right in the loop.

Okay, so the comment is referring to the situation in the register
literally just before the next instruction. I was clearly looking too
far afield for clues on what's going on.

&gt; &gt; My guess is that it's just a matter of interpretation what end of the
&gt; &gt; register is "high" and most significant.

&gt; The way I think about it, a 32-bit register holds a binary integer. Each
&gt; bit has a weight, from 1 to 2^31 (let's stick to unsigned
&gt; interpretation). And then I try to stay with the widely used convention
&gt; that bits are numbered 0-31, with bit k having weight 2^k, and with
&gt; "right", "lower", "less significant", being synonymous, all meaning the
&gt; bits with smaller weight, and "left", "higher", "more significant"
&gt; meaning bits with higher weight.

&gt; Note this termonology is endian independent. It's only when storing the
&gt; integer in memory on a byte-addressed machine, that it becomes relevant
&gt; to ask which 8 bits get stored at which address, with "little-endian"
&gt; meaning that the lower/right/less significant bits in the register get
&gt; stored at lower addresses in memory.

&gt; Maybe it's illuminating to compare with bit order. On a byte-addressed
&gt; machine, we can't really talk about in which "order" individual bits of
&gt; a byte are stored in memory. But we'd have to care about bit order,
&gt; e.g., if transmitting a byte serially over a wire.

Thanks for indulging me. :) I had a similar understanding and treatise
to that effect all typed up but then found ARMs view of the world in
their ARM and felt stupid.

&gt; &gt; Long story short: Let me know what to do with those comments based on
&gt; &gt; how much my thinking is off.

&gt; You could maybe just say "We have TNC/8 left-over bytes in r4 (high end
&gt; if little endian, low end if big endian)". Or feel free to rephrase.

I've gone with:

diff --git a/arm/memxor.asm b/arm/memxor.asm
index 239a4034..e4619629 100644
--- a/arm/memxor.asm
+++ b/arm/memxor.asm
@@ -138,24 +138,25 @@ PROLOGUE(nettle_memxor)
 	adds	N, #8
 	beq	.Lmemxor_odd_done
 
-	C We have TNC/8 left-over bytes in r4, high end
+	C We have TNC/8 left-over bytes in r4, high end on LE and low end on
+	C BE, excess bits to be discarded by alignment adjustment at the other
 	S0ADJ	r4, CNT
+	C now byte-aligned at low end on LE and high end on BE
 	ldr	r3, [DST]
 	eor	r3, r4

Patch in followup mail for your consideration.
-- 
Best wishes,
Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200307160057</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-03-07 16:00:57-0400</timestampReceived><subject>Re: [PATCH 2/2] doc: match ChaCha-Poly1305 documentation to the implementation</subject><body>

Daiki Ueno &lt;ueno@gnu.org&gt; writes:

&gt; From: Daiki Ueno &lt;dueno@redhat.com&gt;
&gt;
&gt; While the documentation said the nonce size is 16 octets, the

And 16 was never correct, the older variant used 8 octests (CHACHA_NONCE_SIZE).

&gt; implementation actually assumed 12 octets following RFC 7539.
&gt;
&gt; Signed-off-by: Daiki Ueno &lt;dueno@redhat.com&gt;
&gt; ---
&gt;  nettle.texinfo | 17 +++++------------
&gt;  1 file changed, 5 insertions(+), 12 deletions(-)
&gt;
&gt; diff --git a/nettle.texinfo b/nettle.texinfo
&gt; index 0b339f51..7d5e1780 100644
&gt; --- a/nettle.texinfo
&gt; +++ b/nettle.texinfo
&gt; @@ -3292,17 +3292,10 @@ except that @var{cipher} and @var{f} are
&gt; replaced with a context structure.
&gt;  ChaCha-Poly1305 is a combination of the ChaCha stream cipher and the
&gt;  poly1305 message authentication code (@pxref{Poly1305}). It originates
&gt;  from the NaCl cryptographic library by D. J. Bernstein et al, which
&gt; -defines a similar construction but with Salsa20 instead of ChaCha. 
&gt; -
&gt; -Nettle's implementation ChaCha-Poly1305 should be considered
&gt; -@strong{experimental}. At the time of this writing, there is no
&gt; -authoritative specification for ChaCha-Poly1305, and a couple of
&gt; -different incompatible variants. Nettle implements it using the original
&gt; -definition of ChaCha, with 64 bits (8 octets) each for the nonce and the
&gt; -block counter. Some protocols prefer to use nonces of 12 bytes, and it's
&gt; -a small change to ChaCha to use the upper 32 bits of the block counter
&gt; -as a nonce, instead limiting message size to @math{2^32} blocks or 256
&gt; -GBytes, but that variant is currently not supported.
&gt; +defines a similar construction but with Salsa20 instead of ChaCha.
&gt; +
&gt; +Nettle's implementation of ChaCha-Poly1305 follows @cite{RFC 7539}.
&gt; +Unlike the original definition of ChaCha, the nonces are of 12 bytes.

Maybe worth mentioning the 32-bit block count and corresponding limit on
message size?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200307160753</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-03-07 16:07:53-0400</timestampReceived><subject>Re: [PATCH 1/2] chacha: add function to set initial block counter</subject><body>

Daiki Ueno &lt;ueno@gnu.org&gt; writes:

&gt; From: Daiki Ueno &lt;dueno@redhat.com&gt;
&gt;
&gt; The ChaCha20 based header protection algorithm in QUIC requires a way
&gt; to set the initial value of counter:
&gt; https://quicwg.org/base-drafts/draft-ietf-quic-tls.html#name-chacha20-based-header-prote
&gt;
&gt; This will add a new function chacha_set_counter, which takes an
&gt; 8-octet initial value of the block counter.

Do you see any need to add functions working with a 32-bit counter
(together with chacha_set_nonce96)? We could have something like
chacha_set_counter32 and chacha_crypt32.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200308191646</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-03-08 19:16:46-0400</timestampReceived><subject>Re: [PATCH] cmac-des3: add meta declaration to Nettle library</subject><body>

dbaryshkov@gmail.com writes:

&gt; From: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
&gt;
&gt; Move cmac-des3 meta information from testsuite/cmac-test.c to main
&gt; Nettle library.
&gt;
&gt; Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;

Thanks, applied.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200309120118</emailId><senderName>Daiki Ueno</senderName><senderEmail>ueno@gnu.org</senderEmail><timestampReceived>2020-03-09 12:01:18-0400</timestampReceived><subject>[PATCH v2 2/3] chacha: add variant that treats counter value as 32-bit</subject><body>

From: Daiki Ueno &lt;dueno@redhat.com&gt;

The ChaCha-Poly1305 implementation previously used the chacha_crypt
function that assumes the block counter is 64-bit long, while RFC 8439
defines that the counter is 32-bit long.  Although this should be fine
as long as up to 256 gigabytes of data is encrypted with the same key,
it would be nice to use a separate functions (chacha_set_counter32 and
chacha_crypt32) that assume the counter is 32-bit long.

Signed-off-by: Daiki Ueno &lt;dueno@redhat.com&gt;
---
 chacha-crypt.c          | 32 ++++++++++++++++++++++++++++++++
 chacha-poly1305.c       |  4 ++--
 chacha-set-nonce.c      |  6 ++++++
 chacha.h                | 10 ++++++++++
 nettle.texinfo          | 31 +++++++++++++++++++++++++++++++
 testsuite/chacha-test.c | 34 ++++++++++++++++++++++++++++++----
 6 files changed, 111 insertions(+), 6 deletions(-)

diff --git a/chacha-crypt.c b/chacha-crypt.c
index 63d799ce..0bb44ed9 100644
--- a/chacha-crypt.c
+++ b/chacha-crypt.c
@@ -85,3 +85,35 @@ chacha_crypt(struct chacha_ctx *ctx,
       m += CHACHA_BLOCK_SIZE;
   }
 }
+
+void
+chacha_crypt32(struct chacha_ctx *ctx,
+	       size_t length,
+	       uint8_t *c,
+	       const uint8_t *m)
+{
+  if (!length)
+    return;
+
+  for (;;)
+    {
+      uint32_t x[_CHACHA_STATE_LENGTH];
+
+      _chacha_core (x, ctx-&gt;state, CHACHA_ROUNDS);
+
+      ++ctx-&gt;state[12];
+
+      /* stopping at 2^70 length per nonce is user's responsibility */
+
+      if (length &lt;= CHACHA_BLOCK_SIZE)
+	{
+	  memxor3 (c, m, x, length);
+	  return;
+	}
+      memxor3 (c, m, x, CHACHA_BLOCK_SIZE);
+
+      length -= CHACHA_BLOCK_SIZE;
+      c += CHACHA_BLOCK_SIZE;
+      m += CHACHA_BLOCK_SIZE;
+  }
+}
diff --git a/chacha-poly1305.c b/chacha-poly1305.c
index 974a5022..a15fef0c 100644
--- a/chacha-poly1305.c
+++ b/chacha-poly1305.c
@@ -130,7 +130,7 @@ chacha_poly1305_encrypt (struct chacha_poly1305_ctx *ctx,
   assert (ctx-&gt;data_size % CHACHA_POLY1305_BLOCK_SIZE == 0);
   poly1305_pad (ctx);
 
-  chacha_crypt (&amp;ctx-&gt;chacha, length, dst, src);
+  chacha_crypt32 (&amp;ctx-&gt;chacha, length, dst, src);
   poly1305_update (ctx, length, dst);
   ctx-&gt;data_size += length;
 }
@@ -146,7 +146,7 @@ chacha_poly1305_decrypt (struct chacha_poly1305_ctx *ctx,
   poly1305_pad (ctx);
 
   poly1305_update (ctx, length, src);
-  chacha_crypt (&amp;ctx-&gt;chacha, length, dst, src);
+  chacha_crypt32 (&amp;ctx-&gt;chacha, length, dst, src);
   ctx-&gt;data_size += length;
 }
 			 
diff --git a/chacha-set-nonce.c b/chacha-set-nonce.c
index 2c34e498..1547aea1 100644
--- a/chacha-set-nonce.c
+++ b/chacha-set-nonce.c
@@ -75,3 +75,9 @@ chacha_set_counter(struct chacha_ctx *ctx, const uint8_t *counter)
   ctx-&gt;state[12] = LE_READ_UINT32(counter + 0);
   ctx-&gt;state[13] = LE_READ_UINT32(counter + 4);
 }
+
+void
+chacha_set_counter32(struct chacha_ctx *ctx, const uint8_t *counter)
+{
+  ctx-&gt;state[12] = LE_READ_UINT32(counter + 0);
+}
diff --git a/chacha.h b/chacha.h
index 440fe968..fe28b835 100644
--- a/chacha.h
+++ b/chacha.h
@@ -47,7 +47,9 @@ extern "C" {
 #define chacha_set_nonce nettle_chacha_set_nonce
 #define chacha_set_nonce96 nettle_chacha_set_nonce96
 #define chacha_set_counter nettle_chacha_set_counter
+#define chacha_set_counter32 nettle_chacha_set_counter32
 #define chacha_crypt nettle_chacha_crypt
+#define chacha_crypt32 nettle_chacha_crypt32
 
 /* Currently, only 256-bit keys are supported. */
 #define CHACHA_KEY_SIZE 32
@@ -55,6 +57,7 @@ extern "C" {
 #define CHACHA_NONCE_SIZE 8
 #define CHACHA_NONCE96_SIZE 12
 #define CHACHA_COUNTER_SIZE 8
+#define CHACHA_COUNTER32_SIZE 4
 
 #define _CHACHA_STATE_LENGTH 16
 
@@ -86,10 +89,17 @@ chacha_set_nonce96(struct chacha_ctx *ctx, const uint8_t *nonce);
 void
 chacha_set_counter(struct chacha_ctx *ctx, const uint8_t *counter);
 
+void
+chacha_set_counter32(struct chacha_ctx *ctx, const uint8_t *counter);
+
 void
 chacha_crypt(struct chacha_ctx *ctx, size_t length, 
              uint8_t *dst, const uint8_t *src);
 
+void
+chacha_crypt32(struct chacha_ctx *ctx, size_t length,
+	       uint8_t *dst, const uint8_t *src);
+
 #ifdef __cplusplus
 }
 #endif
diff --git a/nettle.texinfo b/nettle.texinfo
index 0b339f51..fe44f6af 100644
--- a/nettle.texinfo
+++ b/nettle.texinfo
@@ -1700,6 +1700,37 @@ all but the last call @emph{must} use a length that is a \
multiple of  @code{CHACHA_BLOCK_SIZE}.
 @end deftypefun
 
+@subsubsection 32-bit counter variant
+
+While the original paper uses 64-bit counter value, the variant defined
+in @cite{RFC 8439} uses 32-bit counter value. This variant is
+particularly useful for @pxref{ChaCha-Poly1305} AEAD construction, which
+supports 12-octet nonces.
+
+@defvr Constant CHACHA_NONCE96_SIZE
+Size of the nonce, 12.
+@end defvr
+
+@defvr Constant CHACHA_COUNTER32_SIZE
+Size of the counter, 4.
+@end defvr
+
+@deftypefun void chacha_set_nonce96 (struct chacha_ctx *@var{ctx}, const uint8_t \
*@var{nonce}) +Sets the nonce. This is similar to the above @code{chacha_set_nonce},
+but the input is always of size @code{CHACHA_NONCE96_SIZE}, 12 octets.
+@end deftypefun
+
+@deftypefun void chacha_set_counter32 (struct chacha_ctx *@var{ctx}, const uint8_t \
*@var{counter}) +Sets the block counter. This is similar to the above \
@code{chacha_set_counter}, +but the input is always of size \
@code{CHACHA_COUNTER32_SIZE}, 4 octets. +@end deftypefun
+
+@deftypefun void chacha_crypt32 (struct chacha_ctx *@var{ctx}, size_t @var{length}, \
uint8_t *@var{dst}, const uint8_t *@var{src}) +Encrypts or decrypts the data of a \
message, using ChaCha. This is similar to the +above @code{chacha_crypt}, but it \
assumes the internal counter value is 32-bit +long and the nonce is 96-bit long.
+@end deftypefun
+
 @subsection DES
 @cindex DES
 DES is the old Data Encryption Standard, specified by NIST. It uses a
diff --git a/testsuite/chacha-test.c b/testsuite/chacha-test.c
index 6875d4bb..fb8f1db7 100644
--- a/testsuite/chacha-test.c
+++ b/testsuite/chacha-test.c
@@ -71,9 +71,23 @@ _test_chacha(const struct tstring *key, const struct tstring \
*nonce,  die ("Bad nonce size %u.\n", (unsigned) nonce-&gt;length);
 
 	  if (counter)
-	    chacha_set_counter(&amp;ctx, counter-&gt;data);
+	    {
+	      if (counter-&gt;length == CHACHA_COUNTER_SIZE)
+		{
+		  ASSERT (nonce-&gt;length == CHACHA_NONCE_SIZE);
+		  chacha_set_counter(&amp;ctx, counter-&gt;data);
+		}
+	      else if (counter-&gt;length == CHACHA_COUNTER32_SIZE)
+		{
+		  ASSERT (nonce-&gt;length == CHACHA_NONCE96_SIZE);
+		  chacha_set_counter32(&amp;ctx, counter-&gt;data);
+		}
+	    }
 
-	  chacha_crypt (&amp;ctx, length, data, data);
+	  if (nonce-&gt;length == CHACHA_NONCE_SIZE)
+	    chacha_crypt (&amp;ctx, length, data, data);
+	  else
+	    chacha_crypt32 (&amp;ctx, length, data, data);
 
 	  ASSERT (data[-1] == 17);
 	  ASSERT (data[length] == 17);
@@ -666,8 +680,20 @@ test_main(void)
 		   "b5129cd1de164eb9 cbd083e8a2503c4e"),
 	      20);
 
-  /* This is identical to the 96-bit nonce test, but it manually sets
-     the counter value */
+  /* This is identical to the above 96-bit nonce test, but it manually
+     sets the 32-bit counter value */
+  test_chacha_with_counter(SHEX("0001020304050607 08090a0b0c0d0e0f"
+				"1011121314151617 18191a1b1c1d1e1f"),
+			   SHEX("000000090000004a 00000000"),
+			   SHEX("10f1e7e4d13b5915 500fdd1fa32071c4"
+				"c7d1f4c733c06803 0422aa9ac3d46c4e"
+				"d2826446079faa09 14c2d705d98b02a2"
+				"b5129cd1de164eb9 cbd083e8a2503c4e"),
+			   20,
+			   SHEX("01000000"));
+
+  /* This is identical to the above 96-bit nonce test, but it manually
+     sets the 64-bit counter value */
   test_chacha_with_counter(SHEX("0001020304050607 08090a0b0c0d0e0f"
 				"1011121314151617 18191a1b1c1d1e1f"),
 			   SHEX("0000004a00000000"),
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200309120119</emailId><senderName>Daiki Ueno</senderName><senderEmail>ueno@gnu.org</senderEmail><timestampReceived>2020-03-09 12:01:19-0400</timestampReceived><subject>[PATCH v2 3/3] doc: match ChaCha-Poly1305 documentation to the implementation</subject><body>

From: Daiki Ueno &lt;dueno@redhat.com&gt;

While the documentation said the nonce size is 8 octets, the
implementation actually assumed 12 octets following RFC 7539.

Signed-off-by: Daiki Ueno &lt;dueno@redhat.com&gt;
---
 nettle.texinfo | 19 +++++++------------
 1 file changed, 7 insertions(+), 12 deletions(-)

diff --git a/nettle.texinfo b/nettle.texinfo
index fe44f6af..418f46d8 100644
--- a/nettle.texinfo
+++ b/nettle.texinfo
@@ -3323,17 +3323,12 @@ except that @var{cipher} and @var{f} are replaced with a context structure.
 ChaCha-Poly1305 is a combination of the ChaCha stream cipher and the
 poly1305 message authentication code (@pxref{Poly1305}). It originates
 from the NaCl cryptographic library by D. J. Bernstein et al, which
-defines a similar construction but with Salsa20 instead of ChaCha. 
-
-Nettle's implementation ChaCha-Poly1305 should be considered
-@strong{experimental}. At the time of this writing, there is no
-authoritative specification for ChaCha-Poly1305, and a couple of
-different incompatible variants. Nettle implements it using the original
-definition of ChaCha, with 64 bits (8 octets) each for the nonce and the
-block counter. Some protocols prefer to use nonces of 12 bytes, and it's
-a small change to ChaCha to use the upper 32 bits of the block counter
-as a nonce, instead limiting message size to @math{2^32} blocks or 256
-GBytes, but that variant is currently not supported.
+defines a similar construction but with Salsa20 instead of ChaCha.
+
+Nettle's implementation of ChaCha-Poly1305 follows @cite{RFC 8439},
+where the ChaCha cipher is initialized with a 12-byte nonce and a 4-byte
+block counter. This allows up to 256 gigabytes of data to be encrypted
+using the same key.
 
 For ChaCha-Poly1305, the ChaCha cipher is initialized with a key, of 256
 bits, and a per-message nonce. The first block of the key stream
@@ -3362,7 +3357,7 @@ ChaCha-Poly1305 key size, 32.
 @end defvr
 
 @defvr Constant CHACHA_POLY1305_NONCE_SIZE
-Same as the ChaCha nonce size, 16.
+ChaCha-Poly1305 nonce size, 12.
 @end defvr
 
 @defvr Constant CHACHA_POLY1305_DIGEST_SIZE
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200309183333</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-03-09 18:33:33-0400</timestampReceived><subject>Re: [PATCH v2 1/3] chacha: add function to set initial block counter</subject><body>

Daiki Ueno &lt;ueno@gnu.org&gt; writes:

&gt; From: Daiki Ueno &lt;dueno@redhat.com&gt;
&gt;
&gt; The ChaCha20 based header protection algorithm in QUIC requires a way
&gt; to set the initial value of counter:
&gt; https://quicwg.org/base-drafts/draft-ietf-quic-tls.html#name-chacha20-based-header-prote
&gt;
&gt; This will add a new function chacha_set_counter, which takes an
&gt; 8-octet initial value of the block counter.

I've merged all three patches to master-updates. Two nits below:

&gt; +void
&gt; +chacha_crypt32(struct chacha_ctx *ctx,
&gt; +	       size_t length,
&gt; +	       uint8_t *c,
&gt; +	       const uint8_t *m)
&gt; +{
&gt; +  if (!length)
&gt; +    return;
&gt; +
&gt; +  for (;;)
&gt; +    {
&gt; +      uint32_t x[_CHACHA_STATE_LENGTH];
&gt; +
&gt; +      _chacha_core (x, ctx-&gt;state, CHACHA_ROUNDS);
&gt; +
&gt; +      ++ctx-&gt;state[12];
&gt; +
&gt; +      /* stopping at 2^70 length per nonce is user's responsibility */

Should be 2^38, not 2^70, right?

&gt; +Nettle's implementation of ChaCha-Poly1305 follows @cite{RFC 8439},
&gt; +where the ChaCha cipher is initialized with a 12-byte nonce and a 4-byte
&gt; +block counter. This allows up to 256 gigabytes of data to be encrypted
&gt; +using the same key.

Should be "same key and nonce"; the counter size limits the size of a
message, but the nonce allows for many messages using the same key.

I'll fix these.

It would be nice with a test case where the first 32 bits of the counter
wrap around, which is the only case where chacha_crypt and
chacha_crypt32 behave differently. Is that something you can look into?

Thanks!
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200309192233</emailId><senderName>Simo Sorce</senderName><senderEmail>simo@redhat.com</senderEmail><timestampReceived>2020-03-09 19:22:33-0400</timestampReceived><subject>Re: [PATCH] x86: Add X86_ENDBR and CET marker to config.m4.in</subject><body>

On Mon, 2020-03-09 at 15:19 -0400, Simo Sorce wrote:
&gt; On Mon, 2020-03-09 at 11:56 -0700, H.J. Lu wrote:
&gt; &gt; On Mon, Mar 9, 2020 at 11:19 AM Simo Sorce &lt;simo@redhat.com&gt; wrote:
&gt; &gt; &gt; On Mon, 2020-03-09 at 19:03 +0100, Niels Möller wrote:
&gt; &gt; &gt; &gt; Simo Sorce &lt;simo@redhat.com&gt; writes:
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; &gt; The patchset i solder than I did remember, April 2019
&gt; &gt; &gt; &gt; &gt; But I recall running at least one version of it on our CET emulator @
&gt; &gt; &gt; &gt; &gt; Red Hat.
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; Sorry I forgot to followup on that. It seems only the first easy cleanup
&gt; &gt; &gt; &gt; patch, "Add missing EPILOGUEs in assembly files", was applied back then.
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; &gt; Do you remember why you used GNU_CET_SECTION() explicitly in .asm files,
&gt; &gt; &gt; &gt; rather than using an m4 divert?
&gt; &gt; &gt; 
&gt; &gt; &gt; Not really I do not recall anymore, but I think there was a reason, as
&gt; &gt; &gt; I recall you made that comment back then and it "didn't work out" when
&gt; &gt; &gt; I tried is the memory I have of it.
&gt; &gt; &gt; Might have to do with differences in how it lays out the code when done
&gt; &gt; &gt; via m4 divert, but not 100% sure.
&gt; &gt; &gt; 
&gt; &gt; 
&gt; &gt; m4 divert  requires much less changes.   Here is the updated patch with
&gt; &gt; ASM_X86_ENDBR, ASM_X86_MARK_CET_ALIGN and ASM_X86_MARK_CET.
&gt; &gt; 
&gt; &gt; 
&gt; 
&gt; Two comments on your patch.
&gt; 
&gt; 1. It is an error to align based on architecture. All GNU Notes MUST be
&gt; aligned 8 bytes. Since 2018 GNU Libc ignores misaligned notes.

Ah nevermind this point, misunderstanding with my libc expert, the 4
bytes alignment is ok on 32 bit code.

&gt; 2. It is better to use .pushsection .popsection pairs around the note
&gt; instead of .section because of the side effects of using .section

&gt; The m4 divert looks smaller impact, feel free to lift the Gnu Note
&gt; section in my patch #3 and place it into your patch if you want. My
&gt; code also made it more explicit what all the sections values actually
&gt; mean which will help in long term maintenance if someone else need to
&gt; change anything (like for example changing to enable only ShadowStack
&gt; vs IBT).
&gt; 
&gt; Simo.
&gt; 

-- 
Simo Sorce
RHEL Crypto Team
Red Hat, Inc




_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200312213609</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2020-03-12 21:36:09-0400</timestampReceived><subject>Re: [PATCH 1/1] arm: Fix memxor for non-armv6+ big-endian systems</subject><body>

Hello Niels,

On Thu, Mar 12, 2020 at 10:01:51PM +0100, Niels Möller wrote:

&gt; &gt; ARM assembly adjustments for big-endian systems contained armv6+-only
&gt; &gt; instructions (rev) in generic arm memxor code. Replace those with an
&gt; &gt; actual conversion of the leftover byte store routines for big-endian
&gt; &gt; systems. This also provides a slight optimisation by removing the
&gt; &gt; additional instruction as well as increased symmetry between little- and
&gt; &gt; big-endian implementations.
&gt; Merged onto the master-update branch (to let the ci system verify that
&gt; ARM LE isn't broken). Thanks.

FWIW it just cleared preliminary BE CI:
https://gitlab.com/michaelweiser/nettle/pipelines/125862809
https://gitlab.com/michaelweiser/nettle/pipelines/125862752

&gt; It would be nice to have arm be in the ci as well, but you need to
&gt; coordinate with Nikos. I have a somewhat fuzzy understanding of how it's
&gt; set up, and know very little about the various system images being used.

Will do.
-- 
Thanks!
Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200314190125</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-03-14 19:01:25-0400</timestampReceived><subject>Re: V3 [PATCH] x86: Add X86_ENDBR and CET marker to config.m4.in</subject><body>

"H.J. Lu" &lt;hjl.tools@gmail.com&gt; writes:

&gt; You need to write a run-time test in configure.ac to check if CET is enabled
&gt; since CET requires processor, kernel and user space support.

Do you think a test like this would be feasible? It needs both compile
time and run time checks:

1. Check (preprocessor) if building on x86, and on an operating system
   with unix-style signal handling. If not, define test_main to
   exit with return code 77 (SKIP macro in testutils.h).

2. Use inline assembly in some way to define a trivial function with no
   ENDBR mark, and produce a function pointer to it.

3. If __CET__ is defined by the compiler, check for runtime support
   (hardware + kernel, but *not* the current mode set up based on ELF
   flags in the executable). If it's supported, install a signal handler
   for whatever for whatever signal happens on indirect jumps without
   ENDBR marks, and which exits the process with return code 0
   (success). Call the asm function via the function pointer. If the
   call returns, fail the test by calling abort.

4. Otherwise, call the asm function via the function pointer, and exit
   with return code 77. (To exercise the inline asm, but still indicate
   that the feature inteded to be tested could not be tested).

Then the test will fail if either we're running a CET-enabled build on a
CET enabled system, but for for some reason the test executable didn't
get it this protection. Or we're running on a non-CET x86 system where
the inline asm is somehow broken.

No additional configure checks needed (except if we want a proper test
for signal/sigaction rather than depending on preprocessor predefines).

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200318143232</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-03-18 14:32:32-0400</timestampReceived><subject>[PATCH] Added bcrypt() support.</subject><body>

---
 blowfish.c | 515 ++++++++++++++++++++++++++++++++++++++++++++++++++++-
 blowfish.h |   5 +
 2 files changed, 518 insertions(+), 2 deletions(-)

diff --git a/blowfish.c b/blowfish.c
index 52040f13..d0b45117 100644
--- a/blowfish.c
+++ b/blowfish.c
@@ -45,7 +45,12 @@
    (from Nettle's blowfish.h), dropping the libgcrypt wrapper
    functions, fixing #include's, remove support for non-16 rounds
    (there are no test vectors), adding FOR_BLOCK iterations, and
-   running indent on the code. */
+   running indent on the code.
+
+   The lower half of this file includes code for the computation
+   of bcrypt hashes, which was added at a later date.
+
+ */
 
 #if HAVE_CONFIG_H
 #include "config.h"
@@ -397,7 +402,7 @@ blowfish_set_key (struct blowfish_ctx *ctx,
       ctx-&gt;p[i] = datal;
       ctx-&gt;p[i + 1] = datar;
     }
-  
+
   for (j = 0; j &lt; 4; j++)
     for (i = 0; i &lt; 256; i += 2)
       {
@@ -428,3 +433,509 @@ blowfish128_set_key(struct blowfish_ctx *ctx, const uint8_t *key)
 {
   return blowfish_set_key (ctx, BLOWFISH128_KEY_SIZE, key);
 }
+
+/*
+ * The crypt_blowfish homepage is:
+ *
+ *	http://www.openwall.com/crypt/
+ *
+ * This code comes from John the Ripper password cracker, with reentrant
+ * and crypt(3) interfaces added, but optimizations specific to password
+ * cracking removed.
+ *
+ * Written by Solar Designer &lt;solar at openwall.com&gt; in 1998-2015.
+ * No copyright is claimed, and the software is hereby placed in the public
+ * domain. In case this attempt to disclaim copyright and place the software
+ * in the public domain is deemed null and void, then the software is
+ * Copyright (c) 1998-2015 Solar Designer and it is hereby released to the
+ * general public under the following terms:
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted.
+ *
+ * There's ABSOLUTELY NO WARRANTY, express or implied.
+ *
+ * It is my intent that you should be able to use this on your system,
+ * as part of a software package, or anywhere else to improve security,
+ * ensure compatibility, or for any other purpose. I would appreciate
+ * it if you give credit where it is due and keep your modifications in
+ * the public domain as well, but I don't require that in order to let
+ * you place this code and any modifications you make under a license
+ * of your choice.
+ *
+ * This implementation is fully compatible with OpenBSD's bcrypt.c for prefix
+ * "$2b$", originally by Niels Provos &lt;provos at citi.umich.edu&gt;, and it uses
+ * some of his ideas. The password hashing algorithm was designed by David
+ * Mazieres &lt;dm at lcs.mit.edu&gt;. For information on the level of
+ * compatibility for bcrypt hash prefixes other than "$2b$", please refer to
+ * the comments in BF_set_key() below and to the included crypt(3) man page.
+ *
+ * There's a paper on the algorithm that explains its design decisions:
+ *
+ *	http://www.usenix.org/events/usenix99/provos.html
+ */
+
+#include &lt;string.h&gt;
+
+#include &lt;errno.h&gt;
+#ifndef __set_errno
+#define __set_errno(val) errno = (val)
+#endif
+
+typedef uint32_t BF_key[_BLOWFISH_ROUNDS + 2];
+
+/*
+ * Magic IV for 64 Blowfish encryptions that we do at the end.
+ * The string is "OrpheanBeholderScryDoubt" on big-endian.
+ */
+static uint32_t BF_magic_w[6] = {
+  0x4F727068, 0x65616E42, 0x65686F6C,
+  0x64657253, 0x63727944, 0x6F756274
+};
+
+static unsigned char BF_itoa64[64 + 1] =
+  "./ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789";
+
+static unsigned char BF_atoi64[0x60] = {
+  64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64,  0,  1,
+  54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 64, 64, 64, 64, 64,
+  64,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,
+  17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 64, 64, 64, 64, 64,
+  64, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42,
+  43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 64, 64, 64, 64, 64
+};
+
+#define BF_safe_atoi64(dst, src) \
+{ \
+  tmp = (unsigned char)(src); \
+  if ((unsigned int)(tmp -= 0x20) &gt;= 0x60) return -1; \
+  tmp = BF_atoi64[tmp]; \
+  if (tmp &gt; 63) return -1; \
+  (dst) = tmp; \
+}
+
+static int BF_decode(uint32_t *dst, const char *src, int size)
+{
+  unsigned char *dptr = (unsigned char *)dst;
+  unsigned char *end = dptr + size;
+  const unsigned char *sptr = (const unsigned char *)src;
+  unsigned int tmp, c1, c2, c3, c4;
+
+  do {
+    BF_safe_atoi64(c1, *sptr++);
+    BF_safe_atoi64(c2, *sptr++);
+    *dptr++ = (c1 &lt;&lt; 2) | ((c2 &amp; 0x30) &gt;&gt; 4);
+    if (dptr &gt;= end) break;
+
+    BF_safe_atoi64(c3, *sptr++);
+    *dptr++ = ((c2 &amp; 0x0F) &lt;&lt; 4) | ((c3 &amp; 0x3C) &gt;&gt; 2);
+    if (dptr &gt;= end) break;
+
+    BF_safe_atoi64(c4, *sptr++);
+    *dptr++ = ((c3 &amp; 0x03) &lt;&lt; 6) | c4;
+  } while (dptr &lt; end);
+
+  if (end - dptr == size)
+    return -1;
+
+  *dptr = 0;
+
+  return 0;
+}
+
+static void BF_encode(char *dst, const uint32_t *src, int size)
+{
+  const unsigned char *sptr = (const unsigned char *)src;
+  const unsigned char *end = sptr + size;
+  unsigned char *dptr = (unsigned char *)dst;
+  unsigned int c1, c2;
+
+  do {
+    c1 = *sptr++;
+    *dptr++ = BF_itoa64[c1 &gt;&gt; 2];
+    c1 = (c1 &amp; 0x03) &lt;&lt; 4;
+    if (sptr &gt;= end) {
+      *dptr++ = BF_itoa64[c1];
+      break;
+    }
+
+    c2 = *sptr++;
+    c1 |= c2 &gt;&gt; 4;
+    *dptr++ = BF_itoa64[c1];
+    c1 = (c2 &amp; 0x0f) &lt;&lt; 2;
+    if (sptr &gt;= end) {
+      *dptr++ = BF_itoa64[c1];
+      break;
+    }
+
+    c2 = *sptr++;
+    c1 |= c2 &gt;&gt; 6;
+    *dptr++ = BF_itoa64[c1];
+    *dptr++ = BF_itoa64[c2 &amp; 0x3f];
+  } while (sptr &lt; end);
+}
+
+static void BF_swap(uint32_t *x, int count)
+{
+  static int endianness_check = 1;
+  char *is_little_endian = (char *)&amp;endianness_check;
+  uint32_t tmp;
+
+  if (*is_little_endian)
+  do {
+    tmp = *x;
+    tmp = (tmp &lt;&lt; 16) | (tmp &gt;&gt; 16);
+    *x++ = ((tmp &amp; 0x00FF00FF) &lt;&lt; 8) | ((tmp &gt;&gt; 8) &amp; 0x00FF00FF);
+  } while (--count);
+}
+
+static void BF_set_key(const char *key, BF_key expanded, BF_key initial,
+    unsigned char flags)
+{
+  const char *ptr = key;
+  unsigned int bug, i, j;
+  uint32_t safety, sign, diff, tmp[2];
+
+/*
+ * There was a sign extension bug in older revisions of this function. While
+ * we would have liked to simply fix the bug and move on, we have to provide
+ * a backwards compatibility feature (essentially the bug) for some systems and
+ * a safety measure for some others. The latter is needed because for certain
+ * multiple inputs to the buggy algorithm there exist easily found inputs to
+ * the correct algorithm that produce the same hash. Thus, we optionally
+ * deviate from the correct algorithm just enough to avoid such collisions.
+ * While the bug itself affected the majority of passwords containing
+ * characters with the 8th bit set (although only a percentage of those in a
+ * collision-producing way), the anti-collision safety measure affects
+ * only a subset of passwords containing the '\xff' character (not even all of
+ * those passwords, just some of them). This character is not found in valid
+ * UTF-8 sequences and is rarely used in popular 8-bit character encodings.
+ * Thus, the safety measure is unlikely to cause much annoyance, and is a
+ * reasonable tradeoff to use when authenticating against existing hashes that
+ * are not reliably known to have been computed with the correct algorithm.
+ *
+ * We use an approach that tries to minimize side-channel leaks of password
+ * information - that is, we mostly use fixed-cost bitwise operations instead
+ * of branches or table lookups. (One conditional branch based on password
+ * length remains. It is not part of the bug aftermath, though, and is
+ * difficult and possibly unreasonable to avoid given the use of C strings by
+ * the caller, which results in similar timing leaks anyway.)
+ *
+ * For actual implementation, we set an array index in the variable "bug"
+ * (0 means no bug, 1 means sign extension bug emulation) and a flag in the
+ * variable "safety" (bit 16 is set when the safety measure is requested).
+ * Valid combinations of settings are:
+ *
+ * Prefix "$2a$": bug = 0, safety = 0x10000
+ * Prefix "$2b$": bug = 0, safety = 0
+ * Prefix "$2x$": bug = 1, safety = 0
+ * Prefix "$2y$": bug = 0, safety = 0
+ */
+  bug = (unsigned int)flags &amp; 1;
+  safety = ((uint32_t)flags &amp; 2) &lt;&lt; 15;
+
+  sign = diff = 0;
+
+  for (i = 0; i &lt; _BLOWFISH_ROUNDS + 2; i++) {
+    tmp[0] = tmp[1] = 0;
+    for (j = 0; j &lt; 4; j++) {
+      tmp[0] &lt;&lt;= 8;
+      tmp[0] |= (unsigned char)*ptr; /* correct */
+      tmp[1] &lt;&lt;= 8;
+      tmp[1] |= (signed char)*ptr; /* bug */
+/*
+ * Sign extension in the first char has no effect - nothing to overwrite yet,
+ * and those extra 24 bits will be fully shifted out of the 32-bit word. For
+ * chars 2, 3, 4 in each four-char block, we set bit 7 of "sign" if sign
+ * extension in tmp[1] occurs. Once this flag is set, it remains set.
+ */
+      if (j)
+        sign |= tmp[1] &amp; 0x80;
+      if (!*ptr)
+        ptr = key;
+      else
+        ptr++;
+    }
+    diff |= tmp[0] ^ tmp[1]; /* Non-zero on any differences */
+
+    expanded[i] = tmp[bug];
+    initial[i] = initial_ctx.p[i] ^ tmp[bug];
+  }
+
+/*
+ * At this point, "diff" is zero iff the correct and buggy algorithms produced
+ * exactly the same result. If so and if "sign" is non-zero, which indicates
+ * that there was a non-benign sign extension, this means that we have a
+ * collision between the correctly computed hash for this password and a set of
+ * passwords that could be supplied to the buggy algorithm. Our safety measure
+ * is meant to protect from such many-buggy to one-correct collisions, by
+ * deviating from the correct algorithm in such cases. Let's check for this.
+ */
+  diff |= diff &gt;&gt; 16; /* still zero iff exact match */
+  diff &amp;= 0xffff; /* ditto */
+  diff += 0xffff; /* bit 16 set iff "diff" was non-zero (on non-match) */
+  sign &lt;&lt;= 9; /* move the non-benign sign extension flag to bit 16 */
+  sign &amp;= ~diff &amp; safety; /* action needed? */
+
+/*
+ * If we have determined that we need to deviate from the correct algorithm,
+ * flip bit 16 in initial expanded key. (The choice of 16 is arbitrary, but
+ * let's stick to it now. It came out of the approach we used above, and it's
+ * not any worse than any other choice we could make.)
+ *
+ * It is crucial that we don't do the same to the expanded key used in the main
+ * Eksblowfish loop. By doing it to only one of these two, we deviate from a
+ * state that could be directly specified by a password to the buggy algorithm
+ * (and to the fully correct one as well, but that's a side-effect).
+ */
+  initial[0] ^= sign;
+}
+
+static const unsigned char flags_by_subtype[26] =
+  {2, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
+   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 4, 0};
+
+static char *BF_crypt(const char *key, const char *settings,
+  char *output, int size,
+  uint32_t min)
+{
+  struct {
+    struct blowfish_ctx ctx;
+    BF_key expanded_key;
+    union {
+      uint32_t salt[4];
+      uint32_t output[6];
+    } binary;
+  } data;
+  uint32_t L, R;
+  uint32_t tmp1, tmp2, tmp3, tmp4;
+  uint32_t *ptr;
+  uint32_t count;
+  int i;
+
+  if (size &lt; 7 + 22 + 31 + 1) {
+    __set_errno(ERANGE);
+    return NULL;
+  }
+
+  if (settings[0] != '$' ||
+      settings[1] != '2' ||
+      settings[2] &lt; 'a' || settings[2] &gt; 'z' ||
+      !flags_by_subtype[(unsigned int)(unsigned char)settings[2] - 'a'] ||
+      settings[3] != '$' ||
+      settings[4] &lt; '0' || settings[4] &gt; '3' ||
+      settings[5] &lt; '0' || settings[5] &gt; '9' ||
+      (settings[4] == '3' &amp;&amp; settings[5] &gt; '1') ||
+      settings[6] != '$') {
+    __set_errno(EINVAL);
+    return NULL;
+  }
+
+  count = (uint32_t)1 &lt;&lt; ((settings[4] - '0') * 10 + (settings[5] - '0'));
+  if (count &lt; min || BF_decode(data.binary.salt, &amp;settings[7], 16)) {
+    __set_errno(EINVAL);
+    return NULL;
+  }
+  BF_swap(data.binary.salt, 4);
+
+  BF_set_key(key, data.expanded_key, data.ctx.p,
+      flags_by_subtype[(unsigned int)(unsigned char)settings[2] - 'a']);
+
+  memcpy(data.ctx.s, initial_ctx.s, sizeof(data.ctx.s));
+
+  L = R = 0;
+  for (i = 0; i &lt; _BLOWFISH_ROUNDS + 2; i += 2) {
+    L ^= data.binary.salt[i &amp; 2];
+    R ^= data.binary.salt[(i &amp; 2) + 1];
+    encrypt(&amp;data.ctx, &amp;L, &amp;R);
+    data.ctx.p[i] = L;
+    data.ctx.p[i + 1] = R;
+  }
+
+  ptr = data.ctx.s[0];
+  do {
+    ptr += 4;
+    L ^= data.binary.salt[(_BLOWFISH_ROUNDS + 2) &amp; 3];
+    R ^= data.binary.salt[(_BLOWFISH_ROUNDS + 3) &amp; 3];
+    encrypt(&amp;data.ctx, &amp;L, &amp;R);
+    *(ptr - 4) = L;
+    *(ptr - 3) = R;
+
+    L ^= data.binary.salt[(_BLOWFISH_ROUNDS + 4) &amp; 3];
+    R ^= data.binary.salt[(_BLOWFISH_ROUNDS + 5) &amp; 3];
+    encrypt(&amp;data.ctx, &amp;L, &amp;R);
+    *(ptr - 2) = L;
+    *(ptr - 1) = R;
+  } while (ptr &lt; &amp;data.ctx.s[3][0xFF]);
+
+  do {
+    int done;
+
+    for (i = 0; i &lt; _BLOWFISH_ROUNDS + 2; i += 2) {
+      data.ctx.p[i] ^= data.expanded_key[i];
+      data.ctx.p[i + 1] ^= data.expanded_key[i + 1];
+    }
+
+    done = 0;
+    do {
+      L = R = 0;
+      ptr = data.ctx.p;
+      do {
+        ptr += 2;
+        encrypt(&amp;data.ctx, &amp;L, &amp;R);
+        *(ptr - 2) = L;
+        *(ptr - 1) = R;
+      } while (ptr &lt; &amp;data.ctx.p[_BLOWFISH_ROUNDS + 2]);
+
+      ptr = data.ctx.s[0];
+      do {
+        ptr += 2;
+        encrypt(&amp;data.ctx, &amp;L, &amp;R);
+        *(ptr - 2) = L;
+        *(ptr - 1) = R;
+      } while (ptr &lt; &amp;data.ctx.s[3][0xFF]);
+
+      if (done)
+        break;
+      done = 1;
+
+      tmp1 = data.binary.salt[0];
+      tmp2 = data.binary.salt[1];
+      tmp3 = data.binary.salt[2];
+      tmp4 = data.binary.salt[3];
+      for (i = 0; i &lt; _BLOWFISH_ROUNDS; i += 4) {
+        data.ctx.p[i] ^= tmp1;
+        data.ctx.p[i + 1] ^= tmp2;
+        data.ctx.p[i + 2] ^= tmp3;
+        data.ctx.p[i + 3] ^= tmp4;
+      }
+      data.ctx.p[16] ^= tmp1;
+      data.ctx.p[17] ^= tmp2;
+    } while (1);
+  } while (--count);
+
+  for (i = 0; i &lt; 6; i += 2) {
+    L = BF_magic_w[i];
+    R = BF_magic_w[i + 1];
+
+    count = 64;
+    do {
+      encrypt(&amp;data.ctx, &amp;L, &amp;R);
+    } while (--count);
+
+    data.binary.output[i] = L;
+    data.binary.output[i + 1] = R;
+  }
+
+  memcpy(output, settings, 7 + 22 - 1);
+  output[7 + 22 - 1] = BF_itoa64[(int)
+    BF_atoi64[(int)settings[7 + 22 - 1] - 0x20] &amp; 0x30];
+
+/* This has to be bug-compatible with the original implementation, so
+ * only encode 23 of the 24 bytes. :-) */
+  BF_swap(data.binary.output, 6);
+  BF_encode(&amp;output[7 + 22], data.binary.output, 23);
+  output[7 + 22 + 31] = '\0';
+
+  return output;
+}
+
+static int bcrypt_output_magic(const char *settings, char *output, int size)
+{
+  if (size &lt; 3)
+    return -1;
+
+  output[0] = '*';
+  output[1] = '0';
+  output[2] = '\0';
+
+  if (settings[0] == '*' &amp;&amp; settings[1] == '0')
+    output[1] = '1';
+
+  return 0;
+}
+
+/*
+ * Please preserve the runtime self-test. It serves two purposes at once:
+ *
+ * 1. We really can't afford the risk of producing incompatible hashes e.g.
+ * when there's something like gcc bug 26587 again, whereas an application or
+ * library integrating this code might not also integrate our external tests or
+ * it might not run them after every build. Even if it does, the miscompile
+ * might only occur on the production build, but not on a testing build (such
+ * as because of different optimization settings). It is painful to recover
+ * from incorrectly-computed hashes - merely fixing whatever broke is not
+ * enough. Thus, a proactive measure like this self-test is needed.
+ *
+ * 2. We don't want to leave sensitive data from our actual password hash
+ * computation on the stack or in registers. Previous revisions of the code
+ * would do explicit cleanups, but simply running the self-test after hash
+ * computation is more reliable.
+ *
+ * The performance cost of this quick self-test is around 0.6% at the "$2a$08"
+ * setting.
+ */
+uint8_t *blowfish_bcrypt(const uint8_t *key, const uint8_t *settings,
+  uint8_t *dst, size_t length)
+{
+  const char *test_pw = "8b \xd0\xc1\xd2\xcf\xcc\xd8";
+  const char *test_settings = "$2a$00$abcdefghijklmnopqrstuu";
+  static const char * const test_hashes[2] =
+    {"i1D709vfamulimlGcq0qq3UvuUasvEa\0\x55", /* 'a', 'b', 'y' */
+    "VUrPmXD6q/nVSSp7pNDhCR9071IfIRe\0\x55"}; /* 'x' */
+  const char *test_hash = test_hashes[0];
+  uint8_t *retval;
+  const char *p;
+  int save_errno, ok;
+  struct {
+    char s[7 + 22 + 1];
+    char o[7 + 22 + 31 + 1 + 1 + 1];
+  } buf;
+
+/* Hash the supplied password */
+  bcrypt_output_magic(settings, dst, length);
+  retval = BF_crypt(key, settings, dst, length, 16);
+  save_errno = errno;
+
+/*
+ * Do a quick self-test. It is important that we make both calls to BF_crypt()
+ * from the same scope such that they likely use the same stack locations,
+ * which makes the second call overwrite the first call's sensitive data on the
+ * stack and makes it more likely that any alignment related issues would be
+ * detected by the self-test.
+ */
+  memcpy(buf.s, test_settings, sizeof(buf.s));
+  if (retval) {
+    unsigned int flags = flags_by_subtype[
+        (unsigned int)(unsigned char)settings[2] - 'a'];
+    test_hash = test_hashes[flags &amp; 1];
+    buf.s[2] = settings[2];
+  }
+  memset(buf.o, 0x55, sizeof(buf.o));
+  buf.o[sizeof(buf.o) - 1] = 0;
+  p = BF_crypt(test_pw, buf.s, buf.o, sizeof(buf.o) - (1 + 1), 1);
+
+  ok = (p == buf.o &amp;&amp;
+      !memcmp(p, buf.s, 7 + 22) &amp;&amp;
+      !memcmp(p + (7 + 22), test_hash, 31 + 1 + 1 + 1));
+
+  {
+    const char *k = "\xff\xa3" "34" "\xff\xff\xff\xa3" "345";
+    BF_key ae, ai, ye, yi;
+    BF_set_key(k, ae, ai, 2); /* $2a$ */
+    BF_set_key(k, ye, yi, 4); /* $2y$ */
+    ai[0] ^= 0x10000; /* undo the safety (for comparison) */
+    ok = ok &amp;&amp; ai[0] == 0xdb9c59bc &amp;&amp; ye[17] == 0x33343500 &amp;&amp;
+        !memcmp(ae, ye, sizeof(ae)) &amp;&amp;
+        !memcmp(ai, yi, sizeof(ai));
+  }
+
+  __set_errno(save_errno);
+  if (ok)
+    return retval;
+
+/* Should not happen */
+  bcrypt_output_magic(settings, dst, length);
+  __set_errno(EINVAL); /* pretend we don't support this hash type */
+  return NULL;
+}
diff --git a/blowfish.h b/blowfish.h
index bcdc7cb6..ae7f5b12 100644
--- a/blowfish.h
+++ b/blowfish.h
@@ -81,6 +81,11 @@ void
 blowfish_decrypt(const struct blowfish_ctx *ctx,
                  size_t length, uint8_t *dst,
                  const uint8_t *src);
+uint8_t *
+blowfish_bcrypt(const uint8_t *key,
+                const uint8_t *settings,
+                uint8_t *dst,
+	        size_t length);
 
 #ifdef __cplusplus
 }
-- 
2.20.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200319073907</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-03-19 07:39:07-0400</timestampReceived><subject>Re: Adding code to support bcrypt-hash password verification</subject><body>

"Stephen R. van den Berg" &lt;srb@cuci.nl&gt; writes:

&gt; I just submitted a patch for bcrypt support to Nettle.
&gt; Can this be included in Nettle?

Thanks. What's the main interface? How is it going to be used, in
particular, where will the code be to check the "$2b$ "prefix and invke
this code? The interface needs some documentation (for a start, comments
in the header file) before it can be reviewed.

&gt; If not, do I need to change anything in the patch to make it more
&gt; acceptable?

I think it needs some changes to fit better in Nettle. My initial
comments, after only a quick look:

Put it in a separate .c file. If it needs access to blowfish internals,
add a new header file blowfish-internal.h with declarations, and arrange
so that any internal symbols visibile to the linker has the prefix _nettle.
It's not clear what internals it is using, but if it can be arranged to
only use the public blowfish functions that would be nice.

The new files can use the standard nettle copyright notice + a comment
saying "Based on public domain code by ..." where appropriate.

See if there's a way to reuse Nettle's base64 functions (it's not
entirely clear to me what BF_decode really is doing).

Use macros like READ_UINT32/LE_READ_UNINT32 (macros.h) to convert bytes
to integers. For any other endian-dependent code, use WORDS_BIGENDIAN,
provided by configure.

Don't set errno. If any function really needs to distinguish between
different types of failures, rather than just a success/fail indication,
that should be reported without using any globals. 

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200320154809</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-03-20 15:48:09-0400</timestampReceived><subject>[PATCH] (revision 2.0) Added bcrypt() support.</subject><body>

---
 Makefile.in                       |   2 +-
 base64-decode.c                   |  17 +-
 blowfish-bcrypt.c                 | 492 ++++++++++++++++++++++++++++++
 blowfish.h =&gt; blowfish-internal.h |  51 +---
 blowfish.c                        |  23 +-
 blowfish.h                        |  15 +
 nettle.texinfo                    |  69 +++++
 7 files changed, 603 insertions(+), 66 deletions(-)
 create mode 100644 blowfish-bcrypt.c
 copy blowfish.h =&gt; blowfish-internal.h (50%)

diff --git a/Makefile.in b/Makefile.in
index ddc30428..bfb7ac57 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -73,7 +73,7 @@ nettle_SOURCES = aes-decrypt-internal.c aes-decrypt.c \
 		 aes256-set-encrypt-key.c aes256-set-decrypt-key.c \
 		 aes256-meta.c \
 		 arcfour.c arcfour-crypt.c \
-		 arctwo.c arctwo-meta.c blowfish.c \
+		 arctwo.c arctwo-meta.c blowfish.c blowfish-bcrypt.c \
 		 base16-encode.c base16-decode.c base16-meta.c \
 		 base64-encode.c base64-decode.c base64-meta.c \
 		 base64url-encode.c base64url-decode.c base64url-meta.c \
diff --git a/base64-decode.c b/base64-decode.c
index b993117a..9273224a 100644
--- a/base64-decode.c
+++ b/base64-decode.c
@@ -45,7 +45,7 @@
 void
 base64_decode_init(struct base64_decode_ctx *ctx)
 {
-  static const signed char base64_decode_table[0x100] =
+  static const signed char base64_decode_table[0x80] =
     {
       /* White space is HT, VT, FF, CR, LF and SPC */
       -1, -1, -1, -1, -1, -1, -1, -1, -1, -2, -2, -2, -2, -2, -1, -1, 
@@ -56,14 +56,6 @@ base64_decode_init(struct base64_decode_ctx *ctx)
       15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, -1, -1, -1, -1, -1,
       -1, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,
       41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
     };
 
   ctx-&gt;word = ctx-&gt;bits = ctx-&gt;padding = 0;
@@ -75,7 +67,12 @@ base64_decode_single(struct base64_decode_ctx *ctx,
 		     uint8_t *dst,
 		     char src)
 {
-  int data = ctx-&gt;table[(uint8_t) src];
+  int data;
+
+  if ((uint8_t) src &gt; 0x7f)
+    return -1;
+
+  data = ctx-&gt;table[(uint8_t) src];
 
   switch(data)
     {
diff --git a/blowfish-bcrypt.c b/blowfish-bcrypt.c
new file mode 100644
index 00000000..38516189
--- /dev/null
+++ b/blowfish-bcrypt.c
@@ -0,0 +1,492 @@
+/* blowfish-bcrypt.c
+
+   The blowfish bcrypt implementation.
+
+   Copyright (C) 2014 Niels Möller
+   Copyright (C) 2010  Simon Josefsson
+   Copyright (C) 1998, 2001, 2002, 2003 Free Software Foundation, Inc.
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+/*
+ * This code comes from John the Ripper password cracker, with reentrant
+ * and crypt(3) interfaces added, but optimizations specific to password
+ * cracking removed.
+ *
+ * Written by Solar Designer &lt;solar at openwall.com&gt; in 1998-2015.
+ * No copyright is claimed, and the software is hereby placed in the public
+ * domain. In case this attempt to disclaim copyright and place the software
+ * in the public domain is deemed null and void, then the software is
+ * Copyright (c) 1998-2015 Solar Designer and it is hereby released to the
+ * general public under the following terms:
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted.
+ *
+ * There's ABSOLUTELY NO WARRANTY, express or implied.
+ *
+ * It is my intent that you should be able to use this on your system,
+ * as part of a software package, or anywhere else to improve security,
+ * ensure compatibility, or for any other purpose. I would appreciate
+ * it if you give credit where it is due and keep your modifications in
+ * the public domain as well, but I don't require that in order to let
+ * you place this code and any modifications you make under a license
+ * of your choice.
+ *
+ * This implementation is fully compatible with OpenBSD's bcrypt.c for prefix
+ * "$2b$", originally by Niels Provos &lt;provos at citi.umich.edu&gt;, and it uses
+ * some of his ideas. The password hashing algorithm was designed by David
+ * Mazieres &lt;dm at lcs.mit.edu&gt;. For information on the level of
+ * compatibility for bcrypt hash prefixes other than "$2b$", please refer to
+ * the comments in set_key() below and to the included crypt(3) man page.
+ */
+
+#if HAVE_CONFIG_H
+#include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;string.h&gt;
+
+#include "blowfish.h"
+#include "blowfish-internal.h"
+#include "base64.h"
+
+#include "macros.h"
+
+#define CRYPTPLEN 7
+#define SALTLEN BLOWFISH_BCRYPT_TXTSALT_SIZE
+#define HASHOFFSET (CRYPTPLEN + SALTLEN)
+
+typedef uint32_t bf_key[_BLOWFISH_ROUNDS + 2];
+
+/*
+ * Magic IV for 64 Blowfish encryptions that we do at the end.
+ * The string is "OrpheanBeholderScryDoubt" on big-endian.
+ */
+static uint32_t magic_w[6] = {
+  0x4F727068, 0x65616E42, 0x65686F6C,
+  0x64657253, 0x63727944, 0x6F756274
+};
+
+static const signed char base64_decode_table[0x80] = {
+  /* White space is HT, VT, FF, CR, LF and SPC */
+  -1, -1, -1, -1, -1, -1, -1, -1, -1, -2, -2, -2, -2, -2, -1, -1,
+  -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+  -2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  1,
+  54, 55, 56, 57, 58, 59, 60, 61, 62, 63, -1, -1, -1, -3, -1, -1,
+  -1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,
+  17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, -1, -1, -1, -1, -1,
+  -1, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42,
+  43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, -1, -1, -1, -1, -1,
+};
+
+static const char base64_encode_table[64] =
+  "./ABCDEFGHIJKLMNOPQRSTUVWXYZ"
+    "abcdefghijklmnopqrstuvwxyz"
+    "0123456789";
+
+static int encode_base64(size_t dstlen, char *dst,
+                         size_t srclen, const uint8_t *src)
+{
+  struct base64_encode_ctx ctx;
+  if (dstlen &gt; BASE64_ENCODE_LENGTH(srclen) + BASE64_ENCODE_FINAL_LENGTH)
+    return 0;
+  base64_encode_init(&amp;ctx);
+  ctx.alphabet = base64_encode_table;
+  dst += base64_encode_update(&amp;ctx, dst, srclen, src);
+  dst += base64_encode_final(&amp;ctx, dst);
+  *--dst = '\0';	    /* Strip the trailing = */
+  return 1;
+}
+
+static void swap32(uint32_t *x, int count)
+{
+#if !WORDS_BIGENDIAN
+  do {
+    uint32_t tmp = *x;
+    tmp = (tmp &lt;&lt; 16) | (tmp &gt;&gt; 16);
+    *x++ = ((tmp &amp; 0x00FF00FF) &lt;&lt; 8) | ((tmp &gt;&gt; 8) &amp; 0x00FF00FF);
+  } while (--count);
+#endif
+}
+
+static void set_xkey(const char *key, bf_key expanded, bf_key initial,
+    unsigned flags)
+{
+  const char *ptr = key;
+  unsigned bug, i, j;
+  uint32_t safety, sign, diff, tmp[2];
+
+/*
+ * There was a sign extension bug in older revisions of this function. While
+ * we would have liked to simply fix the bug and move on, we have to provide
+ * a backwards compatibility feature (essentially the bug) for some systems and
+ * a safety measure for some others. The latter is needed because for certain
+ * multiple inputs to the buggy algorithm there exist easily found inputs to
+ * the correct algorithm that produce the same hash. Thus, we optionally
+ * deviate from the correct algorithm just enough to avoid such collisions.
+ * While the bug itself affected the majority of passwords containing
+ * characters with the 8th bit set (although only a percentage of those in a
+ * collision-producing way), the anti-collision safety measure affects
+ * only a subset of passwords containing the '\xff' character (not even all of
+ * those passwords, just some of them). This character is not found in valid
+ * UTF-8 sequences and is rarely used in popular 8-bit character encodings.
+ * Thus, the safety measure is unlikely to cause much annoyance, and is a
+ * reasonable tradeoff to use when authenticating against existing hashes that
+ * are not reliably known to have been computed with the correct algorithm.
+ *
+ * We use an approach that tries to minimize side-channel leaks of password
+ * information - that is, we mostly use fixed-cost bitwise operations instead
+ * of branches or table lookups. (One conditional branch based on password
+ * length remains. It is not part of the bug aftermath, though, and is
+ * difficult and possibly unreasonable to avoid given the use of C strings by
+ * the caller, which results in similar timing leaks anyway.)
+ *
+ * For actual implementation, we set an array index in the variable "bug"
+ * (0 means no bug, 1 means sign extension bug emulation) and a flag in the
+ * variable "safety" (bit 16 is set when the safety measure is requested).
+ * Valid combinations of settings are:
+ *
+ * Prefix "$2a$": bug = 0, safety = 0x10000
+ * Prefix "$2b$": bug = 0, safety = 0
+ * Prefix "$2x$": bug = 1, safety = 0
+ * Prefix "$2y$": bug = 0, safety = 0
+ */
+  bug = (unsigned)flags &amp; 1;
+  safety = ((uint32_t)flags &amp; 2) &lt;&lt; 15;
+
+  sign = diff = 0;
+
+  for (i = 0; i &lt; _BLOWFISH_ROUNDS + 2; i++) {
+    tmp[0] = tmp[1] = 0;
+    for (j = 0; j &lt; 4; j++) {
+      tmp[0] &lt;&lt;= 8;
+      tmp[0] |= (unsigned char)*ptr; /* correct */
+      tmp[1] &lt;&lt;= 8;
+      tmp[1] |= (signed char)*ptr; /* bug */
+/*
+ * Sign extension in the first char has no effect - nothing to overwrite yet,
+ * and those extra 24 bits will be fully shifted out of the 32-bit word. For
+ * chars 2, 3, 4 in each four-char block, we set bit 7 of "sign" if sign
+ * extension in tmp[1] occurs. Once this flag is set, it remains set.
+ */
+      if (j)
+        sign |= tmp[1] &amp; 0x80;
+      if (!*ptr)
+        ptr = key;
+      else
+        ptr++;
+    }
+    diff |= tmp[0] ^ tmp[1]; /* Non-zero on any differences */
+
+    expanded[i] = tmp[bug];
+    initial[i] = _nettle_blowfish_initial_ctx.p[i] ^ tmp[bug];
+  }
+
+/*
+ * At this point, "diff" is zero iff the correct and buggy algorithms produced
+ * exactly the same result. If so and if "sign" is non-zero, which indicates
+ * that there was a non-benign sign extension, this means that we have a
+ * collision between the correctly computed hash for this password and a set of
+ * passwords that could be supplied to the buggy algorithm. Our safety measure
+ * is meant to protect from such many-buggy to one-correct collisions, by
+ * deviating from the correct algorithm in such cases. Let's check for this.
+ */
+  diff |= diff &gt;&gt; 16; /* still zero iff exact match */
+  diff &amp;= 0xffff; /* ditto */
+  diff += 0xffff; /* bit 16 set iff "diff" was non-zero (on non-match) */
+  sign &lt;&lt;= 9; /* move the non-benign sign extension flag to bit 16 */
+  sign &amp;= ~diff &amp; safety; /* action needed? */
+
+/*
+ * If we have determined that we need to deviate from the correct algorithm,
+ * flip bit 16 in initial expanded key. (The choice of 16 is arbitrary, but
+ * let's stick to it now. It came out of the approach we used above, and it's
+ * not any worse than any other choice we could make.)
+ *
+ * It is crucial that we don't do the same to the expanded key used in the main
+ * Eksblowfish loop. By doing it to only one of these two, we deviate from a
+ * state that could be directly specified by a password to the buggy algorithm
+ * (and to the fully correct one as well, but that's a side-effect).
+ */
+  initial[0] ^= sign;
+}
+
+static const unsigned char flags_by_subtype[26] =
+  {2, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
+   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 4, 0};
+
+static int ibcrypt(const char *key, const char *settings,
+  char *output, int size, uint32_t min)
+{
+  struct {
+    struct blowfish_ctx ctx;
+    bf_key expanded_key;
+    union {
+      uint32_t salt[4];
+      uint32_t output[6];
+    } binary;
+  } data;
+  uint32_t L, R;
+  uint32_t tmp1, tmp2, tmp3, tmp4;
+  uint32_t *ptr;
+  uint32_t count;
+  int i;
+
+  if (size &lt; HASHOFFSET + 31 + 1 ||
+      strlen((const char*)settings) &lt; HASHOFFSET ||
+      settings[0] != '$' ||
+      settings[1] != '2' ||
+      settings[2] &lt; 'a' || settings[2] &gt; 'z' ||
+      !flags_by_subtype[(unsigned)(unsigned char)settings[2] - 'a'] ||
+      settings[3] != '$' ||
+      settings[6] != '$')
+    return 0;
+
+  count = (settings[4] - '0') * 10 + (settings[5] - '0');
+  if (count &gt; 31)
+    return 0;
+  count = (uint32_t)1 &lt;&lt; count;
+  if (count &lt; min)
+    return 0;
+  {
+    struct base64_decode_ctx ctx;
+    size_t saltlen = BLOWFISH_BCRYPT_BINSALT_SIZE;
+
+    base64_decode_init(&amp;ctx);
+    ctx.table = base64_decode_table;
+
+    if (!base64_decode_update(&amp;ctx, &amp;saltlen, (uint8_t *) data.binary.salt,
+	                      SALTLEN, &amp;settings[CRYPTPLEN])
+     || saltlen != BLOWFISH_BCRYPT_BINSALT_SIZE)
+      return 0;
+  }
+  swap32(data.binary.salt, 4);
+
+  set_xkey(key, data.expanded_key, data.ctx.p,
+      flags_by_subtype[(unsigned)(unsigned char)settings[2] - 'a']);
+
+  memcpy(data.ctx.s, _nettle_blowfish_initial_ctx.s, sizeof(data.ctx.s));
+
+  L = R = 0;
+  for (i = 0; i &lt; _BLOWFISH_ROUNDS + 2; i += 2) {
+    L ^= data.binary.salt[i &amp; 2];
+    R ^= data.binary.salt[(i &amp; 2) + 1];
+    _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+    data.ctx.p[i] = L;
+    data.ctx.p[i + 1] = R;
+  }
+
+  ptr = data.ctx.s[0];
+  do {
+    ptr += 4;
+    L ^= data.binary.salt[(_BLOWFISH_ROUNDS + 2) &amp; 3];
+    R ^= data.binary.salt[(_BLOWFISH_ROUNDS + 3) &amp; 3];
+    _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+    *(ptr - 4) = L;
+    *(ptr - 3) = R;
+
+    L ^= data.binary.salt[(_BLOWFISH_ROUNDS + 4) &amp; 3];
+    R ^= data.binary.salt[(_BLOWFISH_ROUNDS + 5) &amp; 3];
+    _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+    *(ptr - 2) = L;
+    *(ptr - 1) = R;
+  } while (ptr &lt; &amp;data.ctx.s[3][0xFF]);
+
+  do {
+    int done;
+
+    for (i = 0; i &lt; _BLOWFISH_ROUNDS + 2; i += 2) {
+      data.ctx.p[i] ^= data.expanded_key[i];
+      data.ctx.p[i + 1] ^= data.expanded_key[i + 1];
+    }
+
+    done = 0;
+    do {
+      L = R = 0;
+      ptr = data.ctx.p;
+      do {
+        ptr += 2;
+        _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+        *(ptr - 2) = L;
+        *(ptr - 1) = R;
+      } while (ptr &lt; &amp;data.ctx.p[_BLOWFISH_ROUNDS + 2]);
+
+      ptr = data.ctx.s[0];
+      do {
+        ptr += 2;
+        _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+        *(ptr - 2) = L;
+        *(ptr - 1) = R;
+      } while (ptr &lt; &amp;data.ctx.s[3][0xFF]);
+
+      if (done)
+        break;
+      done = 1;
+
+      tmp1 = data.binary.salt[0];
+      tmp2 = data.binary.salt[1];
+      tmp3 = data.binary.salt[2];
+      tmp4 = data.binary.salt[3];
+      for (i = 0; i &lt; _BLOWFISH_ROUNDS; i += 4) {
+        data.ctx.p[i] ^= tmp1;
+        data.ctx.p[i + 1] ^= tmp2;
+        data.ctx.p[i + 2] ^= tmp3;
+        data.ctx.p[i + 3] ^= tmp4;
+      }
+      data.ctx.p[16] ^= tmp1;
+      data.ctx.p[17] ^= tmp2;
+    } while (1);
+  } while (--count);
+
+  for (i = 0; i &lt; 6; i += 2) {
+    L = magic_w[i];
+    R = magic_w[i + 1];
+
+    count = 64;
+    do {
+      _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+    } while (--count);
+
+    data.binary.output[i] = L;
+    data.binary.output[i + 1] = R;
+  }
+
+  memcpy(output, settings, HASHOFFSET - 1);
+  output[HASHOFFSET - 1] = base64_encode_table[
+    base64_decode_table[(uint8_t) settings[HASHOFFSET - 1]] &amp; 0x30];
+
+/* This has to be bug-compatible with the original implementation, so
+ * only encode 23 of the 24 bytes. :-) */
+  swap32(data.binary.output, 6);
+  encode_base64(23, output + HASHOFFSET, 23, (uint8_t *) data.binary.output);
+  return 1;
+}
+
+static
+int bcrypt_output_magic(const char *settings, char *output, int size)
+{
+  if (size &lt; 3)
+    return -1;
+
+  output[0] = '*';
+  output[1] = '0';
+  output[2] = '\0';
+
+  if (settings[0] == '*' &amp;&amp; settings[1] == '0')
+    output[1] = '1';
+
+  return 0;
+}
+
+/*
+ * Please preserve the runtime self-test. It serves two purposes at once:
+ *
+ * 1. We really can't afford the risk of producing incompatible hashes e.g.
+ * when there's something like gcc bug 26587 again, whereas an application or
+ * library integrating this code might not also integrate our external tests or
+ * it might not run them after every build. Even if it does, the miscompile
+ * might only occur on the production build, but not on a testing build (such
+ * as because of different optimization settings). It is painful to recover
+ * from incorrectly-computed hashes - merely fixing whatever broke is not
+ * enough. Thus, a proactive measure like this self-test is needed.
+ *
+ * 2. We don't want to leave sensitive data from our actual password hash
+ * computation on the stack or in registers. Previous revisions of the code
+ * would do explicit cleanups, but simply running the self-test after hash
+ * computation is more reliable.
+ *
+ * The performance cost of this quick self-test is around 0.6% at the "$2a$08"
+ * setting.
+ */
+int blowfish_bcrypt(size_t length, char *dst,
+                      const char *key, const char *settings)
+{
+  const char *test_pw = "8b \xd0\xc1\xd2\xcf\xcc\xd8";
+  const char *test_settings = "$2a$00$abcdefghijklmnopqrstuu";
+  static const char * const test_hashes[2] =
+    {"i1D709vfamulimlGcq0qq3UvuUasvEa\0\x55", /* 'a', 'b', 'y' */
+    "VUrPmXD6q/nVSSp7pNDhCR9071IfIRe\0\x55"}; /* 'x' */
+  const char *test_hash = test_hashes[0];
+  int retval;
+  int ok;
+  struct {
+    char s[HASHOFFSET + 1];
+    char o[HASHOFFSET + 31 + 1 + 1 + 1];
+  } buf;
+
+/* Hash the supplied password */
+  bcrypt_output_magic(settings, dst, length);
+  retval = ibcrypt(key, settings, dst, length, 16);
+
+/*
+ * Do a quick self-test. It is important that we make both calls to ibcrypt()
+ * from the same scope such that they likely use the same stack locations,
+ * which makes the second call overwrite the first call's sensitive data on the
+ * stack and makes it more likely that any alignment related issues would be
+ * detected by the self-test.
+ */
+  memcpy(buf.s, test_settings, sizeof(buf.s));
+  if (retval) {
+    unsigned flags = flags_by_subtype[
+        (unsigned)(unsigned char)settings[2] - 'a'];
+    test_hash = test_hashes[flags &amp; 1];
+    buf.s[2] = settings[2];
+  }
+  memset(buf.o, 0x55, sizeof(buf.o));
+  buf.o[sizeof(buf.o) - 1] = 0;
+  ok = ibcrypt(test_pw, buf.s, buf.o, sizeof(buf.o) - (1 + 1), 1);
+
+  ok = (ok &amp;&amp;
+      !memcmp(buf.o, buf.s, HASHOFFSET) &amp;&amp;
+      !memcmp(buf.o + HASHOFFSET, test_hash, 31 + 1 + 1 + 1));
+
+  {
+    const char *k = "\xff\xa3" "34" "\xff\xff\xff\xa3" "345";
+    bf_key ae, ai, ye, yi;
+    set_xkey(k, ae, ai, 2); /* $2a$ */
+    set_xkey(k, ye, yi, 4); /* $2y$ */
+    ai[0] ^= 0x10000; /* undo the safety (for comparison) */
+    ok = ok &amp;&amp; ai[0] == 0xdb9c59bc &amp;&amp; ye[17] == 0x33343500 &amp;&amp;
+        !memcmp(ae, ye, sizeof(ae)) &amp;&amp;
+        !memcmp(ai, yi, sizeof(ai));
+  }
+
+  if (ok)
+    return retval;
+
+/* Should not happen */
+  bcrypt_output_magic(settings, dst, length);
+  return 0;
+}
+
+int blowfish_salt_base64(size_t length, char *dst, const uint8_t *salt)
+{ return encode_base64(length, dst, BLOWFISH_BCRYPT_BINSALT_SIZE, salt);
+}
+
diff --git a/blowfish.h b/blowfish-internal.h
similarity index 50%
copy from blowfish.h
copy to blowfish-internal.h
index bcdc7cb6..da28fa34 100644
--- a/blowfish.h
+++ b/blowfish-internal.h
@@ -1,4 +1,4 @@
-/* blowfish.h
+/* blowfish-internal.h
 
    Blowfish block cipher.
 
@@ -32,8 +32,8 @@
    not, see http://www.gnu.org/licenses/.
 */
  
-#ifndef NETTLE_BLOWFISH_H_INCLUDED
-#define NETTLE_BLOWFISH_H_INCLUDED
+#ifndef NETTLE_BLOWFISH_INTERNAL_H_INCLUDED
+#define NETTLE_BLOWFISH_INTERNAL_H_INCLUDED
 
 #include "nettle-types.h"
 
@@ -41,49 +41,12 @@
 extern "C" {
 #endif
 
-/* Name mangling */
-#define blowfish_set_key nettle_blowfish_set_key
-#define blowfish128_set_key nettle_blowfish128_set_key
-#define blowfish_encrypt nettle_blowfish_encrypt
-#define blowfish_decrypt nettle_blowfish_decrypt
-
-#define BLOWFISH_BLOCK_SIZE 8
-
-/* Variable key size between 64 and 448 bits. */
-#define BLOWFISH_MIN_KEY_SIZE 8
-#define BLOWFISH_MAX_KEY_SIZE 56
-
-/* Default to 128 bits */
-#define BLOWFISH_KEY_SIZE 16
-
-#define BLOWFISH128_KEY_SIZE 16
-
-#define _BLOWFISH_ROUNDS 16
-
-struct blowfish_ctx
-{
-  uint32_t s[4][256];
-  uint32_t p[_BLOWFISH_ROUNDS+2];
-};
-
-/* Returns 0 for weak keys, otherwise 1. */
-int
-blowfish_set_key(struct blowfish_ctx *ctx,
-                 size_t length, const uint8_t *key);
-int
-blowfish128_set_key(struct blowfish_ctx *ctx, const uint8_t *key);
-
-void
-blowfish_encrypt(const struct blowfish_ctx *ctx,
-                 size_t length, uint8_t *dst,
-                 const uint8_t *src);
-void
-blowfish_decrypt(const struct blowfish_ctx *ctx,
-                 size_t length, uint8_t *dst,
-                 const uint8_t *src);
+extern const struct blowfish_ctx _nettle_blowfish_initial_ctx;
+extern void _nettle_blowfish_encround (const struct blowfish_ctx *ctx,
+                                       uint32_t * ret_xl, uint32_t * ret_xr);
 
 #ifdef __cplusplus
 }
 #endif
 
-#endif /* NETTLE_BLOWFISH_H_INCLUDED */
+#endif /* NETTLE_BLOWFISH_INTERNAL_H_INCLUDED */
diff --git a/blowfish.c b/blowfish.c
index 52040f13..e73caffe 100644
--- a/blowfish.c
+++ b/blowfish.c
@@ -54,12 +54,13 @@
 #include &lt;assert.h&gt;
 
 #include "blowfish.h"
+#include "blowfish-internal.h"
 
 #include "macros.h"
 
 /* precomputed S boxes */
-static const struct blowfish_ctx
-initial_ctx = {
+const struct blowfish_ctx
+_nettle_blowfish_initial_ctx = {
   {
     { /* ks0 */
       0xD1310BA6, 0x98DFB5AC, 0x2FFD72DB, 0xD01ADFB7, 0xB8E1AFED, 0x6A267E96,
@@ -261,8 +262,8 @@ initial_ctx = {
 
 #define R(c, l,r,i)  do { l ^= c-&gt;p[i]; r ^= F(c,l); } while(0)
 
-static void
-encrypt (const struct blowfish_ctx *ctx, uint32_t * ret_xl,
+void
+_nettle_blowfish_encround (const struct blowfish_ctx *ctx, uint32_t * ret_xl,
 	    uint32_t * ret_xr)
 {
   uint32_t xl, xr;
@@ -295,7 +296,7 @@ encrypt (const struct blowfish_ctx *ctx, uint32_t * ret_xl,
 }
 
 static void
-decrypt (const struct blowfish_ctx *ctx, uint32_t * ret_xl, uint32_t * ret_xr)
+decround (const struct blowfish_ctx *ctx, uint32_t * ret_xl, uint32_t * ret_xr)
 {
   uint32_t xl, xr;
 
@@ -339,7 +340,7 @@ blowfish_encrypt (const struct blowfish_ctx *ctx,
 
       d1 = READ_UINT32(src);
       d2 = READ_UINT32(src+4);
-      encrypt (ctx, &amp;d1, &amp;d2);
+      _nettle_blowfish_encround (ctx, &amp;d1, &amp;d2);
       dst[0] = (d1 &gt;&gt; 24) &amp; 0xff;
       dst[1] = (d1 &gt;&gt; 16) &amp; 0xff;
       dst[2] = (d1 &gt;&gt; 8) &amp; 0xff;
@@ -361,7 +362,7 @@ blowfish_decrypt (const struct blowfish_ctx *ctx,
 
       d1 = READ_UINT32(src);
       d2 = READ_UINT32(src+4);
-      decrypt (ctx, &amp;d1, &amp;d2);
+      decround (ctx, &amp;d1, &amp;d2);
       dst[0] = (d1 &gt;&gt; 24) &amp; 0xff;
       dst[1] = (d1 &gt;&gt; 16) &amp; 0xff;
       dst[2] = (d1 &gt;&gt; 8) &amp; 0xff;
@@ -380,7 +381,7 @@ blowfish_set_key (struct blowfish_ctx *ctx,
   int i, j;
   uint32_t data, datal, datar;
 
-  *ctx = initial_ctx;
+  *ctx = _nettle_blowfish_initial_ctx;
 
   for (i = j = 0; i &lt; _BLOWFISH_ROUNDS + 2; i++)
     {
@@ -393,15 +394,15 @@ blowfish_set_key (struct blowfish_ctx *ctx,
   datal = datar = 0;
   for (i = 0; i &lt; _BLOWFISH_ROUNDS + 2; i += 2)
     {
-      encrypt (ctx, &amp;datal, &amp;datar);
+      _nettle_blowfish_encround (ctx, &amp;datal, &amp;datar);
       ctx-&gt;p[i] = datal;
       ctx-&gt;p[i + 1] = datar;
     }
-  
+
   for (j = 0; j &lt; 4; j++)
     for (i = 0; i &lt; 256; i += 2)
       {
-	encrypt (ctx, &amp;datal, &amp;datar);
+	_nettle_blowfish_encround (ctx, &amp;datal, &amp;datar);
 	ctx-&gt;s[j][i] = datal;
 	ctx-&gt;s[j][i + 1] = datar;
     }
diff --git a/blowfish.h b/blowfish.h
index bcdc7cb6..a4473266 100644
--- a/blowfish.h
+++ b/blowfish.h
@@ -46,6 +46,8 @@ extern "C" {
 #define blowfish128_set_key nettle_blowfish128_set_key
 #define blowfish_encrypt nettle_blowfish_encrypt
 #define blowfish_decrypt nettle_blowfish_decrypt
+#define blowfish_bcrypt nettle_blowfish_bcrypt
+#define blowfish_salt_base64 nettle_blowfish_salt_base64
 
 #define BLOWFISH_BLOCK_SIZE 8
 
@@ -60,6 +62,10 @@ extern "C" {
 
 #define _BLOWFISH_ROUNDS 16
 
+#define BLOWFISH_BCRYPT_HASH_SIZE (60 + 1) /* Including null-terminator */
+#define BLOWFISH_BCRYPT_BINSALT_SIZE 16    /* Binary string size */
+#define BLOWFISH_BCRYPT_TXTSALT_SIZE ((BLOWFISH_BCRYPT_BINSALT_SIZE*8+5) / 6)
+
 struct blowfish_ctx
 {
   uint32_t s[4][256];
@@ -81,6 +87,15 @@ void
 blowfish_decrypt(const struct blowfish_ctx *ctx,
                  size_t length, uint8_t *dst,
                  const uint8_t *src);
+int
+blowfish_bcrypt(size_t length,
+                char *dst,
+                const char *key,
+                const char *settings);
+int
+blowfish_salt_base64(size_t length,
+                     char *dst,
+                     const uint8_t *salt);
 
 #ifdef __cplusplus
 }
diff --git a/nettle.texinfo b/nettle.texinfo
index ff64889c..b6b6fc16 100644
--- a/nettle.texinfo
+++ b/nettle.texinfo
@@ -1512,6 +1512,75 @@ in any other way.
 Analogous to @code{blowfish_encrypt}
 @end deftypefun
 
+@deftypefun int blowfish_bcrypt (size_t @var{length}, char *@var{dst}, const char \
*@var{key}, const char *@var{settings}) +Compute bcrypt password hash.  The same \
function is used for both +generating and verifying an existing hash.
+The function will return @code{0} if the hash cannot be computed
+due to invalid input.
+The function will return @code{1} and store the computed hash
+in the array pointed to by @var{dst}.  The hash is computed based
+on the chosen algorithm, number of rounds and specified salt.
+@var{dst} must
+point to a character array of the specified 'length'.
+@var{length} must be at least @code{BLOWFISH_BCRYPT_HASH_SIZE}.
+
+Sample code to generate a bcrypt hash:
+@example
+char cleartxtpassword[] = "ExamplePassword";
+char hashsettings[BLOWFISH_BCRYPT_HASH_SIZE] =
+           "$2y$"  /* Hash algorithm version */
+           "10"   /* 2^10 hash rounds (strength) */
+           "$";  /* separator */
+uint8_t salt[BLOWFISH_BCRYPT_BINSALT_SIZE];
+@dots{}
+/* Make sure that salt is filled with random bytes */
+@dots{}
+char salt64[BLOWFISH_BCRYPT_TXTSALT_SIZE];
+blowfish_salt_base64(sizeof(salt64), salt64, salt);
+strcat(hashsettings, salt64);
+char hashedresult[BLOWFISH_BCRYPT_HASH_SIZE];
+int result = blowfish_bcrypt(sizeof(hashedresult), hashedresult,
+                               cleartxtpassword, hashsettings);
+if (result)
+  printf("%s\n", hashedresult);
+@end example
+
+Sample code to verify a bcrypt hash:
+@example
+char cleartxtpassword[] = "ExamplePassword";
+char existinghashed[] =
+           "$2y$"  /* Hash algorithm version */
+           "10"   /* 2^10 hash rounds (strength) */
+           "$"   /* separator */
+           "1b2lPgo4XumibnJGN3r3sO" /* base64 encoded 16-byte salt */
+           "u7wE7xNfYDKlAxZffJDCJdVfFTAyevu"; /* Hashedpart */
+char hashedresult[BLOWFISH_BCRYPT_HASH_SIZE];
+int result = blowfish_bcrypt(sizeof(hashedresult), hashedresult,
+                               cleartxtpassword, existinghashed);
+if (result &amp;&amp; !strcmp(hashedresult, existinghashed))
+  printf("Password is correct.");
+else
+  printf("Password is incorrect.");
+@end example
+@end deftypefun
+
+@deftypefun int blowfish_salt_base64 (size_t @var{length}, char *@var{dst}, const \
uint8_t *@var{salt}) +Encodes the supplied 16-byte binary salt into the base64 \
encoding that +is needed in bcrypt-password fields.
+
+Note that the used base64 encoding differs from the standard Nettle base64
+encoding.
+
+The function returns @code{1} if the encoding was successful (if there
+was enough room to store it), and it returns @code{0} if the amount of
+room was insufficient.
+
+@var{dst} must point to a character array of at least @var{length} bytes.
+@var{length} should at least be equal to @code{BLOWFISH_BCRYPT_HASH_SIZE}.
+@var{salt} must point to a byte array filled with
+ @code{BLOWFISH_BCRYPT_BINSALT_SIZE} random salt bytes.
+@end deftypefun
+
 @subsection Camellia
 @cindex Camellia
 
-- 
2.20.1


[Attachment #3 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200321103822</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-03-21 10:38:22-0400</timestampReceived><subject>[PATCH] (revision 2.1) Added bcrypt() support.</subject><body>

---
 Makefile.in                       |   2 +-
 base64-decode.c                   |  17 +-
 blowfish-bcrypt.c                 | 498 ++++++++++++++++++++++++++++++
 blowfish.h =&gt; blowfish-internal.h |  51 +--
 blowfish.c                        |  23 +-
 blowfish.h                        |  15 +
 nettle.texinfo                    |  69 +++++
 7 files changed, 609 insertions(+), 66 deletions(-)
 create mode 100644 blowfish-bcrypt.c
 copy blowfish.h =&gt; blowfish-internal.h (50%)

diff --git a/Makefile.in b/Makefile.in
index ddc30428..bfb7ac57 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -73,7 +73,7 @@ nettle_SOURCES = aes-decrypt-internal.c aes-decrypt.c \
 		 aes256-set-encrypt-key.c aes256-set-decrypt-key.c \
 		 aes256-meta.c \
 		 arcfour.c arcfour-crypt.c \
-		 arctwo.c arctwo-meta.c blowfish.c \
+		 arctwo.c arctwo-meta.c blowfish.c blowfish-bcrypt.c \
 		 base16-encode.c base16-decode.c base16-meta.c \
 		 base64-encode.c base64-decode.c base64-meta.c \
 		 base64url-encode.c base64url-decode.c base64url-meta.c \
diff --git a/base64-decode.c b/base64-decode.c
index b993117a..9273224a 100644
--- a/base64-decode.c
+++ b/base64-decode.c
@@ -45,7 +45,7 @@
 void
 base64_decode_init(struct base64_decode_ctx *ctx)
 {
-  static const signed char base64_decode_table[0x100] =
+  static const signed char base64_decode_table[0x80] =
     {
       /* White space is HT, VT, FF, CR, LF and SPC */
       -1, -1, -1, -1, -1, -1, -1, -1, -1, -2, -2, -2, -2, -2, -1, -1, 
@@ -56,14 +56,6 @@ base64_decode_init(struct base64_decode_ctx *ctx)
       15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, -1, -1, -1, -1, -1,
       -1, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,
       41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
-      -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
     };
 
   ctx-&gt;word = ctx-&gt;bits = ctx-&gt;padding = 0;
@@ -75,7 +67,12 @@ base64_decode_single(struct base64_decode_ctx *ctx,
 		     uint8_t *dst,
 		     char src)
 {
-  int data = ctx-&gt;table[(uint8_t) src];
+  int data;
+
+  if ((uint8_t) src &gt; 0x7f)
+    return -1;
+
+  data = ctx-&gt;table[(uint8_t) src];
 
   switch(data)
     {
diff --git a/blowfish-bcrypt.c b/blowfish-bcrypt.c
new file mode 100644
index 00000000..65dedca9
--- /dev/null
+++ b/blowfish-bcrypt.c
@@ -0,0 +1,498 @@
+/* blowfish-bcrypt.c
+
+   The blowfish bcrypt implementation.
+
+   Copyright (c) 2020 Stephen R. van den Berg
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+#include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;string.h&gt;
+
+#include "blowfish.h"
+#include "blowfish-internal.h"
+#include "base64.h"
+
+#include "macros.h"
+
+#define CRYPTPLEN 7
+#define SALTLEN BLOWFISH_BCRYPT_TXTSALT_SIZE
+#define HASHOFFSET (CRYPTPLEN + SALTLEN)
+
+static const signed char base64_decode_table[0x80] = {
+  /* White space is HT, VT, FF, CR, LF and SPC */
+  -1, -1, -1, -1, -1, -1, -1, -1, -1, -2, -2, -2, -2, -2, -1, -1,
+  -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
+  -2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  1,
+  54, 55, 56, 57, 58, 59, 60, 61, 62, 63, -1, -1, -1, -3, -1, -1,
+  -1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,
+  17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, -1, -1, -1, -1, -1,
+  -1, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42,
+  43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, -1, -1, -1, -1, -1,
+};
+
+static const char base64_encode_table[64] =
+  "./ABCDEFGHIJKLMNOPQRSTUVWXYZ"
+    "abcdefghijklmnopqrstuvwxyz"
+    "0123456789";
+
+static int encode_base64(size_t dstlen, char *dst,
+                         size_t srclen, const uint8_t *src)
+{
+  struct base64_encode_ctx ctx;
+  if (dstlen &gt; BASE64_ENCODE_LENGTH(srclen) + BASE64_ENCODE_FINAL_LENGTH)
+    return 0;
+  base64_encode_init(&amp;ctx);
+  ctx.alphabet = base64_encode_table;
+  dst += base64_encode_update(&amp;ctx, dst, srclen, src);
+  dst += base64_encode_final(&amp;ctx, dst);
+  *--dst = '\0';	    /* Strip the trailing = */
+  return 1;
+}
+
+int blowfish_salt_base64(size_t length, char *dst, const uint8_t *salt)
+{ return encode_base64(length, dst, BLOWFISH_BCRYPT_BINSALT_SIZE, salt);
+}
+
+/*
+ * Large parts of the code below are based on public domain sources.
+ * The comments and copyright notices have been preserved.
+ * Any code added or modified by me is licensed under the
+ * licenses listed above.  --  Stephen R. van den Berg
+ */
+
+/*
+ * This code comes from John the Ripper password cracker, with reentrant
+ * and crypt(3) interfaces added, but optimizations specific to password
+ * cracking removed.
+ *
+ * Written by Solar Designer &lt;solar at openwall.com&gt; in 1998-2015.
+ * No copyright is claimed, and the software is hereby placed in the public
+ * domain. In case this attempt to disclaim copyright and place the software
+ * in the public domain is deemed null and void, then the software is
+ * Copyright (c) 1998-2015 Solar Designer and it is hereby released to the
+ * general public under the following terms:
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted.
+ *
+ * There's ABSOLUTELY NO WARRANTY, express or implied.
+ *
+ * It is my intent that you should be able to use this on your system,
+ * as part of a software package, or anywhere else to improve security,
+ * ensure compatibility, or for any other purpose. I would appreciate
+ * it if you give credit where it is due and keep your modifications in
+ * the public domain as well, but I don't require that in order to let
+ * you place this code and any modifications you make under a license
+ * of your choice.
+ *
+ * This implementation is fully compatible with OpenBSD's bcrypt.c for prefix
+ * "$2b$", originally by Niels Provos &lt;provos at citi.umich.edu&gt;, and it uses
+ * some of his ideas. The password hashing algorithm was designed by David
+ * Mazieres &lt;dm at lcs.mit.edu&gt;. For information on the level of
+ * compatibility for bcrypt hash prefixes other than "$2b$", please refer to
+ * the comments in set_key() below and to the included crypt(3) man page.
+ */
+
+typedef uint32_t bf_key[_BLOWFISH_ROUNDS + 2];
+
+/*
+ * Magic IV for 64 Blowfish encryptions that we do at the end.
+ * The string is "OrpheanBeholderScryDoubt" on big-endian.
+ */
+static uint32_t magic_w[6] = {
+  0x4F727068, 0x65616E42, 0x65686F6C,
+  0x64657253, 0x63727944, 0x6F756274
+};
+
+static void swap32(uint32_t *x, int count)
+{
+#if !WORDS_BIGENDIAN
+  do {
+    uint32_t tmp = *x;
+    tmp = (tmp &lt;&lt; 16) | (tmp &gt;&gt; 16);
+    *x++ = ((tmp &amp; 0x00FF00FF) &lt;&lt; 8) | ((tmp &gt;&gt; 8) &amp; 0x00FF00FF);
+  } while (--count);
+#endif
+}
+
+static void set_xkey(const char *key, bf_key expanded, bf_key initial,
+    unsigned flags)
+{
+  const char *ptr = key;
+  unsigned bug, i, j;
+  uint32_t safety, sign, diff, tmp[2];
+
+/*
+ * There was a sign extension bug in older revisions of this function. While
+ * we would have liked to simply fix the bug and move on, we have to provide
+ * a backwards compatibility feature (essentially the bug) for some systems and
+ * a safety measure for some others. The latter is needed because for certain
+ * multiple inputs to the buggy algorithm there exist easily found inputs to
+ * the correct algorithm that produce the same hash. Thus, we optionally
+ * deviate from the correct algorithm just enough to avoid such collisions.
+ * While the bug itself affected the majority of passwords containing
+ * characters with the 8th bit set (although only a percentage of those in a
+ * collision-producing way), the anti-collision safety measure affects
+ * only a subset of passwords containing the '\xff' character (not even all of
+ * those passwords, just some of them). This character is not found in valid
+ * UTF-8 sequences and is rarely used in popular 8-bit character encodings.
+ * Thus, the safety measure is unlikely to cause much annoyance, and is a
+ * reasonable tradeoff to use when authenticating against existing hashes that
+ * are not reliably known to have been computed with the correct algorithm.
+ *
+ * We use an approach that tries to minimize side-channel leaks of password
+ * information - that is, we mostly use fixed-cost bitwise operations instead
+ * of branches or table lookups. (One conditional branch based on password
+ * length remains. It is not part of the bug aftermath, though, and is
+ * difficult and possibly unreasonable to avoid given the use of C strings by
+ * the caller, which results in similar timing leaks anyway.)
+ *
+ * For actual implementation, we set an array index in the variable "bug"
+ * (0 means no bug, 1 means sign extension bug emulation) and a flag in the
+ * variable "safety" (bit 16 is set when the safety measure is requested).
+ * Valid combinations of settings are:
+ *
+ * Prefix "$2a$": bug = 0, safety = 0x10000
+ * Prefix "$2b$": bug = 0, safety = 0
+ * Prefix "$2x$": bug = 1, safety = 0
+ * Prefix "$2y$": bug = 0, safety = 0
+ */
+  bug = (unsigned)flags &amp; 1;
+  safety = ((uint32_t)flags &amp; 2) &lt;&lt; 15;
+
+  sign = diff = 0;
+
+  for (i = 0; i &lt; _BLOWFISH_ROUNDS + 2; i++) {
+    tmp[0] = tmp[1] = 0;
+    for (j = 0; j &lt; 4; j++) {
+      tmp[0] &lt;&lt;= 8;
+      tmp[0] |= (unsigned char)*ptr; /* correct */
+      tmp[1] &lt;&lt;= 8;
+      tmp[1] |= (signed char)*ptr; /* bug */
+/*
+ * Sign extension in the first char has no effect - nothing to overwrite yet,
+ * and those extra 24 bits will be fully shifted out of the 32-bit word. For
+ * chars 2, 3, 4 in each four-char block, we set bit 7 of "sign" if sign
+ * extension in tmp[1] occurs. Once this flag is set, it remains set.
+ */
+      if (j)
+        sign |= tmp[1] &amp; 0x80;
+      if (!*ptr)
+        ptr = key;
+      else
+        ptr++;
+    }
+    diff |= tmp[0] ^ tmp[1]; /* Non-zero on any differences */
+
+    expanded[i] = tmp[bug];
+    initial[i] = _nettle_blowfish_initial_ctx.p[i] ^ tmp[bug];
+  }
+
+/*
+ * At this point, "diff" is zero if the correct and buggy algorithms produced
+ * exactly the same result. If so and if "sign" is non-zero, which indicates
+ * that there was a non-benign sign extension, this means that we have a
+ * collision between the correctly computed hash for this password and a set of
+ * passwords that could be supplied to the buggy algorithm. Our safety measure
+ * is meant to protect from such many-buggy to one-correct collisions, by
+ * deviating from the correct algorithm in such cases. Let's check for this.
+ */
+  diff |= diff &gt;&gt; 16; /* still zero if exact match */
+  diff &amp;= 0xffff; /* ditto */
+  diff += 0xffff; /* bit 16 set if "diff" was non-zero (on non-match) */
+  sign &lt;&lt;= 9; /* move the non-benign sign extension flag to bit 16 */
+  sign &amp;= ~diff &amp; safety; /* action needed? */
+
+/*
+ * If we have determined that we need to deviate from the correct algorithm,
+ * flip bit 16 in initial expanded key. (The choice of 16 is arbitrary, but
+ * let's stick to it now. It came out of the approach we used above, and it's
+ * not any worse than any other choice we could make.)
+ *
+ * It is crucial that we don't do the same to the expanded key used in the main
+ * Eksblowfish loop. By doing it to only one of these two, we deviate from a
+ * state that could be directly specified by a password to the buggy algorithm
+ * (and to the fully correct one as well, but that's a side-effect).
+ */
+  initial[0] ^= sign;
+}
+
+static const unsigned char flags_by_subtype[26] =
+  {2, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
+   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 4, 0};
+
+static int ibcrypt(const char *key, const char *settings,
+  char *output, int size, uint32_t min)
+{
+  struct {
+    struct blowfish_ctx ctx;
+    bf_key expanded_key;
+    union {
+      uint32_t salt[4];
+      uint32_t output[6];
+    } binary;
+  } data;
+  uint32_t L, R;
+  uint32_t *ptr;
+  uint32_t count;
+  int i;
+
+  if (size &lt; HASHOFFSET + 31 + 1 ||
+      strlen((const char*)settings) &lt; HASHOFFSET ||
+      settings[0] != '$' ||
+      settings[1] != '2' ||
+      settings[2] &lt; 'a' || settings[2] &gt; 'z' ||
+      !flags_by_subtype[(unsigned)(unsigned char)settings[2] - 'a'] ||
+      settings[3] != '$' ||
+      settings[6] != '$')
+    return 0;
+
+  count = (settings[4] - '0') * 10 + (settings[5] - '0');
+  if (count &gt; 31)
+    return 0;
+  count = (uint32_t)1 &lt;&lt; count;
+  if (count &lt; min)
+    return 0;
+  {
+    struct base64_decode_ctx ctx;
+    size_t saltlen = BLOWFISH_BCRYPT_BINSALT_SIZE;
+
+    base64_decode_init(&amp;ctx);
+    ctx.table = base64_decode_table;
+
+    if (!base64_decode_update(&amp;ctx, &amp;saltlen, (uint8_t *) data.binary.salt,
+	                      SALTLEN, &amp;settings[CRYPTPLEN])
+     || saltlen != BLOWFISH_BCRYPT_BINSALT_SIZE)
+      return 0;
+  }
+  swap32(data.binary.salt, 4);
+
+  set_xkey(key, data.expanded_key, data.ctx.p,
+      flags_by_subtype[(unsigned)(unsigned char)settings[2] - 'a']);
+
+  memcpy(data.ctx.s, _nettle_blowfish_initial_ctx.s, sizeof(data.ctx.s));
+
+  L = R = 0;
+  for (i = 0; i &lt; _BLOWFISH_ROUNDS + 2; i += 2) {
+    L ^= data.binary.salt[i &amp; 2];
+    R ^= data.binary.salt[(i &amp; 2) + 1];
+    _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+    data.ctx.p[i] = L;
+    data.ctx.p[i + 1] = R;
+  }
+
+  ptr = data.ctx.s[0];
+  do {
+    ptr += 4;
+    L ^= data.binary.salt[(_BLOWFISH_ROUNDS + 2) &amp; 3];
+    R ^= data.binary.salt[(_BLOWFISH_ROUNDS + 3) &amp; 3];
+    _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+    *(ptr - 4) = L;
+    *(ptr - 3) = R;
+
+    L ^= data.binary.salt[(_BLOWFISH_ROUNDS + 4) &amp; 3];
+    R ^= data.binary.salt[(_BLOWFISH_ROUNDS + 5) &amp; 3];
+    _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+    *(ptr - 2) = L;
+    *(ptr - 1) = R;
+  } while (ptr &lt; &amp;data.ctx.s[3][0xFF]);
+
+  do {
+    int done;
+
+    for (i = 0; i &lt; _BLOWFISH_ROUNDS + 2; i += 2) {
+      data.ctx.p[i] ^= data.expanded_key[i];
+      data.ctx.p[i + 1] ^= data.expanded_key[i + 1];
+    }
+
+    done = 0;
+    do {
+      uint32_t tmp1, tmp2, tmp3, tmp4;
+
+      L = R = 0;
+      ptr = data.ctx.p;
+      do {
+        ptr += 2;
+        _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+        *(ptr - 2) = L;
+        *(ptr - 1) = R;
+      } while (ptr &lt; &amp;data.ctx.p[_BLOWFISH_ROUNDS + 2]);
+
+      ptr = data.ctx.s[0];
+      do {
+        ptr += 2;
+        _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+        *(ptr - 2) = L;
+        *(ptr - 1) = R;
+      } while (ptr &lt; &amp;data.ctx.s[3][0xFF]);
+
+      if (done)
+        break;
+      done = 1;
+
+      tmp1 = data.binary.salt[0];
+      tmp2 = data.binary.salt[1];
+      tmp3 = data.binary.salt[2];
+      tmp4 = data.binary.salt[3];
+      for (i = 0; i &lt; _BLOWFISH_ROUNDS; i += 4) {
+        data.ctx.p[i] ^= tmp1;
+        data.ctx.p[i + 1] ^= tmp2;
+        data.ctx.p[i + 2] ^= tmp3;
+        data.ctx.p[i + 3] ^= tmp4;
+      }
+      data.ctx.p[16] ^= tmp1;
+      data.ctx.p[17] ^= tmp2;
+    } while (1);
+  } while (--count);
+
+  for (i = 0; i &lt; 6; i += 2) {
+    L = magic_w[i];
+    R = magic_w[i + 1];
+
+    count = 64;
+    do
+      _nettle_blowfish_encround(&amp;data.ctx, &amp;L, &amp;R);
+    while (--count);
+
+    data.binary.output[i] = L;
+    data.binary.output[i + 1] = R;
+  }
+
+  memcpy(output, settings, HASHOFFSET - 1);
+  output[HASHOFFSET - 1] = base64_encode_table[
+    base64_decode_table[(uint8_t) settings[HASHOFFSET - 1]] &amp; 0x30];
+
+  swap32(data.binary.output, 6);
+/* This has to be bug-compatible with the original implementation, so
+   only encode 23 of the 24 bytes. */
+  encode_base64(BLOWFISH_BCRYPT_HASH_SIZE - HASHOFFSET, output + HASHOFFSET,
+                23, (uint8_t *) data.binary.output);
+  return 1;
+}
+
+static
+int bcrypt_output_magic(const char *settings, char *output, int size)
+{
+  if (size &lt; 3)
+    return -1;
+
+  output[0] = '*';
+  output[1] = '0';
+  output[2] = '\0';
+
+  if (settings[0] == '*' &amp;&amp; settings[1] == '0')
+    output[1] = '1';
+
+  return 0;
+}
+
+/*
+ * Please preserve the runtime self-test. It serves two purposes at once:
+ *
+ * 1. We really can't afford the risk of producing incompatible hashes e.g.
+ * when there's something like gcc bug 26587 again, whereas an application or
+ * library integrating this code might not also integrate our external tests or
+ * it might not run them after every build. Even if it does, the miscompile
+ * might only occur on the production build, but not on a testing build (such
+ * as because of different optimization settings). It is painful to recover
+ * from incorrectly-computed hashes - merely fixing whatever broke is not
+ * enough. Thus, a proactive measure like this self-test is needed.
+ *
+ * 2. We don't want to leave sensitive data from our actual password hash
+ * computation on the stack or in registers. Previous revisions of the code
+ * would do explicit cleanups, but simply running the self-test after hash
+ * computation is more reliable.
+ *
+ * The performance cost of this quick self-test is around 0.6% at the "$2a$08"
+ * setting.
+ */
+int blowfish_bcrypt(size_t length, char *dst,
+                      const char *key, const char *settings)
+{
+  const char *test_pw = "8b \xd0\xc1\xd2\xcf\xcc\xd8";
+  const char *test_settings = "$2a$00$abcdefghijklmnopqrstuu";
+  static const char * const test_hashes[2] =
+    {"i1D709vfamulimlGcq0qq3UvuUasvEa\0\x55", /* 'a', 'b', 'y' */
+    "VUrPmXD6q/nVSSp7pNDhCR9071IfIRe\0\x55"}; /* 'x' */
+  const char *test_hash = test_hashes[0];
+  int retval;
+  int ok;
+  struct {
+    char s[HASHOFFSET + 1];
+    char o[HASHOFFSET + 31 + 1 + 1 + 1];
+  } buf;
+
+/* Hash the supplied password */
+  bcrypt_output_magic(settings, dst, length);
+  retval = ibcrypt(key, settings, dst, length, 16);
+
+/*
+ * Do a quick self-test. It is important that we make both calls to ibcrypt()
+ * from the same scope such that they likely use the same stack locations,
+ * which makes the second call overwrite the first call's sensitive data on the
+ * stack and makes it more likely that any alignment related issues would be
+ * detected by the self-test.
+ */
+  memcpy(buf.s, test_settings, sizeof(buf.s));
+  if (retval) {
+    unsigned flags = flags_by_subtype[
+        (unsigned)(unsigned char)settings[2] - 'a'];
+    test_hash = test_hashes[flags &amp; 1];
+    buf.s[2] = settings[2];
+  }
+  memset(buf.o, 0x55, sizeof(buf.o));
+  buf.o[sizeof(buf.o) - 1] = 0;
+  ok = ibcrypt(test_pw, buf.s, buf.o, sizeof(buf.o) - (1 + 1), 1);
+
+  ok = (ok &amp;&amp;
+      !memcmp(buf.o, buf.s, HASHOFFSET) &amp;&amp;
+      !memcmp(buf.o + HASHOFFSET, test_hash, 31 + 1 + 1 + 1));
+
+  {
+    const char *k = "\xff\xa3" "34" "\xff\xff\xff\xa3" "345";
+    bf_key ae, ai, ye, yi;
+    set_xkey(k, ae, ai, 2); /* $2a$ */
+    set_xkey(k, ye, yi, 4); /* $2y$ */
+    ai[0] ^= 0x10000; /* undo the safety (for comparison) */
+    ok = ok &amp;&amp; ai[0] == 0xdb9c59bc &amp;&amp; ye[17] == 0x33343500 &amp;&amp;
+        !memcmp(ae, ye, sizeof(ae)) &amp;&amp;
+        !memcmp(ai, yi, sizeof(ai));
+  }
+
+  if (ok)
+    return retval;
+
+/* Should not happen */
+  bcrypt_output_magic(settings, dst, length);
+  return 0;
+}
diff --git a/blowfish.h b/blowfish-internal.h
similarity index 50%
copy from blowfish.h
copy to blowfish-internal.h
index bcdc7cb6..da28fa34 100644
--- a/blowfish.h
+++ b/blowfish-internal.h
@@ -1,4 +1,4 @@
-/* blowfish.h
+/* blowfish-internal.h
 
    Blowfish block cipher.
 
@@ -32,8 +32,8 @@
    not, see http://www.gnu.org/licenses/.
 */
  
-#ifndef NETTLE_BLOWFISH_H_INCLUDED
-#define NETTLE_BLOWFISH_H_INCLUDED
+#ifndef NETTLE_BLOWFISH_INTERNAL_H_INCLUDED
+#define NETTLE_BLOWFISH_INTERNAL_H_INCLUDED
 
 #include "nettle-types.h"
 
@@ -41,49 +41,12 @@
 extern "C" {
 #endif
 
-/* Name mangling */
-#define blowfish_set_key nettle_blowfish_set_key
-#define blowfish128_set_key nettle_blowfish128_set_key
-#define blowfish_encrypt nettle_blowfish_encrypt
-#define blowfish_decrypt nettle_blowfish_decrypt
-
-#define BLOWFISH_BLOCK_SIZE 8
-
-/* Variable key size between 64 and 448 bits. */
-#define BLOWFISH_MIN_KEY_SIZE 8
-#define BLOWFISH_MAX_KEY_SIZE 56
-
-/* Default to 128 bits */
-#define BLOWFISH_KEY_SIZE 16
-
-#define BLOWFISH128_KEY_SIZE 16
-
-#define _BLOWFISH_ROUNDS 16
-
-struct blowfish_ctx
-{
-  uint32_t s[4][256];
-  uint32_t p[_BLOWFISH_ROUNDS+2];
-};
-
-/* Returns 0 for weak keys, otherwise 1. */
-int
-blowfish_set_key(struct blowfish_ctx *ctx,
-                 size_t length, const uint8_t *key);
-int
-blowfish128_set_key(struct blowfish_ctx *ctx, const uint8_t *key);
-
-void
-blowfish_encrypt(const struct blowfish_ctx *ctx,
-                 size_t length, uint8_t *dst,
-                 const uint8_t *src);
-void
-blowfish_decrypt(const struct blowfish_ctx *ctx,
-                 size_t length, uint8_t *dst,
-                 const uint8_t *src);
+extern const struct blowfish_ctx _nettle_blowfish_initial_ctx;
+extern void _nettle_blowfish_encround (const struct blowfish_ctx *ctx,
+                                       uint32_t * ret_xl, uint32_t * ret_xr);
 
 #ifdef __cplusplus
 }
 #endif
 
-#endif /* NETTLE_BLOWFISH_H_INCLUDED */
+#endif /* NETTLE_BLOWFISH_INTERNAL_H_INCLUDED */
diff --git a/blowfish.c b/blowfish.c
index 52040f13..e73caffe 100644
--- a/blowfish.c
+++ b/blowfish.c
@@ -54,12 +54,13 @@
 #include &lt;assert.h&gt;
 
 #include "blowfish.h"
+#include "blowfish-internal.h"
 
 #include "macros.h"
 
 /* precomputed S boxes */
-static const struct blowfish_ctx
-initial_ctx = {
+const struct blowfish_ctx
+_nettle_blowfish_initial_ctx = {
   {
     { /* ks0 */
       0xD1310BA6, 0x98DFB5AC, 0x2FFD72DB, 0xD01ADFB7, 0xB8E1AFED, 0x6A267E96,
@@ -261,8 +262,8 @@ initial_ctx = {
 
 #define R(c, l,r,i)  do { l ^= c-&gt;p[i]; r ^= F(c,l); } while(0)
 
-static void
-encrypt (const struct blowfish_ctx *ctx, uint32_t * ret_xl,
+void
+_nettle_blowfish_encround (const struct blowfish_ctx *ctx, uint32_t * ret_xl,
 	    uint32_t * ret_xr)
 {
   uint32_t xl, xr;
@@ -295,7 +296,7 @@ encrypt (const struct blowfish_ctx *ctx, uint32_t * ret_xl,
 }
 
 static void
-decrypt (const struct blowfish_ctx *ctx, uint32_t * ret_xl, uint32_t * ret_xr)
+decround (const struct blowfish_ctx *ctx, uint32_t * ret_xl, uint32_t * ret_xr)
 {
   uint32_t xl, xr;
 
@@ -339,7 +340,7 @@ blowfish_encrypt (const struct blowfish_ctx *ctx,
 
       d1 = READ_UINT32(src);
       d2 = READ_UINT32(src+4);
-      encrypt (ctx, &amp;d1, &amp;d2);
+      _nettle_blowfish_encround (ctx, &amp;d1, &amp;d2);
       dst[0] = (d1 &gt;&gt; 24) &amp; 0xff;
       dst[1] = (d1 &gt;&gt; 16) &amp; 0xff;
       dst[2] = (d1 &gt;&gt; 8) &amp; 0xff;
@@ -361,7 +362,7 @@ blowfish_decrypt (const struct blowfish_ctx *ctx,
 
       d1 = READ_UINT32(src);
       d2 = READ_UINT32(src+4);
-      decrypt (ctx, &amp;d1, &amp;d2);
+      decround (ctx, &amp;d1, &amp;d2);
       dst[0] = (d1 &gt;&gt; 24) &amp; 0xff;
       dst[1] = (d1 &gt;&gt; 16) &amp; 0xff;
       dst[2] = (d1 &gt;&gt; 8) &amp; 0xff;
@@ -380,7 +381,7 @@ blowfish_set_key (struct blowfish_ctx *ctx,
   int i, j;
   uint32_t data, datal, datar;
 
-  *ctx = initial_ctx;
+  *ctx = _nettle_blowfish_initial_ctx;
 
   for (i = j = 0; i &lt; _BLOWFISH_ROUNDS + 2; i++)
     {
@@ -393,15 +394,15 @@ blowfish_set_key (struct blowfish_ctx *ctx,
   datal = datar = 0;
   for (i = 0; i &lt; _BLOWFISH_ROUNDS + 2; i += 2)
     {
-      encrypt (ctx, &amp;datal, &amp;datar);
+      _nettle_blowfish_encround (ctx, &amp;datal, &amp;datar);
       ctx-&gt;p[i] = datal;
       ctx-&gt;p[i + 1] = datar;
     }
-  
+
   for (j = 0; j &lt; 4; j++)
     for (i = 0; i &lt; 256; i += 2)
       {
-	encrypt (ctx, &amp;datal, &amp;datar);
+	_nettle_blowfish_encround (ctx, &amp;datal, &amp;datar);
 	ctx-&gt;s[j][i] = datal;
 	ctx-&gt;s[j][i + 1] = datar;
     }
diff --git a/blowfish.h b/blowfish.h
index bcdc7cb6..a4473266 100644
--- a/blowfish.h
+++ b/blowfish.h
@@ -46,6 +46,8 @@ extern "C" {
 #define blowfish128_set_key nettle_blowfish128_set_key
 #define blowfish_encrypt nettle_blowfish_encrypt
 #define blowfish_decrypt nettle_blowfish_decrypt
+#define blowfish_bcrypt nettle_blowfish_bcrypt
+#define blowfish_salt_base64 nettle_blowfish_salt_base64
 
 #define BLOWFISH_BLOCK_SIZE 8
 
@@ -60,6 +62,10 @@ extern "C" {
 
 #define _BLOWFISH_ROUNDS 16
 
+#define BLOWFISH_BCRYPT_HASH_SIZE (60 + 1) /* Including null-terminator */
+#define BLOWFISH_BCRYPT_BINSALT_SIZE 16    /* Binary string size */
+#define BLOWFISH_BCRYPT_TXTSALT_SIZE ((BLOWFISH_BCRYPT_BINSALT_SIZE*8+5) / 6)
+
 struct blowfish_ctx
 {
   uint32_t s[4][256];
@@ -81,6 +87,15 @@ void
 blowfish_decrypt(const struct blowfish_ctx *ctx,
                  size_t length, uint8_t *dst,
                  const uint8_t *src);
+int
+blowfish_bcrypt(size_t length,
+                char *dst,
+                const char *key,
+                const char *settings);
+int
+blowfish_salt_base64(size_t length,
+                     char *dst,
+                     const uint8_t *salt);
 
 #ifdef __cplusplus
 }
diff --git a/nettle.texinfo b/nettle.texinfo
index ff64889c..b6b6fc16 100644
--- a/nettle.texinfo
+++ b/nettle.texinfo
@@ -1512,6 +1512,75 @@ in any other way.
 Analogous to @code{blowfish_encrypt}
 @end deftypefun
 
+@deftypefun int blowfish_bcrypt (size_t @var{length}, char *@var{dst}, const char \
*@var{key}, const char *@var{settings}) +Compute bcrypt password hash.  The same \
function is used for both +generating and verifying an existing hash.
+The function will return @code{0} if the hash cannot be computed
+due to invalid input.
+The function will return @code{1} and store the computed hash
+in the array pointed to by @var{dst}.  The hash is computed based
+on the chosen algorithm, number of rounds and specified salt.
+@var{dst} must
+point to a character array of the specified 'length'.
+@var{length} must be at least @code{BLOWFISH_BCRYPT_HASH_SIZE}.
+
+Sample code to generate a bcrypt hash:
+@example
+char cleartxtpassword[] = "ExamplePassword";
+char hashsettings[BLOWFISH_BCRYPT_HASH_SIZE] =
+           "$2y$"  /* Hash algorithm version */
+           "10"   /* 2^10 hash rounds (strength) */
+           "$";  /* separator */
+uint8_t salt[BLOWFISH_BCRYPT_BINSALT_SIZE];
+@dots{}
+/* Make sure that salt is filled with random bytes */
+@dots{}
+char salt64[BLOWFISH_BCRYPT_TXTSALT_SIZE];
+blowfish_salt_base64(sizeof(salt64), salt64, salt);
+strcat(hashsettings, salt64);
+char hashedresult[BLOWFISH_BCRYPT_HASH_SIZE];
+int result = blowfish_bcrypt(sizeof(hashedresult), hashedresult,
+                               cleartxtpassword, hashsettings);
+if (result)
+  printf("%s\n", hashedresult);
+@end example
+
+Sample code to verify a bcrypt hash:
+@example
+char cleartxtpassword[] = "ExamplePassword";
+char existinghashed[] =
+           "$2y$"  /* Hash algorithm version */
+           "10"   /* 2^10 hash rounds (strength) */
+           "$"   /* separator */
+           "1b2lPgo4XumibnJGN3r3sO" /* base64 encoded 16-byte salt */
+           "u7wE7xNfYDKlAxZffJDCJdVfFTAyevu"; /* Hashedpart */
+char hashedresult[BLOWFISH_BCRYPT_HASH_SIZE];
+int result = blowfish_bcrypt(sizeof(hashedresult), hashedresult,
+                               cleartxtpassword, existinghashed);
+if (result &amp;&amp; !strcmp(hashedresult, existinghashed))
+  printf("Password is correct.");
+else
+  printf("Password is incorrect.");
+@end example
+@end deftypefun
+
+@deftypefun int blowfish_salt_base64 (size_t @var{length}, char *@var{dst}, const \
uint8_t *@var{salt}) +Encodes the supplied 16-byte binary salt into the base64 \
encoding that +is needed in bcrypt-password fields.
+
+Note that the used base64 encoding differs from the standard Nettle base64
+encoding.
+
+The function returns @code{1} if the encoding was successful (if there
+was enough room to store it), and it returns @code{0} if the amount of
+room was insufficient.
+
+@var{dst} must point to a character array of at least @var{length} bytes.
+@var{length} should at least be equal to @code{BLOWFISH_BCRYPT_HASH_SIZE}.
+@var{salt} must point to a byte array filled with
+ @code{BLOWFISH_BCRYPT_BINSALT_SIZE} random salt bytes.
+@end deftypefun
+
 @subsection Camellia
 @cindex Camellia
 
-- 
2.20.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200322112303</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-03-22 11:23:03-0400</timestampReceived><subject>Re: [PATCH] x86: Build with -z ibt -z shstk if possible</subject><body>

"H.J. Lu" &lt;hjl.tools@gmail.com&gt; writes:

&gt; Where should such a CET violation happen? I added a CET violation test to glibc:
&gt;
&gt;   void (*funcp) (void);
&gt;   funcp = mmap (NULL, 0x1000, PROT_EXEC | PROT_READ | PROT_WRITE,
&gt;                  MAP_ANONYMOUS | MAP_PRIVATE, -1);
&gt;   printf ("mmap = %p\n", funcp);
&gt;   /* Write RET instruction.  */
&gt;   *(char *) funcp = 0xc3;
&gt;   funcp ();
&gt;
&gt; I can do something similar.  But it is independent of nettle.

The reason it makes sense to have such a test in nettle is that nettle
includes code (your patch) that affects if cet works. If practical, I'd
prefer to do it with inline assembly rather than constructing code at
run time, to not have to worry about flushing caches.

I suspect the tricky part is for the test to find out if cet protections
are expected to work on the test system. Maybe one approch could be to
have two test executables with a cet violation, one linking only to
libc, and one linking also to nettle, hogweed and gmp. Then we'd expect
that either both crash or none crash.

&gt; The regular tests have covered the nettle library with
&gt;
&gt; $ ./configure CC='gcc -fcf-protextion=full' &amp;&amp; make &amp;&amp; make check
&gt;
&gt; I got many CET violations on CET platform before my fix was merged.

That's excellent. What I worry is, now that it's is working fine, if
some later change accidentally breaks cet marks. If that's not detected
by tests, then applications linking with nettle will not get the cet
protection at runtime, despite being compiled with -fcf-protection=full.

So it would be nice with an integration level test to catch that type of
potential regression.

It's a bit special to test security features; it's not enough to test
that everything works fine in the absense of attack, we need tests to
model the attacks, at least when that's practical.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200322152803</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-03-22 15:28:03-0400</timestampReceived><subject>Re: [PATCH] x86: Add ibt-test.c</subject><body>

"H.J. Lu" &lt;hjl.tools@gmail.com&gt; writes:

&gt; Like this?

Yes, thanks! A few comments below.

&gt; +AC_CACHE_CHECK([compiler support for -mshstk],
&gt; +		nettle_cv_x86_mshstk_cflags,
&gt; +[AC_TRY_COMPILE([],[int foo],
&gt; +nettle_cv_x86_mshstk_cflags=yes,
&gt; +nettle_cv_x86_mshstk_cflags=no)])
&gt; +if test "$nettle_cv_x86_mshstk_cflags" = yes; then
&gt; +  EXTRA_X86_CFLAGS=-mshstk
&gt; +fi
&gt; +AC_SUBST(EXTRA_X86_CFLAGS)

Maybe rename autoconf variable to TESTSUITE_CFLAGS.

This check may well be enough, but you could consider limiting it to x86
targets, and having the test program include x86intrin.h and use
_get_ssp. 

&gt; diff --git a/testsuite/.test-rules.make b/testsuite/.test-rules.make
&gt; index 922a2c7f..257ce86e 100644
&gt; --- a/testsuite/.test-rules.make
&gt; +++ b/testsuite/.test-rules.make
&gt; @@ -178,6 +178,9 @@ xts-test$(EXEEXT): xts-test.$(OBJEXT)
&gt;  pbkdf2-test$(EXEEXT): pbkdf2-test.$(OBJEXT)
&gt;  	$(LINK) pbkdf2-test.$(OBJEXT) $(TEST_OBJS) -o pbkdf2-test$(EXEEXT)
&gt;  
&gt; +ibt-test$(EXEEXT): ibt-test.$(OBJEXT)
&gt; +	$(LINK) ibt-test.$(OBJEXT) $(TEST_OBJS) -o ibt-test$(EXEEXT)
&gt; +

Maybe rename x86-ibt-test, if you think this feature is going to be x86
only for the foreseeable future.

&gt; diff --git a/testsuite/ibt-test.c b/testsuite/ibt-test.c
&gt; new file mode 100644
&gt; index 00000000..fdc97d8f
&gt; --- /dev/null
&gt; +++ b/testsuite/ibt-test.c
&gt; @@ -0,0 +1,43 @@
&gt; +#include "testutils.h"
&gt; +#ifdef __CET__

It would make some sense to also check for __GNUC__,
__i386__/__x86_64__, and __posix__. Is __CET__ specific enough, or is
there a risk that some other compiler or target will use that name with
a different meaning? In particular, can it break windows builds?

If needed here, same should apply to the configure check from the
previous patch.

&gt; +#include &lt;signal.h&gt;
&gt; +#include &lt;x86intrin.h&gt;
&gt; +
&gt; +static void
&gt; +segfault_handler(int signo)
&gt; +{
&gt; +  exit(0);
&gt; +}
&gt; +
&gt; +void
&gt; +ibt_violation(void)
&gt; +{
&gt; +#ifdef __i386__
&gt; +  asm volatile("lea 1f, %eax\n\t"
&gt; +	       "jmp *%eax\n"
&gt; +	       "1:");
&gt; +#else
&gt; +  asm volatile("lea 1f, %rax\n\t"
&gt; +	       "jmp *%rax\n"
&gt; +	       "1:");
&gt; +#endif
&gt; +}

Nice and easy. I think these need a clobber list to tell gcc that it
modifies eax/rax, though.

&gt; +void
&gt; +test_main(void)
&gt; +{
&gt; +   /* NB: This test should trigger SIGSEGV on CET platforms.  If SHSTK
&gt; +     is disabled, assuming IBT is also disabled.  */
&gt; +  if (_get_ssp() == 0)
&gt; +    SKIP();

I would suggest

  if (_get_ssp() == 0)
    {
      ibt_violation()
      SKIP();
    }

to have the inline asm exercised, even when cet is disabled.

Can you explain what _get_ssp does? It seems it is included via
x86intrin.h, and defined (on x86_64) as

  extern __inline unsigned long long
  __attribute__((__gnu_inline__, __always_inline__, __artificial__))
  _get_ssp (void)
  {
    return __builtin_ia32_rdsspq ();
  }

Would it be easier to define it using inline asm, eliminating the
configure check for -mshstk? Or is it a complicated thing involving a
cpuid check first?

&gt; +  signal(SIGSEGV, segfault_handler);
&gt; +  ibt_violation();
&gt; +  FAIL();
&gt; +}
&gt; +#else
&gt; +void
&gt; +test_main(void)
&gt; +{
&gt; +}

Should use SKIP()

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200322200140</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-03-22 20:01:40-0400</timestampReceived><subject>Re: [PATCH] x86: Add x86-ibt-test.c</subject><body>

"H.J. Lu" &lt;hjl.tools@gmail.com&gt; writes:

&gt; Here is the updated patch.

Pushed to the master-updates branch now. Thanks!

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200323091432</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-03-23 09:14:32-0400</timestampReceived><subject>Re: [PATCH] (revision 3.0) Added bcrypt() support.</subject><body>

The 3.0 version has been completely revised:
a. Easier to use API (very close to what I provide in Pike internally).
b. Sanitised and revamped internal string handling.
c. More straightforward code-flow (easier to verify output validity).
-- 
Stephen.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200323095301</emailId><senderName>"Stephen R. van den Berg"</senderName><senderEmail>srb@cuci.nl</senderEmail><timestampReceived>2020-03-23 09:53:01-0400</timestampReceived><subject>Re: [PATCH] (revision 3.1) Added bcrypt() support.</subject><body>

Changes since 3.0:
- Got rid of some superflous "fixed" outputs in case of failure.
-- 
Stephen.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200331114200</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-03-31 11:42:00-0400</timestampReceived><subject>Re: Failure of gnutls ci build</subject><body>

On Mon, Mar 30, 2020 at 7:23 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt; 
&gt; I committed a change to update nettle version numbers, which implies a
&gt; new symbol version for internal symbols.
&gt; 
&gt; That seems to break the gnutls ci build,
&gt; https://gitlab.com/gnutls/nettle/-/jobs/487360242
&gt; 
&gt; The error is
&gt; 
&gt; 1217 ./bootstrap: getting translations into po/.reference for gnutls...
&gt; 1218 wget: /lib64/libhogweed.so.5: version `HOGWEED_INTERNAL_5_0' not found \
&gt; (required by /lib64/libgnutls.so.30) 1219 wget: /lib64/libnettle.so.7: version \
&gt; `NETTLE_INTERNAL_7_0' not found (required by /lib64/libgnutls.so.30) 
&gt; I don't quite understand all details. This job buils and installs
&gt; nettle, as
&gt; 
&gt; ./configure --disable-documentation --prefix=/usr --libdir=/usr/lib64 &amp;&amp;
&gt; make -j4 &amp;&amp; make install
&gt; 
&gt; replacing any previously instaled version with the same soname. So
&gt; that's a somewhat broader test than I had expected. That explains why
&gt; linking of wget is affected.
&gt; 
&gt; The more worring part is that the installed gnutls library seems to
&gt; depend on internal nettle symbols (it would have been nice if the error
&gt; message named the offending symbols). Is that intended?
&gt; 
&gt; It's not necessarily wrong, but any packaged version of gnutls built
&gt; that way *must* be marked to depend on exactly the same versions of
&gt; nettle with which it was built. And the ci rule would need to use a
&gt; different prefix and some other way to tell the gnutls build to use the
&gt; newly built nettle library instead of the system version.
&gt; 
&gt; On my own debian machine I have libgnutls.so.30, but apparently an older
&gt; version. According to
&gt; 
&gt; objdump -T /usr/lib/x86_64-linux-gnu/libgnutls.so.30
&gt; 
&gt; the version I have refers only to symbols with version NETTLE_6 and
&gt; HOGWEED_4, i.e., nettle version older than 3.5. And no mention of
&gt; NETTLE_INTERNAL or HOGWEED_INTERNAL.

It is not limited to Nettle.

Last week, /usr/lib/x86_64-linux-gnu/libgnutls.so.30 could not find a
symbol in libidn2.so I had installed into /usr/local or /opt/local.
The problem cascaded to the point I could not open a Terminal to fix
things.

I had to reboot into safe mode, and delete both /usr/local or
/opt/local. Then that promiscuous-ass loader fixed its cache.

Would the genius who thought it was a good idea to compile and link
against one library, and then runtime link against the wrong library,
please step forward to claim their Darwin award...

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200331222337</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-03-31 22:23:37-0400</timestampReceived><subject>Re: Nettle 3.5.1 and OS X 10.12 patch</subject><body>

On Tue, Mar 31, 2020 at 2:08 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; nisse@lysator.liu.se (Niels Möller) writes:
&gt;
&gt; &gt; I think a reasonable way is to add
&gt; &gt;
&gt; &gt; abs_top_builddir = @abs_top_builddir@
&gt; &gt;
&gt; &gt; TEST_SHLIB_DIR = "${abs_top_builddir}/.lib"
&gt; &gt;
&gt; &gt; to config.make.in, and use that to set LD_LIBRARY_PATH. And possibly
&gt; &gt; only pass TEST_SHLIB_DIR to the run-tests script, and move the logic to
&gt; &gt; setup the environment.
&gt;
&gt; I've pushed a change like that to the branch test-shlib-dir. Please try
&gt; it out.
&gt;
&gt; This also makes tests with a shared-library build work in termux on my
&gt; android phone. It used to fail, in part because termux depends on
&gt; LD_LIBRARY_PATH being set, and possibly with additional trouble from
&gt; using an LD_LIBRARY_PATH with relative file names.

Tested mostly OK on my mac-mini:

...
PASS: gostdsa-sign
PASS: gostdsa-verify
PASS: gostdsa-keygen
PASS: cxx
dyld: Library not loaded: /Users/jwalton/tmp/nettle/lib/libnettle.7.dylib
  Referenced from:
/Users/jwalton/Build-Scripts/nettle-master/testsuite/../tools/sexp-conv
  Reason: image not found
cmp: EOF on test1.out
FAIL: sexp-conv
dyld: Library not loaded: /Users/jwalton/tmp/nettle/lib/libhogweed.5.dylib
  Referenced from:
/Users/jwalton/Build-Scripts/nettle-master/testsuite/../tools/pkcs1-conv
  Reason: image not found
./pkcs1-conv-test: line 26: 88645 Abort trap: 6           $EMULATOR
../tools/pkcs1-conv &gt; testkey.priv  &lt;&lt;EOF
-----BEGIN RSA PRIVATE KEY-----
MIICXQIBAAKBgQC3792bBgQ/mc8aYOFaLEJES/JipmLAeVgznob/Vrzvdcx+bl6L
6gTphctU9ToOLC049dZYW3DJ53owUmbQgqB0vvLTjM9lGSEw4oXLrp7x/XVo/fZM
UcRWq5H8Z0l6KANXHwcVcsjjqPBJ6WD/Is3o9rb58GU9GZcsMO2Zoh8z6wIDAQAB
AoGABP+iwRS/xs6yPyBE34N2ZY6+zomBA4QIrpZvSr8bsVI9NW5gaWL5sTLunKdx
ZXMz42li4tHRVdtRicCjhKUYIShH6J3ACKnBsCHwK6MgEyuDifxhmVt/b5xQNdOL
bckwBXCL/XwkIkSgrvgUk/cXcvDXSdf7cRX+tgEHlbGjWGkCQQDaS9Xm3ZTIJ1CO
/chlET2Cf/e5GzC79njzeg5oDyTG7qlXZudpZv5D6NatVoIDF4gfey6NKB7DNehT
ff+v9wztAkEA17TN+cuFBuZX+KT3K7J1uavGqWOypDUy/h7PINODJLzoWAWnw94H
NSu6/pXo1Q1WBMQa1jB1qxJaLpBp56iBNwJAUp6JIouSl/5pOvVKNxZDVXThaSml
VD6AoIX9ldzFapVBelb0FqxoZ4NkXM50/n6VgnS4tawNmIx6lb8GWq8CMQJBAM5S
lMofzyggX3jnYbycQFrOYYFYaWEDubi0A27koYYcYyj+j8+bqc1D/OLSxRg0X1jD
st+5DnQJY9UyMPpyhNUCQQChMjCAamJP3xC7bOoza//k7E9kvx5IZcEsQWqok5BO
PSVKy/gGBeN1Q7Rj+XoybQ/SqLpfgTYRI9UpbKmpkNuq
-----END RSA PRIVATE KEY-----
EOF

FAIL: pkcs1-conv
dyld: Library not loaded: /Users/jwalton/tmp/nettle/lib/libnettle.7.dylib
  Referenced from:
/Users/jwalton/Build-Scripts/nettle-master/testsuite/../tools/nettle-pbkdf2
  Reason: image not found
cmp: EOF on test1.out
FAIL: nettle-pbkdf2
PASS: symbols
PASS: dlopen
=====================
3 of 107 tests failed
=====================
make[1]: *** [check] Error 1
make: *** [check] Error 2

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200203034350</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-02-03 03:43:50-0400</timestampReceived><subject>Re: sha1-compress-2.s:74: Error: no such instruction: `sha1rnds4 $0, %xmm5, %xmm4'</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; I'm working on Solaris 11.3 i86pc. I'm building the Nettle 3.5.1
&gt; release tarball.
&gt;
&gt; configure: summary of build options:
&gt;
&gt;   Version:           nettle 3.5.1
&gt;   Host type:         x86_64-sun-solaris2
&gt;   ABI:               64
&gt;   Assembly files:    x86_64/fat x86_64
&gt;   Install prefix:    /usr/local
&gt;   Library directory: /usr/local/lib
&gt;   Compiler:          gcc
&gt;   Static libraries:  yes
&gt;   Shared libraries:  yes
&gt;   Public key crypto: yes
&gt;   Using mini-gmp:    no
&gt;   Documentation:     no
&gt;
&gt; Running make results in:
&gt;
&gt; gcc -I. -I/usr/local/include -DNDEBUG -DHAVE_CONFIG_H -g2 -O2 -m64
&gt; -march=native -fPIC -pthread -ggdb3 -Wno-pointer-sign -Wall -W
&gt; -Wmissing-prototypes -Wmissing-declarations -Wstrict-prototypes
&gt; -Wpointer-arith -Wbad-function-cast -Wnested-externs -fPIC -MT
&gt; sha256-compress-2.o -MD -MP -MF sha256-compress-2.o.d -c
&gt; sha256-compress-2.s
&gt; sha1-compress-2.s: Assembler messages:
&gt; sha1-compress-2.s:74: Error: no such instruction: `sha1rnds4 $0,%xmm5,%xmm4'
&gt; sha1-compress-2.s:79: Error: no such instruction: `sha1nexte %xmm1,%xmm6'
&gt; sha1-compress-2.s:81: Error: no such instruction: `sha1rnds4 $0,%xmm6,%xmm4'
&gt; sha1-compress-2.s:82: Error: no such instruction: `sha1msg1 %xmm1,%xmm0'
&gt; sha1-compress-2.s:87: Error: no such instruction: `sha1nexte %xmm2,%xmm5'
&gt; ...
&gt;
&gt; Sun provides an old GCC. The compiler supports AES-NI, but it lacks SHA.
&gt;
&gt;     $ gcc --version
&gt;     gcc (GCC) 4.8.2

Note that the error messages are from the assembler, not gcc. You're
using Solaris' assembler, or GNU binutils?

The best option is to upgrade to an assembler supporting these
instructions. The easy option is to drop --eable-fat from the confgure
arguments.

There are other options, e.g., pre-assembling these instructions and
replacing them with .byte sequences in the .asm file, or additional
configure checks to test assembler features and conditionally disable
this code. But I'd prefer to not go that way.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200203042320</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-02-03 04:23:20-0400</timestampReceived><subject>Re: Crash on Core-i7 8700 machine with --enable-x86-aesni and --enable-x86-sha-ni</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; Hi Everyone,
&gt;
&gt; I'm catching a crash with Nettle 3.5.1 on a Core-i7 8700 configured
&gt; with --enable-x86-aesni and --enable-x86-sha-ni. I verified the
&gt; compiler supports both AESNI and SHA.
&gt;
&gt;     Illegal instruction (core dumped)
&gt;     FAIL: hkdf
&gt;     PASS: salsa20
&gt;     Illegal instruction (core dumped)
&gt;     FAIL: sha1
&gt;     Illegal instruction (core dumped)
&gt;     FAIL: sha224
&gt;     Illegal instruction (core dumped)
&gt;     FAIL: sha256

Note that --enable-x86-sha-ni controls if the output binaries use the
instructions in question. It's unconditional, in effect, you're telling
configure "I intend to only ever run the resulting binaries on
processors that support these instructions". And then it appears your
processor actually don't have them, and crashes in the expected way.

The way to enable use conditionally depending on actual processor
features at runtime, is to use --enable-fat.

Support in the tool chain (actually, it's the assembler rather than the C
compiler that matters) is a prerequisite, but doesn't say anything about
processor support.

Regarding the default --enable-arm-neon=auto, that's is a bit special,
but I think the reason I did it that way is

  (i) neon is pretty common on the ARM variants that are
      relevant for Nettle, and 
 
 (ii) for embeddded systems it seems more common that what's supported
      by the cross assembler corresponds to what's actually supported on
      the target processor. E.g., there are pseudo ops like .fpu = neon
      which controls which instructions are accepted.

      I'm can't really say that's the best default for ARM either, but I
      haven't seen any reports of it causing problems. I think it would
      cause a lot of trouble if done the same way for x86.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200206051828</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-02-06 05:18:28-0400</timestampReceived><subject>Re: Please use -shared on Solaris. Don't use -G on Solaris</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; Do you think it makes sense to change from -G to -shared
&gt; unconditionally for Solaris?

I've done this change, after digging just a little in the docs.

According to
https://docs.oracle.com/cd/E77782_01/html/E77792/gqexw.html#OSGCCgqfch,
--shared was added as an alias to -G in Oracle Solaris Studio 12.4, and
according to
https://en.wikipedia.org/wiki/Oracle_Developer_Studio#History, that
version was released in 2014. So I don't expect any breakage from this
change. Obviosly, it can't be "supported" in any meaningful way without
someone actually using these compilers committing to regularly testing
Nettle.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200206063320</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-02-06 06:33:20-0400</timestampReceived><subject>Re: [PATCH] gost28147: move gost params to internal interface</subject><body>

dbaryshkov@gmail.com writes:

&gt; From: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
&gt;
&gt; gost28147_param instances were never a part of stable release, so move
&gt; them to internal header.

Thanks, applied.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200209131812</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-02-09 13:18:12-0400</timestampReceived><subject>Re: [PATCH v2 3/6] nettle-meta: Add meta interface for HMAC functions</subject><body>

Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt; writes:

&gt; ср, 25 дек. 2019 г. в 14:31, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt;&gt;
&gt;&gt; If we define a single nettle_mac for each supported (no-nonce) mac
&gt;&gt; algorithm, what should the key size be for each algorithm? Using the
&gt;&gt; underlying block size for the hmac algorithms seems to be a bit
&gt;&gt; overkill. What key sizes are used in practice? Does it make sense to
&gt;&gt; use key size equal to digest size (at least, that's what used for hmac
&gt;&gt; in the ssh protocol)?
&gt;
&gt; Same goes for TLS. Key size = digest size for HMAC.

I've pushed Daiki's patches with struct nettle_mac to a branch
move-nettle_mac, with a few changes: Drop the nonce things (and hence
also umac). Change the hmac algorithms to all use digest size as the key
size. And I've updated hmac tests to use this interface when possible.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200209171304</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-02-09 17:13:04-0400</timestampReceived><subject>[PATCH] cmac-des3: add meta declaration to Nettle library</subject><body>

From: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;

Move cmac-des3 meta information from testsuite/cmac-test.c to main
Nettle library.

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 Makefile.in               |  2 +-
 cmac-des3-meta.c          | 52 +++++++++++++++++++++++++++++++++++++++
 nettle-meta-macs.c        |  1 +
 nettle-meta.h             |  1 +
 testsuite/cmac-test.c     | 12 ---------
 testsuite/meta-mac-test.c |  1 +
 6 files changed, 56 insertions(+), 13 deletions(-)
 create mode 100644 cmac-des3-meta.c

diff --git a/Makefile.in b/Makefile.in
index d4fcb81302a2..ddc304285321 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -103,7 +103,7 @@ nettle_SOURCES = aes-decrypt-internal.c aes-decrypt.c \
 		 gcm-camellia128.c gcm-camellia128-meta.c \
 		 gcm-camellia256.c gcm-camellia256-meta.c \
 		 cmac.c cmac64.c cmac-aes128.c cmac-aes256.c cmac-des3.c \
-		 cmac-aes128-meta.c cmac-aes256-meta.c \
+		 cmac-aes128-meta.c cmac-aes256-meta.c cmac-des3-meta.c \
 		 gost28147.c gosthash94.c gosthash94-meta.c \
 		 hmac.c hmac-gosthash94.c hmac-md5.c hmac-ripemd160.c \
 		 hmac-sha1.c hmac-sha224.c hmac-sha256.c hmac-sha384.c \
diff --git a/cmac-des3-meta.c b/cmac-des3-meta.c
new file mode 100644
index 000000000000..7fdee8e680cf
--- /dev/null
+++ b/cmac-des3-meta.c
@@ -0,0 +1,52 @@
+/* cmac-des3-meta.c
+
+   Copyright (C) 2020 Dmitry Baryshkov
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+
+#include "nettle-meta.h"
+
+#include "cmac.h"
+
+const struct nettle_mac nettle_cmac_des3 =
+{
+  "cmac_des3",
+  sizeof(struct cmac_des3_ctx),
+  CMAC64_DIGEST_SIZE,
+  DES3_KEY_SIZE,
+
+  (nettle_set_key_func*) cmac_des3_set_key,
+  (nettle_hash_update_func*) cmac_des3_update,
+  (nettle_hash_digest_func*) cmac_des3_digest
+};
diff --git a/nettle-meta-macs.c b/nettle-meta-macs.c
index cb9ede851573..a658ee39e230 100644
--- a/nettle-meta-macs.c
+++ b/nettle-meta-macs.c
@@ -40,6 +40,7 @@
 const struct nettle_mac * const _nettle_macs[] = {
   &amp;nettle_cmac_aes128,
   &amp;nettle_cmac_aes256,
+  &amp;nettle_cmac_des3,
   &amp;nettle_hmac_md5,
   &amp;nettle_hmac_ripemd160,
   &amp;nettle_hmac_sha1,
diff --git a/nettle-meta.h b/nettle-meta.h
index 5d86615f94cc..7a6af363426b 100644
--- a/nettle-meta.h
+++ b/nettle-meta.h
@@ -276,6 +276,7 @@ nettle_get_macs (void);
 
 extern const struct nettle_mac nettle_cmac_aes128;
 extern const struct nettle_mac nettle_cmac_aes256;
+extern const struct nettle_mac nettle_cmac_des3;
 
 /* HMAC variants with key size = digest size */
 extern const struct nettle_mac nettle_hmac_md5;
diff --git a/testsuite/cmac-test.c b/testsuite/cmac-test.c
index 1a2cd0e591cf..a71baa086d01 100644
--- a/testsuite/cmac-test.c
+++ b/testsuite/cmac-test.c
@@ -2,18 +2,6 @@
 #include "nettle-internal.h"
 #include "cmac.h"
 
-const struct nettle_mac nettle_cmac_des3 =
-{
-  "CMAC-3DES",
-  sizeof(struct cmac_des3_ctx),
-  CMAC64_DIGEST_SIZE,
-  DES3_KEY_SIZE,
-
-  (nettle_set_key_func*) cmac_des3_set_key,
-  (nettle_hash_update_func*) cmac_des3_update,
-  (nettle_hash_digest_func*) cmac_des3_digest
-};
-
 #define test_cmac_aes128(key, msg, ref)					\
   test_mac(&amp;nettle_cmac_aes128, key, msg, ref)
 
diff --git a/testsuite/meta-mac-test.c b/testsuite/meta-mac-test.c
index 32b6f20f07cd..55339441c99f 100644
--- a/testsuite/meta-mac-test.c
+++ b/testsuite/meta-mac-test.c
@@ -4,6 +4,7 @@
 const char* macs[] = {
   "cmac_aes128",
   "cmac_aes256",
+  "cmac_des3",
   "hmac_md5",
   "hmac_ripemd160",
   "hmac_sha1",
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200210121046</emailId><senderName>Dmitry Eremin-Solenikov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-02-10 12:10:46-0400</timestampReceived><subject>Two MRs on git.lysator.liu.se</subject><body>

Hello,

I've opened two merge requests on git.lysator.liu.se: one for new hash
function support
(https://git.lysator.liu.se/nettle/nettle/merge_requests/6) and
another one for GOST 28147 cipher/MAC support
(https://git.lysator.liu.se/nettle/nettle/merge_requests/7). Code has
been tested for quite some time in GnuTLS and has been submitted with
minor modifications.


-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200211195817</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-02-11 19:58:17-0400</timestampReceived><subject>[PATCH] gitlab-ci: reenable GOST compilation</subject><body>

From: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;

GnuTLS is now compatible again with Nettle master branch. Remove
--disable-gost.

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 .gitlab-ci.yml | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/.gitlab-ci.yml b/.gitlab-ci.yml
index 663f98f5cb8e..5b348f38568f 100644
--- a/.gitlab-ci.yml
+++ b/.gitlab-ci.yml
@@ -100,7 +100,7 @@ build/gnutls:
     make -j4 &amp;&amp; make install
   - git clone --depth 1 --branch master https://gitlab.com/gnutls/gnutls.git gnutls-git
   - cd gnutls-git &amp;&amp; git submodule update --init &amp;&amp; ./bootstrap &amp;&amp;
-    ./configure --disable-gost --disable-cxx --disable-guile --disable-doc &amp;&amp; make -j$(nproc) &amp;&amp;
+    ./configure --disable-cxx --disable-guile --disable-doc &amp;&amp; make -j$(nproc) &amp;&amp;
     make -j $(nproc) check
   tags:
   - shared
-- 
2.25.0

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200215190251</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-02-15 19:02:51-0400</timestampReceived><subject>Re: [PATCH] ecc: remove ecc_modp_foo/ecc_modq_foo macros</subject><body>

dbaryshkov@gmail.com writes:

&gt; From: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
&gt;
&gt; To make ecc functions usage more obvious remove ecc_modp_foo() and
&gt; ecc_modq_foo() wrapper macros.

Thanks, applied.

Regards,,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200215205840</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-02-15 20:58:40-0400</timestampReceived><subject>[PATCH] Implement GOST VKO key derivation algorithm</subject><body>

From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;

Signed-off-by: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;
---
 Makefile.in                  |  2 +-
 gostdsa-vko.c                | 77 ++++++++++++++++++++++++++++++
 gostdsa.h                    |  7 +++
 testsuite/.gitignore         |  1 +
 testsuite/.test-rules.make   |  3 ++
 testsuite/Makefile.in        |  2 +-
 testsuite/gostdsa-vko-test.c | 92 ++++++++++++++++++++++++++++++++++++
 7 files changed, 182 insertions(+), 2 deletions(-)
 create mode 100644 gostdsa-vko.c
 create mode 100644 testsuite/gostdsa-vko-test.c

diff --git a/Makefile.in b/Makefile.in
index d4fcb81302a2..8f031d7a580d 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -194,7 +194,7 @@ hogweed_SOURCES = sexp.c sexp-format.c \
 		  ecc-ecdsa-sign.c ecdsa-sign.c \
 		  ecc-ecdsa-verify.c ecdsa-verify.c ecdsa-keygen.c \
 		  ecc-gostdsa-sign.c gostdsa-sign.c \
-		  ecc-gostdsa-verify.c gostdsa-verify.c \
+		  ecc-gostdsa-verify.c gostdsa-verify.c gostdsa-vko.c \
 		  curve25519-mul-g.c curve25519-mul.c curve25519-eh-to-x.c \
 		  curve448-mul-g.c curve448-mul.c curve448-eh-to-x.c \
 		  eddsa-compress.c eddsa-decompress.c eddsa-expand.c \
diff --git a/gostdsa-vko.c b/gostdsa-vko.c
new file mode 100644
index 000000000000..f78159a736b3
--- /dev/null
+++ b/gostdsa-vko.c
@@ -0,0 +1,77 @@
+/* gostdsa-vko.c
+
+   Copyright (C) 2016 Dmitry Eremin-Solenikov
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;stdlib.h&gt;
+
+#include "ecc-internal.h"
+#include "gostdsa.h"
+
+int
+gostdsa_vko(const struct ecc_scalar *key,
+	    const struct ecc_point *pub,
+	    size_t ukm_length, const uint8_t *ukm,
+	    size_t out_length, uint8_t *out)
+{
+  const struct ecc_curve *ecc = key-&gt;ecc;
+  unsigned bsize = (ecc_bit_size(ecc) + 7) / 8;
+  mp_size_t size = ecc-&gt;p.size;
+  mp_size_t itch = 4*size + ecc-&gt;mul_itch;
+  mp_limb_t *scratch;
+
+  if (itch &lt; 5*size + ecc-&gt;h_to_a_itch)
+      itch = 5*size + ecc-&gt;h_to_a_itch;
+
+  if (pub-&gt;ecc != ecc)
+      return 0;
+
+  if (out_length &lt; 2 * bsize) {
+      return 0;
+  }
+
+  scratch = gmp_alloc_limbs (itch);
+
+  mpn_set_base256_le (scratch, size, ukm, ukm_length);
+  if (mpn_zero_p (scratch, size))
+    mpn_add_1 (scratch, scratch, size, 1);
+  ecc_mod_mul (&amp;ecc-&gt;q, scratch + 3*size, key-&gt;p, scratch);
+  ecc-&gt;mul (ecc, scratch, scratch + 3*size, pub-&gt;p, scratch + 4*size);
+  ecc-&gt;h_to_a (ecc, 0, scratch + 3*size, scratch, scratch + 5*size);
+  mpn_get_base256_le (out, bsize, scratch + 3*size, size);
+  mpn_get_base256_le (out+bsize, bsize, scratch + 4*size, size);
+  gmp_free_limbs (scratch, itch);
+
+  return 2 * bsize;
+}
diff --git a/gostdsa.h b/gostdsa.h
index c92dfd1e1dd6..6667d0f1d3a8 100644
--- a/gostdsa.h
+++ b/gostdsa.h
@@ -44,6 +44,7 @@ extern "C" {
 /* Name mangling */
 #define gostdsa_sign nettle_gostdsa_sign
 #define gostdsa_verify nettle_gostdsa_verify
+#define gostdsa_vko nettle_gostdsa_vko
 #define ecc_gostdsa_sign nettle_ecc_gostdsa_sign
 #define ecc_gostdsa_sign_itch nettle_ecc_gostdsa_sign_itch
 #define ecc_gostdsa_verify nettle_ecc_gostdsa_verify
@@ -68,6 +69,12 @@ gostdsa_verify (const struct ecc_point *pub,
 	        size_t length, const uint8_t *digest,
 	        const struct dsa_signature *signature);
 
+int
+gostdsa_vko(const struct ecc_scalar *key,
+	    const struct ecc_point *pub,
+	    size_t ukm_length, const uint8_t *ukm,
+	    size_t out_length, uint8_t *out);
+
 /* Low-level GOSTDSA functions. */
 mp_size_t
 ecc_gostdsa_sign_itch (const struct ecc_curve *ecc);
diff --git a/testsuite/.gitignore b/testsuite/.gitignore
index b8b36c2accc2..a2b3d52312cd 100644
--- a/testsuite/.gitignore
+++ b/testsuite/.gitignore
@@ -46,6 +46,7 @@
 /gostdsa-keygen-test
 /gostdsa-sign-test
 /gostdsa-verify-test
+/gostdsa-vko-test
 /gosthash94-test
 /hkdf-test
 /hmac-test
diff --git a/testsuite/.test-rules.make b/testsuite/.test-rules.make
index 922a2c7f1350..b340e3c1b7b9 100644
--- a/testsuite/.test-rules.make
+++ b/testsuite/.test-rules.make
@@ -301,6 +301,9 @@ gostdsa-verify-test$(EXEEXT): gostdsa-verify-test.$(OBJEXT)
 gostdsa-keygen-test$(EXEEXT): gostdsa-keygen-test.$(OBJEXT)
 	$(LINK) gostdsa-keygen-test.$(OBJEXT) $(TEST_OBJS) -o gostdsa-keygen-test$(EXEEXT)
 
+gostdsa-vko-test$(EXEEXT): gostdsa-vko-test.$(OBJEXT)
+	$(LINK) gostdsa-vko-test.$(OBJEXT) $(TEST_OBJS) -o gostdsa-vko-test$(EXEEXT)
+
 sha1-huge-test$(EXEEXT): sha1-huge-test.$(OBJEXT)
 	$(LINK) sha1-huge-test.$(OBJEXT) $(TEST_OBJS) -o sha1-huge-test$(EXEEXT)
 
diff --git a/testsuite/Makefile.in b/testsuite/Makefile.in
index 813467a548bd..9f87c86b1c2f 100644
--- a/testsuite/Makefile.in
+++ b/testsuite/Makefile.in
@@ -55,7 +55,7 @@ TS_HOGWEED_SOURCES = sexp-test.c sexp-format-test.c \
 		     eddsa-compress-test.c eddsa-sign-test.c \
 		     eddsa-verify-test.c ed25519-test.c ed448-test.c \
 		     gostdsa-sign-test.c gostdsa-verify-test.c \
-		     gostdsa-keygen-test.c
+		     gostdsa-keygen-test.c gostdsa-vko-test.c
 
 TS_SOURCES = $(TS_NETTLE_SOURCES) $(TS_HOGWEED_SOURCES)
 CXX_SOURCES = cxx-test.cxx
diff --git a/testsuite/gostdsa-vko-test.c b/testsuite/gostdsa-vko-test.c
new file mode 100644
index 000000000000..9c86774198ed
--- /dev/null
+++ b/testsuite/gostdsa-vko-test.c
@@ -0,0 +1,92 @@
+#include "testutils.h"
+#include "gostdsa.h"
+#include "streebog.h"
+
+static void
+test_vko (const struct ecc_curve *ecc,
+	  const char *priv,
+	  const char *x,
+	  const char *y,
+	  const struct tstring *ukm,
+	  const struct nettle_hash *hash,
+	  void * hash_ctx,
+	  const struct tstring *res)
+{
+    struct ecc_scalar ecc_key;
+    struct ecc_point ecc_pub;
+    mpz_t temp1, temp2;
+    int ret;
+    uint8_t out[128];
+
+    ecc_point_init (&amp;ecc_pub, ecc);
+    mpz_init_set_str (temp1, x, 16);
+    mpz_init_set_str (temp2, y, 16);
+    ASSERT (ecc_point_set (&amp;ecc_pub, temp1, temp2) != 0);
+
+    ecc_scalar_init (&amp;ecc_key, ecc);
+    mpz_set_str (temp1, priv, 16);
+    ASSERT (ecc_scalar_set (&amp;ecc_key, temp1) != 0);
+
+    mpz_clear (temp1);
+    mpz_clear (temp2);
+
+    ret = gostdsa_vko (&amp;ecc_key, &amp;ecc_pub,
+		       ukm-&gt;length, ukm-&gt;data,
+		       sizeof(out), out);
+    ASSERT (ret != 0);
+
+    ecc_scalar_clear (&amp;ecc_key);
+    ecc_point_clear (&amp;ecc_pub);
+
+    hash-&gt;init (hash_ctx);
+    hash-&gt;update (hash_ctx, ret, out);
+    hash-&gt;digest (hash_ctx, hash-&gt;digest_size, out);
+
+    ASSERT (hash-&gt;digest_size == res-&gt;length);
+    ASSERT (MEMEQ (res-&gt;length, out, res-&gt;data));
+}
+
+void
+test_main (void)
+{
+    struct streebog256_ctx ctx_256;
+    struct streebog256_ctx ctx_512;
+
+    test_vko(nettle_get_gost_gc512a(),
+	     "67b63ca4ac8d2bb32618d89296c7476dbeb9f9048496f202b1902cf2ce41dbc2f847712d960483458d4b380867f426c7ca0ff5782702dbc44ee8fc72d9ec90c9",
 +	     "51a6d54ee932d176e87591121cce5f395cb2f2f147114d95f463c8a7ed74a9fc5ecd2325a35fb6387831ea66bc3d2aa42ede35872cc75372073a71b983e12f19",
 +	     "793bde5bf72840ad22b02a363ae4772d4a52fc08ba1a20f7458a222a13bf98b53be002d1973f1e398ce46c17da6d00d9b6d0076f8284dcc42e599b4c413b8804",
 +	     SHEX("1d 80 60 3c 85 44 c7 27"),
+	     &amp;nettle_streebog256,
+	     &amp;ctx_256,
+	     SHEX("c9 a9 a7 73 20 e2 cc 55 9e d7 2d ce 6f 47 e2 19 2c ce a9 5f a6 48 67 05 \
82 c0 54 c0 ef 36 c2 21")); +
+    test_vko(nettle_get_gost_gc512a(),
+	     "dbd09213a592da5bbfd8ed068cccccbbfbeda4feac96b9b4908591440b0714803b9eb763ef932266d4c0181a9b73eacf9013efc65ec07c888515f1b6f759c848",
 +	     "a7c0adb12743c10c3c1beb97c8f631242f7937a1deb6bce5e664e49261baccd3f5dc56ec53b2abb90ca1eb703078ba546655a8b99f79188d2021ffaba4edb0aa",
 +	     "5adb1c63a4e4465e0bbefd897fb9016475934cfa0f8c95f992ea402d47921f46382d00481b720314b19d8c878e75d81b9763358dd304b2ed3a364e07a3134691",
 +	     SHEX("1d 80 60 3c 85 44 c7 27"),
+	     &amp;nettle_streebog256,
+	     &amp;ctx_256,
+	     SHEX("c9 a9 a7 73 20 e2 cc 55 9e d7 2d ce 6f 47 e2 19 2c ce a9 5f a6 48 67 05 \
82 c0 54 c0 ef 36 c2 21")); +
+    test_vko(nettle_get_gost_gc512a(),
+	     "67b63ca4ac8d2bb32618d89296c7476dbeb9f9048496f202b1902cf2ce41dbc2f847712d960483458d4b380867f426c7ca0ff5782702dbc44ee8fc72d9ec90c9",
 +	     "51a6d54ee932d176e87591121cce5f395cb2f2f147114d95f463c8a7ed74a9fc5ecd2325a35fb6387831ea66bc3d2aa42ede35872cc75372073a71b983e12f19",
 +	     "793bde5bf72840ad22b02a363ae4772d4a52fc08ba1a20f7458a222a13bf98b53be002d1973f1e398ce46c17da6d00d9b6d0076f8284dcc42e599b4c413b8804",
 +	     SHEX("1d 80 60 3c 85 44 c7 27"),
+	     &amp;nettle_streebog512,
+	     &amp;ctx_512,
+	     SHEX("79 f0 02 a9 69 40 ce 7b de 32 59 a5 2e 01 52 97 ad aa d8 45 97 a0 d2 05 \
b5 0e 3e 17 19 f9 7b fa" +		  "7e e1 d2 66 1f a9 97 9a 5a a2 35 b5 58 a7 e6 d9 f8 8f \
98 2d d6 3f c3 5a 8e c0 dd 5e 24 2d 3b df")); +
+    test_vko(nettle_get_gost_gc512a(),
+	     "dbd09213a592da5bbfd8ed068cccccbbfbeda4feac96b9b4908591440b0714803b9eb763ef932266d4c0181a9b73eacf9013efc65ec07c888515f1b6f759c848",
 +	     "a7c0adb12743c10c3c1beb97c8f631242f7937a1deb6bce5e664e49261baccd3f5dc56ec53b2abb90ca1eb703078ba546655a8b99f79188d2021ffaba4edb0aa",
 +	     "5adb1c63a4e4465e0bbefd897fb9016475934cfa0f8c95f992ea402d47921f46382d00481b720314b19d8c878e75d81b9763358dd304b2ed3a364e07a3134691",
 +	     SHEX("1d 80 60 3c 85 44 c7 27"),
+	     &amp;nettle_streebog512,
+	     &amp;ctx_512,
+	     SHEX("79 f0 02 a9 69 40 ce 7b de 32 59 a5 2e 01 52 97 ad aa d8 45 97 a0 d2 05 \
b5 0e 3e 17 19 f9 7b fa" +		  "7e e1 d2 66 1f a9 97 9a 5a a2 35 b5 58 a7 e6 d9 f8 8f \
98 2d d6 3f c3 5a 8e c0 dd 5e 24 2d 3b df")); +}
-- 
2.25.0

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200202013822</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-02-02 01:38:22-0400</timestampReceived><subject>Crash on Core-i7 8700 machine with --enable-x86-aesni and --enable-x86-sha-ni</subject><body>

Hi Everyone,

I'm catching a crash with Nettle 3.5.1 on a Core-i7 8700 configured
with --enable-x86-aesni and --enable-x86-sha-ni. I verified the
compiler supports both AESNI and SHA.

    Illegal instruction (core dumped)
    FAIL: hkdf
    PASS: salsa20
    Illegal instruction (core dumped)
    FAIL: sha1
    Illegal instruction (core dumped)
    FAIL: sha224
    Illegal instruction (core dumped)
    FAIL: sha256

The machine is not configured with --enable-fat because of build
failures on other platforms. On other platforms, --enable-fat causes
SHA to be built even when the compiler does not support SHA. To avoid
the compile error I dropped --enable-fat .

So my question now is, how do I enable AES and SHA at compile time
depending on the compiler support, and enable runtime switching?

Thanks

-------

Here is the logic I was trying to use. It accommodates both Linux and Solaris.

AESNI_OPT=$("$CC" "$CFLAGS" -dM -E -maes - &lt;/dev/null 2&gt;&amp;1 | grep -i
-c "__AES__")
SHANI_OPT=$("$CC" "$CFLAGS" -dM -E -msha - &lt;/dev/null 2&gt;&amp;1 | grep -i
-c "__SHA__")

if [[ "$AESNI_OPT" -eq 1 ]]; then
    echo "Compiler supports AES-NI. Adding --enable-x86-aesni"
    CONFIG_OPTS+=("--enable-x86-aesni")
fi

if [[ "$SHANI_OPT" -eq 1 ]]; then
    echo "Compiler supports SHA-NI. Adding --enable-x86-sha-ni"
    CONFIG_OPTS+=("--enable-x86-sha-ni")
fi

# Crash on Solaris machines with --enable-fat
#if [[ "$IS_IA32" -ne 0 ]]; then
#    echo "Using runtime algorithm selection. Adding --enable-fat"
#    CONFIG_OPTS+=("--enable-fat")
#fi
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200215205947</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-02-15 20:59:47-0400</timestampReceived><subject>[PATCH 1/2] Change ecc_mod_*mul_1 to be per-module callbacks</subject><body>

From: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;

GOST curves will require different "fixups" for fast (mul X mod p)
operations. Move these operations to ecc_modulo structure and call them
via function pointer.

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 ecc-add-jja.c     |  8 ++++----
 ecc-add-jjj.c     |  8 ++++----
 ecc-curve25519.c  |  6 ++++++
 ecc-curve448.c    |  6 ++++++
 ecc-dup-jj.c      |  8 ++++----
 ecc-gost-gc256b.c |  6 ++++++
 ecc-gost-gc512a.c |  6 ++++++
 ecc-internal.h    | 25 ++++++++++++++++---------
 ecc-mod-arith.c   | 12 ++++++------
 ecc-mul-m.c       |  6 +++---
 ecc-secp192r1.c   |  6 ++++++
 ecc-secp224r1.c   |  6 ++++++
 ecc-secp256r1.c   |  6 ++++++
 ecc-secp384r1.c   |  6 ++++++
 ecc-secp521r1.c   |  6 ++++++
 15 files changed, 91 insertions(+), 30 deletions(-)

diff --git a/ecc-add-jja.c b/ecc-add-jja.c
index 037711d38249..55ad954587da 100644
--- a/ecc-add-jja.c
+++ b/ecc-add-jja.c
@@ -102,10 +102,10 @@ ecc_add_jja (const struct ecc_curve *ecc,
   /* w */
   ecc_mod_mul (&amp;ecc-&gt;p, j, y2, w);
   ecc_mod_sub (&amp;ecc-&gt;p, w, j, y1);
-  ecc_mod_mul_1 (&amp;ecc-&gt;p, w, w, 2);
+  ecc-&gt;p.mul_1 (&amp;ecc-&gt;p, w, w, 2);
   
   /* i replaces hh, j */
-  ecc_mod_mul_1 (&amp;ecc-&gt;p, hh, hh, 4);
+  ecc-&gt;p.mul_1 (&amp;ecc-&gt;p, hh, hh, 4);
   ecc_mod_mul (&amp;ecc-&gt;p, j, hh, h);
 
   /* v */
@@ -114,12 +114,12 @@ ecc_add_jja (const struct ecc_curve *ecc,
   /* x_3, use (h, hh) as sqratch */  
   ecc_mod_sqr (&amp;ecc-&gt;p, h, w);
   ecc_mod_sub (&amp;ecc-&gt;p, r, h, j);
-  ecc_mod_submul_1 (&amp;ecc-&gt;p, r, v, 2);
+  ecc-&gt;p.submul_1 (&amp;ecc-&gt;p, r, v, 2);
 
   /* y_3, use (h, hh) as sqratch */
   ecc_mod_mul (&amp;ecc-&gt;p, h, y1, j); /* frees j */
   ecc_mod_sub (&amp;ecc-&gt;p, r + ecc-&gt;p.size, v, r);
   ecc_mod_mul (&amp;ecc-&gt;p, j, r + ecc-&gt;p.size, w);
-  ecc_mod_submul_1 (&amp;ecc-&gt;p, j, h, 2);
+  ecc-&gt;p.submul_1 (&amp;ecc-&gt;p, j, h, 2);
   mpn_copyi (r + ecc-&gt;p.size, j, ecc-&gt;p.size);
 }
diff --git a/ecc-add-jjj.c b/ecc-add-jjj.c
index 54b2246aeb24..cad26193234a 100644
--- a/ecc-add-jjj.c
+++ b/ecc-add-jjj.c
@@ -94,14 +94,14 @@ ecc_add_jjj (const struct ecc_curve *ecc,
   ecc_mod_mul (&amp;ecc-&gt;p, s1, p + ecc-&gt;p.size, v);
   ecc_mod_mul (&amp;ecc-&gt;p, v, j, q + ecc-&gt;p.size);
   ecc_mod_sub (&amp;ecc-&gt;p, s2, v, s1);
-  ecc_mod_mul_1 (&amp;ecc-&gt;p, s2, s2, 2);
+  ecc-&gt;p.mul_1 (&amp;ecc-&gt;p, s2, s2, 2);
 
   /* Store z3 */
   mpn_copyi (r + 2*ecc-&gt;p.size, i, ecc-&gt;p.size);
 
   /* i, j, v */
   ecc_mod_sqr (&amp;ecc-&gt;p, i, u2);
-  ecc_mod_mul_1 (&amp;ecc-&gt;p, i, i, 4);
+  ecc-&gt;p.mul_1 (&amp;ecc-&gt;p, i, i, 4);
   ecc_mod_mul (&amp;ecc-&gt;p, j, u2, i);
   ecc_mod_mul (&amp;ecc-&gt;p, v, u1, i);
 
@@ -109,12 +109,12 @@ ecc_add_jjj (const struct ecc_curve *ecc,
   /* x3, use u1, u2 as scratch */
   ecc_mod_sqr (&amp;ecc-&gt;p, u1, s2);
   ecc_mod_sub (&amp;ecc-&gt;p, r, u1, j);
-  ecc_mod_submul_1 (&amp;ecc-&gt;p, r, v, 2);
+  ecc-&gt;p.submul_1 (&amp;ecc-&gt;p, r, v, 2);
 
   /* y3 */
   ecc_mod_mul (&amp;ecc-&gt;p, u1, s1, j); /* Frees j */
   ecc_mod_sub (&amp;ecc-&gt;p, u2, v, r);  /* Frees v */
   ecc_mod_mul (&amp;ecc-&gt;p, i, s2, u2);
-  ecc_mod_submul_1 (&amp;ecc-&gt;p, i, u1, 2);
+  ecc-&gt;p.submul_1 (&amp;ecc-&gt;p, i, u1, 2);
   mpn_copyi (r + ecc-&gt;p.size, i, ecc-&gt;p.size);
 }
diff --git a/ecc-curve25519.c b/ecc-curve25519.c
index f8f2c64af868..04df696f7357 100644
--- a/ecc-curve25519.c
+++ b/ecc-curve25519.c
@@ -310,6 +310,9 @@ const struct ecc_curve _nettle_curve25519 =
     ecc_curve25519_modp,
     ecc_curve25519_inv,
     ecc_curve25519_sqrt,
+
+    ecc_mod_mul_1_std,
+    ecc_mod_submul_1_std,
   },
   {
     253,
@@ -329,6 +332,9 @@ const struct ecc_curve _nettle_curve25519 =
     ecc_curve25519_modq,
     ecc_mod_inv,
     NULL,
+
+    NULL,
+    NULL,
   },
 
   0, /* No redc */
diff --git a/ecc-curve448.c b/ecc-curve448.c
index 484b7d1e0870..ce7a25d14c4e 100644
--- a/ecc-curve448.c
+++ b/ecc-curve448.c
@@ -288,6 +288,9 @@ const struct ecc_curve _nettle_curve448 =
     ecc_curve448_modp,
     ecc_curve448_inv,
     ecc_curve448_sqrt,
+
+    ecc_mod_mul_1_std,
+    ecc_mod_submul_1_std,
   },
   {
     446,
@@ -307,6 +310,9 @@ const struct ecc_curve _nettle_curve448 =
     ecc_mod,	      /* FIXME: Implement optimized reduce function */
     ecc_mod_inv,
     NULL,
+
+    NULL,
+    NULL,
   },
 
   0, /* No redc */
diff --git a/ecc-dup-jj.c b/ecc-dup-jj.c
index 2247e8fdfd5a..4bbd5163c0e3 100644
--- a/ecc-dup-jj.c
+++ b/ecc-dup-jj.c
@@ -87,7 +87,7 @@ ecc_dup_jj (const struct ecc_curve *ecc,
   ecc_mod_add (&amp;ecc-&gt;p, sum, xp, delta);
   ecc_mod_sub (&amp;ecc-&gt;p, delta, xp, delta);
   ecc_mod_mul (&amp;ecc-&gt;p, beta, sum, delta);
-  ecc_mod_mul_1 (&amp;ecc-&gt;p, alpha, beta, 3);
+  ecc-&gt;p.mul_1 (&amp;ecc-&gt;p, alpha, beta, 3);
 
   /* beta */
   ecc_mod_mul (&amp;ecc-&gt;p, beta, xp, gamma);
@@ -95,16 +95,16 @@ ecc_dup_jj (const struct ecc_curve *ecc,
   /* Do gamma^2 and 4*beta early, to get them out of the way. We can
      then use the old area at gamma as scratch. */
   ecc_mod_sqr (&amp;ecc-&gt;p, g2, gamma);
-  ecc_mod_mul_1 (&amp;ecc-&gt;p, sum, beta, 4);
+  ecc-&gt;p.mul_1 (&amp;ecc-&gt;p, sum, beta, 4);
   
   /* x' */
   ecc_mod_sqr (&amp;ecc-&gt;p, gamma, alpha);   /* Overwrites gamma and beta */
-  ecc_mod_submul_1 (&amp;ecc-&gt;p, gamma, sum, 2);
+  ecc-&gt;p.submul_1 (&amp;ecc-&gt;p, gamma, sum, 2);
   mpn_copyi (r, gamma, ecc-&gt;p.size);
 
   /* y' */
   ecc_mod_sub (&amp;ecc-&gt;p, sum, sum, r);
   ecc_mod_mul (&amp;ecc-&gt;p, gamma, sum, alpha);
-  ecc_mod_submul_1 (&amp;ecc-&gt;p, gamma, g2, 8);
+  ecc-&gt;p.submul_1 (&amp;ecc-&gt;p, gamma, g2, 8);
   mpn_copyi (r + ecc-&gt;p.size, gamma, ecc-&gt;p.size);
 }
diff --git a/ecc-gost-gc256b.c b/ecc-gost-gc256b.c
index a23d46fc8af6..24e1ac6c99a7 100644
--- a/ecc-gost-gc256b.c
+++ b/ecc-gost-gc256b.c
@@ -77,6 +77,9 @@ const struct ecc_curve _nettle_gost_gc256b =
     ecc_gost_gc256b_modp,
     ecc_mod_inv,
     NULL,
+
+    ecc_mod_mul_1_std,
+    ecc_mod_submul_1_std,
   },
   {
     256,
@@ -96,6 +99,9 @@ const struct ecc_curve _nettle_gost_gc256b =
     ecc_gost_gc256b_modq,
     ecc_mod_inv,
     NULL,
+
+    NULL,
+    NULL,
   },
 
   USE_REDC,
diff --git a/ecc-gost-gc512a.c b/ecc-gost-gc512a.c
index 398762c337d6..5de4eda85d9c 100644
--- a/ecc-gost-gc512a.c
+++ b/ecc-gost-gc512a.c
@@ -77,6 +77,9 @@ const struct ecc_curve _nettle_gost_gc512a =
     ecc_gost_gc512a_modp,
     ecc_mod_inv,
     NULL,
+
+    ecc_mod_mul_1_std,
+    ecc_mod_submul_1_std,
   },
   {
     512,
@@ -96,6 +99,9 @@ const struct ecc_curve _nettle_gost_gc512a =
     ecc_gost_gc512a_modq,
     ecc_mod_inv,
     NULL,
+
+    NULL,
+    NULL,
   },
 
   USE_REDC,
diff --git a/ecc-internal.h b/ecc-internal.h
index 9e24e0ce4521..e1380bfb2b20 100644
--- a/ecc-internal.h
+++ b/ecc-internal.h
@@ -44,9 +44,9 @@
 #define ecc_pm1_redc _nettle_ecc_pm1_redc
 #define ecc_mod_add _nettle_ecc_mod_add
 #define ecc_mod_sub _nettle_ecc_mod_sub
-#define ecc_mod_mul_1 _nettle_ecc_mod_mul_1
-#define ecc_mod_addmul_1 _nettle_ecc_mod_addmul_1
-#define ecc_mod_submul_1 _nettle_ecc_mod_submul_1
+#define ecc_mod_mul_1_std _nettle_ecc_mod_mul_1_std
+#define ecc_mod_addmul_1_std _nettle_ecc_mod_addmul_1_std
+#define ecc_mod_submul_1_std _nettle_ecc_mod_submul_1_std
 #define ecc_mod_mul _nettle_ecc_mod_mul
 #define ecc_mod_sqr _nettle_ecc_mod_sqr
 #define ecc_mod_random _nettle_ecc_mod_random
@@ -146,6 +146,10 @@ typedef void ecc_h_to_a_func (const struct ecc_curve *ecc,
 			      mp_limb_t *r, const mp_limb_t *p,
 			      mp_limb_t *scratch);
 
+typedef void ecc_mod_mul_1_func (const struct ecc_modulo *m,
+				 mp_limb_t *rp,
+				 const mp_limb_t *ap, mp_limb_t b);
+
 struct ecc_modulo
 {
   unsigned short bit_size;
@@ -170,6 +174,9 @@ struct ecc_modulo
   ecc_mod_func *reduce;
   ecc_mod_inv_func *invert;
   ecc_mod_sqrt_func *sqrt;
+
+  ecc_mod_mul_1_func *mul_1;
+  ecc_mod_mul_1_func *submul_1;
 };
 
 /* Represents an elliptic curve of the form
@@ -237,15 +244,15 @@ ecc_mod_sub (const struct ecc_modulo *m, mp_limb_t *rp,
 	     const mp_limb_t *ap, const mp_limb_t *bp);
 
 void
-ecc_mod_mul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
-	       const mp_limb_t *ap, const mp_limb_t b);
+ecc_mod_mul_1_std (const struct ecc_modulo *m, mp_limb_t *rp,
+		   const mp_limb_t *ap, const mp_limb_t b);
 
 void
-ecc_mod_addmul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
-		  const mp_limb_t *ap, mp_limb_t b);
+ecc_mod_addmul_1_std (const struct ecc_modulo *m, mp_limb_t *rp,
+		      const mp_limb_t *ap, mp_limb_t b);
 void
-ecc_mod_submul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
-		  const mp_limb_t *ap, mp_limb_t b);
+ecc_mod_submul_1_std (const struct ecc_modulo *m, mp_limb_t *rp,
+		      const mp_limb_t *ap, mp_limb_t b);
 
 /* The mul and sqr functions need 2*m-&gt;size limbs at rp */
 void
diff --git a/ecc-mod-arith.c b/ecc-mod-arith.c
index f2e47f6747c1..0399a2cdd7c5 100644
--- a/ecc-mod-arith.c
+++ b/ecc-mod-arith.c
@@ -65,8 +65,8 @@ ecc_mod_sub (const struct ecc_modulo *m, mp_limb_t *rp,
 }
 
 void
-ecc_mod_mul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
-	       const mp_limb_t *ap, mp_limb_t b)
+ecc_mod_mul_1_std (const struct ecc_modulo *m, mp_limb_t *rp,
+		   const mp_limb_t *ap, mp_limb_t b)
 {
   mp_limb_t hi;
 
@@ -80,8 +80,8 @@ ecc_mod_mul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
 }
 
 void
-ecc_mod_addmul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
-		  const mp_limb_t *ap, mp_limb_t b)
+ecc_mod_addmul_1_std (const struct ecc_modulo *m, mp_limb_t *rp,
+		      const mp_limb_t *ap, mp_limb_t b)
 {
   mp_limb_t hi;
 
@@ -95,8 +95,8 @@ ecc_mod_addmul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
 }
   
 void
-ecc_mod_submul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
-		  const mp_limb_t *ap, mp_limb_t b)
+ecc_mod_submul_1_std (const struct ecc_modulo *m, mp_limb_t *rp,
+		      const mp_limb_t *ap, mp_limb_t b)
 {
   mp_limb_t hi;
 
diff --git a/ecc-mul-m.c b/ecc-mul-m.c
index 68bdd16e8e94..539b9d0677e7 100644
--- a/ecc-mul-m.c
+++ b/ecc-mul-m.c
@@ -80,7 +80,7 @@ ecc_mul_m (const struct ecc_modulo *m,
   ecc_mod_sqr (m, BB, B);
   ecc_mod_mul (m, x3, AA, BB);
   ecc_mod_sub (m, E, AA, BB);
-  ecc_mod_addmul_1 (m, AA, E, a24);
+  ecc_mod_addmul_1_std (m, AA, E, a24);
   ecc_mod_mul (m, z3, E, AA);
 
   for (i = bit_high; i &gt;= bit_low; i--)
@@ -98,7 +98,7 @@ ecc_mul_m (const struct ecc_modulo *m,
       ecc_mod_sqr (m, BB, B);
       ecc_mod_mul (m, x2, AA, BB); /* Last use of BB */
       ecc_mod_sub (m, E, AA, BB);
-      ecc_mod_addmul_1 (m, AA, E, a24);
+      ecc_mod_addmul_1_std (m, AA, E, a24);
       ecc_mod_add (m, C, x3, z3);
       ecc_mod_sub (m, D, x3, z3);
       ecc_mod_mul (m, z2, E, AA); /* Last use of E and AA */
@@ -124,7 +124,7 @@ ecc_mul_m (const struct ecc_modulo *m,
       ecc_mod_sqr (m, BB, B);
       ecc_mod_mul (m, x2, AA, BB);
       ecc_mod_sub (m, E, AA, BB);
-      ecc_mod_addmul_1 (m, AA, E, a24);
+      ecc_mod_addmul_1_std (m, AA, E, a24);
       ecc_mod_mul (m, z2, E, AA);
     }
   assert (m-&gt;invert_itch &lt;= 7 * m-&gt;size);
diff --git a/ecc-secp192r1.c b/ecc-secp192r1.c
index 046026f3f697..79080495ec7e 100644
--- a/ecc-secp192r1.c
+++ b/ecc-secp192r1.c
@@ -130,6 +130,9 @@ const struct ecc_curve _nettle_secp_192r1 =
     ecc_secp192r1_modp,
     ecc_mod_inv,
     NULL,
+
+    ecc_mod_mul_1_std,
+    ecc_mod_submul_1_std,
   },
   {
     192,
@@ -149,6 +152,9 @@ const struct ecc_curve _nettle_secp_192r1 =
     ecc_mod,
     ecc_mod_inv,
     NULL,
+
+    NULL,
+    NULL,
   },
   
   USE_REDC,
diff --git a/ecc-secp224r1.c b/ecc-secp224r1.c
index 05d84017a68a..064a9e2f7fd4 100644
--- a/ecc-secp224r1.c
+++ b/ecc-secp224r1.c
@@ -82,6 +82,9 @@ const struct ecc_curve _nettle_secp_224r1 =
     USE_REDC ? ecc_secp224r1_redc : ecc_secp224r1_modp,
     ecc_mod_inv,
     NULL,
+
+    ecc_mod_mul_1_std,
+    ecc_mod_submul_1_std,
   },
   {
     224,
@@ -101,6 +104,9 @@ const struct ecc_curve _nettle_secp_224r1 =
     ecc_mod,
     ecc_mod_inv,
     NULL,
+
+    NULL,
+    NULL,
   },
   
   USE_REDC,
diff --git a/ecc-secp256r1.c b/ecc-secp256r1.c
index d399642453d5..0a25a086f3fe 100644
--- a/ecc-secp256r1.c
+++ b/ecc-secp256r1.c
@@ -259,6 +259,9 @@ const struct ecc_curve _nettle_secp_256r1 =
     USE_REDC ? ecc_secp256r1_redc : ecc_secp256r1_modp,
     ecc_mod_inv,
     NULL,
+
+    ecc_mod_mul_1_std,
+    ecc_mod_submul_1_std,
   },
   {
     256,
@@ -278,6 +281,9 @@ const struct ecc_curve _nettle_secp_256r1 =
     ecc_secp256r1_modq,
     ecc_mod_inv,
     NULL,
+
+    NULL,
+    NULL,
   },
 
   USE_REDC,
diff --git a/ecc-secp384r1.c b/ecc-secp384r1.c
index 54bcd1128d39..5a9131f72c98 100644
--- a/ecc-secp384r1.c
+++ b/ecc-secp384r1.c
@@ -167,6 +167,9 @@ const struct ecc_curve _nettle_secp_384r1 =
     ecc_secp384r1_modp,
     ecc_mod_inv,
     NULL,
+
+    ecc_mod_mul_1_std,
+    ecc_mod_submul_1_std,
   },
   {
     384,
@@ -186,6 +189,9 @@ const struct ecc_curve _nettle_secp_384r1 =
     ecc_mod,
     ecc_mod_inv,
     NULL,
+
+    NULL,
+    NULL,
   },
 
   USE_REDC,
diff --git a/ecc-secp521r1.c b/ecc-secp521r1.c
index 776f7ae03e27..f01a97537eb8 100644
--- a/ecc-secp521r1.c
+++ b/ecc-secp521r1.c
@@ -95,6 +95,9 @@ const struct ecc_curve _nettle_secp_521r1 =
     ecc_secp521r1_modp,
     ecc_mod_inv,
     NULL,
+
+    ecc_mod_mul_1_std,
+    ecc_mod_submul_1_std,
   },
   {
     521,
@@ -114,6 +117,9 @@ const struct ecc_curve _nettle_secp_521r1 =
     ecc_mod,
     ecc_mod_inv,
     NULL,
+
+    NULL,
+    NULL,
   },
   
   USE_REDC,
-- 
2.25.0

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200201145717</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-02-01 14:57:17-0400</timestampReceived><subject>Please use -shared on Solaris. Don't use -G on Solaris</subject><body>

When linking the shared object with -G on Solaris:

gcc -g2 -O2 -m64 -march=native -fPIC -pthread  -Wno-pointer-sign -Wall
-W   -Wmissing-prototypes -Wmissing-declarations -Wstrict-prototypes
-Wpointer-arith -Wbad-function-cast -Wnested-externs -L/usr/local/lib
-m64 -Wl,-R,'$ORIGIN/../lib' -Wl,-R,/usr/local/lib -G -h
libnettle.so.7 aes-decrypt-internal.o aes-decrypt.o
aes-encrypt-internal.o aes-encrypt.o aes-encrypt-table.o ...

It results in:

ld.so.1: aes-test: fatal: relocation error: R_AMD64_PC32: file
../.lib/libhogweed.so.5: symbol _init: value 0x7f004df15e9d does not
fit
../run-tests: line 61: 12934: Killed
FAIL: aes
ld.so.1: arcfour-test: fatal: relocation error: R_AMD64_PC32: file
../.lib/libhogweed.so.5: symbol _init: value 0x7f004df15a1d does not
fit
../run-tests: line 61: 12939: Killed
FAIL: arcfour
ld.so.1: arctwo-test: fatal: relocation error: R_AMD64_PC32: file
../.lib/libhogweed.so.5: symbol _init: value 0x7f004df153dd does not
fit
../run-tests: line 61: 12944: Killed
FAIL: arctwo
...

Here's the full paste of the build using -G: https://pastebin.com/SKZxKfdZ.

Please use -shared, not -G. -shared works as expected on Solaris.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200204132926</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-02-04 13:29:26-0400</timestampReceived><subject>[PATCH] gost28147: move gost params to internal interface</subject><body>

From: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;

gost28147_param instances were never a part of stable release, so move
them to internal header.

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 Makefile.in          |  2 +-
 gost28147-internal.h | 12 +++++++++
 gost28147.c          |  5 ++--
 gost28147.h          | 58 --------------------------------------------
 gosthash94.c         |  9 +++----
 5 files changed, 19 insertions(+), 67 deletions(-)
 delete mode 100644 gost28147.h

diff --git a/Makefile.in b/Makefile.in
index f876e5e82197..0de54e85c7ae 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -207,7 +207,7 @@ HEADERS = aes.h arcfour.h arctwo.h asn1.h blowfish.h \
 	  cbc.h ccm.h cfb.h chacha.h chacha-poly1305.h ctr.h \
 	  curve25519.h curve448.h des.h dsa.h dsa-compat.h eax.h \
 	  ecc-curve.h ecc.h ecdsa.h eddsa.h \
-	  gcm.h gost28147.h gostdsa.h gosthash94.h hmac.h \
+	  gcm.h gostdsa.h gosthash94.h hmac.h \
 	  knuth-lfib.h hkdf.h \
 	  macros.h \
 	  cmac.h siv-cmac.h \
diff --git a/gost28147-internal.h b/gost28147-internal.h
index 7f5c6f8c63c0..0cb2d152c8ad 100644
--- a/gost28147-internal.h
+++ b/gost28147-internal.h
@@ -34,7 +34,19 @@
 #ifndef NETTLE_GOST28147_INTERNAL_H_INCLUDED
 #define NETTLE_GOST28147_INTERNAL_H_INCLUDED
 
+#include &lt;stdint.h&gt;
+
 #define _gost28147_encrypt_block _nettle_gost28147_encrypt_block
+#define _gost28147_param_test_3411 _nettle_gost28147_param_test_3411
+#define _gost28147_param_CryptoPro_3411 _nettle_gost28147_param_CryptoPro_3411
+
+extern const struct gost28147_param _gost28147_param_test_3411;
+extern const struct gost28147_param _gost28147_param_CryptoPro_3411;
+
+struct gost28147_param
+{
+  uint32_t sbox[4][256];
+};
 
 void _gost28147_encrypt_block (const uint32_t *key, const uint32_t sbox[4][256],
 			       const uint32_t *in, uint32_t *out);
diff --git a/gost28147.c b/gost28147.c
index 15d314c86c17..b6db334b2a0b 100644
--- a/gost28147.c
+++ b/gost28147.c
@@ -33,11 +33,10 @@
 #endif
 
 #include "macros.h"
-#include "gost28147.h"
 #include "gost28147-internal.h"
 
 /* pre-initialized GOST lookup tables based on rotated S-Box */
-const struct gost28147_param gost28147_param_test_3411 =
+const struct gost28147_param _gost28147_param_test_3411 =
 {
   {
     { /* 0 */
@@ -304,7 +303,7 @@ const struct gost28147_param gost28147_param_test_3411 =
   }
 };
 
-const struct gost28147_param gost28147_param_CryptoPro_3411 =
+const struct gost28147_param _gost28147_param_CryptoPro_3411 =
 {
   {
     { /* 0 */
diff --git a/gost28147.h b/gost28147.h
deleted file mode 100644
index 32e7d5e81eb8..000000000000
--- a/gost28147.h
+++ /dev/null
@@ -1,58 +0,0 @@
-/* gost28147.h
-
-   The GOST 28147-89 cipher function, described in RFC 5831.
-
-   Copyright (C) 2019 Dmitry Eremin-Solenikov
-
-   This file is part of GNU Nettle.
-
-   GNU Nettle is free software: you can redistribute it and/or
-   modify it under the terms of either:
-
-     * the GNU Lesser General Public License as published by the Free
-       Software Foundation; either version 3 of the License, or (at your
-       option) any later version.
-
-   or
-
-     * the GNU General Public License as published by the Free
-       Software Foundation; either version 2 of the License, or (at your
-       option) any later version.
-
-   or both in parallel, as here.
-
-   GNU Nettle is distributed in the hope that it will be useful,
-   but WITHOUT ANY WARRANTY; without even the implied warranty of
-   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-   General Public License for more details.
-
-   You should have received copies of the GNU General Public License and
-   the GNU Lesser General Public License along with this program.  If
-   not, see http://www.gnu.org/licenses/.
-*/
-
-#ifndef NETTLE_GOST28147_H_INCLUDED
-#define NETTLE_GOST28147_H_INCLUDED
-
-#include "nettle-types.h"
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-#define gost28147_param_test_3411 nettle_gost28147_param_test_3411
-#define gost28147_param_CryptoPro_3411 nettle_gost28147_param_CryptoPro_3411
-
-struct gost28147_param
-{
-  uint32_t sbox[4][256];
-};
-
-extern const struct gost28147_param gost28147_param_test_3411;
-extern const struct gost28147_param gost28147_param_CryptoPro_3411;
-
-#ifdef __cplusplus
-}
-#endif
-
-#endif /* NETTLE_GOST28147_H_INCLUDED */
diff --git a/gosthash94.c b/gosthash94.c
index 954130f741e9..37a7f32272df 100644
--- a/gosthash94.c
+++ b/gosthash94.c
@@ -41,7 +41,6 @@
 #include "macros.h"
 #include "nettle-write.h"
 #include "gosthash94.h"
-#include "gost28147.h"
 #include "gost28147-internal.h"
 
 /**
@@ -339,7 +338,7 @@ gosthash94_update (struct gosthash94_ctx *ctx,
 		   size_t length, const uint8_t *msg)
 {
   gosthash94_update_int (ctx, length, msg,
-			 gost28147_param_test_3411.sbox);
+			 _gost28147_param_test_3411.sbox);
 }
 
 /**
@@ -355,7 +354,7 @@ gosthash94cp_update (struct gosthash94_ctx *ctx,
 		     size_t length, const uint8_t *msg)
 {
   gosthash94_update_int (ctx, length, msg,
-			 gost28147_param_CryptoPro_3411.sbox);
+			 _gost28147_param_CryptoPro_3411.sbox);
 }
 
 /**
@@ -399,7 +398,7 @@ gosthash94_digest (struct gosthash94_ctx *ctx,
 		   size_t length, uint8_t *result)
 {
   gosthash94_write_digest (ctx, length, result,
-			   gost28147_param_test_3411.sbox);
+			   _gost28147_param_test_3411.sbox);
 }
 
 void
@@ -407,5 +406,5 @@ gosthash94cp_digest (struct gosthash94_ctx *ctx,
 		     size_t length, uint8_t *result)
 {
   gosthash94_write_digest (ctx, length, result,
-			   gost28147_param_CryptoPro_3411.sbox);
+			   _gost28147_param_CryptoPro_3411.sbox);
 }
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200210150933</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-02-10 15:09:33-0400</timestampReceived><subject>[PATCH] ecc: remove ecc_modp_foo/ecc_modq_foo macros</subject><body>

From: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;

To make ecc functions usage more obvious remove ecc_modp_foo() and
ecc_modq_foo() wrapper macros.

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 curve25519-eh-to-x.c |  8 +++----
 curve448-eh-to-x.c   |  4 ++--
 ecc-add-eh.c         | 38 +++++++++++++++----------------
 ecc-add-ehh.c        | 42 +++++++++++++++++-----------------
 ecc-add-jja.c        | 44 ++++++++++++++++++------------------
 ecc-add-jjj.c        | 54 ++++++++++++++++++++++----------------------
 ecc-add-th.c         | 38 +++++++++++++++----------------
 ecc-add-thh.c        | 42 +++++++++++++++++-----------------
 ecc-dup-eh.c         | 26 ++++++++++-----------
 ecc-dup-jj.c         | 36 ++++++++++++++---------------
 ecc-dup-th.c         | 26 ++++++++++-----------
 ecc-ecdsa-sign.c     |  6 ++---
 ecc-ecdsa-verify.c   |  4 ++--
 ecc-eh-to-a.c        |  4 ++--
 ecc-gostdsa-sign.c   |  6 ++---
 ecc-gostdsa-verify.c |  4 ++--
 ecc-internal.h       | 20 ----------------
 ecc-j-to-a.c         | 12 +++++-----
 eddsa-decompress.c   | 10 ++++----
 eddsa-sign.c         |  4 ++--
 20 files changed, 204 insertions(+), 224 deletions(-)

diff --git a/curve25519-eh-to-x.c b/curve25519-eh-to-x.c
index 3a8787f022ed..1ce2dd830c75 100644
--- a/curve25519-eh-to-x.c
+++ b/curve25519-eh-to-x.c
@@ -62,14 +62,14 @@ curve25519_eh_to_x (mp_limb_t *xp, const mp_limb_t *p,
   */
   /* NOTE: For the infinity point, this subtraction gives zero (mod
      p), which isn't invertible. For curve25519, the desired output is
-     x = 0, and we should be fine, since ecc_modp_inv returns 0
+     x = 0, and we should be fine, since ecc_mod_inv for ecc-&gt;p returns 0
      in this case. */
-  ecc_modp_sub (ecc, t0, wp, vp);
+  ecc_mod_sub (&amp;ecc-&gt;p, t0, wp, vp);
   /* Needs a total of 5*size storage. */
   ecc-&gt;p.invert (&amp;ecc-&gt;p, t1, t0, t2 + ecc-&gt;p.size);
   
-  ecc_modp_add (ecc, t0, wp, vp);
-  ecc_modp_mul (ecc, t2, t0, t1);
+  ecc_mod_add (&amp;ecc-&gt;p, t0, wp, vp);
+  ecc_mod_mul (&amp;ecc-&gt;p, t2, t0, t1);
 
   cy = mpn_sub_n (xp, t2, ecc-&gt;p.m, ecc-&gt;p.size);
   cnd_copy (cy, xp, t2, ecc-&gt;p.size);
diff --git a/curve448-eh-to-x.c b/curve448-eh-to-x.c
index 4bc78303f93b..ffeb83c15e44 100644
--- a/curve448-eh-to-x.c
+++ b/curve448-eh-to-x.c
@@ -61,8 +61,8 @@ curve448_eh_to_x (mp_limb_t *xp, const mp_limb_t *p, mp_limb_t *scratch)
   */
   /* Needs a total of 9*size storage. */
   ecc-&gt;p.invert (&amp;ecc-&gt;p, t0, p, t1 + ecc-&gt;p.size);
-  ecc_modp_mul (ecc, t1, t0, vp);
-  ecc_modp_mul (ecc, t2, t1, t1);
+  ecc_mod_mul (&amp;ecc-&gt;p, t1, t0, vp);
+  ecc_mod_mul (&amp;ecc-&gt;p, t2, t1, t1);
 
   cy = mpn_sub_n (xp, t2, ecc-&gt;p.m, ecc-&gt;p.size);
   cnd_copy (cy, xp, t2, ecc-&gt;p.size);
diff --git a/ecc-add-eh.c b/ecc-add-eh.c
index 8e6b82ab9fd0..05faa7526f41 100644
--- a/ecc-add-eh.c
+++ b/ecc-add-eh.c
@@ -78,30 +78,30 @@ ecc_add_eh (const struct ecc_curve *ecc,
 #define F D
 #define G E
 
-  ecc_modp_mul (ecc, C, x1, x2);
-  ecc_modp_mul (ecc, D, y1, y2);
-  ecc_modp_add (ecc, x3, x1, y1);
-  ecc_modp_add (ecc, y3, x2, y2);
-  ecc_modp_mul (ecc, T, x3, y3);
-  ecc_modp_sub (ecc, T, T, C);
-  ecc_modp_sub (ecc, T, T, D);
-  ecc_modp_mul (ecc, x3, C, D);
-  ecc_modp_mul (ecc, E, x3, ecc-&gt;b);
-
-  ecc_modp_sub (ecc, C, D, C);
-  ecc_modp_sqr (ecc, B, z1);
-  ecc_modp_sub (ecc, F, B, E);
-  ecc_modp_add (ecc, G, B, E);
+  ecc_mod_mul (&amp;ecc-&gt;p, C, x1, x2);
+  ecc_mod_mul (&amp;ecc-&gt;p, D, y1, y2);
+  ecc_mod_add (&amp;ecc-&gt;p, x3, x1, y1);
+  ecc_mod_add (&amp;ecc-&gt;p, y3, x2, y2);
+  ecc_mod_mul (&amp;ecc-&gt;p, T, x3, y3);
+  ecc_mod_sub (&amp;ecc-&gt;p, T, T, C);
+  ecc_mod_sub (&amp;ecc-&gt;p, T, T, D);
+  ecc_mod_mul (&amp;ecc-&gt;p, x3, C, D);
+  ecc_mod_mul (&amp;ecc-&gt;p, E, x3, ecc-&gt;b);
+
+  ecc_mod_sub (&amp;ecc-&gt;p, C, D, C);
+  ecc_mod_sqr (&amp;ecc-&gt;p, B, z1);
+  ecc_mod_sub (&amp;ecc-&gt;p, F, B, E);
+  ecc_mod_add (&amp;ecc-&gt;p, G, B, E);
 
   /* x3 */
-  ecc_modp_mul (ecc, B, F, T);
-  ecc_modp_mul (ecc, x3, B, z1);
+  ecc_mod_mul (&amp;ecc-&gt;p, B, F, T);
+  ecc_mod_mul (&amp;ecc-&gt;p, x3, B, z1);
 
   /* y3 */
-  ecc_modp_mul (ecc, B, G, z1);
-  ecc_modp_mul (ecc, y3, B, C); /* Clobbers z1 in case r == p. */
+  ecc_mod_mul (&amp;ecc-&gt;p, B, G, z1);
+  ecc_mod_mul (&amp;ecc-&gt;p, y3, B, C); /* Clobbers z1 in case r == p. */
 
   /* z3 */
-  ecc_modp_mul (ecc, B, F, G);
+  ecc_mod_mul (&amp;ecc-&gt;p, B, F, G);
   mpn_copyi (z3, B, ecc-&gt;p.size);
 }
diff --git a/ecc-add-ehh.c b/ecc-add-ehh.c
index bdd827ba396d..1c57a728c797 100644
--- a/ecc-add-ehh.c
+++ b/ecc-add-ehh.c
@@ -80,32 +80,32 @@ ecc_add_ehh (const struct ecc_curve *ecc,
 #define F D
 #define G E
 
-  ecc_modp_mul (ecc, C, x1, x2);
-  ecc_modp_mul (ecc, D, y1, y2);
-  ecc_modp_add (ecc, A, x1, y1);
-  ecc_modp_add (ecc, B, x2, y2);
-  ecc_modp_mul (ecc, T, A, B);
-  ecc_modp_sub (ecc, T, T, C);
-  ecc_modp_sub (ecc, T, T, D);
-  ecc_modp_mul (ecc, x3, C, D);
-  ecc_modp_mul (ecc, E, x3, ecc-&gt;b);
-  ecc_modp_sub (ecc, C, D, C);
-
-  ecc_modp_mul (ecc, A, z1, z2);
-  ecc_modp_sqr (ecc, B, A);
-
-  ecc_modp_sub (ecc, F, B, E);
-  ecc_modp_add (ecc, G, B, E);
+  ecc_mod_mul (&amp;ecc-&gt;p, C, x1, x2);
+  ecc_mod_mul (&amp;ecc-&gt;p, D, y1, y2);
+  ecc_mod_add (&amp;ecc-&gt;p, A, x1, y1);
+  ecc_mod_add (&amp;ecc-&gt;p, B, x2, y2);
+  ecc_mod_mul (&amp;ecc-&gt;p, T, A, B);
+  ecc_mod_sub (&amp;ecc-&gt;p, T, T, C);
+  ecc_mod_sub (&amp;ecc-&gt;p, T, T, D);
+  ecc_mod_mul (&amp;ecc-&gt;p, x3, C, D);
+  ecc_mod_mul (&amp;ecc-&gt;p, E, x3, ecc-&gt;b);
+  ecc_mod_sub (&amp;ecc-&gt;p, C, D, C);
+
+  ecc_mod_mul (&amp;ecc-&gt;p, A, z1, z2);
+  ecc_mod_sqr (&amp;ecc-&gt;p, B, A);
+
+  ecc_mod_sub (&amp;ecc-&gt;p, F, B, E);
+  ecc_mod_add (&amp;ecc-&gt;p, G, B, E);
 
   /* x3 */
-  ecc_modp_mul (ecc, B, F, T);
-  ecc_modp_mul (ecc, x3, B, A);
+  ecc_mod_mul (&amp;ecc-&gt;p, B, F, T);
+  ecc_mod_mul (&amp;ecc-&gt;p, x3, B, A);
 
   /* y3 */
-  ecc_modp_mul (ecc, B, G, C);
-  ecc_modp_mul (ecc, y3, B, A);
+  ecc_mod_mul (&amp;ecc-&gt;p, B, G, C);
+  ecc_mod_mul (&amp;ecc-&gt;p, y3, B, A);
 
   /* z3 */
-  ecc_modp_mul (ecc, B, F, G);
+  ecc_mod_mul (&amp;ecc-&gt;p, B, F, G);
   mpn_copyi (z3, B, ecc-&gt;p.size);
 }
diff --git a/ecc-add-jja.c b/ecc-add-jja.c
index 9b5cab9db315..037711d38249 100644
--- a/ecc-add-jja.c
+++ b/ecc-add-jja.c
@@ -85,41 +85,41 @@ ecc_add_jja (const struct ecc_curve *ecc,
 #define y2 (q + ecc-&gt;p.size)
 
   /* zz */
-  ecc_modp_sqr (ecc, zz, z1);
+  ecc_mod_sqr (&amp;ecc-&gt;p, zz, z1);
   /* h*/
-  ecc_modp_mul (ecc, h, x2, zz);
-  ecc_modp_sub (ecc, h, h, x1);
+  ecc_mod_mul (&amp;ecc-&gt;p, h, x2, zz);
+  ecc_mod_sub (&amp;ecc-&gt;p, h, h, x1);
   /* hh */
-  ecc_modp_sqr (ecc, hh, h);
+  ecc_mod_sqr (&amp;ecc-&gt;p, hh, h);
   /* Do z^3 early, store at w. */
-  ecc_modp_mul (ecc, w, zz, z1);
+  ecc_mod_mul (&amp;ecc-&gt;p, w, zz, z1);
   /* z_3, use j area for scratch */
-  ecc_modp_add (ecc, r + 2*ecc-&gt;p.size, p + 2*ecc-&gt;p.size, h);
-  ecc_modp_sqr (ecc, j, r + 2*ecc-&gt;p.size);
-  ecc_modp_sub (ecc, j, j, zz);
-  ecc_modp_sub (ecc, r + 2*ecc-&gt;p.size, j, hh);
+  ecc_mod_add (&amp;ecc-&gt;p, r + 2*ecc-&gt;p.size, p + 2*ecc-&gt;p.size, h);
+  ecc_mod_sqr (&amp;ecc-&gt;p, j, r + 2*ecc-&gt;p.size);
+  ecc_mod_sub (&amp;ecc-&gt;p, j, j, zz);
+  ecc_mod_sub (&amp;ecc-&gt;p, r + 2*ecc-&gt;p.size, j, hh);
   
   /* w */
-  ecc_modp_mul (ecc, j, y2, w);
-  ecc_modp_sub (ecc, w, j, y1);
-  ecc_modp_mul_1 (ecc, w, w, 2);
+  ecc_mod_mul (&amp;ecc-&gt;p, j, y2, w);
+  ecc_mod_sub (&amp;ecc-&gt;p, w, j, y1);
+  ecc_mod_mul_1 (&amp;ecc-&gt;p, w, w, 2);
   
   /* i replaces hh, j */
-  ecc_modp_mul_1 (ecc, hh, hh, 4);
-  ecc_modp_mul (ecc, j, hh, h);
+  ecc_mod_mul_1 (&amp;ecc-&gt;p, hh, hh, 4);
+  ecc_mod_mul (&amp;ecc-&gt;p, j, hh, h);
 
   /* v */
-  ecc_modp_mul (ecc, v, x1, hh);
+  ecc_mod_mul (&amp;ecc-&gt;p, v, x1, hh);
 
   /* x_3, use (h, hh) as sqratch */  
-  ecc_modp_sqr (ecc, h, w);
-  ecc_modp_sub (ecc, r, h, j);
-  ecc_modp_submul_1 (ecc, r, v, 2);
+  ecc_mod_sqr (&amp;ecc-&gt;p, h, w);
+  ecc_mod_sub (&amp;ecc-&gt;p, r, h, j);
+  ecc_mod_submul_1 (&amp;ecc-&gt;p, r, v, 2);
 
   /* y_3, use (h, hh) as sqratch */
-  ecc_modp_mul (ecc, h, y1, j); /* frees j */
-  ecc_modp_sub (ecc, r + ecc-&gt;p.size, v, r);
-  ecc_modp_mul (ecc, j, r + ecc-&gt;p.size, w);
-  ecc_modp_submul_1 (ecc, j, h, 2);
+  ecc_mod_mul (&amp;ecc-&gt;p, h, y1, j); /* frees j */
+  ecc_mod_sub (&amp;ecc-&gt;p, r + ecc-&gt;p.size, v, r);
+  ecc_mod_mul (&amp;ecc-&gt;p, j, r + ecc-&gt;p.size, w);
+  ecc_mod_submul_1 (&amp;ecc-&gt;p, j, h, 2);
   mpn_copyi (r + ecc-&gt;p.size, j, ecc-&gt;p.size);
 }
diff --git a/ecc-add-jjj.c b/ecc-add-jjj.c
index 1143e79a0b6f..54b2246aeb24 100644
--- a/ecc-add-jjj.c
+++ b/ecc-add-jjj.c
@@ -74,47 +74,47 @@ ecc_add_jjj (const struct ecc_curve *ecc,
   mp_limb_t *v    = scratch + 6*ecc-&gt;p.size;
 
   /* z1^2, z2^2, u1 = x1 x2^2, u2 = x2 z1^2 - u1 */
-  ecc_modp_sqr (ecc, z1z1, p + 2*ecc-&gt;p.size);
-  ecc_modp_sqr (ecc, z2z2, q + 2*ecc-&gt;p.size);
-  ecc_modp_mul (ecc, u1, p, z2z2);
-  ecc_modp_mul (ecc, u2, q, z1z1);
-  ecc_modp_sub (ecc, u2, u2, u1);  /* Store h in u2 */
+  ecc_mod_sqr (&amp;ecc-&gt;p, z1z1, p + 2*ecc-&gt;p.size);
+  ecc_mod_sqr (&amp;ecc-&gt;p, z2z2, q + 2*ecc-&gt;p.size);
+  ecc_mod_mul (&amp;ecc-&gt;p, u1, p, z2z2);
+  ecc_mod_mul (&amp;ecc-&gt;p, u2, q, z1z1);
+  ecc_mod_sub (&amp;ecc-&gt;p, u2, u2, u1);  /* Store h in u2 */
 
   /* z3, use i, j, v as scratch, result at i. */
-  ecc_modp_add (ecc, i, p + 2*ecc-&gt;p.size, q + 2*ecc-&gt;p.size);
-  ecc_modp_sqr (ecc, v, i);
-  ecc_modp_sub (ecc, v, v, z1z1);
-  ecc_modp_sub (ecc, v, v, z2z2);
-  ecc_modp_mul (ecc, i, v, u2);
+  ecc_mod_add (&amp;ecc-&gt;p, i, p + 2*ecc-&gt;p.size, q + 2*ecc-&gt;p.size);
+  ecc_mod_sqr (&amp;ecc-&gt;p, v, i);
+  ecc_mod_sub (&amp;ecc-&gt;p, v, v, z1z1);
+  ecc_mod_sub (&amp;ecc-&gt;p, v, v, z2z2);
+  ecc_mod_mul (&amp;ecc-&gt;p, i, v, u2);
   /* Delayed write, to support in-place operation. */
 
   /* s1 = y1 z2^3, s2 = y2 z1^3, scratch at j and v */
-  ecc_modp_mul (ecc, j, z1z1, p + 2*ecc-&gt;p.size); /* z1^3 */
-  ecc_modp_mul (ecc, v, z2z2, q + 2*ecc-&gt;p.size); /* z2^3 */
-  ecc_modp_mul (ecc, s1, p + ecc-&gt;p.size, v);
-  ecc_modp_mul (ecc, v, j, q + ecc-&gt;p.size);
-  ecc_modp_sub (ecc, s2, v, s1);
-  ecc_modp_mul_1 (ecc, s2, s2, 2);
+  ecc_mod_mul (&amp;ecc-&gt;p, j, z1z1, p + 2*ecc-&gt;p.size); /* z1^3 */
+  ecc_mod_mul (&amp;ecc-&gt;p, v, z2z2, q + 2*ecc-&gt;p.size); /* z2^3 */
+  ecc_mod_mul (&amp;ecc-&gt;p, s1, p + ecc-&gt;p.size, v);
+  ecc_mod_mul (&amp;ecc-&gt;p, v, j, q + ecc-&gt;p.size);
+  ecc_mod_sub (&amp;ecc-&gt;p, s2, v, s1);
+  ecc_mod_mul_1 (&amp;ecc-&gt;p, s2, s2, 2);
 
   /* Store z3 */
   mpn_copyi (r + 2*ecc-&gt;p.size, i, ecc-&gt;p.size);
 
   /* i, j, v */
-  ecc_modp_sqr (ecc, i, u2);
-  ecc_modp_mul_1 (ecc, i, i, 4);
-  ecc_modp_mul (ecc, j, u2, i);
-  ecc_modp_mul (ecc, v, u1, i);
+  ecc_mod_sqr (&amp;ecc-&gt;p, i, u2);
+  ecc_mod_mul_1 (&amp;ecc-&gt;p, i, i, 4);
+  ecc_mod_mul (&amp;ecc-&gt;p, j, u2, i);
+  ecc_mod_mul (&amp;ecc-&gt;p, v, u1, i);
 
   /* now, u1, u2 and i are free for reuse .*/
   /* x3, use u1, u2 as scratch */
-  ecc_modp_sqr (ecc, u1, s2);
-  ecc_modp_sub (ecc, r, u1, j);
-  ecc_modp_submul_1 (ecc, r, v, 2);
+  ecc_mod_sqr (&amp;ecc-&gt;p, u1, s2);
+  ecc_mod_sub (&amp;ecc-&gt;p, r, u1, j);
+  ecc_mod_submul_1 (&amp;ecc-&gt;p, r, v, 2);
 
   /* y3 */
-  ecc_modp_mul (ecc, u1, s1, j); /* Frees j */
-  ecc_modp_sub (ecc, u2, v, r);  /* Frees v */
-  ecc_modp_mul (ecc, i, s2, u2);
-  ecc_modp_submul_1 (ecc, i, u1, 2);
+  ecc_mod_mul (&amp;ecc-&gt;p, u1, s1, j); /* Frees j */
+  ecc_mod_sub (&amp;ecc-&gt;p, u2, v, r);  /* Frees v */
+  ecc_mod_mul (&amp;ecc-&gt;p, i, s2, u2);
+  ecc_mod_submul_1 (&amp;ecc-&gt;p, i, u1, 2);
   mpn_copyi (r + ecc-&gt;p.size, i, ecc-&gt;p.size);
 }
diff --git a/ecc-add-th.c b/ecc-add-th.c
index c19afbb5f7d4..1d61a32ea6ec 100644
--- a/ecc-add-th.c
+++ b/ecc-add-th.c
@@ -84,30 +84,30 @@ ecc_add_th (const struct ecc_curve *ecc,
 #define F D
 #define G E
 
-  ecc_modp_mul (ecc, C, x1, x2);
-  ecc_modp_mul (ecc, D, y1, y2);
-  ecc_modp_add (ecc, x3, x1, y1);
-  ecc_modp_add (ecc, y3, x2, y2);
-  ecc_modp_mul (ecc, T, x3, y3);
-  ecc_modp_sub (ecc, T, T, C);
-  ecc_modp_sub (ecc, T, T, D);
-  ecc_modp_mul (ecc, x3, C, D);
-  ecc_modp_mul (ecc, E, x3, ecc-&gt;b);
-
-  ecc_modp_add (ecc, C, D, C);
-  ecc_modp_sqr (ecc, B, z1);
-  ecc_modp_sub (ecc, F, B, E);
-  ecc_modp_add (ecc, G, B, E);
+  ecc_mod_mul (&amp;ecc-&gt;p, C, x1, x2);
+  ecc_mod_mul (&amp;ecc-&gt;p, D, y1, y2);
+  ecc_mod_add (&amp;ecc-&gt;p, x3, x1, y1);
+  ecc_mod_add (&amp;ecc-&gt;p, y3, x2, y2);
+  ecc_mod_mul (&amp;ecc-&gt;p, T, x3, y3);
+  ecc_mod_sub (&amp;ecc-&gt;p, T, T, C);
+  ecc_mod_sub (&amp;ecc-&gt;p, T, T, D);
+  ecc_mod_mul (&amp;ecc-&gt;p, x3, C, D);
+  ecc_mod_mul (&amp;ecc-&gt;p, E, x3, ecc-&gt;b);
+
+  ecc_mod_add (&amp;ecc-&gt;p, C, D, C);
+  ecc_mod_sqr (&amp;ecc-&gt;p, B, z1);
+  ecc_mod_sub (&amp;ecc-&gt;p, F, B, E);
+  ecc_mod_add (&amp;ecc-&gt;p, G, B, E);
 
   /* x3 */
-  ecc_modp_mul (ecc, B, G, T);
-  ecc_modp_mul (ecc, x3, B, z1);
+  ecc_mod_mul (&amp;ecc-&gt;p, B, G, T);
+  ecc_mod_mul (&amp;ecc-&gt;p, x3, B, z1);
 
   /* y3 */
-  ecc_modp_mul (ecc, B, F, z1);
-  ecc_modp_mul (ecc, y3, B, C); /* Clobbers z1 in case r == p. */
+  ecc_mod_mul (&amp;ecc-&gt;p, B, F, z1);
+  ecc_mod_mul (&amp;ecc-&gt;p, y3, B, C); /* Clobbers z1 in case r == p. */
 
   /* z3 */
-  ecc_modp_mul (ecc, B, F, G);
+  ecc_mod_mul (&amp;ecc-&gt;p, B, F, G);
   mpn_copyi (z3, B, ecc-&gt;p.size);
 }
diff --git a/ecc-add-thh.c b/ecc-add-thh.c
index 03bb761f0500..59b33f385edb 100644
--- a/ecc-add-thh.c
+++ b/ecc-add-thh.c
@@ -85,32 +85,32 @@ ecc_add_thh (const struct ecc_curve *ecc,
 #define F D
 #define G E
 
-  ecc_modp_mul (ecc, C, x1, x2);
-  ecc_modp_mul (ecc, D, y1, y2);
-  ecc_modp_add (ecc, A, x1, y1);
-  ecc_modp_add (ecc, B, x2, y2);
-  ecc_modp_mul (ecc, T, A, B);
-  ecc_modp_sub (ecc, T, T, C);
-  ecc_modp_sub (ecc, T, T, D);
-  ecc_modp_mul (ecc, x3, C, D);
-  ecc_modp_mul (ecc, E, x3, ecc-&gt;b);
-  ecc_modp_add (ecc, C, D, C);
-
-  ecc_modp_mul (ecc, A, z1, z2);
-  ecc_modp_sqr (ecc, B, A);
-
-  ecc_modp_sub (ecc, F, B, E);
-  ecc_modp_add (ecc, G, B, E);
+  ecc_mod_mul (&amp;ecc-&gt;p, C, x1, x2);
+  ecc_mod_mul (&amp;ecc-&gt;p, D, y1, y2);
+  ecc_mod_add (&amp;ecc-&gt;p, A, x1, y1);
+  ecc_mod_add (&amp;ecc-&gt;p, B, x2, y2);
+  ecc_mod_mul (&amp;ecc-&gt;p, T, A, B);
+  ecc_mod_sub (&amp;ecc-&gt;p, T, T, C);
+  ecc_mod_sub (&amp;ecc-&gt;p, T, T, D);
+  ecc_mod_mul (&amp;ecc-&gt;p, x3, C, D);
+  ecc_mod_mul (&amp;ecc-&gt;p, E, x3, ecc-&gt;b);
+  ecc_mod_add (&amp;ecc-&gt;p, C, D, C);
+
+  ecc_mod_mul (&amp;ecc-&gt;p, A, z1, z2);
+  ecc_mod_sqr (&amp;ecc-&gt;p, B, A);
+
+  ecc_mod_sub (&amp;ecc-&gt;p, F, B, E);
+  ecc_mod_add (&amp;ecc-&gt;p, G, B, E);
 
   /* x3 */
-  ecc_modp_mul (ecc, B, G, T);
-  ecc_modp_mul (ecc, x3, B, A);
+  ecc_mod_mul (&amp;ecc-&gt;p, B, G, T);
+  ecc_mod_mul (&amp;ecc-&gt;p, x3, B, A);
 
   /* y3 */
-  ecc_modp_mul (ecc, B, F, C);
-  ecc_modp_mul (ecc, y3, B, A);
+  ecc_mod_mul (&amp;ecc-&gt;p, B, F, C);
+  ecc_mod_mul (&amp;ecc-&gt;p, y3, B, A);
 
   /* z3 */
-  ecc_modp_mul (ecc, B, F, G);
+  ecc_mod_mul (&amp;ecc-&gt;p, B, F, G);
   mpn_copyi (z3, B, ecc-&gt;p.size);
 }
diff --git a/ecc-dup-eh.c b/ecc-dup-eh.c
index f7b46eefa3ae..b36c55408e8c 100644
--- a/ecc-dup-eh.c
+++ b/ecc-dup-eh.c
@@ -64,28 +64,28 @@ ecc_dup_eh (const struct ecc_curve *ecc,
 #define j (scratch  + 4*ecc-&gt;p.size)
 
   /* b */
-  ecc_modp_add (ecc, e, p, p + ecc-&gt;p.size);
-  ecc_modp_sqr (ecc, b, e);
+  ecc_mod_add (&amp;ecc-&gt;p, e, p, p + ecc-&gt;p.size);
+  ecc_mod_sqr (&amp;ecc-&gt;p, b, e);
 
   /* c */
-  ecc_modp_sqr (ecc, c, p);
+  ecc_mod_sqr (&amp;ecc-&gt;p, c, p);
   /* d */
-  ecc_modp_sqr (ecc, d, p + ecc-&gt;p.size);
+  ecc_mod_sqr (&amp;ecc-&gt;p, d, p + ecc-&gt;p.size);
   /* h, can use r as scratch, even for in-place operation. */
-  ecc_modp_sqr (ecc, r, p + 2*ecc-&gt;p.size);
+  ecc_mod_sqr (&amp;ecc-&gt;p, r, p + 2*ecc-&gt;p.size);
   /* e, */
-  ecc_modp_add (ecc, e, c, d);
+  ecc_mod_add (&amp;ecc-&gt;p, e, c, d);
   /* j */
-  ecc_modp_add (ecc, r, r, r);
-  ecc_modp_sub (ecc, j, e, r);
+  ecc_mod_add (&amp;ecc-&gt;p, r, r, r);
+  ecc_mod_sub (&amp;ecc-&gt;p, j, e, r);
 
   /* x' */
-  ecc_modp_sub (ecc, b, b, e);
-  ecc_modp_mul (ecc, r, b, j);
+  ecc_mod_sub (&amp;ecc-&gt;p, b, b, e);
+  ecc_mod_mul (&amp;ecc-&gt;p, r, b, j);
   /* y' */
-  ecc_modp_sub (ecc, c, c, d); /* Redundant */
-  ecc_modp_mul (ecc, r + ecc-&gt;p.size, e, c);
+  ecc_mod_sub (&amp;ecc-&gt;p, c, c, d); /* Redundant */
+  ecc_mod_mul (&amp;ecc-&gt;p, r + ecc-&gt;p.size, e, c);
   /* z' */
-  ecc_modp_mul (ecc, b, e, j);
+  ecc_mod_mul (&amp;ecc-&gt;p, b, e, j);
   mpn_copyi (r + 2*ecc-&gt;p.size, b, ecc-&gt;p.size);
 }
diff --git a/ecc-dup-jj.c b/ecc-dup-jj.c
index 8e1cf36c17eb..2247e8fdfd5a 100644
--- a/ecc-dup-jj.c
+++ b/ecc-dup-jj.c
@@ -72,39 +72,39 @@ ecc_dup_jj (const struct ecc_curve *ecc,
 #define zp (p + 2*ecc-&gt;p.size)
   
   /* delta */
-  ecc_modp_sqr (ecc, delta, zp);
+  ecc_mod_sqr (&amp;ecc-&gt;p, delta, zp);
 
   /* gamma */
-  ecc_modp_sqr (ecc, gamma, yp);
+  ecc_mod_sqr (&amp;ecc-&gt;p, gamma, yp);
 
   /* z'. Can use beta area as scratch. */
-  ecc_modp_add (ecc, r + 2*ecc-&gt;p.size, yp, zp);
-  ecc_modp_sqr (ecc, beta, r + 2*ecc-&gt;p.size);
-  ecc_modp_sub (ecc, beta, beta, gamma);
-  ecc_modp_sub (ecc, r + 2*ecc-&gt;p.size, beta, delta);
+  ecc_mod_add (&amp;ecc-&gt;p, r + 2*ecc-&gt;p.size, yp, zp);
+  ecc_mod_sqr (&amp;ecc-&gt;p, beta, r + 2*ecc-&gt;p.size);
+  ecc_mod_sub (&amp;ecc-&gt;p, beta, beta, gamma);
+  ecc_mod_sub (&amp;ecc-&gt;p, r + 2*ecc-&gt;p.size, beta, delta);
   
   /* alpha. Can use beta area as scratch, and overwrite delta. */
-  ecc_modp_add (ecc, sum, xp, delta);
-  ecc_modp_sub (ecc, delta, xp, delta);
-  ecc_modp_mul (ecc, beta, sum, delta);
-  ecc_modp_mul_1 (ecc, alpha, beta, 3);
+  ecc_mod_add (&amp;ecc-&gt;p, sum, xp, delta);
+  ecc_mod_sub (&amp;ecc-&gt;p, delta, xp, delta);
+  ecc_mod_mul (&amp;ecc-&gt;p, beta, sum, delta);
+  ecc_mod_mul_1 (&amp;ecc-&gt;p, alpha, beta, 3);
 
   /* beta */
-  ecc_modp_mul (ecc, beta, xp, gamma);
+  ecc_mod_mul (&amp;ecc-&gt;p, beta, xp, gamma);
 
   /* Do gamma^2 and 4*beta early, to get them out of the way. We can
      then use the old area at gamma as scratch. */
-  ecc_modp_sqr (ecc, g2, gamma);
-  ecc_modp_mul_1 (ecc, sum, beta, 4);
+  ecc_mod_sqr (&amp;ecc-&gt;p, g2, gamma);
+  ecc_mod_mul_1 (&amp;ecc-&gt;p, sum, beta, 4);
   
   /* x' */
-  ecc_modp_sqr (ecc, gamma, alpha);   /* Overwrites gamma and beta */
-  ecc_modp_submul_1 (ecc, gamma, sum, 2);
+  ecc_mod_sqr (&amp;ecc-&gt;p, gamma, alpha);   /* Overwrites gamma and beta */
+  ecc_mod_submul_1 (&amp;ecc-&gt;p, gamma, sum, 2);
   mpn_copyi (r, gamma, ecc-&gt;p.size);
 
   /* y' */
-  ecc_modp_sub (ecc, sum, sum, r);
-  ecc_modp_mul (ecc, gamma, sum, alpha);
-  ecc_modp_submul_1 (ecc, gamma, g2, 8);
+  ecc_mod_sub (&amp;ecc-&gt;p, sum, sum, r);
+  ecc_mod_mul (&amp;ecc-&gt;p, gamma, sum, alpha);
+  ecc_mod_submul_1 (&amp;ecc-&gt;p, gamma, g2, 8);
   mpn_copyi (r + ecc-&gt;p.size, gamma, ecc-&gt;p.size);
 }
diff --git a/ecc-dup-th.c b/ecc-dup-th.c
index b4ce95c91ebd..dd95b84ac097 100644
--- a/ecc-dup-th.c
+++ b/ecc-dup-th.c
@@ -81,29 +81,29 @@ ecc_dup_th (const struct ecc_curve *ecc,
 #define J (scratch  + 4*ecc-&gt;p.size)
 
   /* B */
-  ecc_modp_add (ecc, F, p, p + ecc-&gt;p.size);
-  ecc_modp_sqr (ecc, B, F);
+  ecc_mod_add (&amp;ecc-&gt;p, F, p, p + ecc-&gt;p.size);
+  ecc_mod_sqr (&amp;ecc-&gt;p, B, F);
 
   /* C */
-  ecc_modp_sqr (ecc, C, p);
+  ecc_mod_sqr (&amp;ecc-&gt;p, C, p);
   /* D */
-  ecc_modp_sqr (ecc, D, p + ecc-&gt;p.size);
+  ecc_mod_sqr (&amp;ecc-&gt;p, D, p + ecc-&gt;p.size);
   /* Can use r as scratch, even for in-place operation. */
-  ecc_modp_sqr (ecc, r, p + 2*ecc-&gt;p.size);
+  ecc_mod_sqr (&amp;ecc-&gt;p, r, p + 2*ecc-&gt;p.size);
   /* F, */
-  ecc_modp_sub (ecc, F, D, C);
+  ecc_mod_sub (&amp;ecc-&gt;p, F, D, C);
   /* B - C - D */
-  ecc_modp_add (ecc, C, C, D);
-  ecc_modp_sub (ecc, B, B, C);
+  ecc_mod_add (&amp;ecc-&gt;p, C, C, D);
+  ecc_mod_sub (&amp;ecc-&gt;p, B, B, C);
   /* J */
-  ecc_modp_add (ecc, r, r, r);
-  ecc_modp_sub (ecc, J, r, F);
+  ecc_mod_add (&amp;ecc-&gt;p, r, r, r);
+  ecc_mod_sub (&amp;ecc-&gt;p, J, r, F);
 
   /* x' */
-  ecc_modp_mul (ecc, r, B, J);
+  ecc_mod_mul (&amp;ecc-&gt;p, r, B, J);
   /* y' */
-  ecc_modp_mul (ecc, r + ecc-&gt;p.size, F, C);
+  ecc_mod_mul (&amp;ecc-&gt;p, r + ecc-&gt;p.size, F, C);
   /* z' */
-  ecc_modp_mul (ecc, B, F, J);
+  ecc_mod_mul (&amp;ecc-&gt;p, B, F, J);
   mpn_copyi (r + 2*ecc-&gt;p.size, B, ecc-&gt;p.size);
 }
diff --git a/ecc-ecdsa-sign.c b/ecc-ecdsa-sign.c
index 3b9e9cc1a35d..d675bd9b3805 100644
--- a/ecc-ecdsa-sign.c
+++ b/ecc-ecdsa-sign.c
@@ -88,9 +88,9 @@ ecc_ecdsa_sign (const struct ecc_curve *ecc,
   /* Process hash digest */
   ecc_hash (&amp;ecc-&gt;q, hp, length, digest);
 
-  ecc_modq_mul (ecc, tp, zp, rp);
-  ecc_modq_add (ecc, hp, hp, tp);
-  ecc_modq_mul (ecc, tp, hp, kinv);
+  ecc_mod_mul (&amp;ecc-&gt;q, tp, zp, rp);
+  ecc_mod_add (&amp;ecc-&gt;q, hp, hp, tp);
+  ecc_mod_mul (&amp;ecc-&gt;q, tp, hp, kinv);
 
   mpn_copyi (sp, tp, ecc-&gt;p.size);
 #undef P
diff --git a/ecc-ecdsa-verify.c b/ecc-ecdsa-verify.c
index d7f5b684841a..6f9fb5d98175 100644
--- a/ecc-ecdsa-verify.c
+++ b/ecc-ecdsa-verify.c
@@ -112,10 +112,10 @@ ecc_ecdsa_verify (const struct ecc_curve *ecc,
 
   /* u1 = h / s, P1 = u1 * G */
   ecc_hash (&amp;ecc-&gt;q, hp, length, digest);
-  ecc_modq_mul (ecc, u1, hp, sinv);
+  ecc_mod_mul (&amp;ecc-&gt;q, u1, hp, sinv);
 
   /* u2 = r / s, P2 = u2 * Y */
-  ecc_modq_mul (ecc, u2, rp, sinv);
+  ecc_mod_mul (&amp;ecc-&gt;q, u2, rp, sinv);
 
    /* Total storage: 5*ecc-&gt;p.size + ecc-&gt;mul_itch */
   ecc-&gt;mul (ecc, P2, u2, pp, u2 + ecc-&gt;p.size);
diff --git a/ecc-eh-to-a.c b/ecc-eh-to-a.c
index 89d2b6e3bcae..869e8ad52c89 100644
--- a/ecc-eh-to-a.c
+++ b/ecc-eh-to-a.c
@@ -61,11 +61,11 @@ ecc_eh_to_a (const struct ecc_curve *ecc,
   /* Needs 2*size + scratch for the invert call. */
   ecc-&gt;p.invert (&amp;ecc-&gt;p, izp, zp, tp + ecc-&gt;p.size);
 
-  ecc_modp_mul (ecc, tp, xp, izp);
+  ecc_mod_mul (&amp;ecc-&gt;p, tp, xp, izp);
   cy = mpn_sub_n (r, tp, ecc-&gt;p.m, ecc-&gt;p.size);
   cnd_copy (cy, r, tp, ecc-&gt;p.size);
 
-  ecc_modp_mul (ecc, tp, yp, izp);
+  ecc_mod_mul (&amp;ecc-&gt;p, tp, yp, izp);
   cy = mpn_sub_n (r + ecc-&gt;p.size, tp, ecc-&gt;p.m, ecc-&gt;p.size);
   cnd_copy (cy, r + ecc-&gt;p.size, tp, ecc-&gt;p.size);
 }
diff --git a/ecc-gostdsa-sign.c b/ecc-gostdsa-sign.c
index 00eeef81f659..a12eb2af20fa 100644
--- a/ecc-gostdsa-sign.c
+++ b/ecc-gostdsa-sign.c
@@ -84,9 +84,9 @@ ecc_gostdsa_sign (const struct ecc_curve *ecc,
   if (mpn_zero_p (hp, ecc-&gt;p.size))
     mpn_add_1 (hp, hp, ecc-&gt;p.size, 1);
 
-  ecc_modq_mul (ecc, tp, rp, zp);
-  ecc_modq_mul (ecc, t2p, kp, hp);
-  ecc_modq_add (ecc, sp, tp, t2p);
+  ecc_mod_mul (&amp;ecc-&gt;q, tp, rp, zp);
+  ecc_mod_mul (&amp;ecc-&gt;q, t2p, kp, hp);
+  ecc_mod_add (&amp;ecc-&gt;q, sp, tp, t2p);
 
   /* Also reduce mod ecc-&gt;q. It should already be &lt; 2*ecc-&gt;q,
    * so one subtraction should suffice. */
diff --git a/ecc-gostdsa-verify.c b/ecc-gostdsa-verify.c
index 4358132b2bf6..29b82c8494ac 100644
--- a/ecc-gostdsa-verify.c
+++ b/ecc-gostdsa-verify.c
@@ -102,10 +102,10 @@ ecc_gostdsa_verify (const struct ecc_curve *ecc,
   ecc-&gt;q.invert (&amp;ecc-&gt;q, vp, hp, vp + 2*ecc-&gt;p.size);
 
   /* z1 = s / h, P1 = z1 * G */
-  ecc_modq_mul (ecc, z1, sp, vp);
+  ecc_mod_mul (&amp;ecc-&gt;q, z1, sp, vp);
 
   /* z2 = - r / h, P2 = z2 * Y */
-  ecc_modq_mul (ecc, z2, rp, vp);
+  ecc_mod_mul (&amp;ecc-&gt;q, z2, rp, vp);
   mpn_sub_n (z2, ecc-&gt;q.m, z2, ecc-&gt;p.size);
 
    /* Total storage: 5*ecc-&gt;p.size + ecc-&gt;mul_itch */
diff --git a/ecc-internal.h b/ecc-internal.h
index 9516023a96ab..9e24e0ce4521 100644
--- a/ecc-internal.h
+++ b/ecc-internal.h
@@ -256,26 +256,6 @@ void
 ecc_mod_sqr (const struct ecc_modulo *m, mp_limb_t *rp,
 	     const mp_limb_t *ap);
 
-#define ecc_modp_add(ecc, r, a, b) \
-  ecc_mod_add (&amp;(ecc)-&gt;p, (r), (a), (b))
-#define ecc_modp_sub(ecc, r, a, b) \
-  ecc_mod_sub (&amp;(ecc)-&gt;p, (r), (a), (b))
-#define ecc_modp_mul_1(ecc, r, a, b) \
-  ecc_mod_mul_1 (&amp;(ecc)-&gt;p, (r), (a), (b))
-#define ecc_modp_addmul_1(ecc, r, a, b) \
-  ecc_mod_addmul_1 (&amp;(ecc)-&gt;p, (r), (a), (b))
-#define ecc_modp_submul_1(ecc, r, a, b) \
-  ecc_mod_submul_1 (&amp;(ecc)-&gt;p, (r), (a), (b))
-#define ecc_modp_mul(ecc, r, a, b) \
-  ecc_mod_mul (&amp;(ecc)-&gt;p, (r), (a), (b))
-#define ecc_modp_sqr(ecc, r, a) \
-  ecc_mod_sqr (&amp;(ecc)-&gt;p, (r), (a))
-
-#define ecc_modq_add(ecc, r, a, b) \
-  ecc_mod_add (&amp;(ecc)-&gt;q, (r), (a), (b))
-#define ecc_modq_mul(ecc, r, a, b) \
-  ecc_mod_mul (&amp;(ecc)-&gt;q, (r), (a), (b))
-
 /* mod q operations. */
 void
 ecc_mod_random (const struct ecc_modulo *m, mp_limb_t *xp,
diff --git a/ecc-j-to-a.c b/ecc-j-to-a.c
index eca10f0fac9e..a232e0c5c5af 100644
--- a/ecc-j-to-a.c
+++ b/ecc-j-to-a.c
@@ -74,7 +74,7 @@ ecc_j_to_a (const struct ecc_curve *ecc,
       mpn_zero (izBp + ecc-&gt;p.size, ecc-&gt;p.size);
       ecc-&gt;p.reduce (&amp;ecc-&gt;p, izBp);
 
-      ecc_modp_mul (ecc, iz2p, izp, izBp);
+      ecc_mod_mul (&amp;ecc-&gt;p, iz2p, izp, izBp);
     }
   else
     {
@@ -83,11 +83,11 @@ ecc_j_to_a (const struct ecc_curve *ecc,
       mpn_copyi (up, p+2*ecc-&gt;p.size, ecc-&gt;p.size); /* p_z */
       ecc-&gt;p.invert (&amp;ecc-&gt;p, izp, up, up + ecc-&gt;p.size);
 
-      ecc_modp_sqr (ecc, iz2p, izp);
+      ecc_mod_sqr (&amp;ecc-&gt;p, iz2p, izp);
     }
 
-  ecc_modp_mul (ecc, iz3p, iz2p, p);
-  /* ecc_modp (and ecc_modp_mul) may return a value up to 2p - 1, so
+  ecc_mod_mul (&amp;ecc-&gt;p, iz3p, iz2p, p);
+  /* ecc_mod (and ecc_mod_mul) may return a value up to 2p - 1, so
      do a conditional subtraction. */
   cy = mpn_sub_n (r, iz3p, ecc-&gt;p.m, ecc-&gt;p.size);
   cnd_copy (cy, r, iz3p, ecc-&gt;p.size);
@@ -105,8 +105,8 @@ ecc_j_to_a (const struct ecc_curve *ecc,
 	}
       return;
     }
-  ecc_modp_mul (ecc, iz3p, iz2p, izp);
-  ecc_modp_mul (ecc, tp, iz3p, p + ecc-&gt;p.size);
+  ecc_mod_mul (&amp;ecc-&gt;p, iz3p, iz2p, izp);
+  ecc_mod_mul (&amp;ecc-&gt;p, tp, iz3p, p + ecc-&gt;p.size);
   /* And a similar subtraction. */
   cy = mpn_sub_n (r + ecc-&gt;p.size, tp, ecc-&gt;p.m, ecc-&gt;p.size);
   cnd_copy (cy, r + ecc-&gt;p.size, tp, ecc-&gt;p.size);
diff --git a/eddsa-decompress.c b/eddsa-decompress.c
index 441ccfbfb18a..8116084dda09 100644
--- a/eddsa-decompress.c
+++ b/eddsa-decompress.c
@@ -90,14 +90,14 @@ _eddsa_decompress (const struct ecc_curve *ecc, mp_limb_t *p,
   /* For a valid input, y &lt; p, so subtraction should underflow. */
   res &amp;= mpn_sub_n (scratch, scratch, ecc-&gt;p.m, ecc-&gt;p.size);
 
-  ecc_modp_sqr (ecc, y2, yp);
-  ecc_modp_mul (ecc, vp, y2, ecc-&gt;b);
-  ecc_modp_sub (ecc, vp, vp, ecc-&gt;unit);
+  ecc_mod_sqr (&amp;ecc-&gt;p, y2, yp);
+  ecc_mod_mul (&amp;ecc-&gt;p, vp, y2, ecc-&gt;b);
+  ecc_mod_sub (&amp;ecc-&gt;p, vp, vp, ecc-&gt;unit);
   /* The sign is different between curve25519 and curve448.  */
   if (ecc-&gt;p.bit_size == 255)
-    ecc_modp_sub (ecc, up, ecc-&gt;unit, y2);
+    ecc_mod_sub (&amp;ecc-&gt;p, up, ecc-&gt;unit, y2);
   else
-    ecc_modp_sub (ecc, up, y2, ecc-&gt;unit);
+    ecc_mod_sub (&amp;ecc-&gt;p, up, y2, ecc-&gt;unit);
   res &amp;= ecc-&gt;p.sqrt (&amp;ecc-&gt;p, tp, up, vp, scratch_out);
 
   cy = mpn_sub_n (xp, tp, ecc-&gt;p.m, ecc-&gt;p.size);
diff --git a/eddsa-sign.c b/eddsa-sign.c
index 1d5e4796b120..acb8299b4191 100644
--- a/eddsa-sign.c
+++ b/eddsa-sign.c
@@ -91,8 +91,8 @@ _eddsa_sign (const struct ecc_curve *ecc,
   eddsa-&gt;digest (ctx, 2*nbytes, hash);
   _eddsa_hash (&amp;ecc-&gt;q, hp, 2*nbytes, hash);
 
-  ecc_modq_mul (ecc, sp, hp, k2);
-  ecc_modq_add (ecc, sp, sp, rp); /* FIXME: Can be plain add */
+  ecc_mod_mul (&amp;ecc-&gt;q, sp, hp, k2);
+  ecc_mod_add (&amp;ecc-&gt;q, sp, sp, rp); /* FIXME: Can be plain add */
   if (ecc-&gt;p.bit_size == 255)
     {
       /* FIXME: Special code duplicated in ecc_curve25519_modq
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200203040655</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-02-03 04:06:55-0400</timestampReceived><subject>Re: Please use -shared on Solaris. Don't use -G on Solaris</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; When linking the shared object with -G on Solaris:
&gt;
&gt; gcc -g2 -O2 -m64 -march=native -fPIC -pthread  -Wno-pointer-sign -Wall
&gt; -W   -Wmissing-prototypes -Wmissing-declarations -Wstrict-prototypes
&gt; -Wpointer-arith -Wbad-function-cast -Wnested-externs -L/usr/local/lib
&gt; -m64 -Wl,-R,'$ORIGIN/../lib' -Wl,-R,/usr/local/lib -G -h
&gt; libnettle.so.7 aes-decrypt-internal.o aes-decrypt.o
&gt; aes-encrypt-internal.o aes-encrypt.o aes-encrypt-table.o ...
&gt;
&gt; It results in:
&gt;
&gt; ld.so.1: aes-test: fatal: relocation error: R_AMD64_PC32: file
&gt; ../.lib/libhogweed.so.5: symbol _init: value 0x7f004df15e9d does not
&gt; fit
&gt; ../run-tests: line 61: 12934: Killed
&gt; FAIL: aes
&gt; ld.so.1: arcfour-test: fatal: relocation error: R_AMD64_PC32: file
&gt; ../.lib/libhogweed.so.5: symbol _init: value 0x7f004df15a1d does not
&gt; fit
&gt; ../run-tests: line 61: 12939: Killed
&gt; FAIL: arcfour
&gt; ld.so.1: arctwo-test: fatal: relocation error: R_AMD64_PC32: file
&gt; ../.lib/libhogweed.so.5: symbol _init: value 0x7f004df153dd does not
&gt; fit
&gt; ../run-tests: line 61: 12944: Killed
&gt; FAIL: arctwo
&gt; ...
&gt;
&gt; Here's the full paste of the build using -G: https://pastebin.com/SKZxKfdZ.
&gt;
&gt; Please use -shared, not -G. -shared works as expected on Solaris.

So you're suggesting the following change, right?

diff --git a/configure.ac b/configure.ac
index 09f719a0..ba3ab7c6 100644
--- a/configure.ac
+++ b/configure.ac
@@ -655,13 +655,13 @@ case "$host_os" in
     LIBNETTLE_FORLINK=libnettle.so
     LIBNETTLE_SONAME='$(LIBNETTLE_FORLINK).$(LIBNETTLE_MAJOR)'
     LIBNETTLE_FILE='$(LIBNETTLE_SONAME).$(LIBNETTLE_MINOR)'
-    LIBNETTLE_LINK='$(CC) $(CFLAGS) $(LDFLAGS) -G -h $(LIBNETTLE_SONAME)'
+    LIBNETTLE_LINK='$(CC) $(CFLAGS) $(LDFLAGS) -shared -h $(LIBNETTLE_SONAME)'
     LIBNETTLE_LIBS=''
 
     LIBHOGWEED_FORLINK=libhogweed.so
     LIBHOGWEED_SONAME='$(LIBHOGWEED_FORLINK).$(LIBHOGWEED_MAJOR)'
     LIBHOGWEED_FILE='$(LIBHOGWEED_SONAME).$(LIBHOGWEED_MINOR)'
-    LIBHOGWEED_LINK='$(CC) $(CFLAGS) $(LDFLAGS) -G -h $(LIBHOGWEED_SONAME)'
+    LIBHOGWEED_LINK='$(CC) $(CFLAGS) $(LDFLAGS) --shared -h $(LIBHOGWEED_SONAME)'
     LIBHOGWEED_LIBS='libnettle.so $(LIBS)'
     ;;
   *)

IIRC, the reason for current use of -G rather than -shared is that it
worked better with Solaris cc. But according to

https://docs.oracle.com/cd/E77782_01/html/E77792/gqexw.html#OSGCCgqfch	

-shared was added as an alias for -G in Oracle Developer Studio 12.4,
and changed to be more gcc-compatible in 12.6. 

Are you able to test if building shared libraries still works with these
tools? Support for unusual proprietary compilers linkers is not that
high a priority, but it would be nice to keep it working, or at least,
know when breaking it.

&gt; Here's the full paste of the build using -G: https://pastebin.com/SKZxKfdZ.

: checking build system type... i386-pc-solaris2.11
: checking host system type... x86_64-sun-solaris2

Looks like a cross-compile configuration. Is that intentional? 

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200203043241</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-02-03 04:32:41-0400</timestampReceived><subject>Re: Please use -shared on Solaris. Don't use -G on Solaris</subject><body>

On Sun, Feb 2, 2020 at 11:06 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; Jeffrey Walton &lt;noloader@gmail.com&gt; writes:
&gt;
&gt; &gt; When linking the shared object with -G on Solaris:
&gt; &gt;
&gt; &gt; gcc -g2 -O2 -m64 -march=native -fPIC -pthread  -Wno-pointer-sign -Wall
&gt; &gt; -W   -Wmissing-prototypes -Wmissing-declarations -Wstrict-prototypes
&gt; &gt; -Wpointer-arith -Wbad-function-cast -Wnested-externs -L/usr/local/lib
&gt; &gt; -m64 -Wl,-R,'$ORIGIN/../lib' -Wl,-R,/usr/local/lib -G -h
&gt; &gt; libnettle.so.7 aes-decrypt-internal.o aes-decrypt.o
&gt; &gt; aes-encrypt-internal.o aes-encrypt.o aes-encrypt-table.o ...
&gt; &gt;
&gt; &gt; It results in:
&gt; &gt;
&gt; &gt; ld.so.1: aes-test: fatal: relocation error: R_AMD64_PC32: file
&gt; &gt; ../.lib/libhogweed.so.5: symbol _init: value 0x7f004df15e9d does not
&gt; &gt; fit
&gt; &gt; ../run-tests: line 61: 12934: Killed
&gt; &gt; FAIL: aes
&gt; &gt; ld.so.1: arcfour-test: fatal: relocation error: R_AMD64_PC32: file
&gt; &gt; ../.lib/libhogweed.so.5: symbol _init: value 0x7f004df15a1d does not
&gt; &gt; fit
&gt; &gt; ../run-tests: line 61: 12939: Killed
&gt; &gt; FAIL: arcfour
&gt; &gt; ld.so.1: arctwo-test: fatal: relocation error: R_AMD64_PC32: file
&gt; &gt; ../.lib/libhogweed.so.5: symbol _init: value 0x7f004df153dd does not
&gt; &gt; fit
&gt; &gt; ../run-tests: line 61: 12944: Killed
&gt; &gt; FAIL: arctwo
&gt; &gt; ...
&gt; &gt;
&gt; &gt; Here's the full paste of the build using -G: https://pastebin.com/SKZxKfdZ.
&gt; &gt;
&gt; &gt; Please use -shared, not -G. -shared works as expected on Solaris.
&gt;
&gt; So you're suggesting the following change, right?

Yes, for GCC.

&gt; diff --git a/configure.ac b/configure.ac
&gt; index 09f719a0..ba3ab7c6 100644
&gt; --- a/configure.ac
&gt; +++ b/configure.ac
&gt; @@ -655,13 +655,13 @@ case "$host_os" in
&gt;      LIBNETTLE_FORLINK=libnettle.so
&gt;      LIBNETTLE_SONAME='$(LIBNETTLE_FORLINK).$(LIBNETTLE_MAJOR)'
&gt;      LIBNETTLE_FILE='$(LIBNETTLE_SONAME).$(LIBNETTLE_MINOR)'
&gt; -    LIBNETTLE_LINK='$(CC) $(CFLAGS) $(LDFLAGS) -G -h $(LIBNETTLE_SONAME)'
&gt; +    LIBNETTLE_LINK='$(CC) $(CFLAGS) $(LDFLAGS) -shared -h $(LIBNETTLE_SONAME)'
&gt;      LIBNETTLE_LIBS=''
&gt;
&gt;      LIBHOGWEED_FORLINK=libhogweed.so
&gt;      LIBHOGWEED_SONAME='$(LIBHOGWEED_FORLINK).$(LIBHOGWEED_MAJOR)'
&gt;      LIBHOGWEED_FILE='$(LIBHOGWEED_SONAME).$(LIBHOGWEED_MINOR)'
&gt; -    LIBHOGWEED_LINK='$(CC) $(CFLAGS) $(LDFLAGS) -G -h $(LIBHOGWEED_SONAME)'
&gt; +    LIBHOGWEED_LINK='$(CC) $(CFLAGS) $(LDFLAGS) --shared -h $(LIBHOGWEED_SONAME)'
&gt;      LIBHOGWEED_LIBS='libnettle.so $(LIBS)'
&gt;      ;;
&gt;    *)
&gt;
&gt; IIRC, the reason for current use of -G rather than -shared is that it
&gt; worked better with Solaris cc. But according to
&gt;
&gt; https://docs.oracle.com/cd/E77782_01/html/E77792/gqexw.html#OSGCCgqfch
&gt;
&gt; -shared was added as an alias for -G in Oracle Developer Studio 12.4,
&gt; and changed to be more gcc-compatible in 12.6.

Yeah, -G and -shared seems to be a moving target with some features
undocumented.

&gt; Are you able to test if building shared libraries still works with these
&gt; tools? Support for unusual proprietary compilers linkers is not that
&gt; high a priority, but it would be nice to keep it working, or at least,
&gt; know when breaking it.

Not at the moment.

I have a Solaris 11.3 box, but it does not have Sun Studio on it. Two
other testing machines have Sun Studio 12.1 through 12.6, but both are
dead at the moment. I need to order some parts.

Maybe the OpenCSW folks have something that can test Sun Studio. They
provide free accounts to developers.

&gt; &gt; Here's the full paste of the build using -G: https://pastebin.com/SKZxKfdZ.
&gt;
&gt; : checking build system type... i386-pc-solaris2.11
&gt; : checking host system type... x86_64-sun-solaris2
&gt;
&gt; Looks like a cross-compile configuration. Is that intentional?

Braindead Autotools. Sun provides a multilib system out of the box,
running a 64-bit kernel:

    jwalton@Solaris:~$ isainfo
    amd64 i386
    jwalton@Solaris:~$ isainfo -b
    64

Sun says to build 64-bit binaries on 64-bit systems. Confer,
https://docs.oracle.com/cd/E37838_01/html/E66175/features-1.html.

But Autotools detects the system as i386:

    $ /usr/share/automake-1.11/config.guess
    i386-pc-solaris2.11

So I have to tell Autotools to build for a 64-bit system via
--host=amd64-sun-solaris

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200203044837</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-02-03 04:48:37-0400</timestampReceived><subject>Re: Please use -shared on Solaris. Don't use -G on Solaris</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; I have a Solaris 11.3 box, but it does not have Sun Studio on it. Two
&gt; other testing machines have Sun Studio 12.1 through 12.6, but both are
&gt; dead at the moment. I need to order some parts.
&gt;
&gt; Maybe the OpenCSW folks have something that can test Sun Studio. They
&gt; provide free accounts to developers.

I don't have any time to spend on testing with these systems or
compilers. Do you think it makes sense to change from -G to -shared
unconditionally for Solaris? It makes no sense to try to do something
more clever based on compiler used, without any contributor able to test
it.

&gt; Braindead Autotools.

Please, no derogatory comments about autoconf on this list. And as I
think I've said before, the term "autotools" is even more irrelevant
here.

&gt; But Autotools detects the system as i386:
&gt;
&gt;     $ /usr/share/automake-1.11/config.guess
&gt;     i386-pc-solaris2.11

Can you check if latest config.guess
(https://git.savannah.gnu.org/gitweb/?p=config.git;a=blob_plain;f=config.guess)
has this bug? If not, I can simply upgrade to the latest version. If
it's still giving the wrong result, it might make your life easier to
submit a patch to fix this problem upstream. 

One subtlety is that it might cause problems to say x86_64 if the
compiler produces 32-bit i386 binaries by default. 

You might also want to test if 

  CC_FOR_BUILD='gcc -m64' ./config.status

makes any difference.

&gt; So I have to tell Autotools to build for a 64-bit system via
&gt; --host=amd64-sun-solaris

If you get into any subtle problems from configure thinking you're
crosscompiling, you might want to add --build=amd64-sun-solaris instead
or in addition to setting --host.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200203050420</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-02-03 05:04:20-0400</timestampReceived><subject>Re: Please use -shared on Solaris. Don't use -G on Solaris</subject><body>

On Sun, Feb 2, 2020 at 11:48 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; Jeffrey Walton &lt;noloader@gmail.com&gt; writes:
&gt;
&gt; &gt; I have a Solaris 11.3 box, but it does not have Sun Studio on it. Two
&gt; &gt; other testing machines have Sun Studio 12.1 through 12.6, but both are
&gt; &gt; dead at the moment. I need to order some parts.
&gt; &gt;
&gt; &gt; Maybe the OpenCSW folks have something that can test Sun Studio. They
&gt; &gt; provide free accounts to developers.
&gt;
&gt; I don't have any time to spend on testing with these systems or
&gt; compilers. Do you think it makes sense to change from -G to -shared
&gt; unconditionally for Solaris? It makes no sense to try to do something
&gt; more clever based on compiler used, without any contributor able to test
&gt; it.
&gt;
&gt; &gt; Braindead Autotools.
&gt;
&gt; Please, no derogatory comments about autoconf on this list. And as I
&gt; think I've said before, the term "autotools" is even more irrelevant
&gt; here.

They've earned it. They own it.

&gt; &gt; But Autotools detects the system as i386:
&gt; &gt;
&gt; &gt;     $ /usr/share/automake-1.11/config.guess
&gt; &gt;     i386-pc-solaris2.11
&gt;
&gt; Can you check if latest config.guess
&gt; (https://git.savannah.gnu.org/gitweb/?p=config.git;a=blob_plain;f=config.guess)
&gt; has this bug? If not, I can simply upgrade to the latest version. If
&gt; it's still giving the wrong result, it might make your life easier to
&gt; submit a patch to fix this problem upstream.
&gt;
&gt; One subtlety is that it might cause problems to say x86_64 if the
&gt; compiler produces 32-bit i386 binaries by default.
&gt;
&gt; You might also want to test if
&gt;
&gt;   CC_FOR_BUILD='gcc -m64' ./config.status
&gt;
&gt; makes any difference.
&gt;
&gt; &gt; So I have to tell Autotools to build for a 64-bit system via
&gt; &gt; --host=amd64-sun-solaris
&gt;
&gt; If you get into any subtle problems from configure thinking you're
&gt; crosscompiling, you might want to add --build=amd64-sun-solaris instead
&gt; or in addition to setting --host.

According to the Autoconf docs at "Specifying target triplets", --host
is for "the type of system on which the package runs". Confer,
https://www.gnu.org/software/autoconf/manual/autoconf-2.65/html_node/Specifying-Target-Triplets.html.

Neither the latest config.sub or config.guess help. Nor does add -m64
to flags. I've tried both.

Maybe someone can report yet another bug to the Autoconf folks that
goes unfixed.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200203052329</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-02-03 05:23:29-0400</timestampReceived><subject>Re: Please use -shared on Solaris. Don't use -G on Solaris</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; Neither the latest config.sub or config.guess help. Nor does add -m64
&gt; to flags. I've tried both.

config.guess is the relevant piece of software. If you can submit a
patch upstream, as instructed at the top of the file, that would be
great. Otherwise, you'll have to stick to workarounds until someone else
decides to fix the problem. Solaris on x86 is a somewhat obscure
platform, so good supports will depend a lot on the user community to
help eachother out.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200203052644</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-02-03 05:26:44-0400</timestampReceived><subject>Re: Please use -shared on Solaris. Don't use -G on Solaris</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; On Sun, Feb 2, 2020 at 11:48 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;&gt;
&gt;&gt; I don't have any time to spend on testing with these systems or
&gt;&gt; compilers. Do you think it makes sense to change from -G to -shared
&gt;&gt; unconditionally for Solaris? It makes no sense to try to do something
&gt;&gt; more clever based on compiler used, without any contributor able to test
&gt;&gt; it.

Since I have no recent experience with Solaris, nor time to gain any
experience, I'd like to hear your opinion on the above question, before
I commit any change.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200203054127</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-02-03 05:41:27-0400</timestampReceived><subject>Re: Please use -shared on Solaris. Don't use -G on Solaris</subject><body>

On Mon, Feb 3, 2020 at 12:26 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; Jeffrey Walton &lt;noloader@gmail.com&gt; writes:
&gt;
&gt; &gt; On Sun, Feb 2, 2020 at 11:48 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt; &gt;&gt;
&gt; &gt;&gt; I don't have any time to spend on testing with these systems or
&gt; &gt;&gt; compilers. Do you think it makes sense to change from -G to -shared
&gt; &gt;&gt; unconditionally for Solaris? It makes no sense to try to do something
&gt; &gt;&gt; more clever based on compiler used, without any contributor able to test
&gt; &gt;&gt; it.
&gt;
&gt; Since I have no recent experience with Solaris, nor time to gain any
&gt; experience, I'd like to hear your opinion on the above question, before
&gt; I commit any change.

Fair enough. I think your best option is to do nothing at the moment.
The problem is documented, so searchers should find the fix.

And I can work around it in my scripts with the following:

    IS_SUNC=$("$CC" -V 2&gt;&amp;1 | grep -i -c -E 'sun|studio')
    IS_SOLARIS=$(uname -s | grep -i -c 'sunos')
    ...

    if [[ "$IS_SOLARIS" -ne 0 &amp;&amp; "$IS_SUNC" -eq 0 ]]; then
        sed 's/ -G / -shared /g' configure &gt; configure.fixed
        mv configure.fixed configure; chmod +x configure
    fi

I _think_ the best (but unavailable) option is an Autoconf test. But
Autoconf does not let you compile and link two files (one for a shared
object, and one for a test driver). So it is not an option at this
moment. Maybe someone can file another bug report :)

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200203074648</emailId><senderName>Amos Jeffries</senderName><senderEmail>squid3@treenet.co.nz</senderEmail><timestampReceived>2020-02-03 07:46:48-0400</timestampReceived><subject>Re: Please use -shared on Solaris. Don't use -G on Solaris</subject><body>

On 3/02/20 6:41 pm, Jeffrey Walton wrote:
&gt; On Mon, Feb 3, 2020 at 12:26 AM Niels Möller wrote:
&gt;&gt;
&gt;&gt; Jeffrey Walton writes:
&gt;&gt;
&gt;&gt;&gt; On Sun, Feb 2, 2020 at 11:48 PM Niels Möller wrote:
&gt;&gt;&gt;&gt;
&gt;&gt;&gt;&gt; I don't have any time to spend on testing with these systems or
&gt;&gt;&gt;&gt; compilers. Do you think it makes sense to change from -G to -shared
&gt;&gt;&gt;&gt; unconditionally for Solaris? It makes no sense to try to do something
&gt;&gt;&gt;&gt; more clever based on compiler used, without any contributor able to test
&gt;&gt;&gt;&gt; it.
&gt;&gt;
&gt;&gt; Since I have no recent experience with Solaris, nor time to gain any
&gt;&gt; experience, I'd like to hear your opinion on the above question, before
&gt;&gt; I commit any change.
&gt; 
&gt; Fair enough. I think your best option is to do nothing at the moment.
&gt; The problem is documented, so searchers should find the fix.
&gt; 
&gt; And I can work around it in my scripts with the following:
&gt; 
&gt;     IS_SUNC=$("$CC" -V 2&gt;&amp;1 | grep -i -c -E 'sun|studio')
&gt;     IS_SOLARIS=$(uname -s | grep -i -c 'sunos')
&gt;     ...
&gt; 
&gt;     if [[ "$IS_SOLARIS" -ne 0 &amp;&amp; "$IS_SUNC" -eq 0 ]]; then
&gt;         sed 's/ -G / -shared /g' configure &gt; configure.fixed
&gt;         mv configure.fixed configure; chmod +x configure
&gt;     fi
&gt; 
&gt; I _think_ the best (but unavailable) option is an Autoconf test. But
&gt; Autoconf does not let you compile and link two files (one for a shared
&gt; object, and one for a test driver). So it is not an option at this
&gt; moment. Maybe someone can file another bug report :)


To build a .c file with different flags include it into the autoconf
test as you would an extra .h file:

  SAVED_CFLAGS=$CFLAGS
  CFLAGS="$CFLAGS -shared"
  AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[#include "src/foo.c"]],[[]])],
    [ AC_MSG_RESULT(yes) ],
    [ CFLAGS="$SAVED_CFLAGS"; AC_MSG_RESULT(no) ])


Amos
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200202014933</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-02-02 01:49:33-0400</timestampReceived><subject>Re: Crash on Core-i7 8700 machine with --enable-x86-aesni and --enable-x86-sha-ni</subject><body>

On Sat, Feb 1, 2020 at 8:38 PM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:
&gt; ...
&gt; I'm catching a crash with Nettle 3.5.1 on a Core-i7 8700 configured
&gt; with --enable-x86-aesni and --enable-x86-sha-ni. I verified the
&gt; compiler supports both AESNI and SHA.
&gt; ...
&gt;
&gt; Here is the logic I was trying to use. It accommodates both Linux and Solaris.
&gt;
&gt; AESNI_OPT=$("$CC" "$CFLAGS" -dM -E -maes - &lt;/dev/null 2&gt;&amp;1 | grep -i
&gt; -c "__AES__")
&gt; SHANI_OPT=$("$CC" "$CFLAGS" -dM -E -msha - &lt;/dev/null 2&gt;&amp;1 | grep -i
&gt; -c "__SHA__")
&gt;
&gt; if [[ "$AESNI_OPT" -eq 1 ]]; then
&gt;     echo "Compiler supports AES-NI. Adding --enable-x86-aesni"
&gt;     CONFIG_OPTS+=("--enable-x86-aesni")
&gt; fi
&gt;
&gt; if [[ "$SHANI_OPT" -eq 1 ]]; then
&gt;     echo "Compiler supports SHA-NI. Adding --enable-x86-sha-ni"
&gt;     CONFIG_OPTS+=("--enable-x86-sha-ni")
&gt; fi
&gt;
&gt; # Crash on Solaris machines with --enable-fat
&gt; #if [[ "$IS_IA32" -ne 0 ]]; then
&gt; #    echo "Using runtime algorithm selection. Adding --enable-fat"
&gt; #    CONFIG_OPTS+=("--enable-fat")
&gt; #fi

This is what is confusing me:

  --enable-fat            Enable fat library build (default=no)
  --enable-arm-neon       Enable ARM Neon assembly. (default=auto)
  --enable-x86-aesni      Enable x86_64 aes instructions. (default=no)
  --enable-x86-sha-ni     Enable x86_64 sha_ni instructions. (default=no)
  --enable-mini-gmp       Enable mini-gmp, used instead of libgmp.

SHA-NI is off by default. The build system should not be trying to
build SHA-NI unless I explicitly enable it.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200215205948</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-02-15 20:59:48-0400</timestampReceived><subject>[PATCH 2/2] Add support for GOST GC256C curve</subject><body>

From: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;

Add support for GC256C curve ("TLS Supported Groups" registry,
draft-smyshlyaev-tls12-gost-suites) also known as
GostR3410-2001-CryptoPro-B (RFC 4357).

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 .gitignore                      |   1 +
 Makefile.in                     |  10 +-
 ecc-curve.h                     |   1 +
 ecc-gost-gc256c.c               | 174 ++++++++++++++++++++++++++++++++
 ecc-internal.h                  |   1 +
 eccdata.c                       |  32 ++++++
 examples/ecc-benchmark.c        |   1 +
 nettle.texinfo                  |   8 ++
 testsuite/gostdsa-sign-test.c   |  11 ++
 testsuite/gostdsa-verify-test.c |  11 ++
 testsuite/testutils.c           |  14 ++-
 11 files changed, 260 insertions(+), 4 deletions(-)
 create mode 100644 ecc-gost-gc256c.c

diff --git a/.gitignore b/.gitignore
index 48e2b7f464da..a94d279e5d18 100644
--- a/.gitignore
+++ b/.gitignore
@@ -46,6 +46,7 @@ core
 /ecc-curve25519.h
 /ecc-curve448.h
 /ecc-gost-gc256b.h
+/ecc-gost-gc256c.h
 /ecc-gost-gc512a.h
 /ecc-secp192r1.h
 /ecc-secp224r1.h
diff --git a/Makefile.in b/Makefile.in
index d4fcb81302a2..7330ab893131 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -180,7 +180,8 @@ hogweed_SOURCES = sexp.c sexp-format.c \
 		  ecc-mod.c ecc-mod-inv.c \
 		  ecc-mod-arith.c ecc-pp1-redc.c ecc-pm1-redc.c \
 		  ecc-curve25519.c ecc-curve448.c \
-		  ecc-gost-gc256b.c ecc-gost-gc512a.c \
+		  ecc-gost-gc256b.c ecc-gost-gc256c.c \
+		  ecc-gost-gc512a.c \
 		  ecc-secp192r1.c ecc-secp224r1.c ecc-secp256r1.c \
 		  ecc-secp384r1.c ecc-secp521r1.c \
 		  ecc-size.c ecc-j-to-a.c ecc-a-to-j.c \
@@ -391,6 +392,9 @@ ecc-curve448.h: eccdata.stamp
 ecc-gost-gc256b.h: eccdata.stamp
 	./eccdata$(EXEEXT_FOR_BUILD) gost_gc256b 11 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
 
+ecc-gost-gc256c.h: eccdata.stamp
+	./eccdata$(EXEEXT_FOR_BUILD) gost_gc256c 11 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
+
 # Some reasonable choices for 512:
 # k = 22, c =  6, S = 256, T = 110 ( 88 A + 22 D) 32 KB
 # k = 29, c =  6, S = 192, T = 116 ( 87 A + 29 D) 24 KB
@@ -407,6 +411,7 @@ eccdata.stamp: eccdata.c
 ecc-curve25519.$(OBJEXT): ecc-curve25519.h
 ecc-curve448.$(OBJEXT): ecc-curve448.h
 ecc-gost-gc256b.$(OBJEXT): ecc-gost-gc256b.h
+ecc-gost-gc256c.$(OBJEXT): ecc-gost-gc256c.h
 ecc-gost-gc512a.$(OBJEXT): ecc-gost-gc512a.h
 ecc-secp192r1.$(OBJEXT): ecc-secp192r1.h
 ecc-secp224r1.$(OBJEXT): ecc-secp224r1.h
@@ -661,7 +666,8 @@ distcheck: dist
 clean-here:
 	-rm -f $(TARGETS) *.$(OBJEXT) *.$(OBJEXT).d *.s *.so *.dll *.a \
 		ecc-curve25519.h ecc-curve448.h \
-		ecc-gost-gc256b.h ecc-gost-gc512a.h \
+		ecc-gost-gc256b.h ecc-gost-gc256c.h \
+		ecc-gost-gc512a.h \
 		ecc-secp192r1.h ecc-secp224r1.h ecc-secp256r1.h \
 		ecc-secp384r1.h ecc-secp521r1.h \
 		aesdata$(EXEEXT_FOR_BUILD) \
diff --git a/ecc-curve.h b/ecc-curve.h
index 8f050404a944..30a33d43782b 100644
--- a/ecc-curve.h
+++ b/ecc-curve.h
@@ -44,6 +44,7 @@ extern "C" {
 struct ecc_curve;
 
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_gost_gc256b(void);
+const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_gost_gc256c(void);
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_gost_gc512a(void);
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_secp_192r1(void);
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_secp_224r1(void);
diff --git a/ecc-gost-gc256c.c b/ecc-gost-gc256c.c
new file mode 100644
index 000000000000..258cf75a26bc
--- /dev/null
+++ b/ecc-gost-gc256c.c
@@ -0,0 +1,174 @@
+/* ecc-gost-gc256c.c
+
+   Compile time constant (but machine dependent) tables.
+
+   Copyright (C) 2016, 2019 Dmitry Eremin-Solenikov
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+
+#include "ecc.h"
+#include "ecc-internal.h"
+
+#define USE_REDC 0
+
+#include "ecc-gost-gc256c.h"
+
+static void
+ecc_gost_gc256c_modp (const struct ecc_modulo *m, mp_limb_t *rp)
+{
+  mp_size_t mn = m-&gt;size;
+  mp_limb_t hi;
+
+  hi = mpn_submul_1(rp, rp + mn, mn, 0xc99 * 2);
+  hi = sec_add_1 (rp, rp, mn, hi * 0xc99 * 2);
+  hi = sec_sub_1 (rp, rp, mn, hi * 0xc99 * 2);
+  assert(hi &lt;= 1);
+  hi = cnd_sub_n (hi, rp, m-&gt;B, mn);
+  assert(hi == 0);
+}
+
+static void
+ecc_gost_gc256c_modq (const struct ecc_modulo *p, mp_limb_t *rp)
+{
+  mp_size_t mn = p-&gt;size;
+  mpz_t r, a, m;
+  mpz_init (r);
+  mpz_mod (r, mpz_roinit_n (a, rp, 2*mn), mpz_roinit_n (m, p-&gt;m, mn));
+  mpz_limbs_copy (rp, r, mn);
+
+  mpz_clear (r);
+}
+
+static void
+ecc_gost_gc256c_mod_mul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
+		      const mp_limb_t *ap, mp_limb_t b)
+{
+  mp_limb_t hi;
+
+  assert (b &lt;= 0xffffffff);
+  hi = mpn_mul_1 (rp, ap, m-&gt;size, b);
+  hi = mpn_sub_1 (rp, rp, m-&gt;size, hi * 0xc99 * 2);
+  assert(hi &lt;= 1);
+  hi = cnd_add_n (hi, rp, m-&gt;B, m-&gt;size);
+  assert(hi == 0);
+}
+
+static void
+ecc_gost_gc256c_mod_submul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
+			 const mp_limb_t *ap, mp_limb_t b)
+{
+  mp_limb_t hi;
+
+  assert (b &lt;= 0xffffffff);
+  hi = mpn_submul_1 (rp, ap, m-&gt;size, b);
+  hi = mpn_add_1 (rp, rp, m-&gt;size, hi * 0xc99 * 2);
+  assert(hi &lt;= 1);
+  hi = cnd_sub_n (hi, rp, m-&gt;B, m-&gt;size);
+  assert(hi == 0);
+}
+
+const struct ecc_curve _nettle_gost_gc256c =
+{
+  {
+    256,
+    ECC_LIMB_SIZE,
+    ECC_BMODP_SIZE,
+    ECC_REDC_SIZE,
+    ECC_MOD_INV_ITCH (ECC_LIMB_SIZE),
+    0,
+
+    ecc_p,
+    ecc_Bmodp,
+    ecc_Bmodp_shifted,
+    ecc_redc_ppm1,
+
+    ecc_pp1h,
+    ecc_gost_gc256c_modp,
+    ecc_gost_gc256c_modp,
+    ecc_mod_inv,
+    NULL,
+
+    ecc_gost_gc256c_mod_mul_1,
+    ecc_gost_gc256c_mod_submul_1,
+  },
+  {
+    256,
+    ECC_LIMB_SIZE,
+    ECC_BMODQ_SIZE,
+    0,
+    ECC_MOD_INV_ITCH (ECC_LIMB_SIZE),
+    0,
+
+    ecc_q,
+    ecc_Bmodq,
+    ecc_Bmodq_shifted,
+    NULL,
+    ecc_qp1h,
+
+    ecc_gost_gc256c_modq,
+    ecc_gost_gc256c_modq,
+    ecc_mod_inv,
+    NULL,
+
+    NULL,
+    NULL,
+  },
+
+  USE_REDC,
+  ECC_PIPPENGER_K,
+  ECC_PIPPENGER_C,
+
+  ECC_ADD_JJA_ITCH (ECC_LIMB_SIZE),
+  ECC_ADD_JJJ_ITCH (ECC_LIMB_SIZE),
+  ECC_DUP_JJ_ITCH (ECC_LIMB_SIZE),
+  ECC_MUL_A_ITCH (ECC_LIMB_SIZE),
+  ECC_MUL_G_ITCH (ECC_LIMB_SIZE),
+  ECC_J_TO_A_ITCH (ECC_LIMB_SIZE),
+
+  ecc_add_jja,
+  ecc_add_jjj,
+  ecc_dup_jj,
+  ecc_mul_a,
+  ecc_mul_g,
+  ecc_j_to_a,
+
+  ecc_b,
+  ecc_unit,
+  ecc_table
+};
+
+const struct ecc_curve *nettle_get_gost_gc256c(void)
+{
+  return &amp;_nettle_gost_gc256c;
+}
diff --git a/ecc-internal.h b/ecc-internal.h
index e1380bfb2b20..6b84ba6fb2f4 100644
--- a/ecc-internal.h
+++ b/ecc-internal.h
@@ -94,6 +94,7 @@ extern const struct ecc_curve _nettle_curve448;
 
 /* GOST curves, visible with underscore prefix for now */
 extern const struct ecc_curve _nettle_gost_gc256b;
+extern const struct ecc_curve _nettle_gost_gc256c;
 extern const struct ecc_curve _nettle_gost_gc512a;
 
 #define ECC_MAX_SIZE ((521 + GMP_NUMB_BITS - 1) / GMP_NUMB_BITS)
diff --git a/eccdata.c b/eccdata.c
index 1b4cb0b5083e..182d4982e849 100644
--- a/eccdata.c
+++ b/eccdata.c
@@ -705,6 +705,38 @@ ecc_curve_init (struct ecc_curve *ecc, const char *curve)
 		   "f7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e4b7",
 		   "83ccf17ba6706d73625cc3534c7a2b9d6ec1ee6a9a7e07c10d84b388de59f741");
 
+    }
+  else if (!strcmp (curve, "gost_gc256c"))
+    {
+      ecc_curve_init_str (ecc, ECC_TYPE_WEIERSTRASS,
+			  "80000000000000000000000000000000"
+			  "00000000000000000000000000000c99",
+
+			  "3e1af419a269a5f866a7d3c25c3df80a"
+			  "e979259373ff2b182f49d4ce7e1bbc8b",
+
+			  "80000000000000000000000000000001"
+			  "5f700cfff1a624e5e497161bcc8a198f",
+
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000001",
+
+			  "3fa8124359f96680b83d1c3eb2c070e5"
+			  "c545c9858d03ecfb744bf8d717717efc");
+
+      ecc-&gt;ref = ecc_alloc (3);
+      ecc_set_str (&amp;ecc-&gt;ref[0], /* 2 g */
+		   "8000000000000000000000000000000000000000000000000000000000000c97",
+		   "4057edbca606997f47c2e3c14d3f8f1a3aba367a72fc13048bb40728e88e8d9d");
+
+      ecc_set_str (&amp;ecc-&gt;ref[1], /* 3 g */
+		   "1b9a33999d8449c3bbd8cfe49ac6355a2ee0827a6c71687c86cb7b0670efe205",
+		   "1876d998a19da37a120e76cb42f4f5225197279b612f712171a4648fe4a3ff12");
+
+      ecc_set_str (&amp;ecc-&gt;ref[2], /* 4 g */
+		   "5fa13ecfadd7ae00c2e65d0ac6cac1deda6d60e577afe90915671b08bbb9065e",
+		   "1b3c2859166129ac6dafee570ab9d40d33fdc25c7253c72f4e3fa77223ab016a");
+
     }
   else if (!strcmp (curve, "gost_gc512a"))
     {
diff --git a/examples/ecc-benchmark.c b/examples/ecc-benchmark.c
index a529cf16ab3a..b774d046ea20 100644
--- a/examples/ecc-benchmark.c
+++ b/examples/ecc-benchmark.c
@@ -315,6 +315,7 @@ const struct ecc_curve * const curves[] = {
   &amp;_nettle_curve448,
   &amp;_nettle_secp_521r1,
   &amp;_nettle_gost_gc256b,
+  &amp;_nettle_gost_gc256c,
   &amp;_nettle_gost_gc512a,
 };
 
diff --git a/nettle.texinfo b/nettle.texinfo
index 19eb6d3472a2..a576c0417c4a 100644
--- a/nettle.texinfo
+++ b/nettle.texinfo
@@ -5112,6 +5112,14 @@ Returns curve corresponding to following identifiers:
 @end itemize
 @end deftypefun
 
+@deftypefun {const struct ecc_curve} nettle_get_gost_gc256c(void)
+Returns curve corresponding to following identifiers:
+@itemize
+@item id-GostR3410-2001-CryptoPro-B-ParamSet (@cite{RFC 4357})
+@item id-tc26-gost-3410-12-256-paramSetC
+@end itemize
+@end deftypefun
+
 @deftypefun {const struct ecc_curve} nettle_get_gost_gc512a(void)
 Returns curve corresponding to following identifiers:
 @itemize
diff --git a/testsuite/gostdsa-sign-test.c b/testsuite/gostdsa-sign-test.c
index 0e2e0420a313..4d25f9521d37 100644
--- a/testsuite/gostdsa-sign-test.c
+++ b/testsuite/gostdsa-sign-test.c
@@ -70,6 +70,17 @@ test_main (void)
 
 	      "5E5B9B805B01147A8492C4A162643AC615DC777B9174108F3DC276A41F987AF3"); /* s */
 
+  test_gostdsa (nettle_get_gost_gc256c(),
+	      "3FCF1D623E5CDD3032A7C6EABB4A923C46E43D640FFEAAF2C3ED39A8FA399924", /* z */
+
+	      "5782C53F110C596F9155D35EBD25A06A89C50391850A8FEFE33B0E270318857C", /* k */
+
+	      SHEX("1C067E20EA6CB183F22EFB0F3C6FD2A4E6A02821CB7A1B17FACD5E1F7AA76F70"), /* h */
+
+	      "4E8F9973B31A134CE0942421573B0529B07EC96B835A07856C16CE8070C62547", /* r */
+
+	      "10CE0EFA72741D5EB24837563AAB9369781D6F487ACF88BBEE3E49EC239F6A90"); /* s */
+
   test_gostdsa (nettle_get_gost_gc512a(),
 	      "3FC01CDCD4EC5F972EB482774C41E66DB7F380528DFE9E67992BA05AEE462435"
 	      "757530E641077CE587B976C8EEB48C48FD33FD175F0C7DE6A44E014E6BCB074B", /* z */
diff --git a/testsuite/gostdsa-verify-test.c b/testsuite/gostdsa-verify-test.c
index 7279f5f46c5b..66660a2c0ad7 100644
--- a/testsuite/gostdsa-verify-test.c
+++ b/testsuite/gostdsa-verify-test.c
@@ -93,6 +93,17 @@ test_main (void)
 
 	      "5E5B9B805B01147A8492C4A162643AC615DC777B9174108F3DC276A41F987AF3"); /* s */
 
+  test_gostdsa (nettle_get_gost_gc256c(),
+	      "347E354F60B8DA8DE659B432600418C7D0E70F01622477579FAB36A066B9B8FD", /* x */
+
+	      "1DD2E31CF7840A5109DFAB561E15D42BC3CE2E64995FB70F3B86679655A1BAA1", /* y */
+
+	      SHEX("1C067E20EA6CB183F22EFB0F3C6FD2A4E6A02821CB7A1B17FACD5E1F7AA76F70"), /* h */
+
+	      "4E8F9973B31A134CE0942421573B0529B07EC96B835A07856C16CE8070C62547", /* r */
+
+	      "10CE0EFA72741D5EB24837563AAB9369781D6F487ACF88BBEE3E49EC239F6A90"); /* s */
+
   test_gostdsa (nettle_get_gost_gc512a(),
 	      "03A36340A95BB5F93D131961B5B1C1B3213DF7FF3B5A30376407E2A65C441BC6"
 	      "D1B34662317083243F007B15A8512B526606D3B172B606DCE86DBD6F82DA3D40", /* x */
diff --git a/testsuite/testutils.c b/testsuite/testutils.c
index 187da0efda29..81952055c8d3 100644
--- a/testsuite/testutils.c
+++ b/testsuite/testutils.c
@@ -1677,6 +1677,7 @@ const struct ecc_curve * const ecc_curves[] = {
   &amp;_nettle_curve25519,
   &amp;_nettle_curve448,
   &amp;_nettle_gost_gc256b,
+  &amp;_nettle_gost_gc256c,
   &amp;_nettle_gost_gc512a,
   NULL
 };
@@ -1726,7 +1727,7 @@ test_ecc_point (const struct ecc_curve *ecc,
 }
 
 /* For each curve, the points g, 2 g, 3 g and 4 g */
-static const struct ecc_ref_point ecc_ref[9][4] = {
+static const struct ecc_ref_point ecc_ref[10][4] = {
   { { "188da80eb03090f67cbf20eb43a18800f4ff0afd82ff1012",
       "07192b95ffc8da78631011ed6b24cdd573f977a11e794811" },
     { "dafebf5828783f2ad35534631588a3f629a70fb16982a888",
@@ -1824,6 +1825,15 @@ static const struct ecc_ref_point ecc_ref[9][4] = {
     { "f7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e4b7",
       "83ccf17ba6706d73625cc3534c7a2b9d6ec1ee6a9a7e07c10d84b388de59f741" },
   },
+  { { "0000000000000000000000000000000000000000000000000000000000000001",
+      "3fa8124359f96680b83d1c3eb2c070e5c545c9858d03ecfb744bf8d717717efc" },
+    { "8000000000000000000000000000000000000000000000000000000000000c97",
+      "4057edbca606997f47c2e3c14d3f8f1a3aba367a72fc13048bb40728e88e8d9d" },
+    { "1b9a33999d8449c3bbd8cfe49ac6355a2ee0827a6c71687c86cb7b0670efe205",
+      "1876d998a19da37a120e76cb42f4f5225197279b612f712171a4648fe4a3ff12" },
+    { "5fa13ecfadd7ae00c2e65d0ac6cac1deda6d60e577afe90915671b08bbb9065e",
+      "1b3c2859166129ac6dafee570ab9d40d33fdc25c7253c72f4e3fa77223ab016a" },
+  },
   { { "0000000000000000000000000000000000000000000000000000000000000000"
       "0000000000000000000000000000000000000000000000000000000000000003",
       "7503cfe87a836ae3a61b8816e25450e6ce5e1c93acf1abc1778064fdcbefa921"
@@ -1852,7 +1862,7 @@ test_ecc_ga (unsigned curve, const mp_limb_t *p)
 void
 test_ecc_mul_a (unsigned curve, unsigned n, const mp_limb_t *p)
 {
-  assert (curve &lt; 9);
+  assert (curve &lt; 10);
   assert (n &lt;= 4);
   if (n == 0)
     {
-- 
2.25.0

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200219065101</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-02-19 06:51:01-0400</timestampReceived><subject>Re: [PATCH] Enable/disable gost</subject><body>

Андрей Аладьев &lt;aladjev.andrew@gmail.com&gt; writes:

&gt; I've noticed this flag is already a part of ".gitlab-ci.yml".

In that case, it is passed to gnutls' configure, not nettle's, and there
are some technical reasons for it.

&gt; From my point of view - I don't trust any russian government innovation,
&gt; especially because of their crypto-licensing politics and unknown genesis
&gt; of s-boxes.

Note that nettle supports various known-weak or known-broken algorithms,
for compatibility with old applications and protocols. E.g, original
single DES, MD4 message digests, 512-bit RSA. Selection of appropriate
algorithms and key sizes is left for the application.

&gt; But I am sure that this flag will be used by many people: for
&gt; example openwrt, ddwrt developers don't like additional code.

Nettle doesn't have any fine-grained configure mechanism to control
which algorithms are included in the library. It could be added, but
it's a significant amount of work to make everything configurable, and
it will also add complexity downstream, since removing any algorithm
breaks the shared library ABI. 

On an embedded system like an openwrt router, you could consider using
static libraries; then the linker will pull in only those object files
that are referenced by the main program. (And avoid features like
nettle_get_hashes, since by design that function references all
supported hash algorithms).

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200218215108</emailId><senderName>Андрей Аладьев</senderName><senderEmail>aladjev.andrew@gmail.com</senderEmail><timestampReceived>2020-02-18 21:51:08-0400</timestampReceived><subject>[PATCH] Enable/disable gost</subject><body>

Hello. I saw new master branch received "gost" support.
Please add "--enable-gost" and "--disable-gost" flag.
I've noticed this flag is already a part of ".gitlab-ci.yml".
I will attach patch to this mail.

From my point of view - I don't trust any russian government innovation,
especially because of their crypto-licensing politics and unknown genesis
of s-boxes. But I am sure that this flag will be used by many people: for
example openwrt, ddwrt developers don't like additional code.

By default I've disabled this flag. If you think it is important - please
enable it by default.

Thank you.

["gost.patch" (text/x-patch)]

diff --git a/Makefile.in b/Makefile.in
index d4fcb813..3b06338b 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -62,6 +62,10 @@ dvi installcheck uninstallcheck:
 
 all-here: $(TARGETS) $(DOCTARGETS)
 
+GOST_nettle_SOURCES = @IF_GOST@ \
+		 gost28147.c gosthash94.c gosthash94-meta.c \
+		 hmac-gosthash94.c pbkdf2-hmac-gosthash94.c
+
 nettle_SOURCES = aes-decrypt-internal.c aes-decrypt.c \
 		 aes-encrypt-internal.c aes-encrypt.c aes-encrypt-table.c \
 		 aes-invert-internal.c aes-set-key-internal.c \
@@ -104,8 +108,7 @@ nettle_SOURCES = aes-decrypt-internal.c aes-decrypt.c \
 		 gcm-camellia256.c gcm-camellia256-meta.c \
 		 cmac.c cmac64.c cmac-aes128.c cmac-aes256.c cmac-des3.c \
 		 cmac-aes128-meta.c cmac-aes256-meta.c \
-		 gost28147.c gosthash94.c gosthash94-meta.c \
-		 hmac.c hmac-gosthash94.c hmac-md5.c hmac-ripemd160.c \
+		 hmac.c hmac-md5.c hmac-ripemd160.c \
 		 hmac-sha1.c hmac-sha224.c hmac-sha256.c hmac-sha384.c \
 		 hmac-sha512.c \
 		 hmac-md5-meta.c hmac-ripemd160-meta.c hmac-sha1-meta.c \
@@ -118,7 +121,7 @@ nettle_SOURCES = aes-decrypt-internal.c aes-decrypt.c \
 		 nettle-lookup-hash.c \
 		 nettle-meta-aeads.c nettle-meta-armors.c \
 		 nettle-meta-ciphers.c nettle-meta-hashes.c nettle-meta-macs.c \
-		 pbkdf2.c pbkdf2-hmac-gosthash94.c pbkdf2-hmac-sha1.c \
+		 pbkdf2.c pbkdf2-hmac-sha1.c \
 		 pbkdf2-hmac-sha256.c \
 		 poly1305-aes.c poly1305-internal.c \
 		 realloc.c \
@@ -144,7 +147,13 @@ nettle_SOURCES = aes-decrypt-internal.c aes-decrypt.c \
 		 version.c \
 		 write-be32.c write-le32.c write-le64.c \
 		 yarrow256.c yarrow_key_event.c \
-		 xts.c xts-aes128.c xts-aes256.c
+		 xts.c xts-aes128.c xts-aes256.c \
+		 $(GOST_nettle_SOURCES)
+
+GOST_hogweed_SOURCES = @IF_GOST@ \
+		  ecc-gost-gc256b.c ecc-gost-gc512a.c \
+		  ecc-gostdsa-sign.c gostdsa-sign.c \
+		  ecc-gostdsa-verify.c gostdsa-verify.c
 
 hogweed_SOURCES = sexp.c sexp-format.c \
 		  sexp-transport.c sexp-transport-format.c \
@@ -180,7 +189,6 @@ hogweed_SOURCES = sexp.c sexp-format.c \
 		  ecc-mod.c ecc-mod-inv.c \
 		  ecc-mod-arith.c ecc-pp1-redc.c ecc-pm1-redc.c \
 		  ecc-curve25519.c ecc-curve448.c \
-		  ecc-gost-gc256b.c ecc-gost-gc512a.c \
 		  ecc-secp192r1.c ecc-secp224r1.c ecc-secp256r1.c \
 		  ecc-secp384r1.c ecc-secp521r1.c \
 		  ecc-size.c ecc-j-to-a.c ecc-a-to-j.c \
@@ -193,8 +201,6 @@ hogweed_SOURCES = sexp.c sexp-format.c \
 		  ecc-point.c ecc-scalar.c ecc-point-mul.c ecc-point-mul-g.c \
 		  ecc-ecdsa-sign.c ecdsa-sign.c \
 		  ecc-ecdsa-verify.c ecdsa-verify.c ecdsa-keygen.c \
-		  ecc-gostdsa-sign.c gostdsa-sign.c \
-		  ecc-gostdsa-verify.c gostdsa-verify.c \
 		  curve25519-mul-g.c curve25519-mul.c curve25519-eh-to-x.c \
 		  curve448-mul-g.c curve448-mul.c curve448-eh-to-x.c \
 		  eddsa-compress.c eddsa-decompress.c eddsa-expand.c \
@@ -202,16 +208,19 @@ hogweed_SOURCES = sexp.c sexp-format.c \
 		  ed25519-sha512.c ed25519-sha512-pubkey.c \
 		  ed25519-sha512-sign.c ed25519-sha512-verify.c \
 		  ed448-shake256.c ed448-shake256-pubkey.c \
-		  ed448-shake256-sign.c ed448-shake256-verify.c
+		  ed448-shake256-sign.c ed448-shake256-verify.c \
+		  $(GOST_hogweed_SOURCES)
 
 OPT_SOURCES = fat-x86_64.c fat-arm.c mini-gmp.c
 
+GOST_HEADERS = @IF_GOST@ gostdsa.h gosthash94.h
+
 HEADERS = aes.h arcfour.h arctwo.h asn1.h blowfish.h \
 	  base16.h base64.h bignum.h buffer.h camellia.h cast128.h \
 	  cbc.h ccm.h cfb.h chacha.h chacha-poly1305.h ctr.h \
 	  curve25519.h curve448.h des.h dsa.h dsa-compat.h eax.h \
 	  ecc-curve.h ecc.h ecdsa.h eddsa.h \
-	  gcm.h gostdsa.h gosthash94.h hmac.h \
+	  gcm.h hmac.h \
 	  knuth-lfib.h hkdf.h \
 	  macros.h \
 	  cmac.h siv-cmac.h \
@@ -223,7 +232,8 @@ HEADERS = aes.h arcfour.h arctwo.h asn1.h blowfish.h \
 	  pgp.h pkcs1.h pss.h pss-mgf1.h realloc.h ripemd160.h rsa.h \
 	  salsa20.h sexp.h \
 	  serpent.h sha.h sha1.h sha2.h sha3.h twofish.h \
-	  umac.h yarrow.h xts.h poly1305.h
+	  umac.h yarrow.h xts.h poly1305.h \
+	  $(GOST_HEADERS)
 
 INSTALL_HEADERS = $(HEADERS) version.h @IF_MINI_GMP@ mini-gmp.h
 
@@ -232,6 +242,8 @@ SOURCES = $(nettle_SOURCES) $(hogweed_SOURCES) \
 	  $(OPT_SOURCES) \
 	  aesdata.c desdata.c twofishdata.c shadata.c gcmdata.c eccdata.c
 
+GOST_DISTFILES = @IF_GOST@ gost28147-internal.h
+
 # NOTE: This list must include all source files, with no duplicates,
 # independently of which source files are included in the build.
 DISTFILES = $(SOURCES) $(HEADERS) getopt.h getopt_int.h \
@@ -246,7 +258,7 @@ DISTFILES = $(SOURCES) $(HEADERS) getopt.h getopt_int.h \
 	nettle.pc.in hogweed.pc.in \
 	$(des_headers) descore.README desdata.stamp \
 	aes-internal.h block-internal.h camellia-internal.h \
-	gost28147-internal.h serpent-internal.h \
+	serpent-internal.h \
 	cast128_sboxes.h desinfo.h desCode.h \
 	ripemd160-internal.h sha2-internal.h \
 	memxor-internal.h nettle-internal.h nettle-write.h \
@@ -255,7 +267,8 @@ DISTFILES = $(SOURCES) $(HEADERS) getopt.h getopt_int.h \
 	rsa-internal.h pkcs1-internal.h dsa-internal.h eddsa-internal.h \
 	gmp-glue.h ecc-internal.h fat-setup.h \
 	mini-gmp.h asm.m4 \
-	nettle.texinfo nettle.info nettle.html nettle.pdf sha-example.c
+	nettle.texinfo nettle.info nettle.html nettle.pdf sha-example.c \
+	$(GOST_DISTFILES)
 
 # Rules building static libraries
 nettle_OBJS = $(nettle_SOURCES:.c=.$(OBJEXT)) \
@@ -401,7 +414,7 @@ ecc-gost-gc512a.h: eccdata.stamp
 	./eccdata$(EXEEXT_FOR_BUILD) gost_gc512a 43 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
 
 eccdata.stamp: eccdata.c
-	$(MAKE) eccdata$(EXEEXT_FOR_BUILD)
+	$(COMPILE) $&lt; -o eccdata$(EXEEXT_FOR_BUILD)
 	echo stamp &gt; eccdata.stamp
 
 ecc-curve25519.$(OBJEXT): ecc-curve25519.h
@@ -658,10 +671,11 @@ distcheck: dist
 	       exit 1; }
 	$(rm_distcheck)
 
+GOST_CLEAN = @IF_GOST@ ecc-gost-gc256b.h ecc-gost-gc512a.h
+
 clean-here:
 	-rm -f $(TARGETS) *.$(OBJEXT) *.$(OBJEXT).d *.s *.so *.dll *.a \
 		ecc-curve25519.h ecc-curve448.h \
-		ecc-gost-gc256b.h ecc-gost-gc512a.h \
 		ecc-secp192r1.h ecc-secp224r1.h ecc-secp256r1.h \
 		ecc-secp384r1.h ecc-secp521r1.h \
 		aesdata$(EXEEXT_FOR_BUILD) \
@@ -669,7 +683,8 @@ clean-here:
 		twofishdata$(EXEEXT_FOR_BUILD) \
 		shadata$(EXEEXT_FOR_BUILD) \
 		gcmdata$(EXEEXT_FOR_BUILD) \
-		eccdata$(EXEEXT_FOR_BUILD) eccdata.stamp
+		eccdata$(EXEEXT_FOR_BUILD) eccdata.stamp \
+		$(GOST_CLEAN)
 	-rm -rf .lib libnettle.stamp libhogweed.stamp
 
 distclean-here: clean-here
diff --git a/configure.ac b/configure.ac
index ba3ab7c6..a3235dd0 100644
--- a/configure.ac
+++ b/configure.ac
@@ -93,6 +93,10 @@ AC_ARG_ENABLE(mini-gmp,
   AC_HELP_STRING([--enable-mini-gmp], [Enable mini-gmp, used instead of libgmp.]),,
   [enable_mini_gmp=no])
 
+AC_ARG_ENABLE(gost,
+  AC_HELP_STRING([--enable-gost], [Enable gost. (default=no)]),,
+  [enable_gost=no])
+
 if test "x$enable_mini_gmp" = xyes ; then
   NETTLE_USE_MINI_GMP=1
   HOGWEED_EXTRA_SYMBOLS="mpz_*;gmp_*;mpn_*;mp_*;"
@@ -888,7 +892,16 @@ if test "x$enable_mini_gmp" = "xyes" ; then
 else
   IF_MINI_GMP='#'
 fi
-  
+
+AH_TEMPLATE([WITH_GOST], [Defined if gost is enabled])
+
+if test "x$enable_gost" = "xyes" ; then
+  AC_DEFINE(WITH_GOST)
+  IF_GOST=''
+else
+  IF_GOST='#'
+fi
+
 AC_SUBST(IF_HOGWEED)
 AC_SUBST(IF_STATIC)
 AC_SUBST(IF_SHARED)
@@ -897,6 +910,7 @@ AC_SUBST(IF_DLOPEN_TEST)
 AC_SUBST(IF_DOCUMENTATION)
 AC_SUBST(IF_DLL)
 AC_SUBST(IF_MINI_GMP)
+AC_SUBST(IF_GOST)
 
 OPENSSL_LIBFLAGS=''
 
@@ -980,5 +994,6 @@ AC_MSG_NOTICE([summary of build options:
   Shared libraries:  ${enable_shared}
   Public key crypto: ${enable_public_key}
   Using mini-gmp:    ${enable_mini_gmp}
+  Gost:              ${enable_gost}
   Documentation:     ${enable_documentation}
 ])
diff --git a/ecc-curve.h b/ecc-curve.h
index 8f050404..27330846 100644
--- a/ecc-curve.h
+++ b/ecc-curve.h
@@ -43,8 +43,10 @@ extern "C" {
 /* The contents of this struct is internal. */
 struct ecc_curve;
 
+#if WITH_GOST
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_gost_gc256b(void);
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_gost_gc512a(void);
+#endif
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_secp_192r1(void);
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_secp_224r1(void);
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_secp_256r1(void);
diff --git a/ecc-hash.c b/ecc-hash.c
index 07877110..0d8fc737 100644
--- a/ecc-hash.c
+++ b/ecc-hash.c
@@ -63,6 +63,7 @@ ecc_hash (const struct ecc_modulo *m,
     mpn_rshift (hp, hp, m-&gt;size + 1, 8*length - m-&gt;bit_size);
 }
 
+#if WITH_GOST
 void
 gost_hash (const struct ecc_modulo *m,
 	   mp_limb_t *hp,
@@ -73,3 +74,4 @@ gost_hash (const struct ecc_modulo *m,
 
   mpn_set_base256_le (hp, m-&gt;size + 1, digest, length);
 }
+#endif
diff --git a/ecc-internal.h b/ecc-internal.h
index 9e24e0ce..7d86a7e4 100644
--- a/ecc-internal.h
+++ b/ecc-internal.h
@@ -53,7 +53,9 @@
 #define ecc_mod _nettle_ecc_mod
 #define ecc_mod_inv _nettle_ecc_mod_inv
 #define ecc_hash _nettle_ecc_hash
+#if WITH_GOST
 #define gost_hash _nettle_gost_hash
+#endif
 #define ecc_a_to_j _nettle_ecc_a_to_j
 #define ecc_j_to_a _nettle_ecc_j_to_a
 #define ecc_eh_to_a _nettle_ecc_eh_to_a
@@ -92,9 +94,11 @@ extern const struct ecc_curve _nettle_secp_521r1;
 extern const struct ecc_curve _nettle_curve25519;
 extern const struct ecc_curve _nettle_curve448;
 
+#if WITH_GOST
 /* GOST curves, visible with underscore prefix for now */
 extern const struct ecc_curve _nettle_gost_gc256b;
 extern const struct ecc_curve _nettle_gost_gc512a;
+#endif
 
 #define ECC_MAX_SIZE ((521 + GMP_NUMB_BITS - 1) / GMP_NUMB_BITS)
 
@@ -266,10 +270,12 @@ ecc_hash (const struct ecc_modulo *m,
 	  mp_limb_t *hp,
 	  size_t length, const uint8_t *digest);
 
+#if WITH_GOST
 void
 gost_hash (const struct ecc_modulo *m,
 	  mp_limb_t *hp,
 	  size_t length, const uint8_t *digest);
+#endif
 
 /* Converts a point P in affine coordinates into a point R in jacobian
    coordinates. */
@@ -439,7 +445,9 @@ curve448_eh_to_x (mp_limb_t *xp, const mp_limb_t *p,
 #endif
 #define ECC_MUL_M_ITCH(size) (11*(size))
 #define ECC_ECDSA_SIGN_ITCH(size) (12*(size))
+#if WITH_GOST
 #define ECC_GOSTDSA_SIGN_ITCH(size) (12*(size))
+#endif
 #define ECC_MOD_RANDOM_ITCH(size) (size)
 #define ECC_HASH_ITCH(size) (1+(size))
 
diff --git a/eccdata.c b/eccdata.c
index 1b4cb0b5..544486fd 100644
--- a/eccdata.c
+++ b/eccdata.c
@@ -35,6 +35,10 @@
 
 /* Development of Nettle's ECC support was funded by the .SE Internet Fund. */
 
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
 #include &lt;assert.h&gt;
 #include &lt;stdio.h&gt;
 #include &lt;stdlib.h&gt;
@@ -674,6 +678,8 @@ ecc_curve_init (struct ecc_curve *ecc, const char *curve)
 		   "47d0e827cb1595e1470eb88580d5716c"
 		   "4cf22832ea2f0ff0df38ab61ca32112f");
     }
+
+#if WITH_GOST
   else if (!strcmp (curve, "gost_gc256b"))
     {
       ecc_curve_init_str (ecc, ECC_TYPE_WEIERSTRASS,
@@ -744,6 +750,8 @@ ecc_curve_init (struct ecc_curve *ecc, const char *curve)
 		   "3bee95e29eecc5d5ad2beba941abcbf9f1cad478df0fecf614f63aeebef77850da7efdb93de8f3df80bc25eac09239c14175f5c29704ce9a3e383f1b3ec0e929");
  
     }
+#endif
+
   else if (!strcmp (curve, "curve448"))
     {
       /* curve448, y^2 = x^3 + 156326 x^2 + x (mod p), with p = 2^{448} - 2^{224} - \
1. @@ -842,7 +850,7 @@ ecc_curve_clear (struct ecc_curve *ecc)
   ecc_clear (&amp;ecc-&gt;g);
   if (ecc-&gt;table)
     {
-      size_t i;
+      mp_size_t i;
       for (i = 0; i &lt; ecc-&gt;table_size; i++)
 	ecc_clear (&amp;ecc-&gt;table[i]);
       free (ecc-&gt;table);
diff --git a/examples/ecc-benchmark.c b/examples/ecc-benchmark.c
index a529cf16..951fe7f8 100644
--- a/examples/ecc-benchmark.c
+++ b/examples/ecc-benchmark.c
@@ -314,8 +314,10 @@ const struct ecc_curve * const curves[] = {
   &amp;_nettle_secp_384r1,
   &amp;_nettle_curve448,
   &amp;_nettle_secp_521r1,
+#if WITH_GOST
   &amp;_nettle_gost_gc256b,
   &amp;_nettle_gost_gc512a,
+#endif
 };
 
 #define numberof(x)  (sizeof (x) / sizeof ((x)[0]))
diff --git a/examples/hogweed-benchmark.c b/examples/hogweed-benchmark.c
index 3d008021..a6443fd1 100644
--- a/examples/hogweed-benchmark.c
+++ b/examples/hogweed-benchmark.c
@@ -48,7 +48,9 @@
 #include "dsa.h"
 #include "rsa.h"
 #include "eddsa.h"
+#if WITH_GOST
 #include "gostdsa.h"
+#endif
 #include "curve25519.h"
 #include "curve448.h"
 
@@ -592,6 +594,7 @@ bench_eddsa_clear (void *p)
   free (p);
 }
 
+#if WITH_GOST
 static void *
 bench_gostdsa_init (unsigned size)
 {
@@ -692,6 +695,7 @@ bench_gostdsa_clear (void *p)
 
   free (ctx);
 }
+#endif
 
 #if WITH_OPENSSL
 struct openssl_rsa_ctx
@@ -940,8 +944,10 @@ struct alg alg_list[] = {
   { "eddsa", 448, bench_eddsa_init, bench_eddsa_sign, bench_eddsa_verify, \
bench_eddsa_clear },  { "curve", 255, bench_curve_init, bench_curve_mul_g, \
bench_curve_mul, bench_curve_clear},  { "curve", 448, bench_curve_init, \
bench_curve_mul_g, bench_curve_mul, bench_curve_clear }, +#if WITH_GOST
   { "gostdsa",  256, bench_gostdsa_init, bench_gostdsa_sign, bench_gostdsa_verify, \
bench_gostdsa_clear },  { "gostdsa",  512, bench_gostdsa_init, bench_gostdsa_sign, \
bench_gostdsa_verify, bench_gostdsa_clear }, +#endif
 };
 
 #define numberof(x)  (sizeof (x) / sizeof ((x)[0]))
diff --git a/examples/nettle-benchmark.c b/examples/nettle-benchmark.c
index 5d0e649e..0d22e040 100644
--- a/examples/nettle-benchmark.c
+++ b/examples/nettle-benchmark.c
@@ -896,6 +896,12 @@ bench_sha3_permute(void)
 # define OPENSSL(x)
 #endif
 
+#if WITH_GOST
+# define GOST(x) x,
+#else
+# define GOST(x)
+#endif
+
 int
 main(int argc, char **argv)
 {
@@ -917,8 +923,8 @@ main(int argc, char **argv)
       &amp;nettle_sha512_224, &amp;nettle_sha512_256,
       &amp;nettle_sha3_224, &amp;nettle_sha3_256,
       &amp;nettle_sha3_384, &amp;nettle_sha3_512,
-      &amp;nettle_ripemd160, &amp;nettle_gosthash94,
-      &amp;nettle_gosthash94cp,
+      &amp;nettle_ripemd160, GOST(&amp;nettle_gosthash94)
+      GOST(&amp;nettle_gosthash94cp)
       NULL
     };
 
diff --git a/hmac.h b/hmac.h
index d9ee3400..c1ad1975 100644
--- a/hmac.h
+++ b/hmac.h
@@ -36,7 +36,9 @@
 
 #include "nettle-meta.h"
 
+#if WITH_GOST
 #include "gosthash94.h"
+#endif
 #include "md5.h"
 #include "ripemd160.h"
 #include "sha1.h"
@@ -69,12 +71,14 @@ extern "C" {
 #define hmac_sha512_set_key nettle_hmac_sha512_set_key
 #define hmac_sha512_update nettle_hmac_sha512_update
 #define hmac_sha512_digest nettle_hmac_sha512_digest
+#if WITH_GOST
 #define hmac_gosthash94_set_key nettle_hmac_gosthash94_set_key
 #define hmac_gosthash94_update nettle_hmac_gosthash94_update
 #define hmac_gosthash94_digest nettle_hmac_gosthash94_digest
 #define hmac_gosthash94cp_set_key nettle_hmac_gosthash94cp_set_key
 #define hmac_gosthash94cp_update nettle_hmac_gosthash94cp_update
 #define hmac_gosthash94cp_digest nettle_hmac_gosthash94cp_digest
+#endif
 
 void
 hmac_set_key(void *outer, void *inner, void *state,
@@ -210,6 +214,7 @@ void
 hmac_sha384_digest(struct hmac_sha512_ctx *ctx,
 		   size_t length, uint8_t *digest);
 
+#if WITH_GOST
 /* hmac-gosthash94 */
 struct hmac_gosthash94_ctx HMAC_CTX(struct gosthash94_ctx);
 
@@ -238,6 +243,7 @@ hmac_gosthash94cp_update(struct hmac_gosthash94cp_ctx *ctx,
 void
 hmac_gosthash94cp_digest(struct hmac_gosthash94cp_ctx *ctx,
 			 size_t length, uint8_t *digest);
+#endif
 
 
 #ifdef __cplusplus
diff --git a/mini-gmp.c b/mini-gmp.c
index d4d257c4..a865d0ce 100644
--- a/mini-gmp.c
+++ b/mini-gmp.c
@@ -270,7 +270,7 @@ gmp_default_alloc (size_t size)
 }
 
 static void *
-gmp_default_realloc (void *old, size_t old_size, size_t new_size)
+gmp_default_realloc (void *old, size_t old_size UNUSED, size_t new_size)
 {
   void * p;
 
@@ -283,7 +283,7 @@ gmp_default_realloc (void *old, size_t old_size, size_t new_size)
 }
 
 static void
-gmp_default_free (void *p, size_t size)
+gmp_default_free (void *p, size_t size UNUSED)
 {
   free (p);
 }
diff --git a/nettle-meta-hashes.c b/nettle-meta-hashes.c
index 27b576cd..ba2a4f66 100644
--- a/nettle-meta-hashes.c
+++ b/nettle-meta-hashes.c
@@ -38,8 +38,10 @@
 #include "nettle-meta.h"
 
 const struct nettle_hash * const _nettle_hashes[] = {
+#if WITH_GOST
   &amp;nettle_gosthash94,
   &amp;nettle_gosthash94cp,
+#endif
   &amp;nettle_md2,
   &amp;nettle_md4,
   &amp;nettle_md5,
diff --git a/nettle-meta.h b/nettle-meta.h
index 5d86615f..d3a49105 100644
--- a/nettle-meta.h
+++ b/nettle-meta.h
@@ -129,8 +129,10 @@ nettle_lookup_hash (const char *name);
 extern const struct nettle_hash nettle_md2;
 extern const struct nettle_hash nettle_md4;
 extern const struct nettle_hash nettle_md5;
+#if WITH_GOST
 extern const struct nettle_hash nettle_gosthash94;
 extern const struct nettle_hash nettle_gosthash94cp;
+#endif
 extern const struct nettle_hash nettle_ripemd160;
 extern const struct nettle_hash nettle_sha1;
 extern const struct nettle_hash nettle_sha224;
diff --git a/pbkdf2.h b/pbkdf2.h
index a36dfdba..65525132 100644
--- a/pbkdf2.h
+++ b/pbkdf2.h
@@ -45,7 +45,9 @@ extern "C"
 #define pbkdf2 nettle_pbkdf2
 #define pbkdf2_hmac_sha1 nettle_pbkdf2_hmac_sha1
 #define pbkdf2_hmac_sha256 nettle_pbkdf2_hmac_sha256
+#if WITH_GOST
 #define pbkdf2_hmac_gosthash94cp nettle_pbkdf2_hmac_gosthash94cp
+#endif
 
 void
 pbkdf2 (void *mac_ctx,
@@ -79,11 +81,13 @@ pbkdf2_hmac_sha256 (size_t key_length, const uint8_t *key,
 		    size_t salt_length, const uint8_t *salt,
 		    size_t length, uint8_t *dst);
 
+#if WITH_GOST
 void
 pbkdf2_hmac_gosthash94cp (size_t key_length, const uint8_t *key,
 			  unsigned iterations,
 			  size_t salt_length, const uint8_t *salt,
 			  size_t length, uint8_t *dst);
+#endif
 
 #ifdef __cplusplus
 }
diff --git a/testsuite/Makefile.in b/testsuite/Makefile.in
index 813467a5..7791fe69 100644
--- a/testsuite/Makefile.in
+++ b/testsuite/Makefile.in
@@ -10,6 +10,8 @@ include ../config.make
 PRE_CPPFLAGS = -I.. -I$(top_srcdir)
 PRE_LDFLAGS = -L..
 
+GOST_TS_NETTLE_SOURCES = @IF_GOST@ gosthash94-test.c
+
 TS_NETTLE_SOURCES = aes-test.c arcfour-test.c arctwo-test.c \
 		    blowfish-test.c cast128-test.c \
 	            base16-test.c base64-test.c \
@@ -17,7 +19,7 @@ TS_NETTLE_SOURCES = aes-test.c arcfour-test.c arctwo-test.c \
 		    cnd-memcpy-test.c \
 		    des-test.c des3-test.c \
 		    md2-test.c md4-test.c md5-test.c md5-compat-test.c \
-		    memeql-test.c memxor-test.c gosthash94-test.c \
+		    memeql-test.c memxor-test.c \
 		    ripemd160-test.c hkdf-test.c \
 		    salsa20-test.c \
 		    sha1-test.c sha224-test.c sha256-test.c \
@@ -33,7 +35,12 @@ TS_NETTLE_SOURCES = aes-test.c arcfour-test.c arctwo-test.c \
 		    hmac-test.c umac-test.c \
 		    meta-hash-test.c meta-cipher-test.c\
 		    meta-aead-test.c meta-armor-test.c meta-mac-test.c \
-		    buffer-test.c yarrow-test.c xts-test.c pbkdf2-test.c
+		    buffer-test.c yarrow-test.c xts-test.c pbkdf2-test.c \
+		    $(GOST_TS_NETTLE_SOURCES)
+
+GOST_TS_HOGWEED_SOURCES = @IF_GOST@ \
+		     gostdsa-sign-test.c gostdsa-verify-test.c \
+		     gostdsa-keygen-test.c
 
 TS_HOGWEED_SOURCES = sexp-test.c sexp-format-test.c \
 		     rsa2sexp-test.c sexp2rsa-test.c \
@@ -54,8 +61,7 @@ TS_HOGWEED_SOURCES = sexp-test.c sexp-format-test.c \
 		     ecdsa-keygen-test.c ecdh-test.c \
 		     eddsa-compress-test.c eddsa-sign-test.c \
 		     eddsa-verify-test.c ed25519-test.c ed448-test.c \
-		     gostdsa-sign-test.c gostdsa-verify-test.c \
-		     gostdsa-keygen-test.c
+		     $(GOST_TS_HOGWEED_SOURCES)
 
 TS_SOURCES = $(TS_NETTLE_SOURCES) $(TS_HOGWEED_SOURCES)
 CXX_SOURCES = cxx-test.cxx
diff --git a/testsuite/hmac-test.c b/testsuite/hmac-test.c
index de1b6bfe..a0130747 100644
--- a/testsuite/hmac-test.c
+++ b/testsuite/hmac-test.c
@@ -853,6 +853,7 @@ test_main(void)
 
   /* Test case AUTH512-3 from same document seems broken. */
 
+#if WITH_GOST
   HMAC_TEST(gosthash94,
 	    SHEX("000102030405060708090a0b0c0d0e0f"
 		 "101112131415161718191a1b1c1d1e1f"),
@@ -866,4 +867,5 @@ test_main(void)
 	    SHEX("0126bdb87800af214341456563780100"),
 	    SHEX("bad70b61c41095bc47e1141cfaed4272"
 		 "6a5ceebd62ce75dbbb9ad76cda9f72f7"));
+#endif
 }
diff --git a/testsuite/meta-hash-test.c b/testsuite/meta-hash-test.c
index 7d863a7c..ec4035a1 100644
--- a/testsuite/meta-hash-test.c
+++ b/testsuite/meta-hash-test.c
@@ -5,8 +5,10 @@
 #include "sha3.h"
 
 const char* hashes[] = {
+#if WITH_GOST
   "gosthash94",
   "gosthash94cp",
+#endif
   "md2",
   "md4",
   "md5",
diff --git a/testsuite/pbkdf2-test.c b/testsuite/pbkdf2-test.c
index e64a20d0..a17ae187 100644
--- a/testsuite/pbkdf2-test.c
+++ b/testsuite/pbkdf2-test.c
@@ -28,7 +28,9 @@ test_main (void)
   struct hmac_sha1_ctx sha1ctx;
   struct hmac_sha256_ctx sha256ctx;
   struct hmac_sha512_ctx sha512ctx;
+#if WITH_GOST
   struct hmac_gosthash94cp_ctx gosthash94cpctx;
+#endif
 
   /* Test vectors for PBKDF2 from RFC 6070. */
 
@@ -111,6 +113,7 @@ test_main (void)
   PBKDF2_HMAC_TEST(pbkdf2_hmac_sha256, LDATA("passwd"), 1, LDATA("salt"),
 		   SHEX("55ac046e56e3089fec1691c22544b605"));
 
+#if WITH_GOST
   /* From TC26 document, MR 26.2.001-2012 */
 
   hmac_gosthash94cp_set_key (&amp;gosthash94cpctx, LDATA("password"));
@@ -134,4 +137,5 @@ test_main (void)
 
   PBKDF2_HMAC_TEST (pbkdf2_hmac_gosthash94cp, LDATA("password"), 1, LDATA("salt"),
 	       SHEX("7314e7c04fb2e662c543674253f68bd0b73445d07f241bed872882da21662d58"));
+#endif
 }
diff --git a/testsuite/testutils.c b/testsuite/testutils.c
index 187da0ef..37cd6039 100644
--- a/testsuite/testutils.c
+++ b/testsuite/testutils.c
@@ -1676,8 +1676,10 @@ const struct ecc_curve * const ecc_curves[] = {
   &amp;_nettle_secp_521r1,
   &amp;_nettle_curve25519,
   &amp;_nettle_curve448,
+#if WITH_GOST
   &amp;_nettle_gost_gc256b,
   &amp;_nettle_gost_gc512a,
+#endif
   NULL
 };
 


[Attachment #4 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200224183144</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2020-02-24 18:31:44-0400</timestampReceived><subject>Re: Armeb is broken</subject><body>

Hi Dmity,

On Mon, Feb 24, 2020 at 08:58:44PM +0300, Dmitry Baryshkov wrote:

&gt; &gt; &gt; I will check with fresh Yocto build later or tomorrow.
&gt; &gt; Thanks!
&gt; I have checked both armv7vet2b and armv5eb targets with qemu. Your
&gt; patch fixes the issue for me.

Perfect!

@Niels: What do you think of these changes?

These comment changes are bugging me:

diff --git a/arm/memxor.asm b/arm/memxor.asm
index 239a4034..b802e95c 100644
--- a/arm/memxor.asm
+++ b/arm/memxor.asm
@@ -138,24 +138,24 @@ PROLOGUE(nettle_memxor)
 	adds	N, #8
 	beq	.Lmemxor_odd_done
 
-	C We have TNC/8 left-over bytes in r4, high end
+	C We have TNC/8 left-over bytes in r4, (since working upwards) low
+	C end on LE and high end on BE
 	S0ADJ	r4, CNT
 	ldr	r3, [DST]
 	eor	r3, r4
 
diff --git a/arm/memxor3.asm b/arm/memxor3.asm
index 69598e1c..76b8aae6 100644
--- a/arm/memxor3.asm
+++ b/arm/memxor3.asm
@@ -159,21 +159,21 @@ PROLOGUE(nettle_memxor3)
 	adds	N, #8
 	beq	.Lmemxor3_done
 
-	C Leftover bytes in r4, low end
+	C Leftover bytes in r4, (since working downwards) in high end on LE and
+	C low end on BE
 	ldr	r5, [AP, #-4]
 	eor	r4, r5, r4, S1ADJ ATNC
 
Have I totally misunderstood how strb works or how the comment is meant
if to my thinking the bytes are sitting in the low or high end bits of
the register and ror #24 and lsr #8 bring the next byte down into the
lowermost 8 bits for saving by strb?

Full patch for reference again below and at
https://git.lysator.liu.se/michaelweiser/nettle/-/tree/arm-memxor-generic.

If it's acceptable shall I rather git send-email it or do a MR on
gitlab?

&gt; &gt; Could Yocto be used for CI then? Do they do any kind of binary releases
&gt; &gt; for armeb? How long and voluminous is a build of an armeb system with
&gt; &gt; and without a native toolchain?
&gt; No, I found no package feeds/binary releases for armeb. So to use
&gt; Yocto for CI, we'd have to build an image with Yocto SDK inside. I can
&gt; try implementing it.

I'm currently doing the same with buildroot. The advantage there is that
it builds relatively quickly (around an hour on my quad-core
workstation) and with minimal configuration:

FROM debian:buster AS build

MAINTAINER Nikos Mavrogiannopoulos &lt;nmav@redhat.com&gt;

RUN apt-get update -qq -y
RUN apt-get install -y dash [...] g++ cpio unzip bc
# tlsfuzzer deps
RUN apt-get install -y python-six

RUN useradd -m buildroot
USER buildroot

WORKDIR /home/buildroot
RUN git clone https://github.com/buildroot/buildroot
WORKDIR /home/buildroot/buildroot
RUN ( \
        echo 'BR2_armeb=y' ; \
        echo 'BR2_TOOLCHAIN_BUILDROOT_GLIBC=y' ; \
        echo 'BR2_TOOLCHAIN_BUILDROOT_CXX=y' ; \
        echo 'BR2_PACKAGE_GMP=y' ; \
        ) &gt; .config
RUN make olddefconfig
RUN make -j16

The downside is that it will not output a native toolchain for armeb. So
nettle needs to be cross-compiled using the buildroot toolchain and then
run either using the EMULATOR mechanism of the testsuite or by chrooting
into the buildroot rootfs.

So if Yocto can be made to build a native toolchain that would certainly
simplify things (at the cost of image build time).

Do you know Nikos' build-images project for gnutls/nettle
(https://gitlab.com/gnutls/build-images)? There's some qemu bits
(specific to Debian's multiarch though) in docker-debian-cross that
might be helpful.
-- 
Thanks,
Michael

From 3e2118d41472842c368bb5bb56d71023b861b59d Mon Sep 17 00:00:00 2001
From: Michael Weiser &lt;michael.weiser@gmx.de&gt;
Date: Sun, 23 Feb 2020 15:22:51 +0100
Subject: [PATCH] arm: Fix memxor for non-armv6+ big-endian systems

ARM assembly adjustments for big-endian systems contained armv6+-only
instructions (rev) in generic arm memxor code. Replace those with an
actual conversion of the leftover byte store routines for big-endian
systems. This also provides a slight optimisation by removing the
additional instruction as well as increased symmetry between little- and
big-endian implementations.

Signed-off-by: Michael Weiser &lt;michael.weiser@gmx.de&gt;
---
 arm/memxor.asm  | 12 ++++++------
 arm/memxor3.asm | 27 ++++++++++++++-------------
 2 files changed, 20 insertions(+), 19 deletions(-)

diff --git a/arm/memxor.asm b/arm/memxor.asm
index 239a4034..b802e95c 100644
--- a/arm/memxor.asm
+++ b/arm/memxor.asm
@@ -138,24 +138,24 @@ PROLOGUE(nettle_memxor)
 	adds	N, #8
 	beq	.Lmemxor_odd_done
 
-	C We have TNC/8 left-over bytes in r4, high end
+	C We have TNC/8 left-over bytes in r4, (since working upwards) low
+	C end on LE and high end on BE
 	S0ADJ	r4, CNT
 	ldr	r3, [DST]
 	eor	r3, r4
 
-	C memxor_leftover does an LSB store
-	C so we need to reverse if actually BE
-IF_BE(&lt;	rev	r3, r3&gt;)
-
 	pop	{r4,r5,r6}
 
 	C Store bytes, one by one.
 .Lmemxor_leftover:
+	C bring uppermost byte down for saving while preserving lower ones
+IF_BE(&lt;	ror	r3, #24&gt;)
 	strb	r3, [DST], #+1
 	subs	N, #1
 	beq	.Lmemxor_done
 	subs	TNC, #8
-	lsr	r3, #8
+	C bring down next byte, no need to preserve
+IF_LE(&lt;	lsr	r3, #8&gt;)
 	bne	.Lmemxor_leftover
 	b	.Lmemxor_bytes
 .Lmemxor_odd_done:
diff --git a/arm/memxor3.asm b/arm/memxor3.asm
index 69598e1c..76b8aae6 100644
--- a/arm/memxor3.asm
+++ b/arm/memxor3.asm
@@ -159,21 +159,21 @@ PROLOGUE(nettle_memxor3)
 	adds	N, #8
 	beq	.Lmemxor3_done
 
-	C Leftover bytes in r4, low end
+	C Leftover bytes in r4, (since working downwards) in high end on LE and
+	C low end on BE
 	ldr	r5, [AP, #-4]
 	eor	r4, r5, r4, S1ADJ ATNC
 
-	C leftover does an LSB store
-	C so we need to reverse if actually BE
-IF_BE(&lt;	rev	r4, r4&gt;)
-
 .Lmemxor3_au_leftover:
 	C Store a byte at a time
-	ror	r4, #24
+	C bring uppermost byte down for saving while preserving lower ones
+IF_LE(&lt;	ror	r4, #24&gt;)
 	strb	r4, [DST, #-1]!
 	subs	N, #1
 	beq	.Lmemxor3_done
 	subs	ACNT, #8
+	C bring down next byte, no need to preserve
+IF_BE(&lt;	lsr	r4, #8&gt;)
 	sub	AP, #1
 	bne	.Lmemxor3_au_leftover
 	b	.Lmemxor3_bytes
@@ -273,18 +273,19 @@ IF_BE(&lt;	rev	r4, r4&gt;)
 	adds	N, #8
 	beq	.Lmemxor3_done
 
-	C leftover does an LSB store
-	C so we need to reverse if actually BE
-IF_BE(&lt;	rev	r4, r4&gt;)
-
-	C Leftover bytes in a4, low end
-	ror	r4, ACNT
+	C Leftover bytes in r4, (since working downwards) in high end on LE and
+	C low end on BE after preparatory alignment correction
+IF_LE(&lt;	ror	r4, ACNT&gt;)
+IF_BE(&lt;	ror	r4, ATNC&gt;)
 .Lmemxor3_uu_leftover:
-	ror	r4, #24
+	C bring uppermost byte down for saving while preserving lower ones
+IF_LE(&lt;	ror	r4, #24&gt;)
 	strb	r4, [DST, #-1]!
 	subs	N, #1
 	beq	.Lmemxor3_done
 	subs	ACNT, #8
+	C bring down next byte, no need to preserve
+IF_BE(&lt;	lsr	r4, #8&gt;)
 	bne	.Lmemxor3_uu_leftover
 	b	.Lmemxor3_bytes
 
-- 
2.25.0

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200226134836</emailId><senderName>Daiki Ueno</senderName><senderEmail>ueno@gnu.org</senderEmail><timestampReceived>2020-02-26 13:48:36-0400</timestampReceived><subject>[PATCH] chacha: add function to set the initial value of counter</subject><body>

From: Daiki Ueno &lt;dueno@redhat.com&gt;

The ChaCha20 based header protection algorithm in QUIC requires a way
to set the initial value of counter:
https://quicwg.org/base-drafts/draft-ietf-quic-tls.html#name-chacha20-based-header-prote

This will add a new function chacha_set_nonce128, which takes the
counter value embedded in the nonce.

Signed-off-by: Daiki Ueno &lt;dueno@redhat.com&gt;
---
 chacha-set-nonce.c      |  9 +++++++++
 chacha.h                |  5 +++++
 testsuite/chacha-test.c | 15 +++++++++++++++
 3 files changed, 29 insertions(+)

diff --git a/chacha-set-nonce.c b/chacha-set-nonce.c
index 607f176b..7098de58 100644
--- a/chacha-set-nonce.c
+++ b/chacha-set-nonce.c
@@ -68,3 +68,12 @@ chacha_set_nonce96(struct chacha_ctx *ctx, const uint8_t *nonce)
   ctx-&gt;state[14] = LE_READ_UINT32(nonce + 4);
   ctx-&gt;state[15] = LE_READ_UINT32(nonce + 8);
 }
+
+void
+chacha_set_nonce128(struct chacha_ctx *ctx, const uint8_t *nonce)
+{
+  ctx-&gt;state[12] = LE_READ_UINT32(nonce + 0);
+  ctx-&gt;state[13] = LE_READ_UINT32(nonce + 4);
+  ctx-&gt;state[14] = LE_READ_UINT32(nonce + 8);
+  ctx-&gt;state[15] = LE_READ_UINT32(nonce + 12);
+}
diff --git a/chacha.h b/chacha.h
index 429a55b6..ff33f03d 100644
--- a/chacha.h
+++ b/chacha.h
@@ -46,6 +46,7 @@ extern "C" {
 #define chacha_set_key nettle_chacha_set_key
 #define chacha_set_nonce nettle_chacha_set_nonce
 #define chacha_set_nonce96 nettle_chacha_set_nonce96
+#define chacha_set_nonce128 nettle_chacha_set_nonce128
 #define chacha_crypt nettle_chacha_crypt
 
 /* Currently, only 256-bit keys are supported. */
@@ -53,6 +54,7 @@ extern "C" {
 #define CHACHA_BLOCK_SIZE 64
 #define CHACHA_NONCE_SIZE 8
 #define CHACHA_NONCE96_SIZE 12
+#define CHACHA_NONCE128_SIZE 16
 
 #define _CHACHA_STATE_LENGTH 16
 
@@ -81,6 +83,9 @@ chacha_set_nonce(struct chacha_ctx *ctx, const uint8_t *nonce);
 void
 chacha_set_nonce96(struct chacha_ctx *ctx, const uint8_t *nonce);
 
+void
+chacha_set_nonce128(struct chacha_ctx *ctx, const uint8_t *nonce);
+
 void
 chacha_crypt(struct chacha_ctx *ctx, size_t length, 
              uint8_t *dst, const uint8_t *src);
diff --git a/testsuite/chacha-test.c b/testsuite/chacha-test.c
index d6489e9c..4731598b 100644
--- a/testsuite/chacha-test.c
+++ b/testsuite/chacha-test.c
@@ -66,6 +66,10 @@ test_chacha(const struct tstring *key, const struct tstring *nonce,
 		 draft-irtf-cfrg-chacha20-poly1305-08 test cases. */
 	      ctx.state[12]++;
 	    }
+	  else if (nonce-&gt;length == CHACHA_NONCE128_SIZE)
+	    {
+	      chacha_set_nonce128(&amp;ctx, nonce-&gt;data);
+	    }
 	  else
 	    die ("Bad nonce size %u.\n", (unsigned) nonce-&gt;length);
 
@@ -644,4 +648,15 @@ test_main(void)
 		   "d2826446079faa09 14c2d705d98b02a2"
 		   "b5129cd1de164eb9 cbd083e8a2503c4e"),
 	      20);
+
+  /* This is identical to the 96-bit nonce test, but it manually sets
+     the counter value */
+  test_chacha(SHEX("0001020304050607 08090a0b0c0d0e0f"
+		   "1011121314151617 18191a1b1c1d1e1f"),
+	      SHEX("0100000000000009 0000004a00000000"),
+	      SHEX("10f1e7e4d13b5915 500fdd1fa32071c4"
+		   "c7d1f4c733c06803 0422aa9ac3d46c4e"
+		   "d2826446079faa09 14c2d705d98b02a2"
+		   "b5129cd1de164eb9 cbd083e8a2503c4e"),
+	      20);
 }
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200106221643</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-01-06 22:16:43-0400</timestampReceived><subject>[PATCH v3 1/3] ecc: rename source files with curves data</subject><body>

From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;

In preparation to adding GOST curves support, rename source files and
use curve name as eccdata parameter.

Signed-off-by: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;
---
 .gitignore                                    | 14 ++---
 Makefile.in                                   | 54 ++++++++---------
 ...cc-192-modp.asm =&gt; ecc-secp192r1-modp.asm} |  4 +-
 ...cc-224-modp.asm =&gt; ecc-secp224r1-modp.asm} |  4 +-
 ...cc-256-redc.asm =&gt; ecc-secp256r1-redc.asm} |  4 +-
 ...cc-384-modp.asm =&gt; ecc-secp384r1-modp.asm} |  4 +-
 ...cc-521-modp.asm =&gt; ecc-secp521r1-modp.asm} |  4 +-
 configure.ac                                  |  6 +-
 ecc-25519.c =&gt; ecc-curve25519.c               |  4 +-
 ecc-448.c =&gt; ecc-curve448.c                   |  4 +-
 ecc-192.c =&gt; ecc-secp192r1.c                  |  4 +-
 ecc-224.c =&gt; ecc-secp224r1.c                  |  4 +-
 ecc-256.c =&gt; ecc-secp256r1.c                  |  4 +-
 ecc-384.c =&gt; ecc-secp384r1.c                  |  4 +-
 ecc-521.c =&gt; ecc-secp521r1.c                  |  4 +-
 eccdata.c                                     | 58 +++++++++++--------
 ...25519-modp.asm =&gt; ecc-curve25519-modp.asm} |  0
 ...cc-192-modp.asm =&gt; ecc-secp192r1-modp.asm} |  4 +-
 ...cc-224-modp.asm =&gt; ecc-secp224r1-modp.asm} |  4 +-
 ...cc-256-redc.asm =&gt; ecc-secp256r1-redc.asm} |  4 +-
 ...cc-384-modp.asm =&gt; ecc-secp384r1-modp.asm} |  4 +-
 ...cc-521-modp.asm =&gt; ecc-secp521r1-modp.asm} |  4 +-
 22 files changed, 105 insertions(+), 95 deletions(-)
 rename arm/{ecc-192-modp.asm =&gt; ecc-secp192r1-modp.asm} (97%)
 rename arm/{ecc-224-modp.asm =&gt; ecc-secp224r1-modp.asm} (97%)
 rename arm/{ecc-256-redc.asm =&gt; ecc-secp256r1-redc.asm} (98%)
 rename arm/{ecc-384-modp.asm =&gt; ecc-secp384r1-modp.asm} (98%)
 rename arm/{ecc-521-modp.asm =&gt; ecc-secp521r1-modp.asm} (97%)
 rename ecc-25519.c =&gt; ecc-curve25519.c (99%)
 rename ecc-448.c =&gt; ecc-curve448.c (99%)
 rename ecc-192.c =&gt; ecc-secp192r1.c (98%)
 rename ecc-224.c =&gt; ecc-secp224r1.c (98%)
 rename ecc-256.c =&gt; ecc-secp256r1.c (99%)
 rename ecc-384.c =&gt; ecc-secp384r1.c (99%)
 rename ecc-521.c =&gt; ecc-secp521r1.c (98%)
 rename x86_64/{ecc-25519-modp.asm =&gt; ecc-curve25519-modp.asm} (100%)
 rename x86_64/{ecc-192-modp.asm =&gt; ecc-secp192r1-modp.asm} (96%)
 rename x86_64/{ecc-224-modp.asm =&gt; ecc-secp224r1-modp.asm} (97%)
 rename x86_64/{ecc-256-redc.asm =&gt; ecc-secp256r1-redc.asm} (97%)
 rename x86_64/{ecc-384-modp.asm =&gt; ecc-secp384r1-modp.asm} (98%)
 rename x86_64/{ecc-521-modp.asm =&gt; ecc-secp521r1-modp.asm} (97%)

diff --git a/.gitignore b/.gitignore
index 0afe61de3826..ea264107fa40 100644
--- a/.gitignore
+++ b/.gitignore
@@ -43,13 +43,13 @@ core
 /keymap.h
 /parity.h
 /rotors.h
-/ecc-192.h
-/ecc-224.h
-/ecc-256.h
-/ecc-384.h
-/ecc-521.h
-/ecc-25519.h
-/ecc-448.h
+/ecc-curve25519.h
+/ecc-curve448.h
+/ecc-secp192r1.h
+/ecc-secp224r1.h
+/ecc-secp256r1.h
+/ecc-secp384r1.h
+/ecc-secp521r1.h
 /version.h
 /nettle.aux
 /nettle.cp
diff --git a/Makefile.in b/Makefile.in
index e0c9f5f7de66..38160bb40fe1 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -175,8 +175,9 @@ hogweed_SOURCES = sexp.c sexp-format.c \
 		  gmp-glue.c cnd-copy.c \
 		  ecc-mod.c ecc-mod-inv.c \
 		  ecc-mod-arith.c ecc-pp1-redc.c ecc-pm1-redc.c \
-		  ecc-192.c ecc-224.c ecc-256.c ecc-384.c ecc-521.c \
-		  ecc-25519.c ecc-448.c \
+		  ecc-curve25519.c ecc-curve448.c \
+		  ecc-secp192r1.c ecc-secp224r1.c ecc-secp256r1.c \
+		  ecc-secp384r1.c ecc-secp521r1.c \
 		  ecc-size.c ecc-j-to-a.c ecc-a-to-j.c \
 		  ecc-dup-jj.c ecc-add-jja.c ecc-add-jjj.c \
 		  ecc-eh-to-a.c \
@@ -350,24 +351,24 @@ des.$(OBJEXT): des.c des.h $(des_headers)
 # k = 14, c =  7, S = 256, T =  42 ( 28 A + 14 D) 12 KB
 # k = 11, c =  6, S = 192, T =  44 ( 33 A + 11 D)  9 KB
 # k = 16, c =  6, S = 128, T =  48 ( 32 A + 16 D)  6 KB
-ecc-192.h: eccdata.stamp
-	./eccdata$(EXEEXT_FOR_BUILD) 192 8 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
+ecc-secp192r1.h: eccdata.stamp
+	./eccdata$(EXEEXT_FOR_BUILD) secp192r1 8 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
 
 # Some reasonable choices for 224:
 # k = 16, c =  7, S = 256, T =  48 ( 32 A + 16 D) ~16 KB
 # k = 10, c =  6, S = 256, T =  50 ( 40 A + 10 D) ~16 KB
 # k = 13, c =  6, S = 192, T =  52 ( 39 A + 13 D) ~12 KB
 # k =  9, c =  5, S = 160, T =  54 ( 45 A +  9 D) ~10 KB
-ecc-224.h: eccdata.stamp
-	./eccdata$(EXEEXT_FOR_BUILD) 224 16 7 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
+ecc-secp224r1.h: eccdata.stamp
+	./eccdata$(EXEEXT_FOR_BUILD) secp224r1 16 7 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
 
 # Some reasonable choices for 256:
 # k =  9, c =  6, S = 320, T =  54 ( 45 A +  9 D) 20 KB
 # k = 11, c =  6, S = 256, T =  55 ( 44 A + 11 D) 16 KB
 # k = 19, c =  7, S = 256, T =  57 ( 38 A + 19 D) 16 KB
 # k = 15, c =  6, S = 192, T =  60 ( 45 A + 15 D) 12 KB
-ecc-256.h: eccdata.stamp
-	./eccdata$(EXEEXT_FOR_BUILD) 256 11 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
+ecc-secp256r1.h: eccdata.stamp
+	./eccdata$(EXEEXT_FOR_BUILD) secp256r1 11 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
 
 # Some reasonable choices for 384:
 # k = 16, c =  6, S = 256, T =  80 ( 64 A + 16 D) 24 KB
@@ -377,35 +378,35 @@ ecc-256.h: eccdata.stamp
 # k = 13, c =  5, S = 192, T =  91 ( 78 A + 13 D) 18 KB
 # k = 16, c =  5, S = 160, T =  96 ( 80 A + 16 D) 15 KB
 # k = 32, c =  6, S = 128, T =  96 ( 64 A + 32 D) 12 KB
-ecc-384.h: eccdata.stamp
-	./eccdata$(EXEEXT_FOR_BUILD) 384 32 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
+ecc-secp384r1.h: eccdata.stamp
+	./eccdata$(EXEEXT_FOR_BUILD) secp384r1 32 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
 
 # Some reasonable choices for 521:
 # k = 29, c =  6, S = 192, T = 116 ( 87 A + 29 D) ~27 KB
 # k = 21, c =  5, S = 160, T = 126 (105 A + 21 D) ~23 KB
 # k = 44, c =  6, S = 128, T = 132 ( 88 A + 44 D) ~18 KB
 # k = 35, c =  5, S =  96, T = 140 (105 A + 35 D) ~14 KB
-ecc-521.h: eccdata.stamp
-	./eccdata$(EXEEXT_FOR_BUILD) 521 44 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
+ecc-secp521r1.h: eccdata.stamp
+	./eccdata$(EXEEXT_FOR_BUILD) secp521r1 44 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
 
-# Parameter choices mostly the same as for ecc-256.h.
-ecc-25519.h: eccdata.stamp
-	./eccdata$(EXEEXT_FOR_BUILD) 255 11 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
+# Parameter choices mostly the same as for ecc-secp256r1.h.
+ecc-curve25519.h: eccdata.stamp
+	./eccdata$(EXEEXT_FOR_BUILD) curve25519 11 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
 
-ecc-448.h: eccdata.stamp
-	./eccdata$(EXEEXT_FOR_BUILD) 448 38 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
+ecc-curve448.h: eccdata.stamp
+	./eccdata$(EXEEXT_FOR_BUILD) curve448 38 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
 
 eccdata.stamp: eccdata.c
 	$(MAKE) eccdata$(EXEEXT_FOR_BUILD)
 	echo stamp &gt; eccdata.stamp
 
-ecc-192.$(OBJEXT): ecc-192.h
-ecc-224.$(OBJEXT): ecc-224.h
-ecc-256.$(OBJEXT): ecc-256.h
-ecc-384.$(OBJEXT): ecc-384.h
-ecc-521.$(OBJEXT): ecc-521.h
-ecc-25519.$(OBJEXT): ecc-25519.h
-ecc-448.$(OBJEXT): ecc-448.h
+ecc-curve25519.$(OBJEXT): ecc-curve25519.h
+ecc-curve448.$(OBJEXT): ecc-curve448.h
+ecc-secp192r1.$(OBJEXT): ecc-secp192r1.h
+ecc-secp224r1.$(OBJEXT): ecc-secp224r1.h
+ecc-secp256r1.$(OBJEXT): ecc-secp256r1.h
+ecc-secp384r1.$(OBJEXT): ecc-secp384r1.h
+ecc-secp521r1.$(OBJEXT): ecc-secp521r1.h
 
 .asm.$(OBJEXT): $(srcdir)/asm.m4 machine.m4 config.m4
 	$(M4) $(srcdir)/asm.m4 machine.m4 config.m4 $&lt; &gt;$*.s
@@ -658,8 +659,9 @@ distcheck: dist
 
 clean-here:
 	-rm -f $(TARGETS) *.$(OBJEXT) *.s *.so *.dll *.a \
-		ecc-192.h ecc-224.h ecc-256.h ecc-384.h ecc-521.h ecc-25519.h \
-		ecc-448.h \
+		ecc-curve25519.h ecc-curve448.h \
+		ecc-secp192r1.h ecc-secp224r1.h ecc-secp256r1.h \
+		ecc-secp384r1.h ecc-secp521r1.h \
 		aesdata$(EXEEXT_FOR_BUILD) \
 		desdata$(EXEEXT_FOR_BUILD) \
 		twofishdata$(EXEEXT_FOR_BUILD) \
diff --git a/arm/ecc-192-modp.asm b/arm/ecc-secp192r1-modp.asm
similarity index 97%
rename from arm/ecc-192-modp.asm
rename to arm/ecc-secp192r1-modp.asm
index b6074a2e05e9..dbaae2e38922 100644
--- a/arm/ecc-192-modp.asm
+++ b/arm/ecc-secp192r1-modp.asm
@@ -1,4 +1,4 @@
-C arm/ecc-192-modp.asm
+C arm/ecc-secp192r1-modp.asm
 
 ifelse(&lt;
    Copyright (C) 2013 Niels Möller
@@ -30,7 +30,7 @@ ifelse(&lt;
    not, see http://www.gnu.org/licenses/.
 &gt;) 
 
-	.file "ecc-192-modp.asm"
+	.file "ecc-secp192r1-modp.asm"
 	.arm
 
 define(&lt;HP&gt;, &lt;r0&gt;) C Overlaps unused modulo argument
diff --git a/arm/ecc-224-modp.asm b/arm/ecc-secp224r1-modp.asm
similarity index 97%
rename from arm/ecc-224-modp.asm
rename to arm/ecc-secp224r1-modp.asm
index 15cc0c1b0f26..2c86755a7c9a 100644
--- a/arm/ecc-224-modp.asm
+++ b/arm/ecc-secp224r1-modp.asm
@@ -1,4 +1,4 @@
-C arm/ecc-224-modp.asm
+C arm/ecc-secp224r1-modp.asm
 
 ifelse(&lt;
    Copyright (C) 2013 Niels Möller
@@ -30,7 +30,7 @@ ifelse(&lt;
    not, see http://www.gnu.org/licenses/.
 &gt;) 
 
-	.file "ecc-224-modp.asm"
+	.file "ecc-secp224r1-modp.asm"
 	.arm
 
 define(&lt;RP&gt;, &lt;r1&gt;)
diff --git a/arm/ecc-256-redc.asm b/arm/ecc-secp256r1-redc.asm
similarity index 98%
rename from arm/ecc-256-redc.asm
rename to arm/ecc-secp256r1-redc.asm
index 0c5e846d5890..9c20062a44e4 100644
--- a/arm/ecc-256-redc.asm
+++ b/arm/ecc-secp256r1-redc.asm
@@ -1,4 +1,4 @@
-C arm/ecc-256-redc.asm
+C arm/ecc-secp256r1-redc.asm
 
 ifelse(&lt;
    Copyright (C) 2013 Niels Möller
@@ -30,7 +30,7 @@ ifelse(&lt;
    not, see http://www.gnu.org/licenses/.
 &gt;) 
 
-	.file "ecc-256-redc.asm"
+	.file "ecc-secp256r1-redc.asm"
 	.arm
 
 define(&lt;RP&gt;, &lt;r1&gt;)
diff --git a/arm/ecc-384-modp.asm b/arm/ecc-secp384r1-modp.asm
similarity index 98%
rename from arm/ecc-384-modp.asm
rename to arm/ecc-secp384r1-modp.asm
index 1d36319d584d..dbedbdf8d32e 100644
--- a/arm/ecc-384-modp.asm
+++ b/arm/ecc-secp384r1-modp.asm
@@ -1,4 +1,4 @@
-C arm/ecc-384-modp.asm
+C arm/ecc-secp384r1-modp.asm
 
 ifelse(&lt;
    Copyright (C) 2013 Niels Möller
@@ -30,7 +30,7 @@ ifelse(&lt;
    not, see http://www.gnu.org/licenses/.
 &gt;) 
 
-	.file "ecc-384-modp.asm"
+	.file "ecc-secp384r1-modp.asm"
 	.arm
 
 define(&lt;RP&gt;, &lt;r1&gt;)
diff --git a/arm/ecc-521-modp.asm b/arm/ecc-secp521r1-modp.asm
similarity index 97%
rename from arm/ecc-521-modp.asm
rename to arm/ecc-secp521r1-modp.asm
index 3fba23963d2c..2b4f79192a2e 100644
--- a/arm/ecc-521-modp.asm
+++ b/arm/ecc-secp521r1-modp.asm
@@ -1,4 +1,4 @@
-C arm/ecc-521-modp.asm
+C arm/ecc-secp521r1-modp.asm
 
 ifelse(&lt;
    Copyright (C) 2013 Niels Möller
@@ -30,7 +30,7 @@ ifelse(&lt;
    not, see http://www.gnu.org/licenses/.
 &gt;) 
 
-	.file "ecc-521-modp.asm"
+	.file "ecc-secp521r1-modp.asm"
 	.arm
 
 define(&lt;HP&gt;, &lt;r0&gt;)
diff --git a/configure.ac b/configure.ac
index ef0c819fb979..745cc2c5c20e 100644
--- a/configure.ac
+++ b/configure.ac
@@ -475,9 +475,9 @@ asm_nettle_optional_list="gcm-hash8.asm cpuid.asm \
 
 asm_hogweed_optional_list=""
 if test "x$enable_public_key" = "xyes" ; then
-  asm_hogweed_optional_list="ecc-192-modp.asm ecc-224-modp.asm \
-    ecc-256-redc.asm ecc-384-modp.asm ecc-521-modp.asm \
-    ecc-25519-modp.asm ecc-curve448-modp.asm"
+  asm_hogweed_optional_list="ecc-secp192r1-modp.asm ecc-secp224r1-modp.asm \
+    ecc-secp256r1-redc.asm ecc-secp384r1-modp.asm ecc-secp521r1-modp.asm \
+    ecc-curve25519-modp.asm ecc-curve448-modp.asm"
 fi
 
 OPT_NETTLE_OBJS=""
diff --git a/ecc-25519.c b/ecc-curve25519.c
similarity index 99%
rename from ecc-25519.c
rename to ecc-curve25519.c
index 7eacc7802952..73d72765dce8 100644
--- a/ecc-25519.c
+++ b/ecc-curve25519.c
@@ -1,4 +1,4 @@
-/* ecc-25519.c
+/* ecc-curve25519.c
 
    Arithmetic and tables for curve25519,
 
@@ -42,7 +42,7 @@
 
 #define USE_REDC 0
 
-#include "ecc-25519.h"
+#include "ecc-curve25519.h"
 
 #define PHIGH_BITS (GMP_NUMB_BITS * ECC_LIMB_SIZE - 255)
 
diff --git a/ecc-448.c b/ecc-curve448.c
similarity index 99%
rename from ecc-448.c
rename to ecc-curve448.c
index b32ad463c68a..7020e3e8f6aa 100644
--- a/ecc-448.c
+++ b/ecc-curve448.c
@@ -1,4 +1,4 @@
-/* ecc-448.c
+/* ecc-curve448.c
 
    Arithmetic and tables for curve448,
 
@@ -43,7 +43,7 @@
 
 #define USE_REDC 0
 
-#include "ecc-448.h"
+#include "ecc-curve448.h"
 
 #if HAVE_NATIVE_ecc_curve448_modp
 #define ecc_448_modp nettle_ecc_curve448_modp
diff --git a/ecc-192.c b/ecc-secp192r1.c
similarity index 98%
rename from ecc-192.c
rename to ecc-secp192r1.c
index 4b756ffd7e8f..858a1b7554ce 100644
--- a/ecc-192.c
+++ b/ecc-secp192r1.c
@@ -1,4 +1,4 @@
-/* ecc-192.c
+/* ecc-secp192r1.c
 
    Compile time constant (but machine dependent) tables.
 
@@ -46,7 +46,7 @@
 
 #define USE_REDC 0
 
-#include "ecc-192.h"
+#include "ecc-secp192r1.h"
 
 #if HAVE_NATIVE_ecc_192_modp
 
diff --git a/ecc-224.c b/ecc-secp224r1.c
similarity index 98%
rename from ecc-224.c
rename to ecc-secp224r1.c
index bf90f848c1b2..4d82f54b57fd 100644
--- a/ecc-224.c
+++ b/ecc-secp224r1.c
@@ -1,4 +1,4 @@
-/* ecc-224.c
+/* ecc-secp224r1.c
 
    Compile time constant (but machine dependent) tables.
 
@@ -52,7 +52,7 @@ ecc_224_modp (const struct ecc_modulo *m, mp_limb_t *rp);
 #define ecc_224_modp ecc_mod
 #endif
 
-#include "ecc-224.h"
+#include "ecc-secp224r1.h"
 
 #if ECC_REDC_SIZE &lt; 0
 # define ecc_224_redc ecc_pm1_redc
diff --git a/ecc-256.c b/ecc-secp256r1.c
similarity index 99%
rename from ecc-256.c
rename to ecc-secp256r1.c
index 0990cb3bcc5c..835c91d30239 100644
--- a/ecc-256.c
+++ b/ecc-secp256r1.c
@@ -1,4 +1,4 @@
-/* ecc-256.c
+/* ecc-secp256r1.c
 
    Compile time constant (but machine dependent) tables.
 
@@ -48,7 +48,7 @@
 # define USE_REDC (ECC_REDC_SIZE != 0)
 #endif
 
-#include "ecc-256.h"
+#include "ecc-secp256r1.h"
 
 #if HAVE_NATIVE_ecc_256_redc
 # define ecc_256_redc nettle_ecc_256_redc
diff --git a/ecc-384.c b/ecc-secp384r1.c
similarity index 99%
rename from ecc-384.c
rename to ecc-secp384r1.c
index 5bb2a2476eec..248b1cf3ef2b 100644
--- a/ecc-384.c
+++ b/ecc-secp384r1.c
@@ -1,4 +1,4 @@
-/* ecc-384.c
+/* ecc-secp384r1.c
 
    Compile time constant (but machine dependent) tables.
 
@@ -44,7 +44,7 @@
 
 #define USE_REDC 0
 
-#include "ecc-384.h"
+#include "ecc-secp384r1.h"
 
 #if HAVE_NATIVE_ecc_384_modp
 #define ecc_384_modp nettle_ecc_384_modp
diff --git a/ecc-521.c b/ecc-secp521r1.c
similarity index 98%
rename from ecc-521.c
rename to ecc-secp521r1.c
index 8ca0e6d2dd64..cc7473035cff 100644
--- a/ecc-521.c
+++ b/ecc-secp521r1.c
@@ -1,4 +1,4 @@
-/* ecc-521.c
+/* ecc-secp521r1.c
 
    Compile time constant (but machine dependent) tables.
 
@@ -42,7 +42,7 @@
 
 #define USE_REDC 0
 
-#include "ecc-521.h"
+#include "ecc-secp521r1.h"
 
 #if HAVE_NATIVE_ecc_521_modp
 #define ecc_521_modp nettle_ecc_521_modp
diff --git a/eccdata.c b/eccdata.c
index 74002c1f305e..d76a42bcde6f 100644
--- a/eccdata.c
+++ b/eccdata.c
@@ -432,11 +432,10 @@ ecc_curve_init_str (struct ecc_curve *ecc, enum ecc_type type,
 }
 
 static void
-ecc_curve_init (struct ecc_curve *ecc, unsigned bit_size)
+ecc_curve_init (struct ecc_curve *ecc, const char *curve)
 {
-  switch (bit_size)
+  if (!strcmp (curve, "secp192r1"))
     {
-    case 192:      
       ecc_curve_init_str (ecc, ECC_TYPE_WEIERSTRASS,
 			  /* p = 2^{192} - 2^{64} - 1 */
 			  "FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFE"
@@ -466,8 +465,9 @@ ecc_curve_init (struct ecc_curve *ecc, unsigned bit_size)
 		   "35433907297cc378b0015703374729d7a4fe46647084e4ba",
 		   "a2649984f2135c301ea3acb0776cd4f125389b311db3be32");
 
-      break;
-    case 224:
+    }
+  else if (!strcmp (curve, "secp224r1"))
+    {
       ecc_curve_init_str (ecc, ECC_TYPE_WEIERSTRASS,
 			  /* p = 2^{224} - 2^{96} + 1 */
 			  "ffffffffffffffffffffffffffffffff"
@@ -498,8 +498,9 @@ ecc_curve_init (struct ecc_curve *ecc, unsigned bit_size)
 		   "ae99feebb5d26945b54892092a8aee02912930fa41cd114e40447301",
 		   "482580a0ec5bc47e88bc8c378632cd196cb3fa058a7114eb03054c9");
 
-      break;
-    case 256:
+    }
+  else if (!strcmp (curve, "secp256r1"))
+    {
       ecc_curve_init_str (ecc, ECC_TYPE_WEIERSTRASS,
 			  /* p = 2^{256} - 2^{224} + 2^{192} + 2^{96} - 1 */
 			  "FFFFFFFF000000010000000000000000"
@@ -530,8 +531,9 @@ ecc_curve_init (struct ecc_curve *ecc, unsigned bit_size)
 		   "e2534a3532d08fbba02dde659ee62bd0031fe2db785596ef509302446b030852",
 		   "e0f1575a4c633cc719dfee5fda862d764efc96c3f30ee0055c42c23f184ed8c6");
 
-      break;
-    case 384:
+    }
+  else if (!strcmp (curve, "secp384r1"))
+    {
       ecc_curve_init_str (ecc, ECC_TYPE_WEIERSTRASS,
 			  /* p = 2^{384} - 2^{128} - 2^{96} + 2^{32} - 1 */
 			  "ffffffffffffffffffffffffffffffff"
@@ -567,8 +569,9 @@ ecc_curve_init (struct ecc_curve *ecc, unsigned bit_size)
 		   "138251cd52ac9298c1c8aad977321deb97e709bd0b4ca0aca55dc8ad51dcfc9d1589a1597e3a5120e1efd631c63e1835",
                
 		   "cacae29869a62e1631e8a28181ab56616dc45d918abc09f3ab0e63cf792aa4dced7387be37bba569549f1c02b270ed67");
  
-      break;
-    case 521:
+    }
+  else if (!strcmp (curve, "secp521r1"))
+    {
       ecc_curve_init_str (ecc, ECC_TYPE_WEIERSTRASS,
 			  "1ff" /* p = 2^{521} - 1 */
 			  "ffffffffffffffffffffffffffffffff"
@@ -613,9 +616,15 @@ ecc_curve_init (struct ecc_curve *ecc, unsigned bit_size)
 		   "35b5df64ae2ac204c354b483487c9070cdc61c891c5ff39afc06c5d55541d3ceac8659e24afe3d0750e8b88e9f078af066a1d5025b08e5a5e2fbc87412871902f3",
                
 		   "82096f84261279d2b673e0178eb0b4abb65521aef6e6e32e1b5ae63fe2f19907f279f283e54ba385405224f750a95b85eebb7faef04699d1d9e21f47fc346e4d0d");
  
-      break;
-    case 255:
-      /* Edwards curve used for eddsa25519 and curve25519,
+    }
+  else if (!strcmp (curve, "curve25519"))
+    {
+      /* curve25519, y^2 = x^3 + 486662 x^2 + x (mod p), with p = 2^{255} - 19.
+
+	 According to http://cr.yp.to/papers.html#newelliptic, this
+	 is birationally equivalent to the Edwards curve
+
+	   x^2 + y^2 = 1 + (121665/121666) x^2 y^2 (mod p).
 
 	   -x^2 + y^2 = 1 - (121665/121666) x^2 y^2, with p = 2^{255} - 19.
 
@@ -664,9 +673,9 @@ ecc_curve_init (struct ecc_curve *ecc, unsigned bit_size)
 		   "1a739ec193ce1547493aa657c4c9f870",
 		   "47d0e827cb1595e1470eb88580d5716c"
 		   "4cf22832ea2f0ff0df38ab61ca32112f");
-      break;
-
-    case 448:
+    }
+  else if (!strcmp (curve, "curve448"))
+    {
       /* curve448, y^2 = x^3 + 156326 x^2 + x (mod p), with p = 2^{448} - 2^{224} - \
1.  
 	 According to RFC 7748, this is 4-isogenious to the Edwards
@@ -745,14 +754,13 @@ ecc_curve_init (struct ecc_curve *ecc, unsigned bit_size)
 		   "9cb7c02f0457d845c90dc3227b8a5bc1"
 		   "c0d8f97ea1ca9472b5d444285d0d4f5b"
 		   "32e236f86de51839");
-
-      break;
-
-    default:
-      fprintf (stderr, "No known curve for size %d\n", bit_size);
-      exit(EXIT_FAILURE);     
     }
-  ecc-&gt;bit_size = bit_size;
+  else
+    {
+      fprintf (stderr, "No known curve with name %s\n", curve);
+      exit(EXIT_FAILURE);
+    }
+  ecc-&gt;bit_size = mpz_sizeinbase (ecc-&gt;p, 2);
 }
 
 static void
@@ -1312,7 +1320,7 @@ main (int argc, char **argv)
       return EXIT_FAILURE;
     }
 
-  ecc_curve_init (&amp;ecc, atoi(argv[1]));
+  ecc_curve_init (&amp;ecc, argv[1]);
 
   ecc_pippenger_precompute (&amp;ecc, atoi(argv[2]), atoi(argv[3]));
 
diff --git a/x86_64/ecc-25519-modp.asm b/x86_64/ecc-curve25519-modp.asm
similarity index 100%
rename from x86_64/ecc-25519-modp.asm
rename to x86_64/ecc-curve25519-modp.asm
diff --git a/x86_64/ecc-192-modp.asm b/x86_64/ecc-secp192r1-modp.asm
similarity index 96%
rename from x86_64/ecc-192-modp.asm
rename to x86_64/ecc-secp192r1-modp.asm
index f0660525e0e1..644ed60c6fab 100644
--- a/x86_64/ecc-192-modp.asm
+++ b/x86_64/ecc-secp192r1-modp.asm
@@ -1,4 +1,4 @@
-C x86_64/ecc-192-modp.asm
+C x86_64/ecc-secp192r1-modp.asm
 
 ifelse(&lt;
    Copyright (C) 2013 Niels Möller
@@ -30,7 +30,7 @@ ifelse(&lt;
    not, see http://www.gnu.org/licenses/.
 &gt;)
 
-	.file "ecc-192-modp.asm"
+	.file "ecc-secp192r1-modp.asm"
 
 define(&lt;RP&gt;, &lt;%rsi&gt;)
 define(&lt;T0&gt;, &lt;%rdi&gt;) C Overlaps unused modulo input
diff --git a/x86_64/ecc-224-modp.asm b/x86_64/ecc-secp224r1-modp.asm
similarity index 97%
rename from x86_64/ecc-224-modp.asm
rename to x86_64/ecc-secp224r1-modp.asm
index 07bd40036705..ca164ac7d637 100644
--- a/x86_64/ecc-224-modp.asm
+++ b/x86_64/ecc-secp224r1-modp.asm
@@ -1,4 +1,4 @@
-C x86_64/ecc-224-modp.asm
+C x86_64/ecc-secp224r1-modp.asm
 
 ifelse(&lt;
    Copyright (C) 2013 Niels Möller
@@ -30,7 +30,7 @@ ifelse(&lt;
    not, see http://www.gnu.org/licenses/.
 &gt;)
 
-	.file "ecc-224-modp.asm"
+	.file "ecc-secp224r1-modp.asm"
 
 GMP_NUMB_BITS(64)
 
diff --git a/x86_64/ecc-256-redc.asm b/x86_64/ecc-secp256r1-redc.asm
similarity index 97%
rename from x86_64/ecc-256-redc.asm
rename to x86_64/ecc-secp256r1-redc.asm
index fb1633541218..ee689cd6d192 100644
--- a/x86_64/ecc-256-redc.asm
+++ b/x86_64/ecc-secp256r1-redc.asm
@@ -1,4 +1,4 @@
-C x86_64/ecc-256-redc.asm
+C x86_64/ecc-secp256r1-redc.asm
 
 ifelse(&lt;
    Copyright (C) 2013 Niels Möller
@@ -30,7 +30,7 @@ ifelse(&lt;
    not, see http://www.gnu.org/licenses/.
 &gt;)
 
-	.file "ecc-256-redc.asm"
+	.file "ecc-secp256r1-redc.asm"
 
 define(&lt;RP&gt;, &lt;%rsi&gt;)
 define(&lt;U0&gt;, &lt;%rdi&gt;) C Overlaps unused modulo input
diff --git a/x86_64/ecc-384-modp.asm b/x86_64/ecc-secp384r1-modp.asm
similarity index 98%
rename from x86_64/ecc-384-modp.asm
rename to x86_64/ecc-secp384r1-modp.asm
index 8e55393f802f..3c8ec3f446c0 100644
--- a/x86_64/ecc-384-modp.asm
+++ b/x86_64/ecc-secp384r1-modp.asm
@@ -1,4 +1,4 @@
-C x86_64/ecc-384-modp.asm
+C x86_64/ecc-secp384r1-modp.asm
 
 ifelse(&lt;
    Copyright (C) 2013, 2015 Niels Möller
@@ -30,7 +30,7 @@ ifelse(&lt;
    not, see http://www.gnu.org/licenses/.
 &gt;)
 
-	.file "ecc-384-modp.asm"
+	.file "ecc-secp384r1-modp.asm"
 
 define(&lt;RP&gt;, &lt;%rsi&gt;)
 define(&lt;D5&gt;, &lt;%rax&gt;)
diff --git a/x86_64/ecc-521-modp.asm b/x86_64/ecc-secp521r1-modp.asm
similarity index 97%
rename from x86_64/ecc-521-modp.asm
rename to x86_64/ecc-secp521r1-modp.asm
index 6e818ad81d41..43a8cb8c9cfe 100644
--- a/x86_64/ecc-521-modp.asm
+++ b/x86_64/ecc-secp521r1-modp.asm
@@ -1,4 +1,4 @@
-C x86_64/ecc-521-modp.asm
+C x86_64/ecc-secp521r1-modp.asm
 
 ifelse(&lt;
    Copyright (C) 2013 Niels Möller
@@ -30,7 +30,7 @@ ifelse(&lt;
    not, see http://www.gnu.org/licenses/.
 &gt;)
 
-	.file "ecc-521-modp.asm"
+	.file "ecc-secp521r1-modp.asm"
 
 GMP_NUMB_BITS(64)
 
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200106221645</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-01-06 22:16:45-0400</timestampReceived><subject>[PATCH v3 3/3] ecc: rename functions to contain curve names instead of bits</subject><body>

From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;

Rename curve functions to use curve names instead of just bits.
Otherwise function names can easily become confusing after adding other
curves.

Signed-off-by: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;
---
 arm/ecc-secp192r1-modp.asm     |  6 +++---
 arm/ecc-secp224r1-modp.asm     |  6 +++---
 arm/ecc-secp256r1-redc.asm     |  6 +++---
 arm/ecc-secp384r1-modp.asm     |  6 +++---
 arm/ecc-secp521r1-modp.asm     |  6 +++---
 configure.ac                   | 22 +++++++++++-----------
 ecc-curve25519.c               | 34 +++++++++++++++++-----------------
 ecc-curve448.c                 | 34 +++++++++++++++++-----------------
 ecc-secp192r1.c                | 16 ++++++++--------
 ecc-secp224r1.c                | 16 ++++++++--------
 ecc-secp256r1.c                | 32 ++++++++++++++++----------------
 ecc-secp384r1.c                | 16 ++++++++--------
 ecc-secp521r1.c                | 12 ++++++------
 eddsa-sign.c                   |  2 +-
 x86_64/ecc-curve25519-modp.asm |  4 ++--
 x86_64/ecc-secp192r1-modp.asm  |  6 +++---
 x86_64/ecc-secp224r1-modp.asm  |  6 +++---
 x86_64/ecc-secp256r1-redc.asm  |  4 ++--
 x86_64/ecc-secp384r1-modp.asm  |  4 ++--
 x86_64/ecc-secp521r1-modp.asm  |  4 ++--
 20 files changed, 121 insertions(+), 121 deletions(-)

diff --git a/arm/ecc-secp192r1-modp.asm b/arm/ecc-secp192r1-modp.asm
index 4680336f1bc7..4c596a168b3d 100644
--- a/arm/ecc-secp192r1-modp.asm
+++ b/arm/ecc-secp192r1-modp.asm
@@ -49,11 +49,11 @@ define(&lt;H1&gt;, &lt;T1&gt;)
 define(&lt;C2&gt;, &lt;HP&gt;)
 define(&lt;C4&gt;, &lt;r12&gt;)
 
-	C ecc_192_modp (const struct ecc_modulo *m, mp_limb_t *rp)
+	C ecc_secp192r1_modp (const struct ecc_modulo *m, mp_limb_t *rp)
 	.text
 	.align 2
 
-PROLOGUE(_nettle_ecc_192_modp)
+PROLOGUE(_nettle_ecc_secp192r1_modp)
 	push	{r4,r5,r6,r7,r8,r10}
 	C Reduce two words at a time
 	add	HP, RP, #48
@@ -103,4 +103,4 @@ PROLOGUE(_nettle_ecc_192_modp)
 
 	pop	{r4,r5,r6,r7,r8,r10}
 	bx	lr
-EPILOGUE(_nettle_ecc_192_modp)
+EPILOGUE(_nettle_ecc_secp192r1_modp)
diff --git a/arm/ecc-secp224r1-modp.asm b/arm/ecc-secp224r1-modp.asm
index 400b7a815c2c..67089a0c2981 100644
--- a/arm/ecc-secp224r1-modp.asm
+++ b/arm/ecc-secp224r1-modp.asm
@@ -48,11 +48,11 @@ define(&lt;L0&gt;, &lt;r11&gt;)
 define(&lt;L1&gt;, &lt;r12&gt;)
 define(&lt;L2&gt;, &lt;lr&gt;)
 
-	C ecc_224_modp (const struct ecc_modulo *m, mp_limb_t *rp)
+	C ecc_secp224r1_modp (const struct ecc_modulo *m, mp_limb_t *rp)
 	.text
 	.align 2
 
-PROLOGUE(_nettle_ecc_224_modp)
+PROLOGUE(_nettle_ecc_secp224r1_modp)
 	push	{r4,r5,r6,r7,r8,r10,r11,lr}
 
 	add	L2, RP, #28
@@ -121,4 +121,4 @@ PROLOGUE(_nettle_ecc_224_modp)
 	stmdb	RP, {T0,T1,T2,T3,T4,T5,T6}
 
 	pop	{r4,r5,r6,r7,r8,r10,r11,pc}
-EPILOGUE(_nettle_ecc_224_modp)
+EPILOGUE(_nettle_ecc_secp224r1_modp)
diff --git a/arm/ecc-secp256r1-redc.asm b/arm/ecc-secp256r1-redc.asm
index 7b117de43fbc..f8386c39c9a6 100644
--- a/arm/ecc-secp256r1-redc.asm
+++ b/arm/ecc-secp256r1-redc.asm
@@ -48,11 +48,11 @@ define(&lt;F1&gt;, &lt;r11&gt;)
 define(&lt;F2&gt;, &lt;r12&gt;)
 define(&lt;F3&gt;, &lt;lr&gt;)
 
-	C ecc_256_redc (const struct ecc_modulo *m, mp_limb_t *rp)
+	C ecc_secp256r1_redc (const struct ecc_modulo *m, mp_limb_t *rp)
 	.text
 	.align 2
 
-PROLOGUE(_nettle_ecc_256_redc)
+PROLOGUE(_nettle_ecc_secp256r1_redc)
 	push	{r4,r5,r6,r7,r8,r10,r11,lr}
 
 	ldm	RP!, {T0,T1,T2,T3,T4,T5,T6,T7}
@@ -170,4 +170,4 @@ PROLOGUE(_nettle_ecc_256_redc)
 	stm	RP, {T0,T1,T2,T3,T4,T5,T6,T7}
 
 	pop	{r4,r5,r6,r7,r8,r10,r11,pc}
-EPILOGUE(_nettle_ecc_256_redc)
+EPILOGUE(_nettle_ecc_secp256r1_redc)
diff --git a/arm/ecc-secp384r1-modp.asm b/arm/ecc-secp384r1-modp.asm
index dd9a325b09de..1983ee68cdd4 100644
--- a/arm/ecc-secp384r1-modp.asm
+++ b/arm/ecc-secp384r1-modp.asm
@@ -46,11 +46,11 @@ define(&lt;F4&gt;, &lt;r10&gt;)
 define(&lt;N&gt;, &lt;r12&gt;)
 define(&lt;H&gt;, &lt;lr&gt;)
 	
-	C ecc_384_modp (const struct ecc_modulo *m, mp_limb_t *rp)
+	C ecc_secp384r1_modp (const struct ecc_modulo *m, mp_limb_t *rp)
 	.text
 	.align 2
 
-PROLOGUE(_nettle_ecc_384_modp)
+PROLOGUE(_nettle_ecc_secp384r1_modp)
 	push	{r4,r5,r6,r7,r8,r10,lr}
 
 	add	RP, RP, #80
@@ -267,4 +267,4 @@ PROLOGUE(_nettle_ecc_384_modp)
 	adcs	T3, T3, H
 	stm	RP!, {T0,T1,T2,T3}	C 8-11
 	pop	{r4,r5,r6,r7,r8,r10,pc}
-EPILOGUE(_nettle_ecc_384_modp)
+EPILOGUE(_nettle_ecc_secp384r1_modp)
diff --git a/arm/ecc-secp521r1-modp.asm b/arm/ecc-secp521r1-modp.asm
index f11967634689..6d1759ec8a2a 100644
--- a/arm/ecc-secp521r1-modp.asm
+++ b/arm/ecc-secp521r1-modp.asm
@@ -45,14 +45,14 @@ define(&lt;F3&gt;, &lt;r8&gt;)
 define(&lt;H&gt;, &lt;r12&gt;)
 define(&lt;N&gt;, &lt;lr&gt;)
 
-	C ecc_521_modp (const struct ecc_modulo *m, mp_limb_t *rp)
+	C ecc_secp521r1_modp (const struct ecc_modulo *m, mp_limb_t *rp)
 	.text
 .Lc511:
 	.int 511
 
 	.align 2
 
-PROLOGUE(_nettle_ecc_521_modp)
+PROLOGUE(_nettle_ecc_secp521r1_modp)
 	push	{r4,r5,r6,r7,r8,lr}
 
 	C Use that B^17 = 2^23 (mod p)
@@ -124,4 +124,4 @@ PROLOGUE(_nettle_ecc_521_modp)
 	stm	RP, {T0,T1,T2,F0,F1,F2,F3,H}	C 9-16
 
 	pop	{r4,r5,r6,r7,r8,pc}
-EPILOGUE(_nettle_ecc_521_modp)
+EPILOGUE(_nettle_ecc_secp521r1_modp)
diff --git a/configure.ac b/configure.ac
index 745cc2c5c20e..5e340d7abbd4 100644
--- a/configure.ac
+++ b/configure.ac
@@ -572,18 +572,18 @@ AH_VERBATIM([HAVE_NATIVE],
 [/* Define to 1 each of the following for which a native (ie. CPU specific)
     implementation of the corresponding routine exists.  */
 #undef HAVE_NATIVE_chacha_core
-#undef HAVE_NATIVE_ecc_192_modp
-#undef HAVE_NATIVE_ecc_192_redc
-#undef HAVE_NATIVE_ecc_224_modp
-#undef HAVE_NATIVE_ecc_224_redc
-#undef HAVE_NATIVE_ecc_25519_modp
-#undef HAVE_NATIVE_ecc_256_modp
-#undef HAVE_NATIVE_ecc_256_redc
-#undef HAVE_NATIVE_ecc_384_modp
-#undef HAVE_NATIVE_ecc_384_redc
+#undef HAVE_NATIVE_ecc_curve25519_modp
 #undef HAVE_NATIVE_ecc_curve448_modp
-#undef HAVE_NATIVE_ecc_521_modp
-#undef HAVE_NATIVE_ecc_521_redc
+#undef HAVE_NATIVE_ecc_secp192r1_modp
+#undef HAVE_NATIVE_ecc_secp192r1_redc
+#undef HAVE_NATIVE_ecc_secp224r1_modp
+#undef HAVE_NATIVE_ecc_secp224r1_redc
+#undef HAVE_NATIVE_ecc_secp256r1_modp
+#undef HAVE_NATIVE_ecc_secp256r1_redc
+#undef HAVE_NATIVE_ecc_secp384r1_modp
+#undef HAVE_NATIVE_ecc_secp384r1_redc
+#undef HAVE_NATIVE_ecc_secp521r1_modp
+#undef HAVE_NATIVE_ecc_secp521r1_redc
 #undef HAVE_NATIVE_gcm_hash8
 #undef HAVE_NATIVE_salsa20_core
 #undef HAVE_NATIVE_sha1_compress
diff --git a/ecc-curve25519.c b/ecc-curve25519.c
index 65843a57ee5a..0ad3017c9ebc 100644
--- a/ecc-curve25519.c
+++ b/ecc-curve25519.c
@@ -46,11 +46,11 @@
 
 #define PHIGH_BITS (GMP_NUMB_BITS * ECC_LIMB_SIZE - 255)
 
-#if HAVE_NATIVE_ecc_25519_modp
+#if HAVE_NATIVE_ecc_curve25519_modp
 
-#define ecc_25519_modp _nettle_ecc_25519_modp
+#define ecc_curve25519_modp _nettle_ecc_curve25519_modp
 void
-ecc_25519_modp (const struct ecc_modulo *m, mp_limb_t *rp);
+ecc_curve25519_modp (const struct ecc_modulo *m, mp_limb_t *rp);
 #else
 
 #if PHIGH_BITS == 0
@@ -58,7 +58,7 @@ ecc_25519_modp (const struct ecc_modulo *m, mp_limb_t *rp);
 #endif
 
 static void
-ecc_25519_modp(const struct ecc_modulo *m UNUSED, mp_limb_t *rp)
+ecc_curve25519_modp(const struct ecc_modulo *m UNUSED, mp_limb_t *rp)
 {
   mp_limb_t hi, cy;
 
@@ -69,7 +69,7 @@ ecc_25519_modp(const struct ecc_modulo *m UNUSED, mp_limb_t *rp)
   rp[ECC_LIMB_SIZE-1] = (hi &amp; (GMP_NUMB_MASK &gt;&gt; PHIGH_BITS))
     + sec_add_1 (rp, rp, ECC_LIMB_SIZE - 1, 19 * cy);
 }
-#endif /* HAVE_NATIVE_ecc_25519_modp */
+#endif /* HAVE_NATIVE_ecc_curve25519_modp */
 
 #define QHIGH_BITS (GMP_NUMB_BITS * ECC_LIMB_SIZE - 252)
 
@@ -78,7 +78,7 @@ ecc_25519_modp(const struct ecc_modulo *m UNUSED, mp_limb_t *rp)
 #endif
 
 static void
-ecc_25519_modq (const struct ecc_modulo *q, mp_limb_t *rp)
+ecc_curve25519_modq (const struct ecc_modulo *q, mp_limb_t *rp)
 {
   mp_size_t n;
   mp_limb_t cy;
@@ -180,7 +180,7 @@ ecc_mod_pow_252m3 (const struct ecc_modulo *m,
 /* Needs 5*ECC_LIMB_SIZE scratch space. */
 #define ECC_25519_INV_ITCH (5*ECC_LIMB_SIZE)
 
-static void ecc_25519_inv (const struct ecc_modulo *p,
+static void ecc_curve25519_inv (const struct ecc_modulo *p,
 			   mp_limb_t *rp, const mp_limb_t *ap,
 			   mp_limb_t *scratch)
 {
@@ -203,7 +203,7 @@ static void ecc_25519_inv (const struct ecc_modulo *p,
 
 /* First, do a canonical reduction, then check if zero */
 static int
-ecc_25519_zero_p (const struct ecc_modulo *p, mp_limb_t *xp)
+ecc_curve25519_zero_p (const struct ecc_modulo *p, mp_limb_t *xp)
 {
   mp_limb_t cy;
   mp_limb_t w;
@@ -239,7 +239,7 @@ ecc_25519_zero_p (const struct ecc_modulo *p, mp_limb_t *xp)
 #define ECC_25519_SQRT_ITCH (9*ECC_LIMB_SIZE)
 
 static int
-ecc_25519_sqrt(const struct ecc_modulo *p, mp_limb_t *rp,
+ecc_curve25519_sqrt(const struct ecc_modulo *p, mp_limb_t *rp,
 	       const mp_limb_t *up, const mp_limb_t *vp,
 	       mp_limb_t *scratch)
 {
@@ -271,9 +271,9 @@ ecc_25519_sqrt(const struct ecc_modulo *p, mp_limb_t *rp,
   ecc_mod_sqr (p, x2, rp);
   ecc_mod_mul (p, vx2, x2, vp);
   ecc_mod_add (p, t0, vx2, up);
-  neg = ecc_25519_zero_p (p, t0);
+  neg = ecc_curve25519_zero_p (p, t0);
   ecc_mod_sub (p, t0, up, vx2);
-  pos = ecc_25519_zero_p (p, t0);
+  pos = ecc_curve25519_zero_p (p, t0);
 
   ecc_mod_mul (p, t0, rp, ecc_sqrt_z);
   cnd_copy (neg, rp, t0, ECC_LIMB_SIZE);
@@ -306,10 +306,10 @@ const struct ecc_curve _nettle_curve25519 =
     NULL,
     ecc_pp1h,
 
-    ecc_25519_modp,
-    ecc_25519_modp,
-    ecc_25519_inv,
-    ecc_25519_sqrt,
+    ecc_curve25519_modp,
+    ecc_curve25519_modp,
+    ecc_curve25519_inv,
+    ecc_curve25519_sqrt,
   },
   {
     253,
@@ -325,8 +325,8 @@ const struct ecc_curve _nettle_curve25519 =
     NULL,
     ecc_qp1h,
 
-    ecc_25519_modq,
-    ecc_25519_modq,
+    ecc_curve25519_modq,
+    ecc_curve25519_modq,
     ecc_mod_inv,
     NULL,
   },
diff --git a/ecc-curve448.c b/ecc-curve448.c
index 981dc53f279e..c31a0eb26ba4 100644
--- a/ecc-curve448.c
+++ b/ecc-curve448.c
@@ -46,12 +46,12 @@
 #include "ecc-curve448.h"
 
 #if HAVE_NATIVE_ecc_curve448_modp
-#define ecc_448_modp _nettle_ecc_curve448_modp
+#define ecc_curve448_modp _nettle_ecc_curve448_modp
 void
-ecc_448_modp (const struct ecc_modulo *m, mp_limb_t *rp);
+ecc_curve448_modp (const struct ecc_modulo *m, mp_limb_t *rp);
 #elif GMP_NUMB_BITS == 64
 static void
-ecc_448_modp(const struct ecc_modulo *m, mp_limb_t *rp)
+ecc_curve448_modp(const struct ecc_modulo *m, mp_limb_t *rp)
 {
   /* Let B = 2^64, b = 2^32 = sqrt(B).
      p = B^7 - b B^3 - 1 ==&gt; B^7 = b B^3 + 1
@@ -95,7 +95,7 @@ ecc_448_modp(const struct ecc_modulo *m, mp_limb_t *rp)
   assert (c7 == 0);
 }
 #else
-#define ecc_448_modp ecc_mod
+#define ecc_curve448_modp ecc_mod
 #endif
 
 /* Needs 2*ecc-&gt;size limbs at rp, and 2*ecc-&gt;size additional limbs of
@@ -175,9 +175,9 @@ ecc_mod_pow_446m224m1 (const struct ecc_modulo *p,
 #undef t2
 }
 
-#define ECC_448_INV_ITCH (5*ECC_LIMB_SIZE)
+#define ECC_CURVE448_INV_ITCH (5*ECC_LIMB_SIZE)
 
-static void ecc_448_inv (const struct ecc_modulo *p,
+static void ecc_curve448_inv (const struct ecc_modulo *p,
 			 mp_limb_t *rp, const mp_limb_t *ap,
 			 mp_limb_t *scratch)
 {
@@ -194,7 +194,7 @@ static void ecc_448_inv (const struct ecc_modulo *p,
 
 /* First, do a canonical reduction, then check if zero */
 static int
-ecc_448_zero_p (const struct ecc_modulo *p, mp_limb_t *xp)
+ecc_curve448_zero_p (const struct ecc_modulo *p, mp_limb_t *xp)
 {
   mp_limb_t cy;
   mp_limb_t w;
@@ -217,10 +217,10 @@ ecc_448_zero_p (const struct ecc_modulo *p, mp_limb_t *xp)
 */
 
 /* Needs 4*n space + scratch for ecc_mod_pow_446m224m1. */
-#define ECC_448_SQRT_ITCH (9*ECC_LIMB_SIZE)
+#define ECC_CURVE448_SQRT_ITCH (9*ECC_LIMB_SIZE)
 
 static int
-ecc_448_sqrt(const struct ecc_modulo *p, mp_limb_t *rp,
+ecc_curve448_sqrt(const struct ecc_modulo *p, mp_limb_t *rp,
 	     const mp_limb_t *up, const mp_limb_t *vp,
 	     mp_limb_t *scratch)
 {
@@ -253,7 +253,7 @@ ecc_448_sqrt(const struct ecc_modulo *p, mp_limb_t *rp,
   ecc_mod_mul (p, vx2, x2, vp);
   ecc_mod_sub (p, t0, vx2, up);
 
-  return ecc_448_zero_p (p, t0);
+  return ecc_curve448_zero_p (p, t0);
 
 #undef u3v
 #undef u5v3
@@ -275,8 +275,8 @@ const struct ecc_curve _nettle_curve448 =
     ECC_LIMB_SIZE,
     ECC_BMODP_SIZE,
     0,
-    ECC_448_INV_ITCH,
-    ECC_448_SQRT_ITCH,
+    ECC_CURVE448_INV_ITCH,
+    ECC_CURVE448_SQRT_ITCH,
 
     ecc_p,
     ecc_Bmodp,
@@ -284,10 +284,10 @@ const struct ecc_curve _nettle_curve448 =
     NULL,
     ecc_pp1h,
 
-    ecc_448_modp,
-    ecc_448_modp,
-    ecc_448_inv,
-    ecc_448_sqrt,
+    ecc_curve448_modp,
+    ecc_curve448_modp,
+    ecc_curve448_inv,
+    ecc_curve448_sqrt,
   },
   {
     446,
@@ -318,7 +318,7 @@ const struct ecc_curve _nettle_curve448 =
   ECC_DUP_EH_ITCH (ECC_LIMB_SIZE),
   ECC_MUL_A_EH_ITCH (ECC_LIMB_SIZE),
   ECC_MUL_G_EH_ITCH (ECC_LIMB_SIZE),
-  ECC_EH_TO_A_ITCH (ECC_LIMB_SIZE, ECC_448_INV_ITCH),
+  ECC_EH_TO_A_ITCH (ECC_LIMB_SIZE, ECC_CURVE448_INV_ITCH),
 
   ecc_add_eh,
   ecc_add_ehh,
diff --git a/ecc-secp192r1.c b/ecc-secp192r1.c
index 15f5f1fa4c04..094074d73ed7 100644
--- a/ecc-secp192r1.c
+++ b/ecc-secp192r1.c
@@ -48,18 +48,18 @@
 
 #include "ecc-secp192r1.h"
 
-#if HAVE_NATIVE_ecc_192_modp
+#if HAVE_NATIVE_ecc_secp192r1_modp
 
-#define ecc_192_modp _nettle_ecc_192_modp
+#define ecc_secp192r1_modp _nettle_ecc_secp192r1_modp
 void
-ecc_192_modp (const struct ecc_modulo *m, mp_limb_t *rp);
+ecc_secp192r1_modp (const struct ecc_modulo *m, mp_limb_t *rp);
 
 /* Use that p = 2^{192} - 2^64 - 1, to eliminate 128 bits at a time. */
 
 #elif GMP_NUMB_BITS == 32
 /* p is 6 limbs, p = B^6 - B^2 - 1 */
 static void
-ecc_192_modp (const struct ecc_modulo *m UNUSED, mp_limb_t *rp)
+ecc_secp192r1_modp (const struct ecc_modulo *m UNUSED, mp_limb_t *rp)
 {
   mp_limb_t cy;
 
@@ -84,7 +84,7 @@ ecc_192_modp (const struct ecc_modulo *m UNUSED, mp_limb_t *rp)
 #elif GMP_NUMB_BITS == 64
 /* p is 3 limbs, p = B^3 - B - 1 */
 static void
-ecc_192_modp (const struct ecc_modulo *m UNUSED, mp_limb_t *rp)
+ecc_secp192r1_modp (const struct ecc_modulo *m UNUSED, mp_limb_t *rp)
 {
   mp_limb_t cy;
 
@@ -107,7 +107,7 @@ ecc_192_modp (const struct ecc_modulo *m UNUSED, mp_limb_t *rp)
 }
   
 #else
-#define ecc_192_modp ecc_mod
+#define ecc_secp192r1_modp ecc_mod
 #endif
 
 const struct ecc_curve _nettle_secp_192r1 =
@@ -126,8 +126,8 @@ const struct ecc_curve _nettle_secp_192r1 =
     ecc_redc_ppm1,
     ecc_pp1h,
 
-    ecc_192_modp,
-    ecc_192_modp,
+    ecc_secp192r1_modp,
+    ecc_secp192r1_modp,
     ecc_mod_inv,
     NULL,
   },
diff --git a/ecc-secp224r1.c b/ecc-secp224r1.c
index 28b938fa3282..e6b43fa61f42 100644
--- a/ecc-secp224r1.c
+++ b/ecc-secp224r1.c
@@ -40,24 +40,24 @@
 #include "ecc.h"
 #include "ecc-internal.h"
 
-#if HAVE_NATIVE_ecc_224_modp
+#if HAVE_NATIVE_ecc_secp224r1_modp
 
 #define USE_REDC 0
-#define ecc_224_modp _nettle_ecc_224_modp
+#define ecc_secp224r1_modp _nettle_ecc_secp224r1_modp
 void
-ecc_224_modp (const struct ecc_modulo *m, mp_limb_t *rp);
+ecc_secp224r1_modp (const struct ecc_modulo *m, mp_limb_t *rp);
 
 #else
 #define USE_REDC (ECC_REDC_SIZE != 0)
-#define ecc_224_modp ecc_mod
+#define ecc_secp224r1_modp ecc_mod
 #endif
 
 #include "ecc-secp224r1.h"
 
 #if ECC_REDC_SIZE &lt; 0
-# define ecc_224_redc ecc_pm1_redc
+# define ecc_secp224r1_redc ecc_pm1_redc
 #elif ECC_REDC_SIZE == 0
-# define ecc_224_redc NULL
+# define ecc_secp224r1_redc NULL
 #else
 # error Configuration error
 #endif
@@ -78,8 +78,8 @@ const struct ecc_curve _nettle_secp_224r1 =
     ecc_redc_ppm1,
     ecc_pp1h,
 
-    ecc_224_modp,
-    USE_REDC ? ecc_224_redc : ecc_224_modp,
+    ecc_secp224r1_modp,
+    USE_REDC ? ecc_secp224r1_redc : ecc_secp224r1_modp,
     ecc_mod_inv,
     NULL,
   },
diff --git a/ecc-secp256r1.c b/ecc-secp256r1.c
index 160a047957f8..6c776a729aea 100644
--- a/ecc-secp256r1.c
+++ b/ecc-secp256r1.c
@@ -42,7 +42,7 @@
 #include "ecc.h"
 #include "ecc-internal.h"
 
-#if HAVE_NATIVE_ecc_256_redc
+#if HAVE_NATIVE_ecc_secp256r1_redc
 # define USE_REDC 1
 #else
 # define USE_REDC (ECC_REDC_SIZE != 0)
@@ -50,27 +50,27 @@
 
 #include "ecc-secp256r1.h"
 
-#if HAVE_NATIVE_ecc_256_redc
-# define ecc_256_redc _nettle_ecc_256_redc
+#if HAVE_NATIVE_ecc_secp256r1_redc
+# define ecc_secp256r1_redc _nettle_ecc_secp256r1_redc
 void
-ecc_256_redc (const struct ecc_modulo *p, mp_limb_t *rp);
-#else /* !HAVE_NATIVE_ecc_256_redc */
+ecc_secp256r1_redc (const struct ecc_modulo *p, mp_limb_t *rp);
+#else /* !HAVE_NATIVE_ecc_secp256r1_redc */
 # if ECC_REDC_SIZE &gt; 0
-#   define ecc_256_redc ecc_pp1_redc
+#   define ecc_secp256r1_redc ecc_pp1_redc
 # elif ECC_REDC_SIZE == 0
-#   define ecc_256_redc NULL
+#   define ecc_secp256r1_redc NULL
 # else
 #  error Configuration error
 # endif
-#endif /* !HAVE_NATIVE_ecc_256_redc */
+#endif /* !HAVE_NATIVE_ecc_secp256r1_redc */
 
 #if ECC_BMODP_SIZE &lt; ECC_LIMB_SIZE
-#define ecc_256_modp ecc_mod
-#define ecc_256_modq ecc_mod
+#define ecc_secp256r1_modp ecc_mod
+#define ecc_secp256r1_modq ecc_mod
 #elif GMP_NUMB_BITS == 64
 
 static void
-ecc_256_modp (const struct ecc_modulo *p, mp_limb_t *rp)
+ecc_secp256r1_modp (const struct ecc_modulo *p, mp_limb_t *rp)
 {
   mp_limb_t u1, u0;
   mp_size_t n;
@@ -146,7 +146,7 @@ ecc_256_modp (const struct ecc_modulo *p, mp_limb_t *rp)
 }
 
 static void
-ecc_256_modq (const struct ecc_modulo *q, mp_limb_t *rp)
+ecc_secp256r1_modq (const struct ecc_modulo *q, mp_limb_t *rp)
 {
   mp_limb_t u2, u1, u0;
   mp_size_t n;
@@ -255,8 +255,8 @@ const struct ecc_curve _nettle_secp_256r1 =
     ecc_redc_ppm1,
     ecc_pp1h,
 
-    ecc_256_modp,
-    USE_REDC ? ecc_256_redc : ecc_256_modp,
+    ecc_secp256r1_modp,
+    USE_REDC ? ecc_secp256r1_redc : ecc_secp256r1_modp,
     ecc_mod_inv,
     NULL,
   },
@@ -274,8 +274,8 @@ const struct ecc_curve _nettle_secp_256r1 =
     NULL,
     ecc_qp1h,
 
-    ecc_256_modq,
-    ecc_256_modq,
+    ecc_secp256r1_modq,
+    ecc_secp256r1_modq,
     ecc_mod_inv,
     NULL,
   },
diff --git a/ecc-secp384r1.c b/ecc-secp384r1.c
index 32f75fb618ba..c4a75564bf58 100644
--- a/ecc-secp384r1.c
+++ b/ecc-secp384r1.c
@@ -46,10 +46,10 @@
 
 #include "ecc-secp384r1.h"
 
-#if HAVE_NATIVE_ecc_384_modp
-#define ecc_384_modp _nettle_ecc_384_modp
+#if HAVE_NATIVE_ecc_secp384r1_modp
+#define ecc_secp384r1_modp _nettle_ecc_secp384r1_modp
 void
-ecc_384_modp (const struct ecc_modulo *m, mp_limb_t *rp);
+ecc_secp384r1_modp (const struct ecc_modulo *m, mp_limb_t *rp);
 #elif GMP_NUMB_BITS == 32
 
 /* Use that 2^{384} = 2^{128} + 2^{96} - 2^{32} + 1, and eliminate 256
@@ -62,7 +62,7 @@ ecc_384_modp (const struct ecc_modulo *m, mp_limb_t *rp);
    almost 8 at a time. Do only 7, to avoid additional carry
    propagation, followed by 5. */
 static void
-ecc_384_modp (const struct ecc_modulo *p, mp_limb_t *rp)
+ecc_secp384r1_modp (const struct ecc_modulo *p, mp_limb_t *rp)
 {
   mp_limb_t cy, bw;
 
@@ -106,7 +106,7 @@ ecc_384_modp (const struct ecc_modulo *p, mp_limb_t *rp)
 /* p is 6 limbs, and B^6 - p = B^2 + 2^32 (B - 1) + 1. Eliminate 3
    (almost 4) limbs at a time. */
 static void
-ecc_384_modp (const struct ecc_modulo *p, mp_limb_t *rp)
+ecc_secp384r1_modp (const struct ecc_modulo *p, mp_limb_t *rp)
 {
   mp_limb_t tp[6];
   mp_limb_t cy;
@@ -144,7 +144,7 @@ ecc_384_modp (const struct ecc_modulo *p, mp_limb_t *rp)
   assert (cy == 0);  
 }
 #else
-#define ecc_384_modp ecc_mod
+#define ecc_secp384r1_modp ecc_mod
 #endif
   
 const struct ecc_curve _nettle_secp_384r1 =
@@ -163,8 +163,8 @@ const struct ecc_curve _nettle_secp_384r1 =
     ecc_redc_ppm1,
     ecc_pp1h,
 
-    ecc_384_modp,
-    ecc_384_modp,
+    ecc_secp384r1_modp,
+    ecc_secp384r1_modp,
     ecc_mod_inv,
     NULL,
   },
diff --git a/ecc-secp521r1.c b/ecc-secp521r1.c
index d952d77e444e..74688008959b 100644
--- a/ecc-secp521r1.c
+++ b/ecc-secp521r1.c
@@ -44,10 +44,10 @@
 
 #include "ecc-secp521r1.h"
 
-#if HAVE_NATIVE_ecc_521_modp
-#define ecc_521_modp _nettle_ecc_521_modp
+#if HAVE_NATIVE_ecc_secp521r1_modp
+#define ecc_secp521r1_modp _nettle_ecc_secp521r1_modp
 void
-ecc_521_modp (const struct ecc_modulo *m, mp_limb_t *rp);
+ecc_secp521r1_modp (const struct ecc_modulo *m, mp_limb_t *rp);
 
 #else
 
@@ -57,7 +57,7 @@ ecc_521_modp (const struct ecc_modulo *m, mp_limb_t *rp);
 
 /* Result may be *slightly* larger than 2^521 */
 static void
-ecc_521_modp (const struct ecc_modulo *m UNUSED, mp_limb_t *rp)
+ecc_secp521r1_modp (const struct ecc_modulo *m UNUSED, mp_limb_t *rp)
 {
   /* FIXME: Should use mpn_addlsh_n_ip1 */
   mp_limb_t hi;
@@ -91,8 +91,8 @@ const struct ecc_curve _nettle_secp_521r1 =
     ecc_redc_ppm1,
     ecc_pp1h,
 
-    ecc_521_modp,
-    ecc_521_modp,
+    ecc_secp521r1_modp,
+    ecc_secp521r1_modp,
     ecc_mod_inv,
     NULL,
   },
diff --git a/eddsa-sign.c b/eddsa-sign.c
index 052770645f29..1d5e4796b120 100644
--- a/eddsa-sign.c
+++ b/eddsa-sign.c
@@ -95,7 +95,7 @@ _eddsa_sign (const struct ecc_curve *ecc,
   ecc_modq_add (ecc, sp, sp, rp); /* FIXME: Can be plain add */
   if (ecc-&gt;p.bit_size == 255)
     {
-      /* FIXME: Special code duplicated in ecc_25519_modq
+      /* FIXME: Special code duplicated in ecc_curve25519_modq
 	 Define a suitable method for canonical reduction? */
 
       /* q is slightly larger than 2^252, underflow from below
diff --git a/x86_64/ecc-curve25519-modp.asm b/x86_64/ecc-curve25519-modp.asm
index 0374db12ab44..44dce6df8789 100644
--- a/x86_64/ecc-curve25519-modp.asm
+++ b/x86_64/ecc-curve25519-modp.asm
@@ -41,7 +41,7 @@ define(&lt;T0&gt;, &lt;%r10&gt;)
 define(&lt;T1&gt;, &lt;%r11&gt;)
 define(&lt;M&gt;, &lt;%rbx&gt;)
 
-PROLOGUE(_nettle_ecc_25519_modp)
+PROLOGUE(_nettle_ecc_curve25519_modp)
 	W64_ENTRY(2, 0)
 	push	%rbx
 
@@ -91,4 +91,4 @@ PROLOGUE(_nettle_ecc_25519_modp)
 	pop	%rbx
 	W64_EXIT(2, 0)
 	ret
-EPILOGUE(_nettle_ecc_25519_modp)
+EPILOGUE(_nettle_ecc_curve25519_modp)
diff --git a/x86_64/ecc-secp192r1-modp.asm b/x86_64/ecc-secp192r1-modp.asm
index ad8dca7186e4..3a008130c1bb 100644
--- a/x86_64/ecc-secp192r1-modp.asm
+++ b/x86_64/ecc-secp192r1-modp.asm
@@ -41,10 +41,10 @@ define(&lt;H&gt;, &lt;%r9&gt;)
 define(&lt;C1&gt;, &lt;%r10&gt;)
 define(&lt;C2&gt;, &lt;%r11&gt;)
 
-	C ecc_192_modp (const struct ecc_modulo *m, mp_limb_t *rp)
+	C ecc_secp192r1_modp (const struct ecc_modulo *m, mp_limb_t *rp)
 	.text
 	ALIGN(16)
-PROLOGUE(_nettle_ecc_192_modp)
+PROLOGUE(_nettle_ecc_secp192r1_modp)
 	W64_ENTRY(2, 0)
 	mov	16(RP), T2
 	mov	24(RP), T3
@@ -85,4 +85,4 @@ PROLOGUE(_nettle_ecc_192_modp)
 
 	W64_EXIT(2, 0)
 	ret
-EPILOGUE(_nettle_ecc_192_modp)
+EPILOGUE(_nettle_ecc_secp192r1_modp)
diff --git a/x86_64/ecc-secp224r1-modp.asm b/x86_64/ecc-secp224r1-modp.asm
index e44b5418e5dd..dfa85a8d6f3f 100644
--- a/x86_64/ecc-secp224r1-modp.asm
+++ b/x86_64/ecc-secp224r1-modp.asm
@@ -44,8 +44,8 @@ define(&lt;F0&gt;, &lt;%r9&gt;)
 define(&lt;F1&gt;, &lt;%r10&gt;)
 define(&lt;F2&gt;, &lt;%r11&gt;)
 
-	C ecc_224_modp (const struct ecc_modulo *m, mp_limb_t *rp)
-PROLOGUE(_nettle_ecc_224_modp)
+	C ecc_secp224r1_modp (const struct ecc_modulo *m, mp_limb_t *rp)
+PROLOGUE(_nettle_ecc_secp224r1_modp)
 	W64_ENTRY(2, 0)
 	mov	48(RP), H0
 	mov	56(RP), H1
@@ -128,4 +128,4 @@ PROLOGUE(_nettle_ecc_224_modp)
 
 	W64_EXIT(2, 0)
 	ret
-EPILOGUE(_nettle_ecc_224_modp)
+EPILOGUE(_nettle_ecc_secp224r1_modp)
diff --git a/x86_64/ecc-secp256r1-redc.asm b/x86_64/ecc-secp256r1-redc.asm
index 533a1766d4bc..67da065b27f4 100644
--- a/x86_64/ecc-secp256r1-redc.asm
+++ b/x86_64/ecc-secp256r1-redc.asm
@@ -58,7 +58,7 @@ define(&lt;FOLD&gt;, &lt;
 	sbb	$1, F2
 	sbb	&lt;$&gt;0, F3
 &gt;)
-PROLOGUE(_nettle_ecc_256_redc)
+PROLOGUE(_nettle_ecc_secp256r1_redc)
 	W64_ENTRY(2, 0)
 	C save all registers that need to be saved
 	push	%rbx
@@ -126,4 +126,4 @@ PROLOGUE(_nettle_ecc_256_redc)
 	pop	%rbx
 	W64_EXIT(2, 0)
 	ret
-EPILOGUE(_nettle_ecc_256_redc)
+EPILOGUE(_nettle_ecc_secp256r1_redc)
diff --git a/x86_64/ecc-secp384r1-modp.asm b/x86_64/ecc-secp384r1-modp.asm
index 13f469b164e4..9bfa0618d33e 100644
--- a/x86_64/ecc-secp384r1-modp.asm
+++ b/x86_64/ecc-secp384r1-modp.asm
@@ -51,7 +51,7 @@ define(&lt;C0&gt;, H5)	C Overlap
 define(&lt;TMP&gt;, RP)	C Overlap
 
 
-PROLOGUE(_nettle_ecc_384_modp)
+PROLOGUE(_nettle_ecc_secp384r1_modp)
 	W64_ENTRY(2, 0)
 
 	push	%rbx
@@ -231,4 +231,4 @@ PROLOGUE(_nettle_ecc_384_modp)
 
 	W64_EXIT(2, 0)
 	ret
-EPILOGUE(_nettle_ecc_384_modp)
+EPILOGUE(_nettle_ecc_secp384r1_modp)
diff --git a/x86_64/ecc-secp521r1-modp.asm b/x86_64/ecc-secp521r1-modp.asm
index 6f4f7d90714d..a6840a60faec 100644
--- a/x86_64/ecc-secp521r1-modp.asm
+++ b/x86_64/ecc-secp521r1-modp.asm
@@ -48,7 +48,7 @@ define(&lt;U9&gt;, &lt;%r11&gt;)
 define(&lt;T0&gt;, &lt;%r12&gt;)
 define(&lt;T1&gt;, &lt;%r13&gt;)
 
-PROLOGUE(_nettle_ecc_521_modp)
+PROLOGUE(_nettle_ecc_secp521r1_modp)
 	W64_ENTRY(2, 0)
 	push	%rbx
 	push	%rbp
@@ -155,4 +155,4 @@ PROLOGUE(_nettle_ecc_521_modp)
 	pop	%rbx
 	W64_EXIT(2, 0)
 	ret
-EPILOGUE(_nettle_ecc_521_modp)
+EPILOGUE(_nettle_ecc_secp521r1_modp)
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200110223409</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-01-10 22:34:09-0400</timestampReceived><subject>[PATCH 3/3] Add GOST DSA according to GOST R 34.10-2001/-2012</subject><body>

From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;

Add GOST Digital Signature Algorithms support according to GOST R
34.10-2001/-2012. English translations of these standards are provided
as RFC 5832 and RFC 7091.

Signed-off-by: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;
---
 Makefile.in                     |   4 +-
 ecc-gostdsa-sign.c              | 103 +++++++++++++++++++++
 ecc-gostdsa-verify.c            | 132 +++++++++++++++++++++++++++
 ecc-hash.c                      |  11 +++
 ecc-internal.h                  |   7 ++
 gostdsa-sign.c                  |  76 ++++++++++++++++
 gostdsa-verify.c                |  80 +++++++++++++++++
 gostdsa.h                       | 102 +++++++++++++++++++++
 testsuite/.gitignore            |   3 +
 testsuite/.test-rules.make      |   9 ++
 testsuite/Makefile.in           |   4 +-
 testsuite/gostdsa-keygen-test.c | 154 ++++++++++++++++++++++++++++++++
 testsuite/gostdsa-sign-test.c   | 125 ++++++++++++++++++++++++++
 testsuite/gostdsa-verify-test.c | 148 ++++++++++++++++++++++++++++++
 testsuite/testutils.h           |   1 +
 15 files changed, 957 insertions(+), 2 deletions(-)
 create mode 100644 ecc-gostdsa-sign.c
 create mode 100644 ecc-gostdsa-verify.c
 create mode 100644 gostdsa-sign.c
 create mode 100644 gostdsa-verify.c
 create mode 100644 gostdsa.h
 create mode 100644 testsuite/gostdsa-keygen-test.c
 create mode 100644 testsuite/gostdsa-sign-test.c
 create mode 100644 testsuite/gostdsa-verify-test.c

diff --git a/Makefile.in b/Makefile.in
index d9b76d8d5354..3efc41f5ea04 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -190,6 +190,8 @@ hogweed_SOURCES = sexp.c sexp-format.c \
 		  ecc-point.c ecc-scalar.c ecc-point-mul.c ecc-point-mul-g.c \
 		  ecc-ecdsa-sign.c ecdsa-sign.c \
 		  ecc-ecdsa-verify.c ecdsa-verify.c ecdsa-keygen.c \
+		  ecc-gostdsa-sign.c gostdsa-sign.c \
+		  ecc-gostdsa-verify.c gostdsa-verify.c \
 		  curve25519-mul-g.c curve25519-mul.c curve25519-eh-to-x.c \
 		  curve448-mul-g.c curve448-mul.c curve448-eh-to-x.c \
 		  eddsa-compress.c eddsa-decompress.c eddsa-expand.c \
@@ -206,7 +208,7 @@ HEADERS = aes.h arcfour.h arctwo.h asn1.h blowfish.h \
 	  cbc.h ccm.h cfb.h chacha.h chacha-poly1305.h ctr.h \
 	  curve25519.h curve448.h des.h dsa.h dsa-compat.h eax.h \
 	  ecc-curve.h ecc.h ecdsa.h eddsa.h \
-	  gcm.h gost28147.h gosthash94.h hmac.h \
+	  gcm.h gost28147.h gostdsa.h gosthash94.h hmac.h \
 	  knuth-lfib.h hkdf.h \
 	  macros.h \
 	  cmac.h siv-cmac.h \
diff --git a/ecc-gostdsa-sign.c b/ecc-gostdsa-sign.c
new file mode 100644
index 000000000000..0b8671d382ec
--- /dev/null
+++ b/ecc-gostdsa-sign.c
@@ -0,0 +1,103 @@
+/* ecc-gostdsa-sign.c
+
+   Copyright (C) 2015 Dmitry Eremin-Solenikov
+   Copyright (C) 2013, 2014 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+/* Development of Nettle's ECC support was funded by the .SE Internet Fund. */
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;stdlib.h&gt;
+
+#include "gostdsa.h"
+#include "ecc-internal.h"
+
+/* Low-level GOST DSA signing */
+
+mp_size_t
+ecc_gostdsa_sign_itch (const struct ecc_curve *ecc)
+{
+  /* Needs 3*ecc-&gt;p.size + scratch for ecc-&gt;mul_g. Currently same for
+     ecc_mul_g and ecc_mul_g_eh. */
+  return ECC_GOSTDSA_SIGN_ITCH (ecc-&gt;p.size);
+}
+
+/* NOTE: Caller should check if r or s is zero. */
+void
+ecc_gostdsa_sign (const struct ecc_curve *ecc,
+		const mp_limb_t *zp,
+		const mp_limb_t *kp,
+		size_t length, const uint8_t *digest,
+		mp_limb_t *rp, mp_limb_t *sp,
+		mp_limb_t *scratch)
+{
+#define P	    scratch
+#define hp	    (scratch + 4*ecc-&gt;p.size)
+#define tp	    (scratch + 2*ecc-&gt;p.size)
+#define t2p	    scratch
+  /* Procedure, according to GOST 34.10. q denotes the group
+     order.
+
+     1. k &lt;-- uniformly random, 0 &lt; k &lt; q
+
+     2. C &lt;-- (c_x, c_y) = k g
+
+     3. r &lt;-- c_x mod q
+
+     4. s &lt;-- (r*z + k*h) mod q.
+  */
+
+  ecc-&gt;mul_g (ecc, P, kp, P + 3*ecc-&gt;p.size);
+  /* x coordinate only, modulo q */
+  ecc-&gt;h_to_a (ecc, 2, rp, P, P + 3*ecc-&gt;p.size);
+
+  /* Process hash digest */
+  gost_hash (&amp;ecc-&gt;q, hp, length, digest);
+  if (mpn_zero_p (hp, ecc-&gt;p.size))
+    mpn_add_1 (hp, hp, ecc-&gt;p.size, 1);
+
+  ecc_modq_mul (ecc, tp, rp, zp);
+  ecc_modq_mul (ecc, t2p, kp, hp);
+  ecc_modq_add (ecc, sp, tp, t2p);
+
+  /* Also reduce mod ecc-&gt;q. It should already be &lt; 2*ecc-&gt;q,
+   * so one subtraction should suffice. */
+
+  *scratch = mpn_sub_n (tp, sp, ecc-&gt;q.m, ecc-&gt;p.size);
+  cnd_copy (*scratch == 0, sp, tp, ecc-&gt;p.size);
+
+#undef P
+#undef hp
+#undef tp
+#undef t2p
+}
diff --git a/ecc-gostdsa-verify.c b/ecc-gostdsa-verify.c
new file mode 100644
index 000000000000..44f87b892f75
--- /dev/null
+++ b/ecc-gostdsa-verify.c
@@ -0,0 +1,132 @@
+/* ecc-gostdsa-verify.c
+
+   Copyright (C) 2015 Dmitry Eremin-Solenikov
+   Copyright (C) 2013, 2014 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+/* Development of Nettle's ECC support was funded by the .SE Internet Fund. */
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;stdlib.h&gt;
+
+#include "gostdsa.h"
+#include "ecc-internal.h"
+
+/* Low-level GOST DSA verify */
+
+static int
+ecdsa_in_range (const struct ecc_curve *ecc, const mp_limb_t *xp)
+{
+  return !mpn_zero_p (xp, ecc-&gt;p.size)
+    &amp;&amp; mpn_cmp (xp, ecc-&gt;q.m, ecc-&gt;p.size) &lt; 0;
+}
+
+mp_size_t
+ecc_gostdsa_verify_itch (const struct ecc_curve *ecc)
+{
+  /* Largest storage need is for the ecc-&gt;mul call. */
+  return 5*ecc-&gt;p.size + ecc-&gt;mul_itch;
+}
+
+/* FIXME: Use faster primitives, not requiring side-channel silence. */
+int
+ecc_gostdsa_verify (const struct ecc_curve *ecc,
+		  const mp_limb_t *pp, /* Public key */
+		  size_t length, const uint8_t *digest,
+		  const mp_limb_t *rp, const mp_limb_t *sp,
+		  mp_limb_t *scratch)
+{
+  /* Procedure, according to GOST R 34.10. q denotes the group
+     order.
+
+     1. Check 0 &lt; r, s &lt; q.
+
+     2. v &lt;-- h^{-1}  (mod q)
+
+     3. z1  &lt;-- s * v (mod q)
+
+     4. z2  &lt;-- -r * v (mod q)
+
+     5. R = u1 G + u2 Y
+
+     6. Signature is valid if R_x = r (mod q).
+  */
+
+#define hp (scratch)
+#define vp (scratch + ecc-&gt;p.size)
+#define z1 (scratch + 3*ecc-&gt;p.size)
+#define z2 (scratch + 4*ecc-&gt;p.size)
+
+#define P1 (scratch + 4*ecc-&gt;p.size)
+#define P2 (scratch)
+
+
+  if (! (ecdsa_in_range (ecc, rp)
+	 &amp;&amp; ecdsa_in_range (ecc, sp)))
+    return 0;
+
+  gost_hash (&amp;ecc-&gt;q, hp, length, digest);
+
+  if (mpn_zero_p (hp, ecc-&gt;p.size))
+    mpn_add_1 (hp, hp, ecc-&gt;p.size, 1);
+
+  /* Compute v */
+  ecc-&gt;q.invert (&amp;ecc-&gt;q, vp, hp, vp + 2*ecc-&gt;p.size);
+
+  /* z1 = s / h, P1 = z1 * G */
+  ecc_modq_mul (ecc, z1, sp, vp);
+
+  /* z2 = - r / h, P2 = z2 * Y */
+  ecc_modq_mul (ecc, z2, rp, vp);
+  mpn_sub_n (z2, ecc-&gt;q.m, z2, ecc-&gt;p.size);
+
+   /* Total storage: 5*ecc-&gt;p.size + ecc-&gt;mul_itch */
+  ecc-&gt;mul (ecc, P2, z2, pp, z2 + ecc-&gt;p.size);
+
+  /* Total storage: 7*ecc-&gt;p.size + ecc-&gt;mul_g_itch (ecc-&gt;p.size) */
+  ecc-&gt;mul_g (ecc, P1, z1, P1 + 3*ecc-&gt;p.size);
+
+  /* Total storage: 6*ecc-&gt;p.size + ecc-&gt;add_hhh_itch */
+  ecc-&gt;add_hhh (ecc, P1, P1, P2, P1 + 3*ecc-&gt;p.size);
+
+  /* x coordinate only, modulo q */
+  ecc-&gt;h_to_a (ecc, 2, P2, P1, P1 + 3*ecc-&gt;p.size);
+
+  return (mpn_cmp (rp, P2, ecc-&gt;p.size) == 0);
+#undef P2
+#undef P1
+#undef z2
+#undef z1
+#undef hp
+#undef vp
+}
diff --git a/ecc-hash.c b/ecc-hash.c
index 4e830a514ac4..07877110263f 100644
--- a/ecc-hash.c
+++ b/ecc-hash.c
@@ -62,3 +62,14 @@ ecc_hash (const struct ecc_modulo *m,
     /* We got a few extra bits, at the low end. Discard them. */
     mpn_rshift (hp, hp, m-&gt;size + 1, 8*length - m-&gt;bit_size);
 }
+
+void
+gost_hash (const struct ecc_modulo *m,
+	   mp_limb_t *hp,
+	   size_t length, const uint8_t *digest)
+{
+  if (length &gt; ((size_t) m-&gt;bit_size + 7) / 8)
+    length = (m-&gt;bit_size + 7) / 8;
+
+  mpn_set_base256_le (hp, m-&gt;size + 1, digest, length);
+}
diff --git a/ecc-internal.h b/ecc-internal.h
index 99e711a5b38d..680e82258be7 100644
--- a/ecc-internal.h
+++ b/ecc-internal.h
@@ -53,6 +53,7 @@
 #define ecc_mod _nettle_ecc_mod
 #define ecc_mod_inv _nettle_ecc_mod_inv
 #define ecc_hash _nettle_ecc_hash
+#define gost_hash _nettle_gost_hash
 #define ecc_a_to_j _nettle_ecc_a_to_j
 #define ecc_j_to_a _nettle_ecc_j_to_a
 #define ecc_eh_to_a _nettle_ecc_eh_to_a
@@ -299,6 +300,11 @@ ecc_hash (const struct ecc_modulo *m,
 	  mp_limb_t *hp,
 	  size_t length, const uint8_t *digest);
 
+void
+gost_hash (const struct ecc_modulo *m,
+	  mp_limb_t *hp,
+	  size_t length, const uint8_t *digest);
+
 /* Converts a point P in affine coordinates into a point R in jacobian
    coordinates. */
 void
@@ -467,6 +473,7 @@ curve448_eh_to_x (mp_limb_t *xp, const mp_limb_t *p,
 #endif
 #define ECC_MUL_M_ITCH(size) (11*(size))
 #define ECC_ECDSA_SIGN_ITCH(size) (12*(size))
+#define ECC_GOSTDSA_SIGN_ITCH(size) (12*(size))
 #define ECC_MOD_RANDOM_ITCH(size) (size)
 #define ECC_HASH_ITCH(size) (1+(size))
 
diff --git a/gostdsa-sign.c b/gostdsa-sign.c
new file mode 100644
index 000000000000..598654ac34f1
--- /dev/null
+++ b/gostdsa-sign.c
@@ -0,0 +1,76 @@
+/* gostdsa-sign.c
+
+   Copyright (C) 2015 Dmitry Eremin-Solenikov
+   Copyright (C) 2013 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+/* Development of Nettle's ECC support was funded by the .SE Internet Fund. */
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;stdlib.h&gt;
+
+#include "gostdsa.h"
+#include "ecc-internal.h"
+#include "nettle-internal.h"
+
+void
+gostdsa_sign (const struct ecc_scalar *key,
+	    void *random_ctx, nettle_random_func *random,
+	    size_t digest_length,
+	    const uint8_t *digest,
+	    struct dsa_signature *signature)
+{
+  /* At most 936 bytes. */
+  TMP_DECL(k, mp_limb_t, ECC_MAX_SIZE + ECC_GOSTDSA_SIGN_ITCH (ECC_MAX_SIZE));
+  mp_limb_t size = key-&gt;ecc-&gt;p.size;
+  mp_limb_t *rp = mpz_limbs_write (signature-&gt;r, size);
+  mp_limb_t *sp = mpz_limbs_write (signature-&gt;s, size);
+
+  TMP_ALLOC (k, size + ECC_GOSTDSA_SIGN_ITCH (size));
+
+  /* Timing reveals the number of rounds through this loop, but the
+     timing is still independent of the secret k finally used. */
+  do
+    {
+      do
+        {
+          ecc_mod_random (&amp;key-&gt;ecc-&gt;q, k, random_ctx, random, k + size);
+	}
+      while (mpn_zero_p(k, size));
+      ecc_gostdsa_sign (key-&gt;ecc, key-&gt;p, k, digest_length, digest,
+		   rp, sp, k + size);
+      mpz_limbs_finish (signature-&gt;r, size);
+      mpz_limbs_finish (signature-&gt;s, size);
+    }
+  while (mpz_sgn (signature-&gt;r) == 0 || mpz_sgn (signature-&gt;s) == 0);
+}
diff --git a/gostdsa-verify.c b/gostdsa-verify.c
new file mode 100644
index 000000000000..cdf87d6ba18d
--- /dev/null
+++ b/gostdsa-verify.c
@@ -0,0 +1,80 @@
+/* gostdsa-verify.c
+
+   Copyright (C) 2015 Dmitry Eremin-Solenikov
+   Copyright (C) 2013 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+/* Development of Nettle's ECC support was funded by the .SE Internet Fund. */
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;stdlib.h&gt;
+
+#include "gostdsa.h"
+
+#include "gmp-glue.h"
+
+int
+gostdsa_verify (const struct ecc_point *pub,
+	      size_t length, const uint8_t *digest,
+	      const struct dsa_signature *signature)
+{
+  mp_limb_t size = ecc_size (pub-&gt;ecc);
+  mp_size_t itch = 2*size + ecc_gostdsa_verify_itch (pub-&gt;ecc);
+  /* For ECC_MUL_A_WBITS == 0, at most 1512 bytes. With
+     ECC_MUL_A_WBITS == 4, currently needs 67 * ecc-&gt;size, at most
+     4824 bytes. Don't use stack allocation for this. */
+  mp_limb_t *scratch;
+  int res;
+
+#define rp scratch
+#define sp (scratch + size)
+#define scratch_out (scratch + 2*size)
+
+  if (mpz_sgn (signature-&gt;r) &lt;= 0 || mpz_size (signature-&gt;r) &gt; size
+      || mpz_sgn (signature-&gt;s) &lt;= 0 || mpz_size (signature-&gt;s) &gt; size)
+    return 0;
+
+  scratch = gmp_alloc_limbs (itch);
+
+  mpz_limbs_copy (rp, signature-&gt;r, size);
+  mpz_limbs_copy (sp, signature-&gt;s, size);
+
+  res = ecc_gostdsa_verify (pub-&gt;ecc, pub-&gt;p, length, digest, rp, sp, scratch_out);
+
+  gmp_free_limbs (scratch, itch);
+
+  return res;
+#undef rp
+#undef sp
+#undef scratch_out
+}
diff --git a/gostdsa.h b/gostdsa.h
new file mode 100644
index 000000000000..b34533436f72
--- /dev/null
+++ b/gostdsa.h
@@ -0,0 +1,102 @@
+/* gostdsa.h
+
+   Copyright (C) 2015 Dmity Eremin-Solenikov
+   Copyright (C) 2013 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+/* Development of Nettle's ECC support was funded by the .SE Internet Fund. */
+
+#ifndef NETTLE_GOSTDSA_H_INCLUDED
+#define NETTLE_GOSTDSA_H_INCLUDED
+
+#include "ecc.h"
+#include "dsa.h"
+#include "ecdsa.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/* Name mangling */
+#define gostdsa_sign nettle_gostdsa_sign
+#define gostdsa_verify nettle_gostdsa_verify
+#define ecc_gostdsa_sign nettle_ecc_gostdsa_sign
+#define ecc_gostdsa_sign_itch nettle_ecc_gostdsa_sign_itch
+#define ecc_gostdsa_verify nettle_ecc_gostdsa_verify
+#define ecc_gostdsa_verify_itch nettle_ecc_gostdsa_verify_itch
+
+/* Just use ECDSA function for key generation */
+#define gostdsa_generate_keypair ecdsa_generate_keypair
+
+/* High level GOST DSA functions.
+ *
+ * A public key is represented as a struct ecc_point, and a private
+ * key as a struct ecc_scalar. FIXME: Introduce some aliases? */
+void
+gostdsa_sign (const struct ecc_scalar *key,
+	      void *random_ctx, nettle_random_func *random,
+	      size_t digest_length,
+	      const uint8_t *digest,
+	      struct dsa_signature *signature);
+
+int
+gostdsa_verify (const struct ecc_point *pub,
+	        size_t length, const uint8_t *digest,
+	        const struct dsa_signature *signature);
+
+/* Low-level GOSTDSA functions. */
+mp_size_t
+ecc_gostdsa_sign_itch (const struct ecc_curve *ecc);
+
+void
+ecc_gostdsa_sign (const struct ecc_curve *ecc,
+		const mp_limb_t *zp,
+		/* Random nonce, must be invertible mod ecc group
+		   order. */
+		const mp_limb_t *kp,
+		size_t length, const uint8_t *digest,
+		mp_limb_t *rp, mp_limb_t *sp,
+		mp_limb_t *scratch);
+
+mp_size_t
+ecc_gostdsa_verify_itch (const struct ecc_curve *ecc);
+
+int
+ecc_gostdsa_verify (const struct ecc_curve *ecc,
+		  const mp_limb_t *pp, /* Public key */
+		  size_t length, const uint8_t *digest,
+		  const mp_limb_t *rp, const mp_limb_t *sp,
+		  mp_limb_t *scratch);
+
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* NETTLE_GOSTDSA_H_INCLUDED */
diff --git a/testsuite/.gitignore b/testsuite/.gitignore
index 1e2a69a60c13..be3a48707580 100644
--- a/testsuite/.gitignore
+++ b/testsuite/.gitignore
@@ -43,6 +43,9 @@
 /eddsa-sign-test
 /eddsa-verify-test
 /gcm-test
+/gostdsa-keygen-test
+/gostdsa-sign-test
+/gostdsa-verify-test
 /gosthash94-test
 /hkdf-test
 /hmac-test
diff --git a/testsuite/.test-rules.make b/testsuite/.test-rules.make
index 6dbef7e24a27..9fd11fd6d126 100644
--- a/testsuite/.test-rules.make
+++ b/testsuite/.test-rules.make
@@ -289,6 +289,15 @@ ed25519-test$(EXEEXT): ed25519-test.$(OBJEXT)
 ed448-test$(EXEEXT): ed448-test.$(OBJEXT)
 	$(LINK) ed448-test.$(OBJEXT) $(TEST_OBJS) -o ed448-test$(EXEEXT)
 
+gostdsa-sign-test$(EXEEXT): gostdsa-sign-test.$(OBJEXT)
+	$(LINK) gostdsa-sign-test.$(OBJEXT) $(TEST_OBJS) -o gostdsa-sign-test$(EXEEXT)
+
+gostdsa-verify-test$(EXEEXT): gostdsa-verify-test.$(OBJEXT)
+	$(LINK) gostdsa-verify-test.$(OBJEXT) $(TEST_OBJS) -o gostdsa-verify-test$(EXEEXT)
+
+gostdsa-keygen-test$(EXEEXT): gostdsa-keygen-test.$(OBJEXT)
+	$(LINK) gostdsa-keygen-test.$(OBJEXT) $(TEST_OBJS) -o gostdsa-keygen-test$(EXEEXT)
+
 sha1-huge-test$(EXEEXT): sha1-huge-test.$(OBJEXT)
 	$(LINK) sha1-huge-test.$(OBJEXT) $(TEST_OBJS) -o sha1-huge-test$(EXEEXT)
 
diff --git a/testsuite/Makefile.in b/testsuite/Makefile.in
index 97128040912e..860394d3bea5 100644
--- a/testsuite/Makefile.in
+++ b/testsuite/Makefile.in
@@ -53,7 +53,9 @@ TS_HOGWEED_SOURCES = sexp-test.c sexp-format-test.c \
 		     ecdsa-sign-test.c ecdsa-verify-test.c \
 		     ecdsa-keygen-test.c ecdh-test.c \
 		     eddsa-compress-test.c eddsa-sign-test.c \
-		     eddsa-verify-test.c ed25519-test.c ed448-test.c
+		     eddsa-verify-test.c ed25519-test.c ed448-test.c \
+		     gostdsa-sign-test.c gostdsa-verify-test.c \
+		     gostdsa-keygen-test.c
 
 TS_SOURCES = $(TS_NETTLE_SOURCES) $(TS_HOGWEED_SOURCES)
 CXX_SOURCES = cxx-test.cxx
diff --git a/testsuite/gostdsa-keygen-test.c b/testsuite/gostdsa-keygen-test.c
new file mode 100644
index 000000000000..f34ff485ad6b
--- /dev/null
+++ b/testsuite/gostdsa-keygen-test.c
@@ -0,0 +1,154 @@
+#include "testutils.h"
+#include "knuth-lfib.h"
+
+/* Check if y^2 = x^3 - 3x + b */
+static int
+ecc_valid_p (struct ecc_point *pub)
+{
+  mpz_t t, x, y;
+  mpz_t lhs, rhs;
+  int res;
+  mp_size_t size;
+
+  size = pub-&gt;ecc-&gt;p.size;
+
+  /* First check range */
+  if (mpn_cmp (pub-&gt;p, pub-&gt;ecc-&gt;p.m, size) &gt;= 0
+      || mpn_cmp (pub-&gt;p + size, pub-&gt;ecc-&gt;p.m, size) &gt;= 0)
+    return 0;
+
+  mpz_init (lhs);
+  mpz_init (rhs);
+
+  mpz_roinit_n (x, pub-&gt;p, size);
+  mpz_roinit_n (y, pub-&gt;p + size, size);
+
+  mpz_mul (lhs, y, y);
+
+  if (pub-&gt;ecc-&gt;p.bit_size == 255)
+    {
+      /* Check that
+	 121666 (1 + x^2 - y^2) = 121665 x^2 y^2 */
+      mpz_t x2;
+      mpz_init (x2);
+      mpz_mul (x2, x, x); /* x^2 */
+      mpz_mul (rhs, x2, lhs); /* x^2 y^2 */
+      mpz_sub (lhs, x2, lhs); /* x^2 - y^2 */
+      mpz_add_ui (lhs, lhs, 1); /* 1 + x^2 - y^2 */
+      mpz_mul_ui (lhs, lhs, 121666);
+      mpz_mul_ui (rhs, rhs, 121665);
+
+      mpz_clear (x2);
+    }
+  else if (pub-&gt;ecc-&gt;p.bit_size == 448)
+    {
+      /* Check that
+	 x^2 + y^2 = 1 - 39081 x^2 y^2 */
+      mpz_t x2, d;
+      mpz_init (x2);
+      mpz_init_set_ui (d, 39081);
+      mpz_mul (x2, x, x); /* x^2 */
+      mpz_mul (d, d, x2); /* 39081 x^2 */
+      mpz_set_ui (rhs, 1);
+      mpz_submul (rhs, d, lhs); /* 1 - 39081 x^2 y^2 */
+      mpz_add (lhs, x2, lhs);	/* x^2 + y^2 */
+
+      mpz_clear (d);
+      mpz_clear (x2);
+    }
+  else
+    {
+      /* Check y^2 = x^3 - 3 x + b */
+      mpz_mul (rhs, x, x);
+      mpz_sub_ui (rhs, rhs, 3);
+      mpz_mul (rhs, rhs, x);
+      mpz_add (rhs, rhs, mpz_roinit_n (t, pub-&gt;ecc-&gt;b, size));
+    }
+  res = mpz_congruent_p (lhs, rhs, mpz_roinit_n (t, pub-&gt;ecc-&gt;p.m, size));
+
+  mpz_clear (lhs);
+  mpz_clear (rhs);
+
+  return res;
+}
+
+void
+test_main (void)
+{
+  unsigned i;
+  struct knuth_lfib_ctx rctx;
+  struct dsa_signature signature;
+
+  struct tstring *digest;
+
+  knuth_lfib_init (&amp;rctx, 4711);
+  dsa_signature_init (&amp;signature);
+
+  digest = SHEX (/* sha256("abc") */
+		 "BA7816BF 8F01CFEA 414140DE 5DAE2223"
+		 "B00361A3 96177A9C B410FF61 F20015AD");
+
+  for (i = 0; ecc_curves[i]; i++)
+    {
+      const struct ecc_curve *ecc = ecc_curves[i];
+      struct ecc_point pub;
+      struct ecc_scalar key;
+
+      if (ecc-&gt;p.bit_size == 255 || ecc-&gt;p.bit_size == 448)
+	/* Exclude curve25519 and curve448, not supported with GOSTDSA. */
+	continue;
+
+      if (verbose)
+	fprintf (stderr, "Curve %d\n", ecc-&gt;p.bit_size);
+
+      ecc_point_init (&amp;pub, ecc);
+      ecc_scalar_init (&amp;key, ecc);
+
+      ecdsa_generate_keypair (&amp;pub, &amp;key,
+			      &amp;rctx,
+			      (nettle_random_func *) knuth_lfib_random);
+
+      if (verbose)
+	{
+	  fprintf (stderr, "Public key:\nx = ");
+	  write_mpn (stderr, 16, pub.p, ecc-&gt;p.size);
+	  fprintf (stderr, "\ny = ");
+	  write_mpn (stderr, 16, pub.p + ecc-&gt;p.size, ecc-&gt;p.size);
+	  fprintf (stderr, "\nPrivate key: ");
+	  write_mpn (stderr, 16, key.p, ecc-&gt;p.size);
+	  fprintf (stderr, "\n");
+	}
+      if (!ecc_valid_p (&amp;pub))
+	die ("gostdsa_generate_keypair produced an invalid point.\n");
+
+      gostdsa_sign (&amp;key,
+		   &amp;rctx, (nettle_random_func *) knuth_lfib_random,
+		   digest-&gt;length, digest-&gt;data,
+		   &amp;signature);
+
+      if (!gostdsa_verify (&amp;pub, digest-&gt;length, digest-&gt;data,
+			   &amp;signature))
+	die ("gostdsa_verify failed.\n");
+
+      digest-&gt;data[3] ^= 17;
+      if (gostdsa_verify (&amp;pub, digest-&gt;length, digest-&gt;data,
+			  &amp;signature))
+	die ("gostdsa_verify  returned success with invalid digest.\n");
+      digest-&gt;data[3] ^= 17;
+
+      mpz_combit (signature.r, 117);
+      if (gostdsa_verify (&amp;pub, digest-&gt;length, digest-&gt;data,
+			  &amp;signature))
+	die ("gostdsa_verify  returned success with invalid signature.r.\n");
+
+      mpz_combit (signature.r, 117);
+      mpz_combit (signature.s, 93);
+      if (gostdsa_verify (&amp;pub, digest-&gt;length, digest-&gt;data,
+			  &amp;signature))
+	die ("gostdsa_verify  returned success with invalid signature.s.\n");
+
+      ecc_point_clear (&amp;pub);
+      ecc_scalar_clear (&amp;key);
+    }
+  dsa_signature_clear (&amp;signature);
+}
diff --git a/testsuite/gostdsa-sign-test.c b/testsuite/gostdsa-sign-test.c
new file mode 100644
index 000000000000..989621536b4b
--- /dev/null
+++ b/testsuite/gostdsa-sign-test.c
@@ -0,0 +1,125 @@
+#include "testutils.h"
+
+static void
+test_gostdsa (const struct ecc_curve *ecc,
+	    /* Private key */
+	    const char *sz,
+	    /* Random nonce */
+	    const char *sk,
+	    /* Hash */
+	    const struct tstring *h,
+	    /* Expected signature */
+	    const char *r, const char *s)
+{
+  struct dsa_signature ref;
+  mpz_t z;
+  mpz_t k;
+  mp_limb_t *rp = xalloc_limbs (ecc-&gt;p.size);
+  mp_limb_t *sp = xalloc_limbs (ecc-&gt;p.size);
+  mp_limb_t *scratch = xalloc_limbs (ecc_gostdsa_sign_itch (ecc));
+
+  dsa_signature_init (&amp;ref);
+
+  mpz_init_set_str (z, sz, 16);
+  mpz_init_set_str (k, sk, 16);
+
+  ecc_gostdsa_sign (ecc, mpz_limbs_read_n (z, ecc-&gt;p.size),
+		  mpz_limbs_read_n (k, ecc-&gt;p.size),
+		  h-&gt;length, h-&gt;data, rp, sp, scratch);
+
+  mpz_set_str (ref.r, r, 16);
+  mpz_set_str (ref.s, s, 16);
+
+  if (mpz_limbs_cmp (ref.r, rp, ecc-&gt;p.size) != 0
+      || mpz_limbs_cmp (ref.s, sp, ecc-&gt;p.size) != 0)
+    {
+      fprintf (stderr, "_gostdsa_sign failed, bit_size = %u\n", ecc-&gt;p.bit_size);
+      fprintf (stderr, "r     = ");
+      write_mpn (stderr, 16, rp, ecc-&gt;p.size);
+      fprintf (stderr, "\ns     = ");
+      write_mpn (stderr, 16, sp, ecc-&gt;p.size);
+      fprintf (stderr, "\nref.r = ");
+      mpz_out_str (stderr, 16, ref.r);
+      fprintf (stderr, "\nref.s = ");
+      mpz_out_str (stderr, 16, ref.s);
+      fprintf (stderr, "\n");
+      abort();
+    }
+
+  free (rp);
+  free (sp);
+  free (scratch);
+
+  dsa_signature_clear (&amp;ref);
+  mpz_clear (k);
+  mpz_clear (z);
+}
+
+void
+test_main (void)
+{
+  test_gostdsa (nettle_get_gc256b(),
+	      "BFCF1D623E5CDD3032A7C6EABB4A923C46E43D640FFEAAF2C3ED39A8FA399924", /* z */
+
+	      "5782C53F110C596F9155D35EBD25A06A89C50391850A8FEFE33B0E270318857C", /* k */
+
+	      SHEX("1C067E20EA6CB183F22EFB0F3C6FD2A4E6A02821CB7A1B17FACD5E1F7AA76F70"), /* h */
+
+	      "E9323A5E88DD87FB7C724383BFFE7CECD4B9FFA2AC33BEEF73A5A1F743404F6B", /* r */
+
+	      "5E5B9B805B01147A8492C4A162643AC615DC777B9174108F3DC276A41F987AF3"); /* s */
+
+  test_gostdsa (nettle_get_gc256c(),
+	      "3FCF1D623E5CDD3032A7C6EABB4A923C46E43D640FFEAAF2C3ED39A8FA399924", /* z */
+
+	      "5782C53F110C596F9155D35EBD25A06A89C50391850A8FEFE33B0E270318857C", /* k */
+
+	      SHEX("1C067E20EA6CB183F22EFB0F3C6FD2A4E6A02821CB7A1B17FACD5E1F7AA76F70"), /* h */
+
+	      "4E8F9973B31A134CE0942421573B0529B07EC96B835A07856C16CE8070C62547", /* r */
+
+	      "10CE0EFA72741D5EB24837563AAB9369781D6F487ACF88BBEE3E49EC239F6A90"); /* s */
+
+  test_gostdsa (nettle_get_gc256d(),
+	      "3FCF1D623E5CDD3032A7C6EABB4A923C46E43D640FFEAAF2C3ED39A8FA399924", /* z */
+
+	      "5782C53F110C596F9155D35EBD25A06A89C50391850A8FEFE33B0E270318857C", /* k */
+
+	      SHEX("1C067E20EA6CB183F22EFB0F3C6FD2A4E6A02821CB7A1B17FACD5E1F7AA76F70"), /* h */
+
+	      "7A03B527F916AF43DB655362A54AA9EBAF1A02B5776B5EBD8F00484EE8FD4AC6", /* r */
+
+	      "7D21C2C0D9AD2D03B5D0EF47AE85AB8861067C1FF5394A755BD4A30B5591F8C4"); /* s */
+
+  test_gostdsa (nettle_get_gc512a(),
+	      "3FC01CDCD4EC5F972EB482774C41E66DB7F380528DFE9E67992BA05AEE462435"
+	      "757530E641077CE587B976C8EEB48C48FD33FD175F0C7DE6A44E014E6BCB074B", /* z */
+
+	      "72ABB44536656BF1618CE10BF7EADD40582304A51EE4E2A25A0A32CB0E773ABB"
+	      "23B7D8FDD8FA5EEE91B4AE452F2272C86E1E2221215D405F51B5D5015616E1F6", /* k */
+
+	      SHEX("EDC257BED45FDDE4F1457B7F5B19017A8F204184366689D938532CDBAA5CB29A"
+		   "1D369DA57F8B983BE272219BD2C9A4FC57ECF7A77F34EE2E8AA553976A4766C0"), /* h */
+
+	      "891AA75C2A6F3B4DE27E3903F61CBB0F3F85A4E3C62F39A6E4E84A7477679C6E"
+	      "45008DC2774CA2FF64C12C0606FF918CAE3A50115440E9BF2971B627A882A1E8", /* r */
+
+	      "31065479996DDBDEE180AFE22CA3CDC44B45CE4C6C83909D1D3B702922A32441"
+	      "A9E11DCFBEA3D847C06B1A8A38EB1671D6C82FA21B79C99BE2EA809B10DAA5DF"); /* s */
+
+  test_gostdsa (nettle_get_gc512b(),
+	      "3FC01CDCD4EC5F972EB482774C41E66DB7F380528DFE9E67992BA05AEE462435"
+	      "757530E641077CE587B976C8EEB48C48FD33FD175F0C7DE6A44E014E6BCB074B", /* z */
+
+	      "72ABB44536656BF1618CE10BF7EADD40582304A51EE4E2A25A0A32CB0E773ABB"
+	      "23B7D8FDD8FA5EEE91B4AE452F2272C86E1E2221215D405F51B5D5015616E1F6", /* k */
+
+	      SHEX("EDC257BED45FDDE4F1457B7F5B19017A8F204184366689D938532CDBAA5CB29A"
+		   "1D369DA57F8B983BE272219BD2C9A4FC57ECF7A77F34EE2E8AA553976A4766C0"), /* h */
+
+	      "5DBF2F4C2D6A7705880FB1458CC58335065BEA5621FC9FBC176C4ACA5BC1E672"
+	      "25459A8EA3779434590DC872704029365A83A53B5EB3C06936B5D287E0A983E7", /* r */
+
+	      "4E6D2EE8A693D35F31F2551D43B4F6BC6F9EE7B9D27323873386C7DE5F91C39E"
+	      "D3AAE39B7D07FA92B3C742E9E1B16E11D9F7308E485B715987668346AEF1723D"); /* s */
+}
diff --git a/testsuite/gostdsa-verify-test.c b/testsuite/gostdsa-verify-test.c
new file mode 100644
index 000000000000..347f19fd277b
--- /dev/null
+++ b/testsuite/gostdsa-verify-test.c
@@ -0,0 +1,148 @@
+#include "testutils.h"
+
+static void
+test_gostdsa (const struct ecc_curve *ecc,
+	    /* Public key */
+	    const char *xs, const char *ys,
+	    /* Hash */
+	    struct tstring *h,
+	    /* Valid signature */
+	    const char *r, const char *s)
+{
+  struct ecc_point pub;
+  struct dsa_signature signature;
+  mpz_t x, y;
+
+  ecc_point_init (&amp;pub, ecc);
+  dsa_signature_init (&amp;signature);
+
+  mpz_init_set_str (x, xs, 16);
+  mpz_init_set_str (y, ys, 16);
+
+  if (!ecc_point_set (&amp;pub, x, y))
+    die ("ecc_point_set failed.\n");
+
+  mpz_set_str (signature.r, r, 16);
+  mpz_set_str (signature.s, s, 16);
+
+  if (!gostdsa_verify (&amp;pub, h-&gt;length, h-&gt;data, &amp;signature))
+    {
+      fprintf (stderr, "gostdsa_verify failed with valid signature.\n");
+    fail:
+      fprintf (stderr, "bit_size = %u\nx = ", ecc-&gt;p.bit_size);
+      mpz_out_str (stderr, 16, x);
+      fprintf (stderr, "\ny = ");
+      mpz_out_str (stderr, 16, y);
+      fprintf (stderr, "\ndigest ");
+      print_hex (h-&gt;length, h-&gt;data);
+      fprintf (stderr, "r = ");
+      mpz_out_str (stderr, 16, signature.r);
+      fprintf (stderr, "\ns = ");
+      mpz_out_str (stderr, 16, signature.s);
+      fprintf (stderr, "\n");
+      abort();
+    }
+
+  mpz_combit (signature.r, ecc-&gt;p.bit_size / 3);
+  if (gostdsa_verify (&amp;pub, h-&gt;length, h-&gt;data, &amp;signature))
+    {
+      fprintf (stderr, "gostdsa_verify unexpectedly succeeded with invalid signature.\n");
+      goto fail;
+    }
+  mpz_combit (signature.r, ecc-&gt;p.bit_size / 3);
+
+  mpz_combit (signature.s, 4*ecc-&gt;p.bit_size / 5);
+  if (gostdsa_verify (&amp;pub, h-&gt;length, h-&gt;data, &amp;signature))
+    {
+      fprintf (stderr, "gostdsa_verify unexpectedly succeeded with invalid signature.\n");
+      goto fail;
+    }
+  mpz_combit (signature.s, 4*ecc-&gt;p.bit_size / 5);
+
+  h-&gt;data[2*h-&gt;length / 3] ^= 0x40;
+  if (gostdsa_verify (&amp;pub, h-&gt;length, h-&gt;data, &amp;signature))
+    {
+      fprintf (stderr, "gostdsa_verify unexpectedly succeeded with invalid signature.\n");
+      goto fail;
+    }
+  h-&gt;data[2*h-&gt;length / 3] ^= 0x40;
+  if (!gostdsa_verify (&amp;pub, h-&gt;length, h-&gt;data, &amp;signature))
+    {
+      fprintf (stderr, "gostdsa_verify failed, internal testsuite error.\n");
+      goto fail;
+    }
+
+  ecc_point_clear (&amp;pub);
+  dsa_signature_clear (&amp;signature);
+  mpz_clear (x);
+  mpz_clear (y);
+}
+
+void
+test_main (void)
+{
+  test_gostdsa (nettle_get_gc256b(),
+	      "971566CEDA436EE7678F7E07E84EBB7217406C0B4747AA8FD2AB1453C3D0DFBA", /* x */
+
+	      "AD58736965949F8E59830F8DE20FC6C0D177F6AB599874F1E2E24FF71F9CE643", /* y */
+
+	      SHEX("1C067E20EA6CB183F22EFB0F3C6FD2A4E6A02821CB7A1B17FACD5E1F7AA76F70"), /* h */
+
+	      "E9323A5E88DD87FB7C724383BFFE7CECD4B9FFA2AC33BEEF73A5A1F743404F6B", /* r */
+
+	      "5E5B9B805B01147A8492C4A162643AC615DC777B9174108F3DC276A41F987AF3"); /* s */
+
+  test_gostdsa (nettle_get_gc256c(),
+	      "347E354F60B8DA8DE659B432600418C7D0E70F01622477579FAB36A066B9B8FD", /* x */
+
+	      "1DD2E31CF7840A5109DFAB561E15D42BC3CE2E64995FB70F3B86679655A1BAA1", /* y */
+
+	      SHEX("1C067E20EA6CB183F22EFB0F3C6FD2A4E6A02821CB7A1B17FACD5E1F7AA76F70"), /* h */
+
+	      "4E8F9973B31A134CE0942421573B0529B07EC96B835A07856C16CE8070C62547", /* r */
+
+	      "10CE0EFA72741D5EB24837563AAB9369781D6F487ACF88BBEE3E49EC239F6A90"); /* s */
+
+  test_gostdsa (nettle_get_gc256d(),
+	      "1F737CC71E43E3FB35B886383714CA5E1226ECDF21F6063E6EA2E40DD04C44EC", /* x */
+
+	      "7DD94CE1044CCEAD21E4E985E281034058A5B11F37B5F96F31DDCF7D513D164E", /* y */
+
+	      SHEX("1C067E20EA6CB183F22EFB0F3C6FD2A4E6A02821CB7A1B17FACD5E1F7AA76F70"), /* h */
+
+	      "7A03B527F916AF43DB655362A54AA9EBAF1A02B5776B5EBD8F00484EE8FD4AC6", /* r */
+
+	      "7D21C2C0D9AD2D03B5D0EF47AE85AB8861067C1FF5394A755BD4A30B5591F8C4"); /* s */
+
+  test_gostdsa (nettle_get_gc512a(),
+	      "03A36340A95BB5F93D131961B5B1C1B3213DF7FF3B5A30376407E2A65C441BC6"
+	      "D1B34662317083243F007B15A8512B526606D3B172B606DCE86DBD6F82DA3D40", /* x */
+
+	      "DEAD76318012FED79507809C89CC44848743640EAC9A3C847DA9082E050760A1"
+	      "0679F4B707ABC1872640AD20D7441F66C7A8B3BFF1B8E11B4A076F0A86749F73", /* y */
+
+	      SHEX("EDC257BED45FDDE4F1457B7F5B19017A8F204184366689D938532CDBAA5CB29A"
+		   "1D369DA57F8B983BE272219BD2C9A4FC57ECF7A77F34EE2E8AA553976A4766C0"), /* h */
+
+	      "891AA75C2A6F3B4DE27E3903F61CBB0F3F85A4E3C62F39A6E4E84A7477679C6E"
+	      "45008DC2774CA2FF64C12C0606FF918CAE3A50115440E9BF2971B627A882A1E8", /* r */
+
+	      "31065479996DDBDEE180AFE22CA3CDC44B45CE4C6C83909D1D3B702922A32441"
+	      "A9E11DCFBEA3D847C06B1A8A38EB1671D6C82FA21B79C99BE2EA809B10DAA5DF"); /* s */
+
+  test_gostdsa (nettle_get_gc512b(),
+	      "07134627CE7FC6770953ABA4714B38AF8DE764B8870A502C2F4CC2D05541459A"
+	      "18DA3B9D4EBC09BC06CB2EA1856A03747561CF04C34382111539230A550F1913", /* x */
+
+	      "7E08A434CB2FA300F8974E3FF69A4BCDF36B6308E1D7A56144693A35E11CBD14"
+	      "D502916E680E35FE1E6ABBA85BD4DAE7065308B16B1CCABFE3D91CE0655B0FFD", /* y */
+
+	      SHEX("EDC257BED45FDDE4F1457B7F5B19017A8F204184366689D938532CDBAA5CB29A"
+		   "1D369DA57F8B983BE272219BD2C9A4FC57ECF7A77F34EE2E8AA553976A4766C0"), /* h */
+
+	      "5DBF2F4C2D6A7705880FB1458CC58335065BEA5621FC9FBC176C4ACA5BC1E672"
+	      "25459A8EA3779434590DC872704029365A83A53B5EB3C06936B5D287E0A983E7", /* r */
+
+	      "4E6D2EE8A693D35F31F2551D43B4F6BC6F9EE7B9D27323873386C7DE5F91C39E"
+	      "D3AAE39B7D07FA92B3C742E9E1B16E11D9F7308E485B715987668346AEF1723D"); /* s */
+}
diff --git a/testsuite/testutils.h b/testsuite/testutils.h
index f4ea38da9deb..cef7f4011a7c 100644
--- a/testsuite/testutils.h
+++ b/testsuite/testutils.h
@@ -22,6 +22,7 @@
 # include "ecc.h"
 # include "ecc-internal.h"
 # include "ecdsa.h"
+# include "gostdsa.h"
 # include "gmp-glue.h"
 # if NETTLE_USE_MINI_GMP
 #  include "knuth-lfib.h"
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200110223451</emailId><senderName>Dmitry Eremin-Solenikov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-01-10 22:34:51-0400</timestampReceived><subject>Re: [PATCH v3 2/3] ecc: prefix optimized ECC function names with underscore</subject><body>

пт, 10 янв. 2020 г. в 23:01, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt;
&gt; Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt; writes:
&gt;
&gt; &gt; So did I at the time of writing a patch, finding no actual users of
&gt; &gt; these functions. I think it is fine to drop them without bumping
&gt; &gt; soname.
&gt;
&gt; It seems none disagrees with that. I've merged all three patches to the
&gt; master-updates branch for testing.

Thank you!

-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200111093612</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-11 09:36:12-0400</timestampReceived><subject>Re: [PATCH 1/3] Change ecc_mod_*mul_1 to be per-module callbacks</subject><body>

dbaryshkov@gmail.com writes:

&gt; GOST curves will require different "fixups" for fast (mul X mod p)
&gt; operations. Move these operations to ecc_modulo structure and call them
&gt; via function pointer.

Can you explain what methods you intend to use? I had a quick look at
the prime definitions in the next patch,

+  else if (!strcmp (curve, "gc256b"))
+    {
+      ecc_curve_init_str (ecc, ECC_TYPE_WEIERSTRASS,
+			  "ffffffffffffffffffffffffffffffff"
+			  "fffffffffffffffffffffffffffffd97",

Should work fine with the current functions.

+  else if (!strcmp (curve, "gc256c"))
+    {
+      ecc_curve_init_str (ecc, ECC_TYPE_WEIERSTRASS,
+			  "80000000000000000000000000000000"
+			  "00000000000000000000000000000c99",

Could use special tricks. Structure is similar to the q for curve25519.

+  else if (!strcmp (curve, "gc256d"))
+    {
+      ecc_curve_init_str (ecc, ECC_TYPE_WEIERSTRASS,
+			  "9b9f605f5a858107ab1ec85e6b41c8aa"
+			  "cf846e86789051d37998f7b9022d759b",

This has no visible structure. One could maybe use some variant of the
3/2 division in https://gmplib.org/~tege/division-paper.pdf to find a
good enough quotient, and divide without any bignum adjustment step. The
result should then be a non-canonical remainder, in the range 0 &lt;= r &lt;
2^256. Everything needs to be side-channel silent.

Another option is to premultiply, and do computations mod k p for some
smallish k. With k = 0x1a51f176161f1d734 (same as the 3/2 reciprocal, I
think),

k p =
ffffffffffffffffd8e5627c0706fb8dc4f73162b7fca65ab59cdb66ec652b2787ac757f10ec107c

with friendly structure (but one word larger). I think this trick is
known as Svoboda division. But for the main operations, it is likely
more efficient to use plain unstructured redc, precomputing p^{-1} mod B
(where B is word size, 2^32 or 2^64 depending on architecture).

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200111093936</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-11 09:39:36-0400</timestampReceived><subject>Re: [PATCH 2/3] Add several GOST R 34.10 curves defined by RFC 4357 and RFC 7836</subject><body>

dbaryshkov@gmail.com writes:

&gt; From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;
&gt;
&gt; Add three 256-bit curves from RFC 4357 (Section 11.4) and two 512-bit
&gt; curves from RFC 7836 (Section A.1).

To easy review, please do one patch or merge-request per curve. We can
do the easiest ones first, which I think are gc256b and gc512a.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200106221644</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-01-06 22:16:44-0400</timestampReceived><subject>[PATCH v3 2/3] ecc: prefix optimized ECC function names with underscore</subject><body>

From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;

There is no need to keep optimized ECC functions in public namespace
(nettle_*), move them to internal namespace (_nettle_*).

Signed-off-by: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;
---
 arm/ecc-secp192r1-modp.asm     | 4 ++--
 arm/ecc-secp224r1-modp.asm     | 4 ++--
 arm/ecc-secp256r1-redc.asm     | 4 ++--
 arm/ecc-secp384r1-modp.asm     | 4 ++--
 arm/ecc-secp521r1-modp.asm     | 4 ++--
 ecc-curve25519.c               | 2 +-
 ecc-curve448.c                 | 2 +-
 ecc-secp192r1.c                | 2 +-
 ecc-secp224r1.c                | 2 +-
 ecc-secp256r1.c                | 2 +-
 ecc-secp384r1.c                | 2 +-
 ecc-secp521r1.c                | 2 +-
 x86_64/ecc-curve25519-modp.asm | 4 ++--
 x86_64/ecc-curve448-modp.asm   | 4 ++--
 x86_64/ecc-secp192r1-modp.asm  | 4 ++--
 x86_64/ecc-secp224r1-modp.asm  | 4 ++--
 x86_64/ecc-secp256r1-redc.asm  | 4 ++--
 x86_64/ecc-secp384r1-modp.asm  | 4 ++--
 x86_64/ecc-secp521r1-modp.asm  | 4 ++--
 19 files changed, 31 insertions(+), 31 deletions(-)

diff --git a/arm/ecc-secp192r1-modp.asm b/arm/ecc-secp192r1-modp.asm
index dbaae2e38922..4680336f1bc7 100644
--- a/arm/ecc-secp192r1-modp.asm
+++ b/arm/ecc-secp192r1-modp.asm
@@ -53,7 +53,7 @@ define(&lt;C4&gt;, &lt;r12&gt;)
 	.text
 	.align 2
 
-PROLOGUE(nettle_ecc_192_modp)
+PROLOGUE(_nettle_ecc_192_modp)
 	push	{r4,r5,r6,r7,r8,r10}
 	C Reduce two words at a time
 	add	HP, RP, #48
@@ -103,4 +103,4 @@ PROLOGUE(nettle_ecc_192_modp)
 
 	pop	{r4,r5,r6,r7,r8,r10}
 	bx	lr
-EPILOGUE(nettle_ecc_192_modp)
+EPILOGUE(_nettle_ecc_192_modp)
diff --git a/arm/ecc-secp224r1-modp.asm b/arm/ecc-secp224r1-modp.asm
index 2c86755a7c9a..400b7a815c2c 100644
--- a/arm/ecc-secp224r1-modp.asm
+++ b/arm/ecc-secp224r1-modp.asm
@@ -52,7 +52,7 @@ define(&lt;L2&gt;, &lt;lr&gt;)
 	.text
 	.align 2
 
-PROLOGUE(nettle_ecc_224_modp)
+PROLOGUE(_nettle_ecc_224_modp)
 	push	{r4,r5,r6,r7,r8,r10,r11,lr}
 
 	add	L2, RP, #28
@@ -121,4 +121,4 @@ PROLOGUE(nettle_ecc_224_modp)
 	stmdb	RP, {T0,T1,T2,T3,T4,T5,T6}
 
 	pop	{r4,r5,r6,r7,r8,r10,r11,pc}
-EPILOGUE(nettle_ecc_224_modp)
+EPILOGUE(_nettle_ecc_224_modp)
diff --git a/arm/ecc-secp256r1-redc.asm b/arm/ecc-secp256r1-redc.asm
index 9c20062a44e4..7b117de43fbc 100644
--- a/arm/ecc-secp256r1-redc.asm
+++ b/arm/ecc-secp256r1-redc.asm
@@ -52,7 +52,7 @@ define(&lt;F3&gt;, &lt;lr&gt;)
 	.text
 	.align 2
 
-PROLOGUE(nettle_ecc_256_redc)
+PROLOGUE(_nettle_ecc_256_redc)
 	push	{r4,r5,r6,r7,r8,r10,r11,lr}
 
 	ldm	RP!, {T0,T1,T2,T3,T4,T5,T6,T7}
@@ -170,4 +170,4 @@ PROLOGUE(nettle_ecc_256_redc)
 	stm	RP, {T0,T1,T2,T3,T4,T5,T6,T7}
 
 	pop	{r4,r5,r6,r7,r8,r10,r11,pc}
-EPILOGUE(nettle_ecc_256_redc)
+EPILOGUE(_nettle_ecc_256_redc)
diff --git a/arm/ecc-secp384r1-modp.asm b/arm/ecc-secp384r1-modp.asm
index dbedbdf8d32e..dd9a325b09de 100644
--- a/arm/ecc-secp384r1-modp.asm
+++ b/arm/ecc-secp384r1-modp.asm
@@ -50,7 +50,7 @@ define(&lt;H&gt;, &lt;lr&gt;)
 	.text
 	.align 2
 
-PROLOGUE(nettle_ecc_384_modp)
+PROLOGUE(_nettle_ecc_384_modp)
 	push	{r4,r5,r6,r7,r8,r10,lr}
 
 	add	RP, RP, #80
@@ -267,4 +267,4 @@ PROLOGUE(nettle_ecc_384_modp)
 	adcs	T3, T3, H
 	stm	RP!, {T0,T1,T2,T3}	C 8-11
 	pop	{r4,r5,r6,r7,r8,r10,pc}
-EPILOGUE(nettle_ecc_384_modp)
+EPILOGUE(_nettle_ecc_384_modp)
diff --git a/arm/ecc-secp521r1-modp.asm b/arm/ecc-secp521r1-modp.asm
index 2b4f79192a2e..f11967634689 100644
--- a/arm/ecc-secp521r1-modp.asm
+++ b/arm/ecc-secp521r1-modp.asm
@@ -52,7 +52,7 @@ define(&lt;N&gt;, &lt;lr&gt;)
 
 	.align 2
 
-PROLOGUE(nettle_ecc_521_modp)
+PROLOGUE(_nettle_ecc_521_modp)
 	push	{r4,r5,r6,r7,r8,lr}
 
 	C Use that B^17 = 2^23 (mod p)
@@ -124,4 +124,4 @@ PROLOGUE(nettle_ecc_521_modp)
 	stm	RP, {T0,T1,T2,F0,F1,F2,F3,H}	C 9-16
 
 	pop	{r4,r5,r6,r7,r8,pc}
-EPILOGUE(nettle_ecc_521_modp)
+EPILOGUE(_nettle_ecc_521_modp)
diff --git a/ecc-curve25519.c b/ecc-curve25519.c
index 73d72765dce8..65843a57ee5a 100644
--- a/ecc-curve25519.c
+++ b/ecc-curve25519.c
@@ -48,7 +48,7 @@
 
 #if HAVE_NATIVE_ecc_25519_modp
 
-#define ecc_25519_modp nettle_ecc_25519_modp
+#define ecc_25519_modp _nettle_ecc_25519_modp
 void
 ecc_25519_modp (const struct ecc_modulo *m, mp_limb_t *rp);
 #else
diff --git a/ecc-curve448.c b/ecc-curve448.c
index 7020e3e8f6aa..981dc53f279e 100644
--- a/ecc-curve448.c
+++ b/ecc-curve448.c
@@ -46,7 +46,7 @@
 #include "ecc-curve448.h"
 
 #if HAVE_NATIVE_ecc_curve448_modp
-#define ecc_448_modp nettle_ecc_curve448_modp
+#define ecc_448_modp _nettle_ecc_curve448_modp
 void
 ecc_448_modp (const struct ecc_modulo *m, mp_limb_t *rp);
 #elif GMP_NUMB_BITS == 64
diff --git a/ecc-secp192r1.c b/ecc-secp192r1.c
index 858a1b7554ce..15f5f1fa4c04 100644
--- a/ecc-secp192r1.c
+++ b/ecc-secp192r1.c
@@ -50,7 +50,7 @@
 
 #if HAVE_NATIVE_ecc_192_modp
 
-#define ecc_192_modp nettle_ecc_192_modp
+#define ecc_192_modp _nettle_ecc_192_modp
 void
 ecc_192_modp (const struct ecc_modulo *m, mp_limb_t *rp);
 
diff --git a/ecc-secp224r1.c b/ecc-secp224r1.c
index 4d82f54b57fd..28b938fa3282 100644
--- a/ecc-secp224r1.c
+++ b/ecc-secp224r1.c
@@ -43,7 +43,7 @@
 #if HAVE_NATIVE_ecc_224_modp
 
 #define USE_REDC 0
-#define ecc_224_modp nettle_ecc_224_modp
+#define ecc_224_modp _nettle_ecc_224_modp
 void
 ecc_224_modp (const struct ecc_modulo *m, mp_limb_t *rp);
 
diff --git a/ecc-secp256r1.c b/ecc-secp256r1.c
index 835c91d30239..160a047957f8 100644
--- a/ecc-secp256r1.c
+++ b/ecc-secp256r1.c
@@ -51,7 +51,7 @@
 #include "ecc-secp256r1.h"
 
 #if HAVE_NATIVE_ecc_256_redc
-# define ecc_256_redc nettle_ecc_256_redc
+# define ecc_256_redc _nettle_ecc_256_redc
 void
 ecc_256_redc (const struct ecc_modulo *p, mp_limb_t *rp);
 #else /* !HAVE_NATIVE_ecc_256_redc */
diff --git a/ecc-secp384r1.c b/ecc-secp384r1.c
index 248b1cf3ef2b..32f75fb618ba 100644
--- a/ecc-secp384r1.c
+++ b/ecc-secp384r1.c
@@ -47,7 +47,7 @@
 #include "ecc-secp384r1.h"
 
 #if HAVE_NATIVE_ecc_384_modp
-#define ecc_384_modp nettle_ecc_384_modp
+#define ecc_384_modp _nettle_ecc_384_modp
 void
 ecc_384_modp (const struct ecc_modulo *m, mp_limb_t *rp);
 #elif GMP_NUMB_BITS == 32
diff --git a/ecc-secp521r1.c b/ecc-secp521r1.c
index cc7473035cff..d952d77e444e 100644
--- a/ecc-secp521r1.c
+++ b/ecc-secp521r1.c
@@ -45,7 +45,7 @@
 #include "ecc-secp521r1.h"
 
 #if HAVE_NATIVE_ecc_521_modp
-#define ecc_521_modp nettle_ecc_521_modp
+#define ecc_521_modp _nettle_ecc_521_modp
 void
 ecc_521_modp (const struct ecc_modulo *m, mp_limb_t *rp);
 
diff --git a/x86_64/ecc-curve25519-modp.asm b/x86_64/ecc-curve25519-modp.asm
index 58c14fe0958e..0374db12ab44 100644
--- a/x86_64/ecc-curve25519-modp.asm
+++ b/x86_64/ecc-curve25519-modp.asm
@@ -41,7 +41,7 @@ define(&lt;T0&gt;, &lt;%r10&gt;)
 define(&lt;T1&gt;, &lt;%r11&gt;)
 define(&lt;M&gt;, &lt;%rbx&gt;)
 
-PROLOGUE(nettle_ecc_25519_modp)
+PROLOGUE(_nettle_ecc_25519_modp)
 	W64_ENTRY(2, 0)
 	push	%rbx
 
@@ -91,4 +91,4 @@ PROLOGUE(nettle_ecc_25519_modp)
 	pop	%rbx
 	W64_EXIT(2, 0)
 	ret
-EPILOGUE(nettle_ecc_25519_modp)
+EPILOGUE(_nettle_ecc_25519_modp)
diff --git a/x86_64/ecc-curve448-modp.asm b/x86_64/ecc-curve448-modp.asm
index 1ca05a190e1a..ea2e78861bc5 100644
--- a/x86_64/ecc-curve448-modp.asm
+++ b/x86_64/ecc-curve448-modp.asm
@@ -45,7 +45,7 @@ define(&lt;T0&gt;, &lt;%r10&gt;)
 define(&lt;T1&gt;, &lt;%r11&gt;)
 define(&lt;T2&gt;, &lt;%r12&gt;)
 
-PROLOGUE(nettle_ecc_curve448_modp)
+PROLOGUE(_nettle_ecc_curve448_modp)
 	W64_ENTRY(2, 0)
 
 	push	%rbx
@@ -141,4 +141,4 @@ PROLOGUE(nettle_ecc_curve448_modp)
 
 	W64_EXIT(2, 0)
 	ret
-EPILOGUE(nettle_ecc_curve448_modp)
+EPILOGUE(_nettle_ecc_curve448_modp)
diff --git a/x86_64/ecc-secp192r1-modp.asm b/x86_64/ecc-secp192r1-modp.asm
index 644ed60c6fab..ad8dca7186e4 100644
--- a/x86_64/ecc-secp192r1-modp.asm
+++ b/x86_64/ecc-secp192r1-modp.asm
@@ -44,7 +44,7 @@ define(&lt;C2&gt;, &lt;%r11&gt;)
 	C ecc_192_modp (const struct ecc_modulo *m, mp_limb_t *rp)
 	.text
 	ALIGN(16)
-PROLOGUE(nettle_ecc_192_modp)
+PROLOGUE(_nettle_ecc_192_modp)
 	W64_ENTRY(2, 0)
 	mov	16(RP), T2
 	mov	24(RP), T3
@@ -85,4 +85,4 @@ PROLOGUE(nettle_ecc_192_modp)
 
 	W64_EXIT(2, 0)
 	ret
-EPILOGUE(nettle_ecc_192_modp)
+EPILOGUE(_nettle_ecc_192_modp)
diff --git a/x86_64/ecc-secp224r1-modp.asm b/x86_64/ecc-secp224r1-modp.asm
index ca164ac7d637..e44b5418e5dd 100644
--- a/x86_64/ecc-secp224r1-modp.asm
+++ b/x86_64/ecc-secp224r1-modp.asm
@@ -45,7 +45,7 @@ define(&lt;F1&gt;, &lt;%r10&gt;)
 define(&lt;F2&gt;, &lt;%r11&gt;)
 
 	C ecc_224_modp (const struct ecc_modulo *m, mp_limb_t *rp)
-PROLOGUE(nettle_ecc_224_modp)
+PROLOGUE(_nettle_ecc_224_modp)
 	W64_ENTRY(2, 0)
 	mov	48(RP), H0
 	mov	56(RP), H1
@@ -128,4 +128,4 @@ PROLOGUE(nettle_ecc_224_modp)
 
 	W64_EXIT(2, 0)
 	ret
-EPILOGUE(nettle_ecc_224_modp)
+EPILOGUE(_nettle_ecc_224_modp)
diff --git a/x86_64/ecc-secp256r1-redc.asm b/x86_64/ecc-secp256r1-redc.asm
index ee689cd6d192..533a1766d4bc 100644
--- a/x86_64/ecc-secp256r1-redc.asm
+++ b/x86_64/ecc-secp256r1-redc.asm
@@ -58,7 +58,7 @@ define(&lt;FOLD&gt;, &lt;
 	sbb	$1, F2
 	sbb	&lt;$&gt;0, F3
 &gt;)
-PROLOGUE(nettle_ecc_256_redc)
+PROLOGUE(_nettle_ecc_256_redc)
 	W64_ENTRY(2, 0)
 	C save all registers that need to be saved
 	push	%rbx
@@ -126,4 +126,4 @@ PROLOGUE(nettle_ecc_256_redc)
 	pop	%rbx
 	W64_EXIT(2, 0)
 	ret
-EPILOGUE(nettle_ecc_256_redc)
+EPILOGUE(_nettle_ecc_256_redc)
diff --git a/x86_64/ecc-secp384r1-modp.asm b/x86_64/ecc-secp384r1-modp.asm
index 3c8ec3f446c0..13f469b164e4 100644
--- a/x86_64/ecc-secp384r1-modp.asm
+++ b/x86_64/ecc-secp384r1-modp.asm
@@ -51,7 +51,7 @@ define(&lt;C0&gt;, H5)	C Overlap
 define(&lt;TMP&gt;, RP)	C Overlap
 
 
-PROLOGUE(nettle_ecc_384_modp)
+PROLOGUE(_nettle_ecc_384_modp)
 	W64_ENTRY(2, 0)
 
 	push	%rbx
@@ -231,4 +231,4 @@ PROLOGUE(nettle_ecc_384_modp)
 
 	W64_EXIT(2, 0)
 	ret
-EPILOGUE(nettle_ecc_384_modp)
+EPILOGUE(_nettle_ecc_384_modp)
diff --git a/x86_64/ecc-secp521r1-modp.asm b/x86_64/ecc-secp521r1-modp.asm
index 43a8cb8c9cfe..6f4f7d90714d 100644
--- a/x86_64/ecc-secp521r1-modp.asm
+++ b/x86_64/ecc-secp521r1-modp.asm
@@ -48,7 +48,7 @@ define(&lt;U9&gt;, &lt;%r11&gt;)
 define(&lt;T0&gt;, &lt;%r12&gt;)
 define(&lt;T1&gt;, &lt;%r13&gt;)
 
-PROLOGUE(nettle_ecc_521_modp)
+PROLOGUE(_nettle_ecc_521_modp)
 	W64_ENTRY(2, 0)
 	push	%rbx
 	push	%rbp
@@ -155,4 +155,4 @@ PROLOGUE(nettle_ecc_521_modp)
 	pop	%rbx
 	W64_EXIT(2, 0)
 	ret
-EPILOGUE(nettle_ecc_521_modp)
+EPILOGUE(_nettle_ecc_521_modp)
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200110223407</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-01-10 22:34:07-0400</timestampReceived><subject>[PATCH 1/3] Change ecc_mod_*mul_1 to be per-module callbacks</subject><body>

From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;

GOST curves will require different "fixups" for fast (mul X mod p)
operations. Move these operations to ecc_modulo structure and call them
via function pointer.

Signed-off-by: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;
---
 ecc-curve25519.c |  8 ++++++++
 ecc-curve448.c   |  8 ++++++++
 ecc-internal.h   | 32 ++++++++++++++++++++------------
 ecc-mod-arith.c  | 12 ++++++------
 ecc-mul-m.c      |  6 +++---
 ecc-secp192r1.c  |  8 ++++++++
 ecc-secp224r1.c  |  8 ++++++++
 ecc-secp256r1.c  |  8 ++++++++
 ecc-secp384r1.c  |  8 ++++++++
 ecc-secp521r1.c  |  8 ++++++++
 10 files changed, 85 insertions(+), 21 deletions(-)

diff --git a/ecc-curve25519.c b/ecc-curve25519.c
index 0ad3017c9ebc..4ee80c8d4463 100644
--- a/ecc-curve25519.c
+++ b/ecc-curve25519.c
@@ -310,6 +310,10 @@ const struct ecc_curve _nettle_curve25519 =
     ecc_curve25519_modp,
     ecc_curve25519_inv,
     ecc_curve25519_sqrt,
+
+    ecc_mod_mul_1_std,
+    ecc_mod_addmul_1_std,
+    ecc_mod_submul_1_std,
   },
   {
     253,
@@ -329,6 +333,10 @@ const struct ecc_curve _nettle_curve25519 =
     ecc_curve25519_modq,
     ecc_mod_inv,
     NULL,
+
+    NULL,
+    NULL,
+    NULL,
   },
 
   0, /* No redc */
diff --git a/ecc-curve448.c b/ecc-curve448.c
index c31a0eb26ba4..71634b855af8 100644
--- a/ecc-curve448.c
+++ b/ecc-curve448.c
@@ -288,6 +288,10 @@ const struct ecc_curve _nettle_curve448 =
     ecc_curve448_modp,
     ecc_curve448_inv,
     ecc_curve448_sqrt,
+
+    ecc_mod_mul_1_std,
+    ecc_mod_addmul_1_std,
+    ecc_mod_submul_1_std,
   },
   {
     446,
@@ -307,6 +311,10 @@ const struct ecc_curve _nettle_curve448 =
     ecc_mod,	      /* FIXME: Implement optimized reduce function */
     ecc_mod_inv,
     NULL,
+
+    NULL,
+    NULL,
+    NULL,
   },
 
   0, /* No redc */
diff --git a/ecc-internal.h b/ecc-internal.h
index c918632df292..105b67b2990e 100644
--- a/ecc-internal.h
+++ b/ecc-internal.h
@@ -44,9 +44,9 @@
 #define ecc_pm1_redc _nettle_ecc_pm1_redc
 #define ecc_mod_add _nettle_ecc_mod_add
 #define ecc_mod_sub _nettle_ecc_mod_sub
-#define ecc_mod_mul_1 _nettle_ecc_mod_mul_1
-#define ecc_mod_addmul_1 _nettle_ecc_mod_addmul_1
-#define ecc_mod_submul_1 _nettle_ecc_mod_submul_1
+#define ecc_mod_mul_1_std _nettle_ecc_mod_mul_1_std
+#define ecc_mod_addmul_1_std _nettle_ecc_mod_addmul_1_std
+#define ecc_mod_submul_1_std _nettle_ecc_mod_submul_1_std
 #define ecc_mod_mul _nettle_ecc_mod_mul
 #define ecc_mod_sqr _nettle_ecc_mod_sqr
 #define ecc_mod_random _nettle_ecc_mod_random
@@ -141,6 +141,10 @@ typedef void ecc_h_to_a_func (const struct ecc_curve *ecc,
 			      mp_limb_t *r, const mp_limb_t *p,
 			      mp_limb_t *scratch);
 
+typedef void ecc_mod_mul_1_func (const struct ecc_modulo *m,
+				 mp_limb_t *rp,
+				 const mp_limb_t *ap, mp_limb_t b);
+
 struct ecc_modulo
 {
   unsigned short bit_size;
@@ -165,6 +169,10 @@ struct ecc_modulo
   ecc_mod_func *reduce;
   ecc_mod_inv_func *invert;
   ecc_mod_sqrt_func *sqrt;
+
+  ecc_mod_mul_1_func *mul_1;
+  ecc_mod_mul_1_func *addmul_1;
+  ecc_mod_mul_1_func *submul_1;
 };
 
 /* Represents an elliptic curve of the form
@@ -235,15 +243,15 @@ ecc_mod_sub (const struct ecc_modulo *m, mp_limb_t *rp,
 	     const mp_limb_t *ap, const mp_limb_t *bp);
 
 void
-ecc_mod_mul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
-	       const mp_limb_t *ap, const mp_limb_t b);
+ecc_mod_mul_1_std (const struct ecc_modulo *m, mp_limb_t *rp,
+		   const mp_limb_t *ap, const mp_limb_t b);
 
 void
-ecc_mod_addmul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
-		  const mp_limb_t *ap, mp_limb_t b);
+ecc_mod_addmul_1_std (const struct ecc_modulo *m, mp_limb_t *rp,
+		      const mp_limb_t *ap, mp_limb_t b);
 void
-ecc_mod_submul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
-		  const mp_limb_t *ap, mp_limb_t b);
+ecc_mod_submul_1_std (const struct ecc_modulo *m, mp_limb_t *rp,
+		      const mp_limb_t *ap, mp_limb_t b);
 
 /* The mul and sqr functions need 2*m-&gt;size limbs at rp */
 void
@@ -259,11 +267,11 @@ ecc_mod_sqr (const struct ecc_modulo *m, mp_limb_t *rp,
 #define ecc_modp_sub(ecc, r, a, b) \
   ecc_mod_sub (&amp;(ecc)-&gt;p, (r), (a), (b))
 #define ecc_modp_mul_1(ecc, r, a, b) \
-  ecc_mod_mul_1 (&amp;(ecc)-&gt;p, (r), (a), (b))
+  (ecc)-&gt;p.mul_1 (&amp;(ecc)-&gt;p, (r), (a), (b))
 #define ecc_modp_addmul_1(ecc, r, a, b) \
-  ecc_mod_addmul_1 (&amp;(ecc)-&gt;p, (r), (a), (b))
+  (ecc)-&gt;p.addmul_1 (&amp;(ecc)-&gt;p, (r), (a), (b))
 #define ecc_modp_submul_1(ecc, r, a, b) \
-  ecc_mod_submul_1 (&amp;(ecc)-&gt;p, (r), (a), (b))
+  (ecc)-&gt;p.submul_1 (&amp;(ecc)-&gt;p, (r), (a), (b))
 #define ecc_modp_mul(ecc, r, a, b) \
   ecc_mod_mul (&amp;(ecc)-&gt;p, (r), (a), (b))
 #define ecc_modp_sqr(ecc, r, a) \
diff --git a/ecc-mod-arith.c b/ecc-mod-arith.c
index f2e47f6747c1..0399a2cdd7c5 100644
--- a/ecc-mod-arith.c
+++ b/ecc-mod-arith.c
@@ -65,8 +65,8 @@ ecc_mod_sub (const struct ecc_modulo *m, mp_limb_t *rp,
 }
 
 void
-ecc_mod_mul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
-	       const mp_limb_t *ap, mp_limb_t b)
+ecc_mod_mul_1_std (const struct ecc_modulo *m, mp_limb_t *rp,
+		   const mp_limb_t *ap, mp_limb_t b)
 {
   mp_limb_t hi;
 
@@ -80,8 +80,8 @@ ecc_mod_mul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
 }
 
 void
-ecc_mod_addmul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
-		  const mp_limb_t *ap, mp_limb_t b)
+ecc_mod_addmul_1_std (const struct ecc_modulo *m, mp_limb_t *rp,
+		      const mp_limb_t *ap, mp_limb_t b)
 {
   mp_limb_t hi;
 
@@ -95,8 +95,8 @@ ecc_mod_addmul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
 }
   
 void
-ecc_mod_submul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
-		  const mp_limb_t *ap, mp_limb_t b)
+ecc_mod_submul_1_std (const struct ecc_modulo *m, mp_limb_t *rp,
+		      const mp_limb_t *ap, mp_limb_t b)
 {
   mp_limb_t hi;
 
diff --git a/ecc-mul-m.c b/ecc-mul-m.c
index 68bdd16e8e94..770350162da1 100644
--- a/ecc-mul-m.c
+++ b/ecc-mul-m.c
@@ -80,7 +80,7 @@ ecc_mul_m (const struct ecc_modulo *m,
   ecc_mod_sqr (m, BB, B);
   ecc_mod_mul (m, x3, AA, BB);
   ecc_mod_sub (m, E, AA, BB);
-  ecc_mod_addmul_1 (m, AA, E, a24);
+  m-&gt;addmul_1 (m, AA, E, a24);
   ecc_mod_mul (m, z3, E, AA);
 
   for (i = bit_high; i &gt;= bit_low; i--)
@@ -98,7 +98,7 @@ ecc_mul_m (const struct ecc_modulo *m,
       ecc_mod_sqr (m, BB, B);
       ecc_mod_mul (m, x2, AA, BB); /* Last use of BB */
       ecc_mod_sub (m, E, AA, BB);
-      ecc_mod_addmul_1 (m, AA, E, a24);
+      m-&gt;addmul_1 (m, AA, E, a24);
       ecc_mod_add (m, C, x3, z3);
       ecc_mod_sub (m, D, x3, z3);
       ecc_mod_mul (m, z2, E, AA); /* Last use of E and AA */
@@ -124,7 +124,7 @@ ecc_mul_m (const struct ecc_modulo *m,
       ecc_mod_sqr (m, BB, B);
       ecc_mod_mul (m, x2, AA, BB);
       ecc_mod_sub (m, E, AA, BB);
-      ecc_mod_addmul_1 (m, AA, E, a24);
+      m-&gt;addmul_1 (m, AA, E, a24);
       ecc_mod_mul (m, z2, E, AA);
     }
   assert (m-&gt;invert_itch &lt;= 7 * m-&gt;size);
diff --git a/ecc-secp192r1.c b/ecc-secp192r1.c
index 094074d73ed7..d36be63d7b3a 100644
--- a/ecc-secp192r1.c
+++ b/ecc-secp192r1.c
@@ -130,6 +130,10 @@ const struct ecc_curve _nettle_secp_192r1 =
     ecc_secp192r1_modp,
     ecc_mod_inv,
     NULL,
+
+    ecc_mod_mul_1_std,
+    ecc_mod_addmul_1_std,
+    ecc_mod_submul_1_std,
   },
   {
     192,
@@ -149,6 +153,10 @@ const struct ecc_curve _nettle_secp_192r1 =
     ecc_mod,
     ecc_mod_inv,
     NULL,
+
+    NULL,
+    NULL,
+    NULL,
   },
   
   USE_REDC,
diff --git a/ecc-secp224r1.c b/ecc-secp224r1.c
index e6b43fa61f42..cde02a01fd6d 100644
--- a/ecc-secp224r1.c
+++ b/ecc-secp224r1.c
@@ -82,6 +82,10 @@ const struct ecc_curve _nettle_secp_224r1 =
     USE_REDC ? ecc_secp224r1_redc : ecc_secp224r1_modp,
     ecc_mod_inv,
     NULL,
+
+    ecc_mod_mul_1_std,
+    ecc_mod_addmul_1_std,
+    ecc_mod_submul_1_std,
   },
   {
     224,
@@ -101,6 +105,10 @@ const struct ecc_curve _nettle_secp_224r1 =
     ecc_mod,
     ecc_mod_inv,
     NULL,
+
+    NULL,
+    NULL,
+    NULL,
   },
   
   USE_REDC,
diff --git a/ecc-secp256r1.c b/ecc-secp256r1.c
index 6c776a729aea..e17061ab761c 100644
--- a/ecc-secp256r1.c
+++ b/ecc-secp256r1.c
@@ -259,6 +259,10 @@ const struct ecc_curve _nettle_secp_256r1 =
     USE_REDC ? ecc_secp256r1_redc : ecc_secp256r1_modp,
     ecc_mod_inv,
     NULL,
+
+    ecc_mod_mul_1_std,
+    ecc_mod_addmul_1_std,
+    ecc_mod_submul_1_std,
   },
   {
     256,
@@ -278,6 +282,10 @@ const struct ecc_curve _nettle_secp_256r1 =
     ecc_secp256r1_modq,
     ecc_mod_inv,
     NULL,
+
+    NULL,
+    NULL,
+    NULL,
   },
 
   USE_REDC,
diff --git a/ecc-secp384r1.c b/ecc-secp384r1.c
index c4a75564bf58..cf0cd25e32fb 100644
--- a/ecc-secp384r1.c
+++ b/ecc-secp384r1.c
@@ -167,6 +167,10 @@ const struct ecc_curve _nettle_secp_384r1 =
     ecc_secp384r1_modp,
     ecc_mod_inv,
     NULL,
+
+    ecc_mod_mul_1_std,
+    ecc_mod_addmul_1_std,
+    ecc_mod_submul_1_std,
   },
   {
     384,
@@ -186,6 +190,10 @@ const struct ecc_curve _nettle_secp_384r1 =
     ecc_mod,
     ecc_mod_inv,
     NULL,
+
+    NULL,
+    NULL,
+    NULL,
   },
 
   USE_REDC,
diff --git a/ecc-secp521r1.c b/ecc-secp521r1.c
index 74688008959b..2241e542f927 100644
--- a/ecc-secp521r1.c
+++ b/ecc-secp521r1.c
@@ -95,6 +95,10 @@ const struct ecc_curve _nettle_secp_521r1 =
     ecc_secp521r1_modp,
     ecc_mod_inv,
     NULL,
+
+    ecc_mod_mul_1_std,
+    ecc_mod_addmul_1_std,
+    ecc_mod_submul_1_std,
   },
   {
     521,
@@ -114,6 +118,10 @@ const struct ecc_curve _nettle_secp_521r1 =
     ecc_mod,
     ecc_mod_inv,
     NULL,
+
+    NULL,
+    NULL,
+    NULL,
   },
   
   USE_REDC,
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200110223408</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-01-10 22:34:08-0400</timestampReceived><subject>[PATCH 2/3] Add several GOST R 34.10 curves defined by RFC 4357 and RFC 7836</subject><body>

From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;

Add three 256-bit curves from RFC 4357 (Section 11.4) and two 512-bit
curves from RFC 7836 (Section A.1).

Curves are named accrording to the "TLS Supported Groups" registry.

Signed-off-by: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;
---
 .gitignore               |   5 +
 Makefile.in              |  49 +++++++++
 ecc-curve.h              |   5 +
 ecc-gc256b.c             | 148 +++++++++++++++++++++++++++
 ecc-gc256c.c             | 210 +++++++++++++++++++++++++++++++++++++++
 ecc-gc256d.c             | 184 ++++++++++++++++++++++++++++++++++
 ecc-gc512a.c             | 148 +++++++++++++++++++++++++++
 ecc-gc512b.c             | 204 +++++++++++++++++++++++++++++++++++++
 ecc-internal.h           |   7 ++
 eccdata.c                | 174 +++++++++++++++++++++++++++++++-
 examples/ecc-benchmark.c |   5 +
 testsuite/testutils.c    |  56 ++++++++++-
 12 files changed, 1192 insertions(+), 3 deletions(-)
 create mode 100644 ecc-gc256b.c
 create mode 100644 ecc-gc256c.c
 create mode 100644 ecc-gc256d.c
 create mode 100644 ecc-gc512a.c
 create mode 100644 ecc-gc512b.c

diff --git a/.gitignore b/.gitignore
index ea264107fa40..a0642b1b6c2f 100644
--- a/.gitignore
+++ b/.gitignore
@@ -45,6 +45,11 @@ core
 /rotors.h
 /ecc-curve25519.h
 /ecc-curve448.h
+/ecc-gc256b.h
+/ecc-gc256c.h
+/ecc-gc256d.h
+/ecc-gc512a.h
+/ecc-gc512b.h
 /ecc-secp192r1.h
 /ecc-secp224r1.h
 /ecc-secp256r1.h
diff --git a/Makefile.in b/Makefile.in
index 38160bb40fe1..d9b76d8d5354 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -176,6 +176,8 @@ hogweed_SOURCES = sexp.c sexp-format.c \
 		  ecc-mod.c ecc-mod-inv.c \
 		  ecc-mod-arith.c ecc-pp1-redc.c ecc-pm1-redc.c \
 		  ecc-curve25519.c ecc-curve448.c \
+		  ecc-gc256b.c ecc-gc256c.c ecc-gc256d.c \
+		  ecc-gc512a.c ecc-gc512b.c \
 		  ecc-secp192r1.c ecc-secp224r1.c ecc-secp256r1.c \
 		  ecc-secp384r1.c ecc-secp521r1.c \
 		  ecc-size.c ecc-j-to-a.c ecc-a-to-j.c \
@@ -396,12 +398,57 @@ ecc-curve25519.h: eccdata.stamp
 ecc-curve448.h: eccdata.stamp
 	./eccdata$(EXEEXT_FOR_BUILD) curve448 38 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
 
+# Some reasonable choices for 256:
+# k =  9, c =  6, S = 320, T =  54 ( 45 A +  9 D) 20 KB
+# k = 11, c =  6, S = 256, T =  55 ( 44 A + 11 D) 16 KB
+# k = 19, c =  7, S = 256, T =  57 ( 38 A + 19 D) 16 KB
+# k = 15, c =  6, S = 192, T =  60 ( 45 A + 15 D) 12 KB
+ecc-gc256b.h: eccdata.stamp
+	./eccdata$(EXEEXT_FOR_BUILD) gc256b 11 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
+
+# Some reasonable choices for 256:
+# k =  9, c =  6, S = 320, T =  54 ( 45 A +  9 D) 20 KB
+# k = 11, c =  6, S = 256, T =  55 ( 44 A + 11 D) 16 KB
+# k = 19, c =  7, S = 256, T =  57 ( 38 A + 19 D) 16 KB
+# k = 15, c =  6, S = 192, T =  60 ( 45 A + 15 D) 12 KB
+ecc-gc256c.h: eccdata.stamp
+	./eccdata$(EXEEXT_FOR_BUILD) gc256c 11 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
+
+# Some reasonable choices for 256:
+# k =  9, c =  6, S = 320, T =  54 ( 45 A +  9 D) 20 KB
+# k = 11, c =  6, S = 256, T =  55 ( 44 A + 11 D) 16 KB
+# k = 19, c =  7, S = 256, T =  57 ( 38 A + 19 D) 16 KB
+# k = 15, c =  6, S = 192, T =  60 ( 45 A + 15 D) 12 KB
+ecc-gc256d.h: eccdata.stamp
+	./eccdata$(EXEEXT_FOR_BUILD) gc256d 11 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
+
+# Some reasonable choices for 512:
+# k = 29, c =  6, S = 192, T = 116 ( 87 A + 29 D)
+# k = 21, c =  5, S = 160, T = 126 (105 A + 21 D)
+# k = 43, c =  6, S = 128, T = 129 ( 86 A + 43 D)
+# k = 35, c =  5, S =  96, T = 140 (105 A + 35 D)
+ecc-gc512a.h: eccdata.stamp
+	./eccdata$(EXEEXT_FOR_BUILD) gc512a 43 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
+
+# Some reasonable choices for 512:
+# k = 29, c =  6, S = 192, T = 116 ( 87 A + 29 D)
+# k = 21, c =  5, S = 160, T = 126 (105 A + 21 D)
+# k = 43, c =  6, S = 128, T = 129 ( 86 A + 43 D)
+# k = 35, c =  5, S =  96, T = 140 (105 A + 35 D)
+ecc-gc512b.h: eccdata.stamp
+	./eccdata$(EXEEXT_FOR_BUILD) gc512b 43 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
+
 eccdata.stamp: eccdata.c
 	$(MAKE) eccdata$(EXEEXT_FOR_BUILD)
 	echo stamp &gt; eccdata.stamp
 
 ecc-curve25519.$(OBJEXT): ecc-curve25519.h
 ecc-curve448.$(OBJEXT): ecc-curve448.h
+ecc-gc256b.$(OBJEXT): ecc-gc256b.h
+ecc-gc256c.$(OBJEXT): ecc-gc256c.h
+ecc-gc256d.$(OBJEXT): ecc-gc256d.h
+ecc-gc512a.$(OBJEXT): ecc-gc512a.h
+ecc-gc512b.$(OBJEXT): ecc-gc512b.h
 ecc-secp192r1.$(OBJEXT): ecc-secp192r1.h
 ecc-secp224r1.$(OBJEXT): ecc-secp224r1.h
 ecc-secp256r1.$(OBJEXT): ecc-secp256r1.h
@@ -660,6 +707,8 @@ distcheck: dist
 clean-here:
 	-rm -f $(TARGETS) *.$(OBJEXT) *.s *.so *.dll *.a \
 		ecc-curve25519.h ecc-curve448.h \
+		ecc-gc256b.h ecc-gc256c.h ecc-gc256d.h \
+		ecc-gc512a.h ecc-gc512b.h \
 		ecc-secp192r1.h ecc-secp224r1.h ecc-secp256r1.h \
 		ecc-secp384r1.h ecc-secp521r1.h \
 		aesdata$(EXEEXT_FOR_BUILD) \
diff --git a/ecc-curve.h b/ecc-curve.h
index 76024a19d24f..6a53506ea815 100644
--- a/ecc-curve.h
+++ b/ecc-curve.h
@@ -48,6 +48,11 @@ const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE \
nettle_get_secp_224r1(void);  const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE \
nettle_get_secp_256r1(void);  const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE \
nettle_get_secp_384r1(void);  const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE \
nettle_get_secp_521r1(void); +const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE \
nettle_get_gc256b(void); +const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE \
nettle_get_gc256c(void); +const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE \
nettle_get_gc256d(void); +const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE \
nettle_get_gc512a(void); +const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE \
nettle_get_gc512b(void);  
 #ifdef __cplusplus
 }
diff --git a/ecc-gc256b.c b/ecc-gc256b.c
new file mode 100644
index 000000000000..9fa818d8c330
--- /dev/null
+++ b/ecc-gc256b.c
@@ -0,0 +1,148 @@
+/* ecc-gc256b.c
+
+   Compile time constant (but machine dependent) tables.
+
+   Copyright (C) 2016, 2019 Dmitry Eremin-Solenikov
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+/* Development of Nettle's ECC support was funded by the .SE Internet Fund. */
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+
+#include "ecc.h"
+#include "ecc-internal.h"
+
+#define USE_REDC (ECC_REDC_SIZE != 0)
+
+#include "ecc-gc256b.h"
+
+#if ECC_REDC_SIZE &gt; 0
+#  define ecc_gc256b_redc ecc_pp1_redc
+#elif ECC_REDC_SIZE == 0
+#  define ecc_gc256b_redc NULL
+#else
+# error Configuration error
+#endif
+
+static void
+ecc_gc256b_modp (const struct ecc_modulo *m, mp_limb_t *rp)
+{
+  mp_size_t mn = m-&gt;size;
+  mp_limb_t hi;
+
+  hi = mpn_addmul_1(rp, rp + mn, mn, 0x269);
+  hi = sec_add_1 (rp, rp, mn, hi * 0x269);
+  hi = sec_add_1 (rp, rp, mn, hi * 0x269);
+  assert(hi == 0);
+}
+
+#define ecc_gc256b_modp ecc_gc256b_modp
+#define ecc_gc256b_modq ecc_mod
+
+const struct ecc_curve _nettle_gc256b =
+{
+  {
+    256,
+    ECC_LIMB_SIZE,
+    ECC_BMODP_SIZE,
+    ECC_REDC_SIZE,
+    ECC_MOD_INV_ITCH (ECC_LIMB_SIZE),
+    0,
+
+    ecc_p,
+    ecc_Bmodp,
+    ecc_Bmodp_shifted,
+    ecc_redc_ppm1,
+
+    ecc_pp1h,
+    ecc_gc256b_modp,
+    USE_REDC ? ecc_gc256b_redc : ecc_gc256b_modp,
+    ecc_mod_inv,
+    NULL,
+
+    ecc_mod_mul_1_std,
+    ecc_mod_addmul_1_std,
+    ecc_mod_submul_1_std,
+  },
+  {
+    256,
+    ECC_LIMB_SIZE,
+    ECC_BMODQ_SIZE,
+    0,
+    ECC_MOD_INV_ITCH (ECC_LIMB_SIZE),
+    0,
+
+    ecc_q,
+    ecc_Bmodq,
+    ecc_Bmodq_shifted,
+    NULL,
+    ecc_qp1h,
+
+    ecc_gc256b_modq,
+    ecc_gc256b_modq,
+    ecc_mod_inv,
+    NULL,
+
+    NULL,
+    NULL,
+    NULL,
+  },
+
+  USE_REDC,
+  ECC_PIPPENGER_K,
+  ECC_PIPPENGER_C,
+
+  ECC_ADD_JJA_ITCH (ECC_LIMB_SIZE),
+  ECC_ADD_JJJ_ITCH (ECC_LIMB_SIZE),
+  ECC_DUP_JJ_ITCH (ECC_LIMB_SIZE),
+  ECC_MUL_A_ITCH (ECC_LIMB_SIZE),
+  ECC_MUL_G_ITCH (ECC_LIMB_SIZE),
+  ECC_J_TO_A_ITCH (ECC_LIMB_SIZE),
+
+  ecc_add_jja,
+  ecc_add_jjj,
+  ecc_dup_jj,
+  ecc_mul_a,
+  ecc_mul_g,
+  ecc_j_to_a,
+
+  ecc_b,
+  ecc_g,
+  ecc_unit,
+  ecc_table
+};
+
+const struct ecc_curve *nettle_get_gc256b(void)
+{
+  return &amp;_nettle_gc256b;
+}
diff --git a/ecc-gc256c.c b/ecc-gc256c.c
new file mode 100644
index 000000000000..9feacd32bfa2
--- /dev/null
+++ b/ecc-gc256c.c
@@ -0,0 +1,210 @@
+/* ecc-gc256c.c
+
+   Compile time constant (but machine dependent) tables.
+
+   Copyright (C) 2016, 2019 Dmitry Eremin-Solenikov
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+/* Development of Nettle's ECC support was funded by the .SE Internet Fund. */
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+
+#include "ecc.h"
+#include "ecc-internal.h"
+
+#define USE_REDC (ECC_REDC_SIZE != 0)
+
+#include "ecc-gc256c.h"
+
+#if HAVE_NATIVE_ecc_gc256c_redc
+# define ecc_gc256c_redc nettle_ecc_gc256c_redc
+void
+ecc_gc256c_redc (const struct ecc_modulo *p, mp_limb_t *rp);
+#else /* !HAVE_NATIVE_ecc_gc256c_redc */
+# if ECC_REDC_SIZE &gt; 0
+#   define ecc_gc256c_redc ecc_pp1_redc
+# elif ECC_REDC_SIZE == 0
+#   define ecc_gc256c_redc NULL
+# else
+#  error Configuration error
+# endif
+#endif /* !HAVE_NATIVE_ecc_gc256c_redc */
+
+static void
+ecc_gc256c_modp (const struct ecc_modulo *m, mp_limb_t *rp)
+{
+  mp_size_t mn = m-&gt;size;
+  mp_limb_t hi;
+
+  hi = mpn_submul_1(rp, rp + mn, mn, 0xc99 * 2);
+  hi = sec_add_1 (rp, rp, mn, hi * 0xc99 * 2);
+  hi = sec_sub_1 (rp, rp, mn, hi * 0xc99 * 2);
+  assert(hi &lt;= 1);
+  hi = cnd_sub_n (hi, rp, m-&gt;B, mn);
+  assert(hi == 0);
+}
+
+static void
+ecc_gost256_mod (const struct ecc_modulo *p, mp_limb_t *rp)
+{
+  mp_size_t mn = p-&gt;size;
+  mpz_t r, a, m;
+  mpz_init (r);
+  mpz_mod (r, mpz_roinit_n (a, rp, 2*mn), mpz_roinit_n (m, p-&gt;m, mn));
+  mpz_limbs_copy (rp, r, mn);
+
+  mpz_clear (r);
+}
+
+static void
+ecc_gc256c_mod_mul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
+		      const mp_limb_t *ap, mp_limb_t b)
+{
+  mp_limb_t hi;
+
+  assert (b &lt;= 0xffffffff);
+  hi = mpn_mul_1 (rp, ap, m-&gt;size, b);
+  hi = mpn_sub_1 (rp, rp, m-&gt;size, hi * 0xc99 * 2);
+  assert(hi &lt;= 1);
+  hi = cnd_add_n (hi, rp, m-&gt;B, m-&gt;size);
+  assert(hi == 0);
+}
+
+static void
+ecc_gc256c_mod_addmul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
+			 const mp_limb_t *ap, mp_limb_t b)
+{
+  mp_limb_t hi;
+
+  assert (b &lt;= 0xffffffff);
+  hi = mpn_addmul_1 (rp, ap, m-&gt;size, b);
+  hi = mpn_sub_1 (rp, rp, m-&gt;size, hi * 0xc99 * 2);
+  assert(hi &lt;= 1);
+  hi = cnd_add_n (hi, rp, m-&gt;B, m-&gt;size);
+  assert(hi == 0);
+}
+
+static void
+ecc_gc256c_mod_submul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
+			 const mp_limb_t *ap, mp_limb_t b)
+{
+  mp_limb_t hi;
+
+  assert (b &lt;= 0xffffffff);
+  hi = mpn_submul_1 (rp, ap, m-&gt;size, b);
+  hi = mpn_add_1 (rp, rp, m-&gt;size, hi * 0xc99 * 2);
+  assert(hi &lt;= 1);
+  hi = cnd_sub_n (hi, rp, m-&gt;B, m-&gt;size);
+  assert(hi == 0);
+}
+
+#define ecc_gc256c_modp ecc_gc256c_modp
+#define ecc_gc256c_modq ecc_gost256_mod
+
+const struct ecc_curve _nettle_gc256c =
+{
+  {
+    256,
+    ECC_LIMB_SIZE,
+    ECC_BMODP_SIZE,
+    ECC_REDC_SIZE,
+    ECC_MOD_INV_ITCH (ECC_LIMB_SIZE),
+    0,
+
+    ecc_p,
+    ecc_Bmodp,
+    ecc_Bmodp_shifted,
+    ecc_redc_ppm1,
+
+    ecc_pp1h,
+    ecc_gc256c_modp,
+    USE_REDC ? ecc_gc256c_redc : ecc_gc256c_modp,
+    ecc_mod_inv,
+    NULL,
+
+    ecc_gc256c_mod_mul_1,
+    ecc_gc256c_mod_addmul_1,
+    ecc_gc256c_mod_submul_1,
+  },
+  {
+    256,
+    ECC_LIMB_SIZE,
+    ECC_BMODQ_SIZE,
+    0,
+    ECC_MOD_INV_ITCH (ECC_LIMB_SIZE),
+    0,
+
+    ecc_q,
+    ecc_Bmodq,
+    ecc_Bmodq_shifted,
+    NULL,
+    ecc_qp1h,
+
+    ecc_gc256c_modq,
+    ecc_gc256c_modq,
+    ecc_mod_inv,
+    NULL,
+
+    NULL,
+    NULL,
+    NULL,
+  },
+
+  USE_REDC,
+  ECC_PIPPENGER_K,
+  ECC_PIPPENGER_C,
+
+  ECC_ADD_JJA_ITCH (ECC_LIMB_SIZE),
+  ECC_ADD_JJJ_ITCH (ECC_LIMB_SIZE),
+  ECC_DUP_JJ_ITCH (ECC_LIMB_SIZE),
+  ECC_MUL_A_ITCH (ECC_LIMB_SIZE),
+  ECC_MUL_G_ITCH (ECC_LIMB_SIZE),
+  ECC_J_TO_A_ITCH (ECC_LIMB_SIZE),
+
+  ecc_add_jja,
+  ecc_add_jjj,
+  ecc_dup_jj,
+  ecc_mul_a,
+  ecc_mul_g,
+  ecc_j_to_a,
+
+  ecc_b,
+  ecc_g,
+  ecc_unit,
+  ecc_table
+};
+
+const struct ecc_curve *nettle_get_gc256c(void)
+{
+  return &amp;_nettle_gc256c;
+}
diff --git a/ecc-gc256d.c b/ecc-gc256d.c
new file mode 100644
index 000000000000..19971f2bda2a
--- /dev/null
+++ b/ecc-gc256d.c
@@ -0,0 +1,184 @@
+/* ecc-gc256d.c
+
+   Compile time constant (but machine dependent) tables.
+
+   Copyright (C) 2016, 2019 Dmitry Eremin-Solenikov
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+/* Development of Nettle's ECC support was funded by the .SE Internet Fund. */
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+
+#include "ecc.h"
+#include "ecc-internal.h"
+
+#define USE_REDC (ECC_REDC_SIZE != 0)
+
+#include "ecc-gc256d.h"
+
+#if ECC_REDC_SIZE &gt; 0
+#  define ecc_gc256d_redc ecc_pp1_redc
+#elif ECC_REDC_SIZE == 0
+#  define ecc_gc256d_redc NULL
+#else
+# error Configuration error
+#endif
+
+static void
+ecc_gost256_mod (const struct ecc_modulo *p, mp_limb_t *rp)
+{
+  mp_size_t mn = p-&gt;size;
+  mpz_t r, a, m;
+  mpz_init (r);
+  mpz_mod (r, mpz_roinit_n (a, rp, 2*mn), mpz_roinit_n (m, p-&gt;m, mn));
+  mpz_limbs_copy (rp, r, mn);
+
+  mpz_clear (r);
+}
+
+static void
+ecc_gc256d_mod_mul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
+		      const mp_limb_t *ap, mp_limb_t b)
+{
+  mp_limb_t hi;
+
+  assert (b &lt;= 0xffffffff);
+  hi = mpn_mul_1 (rp, ap, m-&gt;size, b);
+  while (hi != 0)
+    hi = mpn_addmul_1 (rp, m-&gt;B, m-&gt;size, hi);
+}
+
+static void
+ecc_gc256d_mod_addmul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
+			 const mp_limb_t *ap, mp_limb_t b)
+{
+  mp_limb_t hi;
+
+  assert (b &lt;= 0xffffffff);
+  hi = mpn_addmul_1 (rp, ap, m-&gt;size, b);
+  while (hi != 0)
+    hi = mpn_addmul_1 (rp, m-&gt;B, m-&gt;size, hi);
+}
+
+static void
+ecc_gc256d_mod_submul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
+			 const mp_limb_t *ap, mp_limb_t b)
+{
+  mp_limb_t hi;
+
+  assert (b &lt;= 0xffffffff);
+  hi = mpn_submul_1 (rp, ap, m-&gt;size, b);
+  while (hi != 0)
+    hi = mpn_submul_1 (rp, m-&gt;B, m-&gt;size, hi);
+}
+
+#define ecc_gc256d_modp ecc_gost256_mod
+#define ecc_gc256d_modq ecc_gost256_mod
+
+const struct ecc_curve _nettle_gc256d =
+{
+  {
+    256,
+    ECC_LIMB_SIZE,
+    ECC_BMODP_SIZE,
+    ECC_REDC_SIZE,
+    ECC_MOD_INV_ITCH (ECC_LIMB_SIZE),
+    0,
+
+    ecc_p,
+    ecc_Bmodp,
+    ecc_Bmodp_shifted,
+    ecc_redc_ppm1,
+
+    ecc_pp1h,
+    ecc_gc256d_modp,
+    USE_REDC ? ecc_gc256d_redc : ecc_gc256d_modp,
+    ecc_mod_inv,
+    NULL,
+
+    ecc_gc256d_mod_mul_1,
+    ecc_gc256d_mod_addmul_1,
+    ecc_gc256d_mod_submul_1,
+  },
+  {
+    256,
+    ECC_LIMB_SIZE,
+    ECC_BMODQ_SIZE,
+    0,
+    ECC_MOD_INV_ITCH (ECC_LIMB_SIZE),
+    0,
+
+    ecc_q,
+    ecc_Bmodq,
+    ecc_Bmodq_shifted,
+    NULL,
+    ecc_qp1h,
+
+    ecc_gc256d_modq,
+    ecc_gc256d_modq,
+    ecc_mod_inv,
+    NULL,
+
+    NULL,
+    NULL,
+    NULL,
+  },
+
+  USE_REDC,
+  ECC_PIPPENGER_K,
+  ECC_PIPPENGER_C,
+
+  ECC_ADD_JJA_ITCH (ECC_LIMB_SIZE),
+  ECC_ADD_JJJ_ITCH (ECC_LIMB_SIZE),
+  ECC_DUP_JJ_ITCH (ECC_LIMB_SIZE),
+  ECC_MUL_A_ITCH (ECC_LIMB_SIZE),
+  ECC_MUL_G_ITCH (ECC_LIMB_SIZE),
+  ECC_J_TO_A_ITCH (ECC_LIMB_SIZE),
+
+  ecc_add_jja,
+  ecc_add_jjj,
+  ecc_dup_jj,
+  ecc_mul_a,
+  ecc_mul_g,
+  ecc_j_to_a,
+
+  ecc_b,
+  ecc_g,
+  ecc_unit,
+  ecc_table
+};
+
+const struct ecc_curve *nettle_get_gc256d(void)
+{
+  return &amp;_nettle_gc256d;
+}
diff --git a/ecc-gc512a.c b/ecc-gc512a.c
new file mode 100644
index 000000000000..1e814236b57b
--- /dev/null
+++ b/ecc-gc512a.c
@@ -0,0 +1,148 @@
+/* ecc-gc512a.c
+
+   Compile time constant (but machine dependent) tables.
+
+   Copyright (C) 2016, 2019 Dmitry Eremin-Solenikov
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+/* Development of Nettle's ECC support was funded by the .SE Internet Fund. */
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+
+#include "ecc.h"
+#include "ecc-internal.h"
+
+#define USE_REDC (ECC_REDC_SIZE != 0)
+
+#include "ecc-gc512a.h"
+
+#if ECC_REDC_SIZE &gt; 0
+#  define ecc_gc512a_redc ecc_pp1_redc
+#elif ECC_REDC_SIZE == 0
+#  define ecc_gc512a_redc NULL
+#else
+# error Configuration error
+#endif
+
+static void
+ecc_gc512a_modp (const struct ecc_modulo *m, mp_limb_t *rp)
+{
+  mp_size_t mn = m-&gt;size;
+  mp_limb_t hi;
+
+  hi = mpn_addmul_1(rp, rp + mn, mn, 0x239);
+  hi = sec_add_1 (rp, rp, mn, hi * 0x239);
+  hi = sec_add_1 (rp, rp, mn, hi * 0x239);
+  assert(hi == 0);
+}
+
+#define ecc_gc512a_modp ecc_gc512a_modp
+#define ecc_gc512a_modq ecc_mod
+
+const struct ecc_curve _nettle_gc512a =
+{
+  {
+    512,
+    ECC_LIMB_SIZE,
+    ECC_BMODP_SIZE,
+    ECC_REDC_SIZE,
+    ECC_MOD_INV_ITCH (ECC_LIMB_SIZE),
+    0,
+
+    ecc_p,
+    ecc_Bmodp,
+    ecc_Bmodp_shifted,
+    ecc_redc_ppm1,
+
+    ecc_pp1h,
+    ecc_gc512a_modp,
+    USE_REDC ? ecc_gc512a_redc : ecc_gc512a_modp,
+    ecc_mod_inv,
+    NULL,
+
+    ecc_mod_mul_1_std,
+    ecc_mod_addmul_1_std,
+    ecc_mod_submul_1_std,
+  },
+  {
+    512,
+    ECC_LIMB_SIZE,
+    ECC_BMODQ_SIZE,
+    0,
+    ECC_MOD_INV_ITCH (ECC_LIMB_SIZE),
+    0,
+
+    ecc_q,
+    ecc_Bmodq,
+    ecc_Bmodq_shifted,
+    NULL,
+    ecc_qp1h,
+
+    ecc_gc512a_modq,
+    ecc_gc512a_modq,
+    ecc_mod_inv,
+    NULL,
+
+    NULL,
+    NULL,
+    NULL,
+  },
+
+  USE_REDC,
+  ECC_PIPPENGER_K,
+  ECC_PIPPENGER_C,
+
+  ECC_ADD_JJA_ITCH (ECC_LIMB_SIZE),
+  ECC_ADD_JJJ_ITCH (ECC_LIMB_SIZE),
+  ECC_DUP_JJ_ITCH (ECC_LIMB_SIZE),
+  ECC_MUL_A_ITCH (ECC_LIMB_SIZE),
+  ECC_MUL_G_ITCH (ECC_LIMB_SIZE),
+  ECC_J_TO_A_ITCH (ECC_LIMB_SIZE),
+
+  ecc_add_jja,
+  ecc_add_jjj,
+  ecc_dup_jj,
+  ecc_mul_a,
+  ecc_mul_g,
+  ecc_j_to_a,
+
+  ecc_b,
+  ecc_g,
+  ecc_unit,
+  ecc_table
+};
+
+const struct ecc_curve *nettle_get_gc512a(void)
+{
+  return &amp;_nettle_gc512a;
+}
diff --git a/ecc-gc512b.c b/ecc-gc512b.c
new file mode 100644
index 000000000000..ac2064dde1f3
--- /dev/null
+++ b/ecc-gc512b.c
@@ -0,0 +1,204 @@
+/* ecc-gc512b.c
+
+   Compile time constant (but machine dependent) tables.
+
+   Copyright (C) 2016, 2019 Dmitry Eremin-Solenikov
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+/* Development of Nettle's ECC support was funded by the .SE Internet Fund. */
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+
+#include "ecc.h"
+#include "ecc-internal.h"
+
+#define USE_REDC (ECC_REDC_SIZE != 0)
+
+#include "ecc-gc512b.h"
+
+#if ECC_REDC_SIZE &gt; 0
+#  define ecc_gc512b_redc ecc_pp1_redc
+#elif ECC_REDC_SIZE == 0
+#  define ecc_gc512b_redc NULL
+#else
+# error Configuration error
+#endif
+
+static void
+ecc_gc512b_modp (const struct ecc_modulo *m, mp_limb_t *rp)
+{
+  mp_size_t mn = m-&gt;size;
+  mp_limb_t hi;
+
+  hi = mpn_submul_1(rp, rp + mn, mn, 0x6f * 2);
+  hi = sec_add_1 (rp, rp, mn, hi * 0x6f * 2);
+  hi = sec_sub_1 (rp, rp, mn, hi * 0x6f * 2);
+  assert(hi &lt;= 1);
+  hi = cnd_sub_n (hi, rp, m-&gt;B, mn);
+  assert(hi == 0);
+}
+
+static void
+ecc_gc512_mod (const struct ecc_modulo *p, mp_limb_t *rp)
+{
+  mp_size_t mn = p-&gt;size;
+  mpz_t r, a, m;
+  mpz_init (r);
+  mpz_mod (r, mpz_roinit_n (a, rp, 2*mn), mpz_roinit_n (m, p-&gt;m, mn));
+  mpz_limbs_copy (rp, r, mn);
+
+  mpz_clear (r);
+}
+
+static void
+ecc_gc512b_mod_mul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
+		      const mp_limb_t *ap, mp_limb_t b)
+{
+  mp_limb_t hi;
+
+  assert (b &lt;= 0xffffffff);
+  hi = mpn_mul_1 (rp, ap, m-&gt;size, b);
+  hi = mpn_sub_1 (rp, rp, m-&gt;size, hi * 0x6f * 2);
+  assert(hi &lt;= 1);
+  hi = cnd_add_n (hi, rp, m-&gt;B, m-&gt;size);
+  assert(hi == 0);
+}
+
+static void
+ecc_gc512b_mod_addmul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
+			 const mp_limb_t *ap, mp_limb_t b)
+{
+  mp_limb_t hi;
+
+  assert (b &lt;= 0xffffffff);
+  hi = mpn_addmul_1 (rp, ap, m-&gt;size, b);
+  hi = mpn_sub_1 (rp, rp, m-&gt;size, hi * 0x6f * 2);
+  assert(hi &lt;= 1);
+  hi = cnd_add_n (hi, rp, m-&gt;B, m-&gt;size);
+  assert(hi == 0);
+}
+
+static void
+ecc_gc512b_mod_submul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
+			 const mp_limb_t *ap, mp_limb_t b)
+{
+  mp_limb_t hi;
+
+  assert (b &lt;= 0xffffffff);
+  hi = mpn_submul_1 (rp, ap, m-&gt;size, b);
+  hi = mpn_add_1 (rp, rp, m-&gt;size, hi * 0x6f * 2);
+  assert(hi &lt;= 1);
+  hi = cnd_sub_n (hi, rp, m-&gt;B, m-&gt;size);
+  assert(hi == 0);
+}
+
+#define ecc_gc512b_modp ecc_gc512b_modp
+#define ecc_gc512b_modq ecc_gc512_mod
+
+const struct ecc_curve _nettle_gc512b =
+{
+  {
+    512,
+    ECC_LIMB_SIZE,
+    ECC_BMODP_SIZE,
+    ECC_REDC_SIZE,
+    ECC_MOD_INV_ITCH (ECC_LIMB_SIZE),
+    0,
+
+    ecc_p,
+    ecc_Bmodp,
+    ecc_Bmodp_shifted,
+    ecc_redc_ppm1,
+
+    ecc_pp1h,
+    ecc_gc512b_modp,
+    USE_REDC ? ecc_gc512b_redc : ecc_gc512b_modp,
+    ecc_mod_inv,
+    NULL,
+
+    ecc_gc512b_mod_mul_1,
+    ecc_gc512b_mod_addmul_1,
+    ecc_gc512b_mod_submul_1,
+  },
+  {
+    512,
+    ECC_LIMB_SIZE,
+    ECC_BMODQ_SIZE,
+    0,
+    ECC_MOD_INV_ITCH (ECC_LIMB_SIZE),
+    0,
+
+    ecc_q,
+    ecc_Bmodq,
+    ecc_Bmodq_shifted,
+    NULL,
+    ecc_qp1h,
+
+    ecc_gc512b_modq,
+    ecc_gc512b_modq,
+    ecc_mod_inv,
+    NULL,
+
+    NULL,
+    NULL,
+    NULL,
+  },
+
+  USE_REDC,
+  ECC_PIPPENGER_K,
+  ECC_PIPPENGER_C,
+
+  ECC_ADD_JJA_ITCH (ECC_LIMB_SIZE),
+  ECC_ADD_JJJ_ITCH (ECC_LIMB_SIZE),
+  ECC_DUP_JJ_ITCH (ECC_LIMB_SIZE),
+  ECC_MUL_A_ITCH (ECC_LIMB_SIZE),
+  ECC_MUL_G_ITCH (ECC_LIMB_SIZE),
+  ECC_J_TO_A_ITCH (ECC_LIMB_SIZE),
+
+  ecc_add_jja,
+  ecc_add_jjj,
+  ecc_dup_jj,
+  ecc_mul_a,
+  ecc_mul_g,
+  ecc_j_to_a,
+
+  ecc_b,
+  ecc_g,
+  ecc_unit,
+  ecc_table
+};
+
+const struct ecc_curve *nettle_get_gc512b(void)
+{
+  return &amp;_nettle_gc512b;
+}
diff --git a/ecc-internal.h b/ecc-internal.h
index 105b67b2990e..99e711a5b38d 100644
--- a/ecc-internal.h
+++ b/ecc-internal.h
@@ -91,6 +91,13 @@ extern const struct ecc_curve _nettle_secp_521r1;
 extern const struct ecc_curve _nettle_curve25519;
 extern const struct ecc_curve _nettle_curve448;
 
+/* GOST curves, visible with underscore prefix for now */
+extern const struct ecc_curve _nettle_gc256b;
+extern const struct ecc_curve _nettle_gc256c;
+extern const struct ecc_curve _nettle_gc256d;
+extern const struct ecc_curve _nettle_gc512a;
+extern const struct ecc_curve _nettle_gc512b;
+
 #define ECC_MAX_SIZE ((521 + GMP_NUMB_BITS - 1) / GMP_NUMB_BITS)
 
 /* Window size for ecc_mul_a. Using 4 bits seems like a good choice,
diff --git a/eccdata.c b/eccdata.c
index d76a42bcde6f..6facbace8698 100644
--- a/eccdata.c
+++ b/eccdata.c
@@ -673,6 +673,178 @@ ecc_curve_init (struct ecc_curve *ecc, const char *curve)
 		   "1a739ec193ce1547493aa657c4c9f870",
 		   "47d0e827cb1595e1470eb88580d5716c"
 		   "4cf22832ea2f0ff0df38ab61ca32112f");
+
+    }
+  else if (!strcmp (curve, "gc256b"))
+    {
+      ecc_curve_init_str (ecc, ECC_TYPE_WEIERSTRASS,
+			  "ffffffffffffffffffffffffffffffff"
+			  "fffffffffffffffffffffffffffffd97",
+
+			  "00000000000000000000000000000000"
+			  "000000000000000000000000000000a6",
+
+			  "ffffffffffffffffffffffffffffffff"
+			  "6c611070995ad10045841b09b761b893",
+
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000001",
+
+			  "8d91e471e0989cda27df505a453f2b76"
+			  "35294f2ddf23e3b122acc99c9e9f1e14");
+
+      ecc-&gt;ref = ecc_alloc (3);
+      ecc_set_str (&amp;ecc-&gt;ref[0], /* 2 g */
+		   "fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffd95",
+		   "726e1b8e1f676325d820afa5bac0d489cad6b0d220dc1c4edd5336636160df83");
+
+      ecc_set_str (&amp;ecc-&gt;ref[1], /* 3 g */
+		   "8e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38d2c",
+		   "76bcd1ca9a23b041d4d9baf507a6cd821267a94c838768e8486117796b788a51");
+
+      ecc_set_str (&amp;ecc-&gt;ref[2], /* 4 g */
+		   "f7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e4b7",
+		   "83ccf17ba6706d73625cc3534c7a2b9d6ec1ee6a9a7e07c10d84b388de59f741");
+
+    }
+  else if (!strcmp (curve, "gc256c"))
+    {
+      ecc_curve_init_str (ecc, ECC_TYPE_WEIERSTRASS,
+			  "80000000000000000000000000000000"
+			  "00000000000000000000000000000c99",
+
+			  "3e1af419a269a5f866a7d3c25c3df80a"
+			  "e979259373ff2b182f49d4ce7e1bbc8b",
+
+			  "80000000000000000000000000000001"
+			  "5f700cfff1a624e5e497161bcc8a198f",
+
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000001",
+
+			  "3fa8124359f96680b83d1c3eb2c070e5"
+			  "c545c9858d03ecfb744bf8d717717efc");
+
+      ecc-&gt;ref = ecc_alloc (3);
+      ecc_set_str (&amp;ecc-&gt;ref[0], /* 2 g */
+		   "8000000000000000000000000000000000000000000000000000000000000c97",
+		   "4057edbca606997f47c2e3c14d3f8f1a3aba367a72fc13048bb40728e88e8d9d");
+
+      ecc_set_str (&amp;ecc-&gt;ref[1], /* 3 g */
+		   "1b9a33999d8449c3bbd8cfe49ac6355a2ee0827a6c71687c86cb7b0670efe205",
+		   "1876d998a19da37a120e76cb42f4f5225197279b612f712171a4648fe4a3ff12");
+
+      ecc_set_str (&amp;ecc-&gt;ref[2], /* 4 g */
+		   "5fa13ecfadd7ae00c2e65d0ac6cac1deda6d60e577afe90915671b08bbb9065e",
+		   "1b3c2859166129ac6dafee570ab9d40d33fdc25c7253c72f4e3fa77223ab016a");
+
+    }
+  else if (!strcmp (curve, "gc256d"))
+    {
+      ecc_curve_init_str (ecc, ECC_TYPE_WEIERSTRASS,
+			  "9b9f605f5a858107ab1ec85e6b41c8aa"
+			  "cf846e86789051d37998f7b9022d759b",
+
+			  "00000000000000000000000000000000"
+			  "0000000000000000000000000000805a",
+
+			  "9b9f605f5a858107ab1ec85e6b41c8aa"
+			  "582ca3511eddfb74f02f3a6598980bb9",
+
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000000",
+
+			  "41ece55743711a8c3cbf3783cd08c0ee"
+			  "4d4dc440d4641a8f366e550dfdb3bb67");
+      ecc-&gt;ref = ecc_alloc (3);
+      ecc_set_str (&amp;ecc-&gt;ref[0], /* 2 g */
+		   "74ab1ac14e9ed5cda1af70308c897ebf3d91d913a7bf377833c436bf0f8aa40e",
+		   "7d223beab738ba52a65ffbfe585d2807bfaed5ea9cd651a63a775b4182f562e3");
+
+      ecc_set_str (&amp;ecc-&gt;ref[1], /* 3 g */
+		   "771e56689775fda0bbdeac54e9cd379f30391edf06f335269c48f06446cd037a",
+		   "8430215fbee8a09c5e38bda64b50bbef41392d6afa5ced73652c83cb5221d02b");
+
+      ecc_set_str (&amp;ecc-&gt;ref[2], /* 4 g */
+		   "4fe44356aded59b4b661e9da15fe79dbcb1d7346770919c5c99090e5ae4db8a6",
+		   "24f0222027a3d2577cca5aefb5411c88f92f5f4b8febddebc71c12180640ebfd");
+
+    }
+  else if (!strcmp (curve, "gc512a"))
+    {
+      ecc_curve_init_str (ecc, ECC_TYPE_WEIERSTRASS,
+			  "ffffffffffffffffffffffffffffffff"
+			  "ffffffffffffffffffffffffffffffff"
+			  "ffffffffffffffffffffffffffffffff"
+			  "fffffffffffffffffffffffffffffdc7",
+			  "e8c2505dedfc86ddc1bd0b2b6667f1da"
+			  "34b82574761cb0e879bd081cfd0b6265"
+			  "ee3cb090f30d27614cb4574010da90dd"
+			  "862ef9d4ebee4761503190785a71c760",
+			  "ffffffffffffffffffffffffffffffff"
+			  "ffffffffffffffffffffffffffffffff"
+			  "27e69532f48d89116ff22b8d4e056060"
+			  "9b4b38abfad2b85dcacdb1411f10b275",
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000003",
+			  "7503cfe87a836ae3a61b8816e25450e6"
+			  "ce5e1c93acf1abc1778064fdcbefa921"
+			  "df1626be4fd036e93d75e6a50e3a41e9"
+			  "8028fe5fc235f5b889a589cb5215f2a4");
+
+      ecc-&gt;ref = ecc_alloc (3);
+      ecc_set_str (&amp;ecc-&gt;ref[0], /* 2 g */
+		   "3b89dcfc622996ab97a5869dbff15cf51db00954f43a58a5e5f6b0470a132b2f4434bbcd405d2a9516151d2a6a04f2e4375bf48de1fdb21fb982afd9d2ea137c",
 +		   "c813c4e2e2e0a8a391774c7903da7a6f14686e98e183e670ee6fb784809a3e92ca209dc631d85b1c7534ed3b37fddf64d854d7e01f91f18bb3fd307591afc051");
 +
+      ecc_set_str (&amp;ecc-&gt;ref[1], /* 3 g */
+		   "a1ff1ab2712a267eb53935ddb5a567f84db156cc096168a1174291d5f488fba543d2840b4d2dd35d764b2f57b308907aec55cfba10544e8416e134687ccb87c3",
 +		   "3cb5c4417ec4637f30374f189bb5b984c41e3a48d7f84fbfa3819e3f333f7eb311d3af7e67c4c16eeacfac2fe94c6dd4c6366f711a4fb6c7125cd7ec518d90d6");
 +
+      ecc_set_str (&amp;ecc-&gt;ref[2], /* 4 g */
+		   "b7bfb80956c8670031ba191929f64e301d681634236d47a60e571a4bedc0ef257452ef78b5b98dbb3d9f3129d9349433ce2a3a35cb519c91e2d633d7b373ae16",
 +		   "3bee95e29eecc5d5ad2beba941abcbf9f1cad478df0fecf614f63aeebef77850da7efdb93de8f3df80bc25eac09239c14175f5c29704ce9a3e383f1b3ec0e929");
 +
+    }
+  else if (!strcmp (curve, "gc512b"))
+    {
+      ecc_curve_init_str (ecc, ECC_TYPE_WEIERSTRASS,
+			  "80000000000000000000000000000000"
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000000"
+			  "0000000000000000000000000000006f",
+			  "687d1b459dc841457e3e06cf6f5e2517"
+			  "b97c7d614af138bcbf85dc806c4b289f"
+			  "3e965d2db1416d217f8b276fad1ab69c"
+			  "50f78bee1fa3106efb8ccbc7c5140116",
+			  "80000000000000000000000000000000"
+			  "00000000000000000000000000000001"
+			  "49a1ec142565a545acfdb77bd9d40cfa"
+			  "8b996712101bea0ec6346c54374f25bd",
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000002",
+			  "1a8f7eda389b094c2c071e3647a8940f"
+			  "3c123b697578c213be6dd9e6c8ec7335"
+			  "dcb228fd1edf4a39152cbcaaf8c03988"
+			  "28041055f94ceeec7e21340780fe41bd");
+
+      ecc-&gt;ref = ecc_alloc (3);
+      ecc_set_str (&amp;ecc-&gt;ref[0], /* 2 g */
+		   "73729fb3c0d629ae5dc9bf88ca05d518bce91e502150f5e5822fa0293bc0e3ca31145f3b0e1831d8bb1f20b28780011473339e581a403c676b47c1f9ab764602",
 +		   "35d62c90549f2c17e16c6ea99d3c3dbe610f2c543fc1d0ca5bd48a5ea1d3ec11c3cec5e7fcd74b5306e73b6a8e40c818714f02b25997ee2b54f65432d3f0741e");
 +
+      ecc_set_str (&amp;ecc-&gt;ref[1], /* 3 g */
+		   "1826b56c8dc1d5779b76354070e744f2c9c82755a921142b528f2fe04f5fd0dbdc178314c4546270b423d9fe819ba4c82625b02004bfdf90a08317dceb9309b7",
 +		   "4f6882f8f6422d693f8313bb7b121117ad9ee6b8874135f3e4bff91b01141fdb35d29bc3cf15ab8a3b751050e58392a8eeae790ea5d198eab642dc520fd1713f");
 +
+      ecc_set_str (&amp;ecc-&gt;ref[2], /* 4 g */
+		   "5af069b1624dba4513c303b66b90543d97dbec20b5ba013e4f43ed9e2b88bdc5ac69701b626a8a546d03d52f8510d50df944978b0d33565ab75599b0d0a18563",
 +		   "19eb28c4ee08a66894ca5cb76e160478a4f94c061b1115357557dacd5370bfc22bd1d0faa2e9d72af11ae65cb2335c53f617052331eb56050a972da4efe55eb7");
 +
     }
   else if (!strcmp (curve, "curve448"))
     {
@@ -1316,7 +1488,7 @@ main (int argc, char **argv)
 
   if (argc &lt; 4)
     {
-      fprintf (stderr, "Usage: %s CURVE-BITS K C [BITS-PER-LIMB]\n", argv[0]);
+      fprintf (stderr, "Usage: %s CURVE K C [BITS-PER-LIMB]\n", argv[0]);
       return EXIT_FAILURE;
     }
 
diff --git a/examples/ecc-benchmark.c b/examples/ecc-benchmark.c
index d36d46b77bc1..21e3e24dcef5 100644
--- a/examples/ecc-benchmark.c
+++ b/examples/ecc-benchmark.c
@@ -314,6 +314,11 @@ const struct ecc_curve * const curves[] = {
   &amp;_nettle_secp_384r1,
   &amp;_nettle_curve448,
   &amp;_nettle_secp_521r1,
+  &amp;_nettle_gc256b,
+  &amp;_nettle_gc256c,
+  &amp;_nettle_gc256d,
+  &amp;_nettle_gc512a,
+  &amp;_nettle_gc512b,
 };
 
 #define numberof(x)  (sizeof (x) / sizeof ((x)[0]))
diff --git a/testsuite/testutils.c b/testsuite/testutils.c
index 7772d2b01661..10f2ef915e38 100644
--- a/testsuite/testutils.c
+++ b/testsuite/testutils.c
@@ -1677,6 +1677,11 @@ const struct ecc_curve * const ecc_curves[] = {
   &amp;_nettle_secp_521r1,
   &amp;_nettle_curve25519,
   &amp;_nettle_curve448,
+  &amp;_nettle_gc256b,
+  &amp;_nettle_gc256c,
+  &amp;_nettle_gc256d,
+  &amp;_nettle_gc512a,
+  &amp;_nettle_gc512b,
   NULL
 };
 
@@ -1728,7 +1733,7 @@ void
 test_ecc_mul_a (unsigned curve, unsigned n, const mp_limb_t *p)
 {
   /* For each curve, the points 2 g, 3 g and 4 g */
-  static const struct ecc_ref_point ref[7][3] = {
+  static const struct ecc_ref_point ref[12][3] = {
     { { "dafebf5828783f2ad35534631588a3f629a70fb16982a888",
 	"dd6bda0d993da0fa46b27bbc141b868f59331afa5c7e93ab" },
       { "76e32a2557599e6edcd283201fb2b9aadfd0d359cbb263da",
@@ -1796,9 +1801,56 @@ test_ecc_mul_a (unsigned curve, unsigned n, const mp_limb_t \
*p)  "e005a8dbd5125cf706cbda7ad43aa6449a4a8d952356c3b9fce43c82ec4e1d58bb3a331bdb6767f0bffa9a68fed02dafb822ac13588ed6fc" \
                },
       { "49dcbc5c6c0cce2c1419a17226f929ea255a09cf4e0891c693fda4be70c74cc301b7bdf1515dd8ba21aee1798949e120e2ce42ac48ba7f30",
  "d49077e4accde527164b33a5de021b979cb7c02f0457d845c90dc3227b8a5bc1c0d8f97ea1ca9472b5d444285d0d4f5b32e236f86de51839" \
}, +    },
+    { { "fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffd95",
+	"726e1b8e1f676325d820afa5bac0d489cad6b0d220dc1c4edd5336636160df83" },
+      { "8e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38d2c",
+	"76bcd1ca9a23b041d4d9baf507a6cd821267a94c838768e8486117796b788a51" },
+      { "f7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e4b7",
+	"83ccf17ba6706d73625cc3534c7a2b9d6ec1ee6a9a7e07c10d84b388de59f741" },
+    },
+    { { "8000000000000000000000000000000000000000000000000000000000000c97",
+	"4057edbca606997f47c2e3c14d3f8f1a3aba367a72fc13048bb40728e88e8d9d" },
+      { "1b9a33999d8449c3bbd8cfe49ac6355a2ee0827a6c71687c86cb7b0670efe205",
+	"1876d998a19da37a120e76cb42f4f5225197279b612f712171a4648fe4a3ff12" },
+      { "5fa13ecfadd7ae00c2e65d0ac6cac1deda6d60e577afe90915671b08bbb9065e",
+	"1b3c2859166129ac6dafee570ab9d40d33fdc25c7253c72f4e3fa77223ab016a" },
+    },
+    { { "74ab1ac14e9ed5cda1af70308c897ebf3d91d913a7bf377833c436bf0f8aa40e",
+	"7d223beab738ba52a65ffbfe585d2807bfaed5ea9cd651a63a775b4182f562e3" },
+      { "771e56689775fda0bbdeac54e9cd379f30391edf06f335269c48f06446cd037a",
+	"8430215fbee8a09c5e38bda64b50bbef41392d6afa5ced73652c83cb5221d02b" },
+      { "4fe44356aded59b4b661e9da15fe79dbcb1d7346770919c5c99090e5ae4db8a6",
+	"24f0222027a3d2577cca5aefb5411c88f92f5f4b8febddebc71c12180640ebfd" },
+    },
+    { { "3b89dcfc622996ab97a5869dbff15cf51db00954f43a58a5e5f6b0470a132b2f"
+	"4434bbcd405d2a9516151d2a6a04f2e4375bf48de1fdb21fb982afd9d2ea137c",
+	"c813c4e2e2e0a8a391774c7903da7a6f14686e98e183e670ee6fb784809a3e92"
+	"ca209dc631d85b1c7534ed3b37fddf64d854d7e01f91f18bb3fd307591afc051" },
+      { "a1ff1ab2712a267eb53935ddb5a567f84db156cc096168a1174291d5f488fba5"
+	"43d2840b4d2dd35d764b2f57b308907aec55cfba10544e8416e134687ccb87c3",
+	"3cb5c4417ec4637f30374f189bb5b984c41e3a48d7f84fbfa3819e3f333f7eb3"
+	"11d3af7e67c4c16eeacfac2fe94c6dd4c6366f711a4fb6c7125cd7ec518d90d6" },
+      { "b7bfb80956c8670031ba191929f64e301d681634236d47a60e571a4bedc0ef25"
+	"7452ef78b5b98dbb3d9f3129d9349433ce2a3a35cb519c91e2d633d7b373ae16",
+	"3bee95e29eecc5d5ad2beba941abcbf9f1cad478df0fecf614f63aeebef77850"
+	"da7efdb93de8f3df80bc25eac09239c14175f5c29704ce9a3e383f1b3ec0e929" },
+    },
+    { { "73729fb3c0d629ae5dc9bf88ca05d518bce91e502150f5e5822fa0293bc0e3ca"
+	"31145f3b0e1831d8bb1f20b28780011473339e581a403c676b47c1f9ab764602",
+	"35d62c90549f2c17e16c6ea99d3c3dbe610f2c543fc1d0ca5bd48a5ea1d3ec11"
+	"c3cec5e7fcd74b5306e73b6a8e40c818714f02b25997ee2b54f65432d3f0741e" },
+      { "1826b56c8dc1d5779b76354070e744f2c9c82755a921142b528f2fe04f5fd0db"
+	"dc178314c4546270b423d9fe819ba4c82625b02004bfdf90a08317dceb9309b7",
+	"4f6882f8f6422d693f8313bb7b121117ad9ee6b8874135f3e4bff91b01141fdb"
+	"35d29bc3cf15ab8a3b751050e58392a8eeae790ea5d198eab642dc520fd1713f" },
+      { "5af069b1624dba4513c303b66b90543d97dbec20b5ba013e4f43ed9e2b88bdc5"
+	"ac69701b626a8a546d03d52f8510d50df944978b0d33565ab75599b0d0a18563",
+	"19eb28c4ee08a66894ca5cb76e160478a4f94c061b1115357557dacd5370bfc2"
+	"2bd1d0faa2e9d72af11ae65cb2335c53f617052331eb56050a972da4efe55eb7" },
     }
   };
-  assert (curve &lt; 7);
+  assert (curve &lt; 12);
   assert (n &lt;= 4);
   if (n == 0)
     {
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200111212325</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-01-11 21:23:25-0400</timestampReceived><subject>[PATCH v2 1/3] Add support for GOST GC256B curve</subject><body>

From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;

Add support for GC256B curve ("TLS Supported Groups" registry,
draft-smyshlyaev-tls12-gost-suites) also known as
GostR3410-2001-CryptoPro-A and GostR3410-2001-CryptoPro-XchA (RFC 4357).

Signed-off-by: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;
---
 .gitignore               |   1 +
 Makefile.in              |  11 +++
 ecc-curve.h              |   1 +
 ecc-gc256b.c             | 140 +++++++++++++++++++++++++++++++++++++++
 ecc-internal.h           |   3 +
 eccdata.c                |  34 +++++++++-
 examples/ecc-benchmark.c |   1 +
 testsuite/testutils.c    |  12 +++-
 8 files changed, 200 insertions(+), 3 deletions(-)
 create mode 100644 ecc-gc256b.c

diff --git a/.gitignore b/.gitignore
index ea264107fa40..4454ade5a950 100644
--- a/.gitignore
+++ b/.gitignore
@@ -45,6 +45,7 @@ core
 /rotors.h
 /ecc-curve25519.h
 /ecc-curve448.h
+/ecc-gc256b.h
 /ecc-secp192r1.h
 /ecc-secp224r1.h
 /ecc-secp256r1.h
diff --git a/Makefile.in b/Makefile.in
index 38160bb40fe1..8815e7b76dea 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -176,6 +176,7 @@ hogweed_SOURCES = sexp.c sexp-format.c \
 		  ecc-mod.c ecc-mod-inv.c \
 		  ecc-mod-arith.c ecc-pp1-redc.c ecc-pm1-redc.c \
 		  ecc-curve25519.c ecc-curve448.c \
+		  ecc-gc256b.c \
 		  ecc-secp192r1.c ecc-secp224r1.c ecc-secp256r1.c \
 		  ecc-secp384r1.c ecc-secp521r1.c \
 		  ecc-size.c ecc-j-to-a.c ecc-a-to-j.c \
@@ -396,12 +397,21 @@ ecc-curve25519.h: eccdata.stamp
 ecc-curve448.h: eccdata.stamp
 	./eccdata$(EXEEXT_FOR_BUILD) curve448 38 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
 
+# Some reasonable choices for 256:
+# k =  9, c =  6, S = 320, T =  54 ( 45 A +  9 D) 20 KB
+# k = 11, c =  6, S = 256, T =  55 ( 44 A + 11 D) 16 KB
+# k = 19, c =  7, S = 256, T =  57 ( 38 A + 19 D) 16 KB
+# k = 15, c =  6, S = 192, T =  60 ( 45 A + 15 D) 12 KB
+ecc-gc256b.h: eccdata.stamp
+	./eccdata$(EXEEXT_FOR_BUILD) gc256b 11 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
+
 eccdata.stamp: eccdata.c
 	$(MAKE) eccdata$(EXEEXT_FOR_BUILD)
 	echo stamp &gt; eccdata.stamp
 
 ecc-curve25519.$(OBJEXT): ecc-curve25519.h
 ecc-curve448.$(OBJEXT): ecc-curve448.h
+ecc-gc256b.$(OBJEXT): ecc-gc256b.h
 ecc-secp192r1.$(OBJEXT): ecc-secp192r1.h
 ecc-secp224r1.$(OBJEXT): ecc-secp224r1.h
 ecc-secp256r1.$(OBJEXT): ecc-secp256r1.h
@@ -660,6 +670,7 @@ distcheck: dist
 clean-here:
 	-rm -f $(TARGETS) *.$(OBJEXT) *.s *.so *.dll *.a \
 		ecc-curve25519.h ecc-curve448.h \
+		ecc-gc256b.h \
 		ecc-secp192r1.h ecc-secp224r1.h ecc-secp256r1.h \
 		ecc-secp384r1.h ecc-secp521r1.h \
 		aesdata$(EXEEXT_FOR_BUILD) \
diff --git a/ecc-curve.h b/ecc-curve.h
index 76024a19d24f..b378c8489839 100644
--- a/ecc-curve.h
+++ b/ecc-curve.h
@@ -43,6 +43,7 @@ extern "C" {
 /* The contents of this struct is internal. */
 struct ecc_curve;
 
+const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_gc256b(void);
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_secp_192r1(void);
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_secp_224r1(void);
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_secp_256r1(void);
diff --git a/ecc-gc256b.c b/ecc-gc256b.c
new file mode 100644
index 000000000000..755759a8fd38
--- /dev/null
+++ b/ecc-gc256b.c
@@ -0,0 +1,140 @@
+/* ecc-gc256b.c
+
+   Compile time constant (but machine dependent) tables.
+
+   Copyright (C) 2016, 2019 Dmitry Eremin-Solenikov
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+/* Development of Nettle's ECC support was funded by the .SE Internet Fund. */
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+
+#include "ecc.h"
+#include "ecc-internal.h"
+
+#define USE_REDC (ECC_REDC_SIZE != 0)
+
+#include "ecc-gc256b.h"
+
+#if ECC_REDC_SIZE &gt; 0
+#  define ecc_gc256b_redc ecc_pp1_redc
+#elif ECC_REDC_SIZE == 0
+#  define ecc_gc256b_redc NULL
+#else
+# error Configuration error
+#endif
+
+static void
+ecc_gc256b_modp (const struct ecc_modulo *m, mp_limb_t *rp)
+{
+  mp_size_t mn = m-&gt;size;
+  mp_limb_t hi;
+
+  hi = mpn_addmul_1(rp, rp + mn, mn, 0x269);
+  hi = sec_add_1 (rp, rp, mn, hi * 0x269);
+  hi = sec_add_1 (rp, rp, mn, hi * 0x269);
+  assert(hi == 0);
+}
+
+#define ecc_gc256b_modp ecc_gc256b_modp
+#define ecc_gc256b_modq ecc_mod
+
+const struct ecc_curve _nettle_gc256b =
+{
+  {
+    256,
+    ECC_LIMB_SIZE,
+    ECC_BMODP_SIZE,
+    ECC_REDC_SIZE,
+    ECC_MOD_INV_ITCH (ECC_LIMB_SIZE),
+    0,
+
+    ecc_p,
+    ecc_Bmodp,
+    ecc_Bmodp_shifted,
+    ecc_redc_ppm1,
+
+    ecc_pp1h,
+    ecc_gc256b_modp,
+    USE_REDC ? ecc_gc256b_redc : ecc_gc256b_modp,
+    ecc_mod_inv,
+    NULL,
+  },
+  {
+    256,
+    ECC_LIMB_SIZE,
+    ECC_BMODQ_SIZE,
+    0,
+    ECC_MOD_INV_ITCH (ECC_LIMB_SIZE),
+    0,
+
+    ecc_q,
+    ecc_Bmodq,
+    ecc_Bmodq_shifted,
+    NULL,
+    ecc_qp1h,
+
+    ecc_gc256b_modq,
+    ecc_gc256b_modq,
+    ecc_mod_inv,
+    NULL,
+  },
+
+  USE_REDC,
+  ECC_PIPPENGER_K,
+  ECC_PIPPENGER_C,
+
+  ECC_ADD_JJA_ITCH (ECC_LIMB_SIZE),
+  ECC_ADD_JJJ_ITCH (ECC_LIMB_SIZE),
+  ECC_DUP_JJ_ITCH (ECC_LIMB_SIZE),
+  ECC_MUL_A_ITCH (ECC_LIMB_SIZE),
+  ECC_MUL_G_ITCH (ECC_LIMB_SIZE),
+  ECC_J_TO_A_ITCH (ECC_LIMB_SIZE),
+
+  ecc_add_jja,
+  ecc_add_jjj,
+  ecc_dup_jj,
+  ecc_mul_a,
+  ecc_mul_g,
+  ecc_j_to_a,
+
+  ecc_b,
+  ecc_g,
+  ecc_unit,
+  ecc_table
+};
+
+const struct ecc_curve *nettle_get_gc256b(void)
+{
+  return &amp;_nettle_gc256b;
+}
diff --git a/ecc-internal.h b/ecc-internal.h
index c918632df292..0972efaf10d1 100644
--- a/ecc-internal.h
+++ b/ecc-internal.h
@@ -91,6 +91,9 @@ extern const struct ecc_curve _nettle_secp_521r1;
 extern const struct ecc_curve _nettle_curve25519;
 extern const struct ecc_curve _nettle_curve448;
 
+/* GOST curves, visible with underscore prefix for now */
+extern const struct ecc_curve _nettle_gc256b;
+
 #define ECC_MAX_SIZE ((521 + GMP_NUMB_BITS - 1) / GMP_NUMB_BITS)
 
 /* Window size for ecc_mul_a. Using 4 bits seems like a good choice,
diff --git a/eccdata.c b/eccdata.c
index d76a42bcde6f..3820e150125b 100644
--- a/eccdata.c
+++ b/eccdata.c
@@ -674,6 +674,38 @@ ecc_curve_init (struct ecc_curve *ecc, const char *curve)
 		   "47d0e827cb1595e1470eb88580d5716c"
 		   "4cf22832ea2f0ff0df38ab61ca32112f");
     }
+  else if (!strcmp (curve, "gc256b"))
+    {
+      ecc_curve_init_str (ecc, ECC_TYPE_WEIERSTRASS,
+			  "ffffffffffffffffffffffffffffffff"
+			  "fffffffffffffffffffffffffffffd97",
+
+			  "00000000000000000000000000000000"
+			  "000000000000000000000000000000a6",
+
+			  "ffffffffffffffffffffffffffffffff"
+			  "6c611070995ad10045841b09b761b893",
+
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000001",
+
+			  "8d91e471e0989cda27df505a453f2b76"
+			  "35294f2ddf23e3b122acc99c9e9f1e14");
+
+      ecc-&gt;ref = ecc_alloc (3);
+      ecc_set_str (&amp;ecc-&gt;ref[0], /* 2 g */
+		   "fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffd95",
+		   "726e1b8e1f676325d820afa5bac0d489cad6b0d220dc1c4edd5336636160df83");
+
+      ecc_set_str (&amp;ecc-&gt;ref[1], /* 3 g */
+		   "8e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38d2c",
+		   "76bcd1ca9a23b041d4d9baf507a6cd821267a94c838768e8486117796b788a51");
+
+      ecc_set_str (&amp;ecc-&gt;ref[2], /* 4 g */
+		   "f7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e4b7",
+		   "83ccf17ba6706d73625cc3534c7a2b9d6ec1ee6a9a7e07c10d84b388de59f741");
+
+    }
   else if (!strcmp (curve, "curve448"))
     {
       /* curve448, y^2 = x^3 + 156326 x^2 + x (mod p), with p = 2^{448} - 2^{224} - \
1. @@ -1316,7 +1348,7 @@ main (int argc, char **argv)
 
   if (argc &lt; 4)
     {
-      fprintf (stderr, "Usage: %s CURVE-BITS K C [BITS-PER-LIMB]\n", argv[0]);
+      fprintf (stderr, "Usage: %s CURVE K C [BITS-PER-LIMB]\n", argv[0]);
       return EXIT_FAILURE;
     }
 
diff --git a/examples/ecc-benchmark.c b/examples/ecc-benchmark.c
index d36d46b77bc1..497c76c3e550 100644
--- a/examples/ecc-benchmark.c
+++ b/examples/ecc-benchmark.c
@@ -314,6 +314,7 @@ const struct ecc_curve * const curves[] = {
   &amp;_nettle_secp_384r1,
   &amp;_nettle_curve448,
   &amp;_nettle_secp_521r1,
+  &amp;_nettle_gc256b,
 };
 
 #define numberof(x)  (sizeof (x) / sizeof ((x)[0]))
diff --git a/testsuite/testutils.c b/testsuite/testutils.c
index 7772d2b01661..e4e7c23dcc1b 100644
--- a/testsuite/testutils.c
+++ b/testsuite/testutils.c
@@ -1677,6 +1677,7 @@ const struct ecc_curve * const ecc_curves[] = {
   &amp;_nettle_secp_521r1,
   &amp;_nettle_curve25519,
   &amp;_nettle_curve448,
+  &amp;_nettle_gc256b,
   NULL
 };
 
@@ -1728,7 +1729,7 @@ void
 test_ecc_mul_a (unsigned curve, unsigned n, const mp_limb_t *p)
 {
   /* For each curve, the points 2 g, 3 g and 4 g */
-  static const struct ecc_ref_point ref[7][3] = {
+  static const struct ecc_ref_point ref[8][3] = {
     { { "dafebf5828783f2ad35534631588a3f629a70fb16982a888",
 	"dd6bda0d993da0fa46b27bbc141b868f59331afa5c7e93ab" },
       { "76e32a2557599e6edcd283201fb2b9aadfd0d359cbb263da",
@@ -1796,9 +1797,16 @@ test_ecc_mul_a (unsigned curve, unsigned n, const mp_limb_t \
*p)  "e005a8dbd5125cf706cbda7ad43aa6449a4a8d952356c3b9fce43c82ec4e1d58bb3a331bdb6767f0bffa9a68fed02dafb822ac13588ed6fc" \
                },
       { "49dcbc5c6c0cce2c1419a17226f929ea255a09cf4e0891c693fda4be70c74cc301b7bdf1515dd8ba21aee1798949e120e2ce42ac48ba7f30",
  "d49077e4accde527164b33a5de021b979cb7c02f0457d845c90dc3227b8a5bc1c0d8f97ea1ca9472b5d444285d0d4f5b32e236f86de51839" \
}, +    },
+    { { "fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffd95",
+	"726e1b8e1f676325d820afa5bac0d489cad6b0d220dc1c4edd5336636160df83" },
+      { "8e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38d2c",
+	"76bcd1ca9a23b041d4d9baf507a6cd821267a94c838768e8486117796b788a51" },
+      { "f7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e4b7",
+	"83ccf17ba6706d73625cc3534c7a2b9d6ec1ee6a9a7e07c10d84b388de59f741" },
     }
   };
-  assert (curve &lt; 7);
+  assert (curve &lt; 8);
   assert (n &lt;= 4);
   if (n == 0)
     {
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200111092016</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-11 09:20:16-0400</timestampReceived><subject>Gitlab merge requests</subject><body>

Hi,

After some off-list discussions and encouragement, I've reenabled the
"merge request" feature on git.lysator.liu.se/nettle.

I don't know yet precisely how I will want to use it, but feel free to
create merge requests if you think that helps us keep track of ongoing
work. For the time being, please also write to the mailinglist whenever
some action is done or desired on a merge request.

I intend the mailinglist to remain the main forum for discussing new
features and implementation choices, while detailed patch review might
gradually move to the web interface.

Advice on how to use and configure gitlab is welcome.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200111095402</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-11 09:54:02-0400</timestampReceived><subject>Require GNU make?</subject><body>

Hi,

it's been pointed out to me that GNU make documentation of old-fashioned
suffix rules say

:    Suffix rules cannot have any prerequisites of their own.  If they
: have any, they are treated as normal files with funny names, not as
: suffix rules.  Thus, the rule:
: 
:      .c.o: foo.h
:              $(CC) -c $(CFLAGS) $(CPPFLAGS) -o $@ $&lt;
: 
: tells how to make the file '.c.o' from the prerequisite file 'foo.h',

Nettle's Makefile.in has a rule

  .asm.$(OBJEXT): $(srcdir)/asm.m4 machine.m4 config.m4

which is broken according to these docs. I haven't seen any problems in
practice (not entirely sure why), but it reportedly fails with some GNU
make prerelease.

To change this to a %-pattern rule, I wonder: Should we just drop
support for non-GNU make programs?

Requiring GNU make makes a few things easier: We can use %-patterns
everywhere. We can use -include unconditionally for dep-files, dropping the
@DEP_INCLUDE@ variable and the dummy-dep-files configure step. We can
most likely also drop all logic for the testsuite/.test-rules.make file.

Current status of make compatibility is that it's supposed to work with
Solaris make (but likely not tested for a long time), and it should
kind-of work with BSD make, provided one configures with
--disable-dependency-tracking.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200115223610</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-01-15 22:36:10-0400</timestampReceived><subject>[PATCH v4 3/4] Add GOST DSA according to GOST R 34.10-2001/-2012</subject><body>

From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;

Add GOST Digital Signature Algorithms support according to GOST R
34.10-2001/-2012. English translations of these standards are provided
as RFC 5832 and RFC 7091.

Signed-off-by: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;
Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 Makefile.in                     |   4 +-
 ecc-gostdsa-sign.c              | 101 +++++++++++++++++++++
 ecc-gostdsa-verify.c            | 130 +++++++++++++++++++++++++++
 ecc-hash.c                      |  11 +++
 ecc-internal.h                  |   7 ++
 gostdsa-sign.c                  |  74 +++++++++++++++
 gostdsa-verify.c                |  78 ++++++++++++++++
 gostdsa.h                       | 102 +++++++++++++++++++++
 testsuite/.gitignore            |   3 +
 testsuite/.test-rules.make      |   9 ++
 testsuite/Makefile.in           |   4 +-
 testsuite/gostdsa-keygen-test.c | 154 ++++++++++++++++++++++++++++++++
 testsuite/gostdsa-sign-test.c   |  87 ++++++++++++++++++
 testsuite/gostdsa-verify-test.c | 110 +++++++++++++++++++++++
 testsuite/testutils.h           |   1 +
 15 files changed, 873 insertions(+), 2 deletions(-)
 create mode 100644 ecc-gostdsa-sign.c
 create mode 100644 ecc-gostdsa-verify.c
 create mode 100644 gostdsa-sign.c
 create mode 100644 gostdsa-verify.c
 create mode 100644 gostdsa.h
 create mode 100644 testsuite/gostdsa-keygen-test.c
 create mode 100644 testsuite/gostdsa-sign-test.c
 create mode 100644 testsuite/gostdsa-verify-test.c

diff --git a/Makefile.in b/Makefile.in
index a08dfe4da481..1396e2fe2808 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -189,6 +189,8 @@ hogweed_SOURCES = sexp.c sexp-format.c \
 		  ecc-point.c ecc-scalar.c ecc-point-mul.c ecc-point-mul-g.c \
 		  ecc-ecdsa-sign.c ecdsa-sign.c \
 		  ecc-ecdsa-verify.c ecdsa-verify.c ecdsa-keygen.c \
+		  ecc-gostdsa-sign.c gostdsa-sign.c \
+		  ecc-gostdsa-verify.c gostdsa-verify.c \
 		  curve25519-mul-g.c curve25519-mul.c curve25519-eh-to-x.c \
 		  curve448-mul-g.c curve448-mul.c curve448-eh-to-x.c \
 		  eddsa-compress.c eddsa-decompress.c eddsa-expand.c \
@@ -205,7 +207,7 @@ HEADERS = aes.h arcfour.h arctwo.h asn1.h blowfish.h \
 	  cbc.h ccm.h cfb.h chacha.h chacha-poly1305.h ctr.h \
 	  curve25519.h curve448.h des.h dsa.h dsa-compat.h eax.h \
 	  ecc-curve.h ecc.h ecdsa.h eddsa.h \
-	  gcm.h gost28147.h gosthash94.h hmac.h \
+	  gcm.h gost28147.h gostdsa.h gosthash94.h hmac.h \
 	  knuth-lfib.h hkdf.h \
 	  macros.h \
 	  cmac.h siv-cmac.h \
diff --git a/ecc-gostdsa-sign.c b/ecc-gostdsa-sign.c
new file mode 100644
index 000000000000..00eeef81f659
--- /dev/null
+++ b/ecc-gostdsa-sign.c
@@ -0,0 +1,101 @@
+/* ecc-gostdsa-sign.c
+
+   Copyright (C) 2015 Dmitry Eremin-Solenikov
+   Copyright (C) 2013, 2014 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;stdlib.h&gt;
+
+#include "gostdsa.h"
+#include "ecc-internal.h"
+
+/* Low-level GOST DSA signing */
+
+mp_size_t
+ecc_gostdsa_sign_itch (const struct ecc_curve *ecc)
+{
+  /* Needs 3*ecc-&gt;p.size + scratch for ecc-&gt;mul_g. Currently same for
+     ecc_mul_g and ecc_mul_g_eh. */
+  return ECC_GOSTDSA_SIGN_ITCH (ecc-&gt;p.size);
+}
+
+/* NOTE: Caller should check if r or s is zero. */
+void
+ecc_gostdsa_sign (const struct ecc_curve *ecc,
+		const mp_limb_t *zp,
+		const mp_limb_t *kp,
+		size_t length, const uint8_t *digest,
+		mp_limb_t *rp, mp_limb_t *sp,
+		mp_limb_t *scratch)
+{
+#define P	    scratch
+#define hp	    (scratch + 4*ecc-&gt;p.size)
+#define tp	    (scratch + 2*ecc-&gt;p.size)
+#define t2p	    scratch
+  /* Procedure, according to GOST 34.10. q denotes the group
+     order.
+
+     1. k &lt;-- uniformly random, 0 &lt; k &lt; q
+
+     2. C &lt;-- (c_x, c_y) = k g
+
+     3. r &lt;-- c_x mod q
+
+     4. s &lt;-- (r*z + k*h) mod q.
+  */
+
+  ecc-&gt;mul_g (ecc, P, kp, P + 3*ecc-&gt;p.size);
+  /* x coordinate only, modulo q */
+  ecc-&gt;h_to_a (ecc, 2, rp, P, P + 3*ecc-&gt;p.size);
+
+  /* Process hash digest */
+  gost_hash (&amp;ecc-&gt;q, hp, length, digest);
+  if (mpn_zero_p (hp, ecc-&gt;p.size))
+    mpn_add_1 (hp, hp, ecc-&gt;p.size, 1);
+
+  ecc_modq_mul (ecc, tp, rp, zp);
+  ecc_modq_mul (ecc, t2p, kp, hp);
+  ecc_modq_add (ecc, sp, tp, t2p);
+
+  /* Also reduce mod ecc-&gt;q. It should already be &lt; 2*ecc-&gt;q,
+   * so one subtraction should suffice. */
+
+  *scratch = mpn_sub_n (tp, sp, ecc-&gt;q.m, ecc-&gt;p.size);
+  cnd_copy (*scratch == 0, sp, tp, ecc-&gt;p.size);
+
+#undef P
+#undef hp
+#undef tp
+#undef t2p
+}
diff --git a/ecc-gostdsa-verify.c b/ecc-gostdsa-verify.c
new file mode 100644
index 000000000000..4358132b2bf6
--- /dev/null
+++ b/ecc-gostdsa-verify.c
@@ -0,0 +1,130 @@
+/* ecc-gostdsa-verify.c
+
+   Copyright (C) 2015 Dmitry Eremin-Solenikov
+   Copyright (C) 2013, 2014 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;stdlib.h&gt;
+
+#include "gostdsa.h"
+#include "ecc-internal.h"
+
+/* Low-level GOST DSA verify */
+
+static int
+ecdsa_in_range (const struct ecc_curve *ecc, const mp_limb_t *xp)
+{
+  return !mpn_zero_p (xp, ecc-&gt;p.size)
+    &amp;&amp; mpn_cmp (xp, ecc-&gt;q.m, ecc-&gt;p.size) &lt; 0;
+}
+
+mp_size_t
+ecc_gostdsa_verify_itch (const struct ecc_curve *ecc)
+{
+  /* Largest storage need is for the ecc-&gt;mul call. */
+  return 5*ecc-&gt;p.size + ecc-&gt;mul_itch;
+}
+
+/* FIXME: Use faster primitives, not requiring side-channel silence. */
+int
+ecc_gostdsa_verify (const struct ecc_curve *ecc,
+		  const mp_limb_t *pp, /* Public key */
+		  size_t length, const uint8_t *digest,
+		  const mp_limb_t *rp, const mp_limb_t *sp,
+		  mp_limb_t *scratch)
+{
+  /* Procedure, according to GOST R 34.10. q denotes the group
+     order.
+
+     1. Check 0 &lt; r, s &lt; q.
+
+     2. v &lt;-- h^{-1}  (mod q)
+
+     3. z1  &lt;-- s * v (mod q)
+
+     4. z2  &lt;-- -r * v (mod q)
+
+     5. R = u1 G + u2 Y
+
+     6. Signature is valid if R_x = r (mod q).
+  */
+
+#define hp (scratch)
+#define vp (scratch + ecc-&gt;p.size)
+#define z1 (scratch + 3*ecc-&gt;p.size)
+#define z2 (scratch + 4*ecc-&gt;p.size)
+
+#define P1 (scratch + 4*ecc-&gt;p.size)
+#define P2 (scratch)
+
+
+  if (! (ecdsa_in_range (ecc, rp)
+	 &amp;&amp; ecdsa_in_range (ecc, sp)))
+    return 0;
+
+  gost_hash (&amp;ecc-&gt;q, hp, length, digest);
+
+  if (mpn_zero_p (hp, ecc-&gt;p.size))
+    mpn_add_1 (hp, hp, ecc-&gt;p.size, 1);
+
+  /* Compute v */
+  ecc-&gt;q.invert (&amp;ecc-&gt;q, vp, hp, vp + 2*ecc-&gt;p.size);
+
+  /* z1 = s / h, P1 = z1 * G */
+  ecc_modq_mul (ecc, z1, sp, vp);
+
+  /* z2 = - r / h, P2 = z2 * Y */
+  ecc_modq_mul (ecc, z2, rp, vp);
+  mpn_sub_n (z2, ecc-&gt;q.m, z2, ecc-&gt;p.size);
+
+   /* Total storage: 5*ecc-&gt;p.size + ecc-&gt;mul_itch */
+  ecc-&gt;mul (ecc, P2, z2, pp, z2 + ecc-&gt;p.size);
+
+  /* Total storage: 7*ecc-&gt;p.size + ecc-&gt;mul_g_itch (ecc-&gt;p.size) */
+  ecc-&gt;mul_g (ecc, P1, z1, P1 + 3*ecc-&gt;p.size);
+
+  /* Total storage: 6*ecc-&gt;p.size + ecc-&gt;add_hhh_itch */
+  ecc-&gt;add_hhh (ecc, P1, P1, P2, P1 + 3*ecc-&gt;p.size);
+
+  /* x coordinate only, modulo q */
+  ecc-&gt;h_to_a (ecc, 2, P2, P1, P1 + 3*ecc-&gt;p.size);
+
+  return (mpn_cmp (rp, P2, ecc-&gt;p.size) == 0);
+#undef P2
+#undef P1
+#undef z2
+#undef z1
+#undef hp
+#undef vp
+}
diff --git a/ecc-hash.c b/ecc-hash.c
index 4e830a514ac4..07877110263f 100644
--- a/ecc-hash.c
+++ b/ecc-hash.c
@@ -62,3 +62,14 @@ ecc_hash (const struct ecc_modulo *m,
     /* We got a few extra bits, at the low end. Discard them. */
     mpn_rshift (hp, hp, m-&gt;size + 1, 8*length - m-&gt;bit_size);
 }
+
+void
+gost_hash (const struct ecc_modulo *m,
+	   mp_limb_t *hp,
+	   size_t length, const uint8_t *digest)
+{
+  if (length &gt; ((size_t) m-&gt;bit_size + 7) / 8)
+    length = (m-&gt;bit_size + 7) / 8;
+
+  mpn_set_base256_le (hp, m-&gt;size + 1, digest, length);
+}
diff --git a/ecc-internal.h b/ecc-internal.h
index cef1366545e0..0022e0ab6cc2 100644
--- a/ecc-internal.h
+++ b/ecc-internal.h
@@ -53,6 +53,7 @@
 #define ecc_mod _nettle_ecc_mod
 #define ecc_mod_inv _nettle_ecc_mod_inv
 #define ecc_hash _nettle_ecc_hash
+#define gost_hash _nettle_gost_hash
 #define ecc_a_to_j _nettle_ecc_a_to_j
 #define ecc_j_to_a _nettle_ecc_j_to_a
 #define ecc_eh_to_a _nettle_ecc_eh_to_a
@@ -288,6 +289,11 @@ ecc_hash (const struct ecc_modulo *m,
 	  mp_limb_t *hp,
 	  size_t length, const uint8_t *digest);
 
+void
+gost_hash (const struct ecc_modulo *m,
+	  mp_limb_t *hp,
+	  size_t length, const uint8_t *digest);
+
 /* Converts a point P in affine coordinates into a point R in jacobian
    coordinates. */
 void
@@ -456,6 +462,7 @@ curve448_eh_to_x (mp_limb_t *xp, const mp_limb_t *p,
 #endif
 #define ECC_MUL_M_ITCH(size) (11*(size))
 #define ECC_ECDSA_SIGN_ITCH(size) (12*(size))
+#define ECC_GOSTDSA_SIGN_ITCH(size) (12*(size))
 #define ECC_MOD_RANDOM_ITCH(size) (size)
 #define ECC_HASH_ITCH(size) (1+(size))
 
diff --git a/gostdsa-sign.c b/gostdsa-sign.c
new file mode 100644
index 000000000000..892c0742c898
--- /dev/null
+++ b/gostdsa-sign.c
@@ -0,0 +1,74 @@
+/* gostdsa-sign.c
+
+   Copyright (C) 2015 Dmitry Eremin-Solenikov
+   Copyright (C) 2013 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;stdlib.h&gt;
+
+#include "gostdsa.h"
+#include "ecc-internal.h"
+#include "nettle-internal.h"
+
+void
+gostdsa_sign (const struct ecc_scalar *key,
+	    void *random_ctx, nettle_random_func *random,
+	    size_t digest_length,
+	    const uint8_t *digest,
+	    struct dsa_signature *signature)
+{
+  /* At most 936 bytes. */
+  TMP_DECL(k, mp_limb_t, ECC_MAX_SIZE + ECC_GOSTDSA_SIGN_ITCH (ECC_MAX_SIZE));
+  mp_limb_t size = key-&gt;ecc-&gt;p.size;
+  mp_limb_t *rp = mpz_limbs_write (signature-&gt;r, size);
+  mp_limb_t *sp = mpz_limbs_write (signature-&gt;s, size);
+
+  TMP_ALLOC (k, size + ECC_GOSTDSA_SIGN_ITCH (size));
+
+  /* Timing reveals the number of rounds through this loop, but the
+     timing is still independent of the secret k finally used. */
+  do
+    {
+      do
+        {
+          ecc_mod_random (&amp;key-&gt;ecc-&gt;q, k, random_ctx, random, k + size);
+	}
+      while (mpn_zero_p(k, size));
+      ecc_gostdsa_sign (key-&gt;ecc, key-&gt;p, k, digest_length, digest,
+		   rp, sp, k + size);
+      mpz_limbs_finish (signature-&gt;r, size);
+      mpz_limbs_finish (signature-&gt;s, size);
+    }
+  while (mpz_sgn (signature-&gt;r) == 0 || mpz_sgn (signature-&gt;s) == 0);
+}
diff --git a/gostdsa-verify.c b/gostdsa-verify.c
new file mode 100644
index 000000000000..7dc1bec1ef62
--- /dev/null
+++ b/gostdsa-verify.c
@@ -0,0 +1,78 @@
+/* gostdsa-verify.c
+
+   Copyright (C) 2015 Dmitry Eremin-Solenikov
+   Copyright (C) 2013 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;stdlib.h&gt;
+
+#include "gostdsa.h"
+
+#include "gmp-glue.h"
+
+int
+gostdsa_verify (const struct ecc_point *pub,
+	      size_t length, const uint8_t *digest,
+	      const struct dsa_signature *signature)
+{
+  mp_limb_t size = ecc_size (pub-&gt;ecc);
+  mp_size_t itch = 2*size + ecc_gostdsa_verify_itch (pub-&gt;ecc);
+  /* For ECC_MUL_A_WBITS == 0, at most 1512 bytes. With
+     ECC_MUL_A_WBITS == 4, currently needs 67 * ecc-&gt;size, at most
+     4824 bytes. Don't use stack allocation for this. */
+  mp_limb_t *scratch;
+  int res;
+
+#define rp scratch
+#define sp (scratch + size)
+#define scratch_out (scratch + 2*size)
+
+  if (mpz_sgn (signature-&gt;r) &lt;= 0 || mpz_size (signature-&gt;r) &gt; size
+      || mpz_sgn (signature-&gt;s) &lt;= 0 || mpz_size (signature-&gt;s) &gt; size)
+    return 0;
+
+  scratch = gmp_alloc_limbs (itch);
+
+  mpz_limbs_copy (rp, signature-&gt;r, size);
+  mpz_limbs_copy (sp, signature-&gt;s, size);
+
+  res = ecc_gostdsa_verify (pub-&gt;ecc, pub-&gt;p, length, digest, rp, sp, scratch_out);
+
+  gmp_free_limbs (scratch, itch);
+
+  return res;
+#undef rp
+#undef sp
+#undef scratch_out
+}
diff --git a/gostdsa.h b/gostdsa.h
new file mode 100644
index 000000000000..b34533436f72
--- /dev/null
+++ b/gostdsa.h
@@ -0,0 +1,102 @@
+/* gostdsa.h
+
+   Copyright (C) 2015 Dmity Eremin-Solenikov
+   Copyright (C) 2013 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+/* Development of Nettle's ECC support was funded by the .SE Internet Fund. */
+
+#ifndef NETTLE_GOSTDSA_H_INCLUDED
+#define NETTLE_GOSTDSA_H_INCLUDED
+
+#include "ecc.h"
+#include "dsa.h"
+#include "ecdsa.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/* Name mangling */
+#define gostdsa_sign nettle_gostdsa_sign
+#define gostdsa_verify nettle_gostdsa_verify
+#define ecc_gostdsa_sign nettle_ecc_gostdsa_sign
+#define ecc_gostdsa_sign_itch nettle_ecc_gostdsa_sign_itch
+#define ecc_gostdsa_verify nettle_ecc_gostdsa_verify
+#define ecc_gostdsa_verify_itch nettle_ecc_gostdsa_verify_itch
+
+/* Just use ECDSA function for key generation */
+#define gostdsa_generate_keypair ecdsa_generate_keypair
+
+/* High level GOST DSA functions.
+ *
+ * A public key is represented as a struct ecc_point, and a private
+ * key as a struct ecc_scalar. FIXME: Introduce some aliases? */
+void
+gostdsa_sign (const struct ecc_scalar *key,
+	      void *random_ctx, nettle_random_func *random,
+	      size_t digest_length,
+	      const uint8_t *digest,
+	      struct dsa_signature *signature);
+
+int
+gostdsa_verify (const struct ecc_point *pub,
+	        size_t length, const uint8_t *digest,
+	        const struct dsa_signature *signature);
+
+/* Low-level GOSTDSA functions. */
+mp_size_t
+ecc_gostdsa_sign_itch (const struct ecc_curve *ecc);
+
+void
+ecc_gostdsa_sign (const struct ecc_curve *ecc,
+		const mp_limb_t *zp,
+		/* Random nonce, must be invertible mod ecc group
+		   order. */
+		const mp_limb_t *kp,
+		size_t length, const uint8_t *digest,
+		mp_limb_t *rp, mp_limb_t *sp,
+		mp_limb_t *scratch);
+
+mp_size_t
+ecc_gostdsa_verify_itch (const struct ecc_curve *ecc);
+
+int
+ecc_gostdsa_verify (const struct ecc_curve *ecc,
+		  const mp_limb_t *pp, /* Public key */
+		  size_t length, const uint8_t *digest,
+		  const mp_limb_t *rp, const mp_limb_t *sp,
+		  mp_limb_t *scratch);
+
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* NETTLE_GOSTDSA_H_INCLUDED */
diff --git a/testsuite/.gitignore b/testsuite/.gitignore
index 1e2a69a60c13..be3a48707580 100644
--- a/testsuite/.gitignore
+++ b/testsuite/.gitignore
@@ -43,6 +43,9 @@
 /eddsa-sign-test
 /eddsa-verify-test
 /gcm-test
+/gostdsa-keygen-test
+/gostdsa-sign-test
+/gostdsa-verify-test
 /gosthash94-test
 /hkdf-test
 /hmac-test
diff --git a/testsuite/.test-rules.make b/testsuite/.test-rules.make
index 6dbef7e24a27..9fd11fd6d126 100644
--- a/testsuite/.test-rules.make
+++ b/testsuite/.test-rules.make
@@ -289,6 +289,15 @@ ed25519-test$(EXEEXT): ed25519-test.$(OBJEXT)
 ed448-test$(EXEEXT): ed448-test.$(OBJEXT)
 	$(LINK) ed448-test.$(OBJEXT) $(TEST_OBJS) -o ed448-test$(EXEEXT)
 
+gostdsa-sign-test$(EXEEXT): gostdsa-sign-test.$(OBJEXT)
+	$(LINK) gostdsa-sign-test.$(OBJEXT) $(TEST_OBJS) -o gostdsa-sign-test$(EXEEXT)
+
+gostdsa-verify-test$(EXEEXT): gostdsa-verify-test.$(OBJEXT)
+	$(LINK) gostdsa-verify-test.$(OBJEXT) $(TEST_OBJS) -o gostdsa-verify-test$(EXEEXT)
+
+gostdsa-keygen-test$(EXEEXT): gostdsa-keygen-test.$(OBJEXT)
+	$(LINK) gostdsa-keygen-test.$(OBJEXT) $(TEST_OBJS) -o gostdsa-keygen-test$(EXEEXT)
+
 sha1-huge-test$(EXEEXT): sha1-huge-test.$(OBJEXT)
 	$(LINK) sha1-huge-test.$(OBJEXT) $(TEST_OBJS) -o sha1-huge-test$(EXEEXT)
 
diff --git a/testsuite/Makefile.in b/testsuite/Makefile.in
index 97128040912e..860394d3bea5 100644
--- a/testsuite/Makefile.in
+++ b/testsuite/Makefile.in
@@ -53,7 +53,9 @@ TS_HOGWEED_SOURCES = sexp-test.c sexp-format-test.c \
 		     ecdsa-sign-test.c ecdsa-verify-test.c \
 		     ecdsa-keygen-test.c ecdh-test.c \
 		     eddsa-compress-test.c eddsa-sign-test.c \
-		     eddsa-verify-test.c ed25519-test.c ed448-test.c
+		     eddsa-verify-test.c ed25519-test.c ed448-test.c \
+		     gostdsa-sign-test.c gostdsa-verify-test.c \
+		     gostdsa-keygen-test.c
 
 TS_SOURCES = $(TS_NETTLE_SOURCES) $(TS_HOGWEED_SOURCES)
 CXX_SOURCES = cxx-test.cxx
diff --git a/testsuite/gostdsa-keygen-test.c b/testsuite/gostdsa-keygen-test.c
new file mode 100644
index 000000000000..f34ff485ad6b
--- /dev/null
+++ b/testsuite/gostdsa-keygen-test.c
@@ -0,0 +1,154 @@
+#include "testutils.h"
+#include "knuth-lfib.h"
+
+/* Check if y^2 = x^3 - 3x + b */
+static int
+ecc_valid_p (struct ecc_point *pub)
+{
+  mpz_t t, x, y;
+  mpz_t lhs, rhs;
+  int res;
+  mp_size_t size;
+
+  size = pub-&gt;ecc-&gt;p.size;
+
+  /* First check range */
+  if (mpn_cmp (pub-&gt;p, pub-&gt;ecc-&gt;p.m, size) &gt;= 0
+      || mpn_cmp (pub-&gt;p + size, pub-&gt;ecc-&gt;p.m, size) &gt;= 0)
+    return 0;
+
+  mpz_init (lhs);
+  mpz_init (rhs);
+
+  mpz_roinit_n (x, pub-&gt;p, size);
+  mpz_roinit_n (y, pub-&gt;p + size, size);
+
+  mpz_mul (lhs, y, y);
+
+  if (pub-&gt;ecc-&gt;p.bit_size == 255)
+    {
+      /* Check that
+	 121666 (1 + x^2 - y^2) = 121665 x^2 y^2 */
+      mpz_t x2;
+      mpz_init (x2);
+      mpz_mul (x2, x, x); /* x^2 */
+      mpz_mul (rhs, x2, lhs); /* x^2 y^2 */
+      mpz_sub (lhs, x2, lhs); /* x^2 - y^2 */
+      mpz_add_ui (lhs, lhs, 1); /* 1 + x^2 - y^2 */
+      mpz_mul_ui (lhs, lhs, 121666);
+      mpz_mul_ui (rhs, rhs, 121665);
+
+      mpz_clear (x2);
+    }
+  else if (pub-&gt;ecc-&gt;p.bit_size == 448)
+    {
+      /* Check that
+	 x^2 + y^2 = 1 - 39081 x^2 y^2 */
+      mpz_t x2, d;
+      mpz_init (x2);
+      mpz_init_set_ui (d, 39081);
+      mpz_mul (x2, x, x); /* x^2 */
+      mpz_mul (d, d, x2); /* 39081 x^2 */
+      mpz_set_ui (rhs, 1);
+      mpz_submul (rhs, d, lhs); /* 1 - 39081 x^2 y^2 */
+      mpz_add (lhs, x2, lhs);	/* x^2 + y^2 */
+
+      mpz_clear (d);
+      mpz_clear (x2);
+    }
+  else
+    {
+      /* Check y^2 = x^3 - 3 x + b */
+      mpz_mul (rhs, x, x);
+      mpz_sub_ui (rhs, rhs, 3);
+      mpz_mul (rhs, rhs, x);
+      mpz_add (rhs, rhs, mpz_roinit_n (t, pub-&gt;ecc-&gt;b, size));
+    }
+  res = mpz_congruent_p (lhs, rhs, mpz_roinit_n (t, pub-&gt;ecc-&gt;p.m, size));
+
+  mpz_clear (lhs);
+  mpz_clear (rhs);
+
+  return res;
+}
+
+void
+test_main (void)
+{
+  unsigned i;
+  struct knuth_lfib_ctx rctx;
+  struct dsa_signature signature;
+
+  struct tstring *digest;
+
+  knuth_lfib_init (&amp;rctx, 4711);
+  dsa_signature_init (&amp;signature);
+
+  digest = SHEX (/* sha256("abc") */
+		 "BA7816BF 8F01CFEA 414140DE 5DAE2223"
+		 "B00361A3 96177A9C B410FF61 F20015AD");
+
+  for (i = 0; ecc_curves[i]; i++)
+    {
+      const struct ecc_curve *ecc = ecc_curves[i];
+      struct ecc_point pub;
+      struct ecc_scalar key;
+
+      if (ecc-&gt;p.bit_size == 255 || ecc-&gt;p.bit_size == 448)
+	/* Exclude curve25519 and curve448, not supported with GOSTDSA. */
+	continue;
+
+      if (verbose)
+	fprintf (stderr, "Curve %d\n", ecc-&gt;p.bit_size);
+
+      ecc_point_init (&amp;pub, ecc);
+      ecc_scalar_init (&amp;key, ecc);
+
+      ecdsa_generate_keypair (&amp;pub, &amp;key,
+			      &amp;rctx,
+			      (nettle_random_func *) knuth_lfib_random);
+
+      if (verbose)
+	{
+	  fprintf (stderr, "Public key:\nx = ");
+	  write_mpn (stderr, 16, pub.p, ecc-&gt;p.size);
+	  fprintf (stderr, "\ny = ");
+	  write_mpn (stderr, 16, pub.p + ecc-&gt;p.size, ecc-&gt;p.size);
+	  fprintf (stderr, "\nPrivate key: ");
+	  write_mpn (stderr, 16, key.p, ecc-&gt;p.size);
+	  fprintf (stderr, "\n");
+	}
+      if (!ecc_valid_p (&amp;pub))
+	die ("gostdsa_generate_keypair produced an invalid point.\n");
+
+      gostdsa_sign (&amp;key,
+		   &amp;rctx, (nettle_random_func *) knuth_lfib_random,
+		   digest-&gt;length, digest-&gt;data,
+		   &amp;signature);
+
+      if (!gostdsa_verify (&amp;pub, digest-&gt;length, digest-&gt;data,
+			   &amp;signature))
+	die ("gostdsa_verify failed.\n");
+
+      digest-&gt;data[3] ^= 17;
+      if (gostdsa_verify (&amp;pub, digest-&gt;length, digest-&gt;data,
+			  &amp;signature))
+	die ("gostdsa_verify  returned success with invalid digest.\n");
+      digest-&gt;data[3] ^= 17;
+
+      mpz_combit (signature.r, 117);
+      if (gostdsa_verify (&amp;pub, digest-&gt;length, digest-&gt;data,
+			  &amp;signature))
+	die ("gostdsa_verify  returned success with invalid signature.r.\n");
+
+      mpz_combit (signature.r, 117);
+      mpz_combit (signature.s, 93);
+      if (gostdsa_verify (&amp;pub, digest-&gt;length, digest-&gt;data,
+			  &amp;signature))
+	die ("gostdsa_verify  returned success with invalid signature.s.\n");
+
+      ecc_point_clear (&amp;pub);
+      ecc_scalar_clear (&amp;key);
+    }
+  dsa_signature_clear (&amp;signature);
+}
diff --git a/testsuite/gostdsa-sign-test.c b/testsuite/gostdsa-sign-test.c
new file mode 100644
index 000000000000..14847393ec8e
--- /dev/null
+++ b/testsuite/gostdsa-sign-test.c
@@ -0,0 +1,87 @@
+#include "testutils.h"
+
+static void
+test_gostdsa (const struct ecc_curve *ecc,
+	    /* Private key */
+	    const char *sz,
+	    /* Random nonce */
+	    const char *sk,
+	    /* Hash */
+	    const struct tstring *h,
+	    /* Expected signature */
+	    const char *r, const char *s)
+{
+  struct dsa_signature ref;
+  mpz_t z;
+  mpz_t k;
+  mp_limb_t *rp = xalloc_limbs (ecc-&gt;p.size);
+  mp_limb_t *sp = xalloc_limbs (ecc-&gt;p.size);
+  mp_limb_t *scratch = xalloc_limbs (ecc_gostdsa_sign_itch (ecc));
+
+  dsa_signature_init (&amp;ref);
+
+  mpz_init_set_str (z, sz, 16);
+  mpz_init_set_str (k, sk, 16);
+
+  ecc_gostdsa_sign (ecc, mpz_limbs_read_n (z, ecc-&gt;p.size),
+		  mpz_limbs_read_n (k, ecc-&gt;p.size),
+		  h-&gt;length, h-&gt;data, rp, sp, scratch);
+
+  mpz_set_str (ref.r, r, 16);
+  mpz_set_str (ref.s, s, 16);
+
+  if (mpz_limbs_cmp (ref.r, rp, ecc-&gt;p.size) != 0
+      || mpz_limbs_cmp (ref.s, sp, ecc-&gt;p.size) != 0)
+    {
+      fprintf (stderr, "_gostdsa_sign failed, bit_size = %u\n", ecc-&gt;p.bit_size);
+      fprintf (stderr, "r     = ");
+      write_mpn (stderr, 16, rp, ecc-&gt;p.size);
+      fprintf (stderr, "\ns     = ");
+      write_mpn (stderr, 16, sp, ecc-&gt;p.size);
+      fprintf (stderr, "\nref.r = ");
+      mpz_out_str (stderr, 16, ref.r);
+      fprintf (stderr, "\nref.s = ");
+      mpz_out_str (stderr, 16, ref.s);
+      fprintf (stderr, "\n");
+      abort();
+    }
+
+  free (rp);
+  free (sp);
+  free (scratch);
+
+  dsa_signature_clear (&amp;ref);
+  mpz_clear (k);
+  mpz_clear (z);
+}
+
+void
+test_main (void)
+{
+  test_gostdsa (nettle_get_gost_gc256b(),
+	      "BFCF1D623E5CDD3032A7C6EABB4A923C46E43D640FFEAAF2C3ED39A8FA399924", /* z */
+
+	      "5782C53F110C596F9155D35EBD25A06A89C50391850A8FEFE33B0E270318857C", /* k */
+
+	      SHEX("1C067E20EA6CB183F22EFB0F3C6FD2A4E6A02821CB7A1B17FACD5E1F7AA76F70"), /* h */
+
+	      "E9323A5E88DD87FB7C724383BFFE7CECD4B9FFA2AC33BEEF73A5A1F743404F6B", /* r */
+
+	      "5E5B9B805B01147A8492C4A162643AC615DC777B9174108F3DC276A41F987AF3"); /* s */
+
+  test_gostdsa (nettle_get_gost_gc512a(),
+	      "3FC01CDCD4EC5F972EB482774C41E66DB7F380528DFE9E67992BA05AEE462435"
+	      "757530E641077CE587B976C8EEB48C48FD33FD175F0C7DE6A44E014E6BCB074B", /* z */
+
+	      "72ABB44536656BF1618CE10BF7EADD40582304A51EE4E2A25A0A32CB0E773ABB"
+	      "23B7D8FDD8FA5EEE91B4AE452F2272C86E1E2221215D405F51B5D5015616E1F6", /* k */
+
+	      SHEX("EDC257BED45FDDE4F1457B7F5B19017A8F204184366689D938532CDBAA5CB29A"
+		   "1D369DA57F8B983BE272219BD2C9A4FC57ECF7A77F34EE2E8AA553976A4766C0"), /* h */
+
+	      "891AA75C2A6F3B4DE27E3903F61CBB0F3F85A4E3C62F39A6E4E84A7477679C6E"
+	      "45008DC2774CA2FF64C12C0606FF918CAE3A50115440E9BF2971B627A882A1E8", /* r */
+
+	      "31065479996DDBDEE180AFE22CA3CDC44B45CE4C6C83909D1D3B702922A32441"
+	      "A9E11DCFBEA3D847C06B1A8A38EB1671D6C82FA21B79C99BE2EA809B10DAA5DF"); /* s */
+}
diff --git a/testsuite/gostdsa-verify-test.c b/testsuite/gostdsa-verify-test.c
new file mode 100644
index 000000000000..42fe2ebb090b
--- /dev/null
+++ b/testsuite/gostdsa-verify-test.c
@@ -0,0 +1,110 @@
+#include "testutils.h"
+
+static void
+test_gostdsa (const struct ecc_curve *ecc,
+	    /* Public key */
+	    const char *xs, const char *ys,
+	    /* Hash */
+	    struct tstring *h,
+	    /* Valid signature */
+	    const char *r, const char *s)
+{
+  struct ecc_point pub;
+  struct dsa_signature signature;
+  mpz_t x, y;
+
+  ecc_point_init (&amp;pub, ecc);
+  dsa_signature_init (&amp;signature);
+
+  mpz_init_set_str (x, xs, 16);
+  mpz_init_set_str (y, ys, 16);
+
+  if (!ecc_point_set (&amp;pub, x, y))
+    die ("ecc_point_set failed.\n");
+
+  mpz_set_str (signature.r, r, 16);
+  mpz_set_str (signature.s, s, 16);
+
+  if (!gostdsa_verify (&amp;pub, h-&gt;length, h-&gt;data, &amp;signature))
+    {
+      fprintf (stderr, "gostdsa_verify failed with valid signature.\n");
+    fail:
+      fprintf (stderr, "bit_size = %u\nx = ", ecc-&gt;p.bit_size);
+      mpz_out_str (stderr, 16, x);
+      fprintf (stderr, "\ny = ");
+      mpz_out_str (stderr, 16, y);
+      fprintf (stderr, "\ndigest ");
+      print_hex (h-&gt;length, h-&gt;data);
+      fprintf (stderr, "r = ");
+      mpz_out_str (stderr, 16, signature.r);
+      fprintf (stderr, "\ns = ");
+      mpz_out_str (stderr, 16, signature.s);
+      fprintf (stderr, "\n");
+      abort();
+    }
+
+  mpz_combit (signature.r, ecc-&gt;p.bit_size / 3);
+  if (gostdsa_verify (&amp;pub, h-&gt;length, h-&gt;data, &amp;signature))
+    {
+      fprintf (stderr, "gostdsa_verify unexpectedly succeeded with invalid signature.\n");
+      goto fail;
+    }
+  mpz_combit (signature.r, ecc-&gt;p.bit_size / 3);
+
+  mpz_combit (signature.s, 4*ecc-&gt;p.bit_size / 5);
+  if (gostdsa_verify (&amp;pub, h-&gt;length, h-&gt;data, &amp;signature))
+    {
+      fprintf (stderr, "gostdsa_verify unexpectedly succeeded with invalid signature.\n");
+      goto fail;
+    }
+  mpz_combit (signature.s, 4*ecc-&gt;p.bit_size / 5);
+
+  h-&gt;data[2*h-&gt;length / 3] ^= 0x40;
+  if (gostdsa_verify (&amp;pub, h-&gt;length, h-&gt;data, &amp;signature))
+    {
+      fprintf (stderr, "gostdsa_verify unexpectedly succeeded with invalid signature.\n");
+      goto fail;
+    }
+  h-&gt;data[2*h-&gt;length / 3] ^= 0x40;
+  if (!gostdsa_verify (&amp;pub, h-&gt;length, h-&gt;data, &amp;signature))
+    {
+      fprintf (stderr, "gostdsa_verify failed, internal testsuite error.\n");
+      goto fail;
+    }
+
+  ecc_point_clear (&amp;pub);
+  dsa_signature_clear (&amp;signature);
+  mpz_clear (x);
+  mpz_clear (y);
+}
+
+void
+test_main (void)
+{
+  test_gostdsa (nettle_get_gost_gc256b(),
+	      "971566CEDA436EE7678F7E07E84EBB7217406C0B4747AA8FD2AB1453C3D0DFBA", /* x */
+
+	      "AD58736965949F8E59830F8DE20FC6C0D177F6AB599874F1E2E24FF71F9CE643", /* y */
+
+	      SHEX("1C067E20EA6CB183F22EFB0F3C6FD2A4E6A02821CB7A1B17FACD5E1F7AA76F70"), /* h */
+
+	      "E9323A5E88DD87FB7C724383BFFE7CECD4B9FFA2AC33BEEF73A5A1F743404F6B", /* r */
+
+	      "5E5B9B805B01147A8492C4A162643AC615DC777B9174108F3DC276A41F987AF3"); /* s */
+
+  test_gostdsa (nettle_get_gost_gc512a(),
+	      "03A36340A95BB5F93D131961B5B1C1B3213DF7FF3B5A30376407E2A65C441BC6"
+	      "D1B34662317083243F007B15A8512B526606D3B172B606DCE86DBD6F82DA3D40", /* x */
+
+	      "DEAD76318012FED79507809C89CC44848743640EAC9A3C847DA9082E050760A1"
+	      "0679F4B707ABC1872640AD20D7441F66C7A8B3BFF1B8E11B4A076F0A86749F73", /* y */
+
+	      SHEX("EDC257BED45FDDE4F1457B7F5B19017A8F204184366689D938532CDBAA5CB29A"
+		   "1D369DA57F8B983BE272219BD2C9A4FC57ECF7A77F34EE2E8AA553976A4766C0"), /* h */
+
+	      "891AA75C2A6F3B4DE27E3903F61CBB0F3F85A4E3C62F39A6E4E84A7477679C6E"
+	      "45008DC2774CA2FF64C12C0606FF918CAE3A50115440E9BF2971B627A882A1E8", /* r */
+
+	      "31065479996DDBDEE180AFE22CA3CDC44B45CE4C6C83909D1D3B702922A32441"
+	      "A9E11DCFBEA3D847C06B1A8A38EB1671D6C82FA21B79C99BE2EA809B10DAA5DF"); /* s */
+}
diff --git a/testsuite/testutils.h b/testsuite/testutils.h
index f4ea38da9deb..cef7f4011a7c 100644
--- a/testsuite/testutils.h
+++ b/testsuite/testutils.h
@@ -22,6 +22,7 @@
 # include "ecc.h"
 # include "ecc-internal.h"
 # include "ecdsa.h"
+# include "gostdsa.h"
 # include "gmp-glue.h"
 # if NETTLE_USE_MINI_GMP
 #  include "knuth-lfib.h"
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200116231052</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-01-16 23:10:52-0400</timestampReceived><subject>[PATCH] hogweed-benchmark: fill 32 or 56 bytes rather than just sizeof(int)</subject><body>

From: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;

Don't call sizeof(CURVExyz_SIZE) to get amount of bytes to fill. Just
use CURVExyz_SIZE itself.

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 examples/hogweed-benchmark.c | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/examples/hogweed-benchmark.c b/examples/hogweed-benchmark.c
index 11393df04c81..69315211a0cc 100644
--- a/examples/hogweed-benchmark.c
+++ b/examples/hogweed-benchmark.c
@@ -771,12 +771,12 @@ bench_curve_init (unsigned size)
     case 255:
       ctx-&gt;mul = curve25519_mul;
       ctx-&gt;mul_g = curve25519_mul_g;
-      knuth_lfib_random (&amp;lfib, sizeof(CURVE25519_SIZE), ctx-&gt;s);
+      knuth_lfib_random (&amp;lfib, CURVE25519_SIZE, ctx-&gt;s);
       break;
     case 448:
       ctx-&gt;mul = curve448_mul;
       ctx-&gt;mul_g = curve448_mul_g;
-      knuth_lfib_random (&amp;lfib, sizeof(CURVE448_SIZE), ctx-&gt;s);
+      knuth_lfib_random (&amp;lfib, CURVE448_SIZE, ctx-&gt;s);
       break;
     default:
       abort ();
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200125192111</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-25 19:21:11-0400</timestampReceived><subject>Problem with gitlab CI</subject><body>

Hi,

it seems some of the recent gitlab ci jobs for some reason run on some
windows infrastructure. I can see that might be useful for some
projects, if you want to support and test native windows builds or
something. But for Nettle, it's neither helpful nor working, e.g.,

https://gitlab.com/gnutls/nettle/-/jobs/414926707

fails because build scripts are running in some windows shell not
recognizing a /bin/sh for loop.

Can we add some "Windows? Just say no!" in nettle/.gitlab-ci.yml, to get
it back in working shape? Or do some higher-level config for the gnutls
project on gitlab?

Regards,
/Niels
-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200127094945</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-01-27 09:49:45-0400</timestampReceived><subject>[PATCH 1/2] Change ecc_mod_*mul_1 to be per-module callbacks</subject><body>

From: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;

GOST curves will require different "fixups" for fast (mul X mod p)
operations. Move these operations to ecc_modulo structure and call them
via function pointer.

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 ecc-curve25519.c  |  8 ++++++++
 ecc-curve448.c    |  8 ++++++++
 ecc-gost-gc256b.c |  8 ++++++++
 ecc-gost-gc512a.c |  8 ++++++++
 ecc-internal.h    | 32 ++++++++++++++++++++------------
 ecc-mod-arith.c   | 12 ++++++------
 ecc-mul-m.c       |  6 +++---
 ecc-secp192r1.c   |  8 ++++++++
 ecc-secp224r1.c   |  8 ++++++++
 ecc-secp256r1.c   |  8 ++++++++
 ecc-secp384r1.c   |  8 ++++++++
 ecc-secp521r1.c   |  8 ++++++++
 12 files changed, 101 insertions(+), 21 deletions(-)

diff --git a/ecc-curve25519.c b/ecc-curve25519.c
index 0ad3017c9ebc..4ee80c8d4463 100644
--- a/ecc-curve25519.c
+++ b/ecc-curve25519.c
@@ -310,6 +310,10 @@ const struct ecc_curve _nettle_curve25519 =
     ecc_curve25519_modp,
     ecc_curve25519_inv,
     ecc_curve25519_sqrt,
+
+    ecc_mod_mul_1_std,
+    ecc_mod_addmul_1_std,
+    ecc_mod_submul_1_std,
   },
   {
     253,
@@ -329,6 +333,10 @@ const struct ecc_curve _nettle_curve25519 =
     ecc_curve25519_modq,
     ecc_mod_inv,
     NULL,
+
+    NULL,
+    NULL,
+    NULL,
   },
 
   0, /* No redc */
diff --git a/ecc-curve448.c b/ecc-curve448.c
index c31a0eb26ba4..71634b855af8 100644
--- a/ecc-curve448.c
+++ b/ecc-curve448.c
@@ -288,6 +288,10 @@ const struct ecc_curve _nettle_curve448 =
     ecc_curve448_modp,
     ecc_curve448_inv,
     ecc_curve448_sqrt,
+
+    ecc_mod_mul_1_std,
+    ecc_mod_addmul_1_std,
+    ecc_mod_submul_1_std,
   },
   {
     446,
@@ -307,6 +311,10 @@ const struct ecc_curve _nettle_curve448 =
     ecc_mod,	      /* FIXME: Implement optimized reduce function */
     ecc_mod_inv,
     NULL,
+
+    NULL,
+    NULL,
+    NULL,
   },
 
   0, /* No redc */
diff --git a/ecc-gost-gc256b.c b/ecc-gost-gc256b.c
index 8adc8e1763b9..acf3b56c8955 100644
--- a/ecc-gost-gc256b.c
+++ b/ecc-gost-gc256b.c
@@ -77,6 +77,10 @@ const struct ecc_curve _nettle_gost_gc256b =
     ecc_gost_gc256b_modp,
     ecc_mod_inv,
     NULL,
+
+    ecc_mod_mul_1_std,
+    ecc_mod_addmul_1_std,
+    ecc_mod_submul_1_std,
   },
   {
     256,
@@ -96,6 +100,10 @@ const struct ecc_curve _nettle_gost_gc256b =
     ecc_gost_gc256b_modq,
     ecc_mod_inv,
     NULL,
+
+    NULL,
+    NULL,
+    NULL,
   },
 
   USE_REDC,
diff --git a/ecc-gost-gc512a.c b/ecc-gost-gc512a.c
index 6d210925b609..79d084f38d33 100644
--- a/ecc-gost-gc512a.c
+++ b/ecc-gost-gc512a.c
@@ -77,6 +77,10 @@ const struct ecc_curve _nettle_gost_gc512a =
     ecc_gost_gc512a_modp,
     ecc_mod_inv,
     NULL,
+
+    ecc_mod_mul_1_std,
+    ecc_mod_addmul_1_std,
+    ecc_mod_submul_1_std,
   },
   {
     512,
@@ -96,6 +100,10 @@ const struct ecc_curve _nettle_gost_gc512a =
     ecc_gost_gc512a_modq,
     ecc_mod_inv,
     NULL,
+
+    NULL,
+    NULL,
+    NULL,
   },
 
   USE_REDC,
diff --git a/ecc-internal.h b/ecc-internal.h
index 0022e0ab6cc2..ddeb6d3cb1f3 100644
--- a/ecc-internal.h
+++ b/ecc-internal.h
@@ -44,9 +44,9 @@
 #define ecc_pm1_redc _nettle_ecc_pm1_redc
 #define ecc_mod_add _nettle_ecc_mod_add
 #define ecc_mod_sub _nettle_ecc_mod_sub
-#define ecc_mod_mul_1 _nettle_ecc_mod_mul_1
-#define ecc_mod_addmul_1 _nettle_ecc_mod_addmul_1
-#define ecc_mod_submul_1 _nettle_ecc_mod_submul_1
+#define ecc_mod_mul_1_std _nettle_ecc_mod_mul_1_std
+#define ecc_mod_addmul_1_std _nettle_ecc_mod_addmul_1_std
+#define ecc_mod_submul_1_std _nettle_ecc_mod_submul_1_std
 #define ecc_mod_mul _nettle_ecc_mod_mul
 #define ecc_mod_sqr _nettle_ecc_mod_sqr
 #define ecc_mod_random _nettle_ecc_mod_random
@@ -146,6 +146,10 @@ typedef void ecc_h_to_a_func (const struct ecc_curve *ecc,
 			      mp_limb_t *r, const mp_limb_t *p,
 			      mp_limb_t *scratch);
 
+typedef void ecc_mod_mul_1_func (const struct ecc_modulo *m,
+				 mp_limb_t *rp,
+				 const mp_limb_t *ap, mp_limb_t b);
+
 struct ecc_modulo
 {
   unsigned short bit_size;
@@ -170,6 +174,10 @@ struct ecc_modulo
   ecc_mod_func *reduce;
   ecc_mod_inv_func *invert;
   ecc_mod_sqrt_func *sqrt;
+
+  ecc_mod_mul_1_func *mul_1;
+  ecc_mod_mul_1_func *addmul_1;
+  ecc_mod_mul_1_func *submul_1;
 };
 
 /* Represents an elliptic curve of the form
@@ -240,15 +248,15 @@ ecc_mod_sub (const struct ecc_modulo *m, mp_limb_t *rp,
 	     const mp_limb_t *ap, const mp_limb_t *bp);
 
 void
-ecc_mod_mul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
-	       const mp_limb_t *ap, const mp_limb_t b);
+ecc_mod_mul_1_std (const struct ecc_modulo *m, mp_limb_t *rp,
+		   const mp_limb_t *ap, const mp_limb_t b);
 
 void
-ecc_mod_addmul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
-		  const mp_limb_t *ap, mp_limb_t b);
+ecc_mod_addmul_1_std (const struct ecc_modulo *m, mp_limb_t *rp,
+		      const mp_limb_t *ap, mp_limb_t b);
 void
-ecc_mod_submul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
-		  const mp_limb_t *ap, mp_limb_t b);
+ecc_mod_submul_1_std (const struct ecc_modulo *m, mp_limb_t *rp,
+		      const mp_limb_t *ap, mp_limb_t b);
 
 /* The mul and sqr functions need 2*m-&gt;size limbs at rp */
 void
@@ -264,11 +272,11 @@ ecc_mod_sqr (const struct ecc_modulo *m, mp_limb_t *rp,
 #define ecc_modp_sub(ecc, r, a, b) \
   ecc_mod_sub (&amp;(ecc)-&gt;p, (r), (a), (b))
 #define ecc_modp_mul_1(ecc, r, a, b) \
-  ecc_mod_mul_1 (&amp;(ecc)-&gt;p, (r), (a), (b))
+  (ecc)-&gt;p.mul_1 (&amp;(ecc)-&gt;p, (r), (a), (b))
 #define ecc_modp_addmul_1(ecc, r, a, b) \
-  ecc_mod_addmul_1 (&amp;(ecc)-&gt;p, (r), (a), (b))
+  (ecc)-&gt;p.addmul_1 (&amp;(ecc)-&gt;p, (r), (a), (b))
 #define ecc_modp_submul_1(ecc, r, a, b) \
-  ecc_mod_submul_1 (&amp;(ecc)-&gt;p, (r), (a), (b))
+  (ecc)-&gt;p.submul_1 (&amp;(ecc)-&gt;p, (r), (a), (b))
 #define ecc_modp_mul(ecc, r, a, b) \
   ecc_mod_mul (&amp;(ecc)-&gt;p, (r), (a), (b))
 #define ecc_modp_sqr(ecc, r, a) \
diff --git a/ecc-mod-arith.c b/ecc-mod-arith.c
index f2e47f6747c1..0399a2cdd7c5 100644
--- a/ecc-mod-arith.c
+++ b/ecc-mod-arith.c
@@ -65,8 +65,8 @@ ecc_mod_sub (const struct ecc_modulo *m, mp_limb_t *rp,
 }
 
 void
-ecc_mod_mul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
-	       const mp_limb_t *ap, mp_limb_t b)
+ecc_mod_mul_1_std (const struct ecc_modulo *m, mp_limb_t *rp,
+		   const mp_limb_t *ap, mp_limb_t b)
 {
   mp_limb_t hi;
 
@@ -80,8 +80,8 @@ ecc_mod_mul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
 }
 
 void
-ecc_mod_addmul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
-		  const mp_limb_t *ap, mp_limb_t b)
+ecc_mod_addmul_1_std (const struct ecc_modulo *m, mp_limb_t *rp,
+		      const mp_limb_t *ap, mp_limb_t b)
 {
   mp_limb_t hi;
 
@@ -95,8 +95,8 @@ ecc_mod_addmul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
 }
   
 void
-ecc_mod_submul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
-		  const mp_limb_t *ap, mp_limb_t b)
+ecc_mod_submul_1_std (const struct ecc_modulo *m, mp_limb_t *rp,
+		      const mp_limb_t *ap, mp_limb_t b)
 {
   mp_limb_t hi;
 
diff --git a/ecc-mul-m.c b/ecc-mul-m.c
index 68bdd16e8e94..770350162da1 100644
--- a/ecc-mul-m.c
+++ b/ecc-mul-m.c
@@ -80,7 +80,7 @@ ecc_mul_m (const struct ecc_modulo *m,
   ecc_mod_sqr (m, BB, B);
   ecc_mod_mul (m, x3, AA, BB);
   ecc_mod_sub (m, E, AA, BB);
-  ecc_mod_addmul_1 (m, AA, E, a24);
+  m-&gt;addmul_1 (m, AA, E, a24);
   ecc_mod_mul (m, z3, E, AA);
 
   for (i = bit_high; i &gt;= bit_low; i--)
@@ -98,7 +98,7 @@ ecc_mul_m (const struct ecc_modulo *m,
       ecc_mod_sqr (m, BB, B);
       ecc_mod_mul (m, x2, AA, BB); /* Last use of BB */
       ecc_mod_sub (m, E, AA, BB);
-      ecc_mod_addmul_1 (m, AA, E, a24);
+      m-&gt;addmul_1 (m, AA, E, a24);
       ecc_mod_add (m, C, x3, z3);
       ecc_mod_sub (m, D, x3, z3);
       ecc_mod_mul (m, z2, E, AA); /* Last use of E and AA */
@@ -124,7 +124,7 @@ ecc_mul_m (const struct ecc_modulo *m,
       ecc_mod_sqr (m, BB, B);
       ecc_mod_mul (m, x2, AA, BB);
       ecc_mod_sub (m, E, AA, BB);
-      ecc_mod_addmul_1 (m, AA, E, a24);
+      m-&gt;addmul_1 (m, AA, E, a24);
       ecc_mod_mul (m, z2, E, AA);
     }
   assert (m-&gt;invert_itch &lt;= 7 * m-&gt;size);
diff --git a/ecc-secp192r1.c b/ecc-secp192r1.c
index 094074d73ed7..d36be63d7b3a 100644
--- a/ecc-secp192r1.c
+++ b/ecc-secp192r1.c
@@ -130,6 +130,10 @@ const struct ecc_curve _nettle_secp_192r1 =
     ecc_secp192r1_modp,
     ecc_mod_inv,
     NULL,
+
+    ecc_mod_mul_1_std,
+    ecc_mod_addmul_1_std,
+    ecc_mod_submul_1_std,
   },
   {
     192,
@@ -149,6 +153,10 @@ const struct ecc_curve _nettle_secp_192r1 =
     ecc_mod,
     ecc_mod_inv,
     NULL,
+
+    NULL,
+    NULL,
+    NULL,
   },
   
   USE_REDC,
diff --git a/ecc-secp224r1.c b/ecc-secp224r1.c
index e6b43fa61f42..cde02a01fd6d 100644
--- a/ecc-secp224r1.c
+++ b/ecc-secp224r1.c
@@ -82,6 +82,10 @@ const struct ecc_curve _nettle_secp_224r1 =
     USE_REDC ? ecc_secp224r1_redc : ecc_secp224r1_modp,
     ecc_mod_inv,
     NULL,
+
+    ecc_mod_mul_1_std,
+    ecc_mod_addmul_1_std,
+    ecc_mod_submul_1_std,
   },
   {
     224,
@@ -101,6 +105,10 @@ const struct ecc_curve _nettle_secp_224r1 =
     ecc_mod,
     ecc_mod_inv,
     NULL,
+
+    NULL,
+    NULL,
+    NULL,
   },
   
   USE_REDC,
diff --git a/ecc-secp256r1.c b/ecc-secp256r1.c
index 6c776a729aea..e17061ab761c 100644
--- a/ecc-secp256r1.c
+++ b/ecc-secp256r1.c
@@ -259,6 +259,10 @@ const struct ecc_curve _nettle_secp_256r1 =
     USE_REDC ? ecc_secp256r1_redc : ecc_secp256r1_modp,
     ecc_mod_inv,
     NULL,
+
+    ecc_mod_mul_1_std,
+    ecc_mod_addmul_1_std,
+    ecc_mod_submul_1_std,
   },
   {
     256,
@@ -278,6 +282,10 @@ const struct ecc_curve _nettle_secp_256r1 =
     ecc_secp256r1_modq,
     ecc_mod_inv,
     NULL,
+
+    NULL,
+    NULL,
+    NULL,
   },
 
   USE_REDC,
diff --git a/ecc-secp384r1.c b/ecc-secp384r1.c
index c4a75564bf58..cf0cd25e32fb 100644
--- a/ecc-secp384r1.c
+++ b/ecc-secp384r1.c
@@ -167,6 +167,10 @@ const struct ecc_curve _nettle_secp_384r1 =
     ecc_secp384r1_modp,
     ecc_mod_inv,
     NULL,
+
+    ecc_mod_mul_1_std,
+    ecc_mod_addmul_1_std,
+    ecc_mod_submul_1_std,
   },
   {
     384,
@@ -186,6 +190,10 @@ const struct ecc_curve _nettle_secp_384r1 =
     ecc_mod,
     ecc_mod_inv,
     NULL,
+
+    NULL,
+    NULL,
+    NULL,
   },
 
   USE_REDC,
diff --git a/ecc-secp521r1.c b/ecc-secp521r1.c
index 74688008959b..2241e542f927 100644
--- a/ecc-secp521r1.c
+++ b/ecc-secp521r1.c
@@ -95,6 +95,10 @@ const struct ecc_curve _nettle_secp_521r1 =
     ecc_secp521r1_modp,
     ecc_mod_inv,
     NULL,
+
+    ecc_mod_mul_1_std,
+    ecc_mod_addmul_1_std,
+    ecc_mod_submul_1_std,
   },
   {
     521,
@@ -114,6 +118,10 @@ const struct ecc_curve _nettle_secp_521r1 =
     ecc_mod,
     ecc_mod_inv,
     NULL,
+
+    NULL,
+    NULL,
+    NULL,
   },
   
   USE_REDC,
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200118130143</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-01-18 13:01:43-0400</timestampReceived><subject>[PATCH 0/2] two small fixes for ecc-gost branch</subject><body>

Hello,

Two small fixes to go on top of ecc-gost branch. These two patches can
be squashed into respective patches or just live as separate instances,
whatever you would prefer.

-- 
With best wishes
Dmitry


_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200125155443</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-25 15:54:43-0400</timestampReceived><subject>Re: Current ECC work</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; 1. Eddsa signatures with curve448. Needs SHAKE support first (Daiki
&gt;    posted patches for this long ago).

Done!

&gt; 2. Renaming of stuff using curve names consistently (recent patches by
&gt;    Dmitry). Preparation for new gost curves.

Done! And GOSTDSA with the two easiest GOST curves now on the ecc-cost
branch.

&gt; 3. I'm considering changing the struct ecc_point representation to use
&gt;    montgomery representation of the for the individual coordinates, for
&gt;    primes where we use that. Then ecc_a_to_* will (almost?) be
&gt;    redundant.

I still think ecc_a_to_* could be eliminated. They do redc conversions
for curves that use that, and some copying of the unit field element.

While looking at this, I also noticed that it seems ecc-&gt;g is used only
by tests. So this data could be removed from struct ecc_curve.

&gt; 4. Adding support for compact representation (patches from Wim Lewis). I
&gt;    have some of the preparations merged on a branch, but I think it will
&gt;    be simpler if (3) is done first.

I'm thinking that maybe it's reasonalbe to make a release soon, since we
have a couple of new features, including ED448, GOSTDSA, SIV-CMAC. If we
want to focus on getting a release out, I think both the compact
representation change and additional GOST curves should be postponed
until after the release. (The ecc_a_to_* cleanup above is also not that
important from a release perspective, but I expect it to be fairly
easy).

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200125160820</emailId><senderName>Nikos Mavrogiannopoulos</senderName><senderEmail>nmav@redhat.com</senderEmail><timestampReceived>2020-01-25 16:08:20-0400</timestampReceived><subject>Re: Current ECC work</subject><body>

On Sat, Jan 25, 2020 at 4:54 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; I'm thinking that maybe it's reasonalbe to make a release soon, since we
&gt; have a couple of new features, including ED448, GOSTDSA, SIV-CMAC. If we
&gt; want to focus on getting a release out, I think both the compact
&gt; representation change and additional GOST curves should be postponed
&gt; until after the release. (The ecc_a_to_* cleanup above is also not that
&gt; important from a release perspective, but I expect it to be fairly
&gt; easy).

A release would be amazing! At this point gnutls bundles so much of
nettle, and a release would allow us to have a version which is free
of such bundling!

regards,
Nikos

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200129054637</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-29 05:46:37-0400</timestampReceived><subject>Re: Current ECC work</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt;&gt; 3. I'm considering changing the struct ecc_point representation to use
&gt;&gt;    montgomery representation of the for the individual coordinates, for
&gt;&gt;    primes where we use that. Then ecc_a_to_* will (almost?) be
&gt;&gt;    redundant.
&gt;
&gt; I still think ecc_a_to_* could be eliminated. They do redc conversions
&gt; for curves that use that, and some copying of the unit field element.

I noticed an inconsistency here. For curve25519 and curve448, we do sqrt
and inversion using powering. If using powering for other curves, as is
needed for the sqrt operation with compact representation, it's
desirable to do this with inputs and outputs in redc form, for moduli
where we use redc.

However, inversion using side-channel silent gcdext, ecc_mod_inv, as is
used by all other curves, is unaware of redc. Instead, there's some
extra redc processing where it's called in ecc_j_to_a.

If we want to compute v = z^-1 (mod p), but in redc form with v' = vB
and z' = zB, then we have

  v z = 1 (mod p)

but

  v' z' = B^2 (mod p)

So for redc curves we need to compute v' as

  v' = (z' / B^2)^-1 (mod p)

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200123140634</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-23 14:06:34-0400</timestampReceived><subject>Re: [PATCH 0/2] two small fixes for ecc-gost branch</subject><body>

dbaryshkov@gmail.com writes:

&gt; Two small fixes to go on top of ecc-gost branch. These two patches can
&gt; be squashed into respective patches or just live as separate instances,
&gt; whatever you would prefer.

Pushed to that branch now.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200124100646</emailId><senderName>Dmitry Eremin-Solenikov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-01-24 10:06:46-0400</timestampReceived><subject>Re: [PATCH 0/2] two small fixes for ecc-gost branch</subject><body>

чт, 23 янв. 2020 г. в 17:06, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt;
&gt; dbaryshkov@gmail.com writes:
&gt;
&gt; &gt; Two small fixes to go on top of ecc-gost branch. These two patches can
&gt; &gt; be squashed into respective patches or just live as separate instances,
&gt; &gt; whatever you would prefer.
&gt;
&gt; Pushed to that branch now.

Thank you! What about GOST DSA v5 patches?

-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200125152349</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-25 15:23:49-0400</timestampReceived><subject>Re: [PATCH 0/2] two small fixes for ecc-gost branch</subject><body>

Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt; writes:

&gt; Thank you! What about GOST DSA v5 patches?

Look good, I'm trying them out right now, before leaving for the next
airport. Running the benchmark, signing looks a bit faster than the
ecdsa variants,

            name size   sign/ms verify/ms

           ecdsa  256    3.0218    0.9877
           ecdsa  521    0.7055    0.2278
         gostdsa  256    3.7480    0.9381
         gostdsa  512    0.9642    0.2403

The doc patch didn't apply cleanly, though,

  Applying: Add documentation for GOSTDSA and GOST curves.
  error: corrupt patch at line 65
  error: could not build fake ancestor

(I haven't looked into what the problem might be).

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200127094345</emailId><senderName>Dmitry Eremin-Solenikov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-01-27 09:43:45-0400</timestampReceived><subject>Re: [PATCH 0/2] two small fixes for ecc-gost branch</subject><body>

Hello,

сб, 25 янв. 2020 г. в 18:23, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt;
&gt; Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt; writes:
&gt;
&gt; &gt; Thank you! What about GOST DSA v5 patches?
&gt;
&gt; Look good, I'm trying them out right now, before leaving for the next
&gt; airport. Running the benchmark, signing looks a bit faster than the
&gt; ecdsa variants,
&gt;
&gt;             name size   sign/ms verify/ms
&gt;
&gt;            ecdsa  256    3.0218    0.9877
&gt;            ecdsa  521    0.7055    0.2278
&gt;          gostdsa  256    3.7480    0.9381
&gt;          gostdsa  512    0.9642    0.2403
&gt;
&gt; The doc patch didn't apply cleanly, though,
&gt;
&gt;   Applying: Add documentation for GOSTDSA and GOST curves.
&gt;   error: corrupt patch at line 65
&gt;   error: could not build fake ancestor
&gt;
&gt; (I haven't looked into what the problem might be).

This is strange. I have checked the e-mail from my 'sent' mailbox, it
applies cleanly. Anyway, I have uploaded the diff to paste server. You
can download and apply it:
https://paste.debian.net/1127852/ . The download link is close to the
bottom of the page.

-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200127142652</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-27 14:26:52-0400</timestampReceived><subject>Re: [PATCH 0/2] two small fixes for ecc-gost branch</subject><body>

Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt; writes:

&gt; This is strange. I have checked the e-mail from my 'sent' mailbox, it
&gt; applies cleanly. Anyway, I have uploaded the diff to paste server. You
&gt; can download and apply it:
&gt; https://paste.debian.net/1127852/ . The download link is close to the
&gt; bottom of the page.

Done! I also added two index entries.

Regards,
/Niels
-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200127144331</emailId><senderName>Dmitry Eremin-Solenikov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-01-27 14:43:31-0400</timestampReceived><subject>Re: [PATCH 0/2] two small fixes for ecc-gost branch</subject><body>

пн, 27 янв. 2020 г. в 17:26, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt;
&gt; Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt; writes:
&gt;
&gt; &gt; This is strange. I have checked the e-mail from my 'sent' mailbox, it
&gt; &gt; applies cleanly. Anyway, I have uploaded the diff to paste server. You
&gt; &gt; can download and apply it:
&gt; &gt; https://paste.debian.net/1127852/ . The download link is close to the
&gt; &gt; bottom of the page.
&gt;
&gt; Done! I also added two index entries.

Great, thank you!

I've sent two patches for next curve (the 256-bit 80000.....0c99 one)
for review.

I still hope to get most curves into next release. I'm perfectly fine
with releasing nettle without additional curves though.

-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200129041404</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-29 04:14:04-0400</timestampReceived><subject>Re: [PATCH 0/2] two small fixes for ecc-gost branch</subject><body>

Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt; writes:

&gt; I've sent two patches for next curve (the 256-bit 80000.....0c99 one)
&gt; for review.
&gt;
&gt; I still hope to get most curves into next release. I'm perfectly fine
&gt; with releasing nettle without additional curves though.

I've now merged gostdsa and the first two curves to master.

I'd like to postpone additional gost curves for a bit, to figure out
what else needs to get into the next release.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200125195032</emailId><senderName>Martin_Storsjö</senderName><senderEmail>martin@martin.st</senderEmail><timestampReceived>2020-01-25 19:50:32-0400</timestampReceived><subject>Re: Problem with gitlab CI</subject><body>

On Sat, 25 Jan 2020, Niels MÃ¶ller wrote:

&gt; Hi,
&gt;
&gt; it seems some of the recent gitlab ci jobs for some reason run on some
&gt; windows infrastructure. I can see that might be useful for some
&gt; projects, if you want to support and test native windows builds or
&gt; something. But for Nettle, it's neither helpful nor working, e.g.,
&gt;
&gt; https://gitlab.com/gnutls/nettle/-/jobs/414926707
&gt;
&gt; fails because build scripts are running in some windows shell not
&gt; recognizing a /bin/sh for loop.
&gt;
&gt; Can we add some "Windows? Just say no!" in nettle/.gitlab-ci.yml, to get
&gt; it back in working shape? Or do some higher-level config for the gnutls
&gt; project on gitlab?

I believe you should add the tag 'linux' to all jobs (that currently only 
are tagged with the tag 'shared') to specify which kind of shared runner 
they should run on.

I tried briefly googling what tags are available to choose between on the 
current runners, but it seems like they have 'linux' set at least.

// Martin
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200125195902</emailId><senderName>Nikos Mavrogiannopoulos</senderName><senderEmail>n.mavrogiannopoulos@gmail.com</senderEmail><timestampReceived>2020-01-25 19:59:02-0400</timestampReceived><subject>Re: Problem with gitlab CI</subject><body>

We had the same issue in gnutls. You can apply this patch.

On Sat, Jan 25, 2020 at 8:21 PM Niels M=C3=B6ller &lt;nisse@lysator.liu.se&gt; wr=
ote:
&gt;
&gt; Hi,
&gt;
&gt; it seems some of the recent gitlab ci jobs for some reason run on some
&gt; windows infrastructure. I can see that might be useful for some
&gt; projects, if you want to support and test native windows builds or
&gt; something. But for Nettle, it's neither helpful nor working, e.g.,
&gt;
&gt; https://gitlab.com/gnutls/nettle/-/jobs/414926707
&gt;
&gt; fails because build scripts are running in some windows shell not
&gt; recognizing a /bin/sh for loop.
&gt;
&gt; Can we add some "Windows? Just say no!" in nettle/.gitlab-ci.yml, to get
&gt; it back in working shape? Or do some higher-level config for the gnutls
&gt; project on gitlab?
&gt;
&gt; Regards,
&gt; /Niels
&gt; --
&gt; Niels M=C3=B6ller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt;
&gt; _______________________________________________
&gt; nettle-bugs mailing list
&gt; nettle-bugs@lists.lysator.liu.se
&gt; http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

["0001-.gitlab-ci.yml-require-linux-systems-for-running-CI.patch" (text/x-patch)]

From 341f0345e36625fbee4378587ab9a9aa4eb1b250 Mon Sep 17 00:00:00 2001
From: Nikos Mavrogiannopoulos &lt;n.mavrogiannopoulos@gmail.com&gt;
Date: Sat, 25 Jan 2020 20:56:40 +0100
Subject: [PATCH] .gitlab-ci.yml: require linux systems for running CI

Gitlab added windows shared runners and we should avoid
running CI in this environment as it will immediatelly
fail.

Signed-off-by: Nikos Mavrogiannopoulos &lt;n.mavrogiannopoulos@gmail.com&gt;
---
 .gitlab-ci.yml | 10 ++++++++++
 1 file changed, 10 insertions(+)

diff --git a/.gitlab-ci.yml b/.gitlab-ci.yml
index 85acdf14..663f98f5 100644
--- a/.gitlab-ci.yml
+++ b/.gitlab-ci.yml
@@ -18,6 +18,7 @@ build/x86-64:
     make check -j4
   tags:
   - shared
+  - linux
   except:
   - tags
 build/mini-gmp:
@@ -28,6 +29,7 @@ build/mini-gmp:
     make check -j4
   tags:
   - shared
+  - linux
   except:
   - tags
 build/c89:
@@ -38,6 +40,7 @@ build/c89:
     make check -j4
   tags:
   - shared
+  - linux
   except:
   - tags
 build/ndebug:
@@ -48,6 +51,7 @@ build/ndebug:
     make check -j4
   tags:
   - shared
+  - linux
   except:
   - tags
 build/ubsan:
@@ -58,6 +62,7 @@ build/ubsan:
     --disable-documentation &amp;&amp; make -j4 &amp;&amp; make check -j4
   tags:
   - shared
+  - linux
   except:
   - tags
 build/asan:
@@ -68,6 +73,7 @@ build/asan:
     make -j4 &amp;&amp; make check -j4
   tags:
   - shared
+  - linux
   except:
   - tags
 build/static-analyzers:
@@ -78,6 +84,7 @@ build/static-analyzers:
   - scan-build --status-bugs -o scan-build-lib make -j$(nproc)
   tags:
   - shared
+  - linux
   except:
   - tags
   artifacts:
@@ -97,6 +104,7 @@ build/gnutls:
     make -j $(nproc) check
   tags:
   - shared
+  - linux
   except:
   - tags
   artifacts:
@@ -122,6 +130,7 @@ Debian.cross.x86:
     make check -j4
   tags:
   - shared
+  - linux
   except:
   - tags
 .Debian.cross.template: &amp;Debian_cross_template
@@ -143,6 +152,7 @@ Debian.cross.x86:
   - make -j$(nproc) check
   tags:
   - shared
+  - linux
   except:
   - tags
 Debian.cross.arm-linux-gnueabihf:
-- 
2.24.1


[Attachment #4 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200116183656</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-16 18:36:56-0400</timestampReceived><subject>Re: [PATCH v4 3/4] Add GOST DSA according to GOST R 34.10-2001/-2012</subject><body>

dbaryshkov@gmail.com writes:

&gt; From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;
&gt;
&gt; Add GOST Digital Signature Algorithms support according to GOST R
&gt; 34.10-2001/-2012. English translations of these standards are provided
&gt; as RFC 5832 and RFC 7091.

I've merged the first two patches to a branch ecc-gost. A few comments on
the signature implementation.

&gt; Signed-off-by: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;
&gt; Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
&gt; ---
&gt;  Makefile.in                     |   4 +-
&gt;  ecc-gostdsa-sign.c              | 101 +++++++++++++++++++++
&gt;  ecc-gostdsa-verify.c            | 130 +++++++++++++++++++++++++++
&gt;  ecc-hash.c                      |  11 +++
&gt;  ecc-internal.h                  |   7 ++
&gt;  gostdsa-sign.c                  |  74 +++++++++++++++
&gt;  gostdsa-verify.c                |  78 ++++++++++++++++
&gt;  gostdsa.h                       | 102 +++++++++++++++++++++
&gt;  testsuite/.gitignore            |   3 +
&gt;  testsuite/.test-rules.make      |   9 ++
&gt;  testsuite/Makefile.in           |   4 +-
&gt;  testsuite/gostdsa-keygen-test.c | 154 ++++++++++++++++++++++++++++++++
&gt;  testsuite/gostdsa-sign-test.c   |  87 ++++++++++++++++++
&gt;  testsuite/gostdsa-verify-test.c | 110 +++++++++++++++++++++++
&gt;  testsuite/testutils.h           |   1 +
&gt;  15 files changed, 873 insertions(+), 2 deletions(-)
&gt;  create mode 100644 ecc-gostdsa-sign.c
&gt;  create mode 100644 ecc-gostdsa-verify.c
&gt;  create mode 100644 gostdsa-sign.c
&gt;  create mode 100644 gostdsa-verify.c
&gt;  create mode 100644 gostdsa.h
&gt;  create mode 100644 testsuite/gostdsa-keygen-test.c
&gt;  create mode 100644 testsuite/gostdsa-sign-test.c
&gt;  create mode 100644 testsuite/gostdsa-verify-test.c
&gt;
&gt; diff --git a/Makefile.in b/Makefile.in
&gt; index a08dfe4da481..1396e2fe2808 100644
&gt; --- a/Makefile.in
&gt; +++ b/Makefile.in
&gt; @@ -189,6 +189,8 @@ hogweed_SOURCES = sexp.c sexp-format.c \
&gt;  		  ecc-point.c ecc-scalar.c ecc-point-mul.c ecc-point-mul-g.c \
&gt;  		  ecc-ecdsa-sign.c ecdsa-sign.c \
&gt;  		  ecc-ecdsa-verify.c ecdsa-verify.c ecdsa-keygen.c \
&gt; +		  ecc-gostdsa-sign.c gostdsa-sign.c \
&gt; +		  ecc-gostdsa-verify.c gostdsa-verify.c \
&gt;  		  curve25519-mul-g.c curve25519-mul.c curve25519-eh-to-x.c \
&gt;  		  curve448-mul-g.c curve448-mul.c curve448-eh-to-x.c \
&gt;  		  eddsa-compress.c eddsa-decompress.c eddsa-expand.c \
&gt; @@ -205,7 +207,7 @@ HEADERS = aes.h arcfour.h arctwo.h asn1.h blowfish.h \
&gt;  	  cbc.h ccm.h cfb.h chacha.h chacha-poly1305.h ctr.h \
&gt;  	  curve25519.h curve448.h des.h dsa.h dsa-compat.h eax.h \
&gt;  	  ecc-curve.h ecc.h ecdsa.h eddsa.h \
&gt; -	  gcm.h gost28147.h gosthash94.h hmac.h \
&gt; +	  gcm.h gost28147.h gostdsa.h gosthash94.h hmac.h \
&gt;  	  knuth-lfib.h hkdf.h \
&gt;  	  macros.h \
&gt;  	  cmac.h siv-cmac.h \
&gt; diff --git a/ecc-gostdsa-sign.c b/ecc-gostdsa-sign.c
&gt; new file mode 100644
&gt; index 000000000000..00eeef81f659
&gt; --- /dev/null
&gt; +++ b/ecc-gostdsa-sign.c
&gt; +/* NOTE: Caller should check if r or s is zero. */
&gt; +void
&gt; +ecc_gostdsa_sign (const struct ecc_curve *ecc,
&gt; +		const mp_limb_t *zp,
&gt; +		const mp_limb_t *kp,
&gt; +		size_t length, const uint8_t *digest,
&gt; +		mp_limb_t *rp, mp_limb_t *sp,
&gt; +		mp_limb_t *scratch)
&gt; +{
&gt; +#define P	    scratch
&gt; +#define hp	    (scratch + 4*ecc-&gt;p.size)
&gt; +#define tp	    (scratch + 2*ecc-&gt;p.size)
&gt; +#define t2p	    scratch
&gt; +  /* Procedure, according to GOST 34.10. q denotes the group
&gt; +     order.
&gt; +
&gt; +     1. k &lt;-- uniformly random, 0 &lt; k &lt; q
&gt; +
&gt; +     2. C &lt;-- (c_x, c_y) = k g
&gt; +
&gt; +     3. r &lt;-- c_x mod q
&gt; +
&gt; +     4. s &lt;-- (r*z + k*h) mod q.
&gt; +  */

So no modular inversion in the signature operation? That's an
improvement over NIST's DSA and ECDSA.

&gt; diff --git a/ecc-gostdsa-verify.c b/ecc-gostdsa-verify.c
&gt; new file mode 100644
&gt; index 000000000000..4358132b2bf6
&gt; --- /dev/null
&gt; +++ b/ecc-gostdsa-verify.c
&gt; +/* FIXME: Use faster primitives, not requiring side-channel silence. */
&gt; +int
&gt; +ecc_gostdsa_verify (const struct ecc_curve *ecc,
&gt; +		  const mp_limb_t *pp, /* Public key */
&gt; +		  size_t length, const uint8_t *digest,
&gt; +		  const mp_limb_t *rp, const mp_limb_t *sp,
&gt; +		  mp_limb_t *scratch)
&gt; +{
&gt; +  /* Procedure, according to GOST R 34.10. q denotes the group
&gt; +     order.
&gt; +
&gt; +     1. Check 0 &lt; r, s &lt; q.
&gt; +
&gt; +     2. v &lt;-- h^{-1}  (mod q)
&gt; +
&gt; +     3. z1  &lt;-- s * v (mod q)
&gt; +
&gt; +     4. z2  &lt;-- -r * v (mod q)
&gt; +
&gt; +     5. R = u1 G + u2 Y
&gt; +
&gt; +     6. Signature is valid if R_x = r (mod q).
&gt; +  */
&gt; +
&gt; +#define hp (scratch)
&gt; +#define vp (scratch + ecc-&gt;p.size)
&gt; +#define z1 (scratch + 3*ecc-&gt;p.size)
&gt; +#define z2 (scratch + 4*ecc-&gt;p.size)
&gt; +
&gt; +#define P1 (scratch + 4*ecc-&gt;p.size)
&gt; +#define P2 (scratch)
&gt; +
&gt; +
&gt; +  if (! (ecdsa_in_range (ecc, rp)
&gt; +	 &amp;&amp; ecdsa_in_range (ecc, sp)))
&gt; +    return 0;
&gt; +
&gt; +  gost_hash (&amp;ecc-&gt;q, hp, length, digest);
&gt; +
&gt; +  if (mpn_zero_p (hp, ecc-&gt;p.size))
&gt; +    mpn_add_1 (hp, hp, ecc-&gt;p.size, 1);
&gt; +
&gt; +  /* Compute v */
&gt; +  ecc-&gt;q.invert (&amp;ecc-&gt;q, vp, hp, vp + 2*ecc-&gt;p.size);

Comment about faster primitives applies particularly to this modular
inversion. Using mpn_gcdext, which isn't side-channel silent, is likely
significantly faster (but a bit different interface). Would be
interesting to add to hogweed-benchmark, to compare to other ecc
signatures.

&gt; diff --git a/ecc-hash.c b/ecc-hash.c
&gt; index 4e830a514ac4..07877110263f 100644
&gt; --- a/ecc-hash.c
&gt; +++ b/ecc-hash.c
&gt; @@ -62,3 +62,14 @@ ecc_hash (const struct ecc_modulo *m,
&gt;      /* We got a few extra bits, at the low end. Discard them. */
&gt;      mpn_rshift (hp, hp, m-&gt;size + 1, 8*length - m-&gt;bit_size);
&gt;  }
&gt; +
&gt; +void
&gt; +gost_hash (const struct ecc_modulo *m,
&gt; +	   mp_limb_t *hp,
&gt; +	   size_t length, const uint8_t *digest)
&gt; +{
&gt; +  if (length &gt; ((size_t) m-&gt;bit_size + 7) / 8)
&gt; +    length = (m-&gt;bit_size + 7) / 8;
&gt; +
&gt; +  mpn_set_base256_le (hp, m-&gt;size + 1, digest, length);
&gt; +}

It looks a bit strange to truncate the digest in this function, but I
see that's the same as ecc_hash just above. Do you need to also handle
the case of left-over bits, 8*length &gt; m-&gt;bit_size?

Are the details very specific to gost, or could the helper be renamed
ecc_hash_le ?

What are typical values of length, compared to the prime size?

&gt; --- /dev/null
&gt; +++ b/gostdsa.h
&gt; @@ -0,0 +1,102 @@
[...]
&gt; +
&gt; +/* Development of Nettle's ECC support was funded by the .SE Internet Fund. */

Left-over note?

&gt; diff --git a/testsuite/testutils.h b/testsuite/testutils.h
&gt; index f4ea38da9deb..cef7f4011a7c 100644
&gt; --- a/testsuite/testutils.h
&gt; +++ b/testsuite/testutils.h
&gt; @@ -22,6 +22,7 @@
&gt;  # include "ecc.h"
&gt;  # include "ecc-internal.h"
&gt;  # include "ecdsa.h"
&gt; +# include "gostdsa.h"
&gt;  # include "gmp-glue.h"
&gt;  # if NETTLE_USE_MINI_GMP
&gt;  #  include "knuth-lfib.h"

Drop include, if nothing in testutils.h or testutils.c need gostdsa
types.

Regard,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200113094333</emailId><senderName>Daniel =?utf-8?B?UC4gQmVycmFuZ8Op?=</senderName><senderEmail>berrange@redhat.com</senderEmail><timestampReceived>2020-01-13 09:43:33-0400</timestampReceived><subject>Re: Require GNU make?</subject><body>

On Sat, Jan 11, 2020 at 10:54:02AM +0100, Niels Möller wrote:
&gt; Hi,
&gt; 
&gt; it's been pointed out to me that GNU make documentation of old-fashioned
&gt; suffix rules say
&gt; 
&gt; :    Suffix rules cannot have any prerequisites of their own.  If they
&gt; : have any, they are treated as normal files with funny names, not as
&gt; : suffix rules.  Thus, the rule:
&gt; : 
&gt; :      .c.o: foo.h
&gt; :              $(CC) -c $(CFLAGS) $(CPPFLAGS) -o $@ $&lt;
&gt; : 
&gt; : tells how to make the file '.c.o' from the prerequisite file 'foo.h',
&gt; 
&gt; Nettle's Makefile.in has a rule
&gt; 
&gt;   .asm.$(OBJEXT): $(srcdir)/asm.m4 machine.m4 config.m4
&gt; 
&gt; which is broken according to these docs. I haven't seen any problems in
&gt; practice (not entirely sure why), but it reportedly fails with some GNU
&gt; make prerelease.
&gt; 
&gt; To change this to a %-pattern rule, I wonder: Should we just drop
&gt; support for non-GNU make programs?
&gt; 
&gt; Requiring GNU make makes a few things easier: We can use %-patterns
&gt; everywhere. We can use -include unconditionally for dep-files, dropping the
&gt; @DEP_INCLUDE@ variable and the dummy-dep-files configure step. We can
&gt; most likely also drop all logic for the testsuite/.test-rules.make file.
&gt; 
&gt; Current status of make compatibility is that it's supposed to work with
&gt; Solaris make (but likely not tested for a long time), and it should
&gt; kind-of work with BSD make, provided one configures with
&gt; --disable-dependency-tracking.

Is there any platform that is considered a supported build target for
nettle, which does /not/ have GNU make easily available ? I doubt it.
It is a mere "pkg add gmake" on *BSD to install it.

So I'd flip the question. Is there any compelling benefit to supporting
non-GNU make ? If 95% of development is done &amp; testing with GNU make on
Linux, then I think it is beneficial to mandate GNU make for all non-Linux
too. This cuts down the testing matrix and should lead to more reliable
and consistent build system across platforms, as well as letting nettle
take advantage of GNU make features.

As a reference, with QEMU/libvirt we've mandated GNU make for along time
and never had any users complain about this dependancy. The only irritation
is that devs sometimes forget and just type "make" instead of "gmake" and
then get wierd errors due to GNU extensions, but they quickly realize their
mistake &amp; move on.

IOW, I'd encourage mandating GNU make for any project. It is just not worth
the effort to worry about random vendor specific make impls when GNU make
is available everywhere that matters.

Regards,
Daniel
-- 
|: https://berrange.com      -o-    https://www.flickr.com/photos/dberrange :|
|: https://libvirt.org         -o-            https://fstop138.berrange.com :|
|: https://entangle-photo.org    -o-    https://www.instagram.com/dberrange :|

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200113104821</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-13 10:48:21-0400</timestampReceived><subject>Re: Require GNU make?</subject><body>

Daniel P. Berrangé &lt;berrange@redhat.com&gt; writes:

&gt; So I'd flip the question. Is there any compelling benefit to supporting
&gt; non-GNU make ?

Not that I'm aware of, but I'd like to hear any other opinions before
proceeding. It was a lot more common with proprietary unices with vendor
tools back when Nettle was started.

&gt; IOW, I'd encourage mandating GNU make for any project.

I'd agree. Except for GNU make itself, and its required dependencies, if
any...

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200114040412</emailId><senderName>George Koehler</senderName><senderEmail>kernigh@gmail.com</senderEmail><timestampReceived>2020-01-14 04:04:12-0400</timestampReceived><subject>Re: Require GNU make?</subject><body>

On Sat, 11 Jan 2020 10:54:02 +0100
nisse@lysator.liu.se (Niels Möller) wrote:

&gt; Hi,
&gt; 
&gt; it's been pointed out to me that GNU make documentation of old-fashioned
&gt; suffix rules say
&gt; 
&gt; &gt; Suffix rules cannot have any prerequisites of their own.  If they
&gt; &gt; have any, they are treated as normal files with funny names, not as
&gt; &gt; suffix rules.  Thus, the rule:
&gt; &gt; 
&gt; &gt; .c.o: foo.h
&gt; &gt; $(CC) -c $(CFLAGS) $(CPPFLAGS) -o $@ $&lt;
&gt; &gt; 
&gt; &gt; tells how to make the file '.c.o' from the prerequisite file 'foo.h',

OpenBSD make(1) agrees that a suffix rule has "no prerequisites", but
doesn't enforce this.  The above rule, in OpenBSD make, is a suffix
rule:

$ make file.o
`file.o' is up to date.
$ touch foo.h
$ make file.o
cc -c -O2 -pipe   -o file.o file.c
$ make .c.o
make: don't know how to make .c.o
Stop in /tmp/proj

https://man.openbsd.org/make#INFERENCE_RULES says,

&gt; A complete inference rule is a dependency line with such a target,
&gt; the normal dependency operator, no prerequisites and a list of shell
&gt; commands.

Over in NetBSD, https://netbsd.gw.com/cgi-bin/man-cgi?make seems not
to mention whether a suffix rule can have prerequisites.

&gt; ...
&gt; 
&gt; To change this to a %-pattern rule, I wonder: Should we just drop
&gt; support for non-GNU make programs?
&gt; 
&gt; Requiring GNU make makes a few things easier: We can use %-patterns
&gt; everywhere. We can use -include unconditionally for dep-files, dropping the
&gt; @DEP_INCLUDE@ variable and the dummy-dep-files configure step. We can
&gt; most likely also drop all logic for the testsuite/.test-rules.make file.

I often install GNU make on OpenBSD, because I build software that
uses %-patterns, $(shell ...) calls, or GNU-style ifdef/endif in
Makefiles.  BSD make already has -include.

&gt; Current status of make compatibility is that it's supposed to work with
&gt; Solaris make (but likely not tested for a long time), and it should
&gt; kind-of work with BSD make, provided one configures with
&gt; --disable-dependency-tracking.

I don't know if BSD make can build Nettle; I used GNU make.

The BSDs appear to use GNU make to build their Nettle packages.  In
OpenBSD ports/security/libnettle [1], the line "USE_GMAKE= Yes" uses
GNU make.  FreeBSD [2] and NetBSD [3] appear to also use gmake.  It is
as if Nettle already requires GNU make.

I wonder if we can find anyone who doesn't use GNU make for Nettle.

--George

[1] https://cvsweb.openbsd.org/cgi-bin/cvsweb/ports/security/libnettle/Makefile?rev=1.25&amp;content-type=text/x-cvsweb-markup
 [2] https://svnweb.freebsd.org/ports/head/security/nettle/Makefile?revision=512232&amp;view=markup
 [3] http://cvsweb.netbsd.org/bsdweb.cgi/pkgsrc/security/nettle/Makefile?rev=1.22&amp;content-type=text/x-cvsweb-markup&amp;only_with_tag=MAIN
 _______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200112163353</emailId><senderName>Dmitry Eremin-Solenikov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-01-12 16:33:53-0400</timestampReceived><subject>Re: Gitlab merge requests</subject><body>

Hello,

сб, 11 янв. 2020 г. в 12:20, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt;
&gt; Hi,
&gt;
&gt; After some off-list discussions and encouragement, I've reenabled the
&gt; "merge request" feature on git.lysator.liu.se/nettle.

Great!

&gt; I don't know yet precisely how I will want to use it, but feel free to
&gt; create merge requests if you think that helps us keep track of ongoing
&gt; work. For the time being, please also write to the mailinglist whenever
&gt; some action is done or desired on a merge request.
&gt;
&gt; I intend the mailinglist to remain the main forum for discussing new
&gt; features and implementation choices, while detailed patch review might
&gt; gradually move to the web interface.

Great idea, let's try it!

&gt; Advice on how to use and configure gitlab is welcome.

I've tried registering with @gmai.com address.
I've received "Email is not from an allowed domain." error during registration.

-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200113081036</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-13 08:10:36-0400</timestampReceived><subject>Re: Gitlab merge requests</subject><body>

Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt; writes:

&gt; I've tried registering with @gmai.com address.
&gt; I've received "Email is not from an allowed domain." error during registration.

I asked the sysadm. gmail had been put on the signup blacklist, because
up to now it was used only by a few hundred spam accounts.

Should be fixed now.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200114115747</emailId><senderName>Nikos Mavrogiannopoulos</senderName><senderEmail>n.mavrogiannopoulos@gmail.com</senderEmail><timestampReceived>2020-01-14 11:57:47-0400</timestampReceived><subject>Re: Gitlab merge requests</subject><body>

That's great. Does git.lysator.liu.se support shared runners for CI?
That will allow checking the MR status on CI, and eliminate the need
for mirroring in gitlab and running the CI there.

regards,
Nikos

On Sat, Jan 11, 2020 at 10:20 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; Hi,
&gt;
&gt; After some off-list discussions and encouragement, I've reenabled the
&gt; "merge request" feature on git.lysator.liu.se/nettle.
&gt;
&gt; I don't know yet precisely how I will want to use it, but feel free to
&gt; create merge requests if you think that helps us keep track of ongoing
&gt; work. For the time being, please also write to the mailinglist whenever
&gt; some action is done or desired on a merge request.
&gt;
&gt; I intend the mailinglist to remain the main forum for discussing new
&gt; features and implementation choices, while detailed patch review might
&gt; gradually move to the web interface.
&gt;
&gt; Advice on how to use and configure gitlab is welcome.
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt;
&gt; _______________________________________________
&gt; nettle-bugs mailing list
&gt; nettle-bugs@lists.lysator.liu.se
&gt; http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200114122602</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-14 12:26:02-0400</timestampReceived><subject>Re: Gitlab merge requests</subject><body>

Nikos Mavrogiannopoulos &lt;n.mavrogiannopoulos@gmail.com&gt; writes:

&gt; That's great. Does git.lysator.liu.se support shared runners for CI?

I'm not sure what "shared runners" mean. I'm not aware of any nearby
machines running ci jobs for git.lysator.liu.se. And the machines
running ci jobs for the gitlab mirror, do they belong to gitlab, or
have you set them up?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200114141816</emailId><senderName>Nikos Mavrogiannopoulos</senderName><senderEmail>nmav@redhat.com</senderEmail><timestampReceived>2020-01-14 14:18:16-0400</timestampReceived><subject>Re: Gitlab merge requests</subject><body>

On Tue, Jan 14, 2020 at 1:26 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; Nikos Mavrogiannopoulos &lt;n.mavrogiannopoulos@gmail.com&gt; writes:
&gt;
&gt; &gt; That's great. Does git.lysator.liu.se support shared runners for CI?
&gt;
&gt; I'm not sure what "shared runners" mean. I'm not aware of any nearby
&gt; machines running ci jobs for git.lysator.liu.se.

If they are you should be able to see them in Settings -&gt; CI/CD -&gt; Runners.

&gt; And the machines
&gt; running ci jobs for the gitlab mirror, do they belong to gitlab, or
&gt; have you set them up?

The runners are from gitlab.com.

regards,
Nikos

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200115061826</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-15 06:18:26-0400</timestampReceived><subject>Re: Gitlab merge requests</subject><body>

Nikos Mavrogiannopoulos &lt;nmav@redhat.com&gt; writes:

&gt; On Tue, Jan 14, 2020 at 1:26 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;&gt;
&gt;&gt; Nikos Mavrogiannopoulos &lt;n.mavrogiannopoulos@gmail.com&gt; writes:
&gt;&gt;
&gt;&gt; &gt; That's great. Does git.lysator.liu.se support shared runners for CI?
&gt;&gt;
&gt;&gt; I'm not sure what "shared runners" mean. I'm not aware of any nearby
&gt;&gt; machines running ci jobs for git.lysator.liu.se.
&gt;
&gt; If they are you should be able to see them in Settings -&gt; CI/CD -&gt; Runners.

I've now had a look. There's a section for "Group runners", which is
empty. No mention of "shared runners". There's a link to "Install a
GitLab runner" (with various kinds of binaries, no mention of sources),
and a big button "Install Runner on Kubernetes".

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200115082454</emailId><senderName>Nikos Mavrogiannopoulos</senderName><senderEmail>nmav@redhat.com</senderEmail><timestampReceived>2020-01-15 08:24:54-0400</timestampReceived><subject>Re: Gitlab merge requests</subject><body>

On Wed, Jan 15, 2020 at 7:18 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; &gt; If they are you should be able to see them in Settings -&gt; CI/CD -&gt; Runners.
&gt;
&gt; I've now had a look. There's a section for "Group runners", which is
&gt; empty. No mention of "shared runners". There's a link to "Install a
&gt; GitLab runner" (with various kinds of binaries, no mention of sources),
&gt; and a big button "Install Runner on Kubernetes".

So there aren't any :)

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200115090309</emailId><senderName>Tim_Rühsen</senderName><senderEmail>tim.ruehsen@gmx.de</senderEmail><timestampReceived>2020-01-15 09:03:09-0400</timestampReceived><subject>Re: Gitlab merge requests</subject><body>

[Attachment #2 (multipart/signed)]

[Attachment #4 (multipart/mixed)]


On 1/15/20 9:24 AM, Nikos Mavrogiannopoulos wrote:
&gt; On Wed, Jan 15, 2020 at 7:18 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt; 
&gt;&gt;&gt; If they are you should be able to see them in Settings -&gt; CI/CD -&gt; Runners.
&gt;&gt;
&gt;&gt; I've now had a look. There's a section for "Group runners", which is
&gt;&gt; empty. No mention of "shared runners". There's a link to "Install a
&gt;&gt; GitLab runner" (with various kinds of binaries, no mention of sources),
&gt;&gt; and a big button "Install Runner on Kubernetes".
&gt; 
&gt; So there aren't any :)

Niels, since you set up your own instance of Gitlab, you can't access
the Gitlab.com runners (it's a free service for customers only).

So you can set up your own "machines" (bare metal, vm or container) and
install [1] on them. This gives you runners for your own CI - every
merge request and every push will automatically be built and tested.

Sorry that I am not into the details, thus can't give you detailed
instructions.

[1] https://docs.gitlab.com/runner/install/

Regards, Tim


["signature.asc" (application/pgp-signature)]
[Attachment #8 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200112204553</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-12 20:45:53-0400</timestampReceived><subject>Re: [PATCH v2 1/3] Add support for GOST GC256B curve</subject><body>

dbaryshkov@gmail.com writes:

&gt; From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;
&gt;
&gt; Add support for GC256B curve ("TLS Supported Groups" registry,
&gt; draft-smyshlyaev-tls12-gost-suites) also known as
&gt; GostR3410-2001-CryptoPro-A and GostR3410-2001-CryptoPro-XchA (RFC 4357).

Thanks. Some comments below:

&gt; --- a/Makefile.in
&gt; +++ b/Makefile.in
&gt; @@ -176,6 +176,7 @@ hogweed_SOURCES = sexp.c sexp-format.c \
&gt;  		  ecc-mod.c ecc-mod-inv.c \
&gt;  		  ecc-mod-arith.c ecc-pp1-redc.c ecc-pm1-redc.c \
&gt;  		  ecc-curve25519.c ecc-curve448.c \
&gt; +		  ecc-gc256b.c \
&gt;  		  ecc-secp192r1.c ecc-secp224r1.c ecc-secp256r1.c \
&gt;  		  ecc-secp384r1.c ecc-secp521r1.c \
&gt;  		  ecc-size.c ecc-j-to-a.c ecc-a-to-j.c \
&gt; @@ -396,12 +397,21 @@ ecc-curve25519.h: eccdata.stamp
&gt;  ecc-curve448.h: eccdata.stamp
&gt;  	./eccdata$(EXEEXT_FOR_BUILD) curve448 38 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
&gt;  
&gt; +# Some reasonable choices for 256:
&gt; +# k =  9, c =  6, S = 320, T =  54 ( 45 A +  9 D) 20 KB
&gt; +# k = 11, c =  6, S = 256, T =  55 ( 44 A + 11 D) 16 KB
&gt; +# k = 19, c =  7, S = 256, T =  57 ( 38 A + 19 D) 16 KB
&gt; +# k = 15, c =  6, S = 192, T =  60 ( 45 A + 15 D) 12 KB
&gt; +ecc-gc256b.h: eccdata.stamp
&gt; +	./eccdata$(EXEEXT_FOR_BUILD) gc256b 11 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
&gt; +

These comments and choice copied from secp256r1? I see no reason to do
differently, but one can experiment using the eccparams.c program.

&gt; --- /dev/null
&gt; +++ b/ecc-gc256b.c
&gt; +
&gt; +/* Development of Nettle's ECC support was funded by the .SE Internet Fund. */

I don't think there's any reason to add this note to new files. The .SE
project was concluded in 2013.

&gt; +#if HAVE_CONFIG_H
&gt; +# include "config.h"
&gt; +#endif
&gt; +
&gt; +#include &lt;assert.h&gt;
&gt; +
&gt; +#include "ecc.h"
&gt; +#include "ecc-internal.h"
&gt; +
&gt; +#define USE_REDC (ECC_REDC_SIZE != 0)

I think you can do

  #define USE_REDC 0

unconditionally, and set the redc function pointer to NULL. (I guess
this applies to a few of the older files too). The only curve where this
conditional definition of USE_REDC seems useful is for secp384r1, where
we'll have ECC_REDC_SIZE != 0 on 32-bit archs but not on 64-bit.

Use of the ecc_pp1_redc and ecc_pm1_redc functions depend on p+1 or p-1
having at least one leading zero limb. A general redc function may be
useful for other less structured primes, but currently, we don't have
any.

&gt; +#include "ecc-gc256b.h"
&gt; +
&gt; +#if ECC_REDC_SIZE &gt; 0
&gt; +#  define ecc_gc256b_redc ecc_pp1_redc
&gt; +#elif ECC_REDC_SIZE == 0
&gt; +#  define ecc_gc256b_redc NULL
&gt; +#else
&gt; +# error Configuration error
&gt; +#endif
&gt; +
&gt; +static void
&gt; +ecc_gc256b_modp (const struct ecc_modulo *m, mp_limb_t *rp)
&gt; +{
&gt; +  mp_size_t mn = m-&gt;size;
&gt; +  mp_limb_t hi;
&gt; +
&gt; +  hi = mpn_addmul_1(rp, rp + mn, mn, 0x269);
&gt; +  hi = sec_add_1 (rp, rp, mn, hi * 0x269);
&gt; +  hi = sec_add_1 (rp, rp, mn, hi * 0x269);
&gt; +  assert(hi == 0);
&gt; +}

The last sec_add_1 could probably be a cnd_add with m-&gt;B. But perhaps
sec_add_1 is clearer.

&gt; +const struct ecc_curve *nettle_get_gc256b(void)
&gt; +{
&gt; +  return &amp;_nettle_gc256b;
&gt; +}

Would it make sense to add "gost" to this name, in similar position as
"secp" in other curves?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200112212229</emailId><senderName>Dmitry Eremin-Solenikov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-01-12 21:22:29-0400</timestampReceived><subject>Re: [PATCH v2 1/3] Add support for GOST GC256B curve</subject><body>

вс, 12 янв. 2020 г. в 23:45, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt;
&gt; dbaryshkov@gmail.com writes:
&gt;
&gt; &gt; From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;
&gt; &gt;
&gt; &gt; Add support for GC256B curve ("TLS Supported Groups" registry,
&gt; &gt; draft-smyshlyaev-tls12-gost-suites) also known as
&gt; &gt; GostR3410-2001-CryptoPro-A and GostR3410-2001-CryptoPro-XchA (RFC 4357).
&gt;
&gt; Thanks. Some comments below:
&gt;
&gt; &gt; --- a/Makefile.in
&gt; &gt; +++ b/Makefile.in
&gt; &gt; @@ -176,6 +176,7 @@ hogweed_SOURCES = sexp.c sexp-format.c \
&gt; &gt;                 ecc-mod.c ecc-mod-inv.c \
&gt; &gt;                 ecc-mod-arith.c ecc-pp1-redc.c ecc-pm1-redc.c \
&gt; &gt;                 ecc-curve25519.c ecc-curve448.c \
&gt; &gt; +               ecc-gc256b.c \
&gt; &gt;                 ecc-secp192r1.c ecc-secp224r1.c ecc-secp256r1.c \
&gt; &gt;                 ecc-secp384r1.c ecc-secp521r1.c \
&gt; &gt;                 ecc-size.c ecc-j-to-a.c ecc-a-to-j.c \
&gt; &gt; @@ -396,12 +397,21 @@ ecc-curve25519.h: eccdata.stamp
&gt; &gt;  ecc-curve448.h: eccdata.stamp
&gt; &gt;       ./eccdata$(EXEEXT_FOR_BUILD) curve448 38 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
&gt; &gt;
&gt; &gt; +# Some reasonable choices for 256:
&gt; &gt; +# k =  9, c =  6, S = 320, T =  54 ( 45 A +  9 D) 20 KB
&gt; &gt; +# k = 11, c =  6, S = 256, T =  55 ( 44 A + 11 D) 16 KB
&gt; &gt; +# k = 19, c =  7, S = 256, T =  57 ( 38 A + 19 D) 16 KB
&gt; &gt; +# k = 15, c =  6, S = 192, T =  60 ( 45 A + 15 D) 12 KB
&gt; &gt; +ecc-gc256b.h: eccdata.stamp
&gt; &gt; +     ./eccdata$(EXEEXT_FOR_BUILD) gc256b 11 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
&gt; &gt; +
&gt;
&gt; These comments and choice copied from secp256r1? I see no reason to do
&gt; differently, but one can experiment using the eccparams.c program.

Yes, c&amp;p from secp256r1.

&gt; &gt; --- /dev/null
&gt; &gt; +++ b/ecc-gc256b.c
&gt; &gt; +
&gt; &gt; +/* Development of Nettle's ECC support was funded by the .SE Internet Fund. */
&gt;
&gt; I don't think there's any reason to add this note to new files. The .SE
&gt; project was concluded in 2013.

Fine, I'll drop this.

&gt; &gt; +#if HAVE_CONFIG_H
&gt; &gt; +# include "config.h"
&gt; &gt; +#endif
&gt; &gt; +
&gt; &gt; +#include &lt;assert.h&gt;
&gt; &gt; +
&gt; &gt; +#include "ecc.h"
&gt; &gt; +#include "ecc-internal.h"
&gt; &gt; +
&gt; &gt; +#define USE_REDC (ECC_REDC_SIZE != 0)
&gt;
&gt; I think you can do
&gt;
&gt;   #define USE_REDC 0

Fine, that would be even simpler. I was mostly c&amp;p-sting from other ecc curves.


&gt; &gt; +static void
&gt; &gt; +ecc_gc256b_modp (const struct ecc_modulo *m, mp_limb_t *rp)
&gt; &gt; +{
&gt; &gt; +  mp_size_t mn = m-&gt;size;
&gt; &gt; +  mp_limb_t hi;
&gt; &gt; +
&gt; &gt; +  hi = mpn_addmul_1(rp, rp + mn, mn, 0x269);
&gt; &gt; +  hi = sec_add_1 (rp, rp, mn, hi * 0x269);
&gt; &gt; +  hi = sec_add_1 (rp, rp, mn, hi * 0x269);
&gt; &gt; +  assert(hi == 0);
&gt; &gt; +}
&gt;
&gt; The last sec_add_1 could probably be a cnd_add with m-&gt;B. But perhaps
&gt; sec_add_1 is clearer.

I don't remember why I chose sec_add_1() instead of cnd_add(). Most
probably to be safer.

&gt; &gt; +const struct ecc_curve *nettle_get_gc256b(void)
&gt; &gt; +{
&gt; &gt; +  return &amp;_nettle_gc256b;
&gt; &gt; +}
&gt;
&gt; Would it make sense to add "gost" to this name, in similar position as
&gt; "secp" in other curves?

I don't think so. Consider the names from "TLS Supported Groups" registry.

-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200115161757</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-15 16:17:57-0400</timestampReceived><subject>Re: [PATCH v2 1/3] Add support for GOST GC256B curve</subject><body>

Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt; writes:

&gt;&gt; &gt; +const struct ecc_curve *nettle_get_gc256b(void)
&gt;&gt; &gt; +{
&gt;&gt; &gt; +  return &amp;_nettle_gc256b;
&gt;&gt; &gt; +}
&gt;&gt;
&gt;&gt; Would it make sense to add "gost" to this name, in similar position as
&gt;&gt; "secp" in other curves?
&gt;
&gt; I don't think so. Consider the names from "TLS Supported Groups" registry.

I still think it would be appropriate with some more context for the
Nettle name, just "gc256b" is a bit too terse and obscure. Try doing a
web search for it. Some alternatives:

  nettle_get_gost_gc256b
  nettle_get_gost_curve_256b
  nettle_get_tls_gc256b

I can merge the support as is, but it would be good to agree on name
before release (and perhaps before adapting the gnutls code, to avoid
another renaming hassle there).

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200115171204</emailId><senderName>Dmitry Eremin-Solenikov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-01-15 17:12:04-0400</timestampReceived><subject>Re: [PATCH v2 1/3] Add support for GOST GC256B curve</subject><body>

Please excuse me for top-posting. I'll change the names t follow
gost_gc256b pattern, add documentation and submit v4.

-- 
With best wishes
Dmitry

ср, 15 янв. 2020 г., 19:17 Niels Möller &lt;nisse@lysator.liu.se&gt;:

&gt; Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt; writes:
&gt;
&gt; &gt;&gt; &gt; +const struct ecc_curve *nettle_get_gc256b(void)
&gt; &gt;&gt; &gt; +{
&gt; &gt;&gt; &gt; +  return &amp;_nettle_gc256b;
&gt; &gt;&gt; &gt; +}
&gt; &gt;&gt;
&gt; &gt;&gt; Would it make sense to add "gost" to this name, in similar position as
&gt; &gt;&gt; "secp" in other curves?
&gt; &gt;
&gt; &gt; I don't think so. Consider the names from "TLS Supported Groups"
&gt; registry.
&gt;
&gt; I still think it would be appropriate with some more context for the
&gt; Nettle name, just "gc256b" is a bit too terse and obscure. Try doing a
&gt; web search for it. Some alternatives:
&gt;
&gt;   nettle_get_gost_gc256b
&gt;   nettle_get_gost_curve_256b
&gt;   nettle_get_tls_gc256b
&gt;
&gt; I can merge the support as is, but it would be good to agree on name
&gt; before release (and perhaps before adapting the gnutls code, to avoid
&gt; another renaming hassle there).
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200107202017</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-07 20:20:17-0400</timestampReceived><subject>Re: [PATCH v3 2/3] ecc: prefix optimized ECC function names with underscore</subject><body>

dbaryshkov@gmail.com writes:

&gt; From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;
&gt;
&gt; There is no need to keep optimized ECC functions in public namespace
&gt; (nettle_*), move them to internal namespace (_nettle_*).

I agree this rename makes sense.

But it could be considered an ABI break, since we remove symbols with
version string "HOGWEED_5", matching the soname, and those symbols are
supposed to be stable as long as the soname is the same.

On the other hand, the symbols are not mentioned in docs or headers, and
they don't even exist in all configurations. So maybe it's ok to remove
them without changing the soname? That will break any application
needing them in libhogweed.so, but that application would break in the
same way if nettle were reconfigured with --disable-assembler.

I had a try with
http://codesearch.debian.net/search?q=nettle_ecc_.*modp&amp;literal=0, and
at least the functions appear unused outside of Nettle.

Opinions?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200109082218</emailId><senderName>Dmitry Eremin-Solenikov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-01-09 08:22:18-0400</timestampReceived><subject>Re: [PATCH v3 2/3] ecc: prefix optimized ECC function names with underscore</subject><body>

Hello,

вт, 7 янв. 2020 г. в 23:20, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt;
&gt; dbaryshkov@gmail.com writes:
&gt; &gt; From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;
&gt; &gt;
&gt; &gt; There is no need to keep optimized ECC functions in public namespace
&gt; &gt; (nettle_*), move them to internal namespace (_nettle_*).
&gt;
&gt; I agree this rename makes sense.
&gt;
&gt; But it could be considered an ABI break, since we remove symbols with
&gt; version string "HOGWEED_5", matching the soname, and those symbols are
&gt; supposed to be stable as long as the soname is the same.
&gt;
&gt; On the other hand, the symbols are not mentioned in docs or headers, and
&gt; they don't even exist in all configurations. So maybe it's ok to remove
&gt; them without changing the soname? That will break any application
&gt; needing them in libhogweed.so, but that application would break in the
&gt; same way if nettle were reconfigured with --disable-assembler.
&gt;
&gt; I had a try with
&gt; http://codesearch.debian.net/search?q=nettle_ecc_.*modp&amp;literal=0, and
&gt; at least the functions appear unused outside of Nettle.

So did I at the time of writing a patch, finding no actual users of
these functions. I think it is fine to drop them without bumping
soname.

-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200110200157</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-10 20:01:57-0400</timestampReceived><subject>Re: [PATCH v3 2/3] ecc: prefix optimized ECC function names with underscore</subject><body>

Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt; writes:

&gt; So did I at the time of writing a patch, finding no actual users of
&gt; these functions. I think it is fine to drop them without bumping
&gt; soname.

It seems none disagrees with that. I've merged all three patches to the
master-updates branch for testing.

Thanks,
/Niels Möller

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200111212326</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-01-11 21:23:26-0400</timestampReceived><subject>[PATCH v2 2/3] Add support for GOST GC512A curve</subject><body>

From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;

Add support for GC512A curve ("TLS Supported Groups" registry,
draft-smyshlyaev-tls12-gost-suites) also known as
tc26-gost-3410-12-512-paramSetA (RFC 7836).

Signed-off-by: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;
---
 .gitignore               |   1 +
 Makefile.in              |  13 +++-
 ecc-curve.h              |   1 +
 ecc-gc512a.c             | 140 +++++++++++++++++++++++++++++++++++++++
 ecc-internal.h           |   1 +
 eccdata.c                | 139 ++++++++++++++++++++++++++++++++++++++
 examples/ecc-benchmark.c |   1 +
 testsuite/testutils.c    |  18 ++++-
 8 files changed, 310 insertions(+), 4 deletions(-)
 create mode 100644 ecc-gc512a.c

diff --git a/.gitignore b/.gitignore
index 4454ade5a950..2e64c187574f 100644
--- a/.gitignore
+++ b/.gitignore
@@ -46,6 +46,7 @@ core
 /ecc-curve25519.h
 /ecc-curve448.h
 /ecc-gc256b.h
+/ecc-gc512a.h
 /ecc-secp192r1.h
 /ecc-secp224r1.h
 /ecc-secp256r1.h
diff --git a/Makefile.in b/Makefile.in
index 8815e7b76dea..28672c8546ea 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -176,7 +176,7 @@ hogweed_SOURCES = sexp.c sexp-format.c \
 		  ecc-mod.c ecc-mod-inv.c \
 		  ecc-mod-arith.c ecc-pp1-redc.c ecc-pm1-redc.c \
 		  ecc-curve25519.c ecc-curve448.c \
-		  ecc-gc256b.c \
+		  ecc-gc256b.c ecc-gc512a.c \
 		  ecc-secp192r1.c ecc-secp224r1.c ecc-secp256r1.c \
 		  ecc-secp384r1.c ecc-secp521r1.c \
 		  ecc-size.c ecc-j-to-a.c ecc-a-to-j.c \
@@ -405,6 +405,14 @@ ecc-curve448.h: eccdata.stamp
 ecc-gc256b.h: eccdata.stamp
 	./eccdata$(EXEEXT_FOR_BUILD) gc256b 11 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
 
+# Some reasonable choices for 512:
+# k = 29, c =  6, S = 192, T = 116 ( 87 A + 29 D)
+# k = 21, c =  5, S = 160, T = 126 (105 A + 21 D)
+# k = 43, c =  6, S = 128, T = 129 ( 86 A + 43 D)
+# k = 35, c =  5, S =  96, T = 140 (105 A + 35 D)
+ecc-gc512a.h: eccdata.stamp
+	./eccdata$(EXEEXT_FOR_BUILD) gc512a 43 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
+
 eccdata.stamp: eccdata.c
 	$(MAKE) eccdata$(EXEEXT_FOR_BUILD)
 	echo stamp &gt; eccdata.stamp
@@ -412,6 +420,7 @@ eccdata.stamp: eccdata.c
 ecc-curve25519.$(OBJEXT): ecc-curve25519.h
 ecc-curve448.$(OBJEXT): ecc-curve448.h
 ecc-gc256b.$(OBJEXT): ecc-gc256b.h
+ecc-gc512a.$(OBJEXT): ecc-gc512a.h
 ecc-secp192r1.$(OBJEXT): ecc-secp192r1.h
 ecc-secp224r1.$(OBJEXT): ecc-secp224r1.h
 ecc-secp256r1.$(OBJEXT): ecc-secp256r1.h
@@ -670,7 +679,7 @@ distcheck: dist
 clean-here:
 	-rm -f $(TARGETS) *.$(OBJEXT) *.s *.so *.dll *.a \
 		ecc-curve25519.h ecc-curve448.h \
-		ecc-gc256b.h \
+		ecc-gc256b.h ecc-gc512a.h \
 		ecc-secp192r1.h ecc-secp224r1.h ecc-secp256r1.h \
 		ecc-secp384r1.h ecc-secp521r1.h \
 		aesdata$(EXEEXT_FOR_BUILD) \
diff --git a/ecc-curve.h b/ecc-curve.h
index b378c8489839..93e1585ba15b 100644
--- a/ecc-curve.h
+++ b/ecc-curve.h
@@ -44,6 +44,7 @@ extern "C" {
 struct ecc_curve;
 
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_gc256b(void);
+const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_gc512a(void);
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_secp_192r1(void);
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_secp_224r1(void);
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_secp_256r1(void);
diff --git a/ecc-gc512a.c b/ecc-gc512a.c
new file mode 100644
index 000000000000..cc7be928fa6e
--- /dev/null
+++ b/ecc-gc512a.c
@@ -0,0 +1,140 @@
+/* ecc-gc512a.c
+
+   Compile time constant (but machine dependent) tables.
+
+   Copyright (C) 2016, 2019 Dmitry Eremin-Solenikov
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+/* Development of Nettle's ECC support was funded by the .SE Internet Fund. */
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+
+#include "ecc.h"
+#include "ecc-internal.h"
+
+#define USE_REDC (ECC_REDC_SIZE != 0)
+
+#include "ecc-gc512a.h"
+
+#if ECC_REDC_SIZE &gt; 0
+#  define ecc_gc512a_redc ecc_pp1_redc
+#elif ECC_REDC_SIZE == 0
+#  define ecc_gc512a_redc NULL
+#else
+# error Configuration error
+#endif
+
+static void
+ecc_gc512a_modp (const struct ecc_modulo *m, mp_limb_t *rp)
+{
+  mp_size_t mn = m-&gt;size;
+  mp_limb_t hi;
+
+  hi = mpn_addmul_1(rp, rp + mn, mn, 0x239);
+  hi = sec_add_1 (rp, rp, mn, hi * 0x239);
+  hi = sec_add_1 (rp, rp, mn, hi * 0x239);
+  assert(hi == 0);
+}
+
+#define ecc_gc512a_modp ecc_gc512a_modp
+#define ecc_gc512a_modq ecc_mod
+
+const struct ecc_curve _nettle_gc512a =
+{
+  {
+    512,
+    ECC_LIMB_SIZE,
+    ECC_BMODP_SIZE,
+    ECC_REDC_SIZE,
+    ECC_MOD_INV_ITCH (ECC_LIMB_SIZE),
+    0,
+
+    ecc_p,
+    ecc_Bmodp,
+    ecc_Bmodp_shifted,
+    ecc_redc_ppm1,
+
+    ecc_pp1h,
+    ecc_gc512a_modp,
+    USE_REDC ? ecc_gc512a_redc : ecc_gc512a_modp,
+    ecc_mod_inv,
+    NULL,
+  },
+  {
+    512,
+    ECC_LIMB_SIZE,
+    ECC_BMODQ_SIZE,
+    0,
+    ECC_MOD_INV_ITCH (ECC_LIMB_SIZE),
+    0,
+
+    ecc_q,
+    ecc_Bmodq,
+    ecc_Bmodq_shifted,
+    NULL,
+    ecc_qp1h,
+
+    ecc_gc512a_modq,
+    ecc_gc512a_modq,
+    ecc_mod_inv,
+    NULL,
+  },
+
+  USE_REDC,
+  ECC_PIPPENGER_K,
+  ECC_PIPPENGER_C,
+
+  ECC_ADD_JJA_ITCH (ECC_LIMB_SIZE),
+  ECC_ADD_JJJ_ITCH (ECC_LIMB_SIZE),
+  ECC_DUP_JJ_ITCH (ECC_LIMB_SIZE),
+  ECC_MUL_A_ITCH (ECC_LIMB_SIZE),
+  ECC_MUL_G_ITCH (ECC_LIMB_SIZE),
+  ECC_J_TO_A_ITCH (ECC_LIMB_SIZE),
+
+  ecc_add_jja,
+  ecc_add_jjj,
+  ecc_dup_jj,
+  ecc_mul_a,
+  ecc_mul_g,
+  ecc_j_to_a,
+
+  ecc_b,
+  ecc_g,
+  ecc_unit,
+  ecc_table
+};
+
+const struct ecc_curve *nettle_get_gc512a(void)
+{
+  return &amp;_nettle_gc512a;
+}
diff --git a/ecc-internal.h b/ecc-internal.h
index 0972efaf10d1..733d7fe0273e 100644
--- a/ecc-internal.h
+++ b/ecc-internal.h
@@ -93,6 +93,7 @@ extern const struct ecc_curve _nettle_curve448;
 
 /* GOST curves, visible with underscore prefix for now */
 extern const struct ecc_curve _nettle_gc256b;
+extern const struct ecc_curve _nettle_gc512a;
 
 #define ECC_MAX_SIZE ((521 + GMP_NUMB_BITS - 1) / GMP_NUMB_BITS)
 
diff --git a/eccdata.c b/eccdata.c
index 3820e150125b..0217601fe5b9 100644
--- a/eccdata.c
+++ b/eccdata.c
@@ -705,6 +705,145 @@ ecc_curve_init (struct ecc_curve *ecc, const char *curve)
 		   "f7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e4b7",
 		   "83ccf17ba6706d73625cc3534c7a2b9d6ec1ee6a9a7e07c10d84b388de59f741");
 
+    }
+  else if (!strcmp (curve, "gc256c"))
+    {
+      ecc_curve_init_str (ecc, ECC_TYPE_WEIERSTRASS,
+			  "80000000000000000000000000000000"
+			  "00000000000000000000000000000c99",
+
+			  "3e1af419a269a5f866a7d3c25c3df80a"
+			  "e979259373ff2b182f49d4ce7e1bbc8b",
+
+			  "80000000000000000000000000000001"
+			  "5f700cfff1a624e5e497161bcc8a198f",
+
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000001",
+
+			  "3fa8124359f96680b83d1c3eb2c070e5"
+			  "c545c9858d03ecfb744bf8d717717efc");
+
+      ecc-&gt;ref = ecc_alloc (3);
+      ecc_set_str (&amp;ecc-&gt;ref[0], /* 2 g */
+		   "8000000000000000000000000000000000000000000000000000000000000c97",
+		   "4057edbca606997f47c2e3c14d3f8f1a3aba367a72fc13048bb40728e88e8d9d");
+
+      ecc_set_str (&amp;ecc-&gt;ref[1], /* 3 g */
+		   "1b9a33999d8449c3bbd8cfe49ac6355a2ee0827a6c71687c86cb7b0670efe205",
+		   "1876d998a19da37a120e76cb42f4f5225197279b612f712171a4648fe4a3ff12");
+
+      ecc_set_str (&amp;ecc-&gt;ref[2], /* 4 g */
+		   "5fa13ecfadd7ae00c2e65d0ac6cac1deda6d60e577afe90915671b08bbb9065e",
+		   "1b3c2859166129ac6dafee570ab9d40d33fdc25c7253c72f4e3fa77223ab016a");
+
+    }
+  else if (!strcmp (curve, "gc256d"))
+    {
+      ecc_curve_init_str (ecc, ECC_TYPE_WEIERSTRASS,
+			  "9b9f605f5a858107ab1ec85e6b41c8aa"
+			  "cf846e86789051d37998f7b9022d759b",
+
+			  "00000000000000000000000000000000"
+			  "0000000000000000000000000000805a",
+
+			  "9b9f605f5a858107ab1ec85e6b41c8aa"
+			  "582ca3511eddfb74f02f3a6598980bb9",
+
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000000",
+
+			  "41ece55743711a8c3cbf3783cd08c0ee"
+			  "4d4dc440d4641a8f366e550dfdb3bb67");
+      ecc-&gt;ref = ecc_alloc (3);
+      ecc_set_str (&amp;ecc-&gt;ref[0], /* 2 g */
+		   "74ab1ac14e9ed5cda1af70308c897ebf3d91d913a7bf377833c436bf0f8aa40e",
+		   "7d223beab738ba52a65ffbfe585d2807bfaed5ea9cd651a63a775b4182f562e3");
+
+      ecc_set_str (&amp;ecc-&gt;ref[1], /* 3 g */
+		   "771e56689775fda0bbdeac54e9cd379f30391edf06f335269c48f06446cd037a",
+		   "8430215fbee8a09c5e38bda64b50bbef41392d6afa5ced73652c83cb5221d02b");
+
+      ecc_set_str (&amp;ecc-&gt;ref[2], /* 4 g */
+		   "4fe44356aded59b4b661e9da15fe79dbcb1d7346770919c5c99090e5ae4db8a6",
+		   "24f0222027a3d2577cca5aefb5411c88f92f5f4b8febddebc71c12180640ebfd");
+
+    }
+  else if (!strcmp (curve, "gc512a"))
+    {
+      ecc_curve_init_str (ecc, ECC_TYPE_WEIERSTRASS,
+			  "ffffffffffffffffffffffffffffffff"
+			  "ffffffffffffffffffffffffffffffff"
+			  "ffffffffffffffffffffffffffffffff"
+			  "fffffffffffffffffffffffffffffdc7",
+			  "e8c2505dedfc86ddc1bd0b2b6667f1da"
+			  "34b82574761cb0e879bd081cfd0b6265"
+			  "ee3cb090f30d27614cb4574010da90dd"
+			  "862ef9d4ebee4761503190785a71c760",
+			  "ffffffffffffffffffffffffffffffff"
+			  "ffffffffffffffffffffffffffffffff"
+			  "27e69532f48d89116ff22b8d4e056060"
+			  "9b4b38abfad2b85dcacdb1411f10b275",
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000003",
+			  "7503cfe87a836ae3a61b8816e25450e6"
+			  "ce5e1c93acf1abc1778064fdcbefa921"
+			  "df1626be4fd036e93d75e6a50e3a41e9"
+			  "8028fe5fc235f5b889a589cb5215f2a4");
+
+      ecc-&gt;ref = ecc_alloc (3);
+      ecc_set_str (&amp;ecc-&gt;ref[0], /* 2 g */
+		   "3b89dcfc622996ab97a5869dbff15cf51db00954f43a58a5e5f6b0470a132b2f4434bbcd405d2a9516151d2a6a04f2e4375bf48de1fdb21fb982afd9d2ea137c",
 +		   "c813c4e2e2e0a8a391774c7903da7a6f14686e98e183e670ee6fb784809a3e92ca209dc631d85b1c7534ed3b37fddf64d854d7e01f91f18bb3fd307591afc051");
 +
+      ecc_set_str (&amp;ecc-&gt;ref[1], /* 3 g */
+		   "a1ff1ab2712a267eb53935ddb5a567f84db156cc096168a1174291d5f488fba543d2840b4d2dd35d764b2f57b308907aec55cfba10544e8416e134687ccb87c3",
 +		   "3cb5c4417ec4637f30374f189bb5b984c41e3a48d7f84fbfa3819e3f333f7eb311d3af7e67c4c16eeacfac2fe94c6dd4c6366f711a4fb6c7125cd7ec518d90d6");
 +
+      ecc_set_str (&amp;ecc-&gt;ref[2], /* 4 g */
+		   "b7bfb80956c8670031ba191929f64e301d681634236d47a60e571a4bedc0ef257452ef78b5b98dbb3d9f3129d9349433ce2a3a35cb519c91e2d633d7b373ae16",
 +		   "3bee95e29eecc5d5ad2beba941abcbf9f1cad478df0fecf614f63aeebef77850da7efdb93de8f3df80bc25eac09239c14175f5c29704ce9a3e383f1b3ec0e929");
 +
+    }
+  else if (!strcmp (curve, "gc512b"))
+    {
+      ecc_curve_init_str (ecc, ECC_TYPE_WEIERSTRASS,
+			  "80000000000000000000000000000000"
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000000"
+			  "0000000000000000000000000000006f",
+			  "687d1b459dc841457e3e06cf6f5e2517"
+			  "b97c7d614af138bcbf85dc806c4b289f"
+			  "3e965d2db1416d217f8b276fad1ab69c"
+			  "50f78bee1fa3106efb8ccbc7c5140116",
+			  "80000000000000000000000000000000"
+			  "00000000000000000000000000000001"
+			  "49a1ec142565a545acfdb77bd9d40cfa"
+			  "8b996712101bea0ec6346c54374f25bd",
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000002",
+			  "1a8f7eda389b094c2c071e3647a8940f"
+			  "3c123b697578c213be6dd9e6c8ec7335"
+			  "dcb228fd1edf4a39152cbcaaf8c03988"
+			  "28041055f94ceeec7e21340780fe41bd");
+
+      ecc-&gt;ref = ecc_alloc (3);
+      ecc_set_str (&amp;ecc-&gt;ref[0], /* 2 g */
+		   "73729fb3c0d629ae5dc9bf88ca05d518bce91e502150f5e5822fa0293bc0e3ca31145f3b0e1831d8bb1f20b28780011473339e581a403c676b47c1f9ab764602",
 +		   "35d62c90549f2c17e16c6ea99d3c3dbe610f2c543fc1d0ca5bd48a5ea1d3ec11c3cec5e7fcd74b5306e73b6a8e40c818714f02b25997ee2b54f65432d3f0741e");
 +
+      ecc_set_str (&amp;ecc-&gt;ref[1], /* 3 g */
+		   "1826b56c8dc1d5779b76354070e744f2c9c82755a921142b528f2fe04f5fd0dbdc178314c4546270b423d9fe819ba4c82625b02004bfdf90a08317dceb9309b7",
 +		   "4f6882f8f6422d693f8313bb7b121117ad9ee6b8874135f3e4bff91b01141fdb35d29bc3cf15ab8a3b751050e58392a8eeae790ea5d198eab642dc520fd1713f");
 +
+      ecc_set_str (&amp;ecc-&gt;ref[2], /* 4 g */
+		   "5af069b1624dba4513c303b66b90543d97dbec20b5ba013e4f43ed9e2b88bdc5ac69701b626a8a546d03d52f8510d50df944978b0d33565ab75599b0d0a18563",
 +		   "19eb28c4ee08a66894ca5cb76e160478a4f94c061b1115357557dacd5370bfc22bd1d0faa2e9d72af11ae65cb2335c53f617052331eb56050a972da4efe55eb7");
 +
     }
   else if (!strcmp (curve, "curve448"))
     {
diff --git a/examples/ecc-benchmark.c b/examples/ecc-benchmark.c
index 497c76c3e550..d728d0c96824 100644
--- a/examples/ecc-benchmark.c
+++ b/examples/ecc-benchmark.c
@@ -315,6 +315,7 @@ const struct ecc_curve * const curves[] = {
   &amp;_nettle_curve448,
   &amp;_nettle_secp_521r1,
   &amp;_nettle_gc256b,
+  &amp;_nettle_gc512a,
 };
 
 #define numberof(x)  (sizeof (x) / sizeof ((x)[0]))
diff --git a/testsuite/testutils.c b/testsuite/testutils.c
index e4e7c23dcc1b..8b17b8f424aa 100644
--- a/testsuite/testutils.c
+++ b/testsuite/testutils.c
@@ -1678,6 +1678,7 @@ const struct ecc_curve * const ecc_curves[] = {
   &amp;_nettle_curve25519,
   &amp;_nettle_curve448,
   &amp;_nettle_gc256b,
+  &amp;_nettle_gc512a,
   NULL
 };
 
@@ -1729,7 +1730,7 @@ void
 test_ecc_mul_a (unsigned curve, unsigned n, const mp_limb_t *p)
 {
   /* For each curve, the points 2 g, 3 g and 4 g */
-  static const struct ecc_ref_point ref[8][3] = {
+  static const struct ecc_ref_point ref[9][3] = {
     { { "dafebf5828783f2ad35534631588a3f629a70fb16982a888",
 	"dd6bda0d993da0fa46b27bbc141b868f59331afa5c7e93ab" },
       { "76e32a2557599e6edcd283201fb2b9aadfd0d359cbb263da",
@@ -1804,9 +1805,22 @@ test_ecc_mul_a (unsigned curve, unsigned n, const mp_limb_t \
*p)  "76bcd1ca9a23b041d4d9baf507a6cd821267a94c838768e8486117796b788a51" },
       { "f7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e4b7",
 	"83ccf17ba6706d73625cc3534c7a2b9d6ec1ee6a9a7e07c10d84b388de59f741" },
+    },
+    { { "3b89dcfc622996ab97a5869dbff15cf51db00954f43a58a5e5f6b0470a132b2f"
+	"4434bbcd405d2a9516151d2a6a04f2e4375bf48de1fdb21fb982afd9d2ea137c",
+	"c813c4e2e2e0a8a391774c7903da7a6f14686e98e183e670ee6fb784809a3e92"
+	"ca209dc631d85b1c7534ed3b37fddf64d854d7e01f91f18bb3fd307591afc051" },
+      { "a1ff1ab2712a267eb53935ddb5a567f84db156cc096168a1174291d5f488fba5"
+	"43d2840b4d2dd35d764b2f57b308907aec55cfba10544e8416e134687ccb87c3",
+	"3cb5c4417ec4637f30374f189bb5b984c41e3a48d7f84fbfa3819e3f333f7eb3"
+	"11d3af7e67c4c16eeacfac2fe94c6dd4c6366f711a4fb6c7125cd7ec518d90d6" },
+      { "b7bfb80956c8670031ba191929f64e301d681634236d47a60e571a4bedc0ef25"
+	"7452ef78b5b98dbb3d9f3129d9349433ce2a3a35cb519c91e2d633d7b373ae16",
+	"3bee95e29eecc5d5ad2beba941abcbf9f1cad478df0fecf614f63aeebef77850"
+	"da7efdb93de8f3df80bc25eac09239c14175f5c29704ce9a3e383f1b3ec0e929" },
     }
   };
-  assert (curve &lt; 8);
+  assert (curve &lt; 9);
   assert (n &lt;= 4);
   if (n == 0)
     {
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200111212327</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-01-11 21:23:27-0400</timestampReceived><subject>[PATCH v2 3/3] Add GOST DSA according to GOST R 34.10-2001/-2012</subject><body>

From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;

Add GOST Digital Signature Algorithms support according to GOST R
34.10-2001/-2012. English translations of these standards are provided
as RFC 5832 and RFC 7091.

Signed-off-by: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;
---
 Makefile.in                     |   4 +-
 ecc-gostdsa-sign.c              | 103 +++++++++++++++++++++
 ecc-gostdsa-verify.c            | 132 +++++++++++++++++++++++++++
 ecc-hash.c                      |  11 +++
 ecc-internal.h                  |   7 ++
 gostdsa-sign.c                  |  76 ++++++++++++++++
 gostdsa-verify.c                |  80 +++++++++++++++++
 gostdsa.h                       | 102 +++++++++++++++++++++
 testsuite/.gitignore            |   3 +
 testsuite/.test-rules.make      |   9 ++
 testsuite/Makefile.in           |   4 +-
 testsuite/gostdsa-keygen-test.c | 154 ++++++++++++++++++++++++++++++++
 testsuite/gostdsa-sign-test.c   |  87 ++++++++++++++++++
 testsuite/gostdsa-verify-test.c | 110 +++++++++++++++++++++++
 testsuite/testutils.h           |   1 +
 15 files changed, 881 insertions(+), 2 deletions(-)
 create mode 100644 ecc-gostdsa-sign.c
 create mode 100644 ecc-gostdsa-verify.c
 create mode 100644 gostdsa-sign.c
 create mode 100644 gostdsa-verify.c
 create mode 100644 gostdsa.h
 create mode 100644 testsuite/gostdsa-keygen-test.c
 create mode 100644 testsuite/gostdsa-sign-test.c
 create mode 100644 testsuite/gostdsa-verify-test.c

diff --git a/Makefile.in b/Makefile.in
index 28672c8546ea..05111eded397 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -189,6 +189,8 @@ hogweed_SOURCES = sexp.c sexp-format.c \
 		  ecc-point.c ecc-scalar.c ecc-point-mul.c ecc-point-mul-g.c \
 		  ecc-ecdsa-sign.c ecdsa-sign.c \
 		  ecc-ecdsa-verify.c ecdsa-verify.c ecdsa-keygen.c \
+		  ecc-gostdsa-sign.c gostdsa-sign.c \
+		  ecc-gostdsa-verify.c gostdsa-verify.c \
 		  curve25519-mul-g.c curve25519-mul.c curve25519-eh-to-x.c \
 		  curve448-mul-g.c curve448-mul.c curve448-eh-to-x.c \
 		  eddsa-compress.c eddsa-decompress.c eddsa-expand.c \
@@ -205,7 +207,7 @@ HEADERS = aes.h arcfour.h arctwo.h asn1.h blowfish.h \
 	  cbc.h ccm.h cfb.h chacha.h chacha-poly1305.h ctr.h \
 	  curve25519.h curve448.h des.h dsa.h dsa-compat.h eax.h \
 	  ecc-curve.h ecc.h ecdsa.h eddsa.h \
-	  gcm.h gost28147.h gosthash94.h hmac.h \
+	  gcm.h gost28147.h gostdsa.h gosthash94.h hmac.h \
 	  knuth-lfib.h hkdf.h \
 	  macros.h \
 	  cmac.h siv-cmac.h \
diff --git a/ecc-gostdsa-sign.c b/ecc-gostdsa-sign.c
new file mode 100644
index 000000000000..0b8671d382ec
--- /dev/null
+++ b/ecc-gostdsa-sign.c
@@ -0,0 +1,103 @@
+/* ecc-gostdsa-sign.c
+
+   Copyright (C) 2015 Dmitry Eremin-Solenikov
+   Copyright (C) 2013, 2014 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+/* Development of Nettle's ECC support was funded by the .SE Internet Fund. */
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;stdlib.h&gt;
+
+#include "gostdsa.h"
+#include "ecc-internal.h"
+
+/* Low-level GOST DSA signing */
+
+mp_size_t
+ecc_gostdsa_sign_itch (const struct ecc_curve *ecc)
+{
+  /* Needs 3*ecc-&gt;p.size + scratch for ecc-&gt;mul_g. Currently same for
+     ecc_mul_g and ecc_mul_g_eh. */
+  return ECC_GOSTDSA_SIGN_ITCH (ecc-&gt;p.size);
+}
+
+/* NOTE: Caller should check if r or s is zero. */
+void
+ecc_gostdsa_sign (const struct ecc_curve *ecc,
+		const mp_limb_t *zp,
+		const mp_limb_t *kp,
+		size_t length, const uint8_t *digest,
+		mp_limb_t *rp, mp_limb_t *sp,
+		mp_limb_t *scratch)
+{
+#define P	    scratch
+#define hp	    (scratch + 4*ecc-&gt;p.size)
+#define tp	    (scratch + 2*ecc-&gt;p.size)
+#define t2p	    scratch
+  /* Procedure, according to GOST 34.10. q denotes the group
+     order.
+
+     1. k &lt;-- uniformly random, 0 &lt; k &lt; q
+
+     2. C &lt;-- (c_x, c_y) = k g
+
+     3. r &lt;-- c_x mod q
+
+     4. s &lt;-- (r*z + k*h) mod q.
+  */
+
+  ecc-&gt;mul_g (ecc, P, kp, P + 3*ecc-&gt;p.size);
+  /* x coordinate only, modulo q */
+  ecc-&gt;h_to_a (ecc, 2, rp, P, P + 3*ecc-&gt;p.size);
+
+  /* Process hash digest */
+  gost_hash (&amp;ecc-&gt;q, hp, length, digest);
+  if (mpn_zero_p (hp, ecc-&gt;p.size))
+    mpn_add_1 (hp, hp, ecc-&gt;p.size, 1);
+
+  ecc_modq_mul (ecc, tp, rp, zp);
+  ecc_modq_mul (ecc, t2p, kp, hp);
+  ecc_modq_add (ecc, sp, tp, t2p);
+
+  /* Also reduce mod ecc-&gt;q. It should already be &lt; 2*ecc-&gt;q,
+   * so one subtraction should suffice. */
+
+  *scratch = mpn_sub_n (tp, sp, ecc-&gt;q.m, ecc-&gt;p.size);
+  cnd_copy (*scratch == 0, sp, tp, ecc-&gt;p.size);
+
+#undef P
+#undef hp
+#undef tp
+#undef t2p
+}
diff --git a/ecc-gostdsa-verify.c b/ecc-gostdsa-verify.c
new file mode 100644
index 000000000000..44f87b892f75
--- /dev/null
+++ b/ecc-gostdsa-verify.c
@@ -0,0 +1,132 @@
+/* ecc-gostdsa-verify.c
+
+   Copyright (C) 2015 Dmitry Eremin-Solenikov
+   Copyright (C) 2013, 2014 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+/* Development of Nettle's ECC support was funded by the .SE Internet Fund. */
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;stdlib.h&gt;
+
+#include "gostdsa.h"
+#include "ecc-internal.h"
+
+/* Low-level GOST DSA verify */
+
+static int
+ecdsa_in_range (const struct ecc_curve *ecc, const mp_limb_t *xp)
+{
+  return !mpn_zero_p (xp, ecc-&gt;p.size)
+    &amp;&amp; mpn_cmp (xp, ecc-&gt;q.m, ecc-&gt;p.size) &lt; 0;
+}
+
+mp_size_t
+ecc_gostdsa_verify_itch (const struct ecc_curve *ecc)
+{
+  /* Largest storage need is for the ecc-&gt;mul call. */
+  return 5*ecc-&gt;p.size + ecc-&gt;mul_itch;
+}
+
+/* FIXME: Use faster primitives, not requiring side-channel silence. */
+int
+ecc_gostdsa_verify (const struct ecc_curve *ecc,
+		  const mp_limb_t *pp, /* Public key */
+		  size_t length, const uint8_t *digest,
+		  const mp_limb_t *rp, const mp_limb_t *sp,
+		  mp_limb_t *scratch)
+{
+  /* Procedure, according to GOST R 34.10. q denotes the group
+     order.
+
+     1. Check 0 &lt; r, s &lt; q.
+
+     2. v &lt;-- h^{-1}  (mod q)
+
+     3. z1  &lt;-- s * v (mod q)
+
+     4. z2  &lt;-- -r * v (mod q)
+
+     5. R = u1 G + u2 Y
+
+     6. Signature is valid if R_x = r (mod q).
+  */
+
+#define hp (scratch)
+#define vp (scratch + ecc-&gt;p.size)
+#define z1 (scratch + 3*ecc-&gt;p.size)
+#define z2 (scratch + 4*ecc-&gt;p.size)
+
+#define P1 (scratch + 4*ecc-&gt;p.size)
+#define P2 (scratch)
+
+
+  if (! (ecdsa_in_range (ecc, rp)
+	 &amp;&amp; ecdsa_in_range (ecc, sp)))
+    return 0;
+
+  gost_hash (&amp;ecc-&gt;q, hp, length, digest);
+
+  if (mpn_zero_p (hp, ecc-&gt;p.size))
+    mpn_add_1 (hp, hp, ecc-&gt;p.size, 1);
+
+  /* Compute v */
+  ecc-&gt;q.invert (&amp;ecc-&gt;q, vp, hp, vp + 2*ecc-&gt;p.size);
+
+  /* z1 = s / h, P1 = z1 * G */
+  ecc_modq_mul (ecc, z1, sp, vp);
+
+  /* z2 = - r / h, P2 = z2 * Y */
+  ecc_modq_mul (ecc, z2, rp, vp);
+  mpn_sub_n (z2, ecc-&gt;q.m, z2, ecc-&gt;p.size);
+
+   /* Total storage: 5*ecc-&gt;p.size + ecc-&gt;mul_itch */
+  ecc-&gt;mul (ecc, P2, z2, pp, z2 + ecc-&gt;p.size);
+
+  /* Total storage: 7*ecc-&gt;p.size + ecc-&gt;mul_g_itch (ecc-&gt;p.size) */
+  ecc-&gt;mul_g (ecc, P1, z1, P1 + 3*ecc-&gt;p.size);
+
+  /* Total storage: 6*ecc-&gt;p.size + ecc-&gt;add_hhh_itch */
+  ecc-&gt;add_hhh (ecc, P1, P1, P2, P1 + 3*ecc-&gt;p.size);
+
+  /* x coordinate only, modulo q */
+  ecc-&gt;h_to_a (ecc, 2, P2, P1, P1 + 3*ecc-&gt;p.size);
+
+  return (mpn_cmp (rp, P2, ecc-&gt;p.size) == 0);
+#undef P2
+#undef P1
+#undef z2
+#undef z1
+#undef hp
+#undef vp
+}
diff --git a/ecc-hash.c b/ecc-hash.c
index 4e830a514ac4..07877110263f 100644
--- a/ecc-hash.c
+++ b/ecc-hash.c
@@ -62,3 +62,14 @@ ecc_hash (const struct ecc_modulo *m,
     /* We got a few extra bits, at the low end. Discard them. */
     mpn_rshift (hp, hp, m-&gt;size + 1, 8*length - m-&gt;bit_size);
 }
+
+void
+gost_hash (const struct ecc_modulo *m,
+	   mp_limb_t *hp,
+	   size_t length, const uint8_t *digest)
+{
+  if (length &gt; ((size_t) m-&gt;bit_size + 7) / 8)
+    length = (m-&gt;bit_size + 7) / 8;
+
+  mpn_set_base256_le (hp, m-&gt;size + 1, digest, length);
+}
diff --git a/ecc-internal.h b/ecc-internal.h
index 733d7fe0273e..c3d66517f5fd 100644
--- a/ecc-internal.h
+++ b/ecc-internal.h
@@ -53,6 +53,7 @@
 #define ecc_mod _nettle_ecc_mod
 #define ecc_mod_inv _nettle_ecc_mod_inv
 #define ecc_hash _nettle_ecc_hash
+#define gost_hash _nettle_gost_hash
 #define ecc_a_to_j _nettle_ecc_a_to_j
 #define ecc_j_to_a _nettle_ecc_j_to_a
 #define ecc_eh_to_a _nettle_ecc_eh_to_a
@@ -288,6 +289,11 @@ ecc_hash (const struct ecc_modulo *m,
 	  mp_limb_t *hp,
 	  size_t length, const uint8_t *digest);
 
+void
+gost_hash (const struct ecc_modulo *m,
+	  mp_limb_t *hp,
+	  size_t length, const uint8_t *digest);
+
 /* Converts a point P in affine coordinates into a point R in jacobian
    coordinates. */
 void
@@ -456,6 +462,7 @@ curve448_eh_to_x (mp_limb_t *xp, const mp_limb_t *p,
 #endif
 #define ECC_MUL_M_ITCH(size) (11*(size))
 #define ECC_ECDSA_SIGN_ITCH(size) (12*(size))
+#define ECC_GOSTDSA_SIGN_ITCH(size) (12*(size))
 #define ECC_MOD_RANDOM_ITCH(size) (size)
 #define ECC_HASH_ITCH(size) (1+(size))
 
diff --git a/gostdsa-sign.c b/gostdsa-sign.c
new file mode 100644
index 000000000000..598654ac34f1
--- /dev/null
+++ b/gostdsa-sign.c
@@ -0,0 +1,76 @@
+/* gostdsa-sign.c
+
+   Copyright (C) 2015 Dmitry Eremin-Solenikov
+   Copyright (C) 2013 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+/* Development of Nettle's ECC support was funded by the .SE Internet Fund. */
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;stdlib.h&gt;
+
+#include "gostdsa.h"
+#include "ecc-internal.h"
+#include "nettle-internal.h"
+
+void
+gostdsa_sign (const struct ecc_scalar *key,
+	    void *random_ctx, nettle_random_func *random,
+	    size_t digest_length,
+	    const uint8_t *digest,
+	    struct dsa_signature *signature)
+{
+  /* At most 936 bytes. */
+  TMP_DECL(k, mp_limb_t, ECC_MAX_SIZE + ECC_GOSTDSA_SIGN_ITCH (ECC_MAX_SIZE));
+  mp_limb_t size = key-&gt;ecc-&gt;p.size;
+  mp_limb_t *rp = mpz_limbs_write (signature-&gt;r, size);
+  mp_limb_t *sp = mpz_limbs_write (signature-&gt;s, size);
+
+  TMP_ALLOC (k, size + ECC_GOSTDSA_SIGN_ITCH (size));
+
+  /* Timing reveals the number of rounds through this loop, but the
+     timing is still independent of the secret k finally used. */
+  do
+    {
+      do
+        {
+          ecc_mod_random (&amp;key-&gt;ecc-&gt;q, k, random_ctx, random, k + size);
+	}
+      while (mpn_zero_p(k, size));
+      ecc_gostdsa_sign (key-&gt;ecc, key-&gt;p, k, digest_length, digest,
+		   rp, sp, k + size);
+      mpz_limbs_finish (signature-&gt;r, size);
+      mpz_limbs_finish (signature-&gt;s, size);
+    }
+  while (mpz_sgn (signature-&gt;r) == 0 || mpz_sgn (signature-&gt;s) == 0);
+}
diff --git a/gostdsa-verify.c b/gostdsa-verify.c
new file mode 100644
index 000000000000..cdf87d6ba18d
--- /dev/null
+++ b/gostdsa-verify.c
@@ -0,0 +1,80 @@
+/* gostdsa-verify.c
+
+   Copyright (C) 2015 Dmitry Eremin-Solenikov
+   Copyright (C) 2013 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+/* Development of Nettle's ECC support was funded by the .SE Internet Fund. */
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;stdlib.h&gt;
+
+#include "gostdsa.h"
+
+#include "gmp-glue.h"
+
+int
+gostdsa_verify (const struct ecc_point *pub,
+	      size_t length, const uint8_t *digest,
+	      const struct dsa_signature *signature)
+{
+  mp_limb_t size = ecc_size (pub-&gt;ecc);
+  mp_size_t itch = 2*size + ecc_gostdsa_verify_itch (pub-&gt;ecc);
+  /* For ECC_MUL_A_WBITS == 0, at most 1512 bytes. With
+     ECC_MUL_A_WBITS == 4, currently needs 67 * ecc-&gt;size, at most
+     4824 bytes. Don't use stack allocation for this. */
+  mp_limb_t *scratch;
+  int res;
+
+#define rp scratch
+#define sp (scratch + size)
+#define scratch_out (scratch + 2*size)
+
+  if (mpz_sgn (signature-&gt;r) &lt;= 0 || mpz_size (signature-&gt;r) &gt; size
+      || mpz_sgn (signature-&gt;s) &lt;= 0 || mpz_size (signature-&gt;s) &gt; size)
+    return 0;
+
+  scratch = gmp_alloc_limbs (itch);
+
+  mpz_limbs_copy (rp, signature-&gt;r, size);
+  mpz_limbs_copy (sp, signature-&gt;s, size);
+
+  res = ecc_gostdsa_verify (pub-&gt;ecc, pub-&gt;p, length, digest, rp, sp, scratch_out);
+
+  gmp_free_limbs (scratch, itch);
+
+  return res;
+#undef rp
+#undef sp
+#undef scratch_out
+}
diff --git a/gostdsa.h b/gostdsa.h
new file mode 100644
index 000000000000..b34533436f72
--- /dev/null
+++ b/gostdsa.h
@@ -0,0 +1,102 @@
+/* gostdsa.h
+
+   Copyright (C) 2015 Dmity Eremin-Solenikov
+   Copyright (C) 2013 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+/* Development of Nettle's ECC support was funded by the .SE Internet Fund. */
+
+#ifndef NETTLE_GOSTDSA_H_INCLUDED
+#define NETTLE_GOSTDSA_H_INCLUDED
+
+#include "ecc.h"
+#include "dsa.h"
+#include "ecdsa.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/* Name mangling */
+#define gostdsa_sign nettle_gostdsa_sign
+#define gostdsa_verify nettle_gostdsa_verify
+#define ecc_gostdsa_sign nettle_ecc_gostdsa_sign
+#define ecc_gostdsa_sign_itch nettle_ecc_gostdsa_sign_itch
+#define ecc_gostdsa_verify nettle_ecc_gostdsa_verify
+#define ecc_gostdsa_verify_itch nettle_ecc_gostdsa_verify_itch
+
+/* Just use ECDSA function for key generation */
+#define gostdsa_generate_keypair ecdsa_generate_keypair
+
+/* High level GOST DSA functions.
+ *
+ * A public key is represented as a struct ecc_point, and a private
+ * key as a struct ecc_scalar. FIXME: Introduce some aliases? */
+void
+gostdsa_sign (const struct ecc_scalar *key,
+	      void *random_ctx, nettle_random_func *random,
+	      size_t digest_length,
+	      const uint8_t *digest,
+	      struct dsa_signature *signature);
+
+int
+gostdsa_verify (const struct ecc_point *pub,
+	        size_t length, const uint8_t *digest,
+	        const struct dsa_signature *signature);
+
+/* Low-level GOSTDSA functions. */
+mp_size_t
+ecc_gostdsa_sign_itch (const struct ecc_curve *ecc);
+
+void
+ecc_gostdsa_sign (const struct ecc_curve *ecc,
+		const mp_limb_t *zp,
+		/* Random nonce, must be invertible mod ecc group
+		   order. */
+		const mp_limb_t *kp,
+		size_t length, const uint8_t *digest,
+		mp_limb_t *rp, mp_limb_t *sp,
+		mp_limb_t *scratch);
+
+mp_size_t
+ecc_gostdsa_verify_itch (const struct ecc_curve *ecc);
+
+int
+ecc_gostdsa_verify (const struct ecc_curve *ecc,
+		  const mp_limb_t *pp, /* Public key */
+		  size_t length, const uint8_t *digest,
+		  const mp_limb_t *rp, const mp_limb_t *sp,
+		  mp_limb_t *scratch);
+
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* NETTLE_GOSTDSA_H_INCLUDED */
diff --git a/testsuite/.gitignore b/testsuite/.gitignore
index 1e2a69a60c13..be3a48707580 100644
--- a/testsuite/.gitignore
+++ b/testsuite/.gitignore
@@ -43,6 +43,9 @@
 /eddsa-sign-test
 /eddsa-verify-test
 /gcm-test
+/gostdsa-keygen-test
+/gostdsa-sign-test
+/gostdsa-verify-test
 /gosthash94-test
 /hkdf-test
 /hmac-test
diff --git a/testsuite/.test-rules.make b/testsuite/.test-rules.make
index 6dbef7e24a27..9fd11fd6d126 100644
--- a/testsuite/.test-rules.make
+++ b/testsuite/.test-rules.make
@@ -289,6 +289,15 @@ ed25519-test$(EXEEXT): ed25519-test.$(OBJEXT)
 ed448-test$(EXEEXT): ed448-test.$(OBJEXT)
 	$(LINK) ed448-test.$(OBJEXT) $(TEST_OBJS) -o ed448-test$(EXEEXT)
 
+gostdsa-sign-test$(EXEEXT): gostdsa-sign-test.$(OBJEXT)
+	$(LINK) gostdsa-sign-test.$(OBJEXT) $(TEST_OBJS) -o gostdsa-sign-test$(EXEEXT)
+
+gostdsa-verify-test$(EXEEXT): gostdsa-verify-test.$(OBJEXT)
+	$(LINK) gostdsa-verify-test.$(OBJEXT) $(TEST_OBJS) -o gostdsa-verify-test$(EXEEXT)
+
+gostdsa-keygen-test$(EXEEXT): gostdsa-keygen-test.$(OBJEXT)
+	$(LINK) gostdsa-keygen-test.$(OBJEXT) $(TEST_OBJS) -o gostdsa-keygen-test$(EXEEXT)
+
 sha1-huge-test$(EXEEXT): sha1-huge-test.$(OBJEXT)
 	$(LINK) sha1-huge-test.$(OBJEXT) $(TEST_OBJS) -o sha1-huge-test$(EXEEXT)
 
diff --git a/testsuite/Makefile.in b/testsuite/Makefile.in
index 97128040912e..860394d3bea5 100644
--- a/testsuite/Makefile.in
+++ b/testsuite/Makefile.in
@@ -53,7 +53,9 @@ TS_HOGWEED_SOURCES = sexp-test.c sexp-format-test.c \
 		     ecdsa-sign-test.c ecdsa-verify-test.c \
 		     ecdsa-keygen-test.c ecdh-test.c \
 		     eddsa-compress-test.c eddsa-sign-test.c \
-		     eddsa-verify-test.c ed25519-test.c ed448-test.c
+		     eddsa-verify-test.c ed25519-test.c ed448-test.c \
+		     gostdsa-sign-test.c gostdsa-verify-test.c \
+		     gostdsa-keygen-test.c
 
 TS_SOURCES = $(TS_NETTLE_SOURCES) $(TS_HOGWEED_SOURCES)
 CXX_SOURCES = cxx-test.cxx
diff --git a/testsuite/gostdsa-keygen-test.c b/testsuite/gostdsa-keygen-test.c
new file mode 100644
index 000000000000..f34ff485ad6b
--- /dev/null
+++ b/testsuite/gostdsa-keygen-test.c
@@ -0,0 +1,154 @@
+#include "testutils.h"
+#include "knuth-lfib.h"
+
+/* Check if y^2 = x^3 - 3x + b */
+static int
+ecc_valid_p (struct ecc_point *pub)
+{
+  mpz_t t, x, y;
+  mpz_t lhs, rhs;
+  int res;
+  mp_size_t size;
+
+  size = pub-&gt;ecc-&gt;p.size;
+
+  /* First check range */
+  if (mpn_cmp (pub-&gt;p, pub-&gt;ecc-&gt;p.m, size) &gt;= 0
+      || mpn_cmp (pub-&gt;p + size, pub-&gt;ecc-&gt;p.m, size) &gt;= 0)
+    return 0;
+
+  mpz_init (lhs);
+  mpz_init (rhs);
+
+  mpz_roinit_n (x, pub-&gt;p, size);
+  mpz_roinit_n (y, pub-&gt;p + size, size);
+
+  mpz_mul (lhs, y, y);
+
+  if (pub-&gt;ecc-&gt;p.bit_size == 255)
+    {
+      /* Check that
+	 121666 (1 + x^2 - y^2) = 121665 x^2 y^2 */
+      mpz_t x2;
+      mpz_init (x2);
+      mpz_mul (x2, x, x); /* x^2 */
+      mpz_mul (rhs, x2, lhs); /* x^2 y^2 */
+      mpz_sub (lhs, x2, lhs); /* x^2 - y^2 */
+      mpz_add_ui (lhs, lhs, 1); /* 1 + x^2 - y^2 */
+      mpz_mul_ui (lhs, lhs, 121666);
+      mpz_mul_ui (rhs, rhs, 121665);
+
+      mpz_clear (x2);
+    }
+  else if (pub-&gt;ecc-&gt;p.bit_size == 448)
+    {
+      /* Check that
+	 x^2 + y^2 = 1 - 39081 x^2 y^2 */
+      mpz_t x2, d;
+      mpz_init (x2);
+      mpz_init_set_ui (d, 39081);
+      mpz_mul (x2, x, x); /* x^2 */
+      mpz_mul (d, d, x2); /* 39081 x^2 */
+      mpz_set_ui (rhs, 1);
+      mpz_submul (rhs, d, lhs); /* 1 - 39081 x^2 y^2 */
+      mpz_add (lhs, x2, lhs);	/* x^2 + y^2 */
+
+      mpz_clear (d);
+      mpz_clear (x2);
+    }
+  else
+    {
+      /* Check y^2 = x^3 - 3 x + b */
+      mpz_mul (rhs, x, x);
+      mpz_sub_ui (rhs, rhs, 3);
+      mpz_mul (rhs, rhs, x);
+      mpz_add (rhs, rhs, mpz_roinit_n (t, pub-&gt;ecc-&gt;b, size));
+    }
+  res = mpz_congruent_p (lhs, rhs, mpz_roinit_n (t, pub-&gt;ecc-&gt;p.m, size));
+
+  mpz_clear (lhs);
+  mpz_clear (rhs);
+
+  return res;
+}
+
+void
+test_main (void)
+{
+  unsigned i;
+  struct knuth_lfib_ctx rctx;
+  struct dsa_signature signature;
+
+  struct tstring *digest;
+
+  knuth_lfib_init (&amp;rctx, 4711);
+  dsa_signature_init (&amp;signature);
+
+  digest = SHEX (/* sha256("abc") */
+		 "BA7816BF 8F01CFEA 414140DE 5DAE2223"
+		 "B00361A3 96177A9C B410FF61 F20015AD");
+
+  for (i = 0; ecc_curves[i]; i++)
+    {
+      const struct ecc_curve *ecc = ecc_curves[i];
+      struct ecc_point pub;
+      struct ecc_scalar key;
+
+      if (ecc-&gt;p.bit_size == 255 || ecc-&gt;p.bit_size == 448)
+	/* Exclude curve25519 and curve448, not supported with GOSTDSA. */
+	continue;
+
+      if (verbose)
+	fprintf (stderr, "Curve %d\n", ecc-&gt;p.bit_size);
+
+      ecc_point_init (&amp;pub, ecc);
+      ecc_scalar_init (&amp;key, ecc);
+
+      ecdsa_generate_keypair (&amp;pub, &amp;key,
+			      &amp;rctx,
+			      (nettle_random_func *) knuth_lfib_random);
+
+      if (verbose)
+	{
+	  fprintf (stderr, "Public key:\nx = ");
+	  write_mpn (stderr, 16, pub.p, ecc-&gt;p.size);
+	  fprintf (stderr, "\ny = ");
+	  write_mpn (stderr, 16, pub.p + ecc-&gt;p.size, ecc-&gt;p.size);
+	  fprintf (stderr, "\nPrivate key: ");
+	  write_mpn (stderr, 16, key.p, ecc-&gt;p.size);
+	  fprintf (stderr, "\n");
+	}
+      if (!ecc_valid_p (&amp;pub))
+	die ("gostdsa_generate_keypair produced an invalid point.\n");
+
+      gostdsa_sign (&amp;key,
+		   &amp;rctx, (nettle_random_func *) knuth_lfib_random,
+		   digest-&gt;length, digest-&gt;data,
+		   &amp;signature);
+
+      if (!gostdsa_verify (&amp;pub, digest-&gt;length, digest-&gt;data,
+			   &amp;signature))
+	die ("gostdsa_verify failed.\n");
+
+      digest-&gt;data[3] ^= 17;
+      if (gostdsa_verify (&amp;pub, digest-&gt;length, digest-&gt;data,
+			  &amp;signature))
+	die ("gostdsa_verify  returned success with invalid digest.\n");
+      digest-&gt;data[3] ^= 17;
+
+      mpz_combit (signature.r, 117);
+      if (gostdsa_verify (&amp;pub, digest-&gt;length, digest-&gt;data,
+			  &amp;signature))
+	die ("gostdsa_verify  returned success with invalid signature.r.\n");
+
+      mpz_combit (signature.r, 117);
+      mpz_combit (signature.s, 93);
+      if (gostdsa_verify (&amp;pub, digest-&gt;length, digest-&gt;data,
+			  &amp;signature))
+	die ("gostdsa_verify  returned success with invalid signature.s.\n");
+
+      ecc_point_clear (&amp;pub);
+      ecc_scalar_clear (&amp;key);
+    }
+  dsa_signature_clear (&amp;signature);
+}
diff --git a/testsuite/gostdsa-sign-test.c b/testsuite/gostdsa-sign-test.c
new file mode 100644
index 000000000000..911951c61c88
--- /dev/null
+++ b/testsuite/gostdsa-sign-test.c
@@ -0,0 +1,87 @@
+#include "testutils.h"
+
+static void
+test_gostdsa (const struct ecc_curve *ecc,
+	    /* Private key */
+	    const char *sz,
+	    /* Random nonce */
+	    const char *sk,
+	    /* Hash */
+	    const struct tstring *h,
+	    /* Expected signature */
+	    const char *r, const char *s)
+{
+  struct dsa_signature ref;
+  mpz_t z;
+  mpz_t k;
+  mp_limb_t *rp = xalloc_limbs (ecc-&gt;p.size);
+  mp_limb_t *sp = xalloc_limbs (ecc-&gt;p.size);
+  mp_limb_t *scratch = xalloc_limbs (ecc_gostdsa_sign_itch (ecc));
+
+  dsa_signature_init (&amp;ref);
+
+  mpz_init_set_str (z, sz, 16);
+  mpz_init_set_str (k, sk, 16);
+
+  ecc_gostdsa_sign (ecc, mpz_limbs_read_n (z, ecc-&gt;p.size),
+		  mpz_limbs_read_n (k, ecc-&gt;p.size),
+		  h-&gt;length, h-&gt;data, rp, sp, scratch);
+
+  mpz_set_str (ref.r, r, 16);
+  mpz_set_str (ref.s, s, 16);
+
+  if (mpz_limbs_cmp (ref.r, rp, ecc-&gt;p.size) != 0
+      || mpz_limbs_cmp (ref.s, sp, ecc-&gt;p.size) != 0)
+    {
+      fprintf (stderr, "_gostdsa_sign failed, bit_size = %u\n", ecc-&gt;p.bit_size);
+      fprintf (stderr, "r     = ");
+      write_mpn (stderr, 16, rp, ecc-&gt;p.size);
+      fprintf (stderr, "\ns     = ");
+      write_mpn (stderr, 16, sp, ecc-&gt;p.size);
+      fprintf (stderr, "\nref.r = ");
+      mpz_out_str (stderr, 16, ref.r);
+      fprintf (stderr, "\nref.s = ");
+      mpz_out_str (stderr, 16, ref.s);
+      fprintf (stderr, "\n");
+      abort();
+    }
+
+  free (rp);
+  free (sp);
+  free (scratch);
+
+  dsa_signature_clear (&amp;ref);
+  mpz_clear (k);
+  mpz_clear (z);
+}
+
+void
+test_main (void)
+{
+  test_gostdsa (nettle_get_gc256b(),
+	      "BFCF1D623E5CDD3032A7C6EABB4A923C46E43D640FFEAAF2C3ED39A8FA399924", /* z */
+
+	      "5782C53F110C596F9155D35EBD25A06A89C50391850A8FEFE33B0E270318857C", /* k */
+
+	      SHEX("1C067E20EA6CB183F22EFB0F3C6FD2A4E6A02821CB7A1B17FACD5E1F7AA76F70"), /* h */
+
+	      "E9323A5E88DD87FB7C724383BFFE7CECD4B9FFA2AC33BEEF73A5A1F743404F6B", /* r */
+
+	      "5E5B9B805B01147A8492C4A162643AC615DC777B9174108F3DC276A41F987AF3"); /* s */
+
+  test_gostdsa (nettle_get_gc512a(),
+	      "3FC01CDCD4EC5F972EB482774C41E66DB7F380528DFE9E67992BA05AEE462435"
+	      "757530E641077CE587B976C8EEB48C48FD33FD175F0C7DE6A44E014E6BCB074B", /* z */
+
+	      "72ABB44536656BF1618CE10BF7EADD40582304A51EE4E2A25A0A32CB0E773ABB"
+	      "23B7D8FDD8FA5EEE91B4AE452F2272C86E1E2221215D405F51B5D5015616E1F6", /* k */
+
+	      SHEX("EDC257BED45FDDE4F1457B7F5B19017A8F204184366689D938532CDBAA5CB29A"
+		   "1D369DA57F8B983BE272219BD2C9A4FC57ECF7A77F34EE2E8AA553976A4766C0"), /* h */
+
+	      "891AA75C2A6F3B4DE27E3903F61CBB0F3F85A4E3C62F39A6E4E84A7477679C6E"
+	      "45008DC2774CA2FF64C12C0606FF918CAE3A50115440E9BF2971B627A882A1E8", /* r */
+
+	      "31065479996DDBDEE180AFE22CA3CDC44B45CE4C6C83909D1D3B702922A32441"
+	      "A9E11DCFBEA3D847C06B1A8A38EB1671D6C82FA21B79C99BE2EA809B10DAA5DF"); /* s */
+}
diff --git a/testsuite/gostdsa-verify-test.c b/testsuite/gostdsa-verify-test.c
new file mode 100644
index 000000000000..5631592fe81f
--- /dev/null
+++ b/testsuite/gostdsa-verify-test.c
@@ -0,0 +1,110 @@
+#include "testutils.h"
+
+static void
+test_gostdsa (const struct ecc_curve *ecc,
+	    /* Public key */
+	    const char *xs, const char *ys,
+	    /* Hash */
+	    struct tstring *h,
+	    /* Valid signature */
+	    const char *r, const char *s)
+{
+  struct ecc_point pub;
+  struct dsa_signature signature;
+  mpz_t x, y;
+
+  ecc_point_init (&amp;pub, ecc);
+  dsa_signature_init (&amp;signature);
+
+  mpz_init_set_str (x, xs, 16);
+  mpz_init_set_str (y, ys, 16);
+
+  if (!ecc_point_set (&amp;pub, x, y))
+    die ("ecc_point_set failed.\n");
+
+  mpz_set_str (signature.r, r, 16);
+  mpz_set_str (signature.s, s, 16);
+
+  if (!gostdsa_verify (&amp;pub, h-&gt;length, h-&gt;data, &amp;signature))
+    {
+      fprintf (stderr, "gostdsa_verify failed with valid signature.\n");
+    fail:
+      fprintf (stderr, "bit_size = %u\nx = ", ecc-&gt;p.bit_size);
+      mpz_out_str (stderr, 16, x);
+      fprintf (stderr, "\ny = ");
+      mpz_out_str (stderr, 16, y);
+      fprintf (stderr, "\ndigest ");
+      print_hex (h-&gt;length, h-&gt;data);
+      fprintf (stderr, "r = ");
+      mpz_out_str (stderr, 16, signature.r);
+      fprintf (stderr, "\ns = ");
+      mpz_out_str (stderr, 16, signature.s);
+      fprintf (stderr, "\n");
+      abort();
+    }
+
+  mpz_combit (signature.r, ecc-&gt;p.bit_size / 3);
+  if (gostdsa_verify (&amp;pub, h-&gt;length, h-&gt;data, &amp;signature))
+    {
+      fprintf (stderr, "gostdsa_verify unexpectedly succeeded with invalid signature.\n");
+      goto fail;
+    }
+  mpz_combit (signature.r, ecc-&gt;p.bit_size / 3);
+
+  mpz_combit (signature.s, 4*ecc-&gt;p.bit_size / 5);
+  if (gostdsa_verify (&amp;pub, h-&gt;length, h-&gt;data, &amp;signature))
+    {
+      fprintf (stderr, "gostdsa_verify unexpectedly succeeded with invalid signature.\n");
+      goto fail;
+    }
+  mpz_combit (signature.s, 4*ecc-&gt;p.bit_size / 5);
+
+  h-&gt;data[2*h-&gt;length / 3] ^= 0x40;
+  if (gostdsa_verify (&amp;pub, h-&gt;length, h-&gt;data, &amp;signature))
+    {
+      fprintf (stderr, "gostdsa_verify unexpectedly succeeded with invalid signature.\n");
+      goto fail;
+    }
+  h-&gt;data[2*h-&gt;length / 3] ^= 0x40;
+  if (!gostdsa_verify (&amp;pub, h-&gt;length, h-&gt;data, &amp;signature))
+    {
+      fprintf (stderr, "gostdsa_verify failed, internal testsuite error.\n");
+      goto fail;
+    }
+
+  ecc_point_clear (&amp;pub);
+  dsa_signature_clear (&amp;signature);
+  mpz_clear (x);
+  mpz_clear (y);
+}
+
+void
+test_main (void)
+{
+  test_gostdsa (nettle_get_gc256b(),
+	      "971566CEDA436EE7678F7E07E84EBB7217406C0B4747AA8FD2AB1453C3D0DFBA", /* x */
+
+	      "AD58736965949F8E59830F8DE20FC6C0D177F6AB599874F1E2E24FF71F9CE643", /* y */
+
+	      SHEX("1C067E20EA6CB183F22EFB0F3C6FD2A4E6A02821CB7A1B17FACD5E1F7AA76F70"), /* h */
+
+	      "E9323A5E88DD87FB7C724383BFFE7CECD4B9FFA2AC33BEEF73A5A1F743404F6B", /* r */
+
+	      "5E5B9B805B01147A8492C4A162643AC615DC777B9174108F3DC276A41F987AF3"); /* s */
+
+  test_gostdsa (nettle_get_gc512a(),
+	      "03A36340A95BB5F93D131961B5B1C1B3213DF7FF3B5A30376407E2A65C441BC6"
+	      "D1B34662317083243F007B15A8512B526606D3B172B606DCE86DBD6F82DA3D40", /* x */
+
+	      "DEAD76318012FED79507809C89CC44848743640EAC9A3C847DA9082E050760A1"
+	      "0679F4B707ABC1872640AD20D7441F66C7A8B3BFF1B8E11B4A076F0A86749F73", /* y */
+
+	      SHEX("EDC257BED45FDDE4F1457B7F5B19017A8F204184366689D938532CDBAA5CB29A"
+		   "1D369DA57F8B983BE272219BD2C9A4FC57ECF7A77F34EE2E8AA553976A4766C0"), /* h */
+
+	      "891AA75C2A6F3B4DE27E3903F61CBB0F3F85A4E3C62F39A6E4E84A7477679C6E"
+	      "45008DC2774CA2FF64C12C0606FF918CAE3A50115440E9BF2971B627A882A1E8", /* r */
+
+	      "31065479996DDBDEE180AFE22CA3CDC44B45CE4C6C83909D1D3B702922A32441"
+	      "A9E11DCFBEA3D847C06B1A8A38EB1671D6C82FA21B79C99BE2EA809B10DAA5DF"); /* s */
+}
diff --git a/testsuite/testutils.h b/testsuite/testutils.h
index f4ea38da9deb..cef7f4011a7c 100644
--- a/testsuite/testutils.h
+++ b/testsuite/testutils.h
@@ -22,6 +22,7 @@
 # include "ecc.h"
 # include "ecc-internal.h"
 # include "ecdsa.h"
+# include "gostdsa.h"
 # include "gmp-glue.h"
 # if NETTLE_USE_MINI_GMP
 #  include "knuth-lfib.h"
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200112234151</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-01-12 23:41:51-0400</timestampReceived><subject>[PATCH v3 1/3] Add support for GOST GC256B curve</subject><body>

From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;

Add support for GC256B curve ("TLS Supported Groups" registry,
draft-smyshlyaev-tls12-gost-suites) also known as
GostR3410-2001-CryptoPro-A and GostR3410-2001-CryptoPro-XchA (RFC 4357).

Signed-off-by: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;
---
 .gitignore               |   1 +
 Makefile.in              |  11 ++++
 ecc-curve.h              |   1 +
 ecc-gc256b.c             | 128 +++++++++++++++++++++++++++++++++++++++
 ecc-internal.h           |   3 +
 eccdata.c                |  34 ++++++++++-
 examples/ecc-benchmark.c |   1 +
 testsuite/testutils.c    |  12 +++-
 8 files changed, 188 insertions(+), 3 deletions(-)
 create mode 100644 ecc-gc256b.c

diff --git a/.gitignore b/.gitignore
index ea264107fa40..4454ade5a950 100644
--- a/.gitignore
+++ b/.gitignore
@@ -45,6 +45,7 @@ core
 /rotors.h
 /ecc-curve25519.h
 /ecc-curve448.h
+/ecc-gc256b.h
 /ecc-secp192r1.h
 /ecc-secp224r1.h
 /ecc-secp256r1.h
diff --git a/Makefile.in b/Makefile.in
index 38160bb40fe1..8815e7b76dea 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -176,6 +176,7 @@ hogweed_SOURCES = sexp.c sexp-format.c \
 		  ecc-mod.c ecc-mod-inv.c \
 		  ecc-mod-arith.c ecc-pp1-redc.c ecc-pm1-redc.c \
 		  ecc-curve25519.c ecc-curve448.c \
+		  ecc-gc256b.c \
 		  ecc-secp192r1.c ecc-secp224r1.c ecc-secp256r1.c \
 		  ecc-secp384r1.c ecc-secp521r1.c \
 		  ecc-size.c ecc-j-to-a.c ecc-a-to-j.c \
@@ -396,12 +397,21 @@ ecc-curve25519.h: eccdata.stamp
 ecc-curve448.h: eccdata.stamp
 	./eccdata$(EXEEXT_FOR_BUILD) curve448 38 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
 
+# Some reasonable choices for 256:
+# k =  9, c =  6, S = 320, T =  54 ( 45 A +  9 D) 20 KB
+# k = 11, c =  6, S = 256, T =  55 ( 44 A + 11 D) 16 KB
+# k = 19, c =  7, S = 256, T =  57 ( 38 A + 19 D) 16 KB
+# k = 15, c =  6, S = 192, T =  60 ( 45 A + 15 D) 12 KB
+ecc-gc256b.h: eccdata.stamp
+	./eccdata$(EXEEXT_FOR_BUILD) gc256b 11 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
+
 eccdata.stamp: eccdata.c
 	$(MAKE) eccdata$(EXEEXT_FOR_BUILD)
 	echo stamp &gt; eccdata.stamp
 
 ecc-curve25519.$(OBJEXT): ecc-curve25519.h
 ecc-curve448.$(OBJEXT): ecc-curve448.h
+ecc-gc256b.$(OBJEXT): ecc-gc256b.h
 ecc-secp192r1.$(OBJEXT): ecc-secp192r1.h
 ecc-secp224r1.$(OBJEXT): ecc-secp224r1.h
 ecc-secp256r1.$(OBJEXT): ecc-secp256r1.h
@@ -660,6 +670,7 @@ distcheck: dist
 clean-here:
 	-rm -f $(TARGETS) *.$(OBJEXT) *.s *.so *.dll *.a \
 		ecc-curve25519.h ecc-curve448.h \
+		ecc-gc256b.h \
 		ecc-secp192r1.h ecc-secp224r1.h ecc-secp256r1.h \
 		ecc-secp384r1.h ecc-secp521r1.h \
 		aesdata$(EXEEXT_FOR_BUILD) \
diff --git a/ecc-curve.h b/ecc-curve.h
index 76024a19d24f..b378c8489839 100644
--- a/ecc-curve.h
+++ b/ecc-curve.h
@@ -43,6 +43,7 @@ extern "C" {
 /* The contents of this struct is internal. */
 struct ecc_curve;
 
+const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_gc256b(void);
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_secp_192r1(void);
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_secp_224r1(void);
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_secp_256r1(void);
diff --git a/ecc-gc256b.c b/ecc-gc256b.c
new file mode 100644
index 000000000000..b2d12d0bdf7c
--- /dev/null
+++ b/ecc-gc256b.c
@@ -0,0 +1,128 @@
+/* ecc-gc256b.c
+
+   Copyright (C) 2016-2020 Dmitry Eremin-Solenikov
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+
+#include "ecc.h"
+#include "ecc-internal.h"
+
+#define USE_REDC 0
+
+#include "ecc-gc256b.h"
+
+static void
+ecc_gc256b_modp (const struct ecc_modulo *m, mp_limb_t *rp)
+{
+  mp_size_t mn = m-&gt;size;
+  mp_limb_t hi;
+
+  hi = mpn_addmul_1(rp, rp + mn, mn, 0x269);
+  hi = sec_add_1 (rp, rp, mn, hi * 0x269);
+  hi = sec_add_1 (rp, rp, mn, hi * 0x269);
+  assert(hi == 0);
+}
+
+#define ecc_gc256b_modp ecc_gc256b_modp
+#define ecc_gc256b_modq ecc_mod
+
+const struct ecc_curve _nettle_gc256b =
+{
+  {
+    256,
+    ECC_LIMB_SIZE,
+    ECC_BMODP_SIZE,
+    ECC_REDC_SIZE,
+    ECC_MOD_INV_ITCH (ECC_LIMB_SIZE),
+    0,
+
+    ecc_p,
+    ecc_Bmodp,
+    ecc_Bmodp_shifted,
+    ecc_redc_ppm1,
+
+    ecc_pp1h,
+    ecc_gc256b_modp,
+    ecc_gc256b_modp,
+    ecc_mod_inv,
+    NULL,
+  },
+  {
+    256,
+    ECC_LIMB_SIZE,
+    ECC_BMODQ_SIZE,
+    0,
+    ECC_MOD_INV_ITCH (ECC_LIMB_SIZE),
+    0,
+
+    ecc_q,
+    ecc_Bmodq,
+    ecc_Bmodq_shifted,
+    NULL,
+    ecc_qp1h,
+
+    ecc_gc256b_modq,
+    ecc_gc256b_modq,
+    ecc_mod_inv,
+    NULL,
+  },
+
+  USE_REDC,
+  ECC_PIPPENGER_K,
+  ECC_PIPPENGER_C,
+
+  ECC_ADD_JJA_ITCH (ECC_LIMB_SIZE),
+  ECC_ADD_JJJ_ITCH (ECC_LIMB_SIZE),
+  ECC_DUP_JJ_ITCH (ECC_LIMB_SIZE),
+  ECC_MUL_A_ITCH (ECC_LIMB_SIZE),
+  ECC_MUL_G_ITCH (ECC_LIMB_SIZE),
+  ECC_J_TO_A_ITCH (ECC_LIMB_SIZE),
+
+  ecc_add_jja,
+  ecc_add_jjj,
+  ecc_dup_jj,
+  ecc_mul_a,
+  ecc_mul_g,
+  ecc_j_to_a,
+
+  ecc_b,
+  ecc_g,
+  ecc_unit,
+  ecc_table
+};
+
+const struct ecc_curve *nettle_get_gc256b(void)
+{
+  return &amp;_nettle_gc256b;
+}
diff --git a/ecc-internal.h b/ecc-internal.h
index c918632df292..0972efaf10d1 100644
--- a/ecc-internal.h
+++ b/ecc-internal.h
@@ -91,6 +91,9 @@ extern const struct ecc_curve _nettle_secp_521r1;
 extern const struct ecc_curve _nettle_curve25519;
 extern const struct ecc_curve _nettle_curve448;
 
+/* GOST curves, visible with underscore prefix for now */
+extern const struct ecc_curve _nettle_gc256b;
+
 #define ECC_MAX_SIZE ((521 + GMP_NUMB_BITS - 1) / GMP_NUMB_BITS)
 
 /* Window size for ecc_mul_a. Using 4 bits seems like a good choice,
diff --git a/eccdata.c b/eccdata.c
index d76a42bcde6f..3820e150125b 100644
--- a/eccdata.c
+++ b/eccdata.c
@@ -674,6 +674,38 @@ ecc_curve_init (struct ecc_curve *ecc, const char *curve)
 		   "47d0e827cb1595e1470eb88580d5716c"
 		   "4cf22832ea2f0ff0df38ab61ca32112f");
     }
+  else if (!strcmp (curve, "gc256b"))
+    {
+      ecc_curve_init_str (ecc, ECC_TYPE_WEIERSTRASS,
+			  "ffffffffffffffffffffffffffffffff"
+			  "fffffffffffffffffffffffffffffd97",
+
+			  "00000000000000000000000000000000"
+			  "000000000000000000000000000000a6",
+
+			  "ffffffffffffffffffffffffffffffff"
+			  "6c611070995ad10045841b09b761b893",
+
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000001",
+
+			  "8d91e471e0989cda27df505a453f2b76"
+			  "35294f2ddf23e3b122acc99c9e9f1e14");
+
+      ecc-&gt;ref = ecc_alloc (3);
+      ecc_set_str (&amp;ecc-&gt;ref[0], /* 2 g */
+		   "fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffd95",
+		   "726e1b8e1f676325d820afa5bac0d489cad6b0d220dc1c4edd5336636160df83");
+
+      ecc_set_str (&amp;ecc-&gt;ref[1], /* 3 g */
+		   "8e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38d2c",
+		   "76bcd1ca9a23b041d4d9baf507a6cd821267a94c838768e8486117796b788a51");
+
+      ecc_set_str (&amp;ecc-&gt;ref[2], /* 4 g */
+		   "f7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e4b7",
+		   "83ccf17ba6706d73625cc3534c7a2b9d6ec1ee6a9a7e07c10d84b388de59f741");
+
+    }
   else if (!strcmp (curve, "curve448"))
     {
       /* curve448, y^2 = x^3 + 156326 x^2 + x (mod p), with p = 2^{448} - 2^{224} - \
1. @@ -1316,7 +1348,7 @@ main (int argc, char **argv)
 
   if (argc &lt; 4)
     {
-      fprintf (stderr, "Usage: %s CURVE-BITS K C [BITS-PER-LIMB]\n", argv[0]);
+      fprintf (stderr, "Usage: %s CURVE K C [BITS-PER-LIMB]\n", argv[0]);
       return EXIT_FAILURE;
     }
 
diff --git a/examples/ecc-benchmark.c b/examples/ecc-benchmark.c
index d36d46b77bc1..497c76c3e550 100644
--- a/examples/ecc-benchmark.c
+++ b/examples/ecc-benchmark.c
@@ -314,6 +314,7 @@ const struct ecc_curve * const curves[] = {
   &amp;_nettle_secp_384r1,
   &amp;_nettle_curve448,
   &amp;_nettle_secp_521r1,
+  &amp;_nettle_gc256b,
 };
 
 #define numberof(x)  (sizeof (x) / sizeof ((x)[0]))
diff --git a/testsuite/testutils.c b/testsuite/testutils.c
index 7772d2b01661..e4e7c23dcc1b 100644
--- a/testsuite/testutils.c
+++ b/testsuite/testutils.c
@@ -1677,6 +1677,7 @@ const struct ecc_curve * const ecc_curves[] = {
   &amp;_nettle_secp_521r1,
   &amp;_nettle_curve25519,
   &amp;_nettle_curve448,
+  &amp;_nettle_gc256b,
   NULL
 };
 
@@ -1728,7 +1729,7 @@ void
 test_ecc_mul_a (unsigned curve, unsigned n, const mp_limb_t *p)
 {
   /* For each curve, the points 2 g, 3 g and 4 g */
-  static const struct ecc_ref_point ref[7][3] = {
+  static const struct ecc_ref_point ref[8][3] = {
     { { "dafebf5828783f2ad35534631588a3f629a70fb16982a888",
 	"dd6bda0d993da0fa46b27bbc141b868f59331afa5c7e93ab" },
       { "76e32a2557599e6edcd283201fb2b9aadfd0d359cbb263da",
@@ -1796,9 +1797,16 @@ test_ecc_mul_a (unsigned curve, unsigned n, const mp_limb_t \
*p)  "e005a8dbd5125cf706cbda7ad43aa6449a4a8d952356c3b9fce43c82ec4e1d58bb3a331bdb6767f0bffa9a68fed02dafb822ac13588ed6fc" \
                },
       { "49dcbc5c6c0cce2c1419a17226f929ea255a09cf4e0891c693fda4be70c74cc301b7bdf1515dd8ba21aee1798949e120e2ce42ac48ba7f30",
  "d49077e4accde527164b33a5de021b979cb7c02f0457d845c90dc3227b8a5bc1c0d8f97ea1ca9472b5d444285d0d4f5b32e236f86de51839" \
}, +    },
+    { { "fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffd95",
+	"726e1b8e1f676325d820afa5bac0d489cad6b0d220dc1c4edd5336636160df83" },
+      { "8e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38d2c",
+	"76bcd1ca9a23b041d4d9baf507a6cd821267a94c838768e8486117796b788a51" },
+      { "f7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e4b7",
+	"83ccf17ba6706d73625cc3534c7a2b9d6ec1ee6a9a7e07c10d84b388de59f741" },
     }
   };
-  assert (curve &lt; 7);
+  assert (curve &lt; 8);
   assert (n &lt;= 4);
   if (n == 0)
     {
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200112234152</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-01-12 23:41:52-0400</timestampReceived><subject>[PATCH v3 2/3] Add support for GOST GC512A curve</subject><body>

From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;

Add support for GC512A curve ("TLS Supported Groups" registry,
draft-smyshlyaev-tls12-gost-suites) also known as
tc26-gost-3410-12-512-paramSetA (RFC 7836).

Signed-off-by: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;
---
 .gitignore               |   1 +
 Makefile.in              |  14 ++++-
 ecc-curve.h              |   1 +
 ecc-gc512a.c             | 128 +++++++++++++++++++++++++++++++++++++++
 ecc-internal.h           |   1 +
 eccdata.c                |  38 ++++++++++++
 examples/ecc-benchmark.c |   1 +
 testsuite/testutils.c    |  18 +++++-
 8 files changed, 198 insertions(+), 4 deletions(-)
 create mode 100644 ecc-gc512a.c

diff --git a/.gitignore b/.gitignore
index 4454ade5a950..2e64c187574f 100644
--- a/.gitignore
+++ b/.gitignore
@@ -46,6 +46,7 @@ core
 /ecc-curve25519.h
 /ecc-curve448.h
 /ecc-gc256b.h
+/ecc-gc512a.h
 /ecc-secp192r1.h
 /ecc-secp224r1.h
 /ecc-secp256r1.h
diff --git a/Makefile.in b/Makefile.in
index 8815e7b76dea..11883a8bc88b 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -176,7 +176,7 @@ hogweed_SOURCES = sexp.c sexp-format.c \
 		  ecc-mod.c ecc-mod-inv.c \
 		  ecc-mod-arith.c ecc-pp1-redc.c ecc-pm1-redc.c \
 		  ecc-curve25519.c ecc-curve448.c \
-		  ecc-gc256b.c \
+		  ecc-gc256b.c ecc-gc512a.c \
 		  ecc-secp192r1.c ecc-secp224r1.c ecc-secp256r1.c \
 		  ecc-secp384r1.c ecc-secp521r1.c \
 		  ecc-size.c ecc-j-to-a.c ecc-a-to-j.c \
@@ -405,6 +405,15 @@ ecc-curve448.h: eccdata.stamp
 ecc-gc256b.h: eccdata.stamp
 	./eccdata$(EXEEXT_FOR_BUILD) gc256b 11 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
 
+# Some reasonable choices for 512:
+# k = 22, c =  6, S = 256, T = 110 ( 88 A + 22 D) 32 KB
+# k = 29, c =  6, S = 192, T = 116 ( 87 A + 29 D) 24 KB
+# k = 21, c =  5, S = 160, T = 126 (105 A + 21 D) 20 KB
+# k = 43, c =  6, S = 128, T = 129 ( 86 A + 43 D) 16 KB
+# k = 35, c =  5, S =  96, T = 140 (105 A + 35 D) 12 KB
+ecc-gc512a.h: eccdata.stamp
+	./eccdata$(EXEEXT_FOR_BUILD) gc512a 43 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
+
 eccdata.stamp: eccdata.c
 	$(MAKE) eccdata$(EXEEXT_FOR_BUILD)
 	echo stamp &gt; eccdata.stamp
@@ -412,6 +421,7 @@ eccdata.stamp: eccdata.c
 ecc-curve25519.$(OBJEXT): ecc-curve25519.h
 ecc-curve448.$(OBJEXT): ecc-curve448.h
 ecc-gc256b.$(OBJEXT): ecc-gc256b.h
+ecc-gc512a.$(OBJEXT): ecc-gc512a.h
 ecc-secp192r1.$(OBJEXT): ecc-secp192r1.h
 ecc-secp224r1.$(OBJEXT): ecc-secp224r1.h
 ecc-secp256r1.$(OBJEXT): ecc-secp256r1.h
@@ -670,7 +680,7 @@ distcheck: dist
 clean-here:
 	-rm -f $(TARGETS) *.$(OBJEXT) *.s *.so *.dll *.a \
 		ecc-curve25519.h ecc-curve448.h \
-		ecc-gc256b.h \
+		ecc-gc256b.h ecc-gc512a.h \
 		ecc-secp192r1.h ecc-secp224r1.h ecc-secp256r1.h \
 		ecc-secp384r1.h ecc-secp521r1.h \
 		aesdata$(EXEEXT_FOR_BUILD) \
diff --git a/ecc-curve.h b/ecc-curve.h
index b378c8489839..93e1585ba15b 100644
--- a/ecc-curve.h
+++ b/ecc-curve.h
@@ -44,6 +44,7 @@ extern "C" {
 struct ecc_curve;
 
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_gc256b(void);
+const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_gc512a(void);
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_secp_192r1(void);
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_secp_224r1(void);
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_secp_256r1(void);
diff --git a/ecc-gc512a.c b/ecc-gc512a.c
new file mode 100644
index 000000000000..602fd28147ea
--- /dev/null
+++ b/ecc-gc512a.c
@@ -0,0 +1,128 @@
+/* ecc-gc512a.c
+
+   Copyright (C) 2016-2020 Dmitry Eremin-Solenikov
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+
+#include "ecc.h"
+#include "ecc-internal.h"
+
+#define USE_REDC 0
+
+#include "ecc-gc512a.h"
+
+static void
+ecc_gc512a_modp (const struct ecc_modulo *m, mp_limb_t *rp)
+{
+  mp_size_t mn = m-&gt;size;
+  mp_limb_t hi;
+
+  hi = mpn_addmul_1(rp, rp + mn, mn, 0x239);
+  hi = sec_add_1 (rp, rp, mn, hi * 0x239);
+  hi = sec_add_1 (rp, rp, mn, hi * 0x239);
+  assert(hi == 0);
+}
+
+#define ecc_gc512a_modp ecc_gc512a_modp
+#define ecc_gc512a_modq ecc_mod
+
+const struct ecc_curve _nettle_gc512a =
+{
+  {
+    512,
+    ECC_LIMB_SIZE,
+    ECC_BMODP_SIZE,
+    ECC_REDC_SIZE,
+    ECC_MOD_INV_ITCH (ECC_LIMB_SIZE),
+    0,
+
+    ecc_p,
+    ecc_Bmodp,
+    ecc_Bmodp_shifted,
+    ecc_redc_ppm1,
+
+    ecc_pp1h,
+    ecc_gc512a_modp,
+    ecc_gc512a_modp,
+    ecc_mod_inv,
+    NULL,
+  },
+  {
+    512,
+    ECC_LIMB_SIZE,
+    ECC_BMODQ_SIZE,
+    0,
+    ECC_MOD_INV_ITCH (ECC_LIMB_SIZE),
+    0,
+
+    ecc_q,
+    ecc_Bmodq,
+    ecc_Bmodq_shifted,
+    NULL,
+    ecc_qp1h,
+
+    ecc_gc512a_modq,
+    ecc_gc512a_modq,
+    ecc_mod_inv,
+    NULL,
+  },
+
+  USE_REDC,
+  ECC_PIPPENGER_K,
+  ECC_PIPPENGER_C,
+
+  ECC_ADD_JJA_ITCH (ECC_LIMB_SIZE),
+  ECC_ADD_JJJ_ITCH (ECC_LIMB_SIZE),
+  ECC_DUP_JJ_ITCH (ECC_LIMB_SIZE),
+  ECC_MUL_A_ITCH (ECC_LIMB_SIZE),
+  ECC_MUL_G_ITCH (ECC_LIMB_SIZE),
+  ECC_J_TO_A_ITCH (ECC_LIMB_SIZE),
+
+  ecc_add_jja,
+  ecc_add_jjj,
+  ecc_dup_jj,
+  ecc_mul_a,
+  ecc_mul_g,
+  ecc_j_to_a,
+
+  ecc_b,
+  ecc_g,
+  ecc_unit,
+  ecc_table
+};
+
+const struct ecc_curve *nettle_get_gc512a(void)
+{
+  return &amp;_nettle_gc512a;
+}
diff --git a/ecc-internal.h b/ecc-internal.h
index 0972efaf10d1..733d7fe0273e 100644
--- a/ecc-internal.h
+++ b/ecc-internal.h
@@ -93,6 +93,7 @@ extern const struct ecc_curve _nettle_curve448;
 
 /* GOST curves, visible with underscore prefix for now */
 extern const struct ecc_curve _nettle_gc256b;
+extern const struct ecc_curve _nettle_gc512a;
 
 #define ECC_MAX_SIZE ((521 + GMP_NUMB_BITS - 1) / GMP_NUMB_BITS)
 
diff --git a/eccdata.c b/eccdata.c
index 3820e150125b..a3c69e882655 100644
--- a/eccdata.c
+++ b/eccdata.c
@@ -705,6 +705,44 @@ ecc_curve_init (struct ecc_curve *ecc, const char *curve)
 		   "f7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e4b7",
 		   "83ccf17ba6706d73625cc3534c7a2b9d6ec1ee6a9a7e07c10d84b388de59f741");
 
+    }
+  else if (!strcmp (curve, "gc512a"))
+    {
+      ecc_curve_init_str (ecc, ECC_TYPE_WEIERSTRASS,
+			  "ffffffffffffffffffffffffffffffff"
+			  "ffffffffffffffffffffffffffffffff"
+			  "ffffffffffffffffffffffffffffffff"
+			  "fffffffffffffffffffffffffffffdc7",
+			  "e8c2505dedfc86ddc1bd0b2b6667f1da"
+			  "34b82574761cb0e879bd081cfd0b6265"
+			  "ee3cb090f30d27614cb4574010da90dd"
+			  "862ef9d4ebee4761503190785a71c760",
+			  "ffffffffffffffffffffffffffffffff"
+			  "ffffffffffffffffffffffffffffffff"
+			  "27e69532f48d89116ff22b8d4e056060"
+			  "9b4b38abfad2b85dcacdb1411f10b275",
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000003",
+			  "7503cfe87a836ae3a61b8816e25450e6"
+			  "ce5e1c93acf1abc1778064fdcbefa921"
+			  "df1626be4fd036e93d75e6a50e3a41e9"
+			  "8028fe5fc235f5b889a589cb5215f2a4");
+
+      ecc-&gt;ref = ecc_alloc (3);
+      ecc_set_str (&amp;ecc-&gt;ref[0], /* 2 g */
+		   "3b89dcfc622996ab97a5869dbff15cf51db00954f43a58a5e5f6b0470a132b2f4434bbcd405d2a9516151d2a6a04f2e4375bf48de1fdb21fb982afd9d2ea137c",
 +		   "c813c4e2e2e0a8a391774c7903da7a6f14686e98e183e670ee6fb784809a3e92ca209dc631d85b1c7534ed3b37fddf64d854d7e01f91f18bb3fd307591afc051");
 +
+      ecc_set_str (&amp;ecc-&gt;ref[1], /* 3 g */
+		   "a1ff1ab2712a267eb53935ddb5a567f84db156cc096168a1174291d5f488fba543d2840b4d2dd35d764b2f57b308907aec55cfba10544e8416e134687ccb87c3",
 +		   "3cb5c4417ec4637f30374f189bb5b984c41e3a48d7f84fbfa3819e3f333f7eb311d3af7e67c4c16eeacfac2fe94c6dd4c6366f711a4fb6c7125cd7ec518d90d6");
 +
+      ecc_set_str (&amp;ecc-&gt;ref[2], /* 4 g */
+		   "b7bfb80956c8670031ba191929f64e301d681634236d47a60e571a4bedc0ef257452ef78b5b98dbb3d9f3129d9349433ce2a3a35cb519c91e2d633d7b373ae16",
 +		   "3bee95e29eecc5d5ad2beba941abcbf9f1cad478df0fecf614f63aeebef77850da7efdb93de8f3df80bc25eac09239c14175f5c29704ce9a3e383f1b3ec0e929");
 +
     }
   else if (!strcmp (curve, "curve448"))
     {
diff --git a/examples/ecc-benchmark.c b/examples/ecc-benchmark.c
index 497c76c3e550..d728d0c96824 100644
--- a/examples/ecc-benchmark.c
+++ b/examples/ecc-benchmark.c
@@ -315,6 +315,7 @@ const struct ecc_curve * const curves[] = {
   &amp;_nettle_curve448,
   &amp;_nettle_secp_521r1,
   &amp;_nettle_gc256b,
+  &amp;_nettle_gc512a,
 };
 
 #define numberof(x)  (sizeof (x) / sizeof ((x)[0]))
diff --git a/testsuite/testutils.c b/testsuite/testutils.c
index e4e7c23dcc1b..8b17b8f424aa 100644
--- a/testsuite/testutils.c
+++ b/testsuite/testutils.c
@@ -1678,6 +1678,7 @@ const struct ecc_curve * const ecc_curves[] = {
   &amp;_nettle_curve25519,
   &amp;_nettle_curve448,
   &amp;_nettle_gc256b,
+  &amp;_nettle_gc512a,
   NULL
 };
 
@@ -1729,7 +1730,7 @@ void
 test_ecc_mul_a (unsigned curve, unsigned n, const mp_limb_t *p)
 {
   /* For each curve, the points 2 g, 3 g and 4 g */
-  static const struct ecc_ref_point ref[8][3] = {
+  static const struct ecc_ref_point ref[9][3] = {
     { { "dafebf5828783f2ad35534631588a3f629a70fb16982a888",
 	"dd6bda0d993da0fa46b27bbc141b868f59331afa5c7e93ab" },
       { "76e32a2557599e6edcd283201fb2b9aadfd0d359cbb263da",
@@ -1804,9 +1805,22 @@ test_ecc_mul_a (unsigned curve, unsigned n, const mp_limb_t \
*p)  "76bcd1ca9a23b041d4d9baf507a6cd821267a94c838768e8486117796b788a51" },
       { "f7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e4b7",
 	"83ccf17ba6706d73625cc3534c7a2b9d6ec1ee6a9a7e07c10d84b388de59f741" },
+    },
+    { { "3b89dcfc622996ab97a5869dbff15cf51db00954f43a58a5e5f6b0470a132b2f"
+	"4434bbcd405d2a9516151d2a6a04f2e4375bf48de1fdb21fb982afd9d2ea137c",
+	"c813c4e2e2e0a8a391774c7903da7a6f14686e98e183e670ee6fb784809a3e92"
+	"ca209dc631d85b1c7534ed3b37fddf64d854d7e01f91f18bb3fd307591afc051" },
+      { "a1ff1ab2712a267eb53935ddb5a567f84db156cc096168a1174291d5f488fba5"
+	"43d2840b4d2dd35d764b2f57b308907aec55cfba10544e8416e134687ccb87c3",
+	"3cb5c4417ec4637f30374f189bb5b984c41e3a48d7f84fbfa3819e3f333f7eb3"
+	"11d3af7e67c4c16eeacfac2fe94c6dd4c6366f711a4fb6c7125cd7ec518d90d6" },
+      { "b7bfb80956c8670031ba191929f64e301d681634236d47a60e571a4bedc0ef25"
+	"7452ef78b5b98dbb3d9f3129d9349433ce2a3a35cb519c91e2d633d7b373ae16",
+	"3bee95e29eecc5d5ad2beba941abcbf9f1cad478df0fecf614f63aeebef77850"
+	"da7efdb93de8f3df80bc25eac09239c14175f5c29704ce9a3e383f1b3ec0e929" },
     }
   };
-  assert (curve &lt; 8);
+  assert (curve &lt; 9);
   assert (n &lt;= 4);
   if (n == 0)
     {
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200112234153</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-01-12 23:41:53-0400</timestampReceived><subject>[PATCH v3 3/3] Add GOST DSA according to GOST R 34.10-2001/-2012</subject><body>

From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;

Add GOST Digital Signature Algorithms support according to GOST R
34.10-2001/-2012. English translations of these standards are provided
as RFC 5832 and RFC 7091.

Signed-off-by: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;
---
 Makefile.in                     |   4 +-
 ecc-gostdsa-sign.c              | 101 +++++++++++++++++++++
 ecc-gostdsa-verify.c            | 130 +++++++++++++++++++++++++++
 ecc-hash.c                      |  11 +++
 ecc-internal.h                  |   7 ++
 gostdsa-sign.c                  |  74 +++++++++++++++
 gostdsa-verify.c                |  78 ++++++++++++++++
 gostdsa.h                       | 102 +++++++++++++++++++++
 testsuite/.gitignore            |   3 +
 testsuite/.test-rules.make      |   9 ++
 testsuite/Makefile.in           |   4 +-
 testsuite/gostdsa-keygen-test.c | 154 ++++++++++++++++++++++++++++++++
 testsuite/gostdsa-sign-test.c   |  87 ++++++++++++++++++
 testsuite/gostdsa-verify-test.c | 110 +++++++++++++++++++++++
 testsuite/testutils.h           |   1 +
 15 files changed, 873 insertions(+), 2 deletions(-)
 create mode 100644 ecc-gostdsa-sign.c
 create mode 100644 ecc-gostdsa-verify.c
 create mode 100644 gostdsa-sign.c
 create mode 100644 gostdsa-verify.c
 create mode 100644 gostdsa.h
 create mode 100644 testsuite/gostdsa-keygen-test.c
 create mode 100644 testsuite/gostdsa-sign-test.c
 create mode 100644 testsuite/gostdsa-verify-test.c

diff --git a/Makefile.in b/Makefile.in
index 11883a8bc88b..ac7b090c2ffd 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -189,6 +189,8 @@ hogweed_SOURCES = sexp.c sexp-format.c \
 		  ecc-point.c ecc-scalar.c ecc-point-mul.c ecc-point-mul-g.c \
 		  ecc-ecdsa-sign.c ecdsa-sign.c \
 		  ecc-ecdsa-verify.c ecdsa-verify.c ecdsa-keygen.c \
+		  ecc-gostdsa-sign.c gostdsa-sign.c \
+		  ecc-gostdsa-verify.c gostdsa-verify.c \
 		  curve25519-mul-g.c curve25519-mul.c curve25519-eh-to-x.c \
 		  curve448-mul-g.c curve448-mul.c curve448-eh-to-x.c \
 		  eddsa-compress.c eddsa-decompress.c eddsa-expand.c \
@@ -205,7 +207,7 @@ HEADERS = aes.h arcfour.h arctwo.h asn1.h blowfish.h \
 	  cbc.h ccm.h cfb.h chacha.h chacha-poly1305.h ctr.h \
 	  curve25519.h curve448.h des.h dsa.h dsa-compat.h eax.h \
 	  ecc-curve.h ecc.h ecdsa.h eddsa.h \
-	  gcm.h gost28147.h gosthash94.h hmac.h \
+	  gcm.h gost28147.h gostdsa.h gosthash94.h hmac.h \
 	  knuth-lfib.h hkdf.h \
 	  macros.h \
 	  cmac.h siv-cmac.h \
diff --git a/ecc-gostdsa-sign.c b/ecc-gostdsa-sign.c
new file mode 100644
index 000000000000..00eeef81f659
--- /dev/null
+++ b/ecc-gostdsa-sign.c
@@ -0,0 +1,101 @@
+/* ecc-gostdsa-sign.c
+
+   Copyright (C) 2015 Dmitry Eremin-Solenikov
+   Copyright (C) 2013, 2014 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;stdlib.h&gt;
+
+#include "gostdsa.h"
+#include "ecc-internal.h"
+
+/* Low-level GOST DSA signing */
+
+mp_size_t
+ecc_gostdsa_sign_itch (const struct ecc_curve *ecc)
+{
+  /* Needs 3*ecc-&gt;p.size + scratch for ecc-&gt;mul_g. Currently same for
+     ecc_mul_g and ecc_mul_g_eh. */
+  return ECC_GOSTDSA_SIGN_ITCH (ecc-&gt;p.size);
+}
+
+/* NOTE: Caller should check if r or s is zero. */
+void
+ecc_gostdsa_sign (const struct ecc_curve *ecc,
+		const mp_limb_t *zp,
+		const mp_limb_t *kp,
+		size_t length, const uint8_t *digest,
+		mp_limb_t *rp, mp_limb_t *sp,
+		mp_limb_t *scratch)
+{
+#define P	    scratch
+#define hp	    (scratch + 4*ecc-&gt;p.size)
+#define tp	    (scratch + 2*ecc-&gt;p.size)
+#define t2p	    scratch
+  /* Procedure, according to GOST 34.10. q denotes the group
+     order.
+
+     1. k &lt;-- uniformly random, 0 &lt; k &lt; q
+
+     2. C &lt;-- (c_x, c_y) = k g
+
+     3. r &lt;-- c_x mod q
+
+     4. s &lt;-- (r*z + k*h) mod q.
+  */
+
+  ecc-&gt;mul_g (ecc, P, kp, P + 3*ecc-&gt;p.size);
+  /* x coordinate only, modulo q */
+  ecc-&gt;h_to_a (ecc, 2, rp, P, P + 3*ecc-&gt;p.size);
+
+  /* Process hash digest */
+  gost_hash (&amp;ecc-&gt;q, hp, length, digest);
+  if (mpn_zero_p (hp, ecc-&gt;p.size))
+    mpn_add_1 (hp, hp, ecc-&gt;p.size, 1);
+
+  ecc_modq_mul (ecc, tp, rp, zp);
+  ecc_modq_mul (ecc, t2p, kp, hp);
+  ecc_modq_add (ecc, sp, tp, t2p);
+
+  /* Also reduce mod ecc-&gt;q. It should already be &lt; 2*ecc-&gt;q,
+   * so one subtraction should suffice. */
+
+  *scratch = mpn_sub_n (tp, sp, ecc-&gt;q.m, ecc-&gt;p.size);
+  cnd_copy (*scratch == 0, sp, tp, ecc-&gt;p.size);
+
+#undef P
+#undef hp
+#undef tp
+#undef t2p
+}
diff --git a/ecc-gostdsa-verify.c b/ecc-gostdsa-verify.c
new file mode 100644
index 000000000000..4358132b2bf6
--- /dev/null
+++ b/ecc-gostdsa-verify.c
@@ -0,0 +1,130 @@
+/* ecc-gostdsa-verify.c
+
+   Copyright (C) 2015 Dmitry Eremin-Solenikov
+   Copyright (C) 2013, 2014 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;stdlib.h&gt;
+
+#include "gostdsa.h"
+#include "ecc-internal.h"
+
+/* Low-level GOST DSA verify */
+
+static int
+ecdsa_in_range (const struct ecc_curve *ecc, const mp_limb_t *xp)
+{
+  return !mpn_zero_p (xp, ecc-&gt;p.size)
+    &amp;&amp; mpn_cmp (xp, ecc-&gt;q.m, ecc-&gt;p.size) &lt; 0;
+}
+
+mp_size_t
+ecc_gostdsa_verify_itch (const struct ecc_curve *ecc)
+{
+  /* Largest storage need is for the ecc-&gt;mul call. */
+  return 5*ecc-&gt;p.size + ecc-&gt;mul_itch;
+}
+
+/* FIXME: Use faster primitives, not requiring side-channel silence. */
+int
+ecc_gostdsa_verify (const struct ecc_curve *ecc,
+		  const mp_limb_t *pp, /* Public key */
+		  size_t length, const uint8_t *digest,
+		  const mp_limb_t *rp, const mp_limb_t *sp,
+		  mp_limb_t *scratch)
+{
+  /* Procedure, according to GOST R 34.10. q denotes the group
+     order.
+
+     1. Check 0 &lt; r, s &lt; q.
+
+     2. v &lt;-- h^{-1}  (mod q)
+
+     3. z1  &lt;-- s * v (mod q)
+
+     4. z2  &lt;-- -r * v (mod q)
+
+     5. R = u1 G + u2 Y
+
+     6. Signature is valid if R_x = r (mod q).
+  */
+
+#define hp (scratch)
+#define vp (scratch + ecc-&gt;p.size)
+#define z1 (scratch + 3*ecc-&gt;p.size)
+#define z2 (scratch + 4*ecc-&gt;p.size)
+
+#define P1 (scratch + 4*ecc-&gt;p.size)
+#define P2 (scratch)
+
+
+  if (! (ecdsa_in_range (ecc, rp)
+	 &amp;&amp; ecdsa_in_range (ecc, sp)))
+    return 0;
+
+  gost_hash (&amp;ecc-&gt;q, hp, length, digest);
+
+  if (mpn_zero_p (hp, ecc-&gt;p.size))
+    mpn_add_1 (hp, hp, ecc-&gt;p.size, 1);
+
+  /* Compute v */
+  ecc-&gt;q.invert (&amp;ecc-&gt;q, vp, hp, vp + 2*ecc-&gt;p.size);
+
+  /* z1 = s / h, P1 = z1 * G */
+  ecc_modq_mul (ecc, z1, sp, vp);
+
+  /* z2 = - r / h, P2 = z2 * Y */
+  ecc_modq_mul (ecc, z2, rp, vp);
+  mpn_sub_n (z2, ecc-&gt;q.m, z2, ecc-&gt;p.size);
+
+   /* Total storage: 5*ecc-&gt;p.size + ecc-&gt;mul_itch */
+  ecc-&gt;mul (ecc, P2, z2, pp, z2 + ecc-&gt;p.size);
+
+  /* Total storage: 7*ecc-&gt;p.size + ecc-&gt;mul_g_itch (ecc-&gt;p.size) */
+  ecc-&gt;mul_g (ecc, P1, z1, P1 + 3*ecc-&gt;p.size);
+
+  /* Total storage: 6*ecc-&gt;p.size + ecc-&gt;add_hhh_itch */
+  ecc-&gt;add_hhh (ecc, P1, P1, P2, P1 + 3*ecc-&gt;p.size);
+
+  /* x coordinate only, modulo q */
+  ecc-&gt;h_to_a (ecc, 2, P2, P1, P1 + 3*ecc-&gt;p.size);
+
+  return (mpn_cmp (rp, P2, ecc-&gt;p.size) == 0);
+#undef P2
+#undef P1
+#undef z2
+#undef z1
+#undef hp
+#undef vp
+}
diff --git a/ecc-hash.c b/ecc-hash.c
index 4e830a514ac4..07877110263f 100644
--- a/ecc-hash.c
+++ b/ecc-hash.c
@@ -62,3 +62,14 @@ ecc_hash (const struct ecc_modulo *m,
     /* We got a few extra bits, at the low end. Discard them. */
     mpn_rshift (hp, hp, m-&gt;size + 1, 8*length - m-&gt;bit_size);
 }
+
+void
+gost_hash (const struct ecc_modulo *m,
+	   mp_limb_t *hp,
+	   size_t length, const uint8_t *digest)
+{
+  if (length &gt; ((size_t) m-&gt;bit_size + 7) / 8)
+    length = (m-&gt;bit_size + 7) / 8;
+
+  mpn_set_base256_le (hp, m-&gt;size + 1, digest, length);
+}
diff --git a/ecc-internal.h b/ecc-internal.h
index 733d7fe0273e..c3d66517f5fd 100644
--- a/ecc-internal.h
+++ b/ecc-internal.h
@@ -53,6 +53,7 @@
 #define ecc_mod _nettle_ecc_mod
 #define ecc_mod_inv _nettle_ecc_mod_inv
 #define ecc_hash _nettle_ecc_hash
+#define gost_hash _nettle_gost_hash
 #define ecc_a_to_j _nettle_ecc_a_to_j
 #define ecc_j_to_a _nettle_ecc_j_to_a
 #define ecc_eh_to_a _nettle_ecc_eh_to_a
@@ -288,6 +289,11 @@ ecc_hash (const struct ecc_modulo *m,
 	  mp_limb_t *hp,
 	  size_t length, const uint8_t *digest);
 
+void
+gost_hash (const struct ecc_modulo *m,
+	  mp_limb_t *hp,
+	  size_t length, const uint8_t *digest);
+
 /* Converts a point P in affine coordinates into a point R in jacobian
    coordinates. */
 void
@@ -456,6 +462,7 @@ curve448_eh_to_x (mp_limb_t *xp, const mp_limb_t *p,
 #endif
 #define ECC_MUL_M_ITCH(size) (11*(size))
 #define ECC_ECDSA_SIGN_ITCH(size) (12*(size))
+#define ECC_GOSTDSA_SIGN_ITCH(size) (12*(size))
 #define ECC_MOD_RANDOM_ITCH(size) (size)
 #define ECC_HASH_ITCH(size) (1+(size))
 
diff --git a/gostdsa-sign.c b/gostdsa-sign.c
new file mode 100644
index 000000000000..892c0742c898
--- /dev/null
+++ b/gostdsa-sign.c
@@ -0,0 +1,74 @@
+/* gostdsa-sign.c
+
+   Copyright (C) 2015 Dmitry Eremin-Solenikov
+   Copyright (C) 2013 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;stdlib.h&gt;
+
+#include "gostdsa.h"
+#include "ecc-internal.h"
+#include "nettle-internal.h"
+
+void
+gostdsa_sign (const struct ecc_scalar *key,
+	    void *random_ctx, nettle_random_func *random,
+	    size_t digest_length,
+	    const uint8_t *digest,
+	    struct dsa_signature *signature)
+{
+  /* At most 936 bytes. */
+  TMP_DECL(k, mp_limb_t, ECC_MAX_SIZE + ECC_GOSTDSA_SIGN_ITCH (ECC_MAX_SIZE));
+  mp_limb_t size = key-&gt;ecc-&gt;p.size;
+  mp_limb_t *rp = mpz_limbs_write (signature-&gt;r, size);
+  mp_limb_t *sp = mpz_limbs_write (signature-&gt;s, size);
+
+  TMP_ALLOC (k, size + ECC_GOSTDSA_SIGN_ITCH (size));
+
+  /* Timing reveals the number of rounds through this loop, but the
+     timing is still independent of the secret k finally used. */
+  do
+    {
+      do
+        {
+          ecc_mod_random (&amp;key-&gt;ecc-&gt;q, k, random_ctx, random, k + size);
+	}
+      while (mpn_zero_p(k, size));
+      ecc_gostdsa_sign (key-&gt;ecc, key-&gt;p, k, digest_length, digest,
+		   rp, sp, k + size);
+      mpz_limbs_finish (signature-&gt;r, size);
+      mpz_limbs_finish (signature-&gt;s, size);
+    }
+  while (mpz_sgn (signature-&gt;r) == 0 || mpz_sgn (signature-&gt;s) == 0);
+}
diff --git a/gostdsa-verify.c b/gostdsa-verify.c
new file mode 100644
index 000000000000..7dc1bec1ef62
--- /dev/null
+++ b/gostdsa-verify.c
@@ -0,0 +1,78 @@
+/* gostdsa-verify.c
+
+   Copyright (C) 2015 Dmitry Eremin-Solenikov
+   Copyright (C) 2013 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;stdlib.h&gt;
+
+#include "gostdsa.h"
+
+#include "gmp-glue.h"
+
+int
+gostdsa_verify (const struct ecc_point *pub,
+	      size_t length, const uint8_t *digest,
+	      const struct dsa_signature *signature)
+{
+  mp_limb_t size = ecc_size (pub-&gt;ecc);
+  mp_size_t itch = 2*size + ecc_gostdsa_verify_itch (pub-&gt;ecc);
+  /* For ECC_MUL_A_WBITS == 0, at most 1512 bytes. With
+     ECC_MUL_A_WBITS == 4, currently needs 67 * ecc-&gt;size, at most
+     4824 bytes. Don't use stack allocation for this. */
+  mp_limb_t *scratch;
+  int res;
+
+#define rp scratch
+#define sp (scratch + size)
+#define scratch_out (scratch + 2*size)
+
+  if (mpz_sgn (signature-&gt;r) &lt;= 0 || mpz_size (signature-&gt;r) &gt; size
+      || mpz_sgn (signature-&gt;s) &lt;= 0 || mpz_size (signature-&gt;s) &gt; size)
+    return 0;
+
+  scratch = gmp_alloc_limbs (itch);
+
+  mpz_limbs_copy (rp, signature-&gt;r, size);
+  mpz_limbs_copy (sp, signature-&gt;s, size);
+
+  res = ecc_gostdsa_verify (pub-&gt;ecc, pub-&gt;p, length, digest, rp, sp, scratch_out);
+
+  gmp_free_limbs (scratch, itch);
+
+  return res;
+#undef rp
+#undef sp
+#undef scratch_out
+}
diff --git a/gostdsa.h b/gostdsa.h
new file mode 100644
index 000000000000..b34533436f72
--- /dev/null
+++ b/gostdsa.h
@@ -0,0 +1,102 @@
+/* gostdsa.h
+
+   Copyright (C) 2015 Dmity Eremin-Solenikov
+   Copyright (C) 2013 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+/* Development of Nettle's ECC support was funded by the .SE Internet Fund. */
+
+#ifndef NETTLE_GOSTDSA_H_INCLUDED
+#define NETTLE_GOSTDSA_H_INCLUDED
+
+#include "ecc.h"
+#include "dsa.h"
+#include "ecdsa.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/* Name mangling */
+#define gostdsa_sign nettle_gostdsa_sign
+#define gostdsa_verify nettle_gostdsa_verify
+#define ecc_gostdsa_sign nettle_ecc_gostdsa_sign
+#define ecc_gostdsa_sign_itch nettle_ecc_gostdsa_sign_itch
+#define ecc_gostdsa_verify nettle_ecc_gostdsa_verify
+#define ecc_gostdsa_verify_itch nettle_ecc_gostdsa_verify_itch
+
+/* Just use ECDSA function for key generation */
+#define gostdsa_generate_keypair ecdsa_generate_keypair
+
+/* High level GOST DSA functions.
+ *
+ * A public key is represented as a struct ecc_point, and a private
+ * key as a struct ecc_scalar. FIXME: Introduce some aliases? */
+void
+gostdsa_sign (const struct ecc_scalar *key,
+	      void *random_ctx, nettle_random_func *random,
+	      size_t digest_length,
+	      const uint8_t *digest,
+	      struct dsa_signature *signature);
+
+int
+gostdsa_verify (const struct ecc_point *pub,
+	        size_t length, const uint8_t *digest,
+	        const struct dsa_signature *signature);
+
+/* Low-level GOSTDSA functions. */
+mp_size_t
+ecc_gostdsa_sign_itch (const struct ecc_curve *ecc);
+
+void
+ecc_gostdsa_sign (const struct ecc_curve *ecc,
+		const mp_limb_t *zp,
+		/* Random nonce, must be invertible mod ecc group
+		   order. */
+		const mp_limb_t *kp,
+		size_t length, const uint8_t *digest,
+		mp_limb_t *rp, mp_limb_t *sp,
+		mp_limb_t *scratch);
+
+mp_size_t
+ecc_gostdsa_verify_itch (const struct ecc_curve *ecc);
+
+int
+ecc_gostdsa_verify (const struct ecc_curve *ecc,
+		  const mp_limb_t *pp, /* Public key */
+		  size_t length, const uint8_t *digest,
+		  const mp_limb_t *rp, const mp_limb_t *sp,
+		  mp_limb_t *scratch);
+
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* NETTLE_GOSTDSA_H_INCLUDED */
diff --git a/testsuite/.gitignore b/testsuite/.gitignore
index 1e2a69a60c13..be3a48707580 100644
--- a/testsuite/.gitignore
+++ b/testsuite/.gitignore
@@ -43,6 +43,9 @@
 /eddsa-sign-test
 /eddsa-verify-test
 /gcm-test
+/gostdsa-keygen-test
+/gostdsa-sign-test
+/gostdsa-verify-test
 /gosthash94-test
 /hkdf-test
 /hmac-test
diff --git a/testsuite/.test-rules.make b/testsuite/.test-rules.make
index 6dbef7e24a27..9fd11fd6d126 100644
--- a/testsuite/.test-rules.make
+++ b/testsuite/.test-rules.make
@@ -289,6 +289,15 @@ ed25519-test$(EXEEXT): ed25519-test.$(OBJEXT)
 ed448-test$(EXEEXT): ed448-test.$(OBJEXT)
 	$(LINK) ed448-test.$(OBJEXT) $(TEST_OBJS) -o ed448-test$(EXEEXT)
 
+gostdsa-sign-test$(EXEEXT): gostdsa-sign-test.$(OBJEXT)
+	$(LINK) gostdsa-sign-test.$(OBJEXT) $(TEST_OBJS) -o gostdsa-sign-test$(EXEEXT)
+
+gostdsa-verify-test$(EXEEXT): gostdsa-verify-test.$(OBJEXT)
+	$(LINK) gostdsa-verify-test.$(OBJEXT) $(TEST_OBJS) -o gostdsa-verify-test$(EXEEXT)
+
+gostdsa-keygen-test$(EXEEXT): gostdsa-keygen-test.$(OBJEXT)
+	$(LINK) gostdsa-keygen-test.$(OBJEXT) $(TEST_OBJS) -o gostdsa-keygen-test$(EXEEXT)
+
 sha1-huge-test$(EXEEXT): sha1-huge-test.$(OBJEXT)
 	$(LINK) sha1-huge-test.$(OBJEXT) $(TEST_OBJS) -o sha1-huge-test$(EXEEXT)
 
diff --git a/testsuite/Makefile.in b/testsuite/Makefile.in
index 97128040912e..860394d3bea5 100644
--- a/testsuite/Makefile.in
+++ b/testsuite/Makefile.in
@@ -53,7 +53,9 @@ TS_HOGWEED_SOURCES = sexp-test.c sexp-format-test.c \
 		     ecdsa-sign-test.c ecdsa-verify-test.c \
 		     ecdsa-keygen-test.c ecdh-test.c \
 		     eddsa-compress-test.c eddsa-sign-test.c \
-		     eddsa-verify-test.c ed25519-test.c ed448-test.c
+		     eddsa-verify-test.c ed25519-test.c ed448-test.c \
+		     gostdsa-sign-test.c gostdsa-verify-test.c \
+		     gostdsa-keygen-test.c
 
 TS_SOURCES = $(TS_NETTLE_SOURCES) $(TS_HOGWEED_SOURCES)
 CXX_SOURCES = cxx-test.cxx
diff --git a/testsuite/gostdsa-keygen-test.c b/testsuite/gostdsa-keygen-test.c
new file mode 100644
index 000000000000..f34ff485ad6b
--- /dev/null
+++ b/testsuite/gostdsa-keygen-test.c
@@ -0,0 +1,154 @@
+#include "testutils.h"
+#include "knuth-lfib.h"
+
+/* Check if y^2 = x^3 - 3x + b */
+static int
+ecc_valid_p (struct ecc_point *pub)
+{
+  mpz_t t, x, y;
+  mpz_t lhs, rhs;
+  int res;
+  mp_size_t size;
+
+  size = pub-&gt;ecc-&gt;p.size;
+
+  /* First check range */
+  if (mpn_cmp (pub-&gt;p, pub-&gt;ecc-&gt;p.m, size) &gt;= 0
+      || mpn_cmp (pub-&gt;p + size, pub-&gt;ecc-&gt;p.m, size) &gt;= 0)
+    return 0;
+
+  mpz_init (lhs);
+  mpz_init (rhs);
+
+  mpz_roinit_n (x, pub-&gt;p, size);
+  mpz_roinit_n (y, pub-&gt;p + size, size);
+
+  mpz_mul (lhs, y, y);
+
+  if (pub-&gt;ecc-&gt;p.bit_size == 255)
+    {
+      /* Check that
+	 121666 (1 + x^2 - y^2) = 121665 x^2 y^2 */
+      mpz_t x2;
+      mpz_init (x2);
+      mpz_mul (x2, x, x); /* x^2 */
+      mpz_mul (rhs, x2, lhs); /* x^2 y^2 */
+      mpz_sub (lhs, x2, lhs); /* x^2 - y^2 */
+      mpz_add_ui (lhs, lhs, 1); /* 1 + x^2 - y^2 */
+      mpz_mul_ui (lhs, lhs, 121666);
+      mpz_mul_ui (rhs, rhs, 121665);
+
+      mpz_clear (x2);
+    }
+  else if (pub-&gt;ecc-&gt;p.bit_size == 448)
+    {
+      /* Check that
+	 x^2 + y^2 = 1 - 39081 x^2 y^2 */
+      mpz_t x2, d;
+      mpz_init (x2);
+      mpz_init_set_ui (d, 39081);
+      mpz_mul (x2, x, x); /* x^2 */
+      mpz_mul (d, d, x2); /* 39081 x^2 */
+      mpz_set_ui (rhs, 1);
+      mpz_submul (rhs, d, lhs); /* 1 - 39081 x^2 y^2 */
+      mpz_add (lhs, x2, lhs);	/* x^2 + y^2 */
+
+      mpz_clear (d);
+      mpz_clear (x2);
+    }
+  else
+    {
+      /* Check y^2 = x^3 - 3 x + b */
+      mpz_mul (rhs, x, x);
+      mpz_sub_ui (rhs, rhs, 3);
+      mpz_mul (rhs, rhs, x);
+      mpz_add (rhs, rhs, mpz_roinit_n (t, pub-&gt;ecc-&gt;b, size));
+    }
+  res = mpz_congruent_p (lhs, rhs, mpz_roinit_n (t, pub-&gt;ecc-&gt;p.m, size));
+
+  mpz_clear (lhs);
+  mpz_clear (rhs);
+
+  return res;
+}
+
+void
+test_main (void)
+{
+  unsigned i;
+  struct knuth_lfib_ctx rctx;
+  struct dsa_signature signature;
+
+  struct tstring *digest;
+
+  knuth_lfib_init (&amp;rctx, 4711);
+  dsa_signature_init (&amp;signature);
+
+  digest = SHEX (/* sha256("abc") */
+		 "BA7816BF 8F01CFEA 414140DE 5DAE2223"
+		 "B00361A3 96177A9C B410FF61 F20015AD");
+
+  for (i = 0; ecc_curves[i]; i++)
+    {
+      const struct ecc_curve *ecc = ecc_curves[i];
+      struct ecc_point pub;
+      struct ecc_scalar key;
+
+      if (ecc-&gt;p.bit_size == 255 || ecc-&gt;p.bit_size == 448)
+	/* Exclude curve25519 and curve448, not supported with GOSTDSA. */
+	continue;
+
+      if (verbose)
+	fprintf (stderr, "Curve %d\n", ecc-&gt;p.bit_size);
+
+      ecc_point_init (&amp;pub, ecc);
+      ecc_scalar_init (&amp;key, ecc);
+
+      ecdsa_generate_keypair (&amp;pub, &amp;key,
+			      &amp;rctx,
+			      (nettle_random_func *) knuth_lfib_random);
+
+      if (verbose)
+	{
+	  fprintf (stderr, "Public key:\nx = ");
+	  write_mpn (stderr, 16, pub.p, ecc-&gt;p.size);
+	  fprintf (stderr, "\ny = ");
+	  write_mpn (stderr, 16, pub.p + ecc-&gt;p.size, ecc-&gt;p.size);
+	  fprintf (stderr, "\nPrivate key: ");
+	  write_mpn (stderr, 16, key.p, ecc-&gt;p.size);
+	  fprintf (stderr, "\n");
+	}
+      if (!ecc_valid_p (&amp;pub))
+	die ("gostdsa_generate_keypair produced an invalid point.\n");
+
+      gostdsa_sign (&amp;key,
+		   &amp;rctx, (nettle_random_func *) knuth_lfib_random,
+		   digest-&gt;length, digest-&gt;data,
+		   &amp;signature);
+
+      if (!gostdsa_verify (&amp;pub, digest-&gt;length, digest-&gt;data,
+			   &amp;signature))
+	die ("gostdsa_verify failed.\n");
+
+      digest-&gt;data[3] ^= 17;
+      if (gostdsa_verify (&amp;pub, digest-&gt;length, digest-&gt;data,
+			  &amp;signature))
+	die ("gostdsa_verify  returned success with invalid digest.\n");
+      digest-&gt;data[3] ^= 17;
+
+      mpz_combit (signature.r, 117);
+      if (gostdsa_verify (&amp;pub, digest-&gt;length, digest-&gt;data,
+			  &amp;signature))
+	die ("gostdsa_verify  returned success with invalid signature.r.\n");
+
+      mpz_combit (signature.r, 117);
+      mpz_combit (signature.s, 93);
+      if (gostdsa_verify (&amp;pub, digest-&gt;length, digest-&gt;data,
+			  &amp;signature))
+	die ("gostdsa_verify  returned success with invalid signature.s.\n");
+
+      ecc_point_clear (&amp;pub);
+      ecc_scalar_clear (&amp;key);
+    }
+  dsa_signature_clear (&amp;signature);
+}
diff --git a/testsuite/gostdsa-sign-test.c b/testsuite/gostdsa-sign-test.c
new file mode 100644
index 000000000000..911951c61c88
--- /dev/null
+++ b/testsuite/gostdsa-sign-test.c
@@ -0,0 +1,87 @@
+#include "testutils.h"
+
+static void
+test_gostdsa (const struct ecc_curve *ecc,
+	    /* Private key */
+	    const char *sz,
+	    /* Random nonce */
+	    const char *sk,
+	    /* Hash */
+	    const struct tstring *h,
+	    /* Expected signature */
+	    const char *r, const char *s)
+{
+  struct dsa_signature ref;
+  mpz_t z;
+  mpz_t k;
+  mp_limb_t *rp = xalloc_limbs (ecc-&gt;p.size);
+  mp_limb_t *sp = xalloc_limbs (ecc-&gt;p.size);
+  mp_limb_t *scratch = xalloc_limbs (ecc_gostdsa_sign_itch (ecc));
+
+  dsa_signature_init (&amp;ref);
+
+  mpz_init_set_str (z, sz, 16);
+  mpz_init_set_str (k, sk, 16);
+
+  ecc_gostdsa_sign (ecc, mpz_limbs_read_n (z, ecc-&gt;p.size),
+		  mpz_limbs_read_n (k, ecc-&gt;p.size),
+		  h-&gt;length, h-&gt;data, rp, sp, scratch);
+
+  mpz_set_str (ref.r, r, 16);
+  mpz_set_str (ref.s, s, 16);
+
+  if (mpz_limbs_cmp (ref.r, rp, ecc-&gt;p.size) != 0
+      || mpz_limbs_cmp (ref.s, sp, ecc-&gt;p.size) != 0)
+    {
+      fprintf (stderr, "_gostdsa_sign failed, bit_size = %u\n", ecc-&gt;p.bit_size);
+      fprintf (stderr, "r     = ");
+      write_mpn (stderr, 16, rp, ecc-&gt;p.size);
+      fprintf (stderr, "\ns     = ");
+      write_mpn (stderr, 16, sp, ecc-&gt;p.size);
+      fprintf (stderr, "\nref.r = ");
+      mpz_out_str (stderr, 16, ref.r);
+      fprintf (stderr, "\nref.s = ");
+      mpz_out_str (stderr, 16, ref.s);
+      fprintf (stderr, "\n");
+      abort();
+    }
+
+  free (rp);
+  free (sp);
+  free (scratch);
+
+  dsa_signature_clear (&amp;ref);
+  mpz_clear (k);
+  mpz_clear (z);
+}
+
+void
+test_main (void)
+{
+  test_gostdsa (nettle_get_gc256b(),
+	      "BFCF1D623E5CDD3032A7C6EABB4A923C46E43D640FFEAAF2C3ED39A8FA399924", /* z */
+
+	      "5782C53F110C596F9155D35EBD25A06A89C50391850A8FEFE33B0E270318857C", /* k */
+
+	      SHEX("1C067E20EA6CB183F22EFB0F3C6FD2A4E6A02821CB7A1B17FACD5E1F7AA76F70"), /* h */
+
+	      "E9323A5E88DD87FB7C724383BFFE7CECD4B9FFA2AC33BEEF73A5A1F743404F6B", /* r */
+
+	      "5E5B9B805B01147A8492C4A162643AC615DC777B9174108F3DC276A41F987AF3"); /* s */
+
+  test_gostdsa (nettle_get_gc512a(),
+	      "3FC01CDCD4EC5F972EB482774C41E66DB7F380528DFE9E67992BA05AEE462435"
+	      "757530E641077CE587B976C8EEB48C48FD33FD175F0C7DE6A44E014E6BCB074B", /* z */
+
+	      "72ABB44536656BF1618CE10BF7EADD40582304A51EE4E2A25A0A32CB0E773ABB"
+	      "23B7D8FDD8FA5EEE91B4AE452F2272C86E1E2221215D405F51B5D5015616E1F6", /* k */
+
+	      SHEX("EDC257BED45FDDE4F1457B7F5B19017A8F204184366689D938532CDBAA5CB29A"
+		   "1D369DA57F8B983BE272219BD2C9A4FC57ECF7A77F34EE2E8AA553976A4766C0"), /* h */
+
+	      "891AA75C2A6F3B4DE27E3903F61CBB0F3F85A4E3C62F39A6E4E84A7477679C6E"
+	      "45008DC2774CA2FF64C12C0606FF918CAE3A50115440E9BF2971B627A882A1E8", /* r */
+
+	      "31065479996DDBDEE180AFE22CA3CDC44B45CE4C6C83909D1D3B702922A32441"
+	      "A9E11DCFBEA3D847C06B1A8A38EB1671D6C82FA21B79C99BE2EA809B10DAA5DF"); /* s */
+}
diff --git a/testsuite/gostdsa-verify-test.c b/testsuite/gostdsa-verify-test.c
new file mode 100644
index 000000000000..5631592fe81f
--- /dev/null
+++ b/testsuite/gostdsa-verify-test.c
@@ -0,0 +1,110 @@
+#include "testutils.h"
+
+static void
+test_gostdsa (const struct ecc_curve *ecc,
+	    /* Public key */
+	    const char *xs, const char *ys,
+	    /* Hash */
+	    struct tstring *h,
+	    /* Valid signature */
+	    const char *r, const char *s)
+{
+  struct ecc_point pub;
+  struct dsa_signature signature;
+  mpz_t x, y;
+
+  ecc_point_init (&amp;pub, ecc);
+  dsa_signature_init (&amp;signature);
+
+  mpz_init_set_str (x, xs, 16);
+  mpz_init_set_str (y, ys, 16);
+
+  if (!ecc_point_set (&amp;pub, x, y))
+    die ("ecc_point_set failed.\n");
+
+  mpz_set_str (signature.r, r, 16);
+  mpz_set_str (signature.s, s, 16);
+
+  if (!gostdsa_verify (&amp;pub, h-&gt;length, h-&gt;data, &amp;signature))
+    {
+      fprintf (stderr, "gostdsa_verify failed with valid signature.\n");
+    fail:
+      fprintf (stderr, "bit_size = %u\nx = ", ecc-&gt;p.bit_size);
+      mpz_out_str (stderr, 16, x);
+      fprintf (stderr, "\ny = ");
+      mpz_out_str (stderr, 16, y);
+      fprintf (stderr, "\ndigest ");
+      print_hex (h-&gt;length, h-&gt;data);
+      fprintf (stderr, "r = ");
+      mpz_out_str (stderr, 16, signature.r);
+      fprintf (stderr, "\ns = ");
+      mpz_out_str (stderr, 16, signature.s);
+      fprintf (stderr, "\n");
+      abort();
+    }
+
+  mpz_combit (signature.r, ecc-&gt;p.bit_size / 3);
+  if (gostdsa_verify (&amp;pub, h-&gt;length, h-&gt;data, &amp;signature))
+    {
+      fprintf (stderr, "gostdsa_verify unexpectedly succeeded with invalid signature.\n");
+      goto fail;
+    }
+  mpz_combit (signature.r, ecc-&gt;p.bit_size / 3);
+
+  mpz_combit (signature.s, 4*ecc-&gt;p.bit_size / 5);
+  if (gostdsa_verify (&amp;pub, h-&gt;length, h-&gt;data, &amp;signature))
+    {
+      fprintf (stderr, "gostdsa_verify unexpectedly succeeded with invalid signature.\n");
+      goto fail;
+    }
+  mpz_combit (signature.s, 4*ecc-&gt;p.bit_size / 5);
+
+  h-&gt;data[2*h-&gt;length / 3] ^= 0x40;
+  if (gostdsa_verify (&amp;pub, h-&gt;length, h-&gt;data, &amp;signature))
+    {
+      fprintf (stderr, "gostdsa_verify unexpectedly succeeded with invalid signature.\n");
+      goto fail;
+    }
+  h-&gt;data[2*h-&gt;length / 3] ^= 0x40;
+  if (!gostdsa_verify (&amp;pub, h-&gt;length, h-&gt;data, &amp;signature))
+    {
+      fprintf (stderr, "gostdsa_verify failed, internal testsuite error.\n");
+      goto fail;
+    }
+
+  ecc_point_clear (&amp;pub);
+  dsa_signature_clear (&amp;signature);
+  mpz_clear (x);
+  mpz_clear (y);
+}
+
+void
+test_main (void)
+{
+  test_gostdsa (nettle_get_gc256b(),
+	      "971566CEDA436EE7678F7E07E84EBB7217406C0B4747AA8FD2AB1453C3D0DFBA", /* x */
+
+	      "AD58736965949F8E59830F8DE20FC6C0D177F6AB599874F1E2E24FF71F9CE643", /* y */
+
+	      SHEX("1C067E20EA6CB183F22EFB0F3C6FD2A4E6A02821CB7A1B17FACD5E1F7AA76F70"), /* h */
+
+	      "E9323A5E88DD87FB7C724383BFFE7CECD4B9FFA2AC33BEEF73A5A1F743404F6B", /* r */
+
+	      "5E5B9B805B01147A8492C4A162643AC615DC777B9174108F3DC276A41F987AF3"); /* s */
+
+  test_gostdsa (nettle_get_gc512a(),
+	      "03A36340A95BB5F93D131961B5B1C1B3213DF7FF3B5A30376407E2A65C441BC6"
+	      "D1B34662317083243F007B15A8512B526606D3B172B606DCE86DBD6F82DA3D40", /* x */
+
+	      "DEAD76318012FED79507809C89CC44848743640EAC9A3C847DA9082E050760A1"
+	      "0679F4B707ABC1872640AD20D7441F66C7A8B3BFF1B8E11B4A076F0A86749F73", /* y */
+
+	      SHEX("EDC257BED45FDDE4F1457B7F5B19017A8F204184366689D938532CDBAA5CB29A"
+		   "1D369DA57F8B983BE272219BD2C9A4FC57ECF7A77F34EE2E8AA553976A4766C0"), /* h */
+
+	      "891AA75C2A6F3B4DE27E3903F61CBB0F3F85A4E3C62F39A6E4E84A7477679C6E"
+	      "45008DC2774CA2FF64C12C0606FF918CAE3A50115440E9BF2971B627A882A1E8", /* r */
+
+	      "31065479996DDBDEE180AFE22CA3CDC44B45CE4C6C83909D1D3B702922A32441"
+	      "A9E11DCFBEA3D847C06B1A8A38EB1671D6C82FA21B79C99BE2EA809B10DAA5DF"); /* s */
+}
diff --git a/testsuite/testutils.h b/testsuite/testutils.h
index f4ea38da9deb..cef7f4011a7c 100644
--- a/testsuite/testutils.h
+++ b/testsuite/testutils.h
@@ -22,6 +22,7 @@
 # include "ecc.h"
 # include "ecc-internal.h"
 # include "ecdsa.h"
+# include "gostdsa.h"
 # include "gmp-glue.h"
 # if NETTLE_USE_MINI_GMP
 #  include "knuth-lfib.h"
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200115182653</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-15 18:26:53-0400</timestampReceived><subject>Re: [PATCH v2 1/3] Add support for GOST GC256B curve</subject><body>

Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt; writes:

&gt; I'll change the names t follow
&gt; gost_gc256b pattern, add documentation and submit v4.

Excellent.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200115194118</emailId><senderName>Dmitry Eremin-Solenikov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-01-15 19:41:18-0400</timestampReceived><subject>Re: Gitlab merge requests</subject><body>

ср, 15 янв. 2020 г., 12:03 Tim Rühsen &lt;tim.ruehsen@gmx.de&gt;:

&gt; On 1/15/20 9:24 AM, Nikos Mavrogiannopoulos wrote:
&gt; &gt; On Wed, Jan 15, 2020 at 7:18 AM Niels Möller &lt;nisse@lysator.liu.se&gt;
&gt; wrote:
&gt; &gt;
&gt; &gt;&gt;&gt; If they are you should be able to see them in Settings -&gt; CI/CD -&gt;
&gt; Runners.
&gt; &gt;&gt;
&gt; &gt;&gt; I've now had a look. There's a section for "Group runners", which is
&gt; &gt;&gt; empty. No mention of "shared runners". There's a link to "Install a
&gt; &gt;&gt; GitLab runner" (with various kinds of binaries, no mention of sources),
&gt; &gt;&gt; and a big button "Install Runner on Kubernetes".
&gt; &gt;
&gt; &gt; So there aren't any :)
&gt;
&gt; Niels, since you set up your own instance of Gitlab, you can't access
&gt; the Gitlab.com runners (it's a free service for customers only).
&gt;
&gt; So you can set up your own "machines" (bare metal, vm or container) and
&gt; install [1] on them. This gives you runners for your own CI - every
&gt; merge request and every push will automatically be built and tested.
&gt;


Another option would be to switch to gitlab.com (and use free CI runners)
and use git.lysator.liu.se as a backup/mirror.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200115210100</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-15 21:01:00-0400</timestampReceived><subject>Re: Require GNU make?</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; Requiring GNU make makes a few things easier: We can use %-patterns
&gt; everywhere. We can use -include unconditionally for dep-files, dropping the
&gt; @DEP_INCLUDE@ variable and the dummy-dep-files configure step. We can
&gt; most likely also drop all logic for the testsuite/.test-rules.make file.

I've pushed some changes to the branch require-gnu-make. So far, this
branch simplifies the dep files logic, and replaces all suffix rules by
pattern rules.

I haven't yet looked at deleting testsuite/.testrules.make. I wonder if
static pattern rules (see
https://www.gnu.org/software/make/manual/html_node/Static-Pattern.html#Static-Pattern)
are a good tool for that?

The README file already says "Using GNU make is strongly recommended".
Does it need to be clearer that using other make programs is untested
and not likely to work?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200115223608</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-01-15 22:36:08-0400</timestampReceived><subject>[PATCH v4 1/4] Add support for GOST GC256B curve</subject><body>

From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;

Add support for GC256B curve ("TLS Supported Groups" registry,
draft-smyshlyaev-tls12-gost-suites) also known as
GostR3410-2001-CryptoPro-A and GostR3410-2001-CryptoPro-XchA (RFC 4357).

Signed-off-by: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;
Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 .gitignore               |   1 +
 Makefile.in              |  11 ++++
 ecc-curve.h              |   1 +
 ecc-gost-gc256b.c        | 128 +++++++++++++++++++++++++++++++++++++++
 ecc-internal.h           |   3 +
 eccdata.c                |  34 ++++++++++-
 examples/ecc-benchmark.c |   1 +
 testsuite/testutils.c    |  12 +++-
 8 files changed, 188 insertions(+), 3 deletions(-)
 create mode 100644 ecc-gost-gc256b.c

diff --git a/.gitignore b/.gitignore
index ea264107fa40..4454ade5a950 100644
--- a/.gitignore
+++ b/.gitignore
@@ -45,6 +45,7 @@ core
 /rotors.h
 /ecc-curve25519.h
 /ecc-curve448.h
+/ecc-gc256b.h
 /ecc-secp192r1.h
 /ecc-secp224r1.h
 /ecc-secp256r1.h
diff --git a/Makefile.in b/Makefile.in
index 38160bb40fe1..9c1a925462aa 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -176,6 +176,7 @@ hogweed_SOURCES = sexp.c sexp-format.c \
 		  ecc-mod.c ecc-mod-inv.c \
 		  ecc-mod-arith.c ecc-pp1-redc.c ecc-pm1-redc.c \
 		  ecc-curve25519.c ecc-curve448.c \
+		  ecc-gost-gc256b.c \
 		  ecc-secp192r1.c ecc-secp224r1.c ecc-secp256r1.c \
 		  ecc-secp384r1.c ecc-secp521r1.c \
 		  ecc-size.c ecc-j-to-a.c ecc-a-to-j.c \
@@ -396,12 +397,21 @@ ecc-curve25519.h: eccdata.stamp
 ecc-curve448.h: eccdata.stamp
 	./eccdata$(EXEEXT_FOR_BUILD) curve448 38 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
 
+# Some reasonable choices for 256:
+# k =  9, c =  6, S = 320, T =  54 ( 45 A +  9 D) 20 KB
+# k = 11, c =  6, S = 256, T =  55 ( 44 A + 11 D) 16 KB
+# k = 19, c =  7, S = 256, T =  57 ( 38 A + 19 D) 16 KB
+# k = 15, c =  6, S = 192, T =  60 ( 45 A + 15 D) 12 KB
+ecc-gost-gc256b.h: eccdata.stamp
+	./eccdata$(EXEEXT_FOR_BUILD) gost_gc256b 11 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
+
 eccdata.stamp: eccdata.c
 	$(MAKE) eccdata$(EXEEXT_FOR_BUILD)
 	echo stamp &gt; eccdata.stamp
 
 ecc-curve25519.$(OBJEXT): ecc-curve25519.h
 ecc-curve448.$(OBJEXT): ecc-curve448.h
+ecc-gost-gc256b.$(OBJEXT): ecc-gost-gc256b.h
 ecc-secp192r1.$(OBJEXT): ecc-secp192r1.h
 ecc-secp224r1.$(OBJEXT): ecc-secp224r1.h
 ecc-secp256r1.$(OBJEXT): ecc-secp256r1.h
@@ -660,6 +670,7 @@ distcheck: dist
 clean-here:
 	-rm -f $(TARGETS) *.$(OBJEXT) *.s *.so *.dll *.a \
 		ecc-curve25519.h ecc-curve448.h \
+		ecc-gost-gc256b.h \
 		ecc-secp192r1.h ecc-secp224r1.h ecc-secp256r1.h \
 		ecc-secp384r1.h ecc-secp521r1.h \
 		aesdata$(EXEEXT_FOR_BUILD) \
diff --git a/ecc-curve.h b/ecc-curve.h
index 76024a19d24f..da07b0232d42 100644
--- a/ecc-curve.h
+++ b/ecc-curve.h
@@ -43,6 +43,7 @@ extern "C" {
 /* The contents of this struct is internal. */
 struct ecc_curve;
 
+const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_gost_gc256b(void);
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_secp_192r1(void);
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_secp_224r1(void);
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_secp_256r1(void);
diff --git a/ecc-gost-gc256b.c b/ecc-gost-gc256b.c
new file mode 100644
index 000000000000..8adc8e1763b9
--- /dev/null
+++ b/ecc-gost-gc256b.c
@@ -0,0 +1,128 @@
+/* ecc-gost-gc256b.c
+
+   Copyright (C) 2016-2020 Dmitry Eremin-Solenikov
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+
+#include "ecc.h"
+#include "ecc-internal.h"
+
+#define USE_REDC 0
+
+#include "ecc-gost-gc256b.h"
+
+static void
+ecc_gost_gc256b_modp (const struct ecc_modulo *m, mp_limb_t *rp)
+{
+  mp_size_t mn = m-&gt;size;
+  mp_limb_t hi;
+
+  hi = mpn_addmul_1(rp, rp + mn, mn, 0x269);
+  hi = sec_add_1 (rp, rp, mn, hi * 0x269);
+  hi = sec_add_1 (rp, rp, mn, hi * 0x269);
+  assert(hi == 0);
+}
+
+#define ecc_gost_gc256b_modp ecc_gost_gc256b_modp
+#define ecc_gost_gc256b_modq ecc_mod
+
+const struct ecc_curve _nettle_gost_gc256b =
+{
+  {
+    256,
+    ECC_LIMB_SIZE,
+    ECC_BMODP_SIZE,
+    ECC_REDC_SIZE,
+    ECC_MOD_INV_ITCH (ECC_LIMB_SIZE),
+    0,
+
+    ecc_p,
+    ecc_Bmodp,
+    ecc_Bmodp_shifted,
+    ecc_redc_ppm1,
+
+    ecc_pp1h,
+    ecc_gost_gc256b_modp,
+    ecc_gost_gc256b_modp,
+    ecc_mod_inv,
+    NULL,
+  },
+  {
+    256,
+    ECC_LIMB_SIZE,
+    ECC_BMODQ_SIZE,
+    0,
+    ECC_MOD_INV_ITCH (ECC_LIMB_SIZE),
+    0,
+
+    ecc_q,
+    ecc_Bmodq,
+    ecc_Bmodq_shifted,
+    NULL,
+    ecc_qp1h,
+
+    ecc_gost_gc256b_modq,
+    ecc_gost_gc256b_modq,
+    ecc_mod_inv,
+    NULL,
+  },
+
+  USE_REDC,
+  ECC_PIPPENGER_K,
+  ECC_PIPPENGER_C,
+
+  ECC_ADD_JJA_ITCH (ECC_LIMB_SIZE),
+  ECC_ADD_JJJ_ITCH (ECC_LIMB_SIZE),
+  ECC_DUP_JJ_ITCH (ECC_LIMB_SIZE),
+  ECC_MUL_A_ITCH (ECC_LIMB_SIZE),
+  ECC_MUL_G_ITCH (ECC_LIMB_SIZE),
+  ECC_J_TO_A_ITCH (ECC_LIMB_SIZE),
+
+  ecc_add_jja,
+  ecc_add_jjj,
+  ecc_dup_jj,
+  ecc_mul_a,
+  ecc_mul_g,
+  ecc_j_to_a,
+
+  ecc_b,
+  ecc_g,
+  ecc_unit,
+  ecc_table
+};
+
+const struct ecc_curve *nettle_get_gost_gc256b(void)
+{
+  return &amp;_nettle_gost_gc256b;
+}
diff --git a/ecc-internal.h b/ecc-internal.h
index c918632df292..53305bc08404 100644
--- a/ecc-internal.h
+++ b/ecc-internal.h
@@ -91,6 +91,9 @@ extern const struct ecc_curve _nettle_secp_521r1;
 extern const struct ecc_curve _nettle_curve25519;
 extern const struct ecc_curve _nettle_curve448;
 
+/* GOST curves, visible with underscore prefix for now */
+extern const struct ecc_curve _nettle_gost_gc256b;
+
 #define ECC_MAX_SIZE ((521 + GMP_NUMB_BITS - 1) / GMP_NUMB_BITS)
 
 /* Window size for ecc_mul_a. Using 4 bits seems like a good choice,
diff --git a/eccdata.c b/eccdata.c
index d76a42bcde6f..fd27d56aebdf 100644
--- a/eccdata.c
+++ b/eccdata.c
@@ -674,6 +674,38 @@ ecc_curve_init (struct ecc_curve *ecc, const char *curve)
 		   "47d0e827cb1595e1470eb88580d5716c"
 		   "4cf22832ea2f0ff0df38ab61ca32112f");
     }
+  else if (!strcmp (curve, "gost_gc256b"))
+    {
+      ecc_curve_init_str (ecc, ECC_TYPE_WEIERSTRASS,
+			  "ffffffffffffffffffffffffffffffff"
+			  "fffffffffffffffffffffffffffffd97",
+
+			  "00000000000000000000000000000000"
+			  "000000000000000000000000000000a6",
+
+			  "ffffffffffffffffffffffffffffffff"
+			  "6c611070995ad10045841b09b761b893",
+
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000001",
+
+			  "8d91e471e0989cda27df505a453f2b76"
+			  "35294f2ddf23e3b122acc99c9e9f1e14");
+
+      ecc-&gt;ref = ecc_alloc (3);
+      ecc_set_str (&amp;ecc-&gt;ref[0], /* 2 g */
+		   "fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffd95",
+		   "726e1b8e1f676325d820afa5bac0d489cad6b0d220dc1c4edd5336636160df83");
+
+      ecc_set_str (&amp;ecc-&gt;ref[1], /* 3 g */
+		   "8e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38d2c",
+		   "76bcd1ca9a23b041d4d9baf507a6cd821267a94c838768e8486117796b788a51");
+
+      ecc_set_str (&amp;ecc-&gt;ref[2], /* 4 g */
+		   "f7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e4b7",
+		   "83ccf17ba6706d73625cc3534c7a2b9d6ec1ee6a9a7e07c10d84b388de59f741");
+
+    }
   else if (!strcmp (curve, "curve448"))
     {
       /* curve448, y^2 = x^3 + 156326 x^2 + x (mod p), with p = 2^{448} - 2^{224} - \
1. @@ -1316,7 +1348,7 @@ main (int argc, char **argv)
 
   if (argc &lt; 4)
     {
-      fprintf (stderr, "Usage: %s CURVE-BITS K C [BITS-PER-LIMB]\n", argv[0]);
+      fprintf (stderr, "Usage: %s CURVE K C [BITS-PER-LIMB]\n", argv[0]);
       return EXIT_FAILURE;
     }
 
diff --git a/examples/ecc-benchmark.c b/examples/ecc-benchmark.c
index d36d46b77bc1..42035ca0fc8d 100644
--- a/examples/ecc-benchmark.c
+++ b/examples/ecc-benchmark.c
@@ -314,6 +314,7 @@ const struct ecc_curve * const curves[] = {
   &amp;_nettle_secp_384r1,
   &amp;_nettle_curve448,
   &amp;_nettle_secp_521r1,
+  &amp;_nettle_gost_gc256b,
 };
 
 #define numberof(x)  (sizeof (x) / sizeof ((x)[0]))
diff --git a/testsuite/testutils.c b/testsuite/testutils.c
index 7772d2b01661..086bcbc860c7 100644
--- a/testsuite/testutils.c
+++ b/testsuite/testutils.c
@@ -1677,6 +1677,7 @@ const struct ecc_curve * const ecc_curves[] = {
   &amp;_nettle_secp_521r1,
   &amp;_nettle_curve25519,
   &amp;_nettle_curve448,
+  &amp;_nettle_gost_gc256b,
   NULL
 };
 
@@ -1728,7 +1729,7 @@ void
 test_ecc_mul_a (unsigned curve, unsigned n, const mp_limb_t *p)
 {
   /* For each curve, the points 2 g, 3 g and 4 g */
-  static const struct ecc_ref_point ref[7][3] = {
+  static const struct ecc_ref_point ref[8][3] = {
     { { "dafebf5828783f2ad35534631588a3f629a70fb16982a888",
 	"dd6bda0d993da0fa46b27bbc141b868f59331afa5c7e93ab" },
       { "76e32a2557599e6edcd283201fb2b9aadfd0d359cbb263da",
@@ -1796,9 +1797,16 @@ test_ecc_mul_a (unsigned curve, unsigned n, const mp_limb_t \
*p)  "e005a8dbd5125cf706cbda7ad43aa6449a4a8d952356c3b9fce43c82ec4e1d58bb3a331bdb6767f0bffa9a68fed02dafb822ac13588ed6fc" \
                },
       { "49dcbc5c6c0cce2c1419a17226f929ea255a09cf4e0891c693fda4be70c74cc301b7bdf1515dd8ba21aee1798949e120e2ce42ac48ba7f30",
  "d49077e4accde527164b33a5de021b979cb7c02f0457d845c90dc3227b8a5bc1c0d8f97ea1ca9472b5d444285d0d4f5b32e236f86de51839" \
}, +    },
+    { { "fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffd95",
+	"726e1b8e1f676325d820afa5bac0d489cad6b0d220dc1c4edd5336636160df83" },
+      { "8e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38d2c",
+	"76bcd1ca9a23b041d4d9baf507a6cd821267a94c838768e8486117796b788a51" },
+      { "f7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e4b7",
+	"83ccf17ba6706d73625cc3534c7a2b9d6ec1ee6a9a7e07c10d84b388de59f741" },
     }
   };
-  assert (curve &lt; 7);
+  assert (curve &lt; 8);
   assert (n &lt;= 4);
   if (n == 0)
     {
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200115223609</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-01-15 22:36:09-0400</timestampReceived><subject>[PATCH v4 2/4] Add support for GOST GC512A curve</subject><body>

From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;

Add support for GC512A curve ("TLS Supported Groups" registry,
draft-smyshlyaev-tls12-gost-suites) also known as
tc26-gost-3410-12-512-paramSetA (RFC 7836).

Signed-off-by: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;
---
 .gitignore               |   1 +
 Makefile.in              |  14 ++++-
 ecc-curve.h              |   1 +
 ecc-gost-gc512a.c        | 128 +++++++++++++++++++++++++++++++++++++++
 ecc-internal.h           |   1 +
 eccdata.c                |  38 ++++++++++++
 examples/ecc-benchmark.c |   1 +
 testsuite/testutils.c    |  18 +++++-
 8 files changed, 198 insertions(+), 4 deletions(-)
 create mode 100644 ecc-gost-gc512a.c

diff --git a/.gitignore b/.gitignore
index 4454ade5a950..2e64c187574f 100644
--- a/.gitignore
+++ b/.gitignore
@@ -46,6 +46,7 @@ core
 /ecc-curve25519.h
 /ecc-curve448.h
 /ecc-gc256b.h
+/ecc-gc512a.h
 /ecc-secp192r1.h
 /ecc-secp224r1.h
 /ecc-secp256r1.h
diff --git a/Makefile.in b/Makefile.in
index 9c1a925462aa..a08dfe4da481 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -176,7 +176,7 @@ hogweed_SOURCES = sexp.c sexp-format.c \
 		  ecc-mod.c ecc-mod-inv.c \
 		  ecc-mod-arith.c ecc-pp1-redc.c ecc-pm1-redc.c \
 		  ecc-curve25519.c ecc-curve448.c \
-		  ecc-gost-gc256b.c \
+		  ecc-gost-gc256b.c ecc-gost-gc512a.c \
 		  ecc-secp192r1.c ecc-secp224r1.c ecc-secp256r1.c \
 		  ecc-secp384r1.c ecc-secp521r1.c \
 		  ecc-size.c ecc-j-to-a.c ecc-a-to-j.c \
@@ -405,6 +405,15 @@ ecc-curve448.h: eccdata.stamp
 ecc-gost-gc256b.h: eccdata.stamp
 	./eccdata$(EXEEXT_FOR_BUILD) gost_gc256b 11 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
 
+# Some reasonable choices for 512:
+# k = 22, c =  6, S = 256, T = 110 ( 88 A + 22 D) 32 KB
+# k = 29, c =  6, S = 192, T = 116 ( 87 A + 29 D) 24 KB
+# k = 21, c =  5, S = 160, T = 126 (105 A + 21 D) 20 KB
+# k = 43, c =  6, S = 128, T = 129 ( 86 A + 43 D) 16 KB
+# k = 35, c =  5, S =  96, T = 140 (105 A + 35 D) 12 KB
+ecc-gost-gc512a.h: eccdata.stamp
+	./eccdata$(EXEEXT_FOR_BUILD) gost_gc512a 43 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
+
 eccdata.stamp: eccdata.c
 	$(MAKE) eccdata$(EXEEXT_FOR_BUILD)
 	echo stamp &gt; eccdata.stamp
@@ -412,6 +421,7 @@ eccdata.stamp: eccdata.c
 ecc-curve25519.$(OBJEXT): ecc-curve25519.h
 ecc-curve448.$(OBJEXT): ecc-curve448.h
 ecc-gost-gc256b.$(OBJEXT): ecc-gost-gc256b.h
+ecc-gost-gc512a.$(OBJEXT): ecc-gost-gc512a.h
 ecc-secp192r1.$(OBJEXT): ecc-secp192r1.h
 ecc-secp224r1.$(OBJEXT): ecc-secp224r1.h
 ecc-secp256r1.$(OBJEXT): ecc-secp256r1.h
@@ -670,7 +680,7 @@ distcheck: dist
 clean-here:
 	-rm -f $(TARGETS) *.$(OBJEXT) *.s *.so *.dll *.a \
 		ecc-curve25519.h ecc-curve448.h \
-		ecc-gost-gc256b.h \
+		ecc-gost-gc256b.h ecc-gost-gc512a.h \
 		ecc-secp192r1.h ecc-secp224r1.h ecc-secp256r1.h \
 		ecc-secp384r1.h ecc-secp521r1.h \
 		aesdata$(EXEEXT_FOR_BUILD) \
diff --git a/ecc-curve.h b/ecc-curve.h
index da07b0232d42..8f050404a944 100644
--- a/ecc-curve.h
+++ b/ecc-curve.h
@@ -44,6 +44,7 @@ extern "C" {
 struct ecc_curve;
 
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_gost_gc256b(void);
+const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_gost_gc512a(void);
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_secp_192r1(void);
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_secp_224r1(void);
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_secp_256r1(void);
diff --git a/ecc-gost-gc512a.c b/ecc-gost-gc512a.c
new file mode 100644
index 000000000000..4baec1f5945d
--- /dev/null
+++ b/ecc-gost-gc512a.c
@@ -0,0 +1,128 @@
+/* ecc-gost-gc512a.c
+
+   Copyright (C) 2016-2020 Dmitry Eremin-Solenikov
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+
+#include "ecc.h"
+#include "ecc-internal.h"
+
+#define USE_REDC 0
+
+#include "ecc-gost-gc512a.h"
+
+static void
+ecc_gc512a_modp (const struct ecc_modulo *m, mp_limb_t *rp)
+{
+  mp_size_t mn = m-&gt;size;
+  mp_limb_t hi;
+
+  hi = mpn_addmul_1(rp, rp + mn, mn, 0x239);
+  hi = sec_add_1 (rp, rp, mn, hi * 0x239);
+  hi = sec_add_1 (rp, rp, mn, hi * 0x239);
+  assert(hi == 0);
+}
+
+#define ecc_gc512a_modp ecc_gc512a_modp
+#define ecc_gc512a_modq ecc_mod
+
+const struct ecc_curve _nettle_gost_gc512a =
+{
+  {
+    512,
+    ECC_LIMB_SIZE,
+    ECC_BMODP_SIZE,
+    ECC_REDC_SIZE,
+    ECC_MOD_INV_ITCH (ECC_LIMB_SIZE),
+    0,
+
+    ecc_p,
+    ecc_Bmodp,
+    ecc_Bmodp_shifted,
+    ecc_redc_ppm1,
+
+    ecc_pp1h,
+    ecc_gc512a_modp,
+    ecc_gc512a_modp,
+    ecc_mod_inv,
+    NULL,
+  },
+  {
+    512,
+    ECC_LIMB_SIZE,
+    ECC_BMODQ_SIZE,
+    0,
+    ECC_MOD_INV_ITCH (ECC_LIMB_SIZE),
+    0,
+
+    ecc_q,
+    ecc_Bmodq,
+    ecc_Bmodq_shifted,
+    NULL,
+    ecc_qp1h,
+
+    ecc_gc512a_modq,
+    ecc_gc512a_modq,
+    ecc_mod_inv,
+    NULL,
+  },
+
+  USE_REDC,
+  ECC_PIPPENGER_K,
+  ECC_PIPPENGER_C,
+
+  ECC_ADD_JJA_ITCH (ECC_LIMB_SIZE),
+  ECC_ADD_JJJ_ITCH (ECC_LIMB_SIZE),
+  ECC_DUP_JJ_ITCH (ECC_LIMB_SIZE),
+  ECC_MUL_A_ITCH (ECC_LIMB_SIZE),
+  ECC_MUL_G_ITCH (ECC_LIMB_SIZE),
+  ECC_J_TO_A_ITCH (ECC_LIMB_SIZE),
+
+  ecc_add_jja,
+  ecc_add_jjj,
+  ecc_dup_jj,
+  ecc_mul_a,
+  ecc_mul_g,
+  ecc_j_to_a,
+
+  ecc_b,
+  ecc_g,
+  ecc_unit,
+  ecc_table
+};
+
+const struct ecc_curve *nettle_get_gost_gc512a(void)
+{
+  return &amp;_nettle_gost_gc512a;
+}
diff --git a/ecc-internal.h b/ecc-internal.h
index 53305bc08404..cef1366545e0 100644
--- a/ecc-internal.h
+++ b/ecc-internal.h
@@ -93,6 +93,7 @@ extern const struct ecc_curve _nettle_curve448;
 
 /* GOST curves, visible with underscore prefix for now */
 extern const struct ecc_curve _nettle_gost_gc256b;
+extern const struct ecc_curve _nettle_gost_gc512a;
 
 #define ECC_MAX_SIZE ((521 + GMP_NUMB_BITS - 1) / GMP_NUMB_BITS)
 
diff --git a/eccdata.c b/eccdata.c
index fd27d56aebdf..06b6937aebc5 100644
--- a/eccdata.c
+++ b/eccdata.c
@@ -705,6 +705,44 @@ ecc_curve_init (struct ecc_curve *ecc, const char *curve)
 		   "f7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e4b7",
 		   "83ccf17ba6706d73625cc3534c7a2b9d6ec1ee6a9a7e07c10d84b388de59f741");
 
+    }
+  else if (!strcmp (curve, "gost_gc512a"))
+    {
+      ecc_curve_init_str (ecc, ECC_TYPE_WEIERSTRASS,
+			  "ffffffffffffffffffffffffffffffff"
+			  "ffffffffffffffffffffffffffffffff"
+			  "ffffffffffffffffffffffffffffffff"
+			  "fffffffffffffffffffffffffffffdc7",
+			  "e8c2505dedfc86ddc1bd0b2b6667f1da"
+			  "34b82574761cb0e879bd081cfd0b6265"
+			  "ee3cb090f30d27614cb4574010da90dd"
+			  "862ef9d4ebee4761503190785a71c760",
+			  "ffffffffffffffffffffffffffffffff"
+			  "ffffffffffffffffffffffffffffffff"
+			  "27e69532f48d89116ff22b8d4e056060"
+			  "9b4b38abfad2b85dcacdb1411f10b275",
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000003",
+			  "7503cfe87a836ae3a61b8816e25450e6"
+			  "ce5e1c93acf1abc1778064fdcbefa921"
+			  "df1626be4fd036e93d75e6a50e3a41e9"
+			  "8028fe5fc235f5b889a589cb5215f2a4");
+
+      ecc-&gt;ref = ecc_alloc (3);
+      ecc_set_str (&amp;ecc-&gt;ref[0], /* 2 g */
+		   "3b89dcfc622996ab97a5869dbff15cf51db00954f43a58a5e5f6b0470a132b2f4434bbcd405d2a9516151d2a6a04f2e4375bf48de1fdb21fb982afd9d2ea137c",
 +		   "c813c4e2e2e0a8a391774c7903da7a6f14686e98e183e670ee6fb784809a3e92ca209dc631d85b1c7534ed3b37fddf64d854d7e01f91f18bb3fd307591afc051");
 +
+      ecc_set_str (&amp;ecc-&gt;ref[1], /* 3 g */
+		   "a1ff1ab2712a267eb53935ddb5a567f84db156cc096168a1174291d5f488fba543d2840b4d2dd35d764b2f57b308907aec55cfba10544e8416e134687ccb87c3",
 +		   "3cb5c4417ec4637f30374f189bb5b984c41e3a48d7f84fbfa3819e3f333f7eb311d3af7e67c4c16eeacfac2fe94c6dd4c6366f711a4fb6c7125cd7ec518d90d6");
 +
+      ecc_set_str (&amp;ecc-&gt;ref[2], /* 4 g */
+		   "b7bfb80956c8670031ba191929f64e301d681634236d47a60e571a4bedc0ef257452ef78b5b98dbb3d9f3129d9349433ce2a3a35cb519c91e2d633d7b373ae16",
 +		   "3bee95e29eecc5d5ad2beba941abcbf9f1cad478df0fecf614f63aeebef77850da7efdb93de8f3df80bc25eac09239c14175f5c29704ce9a3e383f1b3ec0e929");
 +
     }
   else if (!strcmp (curve, "curve448"))
     {
diff --git a/examples/ecc-benchmark.c b/examples/ecc-benchmark.c
index 42035ca0fc8d..a529cf16ab3a 100644
--- a/examples/ecc-benchmark.c
+++ b/examples/ecc-benchmark.c
@@ -315,6 +315,7 @@ const struct ecc_curve * const curves[] = {
   &amp;_nettle_curve448,
   &amp;_nettle_secp_521r1,
   &amp;_nettle_gost_gc256b,
+  &amp;_nettle_gost_gc512a,
 };
 
 #define numberof(x)  (sizeof (x) / sizeof ((x)[0]))
diff --git a/testsuite/testutils.c b/testsuite/testutils.c
index 086bcbc860c7..61d52d92fc04 100644
--- a/testsuite/testutils.c
+++ b/testsuite/testutils.c
@@ -1678,6 +1678,7 @@ const struct ecc_curve * const ecc_curves[] = {
   &amp;_nettle_curve25519,
   &amp;_nettle_curve448,
   &amp;_nettle_gost_gc256b,
+  &amp;_nettle_gost_gc512a,
   NULL
 };
 
@@ -1729,7 +1730,7 @@ void
 test_ecc_mul_a (unsigned curve, unsigned n, const mp_limb_t *p)
 {
   /* For each curve, the points 2 g, 3 g and 4 g */
-  static const struct ecc_ref_point ref[8][3] = {
+  static const struct ecc_ref_point ref[9][3] = {
     { { "dafebf5828783f2ad35534631588a3f629a70fb16982a888",
 	"dd6bda0d993da0fa46b27bbc141b868f59331afa5c7e93ab" },
       { "76e32a2557599e6edcd283201fb2b9aadfd0d359cbb263da",
@@ -1804,9 +1805,22 @@ test_ecc_mul_a (unsigned curve, unsigned n, const mp_limb_t \
*p)  "76bcd1ca9a23b041d4d9baf507a6cd821267a94c838768e8486117796b788a51" },
       { "f7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e4b7",
 	"83ccf17ba6706d73625cc3534c7a2b9d6ec1ee6a9a7e07c10d84b388de59f741" },
+    },
+    { { "3b89dcfc622996ab97a5869dbff15cf51db00954f43a58a5e5f6b0470a132b2f"
+	"4434bbcd405d2a9516151d2a6a04f2e4375bf48de1fdb21fb982afd9d2ea137c",
+	"c813c4e2e2e0a8a391774c7903da7a6f14686e98e183e670ee6fb784809a3e92"
+	"ca209dc631d85b1c7534ed3b37fddf64d854d7e01f91f18bb3fd307591afc051" },
+      { "a1ff1ab2712a267eb53935ddb5a567f84db156cc096168a1174291d5f488fba5"
+	"43d2840b4d2dd35d764b2f57b308907aec55cfba10544e8416e134687ccb87c3",
+	"3cb5c4417ec4637f30374f189bb5b984c41e3a48d7f84fbfa3819e3f333f7eb3"
+	"11d3af7e67c4c16eeacfac2fe94c6dd4c6366f711a4fb6c7125cd7ec518d90d6" },
+      { "b7bfb80956c8670031ba191929f64e301d681634236d47a60e571a4bedc0ef25"
+	"7452ef78b5b98dbb3d9f3129d9349433ce2a3a35cb519c91e2d633d7b373ae16",
+	"3bee95e29eecc5d5ad2beba941abcbf9f1cad478df0fecf614f63aeebef77850"
+	"da7efdb93de8f3df80bc25eac09239c14175f5c29704ce9a3e383f1b3ec0e929" },
     }
   };
-  assert (curve &lt; 8);
+  assert (curve &lt; 9);
   assert (n &lt;= 4);
   if (n == 0)
     {
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200115223611</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-01-15 22:36:11-0400</timestampReceived><subject>[PATCH v4 4/4] Add documentation for GOSTDSA and GOST curves.</subject><body>

From: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 nettle.texinfo | 65 +++++++++++++++++++++++++++++++++++++++++++++++++-
 1 file changed, 64 insertions(+), 1 deletion(-)

diff --git a/nettle.texinfo b/nettle.texinfo
index 65b36e315f81..38c84410c103 100644
--- a/nettle.texinfo
+++ b/nettle.texinfo
@@ -115,6 +115,7 @@ Public-key algorithms
 
 * Side-channel silence::
 * ECDSA::
+* GOSTDSA::
 * Curve 25519 and Curve 448::
 
 @end detailmenu
@@ -4916,6 +4917,7 @@ curve'' is used as a shorthand for the bitsize of the curve's \
prime  @menu
 * Side-channel silence::
 * ECDSA::
+* GOSTDSA::
 * Curve 25519 and Curve 448::
 @end menu
 
@@ -4950,7 +4952,7 @@ accesses depend only on the size of the input data and its \
location in  memory, not on the actual data bits. This implies a performance penalty
 in several of the building blocks.
 
-@node ECDSA, Curve 25519 and Curve 448, Side-channel silence, Elliptic curves
+@node ECDSA, GOSTDSA, Side-channel silence, Elliptic curves
 @comment  node-name,  next,  previous,  up
 @subsubsection ECDSA
 
@@ -5054,6 +5056,67 @@ random octets and store them at @code{dst}. For advice, see
 @xref{Randomness}.
 @end deftypefun
 
+@node GOSTDSA, Curve 25519 and Curve 448, ECDSA, Elliptic curves
+@comment  node-name,  next,  previous,  up
+@subsubsection GOSTDSA
+
+GOSTDSA (GOST R 34.10-2001, GOST R 34.10-2012) is a variant of the DSA
+(@pxref{DSA}) and ECDSA (@pxref{ECDSA}) digital signature schemes, which works
+over an elliptic curve group. Original documents are written in Russian.
+English translations are provided in @cite{RFC 5832} and @cite{RFC 7091}.
+While technically nothing stops one from using GOSTDSA over any curve, it
+is defined only over several 256 and 512-bit curves.  Like DSA and ECDSA,
+creating a signature requires a unique random nonce (repeating the nonce
+with two different messages reveals the private key, and any leak or bias
+in the generation of the nonce also leaks information about the key).
+
+GOST R 34.10-2001 was defined to use GOST R 34.11-94 hash function
+(GOSTHASH94 and GOSTHASH94CP, @cite{RFC 5831}).  GOST R 34.10-2012 is
+defined to use GOST R 34.11-2012 hash function (Streebog, @cite{RFC
+6986}) of corresponding size (256 or 512) depending on curve size.
+
+Nettle defines GOSTDSA in @file{&lt;nettle/gostdsa.h&gt;}. GOSTDSA reuses ECDSA
+data types (@code{struct ecc_point}, @code{struct ecc_scalar}) to
+represent public and private keys.  Also to generate a new GOSTDSA key
+pair one has to use @code{ecdsa_generate_keypair()} function.
+
+To create and verify GOSTDSA signatures, the following functions are used.
+
+@deftypefun void gostdsa_sign (const struct ecc_scalar *@var{key}, void \
*@var{random_ctx}, nettle_random_func *@var{random}, size_t @var{digest_length}, \
const uint8_t *@var{digest}, struct dsa_signature *@var{signature}) +Uses the private \
key @var{key} to create a signature on @var{digest}. +@var{random_ctx} and \
@var{random} is a randomness generator. +@code{random(random_ctx, length, dst)} \
should generate @code{length} +random octets and store them at @code{dst}. The \
signature is stored in +@var{signature}, in the same was as for plain DSA.
+@end deftypefun
+
+@deftypefun int gostdsa_verify (const struct ecc_point *@var{pub}, size_t \
@var{length}, const uint8_t *@var{digest}, const struct dsa_signature \
*@var{signature}) +Uses the public key @var{pub} to verify that @var{signature} is a \
valid +signature for the message digest @var{digest} (of @var{length} octets).
+Returns 1 if the signature is valid, otherwise 0.
+@end deftypefun
+
+For historical reason several curve IDs (OIDs) may correspond to a single
+curve/generator combination. Following list defines correspondence
+between nettle's view on curves and actual identifiers defined in @cite{RFC
+4357} and @cite{RFC 7836}.
+
+@deftypefun {const struct ecc_curve} nettle_get_gost_gc256b(void)
+Returns curve corresponding to following identifiers:
+@itemize
+@item id-GostR3410-2001-CryptoPro-A-ParamSet (@cite{RFC 4357})
+@item id-GostR3410-2001-CryptoPro-XchA-ParamSet (@cite{RFC 4357})
+@item id-tc26-gost-3410-12-256-paramSetB
+@end itemize
+@end deftypefun
+
+@deftypefun {const struct ecc_curve} nettle_get_gost_gc512a(void)
+Returns curve corresponding to following identifiers:
+@itemize
+@item id-tc26-gost-3410-12-512-paramSetA (@cite{RFC 7836})
+@end itemize
+@end deftypefun
+
 @node Curve 25519 and Curve 448, , ECDSA, Elliptic curves
 @comment  node-name,  next,  previous,  up
 @subsubsection Curve25519 and Curve448
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200116215235</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-01-16 21:52:35-0400</timestampReceived><subject>[PATCH v5 1/3] Add GOST DSA according to GOST R 34.10-2001/-2012</subject><body>

From: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;

Add GOST Digital Signature Algorithms support according to GOST R
34.10-2001/-2012. English translations of these standards are provided
as RFC 5832 and RFC 7091.

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 Makefile.in                     |   4 +-
 ecc-gostdsa-sign.c              | 101 +++++++++++++++++++++
 ecc-gostdsa-verify.c            | 130 +++++++++++++++++++++++++++
 ecc-hash.c                      |  11 +++
 ecc-internal.h                  |   7 ++
 gostdsa-sign.c                  |  74 +++++++++++++++
 gostdsa-verify.c                |  78 ++++++++++++++++
 gostdsa.h                       | 100 +++++++++++++++++++++
 testsuite/.gitignore            |   3 +
 testsuite/.test-rules.make      |   9 ++
 testsuite/Makefile.in           |   4 +-
 testsuite/gostdsa-keygen-test.c | 155 ++++++++++++++++++++++++++++++++
 testsuite/gostdsa-sign-test.c   |  88 ++++++++++++++++++
 testsuite/gostdsa-verify-test.c | 111 +++++++++++++++++++++++
 14 files changed, 873 insertions(+), 2 deletions(-)
 create mode 100644 ecc-gostdsa-sign.c
 create mode 100644 ecc-gostdsa-verify.c
 create mode 100644 gostdsa-sign.c
 create mode 100644 gostdsa-verify.c
 create mode 100644 gostdsa.h
 create mode 100644 testsuite/gostdsa-keygen-test.c
 create mode 100644 testsuite/gostdsa-sign-test.c
 create mode 100644 testsuite/gostdsa-verify-test.c

diff --git a/Makefile.in b/Makefile.in
index eb1c6c335c39..f876e5e82197 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -189,6 +189,8 @@ hogweed_SOURCES = sexp.c sexp-format.c \
 		  ecc-point.c ecc-scalar.c ecc-point-mul.c ecc-point-mul-g.c \
 		  ecc-ecdsa-sign.c ecdsa-sign.c \
 		  ecc-ecdsa-verify.c ecdsa-verify.c ecdsa-keygen.c \
+		  ecc-gostdsa-sign.c gostdsa-sign.c \
+		  ecc-gostdsa-verify.c gostdsa-verify.c \
 		  curve25519-mul-g.c curve25519-mul.c curve25519-eh-to-x.c \
 		  curve448-mul-g.c curve448-mul.c curve448-eh-to-x.c \
 		  eddsa-compress.c eddsa-decompress.c eddsa-expand.c \
@@ -205,7 +207,7 @@ HEADERS = aes.h arcfour.h arctwo.h asn1.h blowfish.h \
 	  cbc.h ccm.h cfb.h chacha.h chacha-poly1305.h ctr.h \
 	  curve25519.h curve448.h des.h dsa.h dsa-compat.h eax.h \
 	  ecc-curve.h ecc.h ecdsa.h eddsa.h \
-	  gcm.h gost28147.h gosthash94.h hmac.h \
+	  gcm.h gost28147.h gostdsa.h gosthash94.h hmac.h \
 	  knuth-lfib.h hkdf.h \
 	  macros.h \
 	  cmac.h siv-cmac.h \
diff --git a/ecc-gostdsa-sign.c b/ecc-gostdsa-sign.c
new file mode 100644
index 000000000000..00eeef81f659
--- /dev/null
+++ b/ecc-gostdsa-sign.c
@@ -0,0 +1,101 @@
+/* ecc-gostdsa-sign.c
+
+   Copyright (C) 2015 Dmitry Eremin-Solenikov
+   Copyright (C) 2013, 2014 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;stdlib.h&gt;
+
+#include "gostdsa.h"
+#include "ecc-internal.h"
+
+/* Low-level GOST DSA signing */
+
+mp_size_t
+ecc_gostdsa_sign_itch (const struct ecc_curve *ecc)
+{
+  /* Needs 3*ecc-&gt;p.size + scratch for ecc-&gt;mul_g. Currently same for
+     ecc_mul_g and ecc_mul_g_eh. */
+  return ECC_GOSTDSA_SIGN_ITCH (ecc-&gt;p.size);
+}
+
+/* NOTE: Caller should check if r or s is zero. */
+void
+ecc_gostdsa_sign (const struct ecc_curve *ecc,
+		const mp_limb_t *zp,
+		const mp_limb_t *kp,
+		size_t length, const uint8_t *digest,
+		mp_limb_t *rp, mp_limb_t *sp,
+		mp_limb_t *scratch)
+{
+#define P	    scratch
+#define hp	    (scratch + 4*ecc-&gt;p.size)
+#define tp	    (scratch + 2*ecc-&gt;p.size)
+#define t2p	    scratch
+  /* Procedure, according to GOST 34.10. q denotes the group
+     order.
+
+     1. k &lt;-- uniformly random, 0 &lt; k &lt; q
+
+     2. C &lt;-- (c_x, c_y) = k g
+
+     3. r &lt;-- c_x mod q
+
+     4. s &lt;-- (r*z + k*h) mod q.
+  */
+
+  ecc-&gt;mul_g (ecc, P, kp, P + 3*ecc-&gt;p.size);
+  /* x coordinate only, modulo q */
+  ecc-&gt;h_to_a (ecc, 2, rp, P, P + 3*ecc-&gt;p.size);
+
+  /* Process hash digest */
+  gost_hash (&amp;ecc-&gt;q, hp, length, digest);
+  if (mpn_zero_p (hp, ecc-&gt;p.size))
+    mpn_add_1 (hp, hp, ecc-&gt;p.size, 1);
+
+  ecc_modq_mul (ecc, tp, rp, zp);
+  ecc_modq_mul (ecc, t2p, kp, hp);
+  ecc_modq_add (ecc, sp, tp, t2p);
+
+  /* Also reduce mod ecc-&gt;q. It should already be &lt; 2*ecc-&gt;q,
+   * so one subtraction should suffice. */
+
+  *scratch = mpn_sub_n (tp, sp, ecc-&gt;q.m, ecc-&gt;p.size);
+  cnd_copy (*scratch == 0, sp, tp, ecc-&gt;p.size);
+
+#undef P
+#undef hp
+#undef tp
+#undef t2p
+}
diff --git a/ecc-gostdsa-verify.c b/ecc-gostdsa-verify.c
new file mode 100644
index 000000000000..4358132b2bf6
--- /dev/null
+++ b/ecc-gostdsa-verify.c
@@ -0,0 +1,130 @@
+/* ecc-gostdsa-verify.c
+
+   Copyright (C) 2015 Dmitry Eremin-Solenikov
+   Copyright (C) 2013, 2014 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;stdlib.h&gt;
+
+#include "gostdsa.h"
+#include "ecc-internal.h"
+
+/* Low-level GOST DSA verify */
+
+static int
+ecdsa_in_range (const struct ecc_curve *ecc, const mp_limb_t *xp)
+{
+  return !mpn_zero_p (xp, ecc-&gt;p.size)
+    &amp;&amp; mpn_cmp (xp, ecc-&gt;q.m, ecc-&gt;p.size) &lt; 0;
+}
+
+mp_size_t
+ecc_gostdsa_verify_itch (const struct ecc_curve *ecc)
+{
+  /* Largest storage need is for the ecc-&gt;mul call. */
+  return 5*ecc-&gt;p.size + ecc-&gt;mul_itch;
+}
+
+/* FIXME: Use faster primitives, not requiring side-channel silence. */
+int
+ecc_gostdsa_verify (const struct ecc_curve *ecc,
+		  const mp_limb_t *pp, /* Public key */
+		  size_t length, const uint8_t *digest,
+		  const mp_limb_t *rp, const mp_limb_t *sp,
+		  mp_limb_t *scratch)
+{
+  /* Procedure, according to GOST R 34.10. q denotes the group
+     order.
+
+     1. Check 0 &lt; r, s &lt; q.
+
+     2. v &lt;-- h^{-1}  (mod q)
+
+     3. z1  &lt;-- s * v (mod q)
+
+     4. z2  &lt;-- -r * v (mod q)
+
+     5. R = u1 G + u2 Y
+
+     6. Signature is valid if R_x = r (mod q).
+  */
+
+#define hp (scratch)
+#define vp (scratch + ecc-&gt;p.size)
+#define z1 (scratch + 3*ecc-&gt;p.size)
+#define z2 (scratch + 4*ecc-&gt;p.size)
+
+#define P1 (scratch + 4*ecc-&gt;p.size)
+#define P2 (scratch)
+
+
+  if (! (ecdsa_in_range (ecc, rp)
+	 &amp;&amp; ecdsa_in_range (ecc, sp)))
+    return 0;
+
+  gost_hash (&amp;ecc-&gt;q, hp, length, digest);
+
+  if (mpn_zero_p (hp, ecc-&gt;p.size))
+    mpn_add_1 (hp, hp, ecc-&gt;p.size, 1);
+
+  /* Compute v */
+  ecc-&gt;q.invert (&amp;ecc-&gt;q, vp, hp, vp + 2*ecc-&gt;p.size);
+
+  /* z1 = s / h, P1 = z1 * G */
+  ecc_modq_mul (ecc, z1, sp, vp);
+
+  /* z2 = - r / h, P2 = z2 * Y */
+  ecc_modq_mul (ecc, z2, rp, vp);
+  mpn_sub_n (z2, ecc-&gt;q.m, z2, ecc-&gt;p.size);
+
+   /* Total storage: 5*ecc-&gt;p.size + ecc-&gt;mul_itch */
+  ecc-&gt;mul (ecc, P2, z2, pp, z2 + ecc-&gt;p.size);
+
+  /* Total storage: 7*ecc-&gt;p.size + ecc-&gt;mul_g_itch (ecc-&gt;p.size) */
+  ecc-&gt;mul_g (ecc, P1, z1, P1 + 3*ecc-&gt;p.size);
+
+  /* Total storage: 6*ecc-&gt;p.size + ecc-&gt;add_hhh_itch */
+  ecc-&gt;add_hhh (ecc, P1, P1, P2, P1 + 3*ecc-&gt;p.size);
+
+  /* x coordinate only, modulo q */
+  ecc-&gt;h_to_a (ecc, 2, P2, P1, P1 + 3*ecc-&gt;p.size);
+
+  return (mpn_cmp (rp, P2, ecc-&gt;p.size) == 0);
+#undef P2
+#undef P1
+#undef z2
+#undef z1
+#undef hp
+#undef vp
+}
diff --git a/ecc-hash.c b/ecc-hash.c
index 4e830a514ac4..07877110263f 100644
--- a/ecc-hash.c
+++ b/ecc-hash.c
@@ -62,3 +62,14 @@ ecc_hash (const struct ecc_modulo *m,
     /* We got a few extra bits, at the low end. Discard them. */
     mpn_rshift (hp, hp, m-&gt;size + 1, 8*length - m-&gt;bit_size);
 }
+
+void
+gost_hash (const struct ecc_modulo *m,
+	   mp_limb_t *hp,
+	   size_t length, const uint8_t *digest)
+{
+  if (length &gt; ((size_t) m-&gt;bit_size + 7) / 8)
+    length = (m-&gt;bit_size + 7) / 8;
+
+  mpn_set_base256_le (hp, m-&gt;size + 1, digest, length);
+}
diff --git a/ecc-internal.h b/ecc-internal.h
index cef1366545e0..0022e0ab6cc2 100644
--- a/ecc-internal.h
+++ b/ecc-internal.h
@@ -53,6 +53,7 @@
 #define ecc_mod _nettle_ecc_mod
 #define ecc_mod_inv _nettle_ecc_mod_inv
 #define ecc_hash _nettle_ecc_hash
+#define gost_hash _nettle_gost_hash
 #define ecc_a_to_j _nettle_ecc_a_to_j
 #define ecc_j_to_a _nettle_ecc_j_to_a
 #define ecc_eh_to_a _nettle_ecc_eh_to_a
@@ -288,6 +289,11 @@ ecc_hash (const struct ecc_modulo *m,
 	  mp_limb_t *hp,
 	  size_t length, const uint8_t *digest);
 
+void
+gost_hash (const struct ecc_modulo *m,
+	  mp_limb_t *hp,
+	  size_t length, const uint8_t *digest);
+
 /* Converts a point P in affine coordinates into a point R in jacobian
    coordinates. */
 void
@@ -456,6 +462,7 @@ curve448_eh_to_x (mp_limb_t *xp, const mp_limb_t *p,
 #endif
 #define ECC_MUL_M_ITCH(size) (11*(size))
 #define ECC_ECDSA_SIGN_ITCH(size) (12*(size))
+#define ECC_GOSTDSA_SIGN_ITCH(size) (12*(size))
 #define ECC_MOD_RANDOM_ITCH(size) (size)
 #define ECC_HASH_ITCH(size) (1+(size))
 
diff --git a/gostdsa-sign.c b/gostdsa-sign.c
new file mode 100644
index 000000000000..892c0742c898
--- /dev/null
+++ b/gostdsa-sign.c
@@ -0,0 +1,74 @@
+/* gostdsa-sign.c
+
+   Copyright (C) 2015 Dmitry Eremin-Solenikov
+   Copyright (C) 2013 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;stdlib.h&gt;
+
+#include "gostdsa.h"
+#include "ecc-internal.h"
+#include "nettle-internal.h"
+
+void
+gostdsa_sign (const struct ecc_scalar *key,
+	    void *random_ctx, nettle_random_func *random,
+	    size_t digest_length,
+	    const uint8_t *digest,
+	    struct dsa_signature *signature)
+{
+  /* At most 936 bytes. */
+  TMP_DECL(k, mp_limb_t, ECC_MAX_SIZE + ECC_GOSTDSA_SIGN_ITCH (ECC_MAX_SIZE));
+  mp_limb_t size = key-&gt;ecc-&gt;p.size;
+  mp_limb_t *rp = mpz_limbs_write (signature-&gt;r, size);
+  mp_limb_t *sp = mpz_limbs_write (signature-&gt;s, size);
+
+  TMP_ALLOC (k, size + ECC_GOSTDSA_SIGN_ITCH (size));
+
+  /* Timing reveals the number of rounds through this loop, but the
+     timing is still independent of the secret k finally used. */
+  do
+    {
+      do
+        {
+          ecc_mod_random (&amp;key-&gt;ecc-&gt;q, k, random_ctx, random, k + size);
+	}
+      while (mpn_zero_p(k, size));
+      ecc_gostdsa_sign (key-&gt;ecc, key-&gt;p, k, digest_length, digest,
+		   rp, sp, k + size);
+      mpz_limbs_finish (signature-&gt;r, size);
+      mpz_limbs_finish (signature-&gt;s, size);
+    }
+  while (mpz_sgn (signature-&gt;r) == 0 || mpz_sgn (signature-&gt;s) == 0);
+}
diff --git a/gostdsa-verify.c b/gostdsa-verify.c
new file mode 100644
index 000000000000..7dc1bec1ef62
--- /dev/null
+++ b/gostdsa-verify.c
@@ -0,0 +1,78 @@
+/* gostdsa-verify.c
+
+   Copyright (C) 2015 Dmitry Eremin-Solenikov
+   Copyright (C) 2013 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+#include &lt;stdlib.h&gt;
+
+#include "gostdsa.h"
+
+#include "gmp-glue.h"
+
+int
+gostdsa_verify (const struct ecc_point *pub,
+	      size_t length, const uint8_t *digest,
+	      const struct dsa_signature *signature)
+{
+  mp_limb_t size = ecc_size (pub-&gt;ecc);
+  mp_size_t itch = 2*size + ecc_gostdsa_verify_itch (pub-&gt;ecc);
+  /* For ECC_MUL_A_WBITS == 0, at most 1512 bytes. With
+     ECC_MUL_A_WBITS == 4, currently needs 67 * ecc-&gt;size, at most
+     4824 bytes. Don't use stack allocation for this. */
+  mp_limb_t *scratch;
+  int res;
+
+#define rp scratch
+#define sp (scratch + size)
+#define scratch_out (scratch + 2*size)
+
+  if (mpz_sgn (signature-&gt;r) &lt;= 0 || mpz_size (signature-&gt;r) &gt; size
+      || mpz_sgn (signature-&gt;s) &lt;= 0 || mpz_size (signature-&gt;s) &gt; size)
+    return 0;
+
+  scratch = gmp_alloc_limbs (itch);
+
+  mpz_limbs_copy (rp, signature-&gt;r, size);
+  mpz_limbs_copy (sp, signature-&gt;s, size);
+
+  res = ecc_gostdsa_verify (pub-&gt;ecc, pub-&gt;p, length, digest, rp, sp, scratch_out);
+
+  gmp_free_limbs (scratch, itch);
+
+  return res;
+#undef rp
+#undef sp
+#undef scratch_out
+}
diff --git a/gostdsa.h b/gostdsa.h
new file mode 100644
index 000000000000..c92dfd1e1dd6
--- /dev/null
+++ b/gostdsa.h
@@ -0,0 +1,100 @@
+/* gostdsa.h
+
+   Copyright (C) 2015 Dmity Eremin-Solenikov
+   Copyright (C) 2013 Niels Möller
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#ifndef NETTLE_GOSTDSA_H_INCLUDED
+#define NETTLE_GOSTDSA_H_INCLUDED
+
+#include "ecc.h"
+#include "dsa.h"
+#include "ecdsa.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/* Name mangling */
+#define gostdsa_sign nettle_gostdsa_sign
+#define gostdsa_verify nettle_gostdsa_verify
+#define ecc_gostdsa_sign nettle_ecc_gostdsa_sign
+#define ecc_gostdsa_sign_itch nettle_ecc_gostdsa_sign_itch
+#define ecc_gostdsa_verify nettle_ecc_gostdsa_verify
+#define ecc_gostdsa_verify_itch nettle_ecc_gostdsa_verify_itch
+
+/* Just use ECDSA function for key generation */
+#define gostdsa_generate_keypair ecdsa_generate_keypair
+
+/* High level GOST DSA functions.
+ *
+ * A public key is represented as a struct ecc_point, and a private
+ * key as a struct ecc_scalar. FIXME: Introduce some aliases? */
+void
+gostdsa_sign (const struct ecc_scalar *key,
+	      void *random_ctx, nettle_random_func *random,
+	      size_t digest_length,
+	      const uint8_t *digest,
+	      struct dsa_signature *signature);
+
+int
+gostdsa_verify (const struct ecc_point *pub,
+	        size_t length, const uint8_t *digest,
+	        const struct dsa_signature *signature);
+
+/* Low-level GOSTDSA functions. */
+mp_size_t
+ecc_gostdsa_sign_itch (const struct ecc_curve *ecc);
+
+void
+ecc_gostdsa_sign (const struct ecc_curve *ecc,
+		const mp_limb_t *zp,
+		/* Random nonce, must be invertible mod ecc group
+		   order. */
+		const mp_limb_t *kp,
+		size_t length, const uint8_t *digest,
+		mp_limb_t *rp, mp_limb_t *sp,
+		mp_limb_t *scratch);
+
+mp_size_t
+ecc_gostdsa_verify_itch (const struct ecc_curve *ecc);
+
+int
+ecc_gostdsa_verify (const struct ecc_curve *ecc,
+		  const mp_limb_t *pp, /* Public key */
+		  size_t length, const uint8_t *digest,
+		  const mp_limb_t *rp, const mp_limb_t *sp,
+		  mp_limb_t *scratch);
+
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* NETTLE_GOSTDSA_H_INCLUDED */
diff --git a/testsuite/.gitignore b/testsuite/.gitignore
index 1e2a69a60c13..be3a48707580 100644
--- a/testsuite/.gitignore
+++ b/testsuite/.gitignore
@@ -43,6 +43,9 @@
 /eddsa-sign-test
 /eddsa-verify-test
 /gcm-test
+/gostdsa-keygen-test
+/gostdsa-sign-test
+/gostdsa-verify-test
 /gosthash94-test
 /hkdf-test
 /hmac-test
diff --git a/testsuite/.test-rules.make b/testsuite/.test-rules.make
index 6dbef7e24a27..9fd11fd6d126 100644
--- a/testsuite/.test-rules.make
+++ b/testsuite/.test-rules.make
@@ -289,6 +289,15 @@ ed25519-test$(EXEEXT): ed25519-test.$(OBJEXT)
 ed448-test$(EXEEXT): ed448-test.$(OBJEXT)
 	$(LINK) ed448-test.$(OBJEXT) $(TEST_OBJS) -o ed448-test$(EXEEXT)
 
+gostdsa-sign-test$(EXEEXT): gostdsa-sign-test.$(OBJEXT)
+	$(LINK) gostdsa-sign-test.$(OBJEXT) $(TEST_OBJS) -o gostdsa-sign-test$(EXEEXT)
+
+gostdsa-verify-test$(EXEEXT): gostdsa-verify-test.$(OBJEXT)
+	$(LINK) gostdsa-verify-test.$(OBJEXT) $(TEST_OBJS) -o gostdsa-verify-test$(EXEEXT)
+
+gostdsa-keygen-test$(EXEEXT): gostdsa-keygen-test.$(OBJEXT)
+	$(LINK) gostdsa-keygen-test.$(OBJEXT) $(TEST_OBJS) -o gostdsa-keygen-test$(EXEEXT)
+
 sha1-huge-test$(EXEEXT): sha1-huge-test.$(OBJEXT)
 	$(LINK) sha1-huge-test.$(OBJEXT) $(TEST_OBJS) -o sha1-huge-test$(EXEEXT)
 
diff --git a/testsuite/Makefile.in b/testsuite/Makefile.in
index dea6c28d2f20..73a61685dfc1 100644
--- a/testsuite/Makefile.in
+++ b/testsuite/Makefile.in
@@ -53,7 +53,9 @@ TS_HOGWEED_SOURCES = sexp-test.c sexp-format-test.c \
 		     ecdsa-sign-test.c ecdsa-verify-test.c \
 		     ecdsa-keygen-test.c ecdh-test.c \
 		     eddsa-compress-test.c eddsa-sign-test.c \
-		     eddsa-verify-test.c ed25519-test.c ed448-test.c
+		     eddsa-verify-test.c ed25519-test.c ed448-test.c \
+		     gostdsa-sign-test.c gostdsa-verify-test.c \
+		     gostdsa-keygen-test.c
 
 TS_SOURCES = $(TS_NETTLE_SOURCES) $(TS_HOGWEED_SOURCES)
 CXX_SOURCES = cxx-test.cxx
diff --git a/testsuite/gostdsa-keygen-test.c b/testsuite/gostdsa-keygen-test.c
new file mode 100644
index 000000000000..ebeabc860bca
--- /dev/null
+++ b/testsuite/gostdsa-keygen-test.c
@@ -0,0 +1,155 @@
+#include "testutils.h"
+#include "gostdsa.h"
+#include "knuth-lfib.h"
+
+/* Check if y^2 = x^3 - 3x + b */
+static int
+ecc_valid_p (struct ecc_point *pub)
+{
+  mpz_t t, x, y;
+  mpz_t lhs, rhs;
+  int res;
+  mp_size_t size;
+
+  size = pub-&gt;ecc-&gt;p.size;
+
+  /* First check range */
+  if (mpn_cmp (pub-&gt;p, pub-&gt;ecc-&gt;p.m, size) &gt;= 0
+      || mpn_cmp (pub-&gt;p + size, pub-&gt;ecc-&gt;p.m, size) &gt;= 0)
+    return 0;
+
+  mpz_init (lhs);
+  mpz_init (rhs);
+
+  mpz_roinit_n (x, pub-&gt;p, size);
+  mpz_roinit_n (y, pub-&gt;p + size, size);
+
+  mpz_mul (lhs, y, y);
+
+  if (pub-&gt;ecc-&gt;p.bit_size == 255)
+    {
+      /* Check that
+	 121666 (1 + x^2 - y^2) = 121665 x^2 y^2 */
+      mpz_t x2;
+      mpz_init (x2);
+      mpz_mul (x2, x, x); /* x^2 */
+      mpz_mul (rhs, x2, lhs); /* x^2 y^2 */
+      mpz_sub (lhs, x2, lhs); /* x^2 - y^2 */
+      mpz_add_ui (lhs, lhs, 1); /* 1 + x^2 - y^2 */
+      mpz_mul_ui (lhs, lhs, 121666);
+      mpz_mul_ui (rhs, rhs, 121665);
+
+      mpz_clear (x2);
+    }
+  else if (pub-&gt;ecc-&gt;p.bit_size == 448)
+    {
+      /* Check that
+	 x^2 + y^2 = 1 - 39081 x^2 y^2 */
+      mpz_t x2, d;
+      mpz_init (x2);
+      mpz_init_set_ui (d, 39081);
+      mpz_mul (x2, x, x); /* x^2 */
+      mpz_mul (d, d, x2); /* 39081 x^2 */
+      mpz_set_ui (rhs, 1);
+      mpz_submul (rhs, d, lhs); /* 1 - 39081 x^2 y^2 */
+      mpz_add (lhs, x2, lhs);	/* x^2 + y^2 */
+
+      mpz_clear (d);
+      mpz_clear (x2);
+    }
+  else
+    {
+      /* Check y^2 = x^3 - 3 x + b */
+      mpz_mul (rhs, x, x);
+      mpz_sub_ui (rhs, rhs, 3);
+      mpz_mul (rhs, rhs, x);
+      mpz_add (rhs, rhs, mpz_roinit_n (t, pub-&gt;ecc-&gt;b, size));
+    }
+  res = mpz_congruent_p (lhs, rhs, mpz_roinit_n (t, pub-&gt;ecc-&gt;p.m, size));
+
+  mpz_clear (lhs);
+  mpz_clear (rhs);
+
+  return res;
+}
+
+void
+test_main (void)
+{
+  unsigned i;
+  struct knuth_lfib_ctx rctx;
+  struct dsa_signature signature;
+
+  struct tstring *digest;
+
+  knuth_lfib_init (&amp;rctx, 4711);
+  dsa_signature_init (&amp;signature);
+
+  digest = SHEX (/* sha256("abc") */
+		 "BA7816BF 8F01CFEA 414140DE 5DAE2223"
+		 "B00361A3 96177A9C B410FF61 F20015AD");
+
+  for (i = 0; ecc_curves[i]; i++)
+    {
+      const struct ecc_curve *ecc = ecc_curves[i];
+      struct ecc_point pub;
+      struct ecc_scalar key;
+
+      if (ecc-&gt;p.bit_size == 255 || ecc-&gt;p.bit_size == 448)
+	/* Exclude curve25519 and curve448, not supported with GOSTDSA. */
+	continue;
+
+      if (verbose)
+	fprintf (stderr, "Curve %d\n", ecc-&gt;p.bit_size);
+
+      ecc_point_init (&amp;pub, ecc);
+      ecc_scalar_init (&amp;key, ecc);
+
+      ecdsa_generate_keypair (&amp;pub, &amp;key,
+			      &amp;rctx,
+			      (nettle_random_func *) knuth_lfib_random);
+
+      if (verbose)
+	{
+	  fprintf (stderr, "Public key:\nx = ");
+	  write_mpn (stderr, 16, pub.p, ecc-&gt;p.size);
+	  fprintf (stderr, "\ny = ");
+	  write_mpn (stderr, 16, pub.p + ecc-&gt;p.size, ecc-&gt;p.size);
+	  fprintf (stderr, "\nPrivate key: ");
+	  write_mpn (stderr, 16, key.p, ecc-&gt;p.size);
+	  fprintf (stderr, "\n");
+	}
+      if (!ecc_valid_p (&amp;pub))
+	die ("gostdsa_generate_keypair produced an invalid point.\n");
+
+      gostdsa_sign (&amp;key,
+		   &amp;rctx, (nettle_random_func *) knuth_lfib_random,
+		   digest-&gt;length, digest-&gt;data,
+		   &amp;signature);
+
+      if (!gostdsa_verify (&amp;pub, digest-&gt;length, digest-&gt;data,
+			   &amp;signature))
+	die ("gostdsa_verify failed.\n");
+
+      digest-&gt;data[3] ^= 17;
+      if (gostdsa_verify (&amp;pub, digest-&gt;length, digest-&gt;data,
+			  &amp;signature))
+	die ("gostdsa_verify  returned success with invalid digest.\n");
+      digest-&gt;data[3] ^= 17;
+
+      mpz_combit (signature.r, 117);
+      if (gostdsa_verify (&amp;pub, digest-&gt;length, digest-&gt;data,
+			  &amp;signature))
+	die ("gostdsa_verify  returned success with invalid signature.r.\n");
+
+      mpz_combit (signature.r, 117);
+      mpz_combit (signature.s, 93);
+      if (gostdsa_verify (&amp;pub, digest-&gt;length, digest-&gt;data,
+			  &amp;signature))
+	die ("gostdsa_verify  returned success with invalid signature.s.\n");
+
+      ecc_point_clear (&amp;pub);
+      ecc_scalar_clear (&amp;key);
+    }
+  dsa_signature_clear (&amp;signature);
+}
diff --git a/testsuite/gostdsa-sign-test.c b/testsuite/gostdsa-sign-test.c
new file mode 100644
index 000000000000..0e2e0420a313
--- /dev/null
+++ b/testsuite/gostdsa-sign-test.c
@@ -0,0 +1,88 @@
+#include "testutils.h"
+#include "gostdsa.h"
+
+static void
+test_gostdsa (const struct ecc_curve *ecc,
+	    /* Private key */
+	    const char *sz,
+	    /* Random nonce */
+	    const char *sk,
+	    /* Hash */
+	    const struct tstring *h,
+	    /* Expected signature */
+	    const char *r, const char *s)
+{
+  struct dsa_signature ref;
+  mpz_t z;
+  mpz_t k;
+  mp_limb_t *rp = xalloc_limbs (ecc-&gt;p.size);
+  mp_limb_t *sp = xalloc_limbs (ecc-&gt;p.size);
+  mp_limb_t *scratch = xalloc_limbs (ecc_gostdsa_sign_itch (ecc));
+
+  dsa_signature_init (&amp;ref);
+
+  mpz_init_set_str (z, sz, 16);
+  mpz_init_set_str (k, sk, 16);
+
+  ecc_gostdsa_sign (ecc, mpz_limbs_read_n (z, ecc-&gt;p.size),
+		  mpz_limbs_read_n (k, ecc-&gt;p.size),
+		  h-&gt;length, h-&gt;data, rp, sp, scratch);
+
+  mpz_set_str (ref.r, r, 16);
+  mpz_set_str (ref.s, s, 16);
+
+  if (mpz_limbs_cmp (ref.r, rp, ecc-&gt;p.size) != 0
+      || mpz_limbs_cmp (ref.s, sp, ecc-&gt;p.size) != 0)
+    {
+      fprintf (stderr, "_gostdsa_sign failed, bit_size = %u\n", ecc-&gt;p.bit_size);
+      fprintf (stderr, "r     = ");
+      write_mpn (stderr, 16, rp, ecc-&gt;p.size);
+      fprintf (stderr, "\ns     = ");
+      write_mpn (stderr, 16, sp, ecc-&gt;p.size);
+      fprintf (stderr, "\nref.r = ");
+      mpz_out_str (stderr, 16, ref.r);
+      fprintf (stderr, "\nref.s = ");
+      mpz_out_str (stderr, 16, ref.s);
+      fprintf (stderr, "\n");
+      abort();
+    }
+
+  free (rp);
+  free (sp);
+  free (scratch);
+
+  dsa_signature_clear (&amp;ref);
+  mpz_clear (k);
+  mpz_clear (z);
+}
+
+void
+test_main (void)
+{
+  test_gostdsa (nettle_get_gost_gc256b(),
+	      "BFCF1D623E5CDD3032A7C6EABB4A923C46E43D640FFEAAF2C3ED39A8FA399924", /* z */
+
+	      "5782C53F110C596F9155D35EBD25A06A89C50391850A8FEFE33B0E270318857C", /* k */
+
+	      SHEX("1C067E20EA6CB183F22EFB0F3C6FD2A4E6A02821CB7A1B17FACD5E1F7AA76F70"), /* h */
+
+	      "E9323A5E88DD87FB7C724383BFFE7CECD4B9FFA2AC33BEEF73A5A1F743404F6B", /* r */
+
+	      "5E5B9B805B01147A8492C4A162643AC615DC777B9174108F3DC276A41F987AF3"); /* s */
+
+  test_gostdsa (nettle_get_gost_gc512a(),
+	      "3FC01CDCD4EC5F972EB482774C41E66DB7F380528DFE9E67992BA05AEE462435"
+	      "757530E641077CE587B976C8EEB48C48FD33FD175F0C7DE6A44E014E6BCB074B", /* z */
+
+	      "72ABB44536656BF1618CE10BF7EADD40582304A51EE4E2A25A0A32CB0E773ABB"
+	      "23B7D8FDD8FA5EEE91B4AE452F2272C86E1E2221215D405F51B5D5015616E1F6", /* k */
+
+	      SHEX("EDC257BED45FDDE4F1457B7F5B19017A8F204184366689D938532CDBAA5CB29A"
+		   "1D369DA57F8B983BE272219BD2C9A4FC57ECF7A77F34EE2E8AA553976A4766C0"), /* h */
+
+	      "891AA75C2A6F3B4DE27E3903F61CBB0F3F85A4E3C62F39A6E4E84A7477679C6E"
+	      "45008DC2774CA2FF64C12C0606FF918CAE3A50115440E9BF2971B627A882A1E8", /* r */
+
+	      "31065479996DDBDEE180AFE22CA3CDC44B45CE4C6C83909D1D3B702922A32441"
+	      "A9E11DCFBEA3D847C06B1A8A38EB1671D6C82FA21B79C99BE2EA809B10DAA5DF"); /* s */
+}
diff --git a/testsuite/gostdsa-verify-test.c b/testsuite/gostdsa-verify-test.c
new file mode 100644
index 000000000000..7279f5f46c5b
--- /dev/null
+++ b/testsuite/gostdsa-verify-test.c
@@ -0,0 +1,111 @@
+#include "testutils.h"
+#include "gostdsa.h"
+
+static void
+test_gostdsa (const struct ecc_curve *ecc,
+	    /* Public key */
+	    const char *xs, const char *ys,
+	    /* Hash */
+	    struct tstring *h,
+	    /* Valid signature */
+	    const char *r, const char *s)
+{
+  struct ecc_point pub;
+  struct dsa_signature signature;
+  mpz_t x, y;
+
+  ecc_point_init (&amp;pub, ecc);
+  dsa_signature_init (&amp;signature);
+
+  mpz_init_set_str (x, xs, 16);
+  mpz_init_set_str (y, ys, 16);
+
+  if (!ecc_point_set (&amp;pub, x, y))
+    die ("ecc_point_set failed.\n");
+
+  mpz_set_str (signature.r, r, 16);
+  mpz_set_str (signature.s, s, 16);
+
+  if (!gostdsa_verify (&amp;pub, h-&gt;length, h-&gt;data, &amp;signature))
+    {
+      fprintf (stderr, "gostdsa_verify failed with valid signature.\n");
+    fail:
+      fprintf (stderr, "bit_size = %u\nx = ", ecc-&gt;p.bit_size);
+      mpz_out_str (stderr, 16, x);
+      fprintf (stderr, "\ny = ");
+      mpz_out_str (stderr, 16, y);
+      fprintf (stderr, "\ndigest ");
+      print_hex (h-&gt;length, h-&gt;data);
+      fprintf (stderr, "r = ");
+      mpz_out_str (stderr, 16, signature.r);
+      fprintf (stderr, "\ns = ");
+      mpz_out_str (stderr, 16, signature.s);
+      fprintf (stderr, "\n");
+      abort();
+    }
+
+  mpz_combit (signature.r, ecc-&gt;p.bit_size / 3);
+  if (gostdsa_verify (&amp;pub, h-&gt;length, h-&gt;data, &amp;signature))
+    {
+      fprintf (stderr, "gostdsa_verify unexpectedly succeeded with invalid signature.\n");
+      goto fail;
+    }
+  mpz_combit (signature.r, ecc-&gt;p.bit_size / 3);
+
+  mpz_combit (signature.s, 4*ecc-&gt;p.bit_size / 5);
+  if (gostdsa_verify (&amp;pub, h-&gt;length, h-&gt;data, &amp;signature))
+    {
+      fprintf (stderr, "gostdsa_verify unexpectedly succeeded with invalid signature.\n");
+      goto fail;
+    }
+  mpz_combit (signature.s, 4*ecc-&gt;p.bit_size / 5);
+
+  h-&gt;data[2*h-&gt;length / 3] ^= 0x40;
+  if (gostdsa_verify (&amp;pub, h-&gt;length, h-&gt;data, &amp;signature))
+    {
+      fprintf (stderr, "gostdsa_verify unexpectedly succeeded with invalid signature.\n");
+      goto fail;
+    }
+  h-&gt;data[2*h-&gt;length / 3] ^= 0x40;
+  if (!gostdsa_verify (&amp;pub, h-&gt;length, h-&gt;data, &amp;signature))
+    {
+      fprintf (stderr, "gostdsa_verify failed, internal testsuite error.\n");
+      goto fail;
+    }
+
+  ecc_point_clear (&amp;pub);
+  dsa_signature_clear (&amp;signature);
+  mpz_clear (x);
+  mpz_clear (y);
+}
+
+void
+test_main (void)
+{
+  test_gostdsa (nettle_get_gost_gc256b(),
+	      "971566CEDA436EE7678F7E07E84EBB7217406C0B4747AA8FD2AB1453C3D0DFBA", /* x */
+
+	      "AD58736965949F8E59830F8DE20FC6C0D177F6AB599874F1E2E24FF71F9CE643", /* y */
+
+	      SHEX("1C067E20EA6CB183F22EFB0F3C6FD2A4E6A02821CB7A1B17FACD5E1F7AA76F70"), /* h */
+
+	      "E9323A5E88DD87FB7C724383BFFE7CECD4B9FFA2AC33BEEF73A5A1F743404F6B", /* r */
+
+	      "5E5B9B805B01147A8492C4A162643AC615DC777B9174108F3DC276A41F987AF3"); /* s */
+
+  test_gostdsa (nettle_get_gost_gc512a(),
+	      "03A36340A95BB5F93D131961B5B1C1B3213DF7FF3B5A30376407E2A65C441BC6"
+	      "D1B34662317083243F007B15A8512B526606D3B172B606DCE86DBD6F82DA3D40", /* x */
+
+	      "DEAD76318012FED79507809C89CC44848743640EAC9A3C847DA9082E050760A1"
+	      "0679F4B707ABC1872640AD20D7441F66C7A8B3BFF1B8E11B4A076F0A86749F73", /* y */
+
+	      SHEX("EDC257BED45FDDE4F1457B7F5B19017A8F204184366689D938532CDBAA5CB29A"
+		   "1D369DA57F8B983BE272219BD2C9A4FC57ECF7A77F34EE2E8AA553976A4766C0"), /* h */
+
+	      "891AA75C2A6F3B4DE27E3903F61CBB0F3F85A4E3C62F39A6E4E84A7477679C6E"
+	      "45008DC2774CA2FF64C12C0606FF918CAE3A50115440E9BF2971B627A882A1E8", /* r */
+
+	      "31065479996DDBDEE180AFE22CA3CDC44B45CE4C6C83909D1D3B702922A32441"
+	      "A9E11DCFBEA3D847C06B1A8A38EB1671D6C82FA21B79C99BE2EA809B10DAA5DF"); /* s */
+}
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200116215236</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-01-16 21:52:36-0400</timestampReceived><subject>[PATCH v5 2/3] Add documentation for GOSTDSA and GOST curves.</subject><body>

From: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 nettle.texinfo | 65 +++++++++++++++++++++++++++++++++++++++++++++++++-
 1 file changed, 64 insertions(+), 1 deletion(-)

diff --git a/nettle.texinfo b/nettle.texinfo
index 65b36e315f81..38c84410c103 100644
--- a/nettle.texinfo
+++ b/nettle.texinfo
@@ -115,6 +115,7 @@ Public-key algorithms
 
 * Side-channel silence::
 * ECDSA::
+* GOSTDSA::
 * Curve 25519 and Curve 448::
 
 @end detailmenu
@@ -4916,6 +4917,7 @@ curve'' is used as a shorthand for the bitsize of the curve's \
prime  @menu
 * Side-channel silence::
 * ECDSA::
+* GOSTDSA::
 * Curve 25519 and Curve 448::
 @end menu
 
@@ -4950,7 +4952,7 @@ accesses depend only on the size of the input data and its \
location in  memory, not on the actual data bits. This implies a performance penalty
 in several of the building blocks.
 
-@node ECDSA, Curve 25519 and Curve 448, Side-channel silence, Elliptic curves
+@node ECDSA, GOSTDSA, Side-channel silence, Elliptic curves
 @comment  node-name,  next,  previous,  up
 @subsubsection ECDSA
 
@@ -5054,6 +5056,67 @@ random octets and store them at @code{dst}. For advice, see
 @xref{Randomness}.
 @end deftypefun
 
+@node GOSTDSA, Curve 25519 and Curve 448, ECDSA, Elliptic curves
+@comment  node-name,  next,  previous,  up
+@subsubsection GOSTDSA
+
+GOSTDSA (GOST R 34.10-2001, GOST R 34.10-2012) is a variant of the DSA
+(@pxref{DSA}) and ECDSA (@pxref{ECDSA}) digital signature schemes, which works
+over an elliptic curve group. Original documents are written in Russian.
+English translations are provided in @cite{RFC 5832} and @cite{RFC 7091}.
+While technically nothing stops one from using GOSTDSA over any curve, it
+is defined only over several 256 and 512-bit curves.  Like DSA and ECDSA,
+creating a signature requires a unique random nonce (repeating the nonce
+with two different messages reveals the private key, and any leak or bias
+in the generation of the nonce also leaks information about the key).
+
+GOST R 34.10-2001 was defined to use GOST R 34.11-94 hash function
+(GOSTHASH94 and GOSTHASH94CP, @cite{RFC 5831}).  GOST R 34.10-2012 is
+defined to use GOST R 34.11-2012 hash function (Streebog, @cite{RFC
+6986}) of corresponding size (256 or 512) depending on curve size.
+
+Nettle defines GOSTDSA in @file{&lt;nettle/gostdsa.h&gt;}. GOSTDSA reuses ECDSA
+data types (@code{struct ecc_point}, @code{struct ecc_scalar}) to
+represent public and private keys.  Also to generate a new GOSTDSA key
+pair one has to use @code{ecdsa_generate_keypair()} function.
+
+To create and verify GOSTDSA signatures, the following functions are used.
+
+@deftypefun void gostdsa_sign (const struct ecc_scalar *@var{key}, void \
*@var{random_ctx}, nettle_random_func *@var{random}, size_t @var{digest_length}, \
const uint8_t *@var{digest}, struct dsa_signature *@var{signature}) +Uses the private \
key @var{key} to create a signature on @var{digest}. +@var{random_ctx} and \
@var{random} is a randomness generator. +@code{random(random_ctx, length, dst)} \
should generate @code{length} +random octets and store them at @code{dst}. The \
signature is stored in +@var{signature}, in the same was as for plain DSA.
+@end deftypefun
+
+@deftypefun int gostdsa_verify (const struct ecc_point *@var{pub}, size_t \
@var{length}, const uint8_t *@var{digest}, const struct dsa_signature \
*@var{signature}) +Uses the public key @var{pub} to verify that @var{signature} is a \
valid +signature for the message digest @var{digest} (of @var{length} octets).
+Returns 1 if the signature is valid, otherwise 0.
+@end deftypefun
+
+For historical reason several curve IDs (OIDs) may correspond to a single
+curve/generator combination. Following list defines correspondence
+between nettle's view on curves and actual identifiers defined in @cite{RFC
+4357} and @cite{RFC 7836}.
+
+@deftypefun {const struct ecc_curve} nettle_get_gost_gc256b(void)
+Returns curve corresponding to following identifiers:
+@itemize
+@item id-GostR3410-2001-CryptoPro-A-ParamSet (@cite{RFC 4357})
+@item id-GostR3410-2001-CryptoPro-XchA-ParamSet (@cite{RFC 4357})
+@item id-tc26-gost-3410-12-256-paramSetB
+@end itemize
+@end deftypefun
+
+@deftypefun {const struct ecc_curve} nettle_get_gost_gc512a(void)
+Returns curve corresponding to following identifiers:
+@itemize
+@item id-tc26-gost-3410-12-512-paramSetA (@cite{RFC 7836})
+@end itemize
+@end deftypefun
+
 @node Curve 25519 and Curve 448, , ECDSA, Elliptic curves
 @comment  node-name,  next,  previous,  up
 @subsubsection Curve25519 and Curve448
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200116215237</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-01-16 21:52:37-0400</timestampReceived><subject>[PATCH v5 3/3] hogweed-benchmark: enable testing of GOST DSA</subject><body>

From: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 examples/hogweed-benchmark.c | 104 +++++++++++++++++++++++++++++++++++
 1 file changed, 104 insertions(+)

diff --git a/examples/hogweed-benchmark.c b/examples/hogweed-benchmark.c
index 11393df04c81..bceed77e55d9 100644
--- a/examples/hogweed-benchmark.c
+++ b/examples/hogweed-benchmark.c
@@ -48,6 +48,7 @@
 #include "dsa.h"
 #include "rsa.h"
 #include "eddsa.h"
+#include "gostdsa.h"
 #include "curve25519.h"
 #include "curve448.h"
 
@@ -591,6 +592,107 @@ bench_eddsa_clear (void *p)
   free (p);
 }
 
+static void *
+bench_gostdsa_init (unsigned size)
+{
+  struct ecdsa_ctx *ctx;
+  const struct ecc_curve *ecc;
+
+  const char *xs;
+  const char *ys;
+  const char *zs;
+  mpz_t x, y, z;
+
+  ctx = xalloc (sizeof(*ctx));
+
+  dsa_signature_init (&amp;ctx-&gt;s);
+  knuth_lfib_init (&amp;ctx-&gt;lfib, 17);
+
+  switch (size)
+    {
+    case 256:
+      ecc = &amp;_nettle_gost_gc256b;
+      xs = "971566ceda436ee7678f7e07e84ebb7217406c0b4747aa8fd2ab1453c3d0dfba";
+      ys = "ad58736965949f8e59830f8de20fc6c0d177f6ab599874f1e2e24ff71f9ce643";
+      zs = "bfcf1d623e5cdd3032a7c6eabb4a923c46e43d640ffeaaf2c3ed39a8fa399924";
+      ctx-&gt;digest = hash_string (&amp;nettle_sha256, "abc");
+      ctx-&gt;digest_size = 32;
+      break;
+
+    case 512:
+      ecc = &amp;_nettle_gost_gc512a;
+      xs = "03A36340A95BB5F93D131961B5B1C1B3213DF7FF3B5A30376407E2A65C441BC6"
+	   "D1B34662317083243F007B15A8512B526606D3B172B606DCE86DBD6F82DA3D40";
+      ys = "DEAD76318012FED79507809C89CC44848743640EAC9A3C847DA9082E050760A1"
+	   "0679F4B707ABC1872640AD20D7441F66C7A8B3BFF1B8E11B4A076F0A86749F73";
+      zs = "3FC01CDCD4EC5F972EB482774C41E66DB7F380528DFE9E67992BA05AEE462435"
+	   "757530E641077CE587B976C8EEB48C48FD33FD175F0C7DE6A44E014E6BCB074B";
+      ctx-&gt;digest = hash_string (&amp;nettle_sha512, "abc");
+      ctx-&gt;digest_size = 64;
+      break;
+
+    default:
+      die ("Internal error.\n");
+    }
+  ecc_point_init (&amp;ctx-&gt;pub, ecc);
+  ecc_scalar_init (&amp;ctx-&gt;key, ecc);
+
+  mpz_init_set_str (x, xs, 16);
+  mpz_init_set_str (y, ys, 16);
+  mpz_init_set_str (z, zs, 16);
+
+  ecc_point_set (&amp;ctx-&gt;pub, x, y);
+  ecc_scalar_set (&amp;ctx-&gt;key, z);
+
+  mpz_clear (x);
+  mpz_clear (y);
+  mpz_clear (z);
+
+  gostdsa_sign (&amp;ctx-&gt;key,
+		&amp;ctx-&gt;lfib, (nettle_random_func *) knuth_lfib_random,
+		ctx-&gt;digest_size, ctx-&gt;digest,
+		&amp;ctx-&gt;s);
+
+  return ctx;
+}
+
+static void
+bench_gostdsa_sign (void *p)
+{
+  struct ecdsa_ctx *ctx = p;
+  struct dsa_signature s;
+
+  dsa_signature_init (&amp;s);
+  gostdsa_sign (&amp;ctx-&gt;key,
+		&amp;ctx-&gt;lfib, (nettle_random_func *) knuth_lfib_random,
+		ctx-&gt;digest_size, ctx-&gt;digest,
+		&amp;s);
+  dsa_signature_clear (&amp;s);
+}
+
+static void
+bench_gostdsa_verify (void *p)
+{
+  struct ecdsa_ctx *ctx = p;
+  if (! gostdsa_verify (&amp;ctx-&gt;pub,
+			ctx-&gt;digest_size, ctx-&gt;digest,
+			&amp;ctx-&gt;s))
+    die ("Internal error, _gostdsa_verify failed.\n");
+}
+
+static void
+bench_gostdsa_clear (void *p)
+{
+  struct ecdsa_ctx *ctx = p;
+
+  ecc_point_clear (&amp;ctx-&gt;pub);
+  ecc_scalar_clear (&amp;ctx-&gt;key);
+  dsa_signature_clear (&amp;ctx-&gt;s);
+  free (ctx-&gt;digest);
+
+  free (ctx);
+}
+
 #if WITH_OPENSSL
 struct openssl_rsa_ctx
 {
@@ -838,6 +940,8 @@ struct alg alg_list[] = {
   { "eddsa", 448, bench_eddsa_init, bench_eddsa_sign, bench_eddsa_verify, \
bench_eddsa_clear },  { "curve", 255, bench_curve_init, bench_curve_mul_g, \
bench_curve_mul, bench_curve_clear},  { "curve", 448, bench_curve_init, \
bench_curve_mul_g, bench_curve_mul, bench_curve_clear }, +  { "gostdsa",  256, \
bench_gostdsa_init, bench_gostdsa_sign, bench_gostdsa_verify, bench_gostdsa_clear }, \
+  { "gostdsa",  512, bench_gostdsa_init, bench_gostdsa_sign, bench_gostdsa_verify, \
bench_gostdsa_clear },  };
 
 #define numberof(x)  (sizeof (x) / sizeof ((x)[0]))
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20200116215931</emailId><senderName>Dmitry Eremin-Solenikov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-01-16 21:59:31-0400</timestampReceived><subject>Re: [PATCH v4 3/4] Add GOST DSA according to GOST R 34.10-2001/-2012</subject><body>

Hello,

чт, 16 янв. 2020 г. в 21:36, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt; &gt; From: Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt;
&gt; &gt;
&gt; &gt; Add GOST Digital Signature Algorithms support according to GOST R
&gt; &gt; 34.10-2001/-2012. English translations of these standards are provided
&gt; &gt; as RFC 5832 and RFC 7091.
&gt;
&gt; I've merged the first two patches to a branch ecc-gost. A few comments on
&gt; the signature implementation.

Thank you!



&gt; &gt; +void
&gt; &gt; +ecc_gostdsa_sign (const struct ecc_curve *ecc,
&gt; &gt; +             const mp_limb_t *zp,
&gt; &gt; +             const mp_limb_t *kp,
&gt; &gt; +             size_t length, const uint8_t *digest,
&gt; &gt; +             mp_limb_t *rp, mp_limb_t *sp,
&gt; &gt; +             mp_limb_t *scratch)
&gt; &gt; +{
&gt; &gt; +#define P        scratch
&gt; &gt; +#define hp       (scratch + 4*ecc-&gt;p.size)
&gt; &gt; +#define tp       (scratch + 2*ecc-&gt;p.size)
&gt; &gt; +#define t2p      scratch
&gt; &gt; +  /* Procedure, according to GOST 34.10. q denotes the group
&gt; &gt; +     order.
&gt; &gt; +
&gt; &gt; +     1. k &lt;-- uniformly random, 0 &lt; k &lt; q
&gt; &gt; +
&gt; &gt; +     2. C &lt;-- (c_x, c_y) = k g
&gt; &gt; +
&gt; &gt; +     3. r &lt;-- c_x mod q
&gt; &gt; +
&gt; &gt; +     4. s &lt;-- (r*z + k*h) mod q.
&gt; &gt; +  */
&gt;
&gt; So no modular inversion in the signature operation? That's an
&gt; improvement over NIST's DSA and ECDSA.

exactly.

&gt; &gt; diff --git a/ecc-gostdsa-verify.c b/ecc-gostdsa-verify.c
&gt; &gt; new file mode 100644
&gt; &gt; index 000000000000..4358132b2bf6
&gt; &gt; --- /dev/null
&gt; &gt; +++ b/ecc-gostdsa-verify.c
&gt; &gt; +/* FIXME: Use faster primitives, not requiring side-channel silence. */
&gt; &gt; +int
&gt; &gt; +ecc_gostdsa_verify (const struct ecc_curve *ecc,
&gt; &gt; +               const mp_limb_t *pp, /* Public key */
&gt; &gt; +               size_t length, const uint8_t *digest,
&gt; &gt; +               const mp_limb_t *rp, const mp_limb_t *sp,
&gt; &gt; +               mp_limb_t *scratch)
&gt; &gt; +{
&gt; &gt; +  /* Procedure, according to GOST R 34.10. q denotes the group
&gt; &gt; +     order.
&gt; &gt; +
&gt; &gt; +     1. Check 0 &lt; r, s &lt; q.
&gt; &gt; +
&gt; &gt; +     2. v &lt;-- h^{-1}  (mod q)
&gt; &gt; +
&gt; &gt; +     3. z1  &lt;-- s * v (mod q)
&gt; &gt; +
&gt; &gt; +     4. z2  &lt;-- -r * v (mod q)
&gt; &gt; +
&gt; &gt; +     5. R = u1 G + u2 Y
&gt; &gt; +
&gt; &gt; +     6. Signature is valid if R_x = r (mod q).
&gt; &gt; +  */
&gt; &gt; +
&gt; &gt; +#define hp (scratch)
&gt; &gt; +#define vp (scratch + ecc-&gt;p.size)
&gt; &gt; +#define z1 (scratch + 3*ecc-&gt;p.size)
&gt; &gt; +#define z2 (scratch + 4*ecc-&gt;p.size)
&gt; &gt; +
&gt; &gt; +#define P1 (scratch + 4*ecc-&gt;p.size)
&gt; &gt; +#define P2 (scratch)
&gt; &gt; +
&gt; &gt; +
&gt; &gt; +  if (! (ecdsa_in_range (ecc, rp)
&gt; &gt; +      &amp;&amp; ecdsa_in_range (ecc, sp)))
&gt; &gt; +    return 0;
&gt; &gt; +
&gt; &gt; +  gost_hash (&amp;ecc-&gt;q, hp, length, digest);
&gt; &gt; +
&gt; &gt; +  if (mpn_zero_p (hp, ecc-&gt;p.size))
&gt; &gt; +    mpn_add_1 (hp, hp, ecc-&gt;p.size, 1);
&gt; &gt; +
&gt; &gt; +  /* Compute v */
&gt; &gt; +  ecc-&gt;q.invert (&amp;ecc-&gt;q, vp, hp, vp + 2*ecc-&gt;p.size);
&gt;
&gt; Comment about faster primitives applies particularly to this modular
&gt; inversion. Using mpn_gcdext, which isn't side-channel silent, is likely
&gt; significantly faster (but a bit different interface). Would be
&gt; interesting to add to hogweed-benchmark, to compare to other ecc
&gt; signatures.

I'll take a look at this later.

&gt; &gt; diff --git a/ecc-hash.c b/ecc-hash.c
&gt; &gt; index 4e830a514ac4..07877110263f 100644
&gt; &gt; --- a/ecc-hash.c
&gt; &gt; +++ b/ecc-hash.c
&gt; &gt; @@ -62,3 +62,14 @@ ecc_hash (const struct ecc_modulo *m,
&gt; &gt;      /* We got a few extra bits, at the low end. Discard them. */
&gt; &gt;      mpn_rshift (hp, hp, m-&gt;size + 1, 8*length - m-&gt;bit_size);
&gt; &gt;  }
&gt; &gt; +
&gt; &gt; +void
&gt; &gt; +gost_hash (const struct ecc_modulo *m,
&gt; &gt; +        mp_limb_t *hp,
&gt; &gt; +        size_t length, const uint8_t *digest)
&gt; &gt; +{
&gt; &gt; +  if (length &gt; ((size_t) m-&gt;bit_size + 7) / 8)
&gt; &gt; +    length = (m-&gt;bit_size + 7) / 8;
&gt; &gt; +
&gt; &gt; +  mpn_set_base256_le (hp, m-&gt;size + 1, digest, length);
&gt; &gt; +}
&gt;
&gt; It looks a bit strange to truncate the digest in this function, but I
&gt; see that's the same as ecc_hash just above. Do you need to also handle
&gt; the case of left-over bits, 8*length &gt; m-&gt;bit_size?

Technically there should be no need to truncate, as the standard
enforces using  specific hash functions. I've copied this from
ecc_hash just to be on a safe side.

&gt; Are the details very specific to gost, or could the helper be renamed
&gt; ecc_hash_le ?

Just there is no point in doing hash_le for the generic ecc case.

&gt; What are typical values of length, compared to the prime size?

256-bit curve, 256-bit prime, 256-bit hash function
512-bit curve, 512-bit prime, 512-bit hash function

&gt; &gt; --- /dev/null
&gt; &gt; +++ b/gostdsa.h
&gt; &gt; @@ -0,0 +1,102 @@
&gt; [...]
&gt; &gt; +
&gt; &gt; +/* Development of Nettle's ECC support was funded by the .SE Internet Fund. */
&gt;
&gt; Left-over note?

Oops, dropped in v5.

&gt; &gt; diff --git a/testsuite/testutils.h b/testsuite/testutils.h
&gt; &gt; index f4ea38da9deb..cef7f4011a7c 100644
&gt; &gt; --- a/testsuite/testutils.h
&gt; &gt; +++ b/testsuite/testutils.h
&gt; &gt; @@ -22,6 +22,7 @@
&gt; &gt;  # include "ecc.h"
&gt; &gt;  # include "ecc-internal.h"
&gt; &gt;  # include "ecdsa.h"
&gt; &gt; +# include "gostdsa.h"
&gt; &gt;  # include "gmp-glue.h"
&gt; &gt;  # if NETTLE_USE_MINI_GMP
&gt; &gt;  #  include "knuth-lfib.h"
&gt;
&gt; Drop include, if nothing in testutils.h or testutils.c need gostdsa
&gt; types.

Done.

-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200118130144</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-01-18 13:01:44-0400</timestampReceived><subject>[PATCH 1/2] gost gc512a: rename functions to follow usual pattern</subject><body>

From: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 ecc-gost-gc512a.c | 14 +++++++-------
 1 file changed, 7 insertions(+), 7 deletions(-)

diff --git a/ecc-gost-gc512a.c b/ecc-gost-gc512a.c
index 4baec1f5945d..6d210925b609 100644
--- a/ecc-gost-gc512a.c
+++ b/ecc-gost-gc512a.c
@@ -43,7 +43,7 @@
 #include "ecc-gost-gc512a.h"
 
 static void
-ecc_gc512a_modp (const struct ecc_modulo *m, mp_limb_t *rp)
+ecc_gost_gc512a_modp (const struct ecc_modulo *m, mp_limb_t *rp)
 {
   mp_size_t mn = m-&gt;size;
   mp_limb_t hi;
@@ -54,8 +54,8 @@ ecc_gc512a_modp (const struct ecc_modulo *m, mp_limb_t *rp)
   assert(hi == 0);
 }
 
-#define ecc_gc512a_modp ecc_gc512a_modp
-#define ecc_gc512a_modq ecc_mod
+#define ecc_gost_gc512a_modp ecc_gost_gc512a_modp
+#define ecc_gost_gc512a_modq ecc_mod
 
 const struct ecc_curve _nettle_gost_gc512a =
 {
@@ -73,8 +73,8 @@ const struct ecc_curve _nettle_gost_gc512a =
     ecc_redc_ppm1,
 
     ecc_pp1h,
-    ecc_gc512a_modp,
-    ecc_gc512a_modp,
+    ecc_gost_gc512a_modp,
+    ecc_gost_gc512a_modp,
     ecc_mod_inv,
     NULL,
   },
@@ -92,8 +92,8 @@ const struct ecc_curve _nettle_gost_gc512a =
     NULL,
     ecc_qp1h,
 
-    ecc_gc512a_modq,
-    ecc_gc512a_modq,
+    ecc_gost_gc512a_modq,
+    ecc_gost_gc512a_modq,
     ecc_mod_inv,
     NULL,
   },
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200118130145</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-01-18 13:01:45-0400</timestampReceived><subject>[PATCH 2/2] .gitignore: correct generated header names</subject><body>

From: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 .gitignore | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/.gitignore b/.gitignore
index 2e64c187574f..48e2b7f464da 100644
--- a/.gitignore
+++ b/.gitignore
@@ -45,8 +45,8 @@ core
 /rotors.h
 /ecc-curve25519.h
 /ecc-curve448.h
-/ecc-gc256b.h
-/ecc-gc512a.h
+/ecc-gost-gc256b.h
+/ecc-gost-gc512a.h
 /ecc-secp192r1.h
 /ecc-secp224r1.h
 /ecc-secp256r1.h
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200118133146</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-18 13:31:46-0400</timestampReceived><subject>Travel</subject><body>

FYI, I'll be traveling to the US next two weeks, first to Mountain View
(close to San Franscisco) and then to Kirkland (close to Seattle). I'll
read email from time to time, but not sure how much time I'll get for
Nettle hacking. If any of you are in these areas, it would be nice to
meet.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200125153343</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-25 15:33:43-0400</timestampReceived><subject>Re: [PATCH] hogweed-benchmark: fill 32 or 56 bytes rather than just sizeof(int)</subject><body>

dbaryshkov@gmail.com writes:

&gt; diff --git a/examples/hogweed-benchmark.c b/examples/hogweed-benchmark.c
&gt; index 11393df04c81..69315211a0cc 100644
&gt; --- a/examples/hogweed-benchmark.c
&gt; +++ b/examples/hogweed-benchmark.c
&gt; @@ -771,12 +771,12 @@ bench_curve_init (unsigned size)
&gt;      case 255:
&gt;        ctx-&gt;mul = curve25519_mul;
&gt;        ctx-&gt;mul_g = curve25519_mul_g;
&gt; -      knuth_lfib_random (&amp;lfib, sizeof(CURVE25519_SIZE), ctx-&gt;s);
&gt; +      knuth_lfib_random (&amp;lfib, CURVE25519_SIZE, ctx-&gt;s);
&gt;        break;
&gt;      case 448:
&gt;        ctx-&gt;mul = curve448_mul;
&gt;        ctx-&gt;mul_g = curve448_mul_g;
&gt; -      knuth_lfib_random (&amp;lfib, sizeof(CURVE448_SIZE), ctx-&gt;s);
&gt; +      knuth_lfib_random (&amp;lfib, CURVE448_SIZE, ctx-&gt;s);
&gt;        break;
&gt;      default:
&gt;        abort ();

Thanks, fix applied.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200126014056</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-26 01:40:56-0400</timestampReceived><subject>Re: Problem with gitlab CI</subject><body>

Nikos Mavrogiannopoulos &lt;n.mavrogiannopoulos@gmail.com&gt; writes:

&gt; We had the same issue in gnutls. You can apply this patch.

Thanks, applied on master branch now. Will need merge/rebase any
other branches we want tested too.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200127094946</emailId><senderName></senderName><senderEmail>dbaryshkov</senderEmail><timestampReceived>2020-01-27 09:49:46-0400</timestampReceived><subject>[PATCH 2/2] Add support for GOST GC256C curve</subject><body>

From: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;

Add support for GC256C curve ("TLS Supported Groups" registry,
draft-smyshlyaev-tls12-gost-suites) also known as
GostR3410-2001-CryptoPro-B (RFC 4357).

Signed-off-by: Dmitry Baryshkov &lt;dbaryshkov@gmail.com&gt;
---
 .gitignore                      |   1 +
 Makefile.in                     |  10 +-
 ecc-curve.h                     |   1 +
 ecc-gost-gc256c.c               | 191 ++++++++++++++++++++++++++++++++
 ecc-internal.h                  |   1 +
 eccdata.c                       |  32 ++++++
 examples/ecc-benchmark.c        |   1 +
 nettle.texinfo                  |   8 ++
 testsuite/gostdsa-sign-test.c   |  11 ++
 testsuite/gostdsa-verify-test.c |  11 ++
 testsuite/testutils.c           |  12 +-
 11 files changed, 275 insertions(+), 4 deletions(-)
 create mode 100644 ecc-gost-gc256c.c

diff --git a/.gitignore b/.gitignore
index 48e2b7f464da..a94d279e5d18 100644
--- a/.gitignore
+++ b/.gitignore
@@ -46,6 +46,7 @@ core
 /ecc-curve25519.h
 /ecc-curve448.h
 /ecc-gost-gc256b.h
+/ecc-gost-gc256c.h
 /ecc-gost-gc512a.h
 /ecc-secp192r1.h
 /ecc-secp224r1.h
diff --git a/Makefile.in b/Makefile.in
index f876e5e82197..9400a357fe81 100644
--- a/Makefile.in
+++ b/Makefile.in
@@ -176,7 +176,8 @@ hogweed_SOURCES = sexp.c sexp-format.c \
 		  ecc-mod.c ecc-mod-inv.c \
 		  ecc-mod-arith.c ecc-pp1-redc.c ecc-pm1-redc.c \
 		  ecc-curve25519.c ecc-curve448.c \
-		  ecc-gost-gc256b.c ecc-gost-gc512a.c \
+		  ecc-gost-gc256b.c ecc-gost-gc256c.c \
+		  ecc-gost-gc512a.c \
 		  ecc-secp192r1.c ecc-secp224r1.c ecc-secp256r1.c \
 		  ecc-secp384r1.c ecc-secp521r1.c \
 		  ecc-size.c ecc-j-to-a.c ecc-a-to-j.c \
@@ -387,6 +388,9 @@ ecc-curve448.h: eccdata.stamp
 ecc-gost-gc256b.h: eccdata.stamp
 	./eccdata$(EXEEXT_FOR_BUILD) gost_gc256b 11 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
 
+ecc-gost-gc256c.h: eccdata.stamp
+	./eccdata$(EXEEXT_FOR_BUILD) gost_gc256c 11 6 $(NUMB_BITS) &gt; $@T &amp;&amp; mv $@T $@
+
 # Some reasonable choices for 512:
 # k = 22, c =  6, S = 256, T = 110 ( 88 A + 22 D) 32 KB
 # k = 29, c =  6, S = 192, T = 116 ( 87 A + 29 D) 24 KB
@@ -403,6 +407,7 @@ eccdata.stamp: eccdata.c
 ecc-curve25519.$(OBJEXT): ecc-curve25519.h
 ecc-curve448.$(OBJEXT): ecc-curve448.h
 ecc-gost-gc256b.$(OBJEXT): ecc-gost-gc256b.h
+ecc-gost-gc256c.$(OBJEXT): ecc-gost-gc256c.h
 ecc-gost-gc512a.$(OBJEXT): ecc-gost-gc512a.h
 ecc-secp192r1.$(OBJEXT): ecc-secp192r1.h
 ecc-secp224r1.$(OBJEXT): ecc-secp224r1.h
@@ -657,7 +662,8 @@ distcheck: dist
 clean-here:
 	-rm -f $(TARGETS) *.$(OBJEXT) *.$(OBJEXT).d *.s *.so *.dll *.a \
 		ecc-curve25519.h ecc-curve448.h \
-		ecc-gost-gc256b.h ecc-gost-gc512a.h \
+		ecc-gost-gc256b.h ecc-gost-gc256c.h \
+		ecc-gost-gc512a.h \
 		ecc-secp192r1.h ecc-secp224r1.h ecc-secp256r1.h \
 		ecc-secp384r1.h ecc-secp521r1.h \
 		aesdata$(EXEEXT_FOR_BUILD) \
diff --git a/ecc-curve.h b/ecc-curve.h
index 8f050404a944..30a33d43782b 100644
--- a/ecc-curve.h
+++ b/ecc-curve.h
@@ -44,6 +44,7 @@ extern "C" {
 struct ecc_curve;
 
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_gost_gc256b(void);
+const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_gost_gc256c(void);
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_gost_gc512a(void);
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_secp_192r1(void);
 const struct ecc_curve * _NETTLE_ATTRIBUTE_PURE nettle_get_secp_224r1(void);
diff --git a/ecc-gost-gc256c.c b/ecc-gost-gc256c.c
new file mode 100644
index 000000000000..9725ff65e6e2
--- /dev/null
+++ b/ecc-gost-gc256c.c
@@ -0,0 +1,191 @@
+/* ecc-gost-gc256c.c
+
+   Compile time constant (but machine dependent) tables.
+
+   Copyright (C) 2016, 2019 Dmitry Eremin-Solenikov
+
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+*/
+
+#if HAVE_CONFIG_H
+# include "config.h"
+#endif
+
+#include &lt;assert.h&gt;
+
+#include "ecc.h"
+#include "ecc-internal.h"
+
+#define USE_REDC 0
+
+#include "ecc-gost-gc256c.h"
+
+static void
+ecc_gost_gc256c_modp (const struct ecc_modulo *m, mp_limb_t *rp)
+{
+  mp_size_t mn = m-&gt;size;
+  mp_limb_t hi;
+
+  hi = mpn_submul_1(rp, rp + mn, mn, 0xc99 * 2);
+  hi = sec_add_1 (rp, rp, mn, hi * 0xc99 * 2);
+  hi = sec_sub_1 (rp, rp, mn, hi * 0xc99 * 2);
+  assert(hi &lt;= 1);
+  hi = cnd_sub_n (hi, rp, m-&gt;B, mn);
+  assert(hi == 0);
+}
+
+static void
+ecc_gost_gc256c_modq (const struct ecc_modulo *p, mp_limb_t *rp)
+{
+  mp_size_t mn = p-&gt;size;
+  mpz_t r, a, m;
+  mpz_init (r);
+  mpz_mod (r, mpz_roinit_n (a, rp, 2*mn), mpz_roinit_n (m, p-&gt;m, mn));
+  mpz_limbs_copy (rp, r, mn);
+
+  mpz_clear (r);
+}
+
+static void
+ecc_gost_gc256c_mod_mul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
+		      const mp_limb_t *ap, mp_limb_t b)
+{
+  mp_limb_t hi;
+
+  assert (b &lt;= 0xffffffff);
+  hi = mpn_mul_1 (rp, ap, m-&gt;size, b);
+  hi = mpn_sub_1 (rp, rp, m-&gt;size, hi * 0xc99 * 2);
+  assert(hi &lt;= 1);
+  hi = cnd_add_n (hi, rp, m-&gt;B, m-&gt;size);
+  assert(hi == 0);
+}
+
+static void
+ecc_gost_gc256c_mod_addmul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
+			 const mp_limb_t *ap, mp_limb_t b)
+{
+  mp_limb_t hi;
+
+  assert (b &lt;= 0xffffffff);
+  hi = mpn_addmul_1 (rp, ap, m-&gt;size, b);
+  hi = mpn_sub_1 (rp, rp, m-&gt;size, hi * 0xc99 * 2);
+  assert(hi &lt;= 1);
+  hi = cnd_add_n (hi, rp, m-&gt;B, m-&gt;size);
+  assert(hi == 0);
+}
+
+static void
+ecc_gost_gc256c_mod_submul_1 (const struct ecc_modulo *m, mp_limb_t *rp,
+			 const mp_limb_t *ap, mp_limb_t b)
+{
+  mp_limb_t hi;
+
+  assert (b &lt;= 0xffffffff);
+  hi = mpn_submul_1 (rp, ap, m-&gt;size, b);
+  hi = mpn_add_1 (rp, rp, m-&gt;size, hi * 0xc99 * 2);
+  assert(hi &lt;= 1);
+  hi = cnd_sub_n (hi, rp, m-&gt;B, m-&gt;size);
+  assert(hi == 0);
+}
+
+const struct ecc_curve _nettle_gost_gc256c =
+{
+  {
+    256,
+    ECC_LIMB_SIZE,
+    ECC_BMODP_SIZE,
+    ECC_REDC_SIZE,
+    ECC_MOD_INV_ITCH (ECC_LIMB_SIZE),
+    0,
+
+    ecc_p,
+    ecc_Bmodp,
+    ecc_Bmodp_shifted,
+    ecc_redc_ppm1,
+
+    ecc_pp1h,
+    ecc_gost_gc256c_modp,
+    ecc_gost_gc256c_modp,
+    ecc_mod_inv,
+    NULL,
+
+    ecc_gost_gc256c_mod_mul_1,
+    ecc_gost_gc256c_mod_addmul_1,
+    ecc_gost_gc256c_mod_submul_1,
+  },
+  {
+    256,
+    ECC_LIMB_SIZE,
+    ECC_BMODQ_SIZE,
+    0,
+    ECC_MOD_INV_ITCH (ECC_LIMB_SIZE),
+    0,
+
+    ecc_q,
+    ecc_Bmodq,
+    ecc_Bmodq_shifted,
+    NULL,
+    ecc_qp1h,
+
+    ecc_gost_gc256c_modq,
+    ecc_gost_gc256c_modq,
+    ecc_mod_inv,
+    NULL,
+
+    NULL,
+    NULL,
+    NULL,
+  },
+
+  USE_REDC,
+  ECC_PIPPENGER_K,
+  ECC_PIPPENGER_C,
+
+  ECC_ADD_JJA_ITCH (ECC_LIMB_SIZE),
+  ECC_ADD_JJJ_ITCH (ECC_LIMB_SIZE),
+  ECC_DUP_JJ_ITCH (ECC_LIMB_SIZE),
+  ECC_MUL_A_ITCH (ECC_LIMB_SIZE),
+  ECC_MUL_G_ITCH (ECC_LIMB_SIZE),
+  ECC_J_TO_A_ITCH (ECC_LIMB_SIZE),
+
+  ecc_add_jja,
+  ecc_add_jjj,
+  ecc_dup_jj,
+  ecc_mul_a,
+  ecc_mul_g,
+  ecc_j_to_a,
+
+  ecc_b,
+  ecc_g,
+  ecc_unit,
+  ecc_table
+};
+
+const struct ecc_curve *nettle_get_gost_gc256c(void)
+{
+  return &amp;_nettle_gost_gc256c;
+}
diff --git a/ecc-internal.h b/ecc-internal.h
index ddeb6d3cb1f3..ed54b5fbd367 100644
--- a/ecc-internal.h
+++ b/ecc-internal.h
@@ -94,6 +94,7 @@ extern const struct ecc_curve _nettle_curve448;
 
 /* GOST curves, visible with underscore prefix for now */
 extern const struct ecc_curve _nettle_gost_gc256b;
+extern const struct ecc_curve _nettle_gost_gc256c;
 extern const struct ecc_curve _nettle_gost_gc512a;
 
 #define ECC_MAX_SIZE ((521 + GMP_NUMB_BITS - 1) / GMP_NUMB_BITS)
diff --git a/eccdata.c b/eccdata.c
index 06b6937aebc5..01afcd4cf2df 100644
--- a/eccdata.c
+++ b/eccdata.c
@@ -705,6 +705,38 @@ ecc_curve_init (struct ecc_curve *ecc, const char *curve)
 		   "f7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e4b7",
 		   "83ccf17ba6706d73625cc3534c7a2b9d6ec1ee6a9a7e07c10d84b388de59f741");
 
+    }
+  else if (!strcmp (curve, "gost_gc256c"))
+    {
+      ecc_curve_init_str (ecc, ECC_TYPE_WEIERSTRASS,
+			  "80000000000000000000000000000000"
+			  "00000000000000000000000000000c99",
+
+			  "3e1af419a269a5f866a7d3c25c3df80a"
+			  "e979259373ff2b182f49d4ce7e1bbc8b",
+
+			  "80000000000000000000000000000001"
+			  "5f700cfff1a624e5e497161bcc8a198f",
+
+			  "00000000000000000000000000000000"
+			  "00000000000000000000000000000001",
+
+			  "3fa8124359f96680b83d1c3eb2c070e5"
+			  "c545c9858d03ecfb744bf8d717717efc");
+
+      ecc-&gt;ref = ecc_alloc (3);
+      ecc_set_str (&amp;ecc-&gt;ref[0], /* 2 g */
+		   "8000000000000000000000000000000000000000000000000000000000000c97",
+		   "4057edbca606997f47c2e3c14d3f8f1a3aba367a72fc13048bb40728e88e8d9d");
+
+      ecc_set_str (&amp;ecc-&gt;ref[1], /* 3 g */
+		   "1b9a33999d8449c3bbd8cfe49ac6355a2ee0827a6c71687c86cb7b0670efe205",
+		   "1876d998a19da37a120e76cb42f4f5225197279b612f712171a4648fe4a3ff12");
+
+      ecc_set_str (&amp;ecc-&gt;ref[2], /* 4 g */
+		   "5fa13ecfadd7ae00c2e65d0ac6cac1deda6d60e577afe90915671b08bbb9065e",
+		   "1b3c2859166129ac6dafee570ab9d40d33fdc25c7253c72f4e3fa77223ab016a");
+
     }
   else if (!strcmp (curve, "gost_gc512a"))
     {
diff --git a/examples/ecc-benchmark.c b/examples/ecc-benchmark.c
index a529cf16ab3a..b774d046ea20 100644
--- a/examples/ecc-benchmark.c
+++ b/examples/ecc-benchmark.c
@@ -315,6 +315,7 @@ const struct ecc_curve * const curves[] = {
   &amp;_nettle_curve448,
   &amp;_nettle_secp_521r1,
   &amp;_nettle_gost_gc256b,
+  &amp;_nettle_gost_gc256c,
   &amp;_nettle_gost_gc512a,
 };
 
diff --git a/nettle.texinfo b/nettle.texinfo
index 38c84410c103..2d448f92f5d8 100644
--- a/nettle.texinfo
+++ b/nettle.texinfo
@@ -5110,6 +5110,14 @@ Returns curve corresponding to following identifiers:
 @end itemize
 @end deftypefun
 
+@deftypefun {const struct ecc_curve} nettle_get_gost_gc256c(void)
+Returns curve corresponding to following identifiers:
+@itemize
+@item id-GostR3410-2001-CryptoPro-B-ParamSet (@cite{RFC 4357})
+@item id-tc26-gost-3410-12-256-paramSetC
+@end itemize
+@end deftypefun
+
 @deftypefun {const struct ecc_curve} nettle_get_gost_gc512a(void)
 Returns curve corresponding to following identifiers:
 @itemize
diff --git a/testsuite/gostdsa-sign-test.c b/testsuite/gostdsa-sign-test.c
index 0e2e0420a313..4d25f9521d37 100644
--- a/testsuite/gostdsa-sign-test.c
+++ b/testsuite/gostdsa-sign-test.c
@@ -70,6 +70,17 @@ test_main (void)
 
 	      "5E5B9B805B01147A8492C4A162643AC615DC777B9174108F3DC276A41F987AF3"); /* s */
 
+  test_gostdsa (nettle_get_gost_gc256c(),
+	      "3FCF1D623E5CDD3032A7C6EABB4A923C46E43D640FFEAAF2C3ED39A8FA399924", /* z */
+
+	      "5782C53F110C596F9155D35EBD25A06A89C50391850A8FEFE33B0E270318857C", /* k */
+
+	      SHEX("1C067E20EA6CB183F22EFB0F3C6FD2A4E6A02821CB7A1B17FACD5E1F7AA76F70"), /* h */
+
+	      "4E8F9973B31A134CE0942421573B0529B07EC96B835A07856C16CE8070C62547", /* r */
+
+	      "10CE0EFA72741D5EB24837563AAB9369781D6F487ACF88BBEE3E49EC239F6A90"); /* s */
+
   test_gostdsa (nettle_get_gost_gc512a(),
 	      "3FC01CDCD4EC5F972EB482774C41E66DB7F380528DFE9E67992BA05AEE462435"
 	      "757530E641077CE587B976C8EEB48C48FD33FD175F0C7DE6A44E014E6BCB074B", /* z */
diff --git a/testsuite/gostdsa-verify-test.c b/testsuite/gostdsa-verify-test.c
index 7279f5f46c5b..66660a2c0ad7 100644
--- a/testsuite/gostdsa-verify-test.c
+++ b/testsuite/gostdsa-verify-test.c
@@ -93,6 +93,17 @@ test_main (void)
 
 	      "5E5B9B805B01147A8492C4A162643AC615DC777B9174108F3DC276A41F987AF3"); /* s */
 
+  test_gostdsa (nettle_get_gost_gc256c(),
+	      "347E354F60B8DA8DE659B432600418C7D0E70F01622477579FAB36A066B9B8FD", /* x */
+
+	      "1DD2E31CF7840A5109DFAB561E15D42BC3CE2E64995FB70F3B86679655A1BAA1", /* y */
+
+	      SHEX("1C067E20EA6CB183F22EFB0F3C6FD2A4E6A02821CB7A1B17FACD5E1F7AA76F70"), /* h */
+
+	      "4E8F9973B31A134CE0942421573B0529B07EC96B835A07856C16CE8070C62547", /* r */
+
+	      "10CE0EFA72741D5EB24837563AAB9369781D6F487ACF88BBEE3E49EC239F6A90"); /* s */
+
   test_gostdsa (nettle_get_gost_gc512a(),
 	      "03A36340A95BB5F93D131961B5B1C1B3213DF7FF3B5A30376407E2A65C441BC6"
 	      "D1B34662317083243F007B15A8512B526606D3B172B606DCE86DBD6F82DA3D40", /* x */
diff --git a/testsuite/testutils.c b/testsuite/testutils.c
index 61d52d92fc04..86bc8f098352 100644
--- a/testsuite/testutils.c
+++ b/testsuite/testutils.c
@@ -1678,6 +1678,7 @@ const struct ecc_curve * const ecc_curves[] = {
   &amp;_nettle_curve25519,
   &amp;_nettle_curve448,
   &amp;_nettle_gost_gc256b,
+  &amp;_nettle_gost_gc256c,
   &amp;_nettle_gost_gc512a,
   NULL
 };
@@ -1730,7 +1731,7 @@ void
 test_ecc_mul_a (unsigned curve, unsigned n, const mp_limb_t *p)
 {
   /* For each curve, the points 2 g, 3 g and 4 g */
-  static const struct ecc_ref_point ref[9][3] = {
+  static const struct ecc_ref_point ref[10][3] = {
     { { "dafebf5828783f2ad35534631588a3f629a70fb16982a888",
 	"dd6bda0d993da0fa46b27bbc141b868f59331afa5c7e93ab" },
       { "76e32a2557599e6edcd283201fb2b9aadfd0d359cbb263da",
@@ -1806,6 +1807,13 @@ test_ecc_mul_a (unsigned curve, unsigned n, const mp_limb_t *p)
       { "f7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e7063e4b7",
 	"83ccf17ba6706d73625cc3534c7a2b9d6ec1ee6a9a7e07c10d84b388de59f741" },
     },
+    { { "8000000000000000000000000000000000000000000000000000000000000c97",
+	"4057edbca606997f47c2e3c14d3f8f1a3aba367a72fc13048bb40728e88e8d9d" },
+      { "1b9a33999d8449c3bbd8cfe49ac6355a2ee0827a6c71687c86cb7b0670efe205",
+	"1876d998a19da37a120e76cb42f4f5225197279b612f712171a4648fe4a3ff12" },
+      { "5fa13ecfadd7ae00c2e65d0ac6cac1deda6d60e577afe90915671b08bbb9065e",
+	"1b3c2859166129ac6dafee570ab9d40d33fdc25c7253c72f4e3fa77223ab016a" },
+    },
     { { "3b89dcfc622996ab97a5869dbff15cf51db00954f43a58a5e5f6b0470a132b2f"
 	"4434bbcd405d2a9516151d2a6a04f2e4375bf48de1fdb21fb982afd9d2ea137c",
 	"c813c4e2e2e0a8a391774c7903da7a6f14686e98e183e670ee6fb784809a3e92"
@@ -1820,7 +1828,7 @@ test_ecc_mul_a (unsigned curve, unsigned n, const mp_limb_t *p)
 	"da7efdb93de8f3df80bc25eac09239c14175f5c29704ce9a3e383f1b3ec0e929" },
     }
   };
-  assert (curve &lt; 9);
+  assert (curve &lt; 10);
   assert (n &lt;= 4);
   if (n == 0)
     {
-- 
2.24.1

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200129042735</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-29 04:27:35-0400</timestampReceived><subject>Re: [PATCH 1/2] Change ecc_mod_*mul_1 to be per-module callbacks</subject><body>

dbaryshkov@gmail.com writes:

&gt; GOST curves will require different "fixups" for fast (mul X mod p)
&gt; operations. Move these operations to ecc_modulo structure and call them
&gt; via function pointer.

It looks like ecc_mod_addmul_1 is used only by ecc-mul-m.c, used only
for curve25519 and curve448. So shouldn't need any redirection.

While ecc_mod_mul_1 and ecc_mod_submul_1 are used by all of
ecc-add-jja.c, ecc-add-jjj.c and ecc-dup-jj.c, via the ecc_modp_mul_1
and ecc_modp_submul_1 wrapper macros.

Maybe the wrapper macros should be deleted, to make usage less confusing.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200129155354</emailId><senderName>Dmitry Eremin-Solenikov</senderName><senderEmail>dbaryshkov@gmail.com</senderEmail><timestampReceived>2020-01-29 15:53:54-0400</timestampReceived><subject>Re: [PATCH 0/2] two small fixes for ecc-gost branch</subject><body>

Hello,

ср, 29 янв. 2020 г. в 07:14, Niels Möller &lt;nisse@lysator.liu.se&gt;:
&gt;
&gt; Dmitry Eremin-Solenikov &lt;dbaryshkov@gmail.com&gt; writes:
&gt;
&gt; &gt; I've sent two patches for next curve (the 256-bit 80000.....0c99 one)
&gt; &gt; for review.
&gt; &gt;
&gt; &gt; I still hope to get most curves into next release. I'm perfectly fine
&gt; &gt; with releasing nettle without additional curves though.
&gt;
&gt; I've now merged gostdsa and the first two curves to master.

Thank you!

&gt; I'd like to postpone additional gost curves for a bit, to figure out
&gt; what else needs to get into the next release.

Fine with me, thank you!

-- 
With best wishes
Dmitry
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20200129162156</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-01-29 16:21:56-0400</timestampReceived><subject>Re: Current ECC work</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; If we want to compute v = z^-1 (mod p), but in redc form with v' = vB
&gt; and z' = zB, then we have
&gt;
&gt;   v z = 1 (mod p)
&gt;
&gt; but
&gt;
&gt;   v' z' = B^2 (mod p)
&gt;
&gt; So for redc curves we need to compute v' as
&gt;
&gt;   v' = (z' / B^2)^-1 (mod p)

I've pushed changes to do this to a new branch invert-with-redc. I think
it makes things a bit simpler. I haven't yet looked at any benchmarks,
but I'd hope to either see no change or an epsilon improvement.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201011174245</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-10-11 17:42:45-0400</timestampReceived><subject>GCM with ARM Neon (was: Re: [PATCH] "PowerPC64" GCM support)</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; So if we have the input in register A (loaded from memory with no
&gt; processing besides ensuring proper *byte* order), and precompute two
&gt; values, M representing b_1(x) x^64 + c_1(x), and L representing b_0(x)
&gt; x^64 + d_1(x)), then we get the two halves above with two vpmsumd,
&gt;
&gt;   vpmsumd R, M, A
&gt;   vpmsumd F, L, A
&gt;
&gt; When doing more than one block at a time, I think it's easiest to
&gt; accumulate the R and F values separately.

BTW, I wonder if similar organization would make sense for Arm Neon.
Now, Neon doesn't have vpmsumd, the widest carryless multiplication
available is vmull.p8, which is an 8-bit to 15-bit multiply, 8 in
parallel.

I'm sketching an instruction sequence doing the equivalent of two
vpmsumd using 32 vmull.p8, with good parallelism and not too many
instructions to shuffle around data to the right places. Is that a good
idea? To be compared to what the C code does, a loop of 16 iterations,
each doing some table lookup, shift and xoring.

With this large number of multiply instructions, it might pay off to use
Karatsuba, which could reduce it to 24 multiples (one level) or 18 (two
levels), at the cost of more xors and data movement instructions, and
lots of complexity.

(There have been ARM Neon code for gcm posted to the list earlier, but if I
remember correctly, that code didn't work in bit-reversed representation,
but used a bunch of explicit reversal operations).

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201011180311</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-10-11 18:03:11-0400</timestampReceived><subject>Re: GCM with ARM Neon</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; I may be mistaken, but I believe 64-bit poly multiplies are available.
&gt; Or they are available on Aarch64 with Crypto extensions.

I'm looking in the Arm Instruction Set Reference Guide, labeled version
1.0, 2018.

It includes a section on cryptographic instructions, but that's aes,
sha1 and sha256, no carry-less multiplication.

But I may well be missing something, I'm not really familiar with
Aarch64.

&gt; I'm not aware of poly multiplies on other ARM arches, like ARMv6 or
&gt; ARMv7 with NEON.

I think the "p8" SIMD datatype and vmull.p8 have been part of the Neon
instruction set for a long time, at least since I wrote my first ARM
code back in 2013. It's just a bit annoyning that one needs so many of
them to do a wide multiply.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201102115334</emailId><senderName>"Neal H. Walfield"</senderName><senderEmail>neal@walfield.org</senderEmail><timestampReceived>2020-11-02 11:53:34-0400</timestampReceived><subject>SHA1 Collision Detection</subject><body>

Hi,

It's well known that SHA-1 is broken.  I don't want to save it.  But,
particularly when dealing with data at rest, there are cases where one
has to use SHA-1.  It would be nice if Nettle integrated SHA-1
collision detection to make that a tiny bit safer:

  https://github.com/cr-marcstevens/sha1collisiondetection

That library is under the MIT license, and apparently detects known
attacks against SHA-1:

  [The routines] will compute the SHA-1 hash of any given file and
  additionally will detect cryptanalytic collision attacks against
  SHA-1 present in each file. It is very fast and takes less than
  twice the amount of time as regular SHA-1.

  More specifically they will detect any cryptanalytic collision
  attack against SHA-1 using any of the top 32 SHA-1 disturbance
  vectors with probability 1: ...

  The possibility of false positives can be neglected as the
  probability is smaller than 2^-90.

Thanks,

:) Neal
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201102133134</emailId><senderName>Simo Sorce</senderName><senderEmail>simo@redhat.com</senderEmail><timestampReceived>2020-11-02 13:31:34-0400</timestampReceived><subject>Re: SHA1 Collision Detection</subject><body>

On Mon, 2020-11-02 at 12:53 +0100, Neal H. Walfield wrote:
&gt; Hi,
&gt; 
&gt; It's well known that SHA-1 is broken.  I don't want to save it.  But,
&gt; particularly when dealing with data at rest, there are cases where one
&gt; has to use SHA-1.  It would be nice if Nettle integrated SHA-1
&gt; collision detection to make that a tiny bit safer:
&gt; 
&gt;   https://github.com/cr-marcstevens/sha1collisiondetection
&gt; 
&gt; That library is under the MIT license, and apparently detects known
&gt; attacks against SHA-1:
&gt; 
&gt;   [The routines] will compute the SHA-1 hash of any given file and
&gt;   additionally will detect cryptanalytic collision attacks against
&gt;   SHA-1 present in each file. It is very fast and takes less than
&gt;   twice the amount of time as regular SHA-1.
&gt; 
&gt;   More specifically they will detect any cryptanalytic collision
&gt;   attack against SHA-1 using any of the top 32 SHA-1 disturbance
&gt;   vectors with probability 1: ...
&gt; 
&gt;   The possibility of false positives can be neglected as the
&gt;   probability is smaller than 2^-90.
&gt; 
&gt; Thanks,
&gt; 
&gt; :) Neal

This change would have to be conditional as it will break compatibility
for the very use case you mention, data at rest saved moons ago.

Simo.

-- 
Simo Sorce
RHEL Crypto Team
Red Hat, Inc




_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201102134011</emailId><senderName>"Neal H. Walfield"</senderName><senderEmail>neal@walfield.org</senderEmail><timestampReceived>2020-11-02 13:40:11-0400</timestampReceived><subject>Re: SHA1 Collision Detection</subject><body>

Hi Simo,

On Mon, 02 Nov 2020 14:31:34 +0100,
Simo Sorce wrote:
&gt; On Mon, 2020-11-02 at 12:53 +0100, Neal H. Walfield wrote:
&gt; This change would have to be conditional as it will break compatibility
&gt; for the very use case you mention, data at rest saved moons ago.

I see two ways forward.

If I recall the C calling conventions correctly, it should be possible
to change sha1_digest from returning void to returning an int in a
backwards compatible way.  Then, a user of the return code would check
some function at run time to see whether the function really returns
an int.

That's ugly.  For us (Sequoia [1]), we'd be happy to have a parallel
API.

  [1] https://sequoia-pgp.org/

For SHA1, Nettle has the following functions [2]:

  void sha1_init (struct sha1_ctx *ctx)
  void sha1_update (struct sha1_ctx *ctx, size_t length, const uint8_t *data)
  void sha1_digest (struct sha1_ctx *ctx, size_t length, uint8_t *digest)

  [2] http://www.lysator.liu.se/~nisse/nettle/nettle.html#Legacy-hash-functions

So we could add:

  void sha1_collision_detection_init(...);
  void sha1_collision_detection_update (struct sha1_ctx *ctx, size_t length, const uint8_t *data)
  error_code_t sha1_collision_detection_digest (struct sha1_ctx *ctx, size_t length, uint8_t *digest)
  
What do you think?  Or, am I misunderstanding what you mean by
breaking compatibility?

Thanks!

:) Neal
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201102141121</emailId><senderName>Simo Sorce</senderName><senderEmail>simo@redhat.com</senderEmail><timestampReceived>2020-11-02 14:11:21-0400</timestampReceived><subject>Re: SHA1 Collision Detection</subject><body>

On Mon, 2020-11-02 at 14:40 +0100, Neal H. Walfield wrote:
&gt; Hi Simo,
&gt; 
&gt; On Mon, 02 Nov 2020 14:31:34 +0100,
&gt; Simo Sorce wrote:
&gt; &gt; On Mon, 2020-11-02 at 12:53 +0100, Neal H. Walfield wrote:
&gt; &gt; This change would have to be conditional as it will break compatibility
&gt; &gt; for the very use case you mention, data at rest saved moons ago.
&gt; 
&gt; I see two ways forward.
&gt; 
&gt; If I recall the C calling conventions correctly, it should be possible
&gt; to change sha1_digest from returning void to returning an int in a
&gt; backwards compatible way.  Then, a user of the return code would check
&gt; some function at run time to see whether the function really returns
&gt; an int.
&gt; 
&gt; That's ugly.  For us (Sequoia [1]), we'd be happy to have a parallel
&gt; API.
&gt; 
&gt;   [1] https://sequoia-pgp.org/
&gt; 
&gt; For SHA1, Nettle has the following functions [2]:
&gt; 
&gt;   void sha1_init (struct sha1_ctx *ctx)
&gt;   void sha1_update (struct sha1_ctx *ctx, size_t length, const uint8_t *data)
&gt;   void sha1_digest (struct sha1_ctx *ctx, size_t length, uint8_t *digest)
&gt; 
&gt;   [2] http://www.lysator.liu.se/~nisse/nettle/nettle.html#Legacy-hash-functions
&gt; 
&gt; So we could add:
&gt; 
&gt;   void sha1_collision_detection_init(...);
&gt;   void sha1_collision_detection_update (struct sha1_ctx *ctx, size_t length, const uint8_t *data)
&gt;   error_code_t sha1_collision_detection_digest (struct sha1_ctx *ctx, size_t length, uint8_t *digest)
&gt;   
&gt; What do you think?  Or, am I misunderstanding what you mean by
&gt; breaking compatibility?

This is a possible way to go, you did not misunderstand.

Simo.

-- 
Simo Sorce
RHEL Crypto Team
Red Hat, Inc




_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201102174939</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-11-02 17:49:39-0400</timestampReceived><subject>Re: SHA1 Collision Detection</subject><body>

"Neal H. Walfield" &lt;neal@walfield.org&gt; writes:

&gt; So we could add:
&gt;
&gt;   void sha1_collision_detection_init(...);
&gt;   void sha1_collision_detection_update (struct sha1_ctx *ctx, size_t length, const uint8_t *data)
&gt;   error_code_t sha1_collision_detection_digest (struct sha1_ctx *ctx, size_t length, uint8_t *digest)
&gt;   
&gt; What do you think?  Or, am I misunderstanding what you mean by
&gt; breaking compatibility?

I haven't yet read the background, so I don't know what I think about
the feature in general. But from an api point of view, that looks
reasonable. Do all three operations need new functions? Do you need an
extended context struct too?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201102212240</emailId><senderName>"Neal H. Walfield"</senderName><senderEmail>neal@walfield.org</senderEmail><timestampReceived>2020-11-02 21:22:40-0400</timestampReceived><subject>Re: SHA1 Collision Detection</subject><body>

Hi Niels,

On Mon, 02 Nov 2020 18:49:39 +0100,
Niels Möller wrote:
&gt; 
&gt; "Neal H. Walfield" &lt;neal@walfield.org&gt; writes:
&gt; 
&gt; &gt; So we could add:
&gt; &gt;
&gt; &gt;   void sha1_collision_detection_init(...);
&gt; &gt;   void sha1_collision_detection_update (struct sha1_ctx *ctx, size_t length, const uint8_t *data)
&gt; &gt;   error_code_t sha1_collision_detection_digest (struct sha1_ctx *ctx, size_t length, uint8_t *digest)
&gt; &gt;   
&gt; &gt; What do you think?  Or, am I misunderstanding what you mean by
&gt; &gt; breaking compatibility?
&gt; 
&gt; I haven't yet read the background, so I don't know what I think about
&gt; the feature in general. But from an api point of view, that looks
&gt; reasonable. Do all three operations need new functions? Do you need an
&gt; extended context struct too?

I'm not that familiar with Nettle's API, so I don't know if the
following is sufficiently idiomatic.

That said, we could do the following: we could add a flag to the sha1
context to indicate to the update function that it should try to
detect collision attempts, we could add a few ifs to the update
function to do the checks, and we could add a second function to
return whether a collision was detected:

   void sha1_check_for_collisions(struct sha1_ctx *ctx);
   int sha1_detected_collision(struct sha1_ctx *ctx);

What do you think?

:) Neal
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201103092417</emailId><senderName>Justus Winter</senderName><senderEmail>justus@sequoia-pgp.org</senderEmail><timestampReceived>2020-11-03 09:24:17-0400</timestampReceived><subject>Re: SHA1 Collision Detection</subject><body>

[Attachment #2 (multipart/signed)]


"Neal H. Walfield" &lt;neal@walfield.org&gt; writes:

&gt; I'm not that familiar with Nettle's API, so I don't know if the
&gt; following is sufficiently idiomatic.
&gt;
&gt; That said, we could do the following: we could add a flag to the sha1
&gt; context to indicate to the update function that it should try to
&gt; detect collision attempts, we could add a few ifs to the update
&gt; function to do the checks, and we could add a second function to
&gt; return whether a collision was detected:
&gt;
&gt;    void sha1_check_for_collisions(struct sha1_ctx *ctx);
&gt;    int sha1_detected_collision(struct sha1_ctx *ctx);
&gt;
&gt; What do you think?

I think hashing should be fallible.  If a collision attack is detected,
no digest should be produced, because the digest has none of the
properties that we usually associate with a hash digest.

If we come up with a new API anyway, we should make all hash functions
fallible, because sooner or later, any algorithm may fall.

Cheers,
Justus

["signature.asc" (application/pgp-signature)]
[Attachment #6 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20201103093336</emailId><senderName>"Neal H. Walfield"</senderName><senderEmail>neal@walfield.org</senderEmail><timestampReceived>2020-11-03 09:33:36-0400</timestampReceived><subject>Re: SHA1 Collision Detection</subject><body>

On Tue, 03 Nov 2020 10:24:17 +0100,
Justus Winter wrote:
&gt; "Neal H. Walfield" &lt;neal@walfield.org&gt; writes:
&gt; 
&gt; &gt; I'm not that familiar with Nettle's API, so I don't know if the
&gt; &gt; following is sufficiently idiomatic.
&gt; &gt;
&gt; &gt; That said, we could do the following: we could add a flag to the sha1
&gt; &gt; context to indicate to the update function that it should try to
&gt; &gt; detect collision attempts, we could add a few ifs to the update
&gt; &gt; function to do the checks, and we could add a second function to
&gt; &gt; return whether a collision was detected:
&gt; &gt;
&gt; &gt;    void sha1_check_for_collisions(struct sha1_ctx *ctx);
&gt; &gt;    int sha1_detected_collision(struct sha1_ctx *ctx);
&gt; &gt;
&gt; &gt; What do you think?
&gt; 
&gt; I think hashing should be fallible.  If a collision attack is detected,
&gt; no digest should be produced, because the digest has none of the
&gt; properties that we usually associate with a hash digest.
&gt; 
&gt; If we come up with a new API anyway, we should make all hash functions
&gt; fallible, because sooner or later, any algorithm may fall.

I think there are still cases where one may want the digest even if a
collision attack was detected.  So, I think it should still be
possible to get the digest.  But, I'd agree that most users of this
function shouldn't use it.  As such, I'd support making it hard to get
the digest.

:) Neal
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201217102817</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-12-17 10:28:17-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

&gt;
&gt; I wonder which assembly files we should use if target host is aarch64,
&gt; but ABI=32? I guess the arm/v6/ code can be used unconditionally. Can
&gt; we also use arm/neon/ code unconditionally?
&gt;

It seems gcc for aarch64 doesn't support building 32-bit binaries, maybe we
should remove the check of ABI since 64-bit is the only option. I tried
adding arm/v6 and arm/neon unconditionally, both yield a bunch of errors
such as the integer register is r4 instead of w4 or x4 plus getting a few
unknown mnemonics.

Do you agre with aiming for a release pretty soon, including the new
&gt; powerpc64 code, but no aarch64 code?
&gt;

Isn't starting a new version with both powerpc64 and aarch64 changes is
more reasonable? I'm not sure here, if there are a few commits before
powerpc64 patches then it makes sense to wrap up the current version with
powerpc64 code. It's up to you to decide, you can also consider an AES
modes optimizations for S390x arch which I'll drop its patch in the next
few days.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201218162633</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-12-18 16:26:33-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

I created a couple of merge requests in the repo, with those MRs merged I
think the powerpc code is stable to be included in the upcoming version of
nettle.

regards,
Mamone

On Thu, Dec 17, 2020 at 12:28 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
wrote:

&gt; I wonder which assembly files we should use if target host is aarch64,
&gt;&gt; but ABI=32? I guess the arm/v6/ code can be used unconditionally. Can
&gt;&gt; we also use arm/neon/ code unconditionally?
&gt;&gt;
&gt;
&gt; It seems gcc for aarch64 doesn't support building 32-bit binaries, maybe
&gt; we should remove the check of ABI since 64-bit is the only option. I tried
&gt; adding arm/v6 and arm/neon unconditionally, both yield a bunch of errors
&gt; such as the integer register is r4 instead of w4 or x4 plus getting a few
&gt; unknown mnemonics.
&gt;
&gt; Do you agre with aiming for a release pretty soon, including the new
&gt;&gt; powerpc64 code, but no aarch64 code?
&gt;&gt;
&gt;
&gt; Isn't starting a new version with both powerpc64 and aarch64 changes is
&gt; more reasonable? I'm not sure here, if there are a few commits before
&gt; powerpc64 patches then it makes sense to wrap up the current version with
&gt; powerpc64 code. It's up to you to decide, you can also consider an AES
&gt; modes optimizations for S390x arch which I'll drop its patch in the next
&gt; few days.
&gt;
&gt; regards,
&gt; Mamone
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201218163119</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-12-18 16:31:19-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; It seems gcc for aarch64 doesn't support building 32-bit binaries, maybe we
&gt; should remove the check of ABI since 64-bit is the only option.

Ok, that's a bit confusing. There's a command line flag for it, not -m32
but -mabi=ilp32, but that doesn't work out of the box with my
(debian-packaged) cross compiler. Searching turns up this old (2015)
email saying that gcc support is work-in-progress:
https://gcc.gnu.org/legacy-ml/gcc-help/2015-02/msg00034.html

I would suggest keeping the ABI check, but leave asm_path empty (or
maybe use asm_path=arm), until we have figured out how to build and
test for that configuration.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201219092704</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-12-19 09:27:04-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; I created a couple of merge requests in the repo, with those MRs merged I
&gt; think the powerpc code is stable to be included in the upcoming version of
&gt; nettle.

Thanks. I've merged the "Use 32-bit offset to load data". 

For the other one,
https://git.lysator.liu.se/nettle/nettle/-/merge_requests/15 "Use signal
to detect CPU features when getauxval() isn't available", can you
explain for which systems is that needed? In the current code, you
handle gnu/linux (depends on glibc, I guess), freebsd and aix.

I hesitate adding signal code, because it seems a bit dangerous and
brittle for a library to modify signal handlers. In particular, I worry
about what happens to other threads, since sigaction modifies the
process-global signal handler.

The fat setup code is otherwise threadsafe, under the assumption that
writes to a function pointer variable is atomic on the relevant
architecture. In the unlikely case that we get concurrent calls to
fat_init, both threads will get to the same conclusion and store
identical values in the target variables, so then it shouldn't matter in
which order (and how late) writes propagate to other cores.

If there's some way to setup (and restore) a thread-local signal handler
for SIGILL, that would be safer, but I don't know if that's at all
possible.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201219093607</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-12-19 09:36:07-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

On Fri, Dec 18, 2020 at 11:31 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt; It seems gcc for aarch64 doesn't support building 32-bit binaries, maybe we
&gt; &gt; should remove the check of ABI since 64-bit is the only option.
&gt;
&gt; Ok, that's a bit confusing. There's a command line flag for it, not -m32
&gt; but -mabi=ilp32, but that doesn't work out of the box with my
&gt; (debian-packaged) cross compiler. Searching turns up this old (2015)
&gt; email saying that gcc support is work-in-progress:
&gt; https://gcc.gnu.org/legacy-ml/gcc-help/2015-02/msg00034.html

Also see https://gcc.gnu.org/legacy-ml/gcc-help/2016-06/msg00097.html

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201219173026</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-12-19 17:30:26-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

On Sat, Dec 19, 2020 at 11:27 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; For the other one,
&gt; https://git.lysator.liu.se/nettle/nettle/-/merge_requests/15 "Use signal
&gt; to detect CPU features when getauxval() isn't available", can you
&gt; explain for which systems is that needed? In the current code, you
&gt; handle gnu/linux (depends on glibc, I guess), freebsd and aix.
&gt;
&gt; I hesitate adding signal code, because it seems a bit dangerous and
&gt; brittle for a library to modify signal handlers. In particular, I worry
&gt; about what happens to other threads, since sigaction modifies the
&gt; process-global signal handler.
&gt;
&gt; The fat setup code is otherwise threadsafe, under the assumption that
&gt; writes to a function pointer variable is atomic on the relevant
&gt; architecture. In the unlikely case that we get concurrent calls to
&gt; fat_init, both threads will get to the same conclusion and store
&gt; identical values in the target variables, so then it shouldn't matter in
&gt; which order (and how late) writes propagate to other cores.
&gt;
&gt; If there's some way to setup (and restore) a thread-local signal handler
&gt; for SIGILL, that would be safer, but I don't know if that's at all
&gt; possible.
&gt;

fat-ppc.c uses getauxval() function to detect cpu features for Linux
systems, the problem is that getauxval was introduced in glibc v2.16 which
released in 2012 so in case fat option enabled, the build will fail for
older glibc versions. To get around that, I implemented cpu features
detection using signal in case an old glibc version been used but as you
mentioned the signals work as process-based in UNIX and that could be
problematic in this case for certain circumstances. However, I'm not aware
of any approach to achieve thread-safety signal handling and even if such
approach exists I think it won't be tempting to complicate such procedure
in order to detect cpu features in this way. Do you have any
suggestions here or we have to look for alternative solutions?

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201219190551</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-12-19 19:05:51-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; fat-ppc.c uses getauxval() function to detect cpu features for Linux
&gt; systems, the problem is that getauxval was introduced in glibc v2.16 which
&gt; released in 2012 so in case fat option enabled, the build will fail for
&gt; older glibc versions.

I agree it's not so nice that the build fails on old systems. Do you
have any idea how common such old systems might be?

Maybe add a configure check for getauxval, and either fail at configure
time if --enable-fat is specified but we can't support it, or fall back
to assuming that none of the optional features are present at runtime?

Some preprocessor check of glibc version in fat-ppc.c could work too, if
that's simpler.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201215154727</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-12-15 15:47:27-0400</timestampReceived><subject>Release of Nettle-3.7?</subject><body>

Hi, I wonder if it would make sense to try to cut a release pretty soon
(and without any arm64 changes)? Previous release was made end of April,
and there's been quite a few improvements since then.

I wonder if it is possible to make a release in time for the upcoming
debian release?
https://lists.debian.org/debian-devel-announce/2020/11/msg00002.html
Nettle-3.7 should be abi-compatible, and with unchanged soname, so I'm
not sure if it would count as a "transition" in the debian world.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201215184229</emailId><senderName>Andreas Metzler</senderName><senderEmail>ametzler@bebt.de</senderEmail><timestampReceived>2020-12-15 18:42:29-0400</timestampReceived><subject>Re: Release of Nettle-3.7?</subject><body>

On 2020-12-15 Niels Möller wrote:
&gt; Hi, I wonder if it would make sense to try to cut a release pretty soon
&gt; (and without any arm64 changes)? Previous release was made end of April,
&gt; and there's been quite a few improvements since then.

&gt; I wonder if it is possible to make a release in time for the upcoming
&gt; debian release?
&gt; https://lists.debian.org/debian-devel-announce/2020/11/msg00002.html
&gt; Nettle-3.7 should be abi-compatible, and with unchanged soname, so I'm
&gt; not sure if it would count as a "transition" in the debian world.

Hello,

it would not count as transition
https://release.debian.org/bullseye/freeze_policy.html#transition

| When changes in a package cause the need for changes in other
| packages, we call this a 'transition'. The most common example is
| a library transition. Transitions require coordination between
| maintainers and can take a long time to finish, especially when bugs
| are discovered during the transition. Unfinished transitions can block
| the migration of unrelated fixes in the packages involved in the
| transition. From the start of the Transition and (build-)essentials
| Freeze, it's no longer appropriate to start new transitions.

A "library transition" happens after a soname-bump, all reverse
dependencies need to be rebuilt against the new version and if the API
also changed incompatibly require source changes.

cu And- I am not hinting that delaying a release until after the
        start of the transition freeze would be welcome ;-)-reas

-- 
`What a good friend you are to him, Dr. Maturin. His other friends are
so grateful to you.'
`I sew his ears on from time to time, sure'
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201218162947</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-12-18 16:29:47-0400</timestampReceived><subject>Re: Release of Nettle-3.7?</subject><body>

Andreas Metzler &lt;ametzler@bebt.de&gt; writes:

&gt; it would not count as transition
&gt; https://release.debian.org/bullseye/freeze_policy.html#transition

Thanks, good to know.

&gt; cu And- I am not hinting that delaying a release until after the
&gt;         start of the transition freeze would be welcome ;-)-reas

Right, if we want to have a good chance to get into the release, we'd
better be quick. 

On a different thread, 

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; Isn't starting a new version with both powerpc64 and aarch64 changes is
&gt; more reasonable? I'm not sure here, if there are a few commits before
&gt; powerpc64 patches then it makes sense to wrap up the current version with
&gt; powerpc64 code.

I think the powerpc64 code is in good shape now, and ready for release. Are
you aware of anything that needs fixing? 

We could aim to have another release in a couple of months, with
optimizations for aarch64 and maybe others too. I don't want to try to
add any new features before the release, if we aim to get done in time
for debian freeze.

And there's also the bcrypt code, added half a year ago, which it would be
nice to get into a released version.

One problem with the current state is that big-endian arm is most likely
broken. I don't want to delay the release for that though, since I'm not
able to fix it. If anyone is able to test and fix, soon would be a good
time for it (but I'd consider a bug-fix release with just those fixes
anytime later).

I'm appending my draft NEWS entries.

Regards,
/Niels

NEWS for the Nettle 3.7 release

	This release adds one new feature, the bcrypt password hashing
	function, and lots of optimizations. The release adds
	PowerPC64 assembly for a few algorithms, resulting in great
	speedups. Benchmarked on a Power9 machine, speedup was 13
	times for AES256-CTR and AES256-GCM, and 3.5 times for Chacha.

	New features:

	* Support for bcrypt, contributed by Stephen R. van den Berg.

	Optimizations:

	* Much faster AES and GCM on PowerPC64 processors supporting
	  the corresponding crypto extensions. Contributed by Mamone
	  Tarsha.

	* Speed of Chacha improved on PowerPC64, x86_64 and ARM Neon.

	* Speed of Salsa20 improved on x86_64 and ARM Neon.

	* Overhaul of some elliptic curve primitives, improving ECDSA
	  signature speed.

	Miscellaneous:

	* Use a few more gmp-6.1 functions: mpn_cnd_add_n,
	  mpn_cnd_sub_n, mpn_cnd_swap. Delete corresponding internal
	  Nettle functions.

	* Convert all assembly files to use the default m4 quote
	  characters.


-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201218171824</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-12-18 17:18:24-0400</timestampReceived><subject>Re: Release of Nettle-3.7?</subject><body>

&gt;
&gt; I think the powerpc64 code is in good shape now, and ready for release. Are
&gt; you aware of anything that needs fixing?
&gt;

No, all what I can think of are a couple of issues that make the powerpc64
code more stable (you can check their merge requests in the repo).


&gt; One problem with the current state is that big-endian arm is most likely
&gt; broken. I don't want to delay the release for that though, since I'm not
&gt; able to fix it. If anyone is able to test and fix, soon would be a good
&gt; time for it (but I'd consider a bug-fix release with just those fixes
&gt; anytime later).
&gt;

I also delayed the big-endian support of GHASH algorithm for Aarch64
because I don't have access to big-endian device for testing. Do you think
using cross-compile and qemu for the test would work? If so I will gladly
contribute with those fixes.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201218182007</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2020-12-18 18:20:07-0400</timestampReceived><subject>Re: Release of Nettle-3.7?</subject><body>

Hi Niels and Maamoun,

On Fri, Dec 18, 2020 at 07:18:24PM +0200, Maamoun TK wrote:

&gt; &gt; One problem with the current state is that big-endian arm is most likely
&gt; &gt; broken. I don't want to delay the release for that though, since I'm not
&gt; &gt; able to fix it. If anyone is able to test and fix, soon would be a good
&gt; &gt; time for it (but I'd consider a bug-fix release with just those fixes
&gt; &gt; anytime later).
With the prospect of a new release on the horizon I finally gave myself
a push and dug into chacha-3core yesterday. Porting over the basic
IF_[LB]E mechanism from chacha-core-internal was easy and fixed up the
first of the three interleaved blocks right away. For the other two I am
still in the process of wrapping my head around how the interleaving
works and how it would need some adjustment for BE.

Don't delay the release on my part because I guess I'm still the only
joker running big-endian arm. ;)

&gt; I also delayed the big-endian support of GHASH algorithm for Aarch64
&gt; because I don't have access to big-endian device for testing. Do you think
&gt; using cross-compile and qemu for the test would work? If so I will gladly
&gt; contribute with those fixes.

qemu-user works nicely for aarch64_be. I used it to semi-natively
compile a whole aarch64 userland. I could dust off pine64 board that is
running that userland now for real-world testing if you like.
-- 
Thanks,
Michael
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201219082509</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-12-19 08:25:09-0400</timestampReceived><subject>Re: Release of Nettle-3.7?</subject><body>

Hi Michael,

On Fri, Dec 18, 2020 at 8:00 PM Michael Weiser &lt;michael@weiser.dinsnail.net&gt;
wrote:

&gt; qemu-user works nicely for aarch64_be. I used it to semi-natively
&gt; compile a whole aarch64 userland. I could dust off pine64 board that is
&gt; running that userland now for real-world testing if you like.
&gt;

Thank you, I will give qemu-user a shot for aarch64_be testing. Also, I
will let you know if I reach a point where real-world testing is needed.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201219085039</emailId><senderName>Amos Jeffries</senderName><senderEmail>squid3@treenet.co.nz</senderEmail><timestampReceived>2020-12-19 08:50:39-0400</timestampReceived><subject>Re: Release of Nettle-3.7?</subject><body>

On 19/12/20 5:29 am, Niels Möller wrote:
&gt; Andreas Metzler writes:
&gt; 
&gt;&gt; it would not count as transition
&gt;&gt; https://release.debian.org/bullseye/freeze_policy.html#transition
&gt; 

...

&gt; 	* Support for bcrypt, contributed by Stephen R. van den Berg.
&gt; 


I would have though this needs a soname bump. Otherwise software built 
to use bcrypt might try to link to the old version with same soname.


Amos
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201219085145</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-12-19 08:51:45-0400</timestampReceived><subject>Re: Release of Nettle-3.7?</subject><body>

Michael Weiser &lt;michael@weiser.dinsnail.net&gt; writes:

&gt; Porting over the basic
&gt; IF_[LB]E mechanism from chacha-core-internal was easy and fixed up the
&gt; first of the three interleaved blocks right away. For the other two I am
&gt; still in the process of wrapping my head around how the interleaving
&gt; works and how it would need some adjustment for BE.

The 3-way functions don't do anything fancy, just each of the three
blocks represented in separate registers, and same instruction sequence
as for the 1-way version, duplicated threee times and interleaved.

The 2-way version (for ARM, that's salsa only) tries to be a bit more
clever, with registers representing either odd or even words from both
blocks.

Not sure how endianness affects the code to move words around.

Byte swapping should go close to the final stores, but after the addition
of the initial state.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201219094454</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-12-19 09:44:54-0400</timestampReceived><subject>Re: Release of Nettle-3.7?</subject><body>

Amos Jeffries &lt;squid3@treenet.co.nz&gt; writes:

&gt; I would have though this needs a soname bump. Otherwise software built
&gt; to use bcrypt might try to link to the old version with same soname.

My understanding is that one usually doesn't bump the soname when adding
new functions. 

I was trying to look at how it has been done in gmp, but there it's all
done via automake/libtool, which makes me slightly confused. But I think
the current soname libgmp10.so dates from gmp-5.0.0 released 10 years
ago, and there's been quite a few new public gmp functions added since
then, e.g., the various mnp_sec_* functions used in Nettle.

Then the soname only ensures that upgrading *the library* doesn't break
installed and working applications. Upgrading an application (to a new
version depending on new library functions) could break, and require
library to be upgraded first. Preventing that kind of breakage has to be
prevented by other means, e.g., dependencies in the packaging system.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201214221225</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-12-14 22:12:25-0400</timestampReceived><subject>[AArch64] Optimize GHASH</subject><body>

I made a merge request in the main repo that enables optimized GHASH on
AArch64 architecture. The implementation is based on Niels M��ller's
enhanced algorithm which yields more speedup on AArch64 arch in
comparison with intel algorithm. Using the Karatsuba algorithm with Intel
algorithm yielded an overhead so I dropped its benchmark result. I'll
attach the file of Intel algorithm implementation here since it's not
include in the MR.

Here is the benchmark result on AArch64:

*---------------------------------------------------------------------------------------------*
| C version       |   Intel algorithm  |   Niels M��ller's enhanced
algorithm  |
|  208 Mbyte/s  |   2781 Mbyte/s   |   3255 Mbyte/s
          |
*---------------------------------------------------------------------------------------------*

This is +17% performance boost of the enhanced algorithm over the Intel
algorithm, it's not as impressive as PowerPC benchmark result but it did a
great job on AArch64 considering PMULL instruction doesn't have
the assistance that vpmsumd offers by multiply four polynomials then
summing.

I tried to avoid using the stack in this implementation so I wrote a
procedure to handle leftovers by just using the registers, let me know if
there's a room for improvement here.

regards,
Mamone

C arm/v8/gcm-hash.asm

ifelse(`
   Copyright (C) 2020 Niels M��ller and Mamone Tarsha
   This file is part of GNU Nettle.

   GNU Nettle is free software: you can redistribute it and/or
   modify it under the terms of either:

     * the GNU Lesser General Public License as published by the Free
       Software Foundation; either version 3 of the License, or (at your
       option) any later version.

   or

     * the GNU General Public License as published by the Free
       Software Foundation; either version 2 of the License, or (at your
       option) any later version.

   or both in parallel, as here.

   GNU Nettle is distributed in the hope that it will be useful,
   but WITHOUT ANY WARRANTY; without even the implied warranty of
   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
   General Public License for more details.

   You should have received copies of the GNU General Public License and
   the GNU Lesser General Public License along with this program.  If
   not, see http://www.gnu.org/licenses/.
')

C gcm_set_key() assigns H value in the middle element of the table
define(`H_Idx', `128')

.file "gcm-hash.asm"

.text

    C void gcm_init_key (union gcm_block *table)

C This function populates the gcm table as the following layout
C
*******************************************************************************
C | H1M = (H1 div x������)||((H1 mod x������) �� (x������+x��� �+x��� �+x������)) div x������
     |
C | H1L = (H1 mod x������)||(((H1 mod x������) �� (x��� �+x��� �+x������)) mod x������) + (H1 div
x������) |
C |
    |
C | H2M = (H2 div x������)||((H2 mod x������) �� (x������+x��� �+x��� �+x������)) div x������
     |
C | H2L = (H2 mod x������)||(((H2 mod x������) �� (x��� �+x��� �+x������)) mod x������) + (H2 div
x������) |
C |
    |
C | H3M = (H3 div x������)||((H3 mod x������) �� (x������+x��� �+x��� �+x������)) div x������
     |
C | H3L = (H3 mod x������)||(((H3 mod x������) �� (x��� �+x��� �+x������)) mod x������) + (H3 div
x������) |
C |
    |
C | H4M = (H3 div x������)||((H4 mod x������) �� (x������+x��� �+x��� �+x������)) div x������
     |
C | H4L = (H3 mod x������)||(((H4 mod x������) �� (x��� �+x��� �+x������)) mod x������) + (H4 div
x������) |
C
*******************************************************************************


define(`TABLE', `x0')

define(`ZERO', `v0')
define(`EMSB', `v1')
define(`POLY', `v2')
define(`B', `v3')

define(`H', `v4')
define(`HQ', `q4')
define(`H_t', `v5')
define(`H2', `v6')
define(`H2_t', `v7')
define(`H3', `v16')
define(`H3_t', `v17')
define(`H4', `v18')
define(`H4_t', `v19')
define(`H_m', `v20')
define(`H_m1', `v21')
define(`H_h', `v22')
define(`H_l', `v23')
define(`RP', `v24')
define(`Ml', `v25')
define(`Mh', `v26')


PROLOGUE(_nettle_gcm_init_key)
    ldr            HQ,[TABLE,#16*H_Idx]
    dup            EMSB.16b,H.b[0]
    rev64          H.16b,H.16b
    mov            x9,#0xC200000000000000
    mov            x10,#1
    mov            POLY.d[0],x9
    mov            POLY.d[1],x10
    sshr           EMSB.16b,EMSB.16b,#7
    and            EMSB.16b,EMSB.16b,POLY.16b
    ushr           B.2d,H.2d,#63
    and            B.16b,B.16b,POLY.16b
    ext            B.16b,B.16b,B.16b,#8
    shl            H.2d,H.2d,#1
    orr            H.16b,H.16b,B.16b
    eor            H.16b,H.16b,EMSB.16b

    eor            ZERO.16b,ZERO.16b,ZERO.16b
    dup            POLY.2d,POLY.d[0]
    ext            H_t.16b,H.16b,H.16b,#8

    pmull          H_m.1q,H.1d,H_t.1d
    pmull2         H_m1.1q,H.2d,H_t.2d
    pmull          H_h.1q,H.1d,H.1d
    pmull2         H_l.1q,H.2d,H.2d

    eor            H_m.16b,H_m.16b,H_m1.16b
    pmull          RP.1q,H_l.1d,POLY.1d
    ext            Ml.16b,ZERO.16b,H_m.16b,#8
    ext            Mh.16b,H_m.16b,ZERO.16b,#8
    ext            RP.16b,RP.16b,RP.16b,#8
    eor            H_l.16b,H_l.16b,Ml.16b
    eor            H_h.16b,H_h.16b,Mh.16b
    eor            H_l.16b,H_l.16b,RP.16b

    pmull2         RP.1q,H_l.2d,POLY.2d
    eor            H_h.16b,H_h.16b,H_l.16b
    eor            H2_t.16b,H_h.16b,RP.16b
    ext            H2.16b,H2_t.16b,H2_t.16b,#8

    st1            {H.16b,H_t.16b,H2.16b,H2_t.16b},[TABLE],#64

    pmull          H_m.1q,H.1d,H2_t.1d
    pmull2         H_m1.1q,H.2d,H2_t.2d
    pmull          H_h.1q,H.1d,H2.1d
    pmull2         H_l.1q,H.2d,H2.2d

    eor            H_m.16b,H_m.16b,H_m1.16b
    pmull          RP.1q,H_l.1d,POLY.1d
    ext            Ml.16b,ZERO.16b,H_m.16b,#8
    ext            Mh.16b,H_m.16b,ZERO.16b,#8
    ext            RP.16b,RP.16b,RP.16b,#8
    eor            H_l.16b,H_l.16b,Ml.16b
    eor            H_h.16b,H_h.16b,Mh.16b
    eor            H_l.16b,H_l.16b,RP.16b

    pmull2         RP.1q,H_l.2d,POLY.2d
    eor            H_h.16b,H_h.16b,H_l.16b
    eor            H3_t.16b,H_h.16b,RP.16b
    ext            H3.16b,H3_t.16b,H3_t.16b,#8

    pmull          H_m.1q,H2.1d,H2_t.1d
    pmull2         H_m1.1q,H2.2d,H2_t.2d
    pmull          H_h.1q,H2.1d,H2.1d
    pmull2         H_l.1q,H2.2d,H2.2d

    eor            H_m.16b,H_m.16b,H_m1.16b
    pmull          RP.1q,H_l.1d,POLY.1d
    ext            Ml.16b,ZERO.16b,H_m.16b,#8
    ext            Mh.16b,H_m.16b,ZERO.16b,#8
    ext            RP.16b,RP.16b,RP.16b,#8
    eor            H_l.16b,H_l.16b,Ml.16b
    eor            H_h.16b,H_h.16b,Mh.16b
    eor            H_l.16b,H_l.16b,RP.16b

    pmull2         RP.1q,H_l.2d,POLY.2d
    eor            H_h.16b,H_h.16b,H_l.16b
    eor            H4_t.16b,H_h.16b,RP.16b
    ext            H4.16b,H4_t.16b,H4_t.16b,#8

    st1            {H3.16b,H3_t.16b,H4.16b,H4_t.16b},[TABLE]

    ret
EPILOGUE(_nettle_gcm_init_key)

define(`TABLE', `x0')
define(`X', `x1')
define(`LENGTH', `x2')
define(`DATA', `x3')

define(`POLY', `v0')
define(`ZERO', `v1')

define(`D', `v2')
define(`C0', `v3')
define(`C0D', `d3')
define(`C1', `v4')
define(`C2', `v5')
define(`C3', `v6')
define(`RP', `v7')
define(`H', `v16')
define(`H_t', `v17')
define(`H2', `v18')
define(`H2_t', `v19')
define(`H3', `v20')
define(`H3_t', `v21')
define(`H4', `v22')
define(`H4_t', `v23')
define(`H_m', `v24')
define(`H_m1', `v25')
define(`H_h', `v26')
define(`H_l', `v27')
define(`H_m2', `v28')
define(`H_m3', `v29')
define(`H_h2', `v30')
define(`H_l2', `v31')
define(`Ml', `v4')
define(`Mh', `v5')


    C void gcm_hash (const struct gcm_key *key, union gcm_block *x,
    C                size_t length, const uint8_t *data)

PROLOGUE(_nettle_gcm_hash)
    mov            x10,#0xC200000000000000
    mov            POLY.d[0],x10
    dup            POLY.2d,POLY.d[0]
    eor            ZERO.16b,ZERO.16b,ZERO.16b

    ld1            {D.16b},[X]
    rev64          D.16b,D.16b

    ands           x10,LENGTH,#-64
    b.eq           L2x

    add            x9,TABLE,64
    ld1            {H.16b,H_t.16b,H2.16b,H2_t.16b},[TABLE]
    ld1            {H3.16b,H3_t.16b,H4.16b,H4_t.16b},[x9]

L4x_loop:
    ld1            {C0.16b,C1.16b,C2.16b,C3.16b},[DATA],#64
    rev64          C0.16b,C0.16b
    rev64          C1.16b,C1.16b
    rev64          C2.16b,C2.16b
    rev64          C3.16b,C3.16b

    eor            C0.16b,C0.16b,D.16b

    pmull          H_m.1q,C1.1d,H3_t.1d
    pmull2         H_m1.1q,C1.2d,H3_t.2d
    pmull          H_h.1q,C1.1d,H3.1d
    pmull2         H_l.1q,C1.2d,H3.2d

    pmull          H_m2.1q,C2.1d,H2_t.1d
    pmull2         H_m3.1q,C2.2d,H2_t.2d
    pmull          H_h2.1q,C2.1d,H2.1d
    pmull2         H_l2.1q,C2.2d,H2.2d

    eor            H_m.16b,H_m.16b,H_m2.16b
    eor            H_m1.16b,H_m1.16b,H_m3.16b
    eor            H_h.16b,H_h.16b,H_h2.16b
    eor            H_l.16b,H_l.16b,H_l2.16b

    pmull          H_m2.1q,C3.1d,H_t.1d
    pmull2         H_m3.1q,C3.2d,H_t.2d
    pmull          H_h2.1q,C3.1d,H.1d
    pmull2         H_l2.1q,C3.2d,H.2d

    eor            H_m.16b,H_m.16b,H_m2.16b
    eor            H_m1.16b,H_m1.16b,H_m3.16b
    eor            H_h.16b,H_h.16b,H_h2.16b
    eor            H_l.16b,H_l.16b,H_l2.16b

    pmull          H_m2.1q,C0.1d,H4_t.1d
    pmull2         H_m3.1q,C0.2d,H4_t.2d
    pmull          H_h2.1q,C0.1d,H4.1d
    pmull2         H_l2.1q,C0.2d,H4.2d

    eor            H_m.16b,H_m.16b,H_m2.16b
    eor            H_m1.16b,H_m1.16b,H_m3.16b
    eor            H_h.16b,H_h.16b,H_h2.16b
    eor            H_l.16b,H_l.16b,H_l2.16b

    eor            H_m.16b,H_m.16b,H_m1.16b
    pmull          RP.1q,H_l.1d,POLY.1d
    ext            Ml.16b,ZERO.16b,H_m.16b,#8
    ext            Mh.16b,H_m.16b,ZERO.16b,#8
    ext            RP.16b,RP.16b,RP.16b,#8
    eor            H_l.16b,H_l.16b,Ml.16b
    eor            H_h.16b,H_h.16b,Mh.16b
    eor            H_l.16b,H_l.16b,RP.16b

    pmull2         RP.1q,H_l.2d,POLY.2d
    eor            H_h.16b,H_h.16b,H_l.16b
    eor            D.16b,H_h.16b,RP.16b
    ext            D.16b,D.16b,D.16b,#8

    subs           x10,x10,64
    b.ne           L4x_loop

    and            LENGTH,LENGTH,#63

L2x:
    tst            LENGTH,#-32
    b.eq           L1x

    ld1            {H.16b,H_t.16b,H2.16b,H2_t.16b},[TABLE]

    ld1            {C0.16b,C1.16b},[DATA],#32
    rev64          C0.16b,C0.16b
    rev64          C1.16b,C1.16b

    eor            C0.16b,C0.16b,D.16b

    pmull          H_m.1q,C1.1d,H_t.1d
    pmull2         H_m1.1q,C1.2d,H_t.2d
    pmull          H_h.1q,C1.1d,H.1d
    pmull2         H_l.1q,C1.2d,H.2d

    pmull          H_m2.1q,C0.1d,H2_t.1d
    pmull2         H_m3.1q,C0.2d,H2_t.2d
    pmull          H_h2.1q,C0.1d,H2.1d
    pmull2         H_l2.1q,C0.2d,H2.2d

    eor            H_m.16b,H_m.16b,H_m2.16b
    eor            H_m1.16b,H_m1.16b,H_m3.16b
    eor            H_h.16b,H_h.16b,H_h2.16b
    eor            H_l.16b,H_l.16b,H_l2.16b

    eor            H_m.16b,H_m.16b,H_m1.16b
    pmull          RP.1q,H_l.1d,POLY.1d
    ext            Ml.16b,ZERO.16b,H_m.16b,#8
    ext            Mh.16b,H_m.16b,ZERO.16b,#8
    ext            RP.16b,RP.16b,RP.16b,#8
    eor            H_l.16b,H_l.16b,Ml.16b
    eor            H_h.16b,H_h.16b,Mh.16b
    eor            H_l.16b,H_l.16b,RP.16b

    pmull2         RP.1q,H_l.2d,POLY.2d
    eor            H_h.16b,H_h.16b,H_l.16b
    eor            D.16b,H_h.16b,RP.16b
    ext            D.16b,D.16b,D.16b,#8

    and            LENGTH,LENGTH,#31

L1x:
    tst            LENGTH,#-16
    b.eq           Lmod

    ld1            {H.16b,H_t.16b},[TABLE]

    ld1            {C0.16b},[DATA],#16
    rev64          C0.16b,C0.16b

    eor            C0.16b,C0.16b,D.16b

    pmull          H_m.1q,C0.1d,H_t.1d
    pmull2         H_m1.1q,C0.2d,H_t.2d
    pmull          H_h.1q,C0.1d,H.1d
    pmull2         H_l.1q,C0.2d,H.2d

    eor            H_m.16b,H_m.16b,H_m1.16b
    pmull          RP.1q,H_l.1d,POLY.1d
    ext            Ml.16b,ZERO.16b,H_m.16b,#8
    ext            Mh.16b,H_m.16b,ZERO.16b,#8
    ext            RP.16b,RP.16b,RP.16b,#8
    eor            H_l.16b,H_l.16b,Ml.16b
    eor            H_h.16b,H_h.16b,Mh.16b
    eor            H_l.16b,H_l.16b,RP.16b

    pmull2         RP.1q,H_l.2d,POLY.2d
    eor            H_h.16b,H_h.16b,H_l.16b
    eor            D.16b,H_h.16b,RP.16b
    ext            D.16b,D.16b,D.16b,#8

Lmod:
    tst            LENGTH,#15
    b.eq           Ldone

    ld1            {H.16b,H_t.16b},[TABLE]

    tbz            LENGTH,3,Lmod_8
    ldr            C0D,[DATA],#8
    rev64          C0.16b,C0.16b
    mov            x10,#0
    mov            C0.d[1],x10
Lmod_8:
    tst            LENGTH,#7
    b.eq           Lmod_8_done
    mov            x9,#0
    mov            x8,#64
    and            x7,LENGTH,#7
Lmod_8_loop:
    mov            x10,#0
    ldrb           w10,[DATA],#1
    sub            x8,x8,#8
    lsl            x10,x10,x8
    orr            x9,x9,x10
    subs           x7,x7,#1
    b.ne           Lmod_8_loop
    tbz            LENGTH,3,Lmod_8_load
    mov            C0.d[1],x9
    b              Lmod_8_done
Lmod_8_load:
    mov            x10,#0
    mov            C0.d[0],x9
    mov            C0.d[1],x10
Lmod_8_done:
    eor            C0.16b,C0.16b,D.16b

    pmull          H_m.1q,C0.1d,H_t.1d
    pmull2         H_m1.1q,C0.2d,H_t.2d
    pmull          H_h.1q,C0.1d,H.1d
    pmull2         H_l.1q,C0.2d,H.2d

    eor            H_m.16b,H_m.16b,H_m1.16b
    pmull          RP.1q,H_l.1d,POLY.1d
    ext            Ml.16b,ZERO.16b,H_m.16b,#8
    ext            Mh.16b,H_m.16b,ZERO.16b,#8
    ext            RP.16b,RP.16b,RP.16b,#8
    eor            H_l.16b,H_l.16b,Ml.16b
    eor            H_h.16b,H_h.16b,Mh.16b
    eor            H_l.16b,H_l.16b,RP.16b

    pmull2         RP.1q,H_l.2d,POLY.2d
    eor            H_h.16b,H_h.16b,H_l.16b
    eor            D.16b,H_h.16b,RP.16b
    ext            D.16b,D.16b,D.16b,#8

Ldone:
    rev64          D.16b,D.16b
    st1            {D.16b},[X]
    ret
EPILOGUE(_nettle_gcm_hash)
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201214230033</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-12-14 23:00:33-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

I forgot to mention that I made the benchmark test on gcc17 in GCC Farm.

regards,
Mamone

On Tue, Dec 15, 2020 at 12:12 AM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
wrote:

&gt; I made a merge request in the main repo that enables optimized GHASH on
&gt; AArch64 architecture. The implementation is based on Niels M��ller's
&gt; enhanced algorithm which yields more speedup on AArch64 arch in
&gt; comparison with intel algorithm. Using the Karatsuba algorithm with Intel
&gt; algorithm yielded an overhead so I dropped its benchmark result. I'll
&gt; attach the file of Intel algorithm implementation here since it's not
&gt; include in the MR.
&gt;
&gt; Here is the benchmark result on AArch64:
&gt;
&gt;
&gt; *---------------------------------------------------------------------------------------------*
&gt; | C version       |   Intel algorithm  |   Niels M��ller's enhanced
&gt; algorithm  |
&gt; |  208 Mbyte/s  |   2781 Mbyte/s   |   3255 Mbyte/s
&gt;           |
&gt;
&gt; *---------------------------------------------------------------------------------------------*
&gt;
&gt; This is +17% performance boost of the enhanced algorithm over the Intel
&gt; algorithm, it's not as impressive as PowerPC benchmark result but it did a
&gt; great job on AArch64 considering PMULL instruction doesn't have
&gt; the assistance that vpmsumd offers by multiply four polynomials then
&gt; summing.
&gt;
&gt; I tried to avoid using the stack in this implementation so I wrote a
&gt; procedure to handle leftovers by just using the registers, let me know if
&gt; there's a room for improvement here.
&gt;
&gt; regards,
&gt; Mamone
&gt;
&gt; C arm/v8/gcm-hash.asm
&gt;
&gt; ifelse(`
&gt;    Copyright (C) 2020 Niels M��ller and Mamone Tarsha
&gt;    This file is part of GNU Nettle.
&gt;
&gt;    GNU Nettle is free software: you can redistribute it and/or
&gt;    modify it under the terms of either:
&gt;
&gt;      * the GNU Lesser General Public License as published by the Free
&gt;        Software Foundation; either version 3 of the License, or (at your
&gt;        option) any later version.
&gt;
&gt;    or
&gt;
&gt;      * the GNU General Public License as published by the Free
&gt;        Software Foundation; either version 2 of the License, or (at your
&gt;        option) any later version.
&gt;
&gt;    or both in parallel, as here.
&gt;
&gt;    GNU Nettle is distributed in the hope that it will be useful,
&gt;    but WITHOUT ANY WARRANTY; without even the implied warranty of
&gt;    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
&gt;    General Public License for more details.
&gt;
&gt;    You should have received copies of the GNU General Public License and
&gt;    the GNU Lesser General Public License along with this program.  If
&gt;    not, see http://www.gnu.org/licenses/.
&gt; ')
&gt;
&gt; C gcm_set_key() assigns H value in the middle element of the table
&gt; define(`H_Idx', `128')
&gt;
&gt; .file "gcm-hash.asm"
&gt;
&gt; .text
&gt;
&gt;     C void gcm_init_key (union gcm_block *table)
&gt;
&gt; C This function populates the gcm table as the following layout
&gt; C
&gt; *******************************************************************************
&gt; C | H1M = (H1 div x������)||((H1 mod x������) �� (x������+x��� �+x��� �+x������)) div x������
&gt;      |
&gt; C | H1L = (H1 mod x������)||(((H1 mod x������) �� (x��� �+x��� �+x������)) mod x������) + (H1 div
&gt; x������) |
&gt; C |
&gt;       |
&gt; C | H2M = (H2 div x������)||((H2 mod x������) �� (x������+x��� �+x��� �+x������)) div x������
&gt;      |
&gt; C | H2L = (H2 mod x������)||(((H2 mod x������) �� (x��� �+x��� �+x������)) mod x������) + (H2 div
&gt; x������) |
&gt; C |
&gt;       |
&gt; C | H3M = (H3 div x������)||((H3 mod x������) �� (x������+x��� �+x��� �+x������)) div x������
&gt;      |
&gt; C | H3L = (H3 mod x������)||(((H3 mod x������) �� (x��� �+x��� �+x������)) mod x������) + (H3 div
&gt; x������) |
&gt; C |
&gt;       |
&gt; C | H4M = (H3 div x������)||((H4 mod x������) �� (x������+x��� �+x��� �+x������)) div x������
&gt;      |
&gt; C | H4L = (H3 mod x������)||(((H4 mod x������) �� (x��� �+x��� �+x������)) mod x������) + (H4 div
&gt; x������) |
&gt; C
&gt; *******************************************************************************
&gt;
&gt;
&gt; define(`TABLE', `x0')
&gt;
&gt; define(`ZERO', `v0')
&gt; define(`EMSB', `v1')
&gt; define(`POLY', `v2')
&gt; define(`B', `v3')
&gt;
&gt; define(`H', `v4')
&gt; define(`HQ', `q4')
&gt; define(`H_t', `v5')
&gt; define(`H2', `v6')
&gt; define(`H2_t', `v7')
&gt; define(`H3', `v16')
&gt; define(`H3_t', `v17')
&gt; define(`H4', `v18')
&gt; define(`H4_t', `v19')
&gt; define(`H_m', `v20')
&gt; define(`H_m1', `v21')
&gt; define(`H_h', `v22')
&gt; define(`H_l', `v23')
&gt; define(`RP', `v24')
&gt; define(`Ml', `v25')
&gt; define(`Mh', `v26')
&gt;
&gt;
&gt; PROLOGUE(_nettle_gcm_init_key)
&gt;     ldr            HQ,[TABLE,#16*H_Idx]
&gt;     dup            EMSB.16b,H.b[0]
&gt;     rev64          H.16b,H.16b
&gt;     mov            x9,#0xC200000000000000
&gt;     mov            x10,#1
&gt;     mov            POLY.d[0],x9
&gt;     mov            POLY.d[1],x10
&gt;     sshr           EMSB.16b,EMSB.16b,#7
&gt;     and            EMSB.16b,EMSB.16b,POLY.16b
&gt;     ushr           B.2d,H.2d,#63
&gt;     and            B.16b,B.16b,POLY.16b
&gt;     ext            B.16b,B.16b,B.16b,#8
&gt;     shl            H.2d,H.2d,#1
&gt;     orr            H.16b,H.16b,B.16b
&gt;     eor            H.16b,H.16b,EMSB.16b
&gt;
&gt;     eor            ZERO.16b,ZERO.16b,ZERO.16b
&gt;     dup            POLY.2d,POLY.d[0]
&gt;     ext            H_t.16b,H.16b,H.16b,#8
&gt;
&gt;     pmull          H_m.1q,H.1d,H_t.1d
&gt;     pmull2         H_m1.1q,H.2d,H_t.2d
&gt;     pmull          H_h.1q,H.1d,H.1d
&gt;     pmull2         H_l.1q,H.2d,H.2d
&gt;
&gt;     eor            H_m.16b,H_m.16b,H_m1.16b
&gt;     pmull          RP.1q,H_l.1d,POLY.1d
&gt;     ext            Ml.16b,ZERO.16b,H_m.16b,#8
&gt;     ext            Mh.16b,H_m.16b,ZERO.16b,#8
&gt;     ext            RP.16b,RP.16b,RP.16b,#8
&gt;     eor            H_l.16b,H_l.16b,Ml.16b
&gt;     eor            H_h.16b,H_h.16b,Mh.16b
&gt;     eor            H_l.16b,H_l.16b,RP.16b
&gt;
&gt;     pmull2         RP.1q,H_l.2d,POLY.2d
&gt;     eor            H_h.16b,H_h.16b,H_l.16b
&gt;     eor            H2_t.16b,H_h.16b,RP.16b
&gt;     ext            H2.16b,H2_t.16b,H2_t.16b,#8
&gt;
&gt;     st1            {H.16b,H_t.16b,H2.16b,H2_t.16b},[TABLE],#64
&gt;
&gt;     pmull          H_m.1q,H.1d,H2_t.1d
&gt;     pmull2         H_m1.1q,H.2d,H2_t.2d
&gt;     pmull          H_h.1q,H.1d,H2.1d
&gt;     pmull2         H_l.1q,H.2d,H2.2d
&gt;
&gt;     eor            H_m.16b,H_m.16b,H_m1.16b
&gt;     pmull          RP.1q,H_l.1d,POLY.1d
&gt;     ext            Ml.16b,ZERO.16b,H_m.16b,#8
&gt;     ext            Mh.16b,H_m.16b,ZERO.16b,#8
&gt;     ext            RP.16b,RP.16b,RP.16b,#8
&gt;     eor            H_l.16b,H_l.16b,Ml.16b
&gt;     eor            H_h.16b,H_h.16b,Mh.16b
&gt;     eor            H_l.16b,H_l.16b,RP.16b
&gt;
&gt;     pmull2         RP.1q,H_l.2d,POLY.2d
&gt;     eor            H_h.16b,H_h.16b,H_l.16b
&gt;     eor            H3_t.16b,H_h.16b,RP.16b
&gt;     ext            H3.16b,H3_t.16b,H3_t.16b,#8
&gt;
&gt;     pmull          H_m.1q,H2.1d,H2_t.1d
&gt;     pmull2         H_m1.1q,H2.2d,H2_t.2d
&gt;     pmull          H_h.1q,H2.1d,H2.1d
&gt;     pmull2         H_l.1q,H2.2d,H2.2d
&gt;
&gt;     eor            H_m.16b,H_m.16b,H_m1.16b
&gt;     pmull          RP.1q,H_l.1d,POLY.1d
&gt;     ext            Ml.16b,ZERO.16b,H_m.16b,#8
&gt;     ext            Mh.16b,H_m.16b,ZERO.16b,#8
&gt;     ext            RP.16b,RP.16b,RP.16b,#8
&gt;     eor            H_l.16b,H_l.16b,Ml.16b
&gt;     eor            H_h.16b,H_h.16b,Mh.16b
&gt;     eor            H_l.16b,H_l.16b,RP.16b
&gt;
&gt;     pmull2         RP.1q,H_l.2d,POLY.2d
&gt;     eor            H_h.16b,H_h.16b,H_l.16b
&gt;     eor            H4_t.16b,H_h.16b,RP.16b
&gt;     ext            H4.16b,H4_t.16b,H4_t.16b,#8
&gt;
&gt;     st1            {H3.16b,H3_t.16b,H4.16b,H4_t.16b},[TABLE]
&gt;
&gt;     ret
&gt; EPILOGUE(_nettle_gcm_init_key)
&gt;
&gt; define(`TABLE', `x0')
&gt; define(`X', `x1')
&gt; define(`LENGTH', `x2')
&gt; define(`DATA', `x3')
&gt;
&gt; define(`POLY', `v0')
&gt; define(`ZERO', `v1')
&gt;
&gt; define(`D', `v2')
&gt; define(`C0', `v3')
&gt; define(`C0D', `d3')
&gt; define(`C1', `v4')
&gt; define(`C2', `v5')
&gt; define(`C3', `v6')
&gt; define(`RP', `v7')
&gt; define(`H', `v16')
&gt; define(`H_t', `v17')
&gt; define(`H2', `v18')
&gt; define(`H2_t', `v19')
&gt; define(`H3', `v20')
&gt; define(`H3_t', `v21')
&gt; define(`H4', `v22')
&gt; define(`H4_t', `v23')
&gt; define(`H_m', `v24')
&gt; define(`H_m1', `v25')
&gt; define(`H_h', `v26')
&gt; define(`H_l', `v27')
&gt; define(`H_m2', `v28')
&gt; define(`H_m3', `v29')
&gt; define(`H_h2', `v30')
&gt; define(`H_l2', `v31')
&gt; define(`Ml', `v4')
&gt; define(`Mh', `v5')
&gt;
&gt;
&gt;     C void gcm_hash (const struct gcm_key *key, union gcm_block *x,
&gt;     C                size_t length, const uint8_t *data)
&gt;
&gt; PROLOGUE(_nettle_gcm_hash)
&gt;     mov            x10,#0xC200000000000000
&gt;     mov            POLY.d[0],x10
&gt;     dup            POLY.2d,POLY.d[0]
&gt;     eor            ZERO.16b,ZERO.16b,ZERO.16b
&gt;
&gt;     ld1            {D.16b},[X]
&gt;     rev64          D.16b,D.16b
&gt;
&gt;     ands           x10,LENGTH,#-64
&gt;     b.eq           L2x
&gt;
&gt;     add            x9,TABLE,64
&gt;     ld1            {H.16b,H_t.16b,H2.16b,H2_t.16b},[TABLE]
&gt;     ld1            {H3.16b,H3_t.16b,H4.16b,H4_t.16b},[x9]
&gt;
&gt; L4x_loop:
&gt;     ld1            {C0.16b,C1.16b,C2.16b,C3.16b},[DATA],#64
&gt;     rev64          C0.16b,C0.16b
&gt;     rev64          C1.16b,C1.16b
&gt;     rev64          C2.16b,C2.16b
&gt;     rev64          C3.16b,C3.16b
&gt;
&gt;     eor            C0.16b,C0.16b,D.16b
&gt;
&gt;     pmull          H_m.1q,C1.1d,H3_t.1d
&gt;     pmull2         H_m1.1q,C1.2d,H3_t.2d
&gt;     pmull          H_h.1q,C1.1d,H3.1d
&gt;     pmull2         H_l.1q,C1.2d,H3.2d
&gt;
&gt;     pmull          H_m2.1q,C2.1d,H2_t.1d
&gt;     pmull2         H_m3.1q,C2.2d,H2_t.2d
&gt;     pmull          H_h2.1q,C2.1d,H2.1d
&gt;     pmull2         H_l2.1q,C2.2d,H2.2d
&gt;
&gt;     eor            H_m.16b,H_m.16b,H_m2.16b
&gt;     eor            H_m1.16b,H_m1.16b,H_m3.16b
&gt;     eor            H_h.16b,H_h.16b,H_h2.16b
&gt;     eor            H_l.16b,H_l.16b,H_l2.16b
&gt;
&gt;     pmull          H_m2.1q,C3.1d,H_t.1d
&gt;     pmull2         H_m3.1q,C3.2d,H_t.2d
&gt;     pmull          H_h2.1q,C3.1d,H.1d
&gt;     pmull2         H_l2.1q,C3.2d,H.2d
&gt;
&gt;     eor            H_m.16b,H_m.16b,H_m2.16b
&gt;     eor            H_m1.16b,H_m1.16b,H_m3.16b
&gt;     eor            H_h.16b,H_h.16b,H_h2.16b
&gt;     eor            H_l.16b,H_l.16b,H_l2.16b
&gt;
&gt;     pmull          H_m2.1q,C0.1d,H4_t.1d
&gt;     pmull2         H_m3.1q,C0.2d,H4_t.2d
&gt;     pmull          H_h2.1q,C0.1d,H4.1d
&gt;     pmull2         H_l2.1q,C0.2d,H4.2d
&gt;
&gt;     eor            H_m.16b,H_m.16b,H_m2.16b
&gt;     eor            H_m1.16b,H_m1.16b,H_m3.16b
&gt;     eor            H_h.16b,H_h.16b,H_h2.16b
&gt;     eor            H_l.16b,H_l.16b,H_l2.16b
&gt;
&gt;     eor            H_m.16b,H_m.16b,H_m1.16b
&gt;     pmull          RP.1q,H_l.1d,POLY.1d
&gt;     ext            Ml.16b,ZERO.16b,H_m.16b,#8
&gt;     ext            Mh.16b,H_m.16b,ZERO.16b,#8
&gt;     ext            RP.16b,RP.16b,RP.16b,#8
&gt;     eor            H_l.16b,H_l.16b,Ml.16b
&gt;     eor            H_h.16b,H_h.16b,Mh.16b
&gt;     eor            H_l.16b,H_l.16b,RP.16b
&gt;
&gt;     pmull2         RP.1q,H_l.2d,POLY.2d
&gt;     eor            H_h.16b,H_h.16b,H_l.16b
&gt;     eor            D.16b,H_h.16b,RP.16b
&gt;     ext            D.16b,D.16b,D.16b,#8
&gt;
&gt;     subs           x10,x10,64
&gt;     b.ne           L4x_loop
&gt;
&gt;     and            LENGTH,LENGTH,#63
&gt;
&gt; L2x:
&gt;     tst            LENGTH,#-32
&gt;     b.eq           L1x
&gt;
&gt;     ld1            {H.16b,H_t.16b,H2.16b,H2_t.16b},[TABLE]
&gt;
&gt;     ld1            {C0.16b,C1.16b},[DATA],#32
&gt;     rev64          C0.16b,C0.16b
&gt;     rev64          C1.16b,C1.16b
&gt;
&gt;     eor            C0.16b,C0.16b,D.16b
&gt;
&gt;     pmull          H_m.1q,C1.1d,H_t.1d
&gt;     pmull2         H_m1.1q,C1.2d,H_t.2d
&gt;     pmull          H_h.1q,C1.1d,H.1d
&gt;     pmull2         H_l.1q,C1.2d,H.2d
&gt;
&gt;     pmull          H_m2.1q,C0.1d,H2_t.1d
&gt;     pmull2         H_m3.1q,C0.2d,H2_t.2d
&gt;     pmull          H_h2.1q,C0.1d,H2.1d
&gt;     pmull2         H_l2.1q,C0.2d,H2.2d
&gt;
&gt;     eor            H_m.16b,H_m.16b,H_m2.16b
&gt;     eor            H_m1.16b,H_m1.16b,H_m3.16b
&gt;     eor            H_h.16b,H_h.16b,H_h2.16b
&gt;     eor            H_l.16b,H_l.16b,H_l2.16b
&gt;
&gt;     eor            H_m.16b,H_m.16b,H_m1.16b
&gt;     pmull          RP.1q,H_l.1d,POLY.1d
&gt;     ext            Ml.16b,ZERO.16b,H_m.16b,#8
&gt;     ext            Mh.16b,H_m.16b,ZERO.16b,#8
&gt;     ext            RP.16b,RP.16b,RP.16b,#8
&gt;     eor            H_l.16b,H_l.16b,Ml.16b
&gt;     eor            H_h.16b,H_h.16b,Mh.16b
&gt;     eor            H_l.16b,H_l.16b,RP.16b
&gt;
&gt;     pmull2         RP.1q,H_l.2d,POLY.2d
&gt;     eor            H_h.16b,H_h.16b,H_l.16b
&gt;     eor            D.16b,H_h.16b,RP.16b
&gt;     ext            D.16b,D.16b,D.16b,#8
&gt;
&gt;     and            LENGTH,LENGTH,#31
&gt;
&gt; L1x:
&gt;     tst            LENGTH,#-16
&gt;     b.eq           Lmod
&gt;
&gt;     ld1            {H.16b,H_t.16b},[TABLE]
&gt;
&gt;     ld1            {C0.16b},[DATA],#16
&gt;     rev64          C0.16b,C0.16b
&gt;
&gt;     eor            C0.16b,C0.16b,D.16b
&gt;
&gt;     pmull          H_m.1q,C0.1d,H_t.1d
&gt;     pmull2         H_m1.1q,C0.2d,H_t.2d
&gt;     pmull          H_h.1q,C0.1d,H.1d
&gt;     pmull2         H_l.1q,C0.2d,H.2d
&gt;
&gt;     eor            H_m.16b,H_m.16b,H_m1.16b
&gt;     pmull          RP.1q,H_l.1d,POLY.1d
&gt;     ext            Ml.16b,ZERO.16b,H_m.16b,#8
&gt;     ext            Mh.16b,H_m.16b,ZERO.16b,#8
&gt;     ext            RP.16b,RP.16b,RP.16b,#8
&gt;     eor            H_l.16b,H_l.16b,Ml.16b
&gt;     eor            H_h.16b,H_h.16b,Mh.16b
&gt;     eor            H_l.16b,H_l.16b,RP.16b
&gt;
&gt;     pmull2         RP.1q,H_l.2d,POLY.2d
&gt;     eor            H_h.16b,H_h.16b,H_l.16b
&gt;     eor            D.16b,H_h.16b,RP.16b
&gt;     ext            D.16b,D.16b,D.16b,#8
&gt;
&gt; Lmod:
&gt;     tst            LENGTH,#15
&gt;     b.eq           Ldone
&gt;
&gt;     ld1            {H.16b,H_t.16b},[TABLE]
&gt;
&gt;     tbz            LENGTH,3,Lmod_8
&gt;     ldr            C0D,[DATA],#8
&gt;     rev64          C0.16b,C0.16b
&gt;     mov            x10,#0
&gt;     mov            C0.d[1],x10
&gt; Lmod_8:
&gt;     tst            LENGTH,#7
&gt;     b.eq           Lmod_8_done
&gt;     mov            x9,#0
&gt;     mov            x8,#64
&gt;     and            x7,LENGTH,#7
&gt; Lmod_8_loop:
&gt;     mov            x10,#0
&gt;     ldrb           w10,[DATA],#1
&gt;     sub            x8,x8,#8
&gt;     lsl            x10,x10,x8
&gt;     orr            x9,x9,x10
&gt;     subs           x7,x7,#1
&gt;     b.ne           Lmod_8_loop
&gt;     tbz            LENGTH,3,Lmod_8_load
&gt;     mov            C0.d[1],x9
&gt;     b              Lmod_8_done
&gt; Lmod_8_load:
&gt;     mov            x10,#0
&gt;     mov            C0.d[0],x9
&gt;     mov            C0.d[1],x10
&gt; Lmod_8_done:
&gt;     eor            C0.16b,C0.16b,D.16b
&gt;
&gt;     pmull          H_m.1q,C0.1d,H_t.1d
&gt;     pmull2         H_m1.1q,C0.2d,H_t.2d
&gt;     pmull          H_h.1q,C0.1d,H.1d
&gt;     pmull2         H_l.1q,C0.2d,H.2d
&gt;
&gt;     eor            H_m.16b,H_m.16b,H_m1.16b
&gt;     pmull          RP.1q,H_l.1d,POLY.1d
&gt;     ext            Ml.16b,ZERO.16b,H_m.16b,#8
&gt;     ext            Mh.16b,H_m.16b,ZERO.16b,#8
&gt;     ext            RP.16b,RP.16b,RP.16b,#8
&gt;     eor            H_l.16b,H_l.16b,Ml.16b
&gt;     eor            H_h.16b,H_h.16b,Mh.16b
&gt;     eor            H_l.16b,H_l.16b,RP.16b
&gt;
&gt;     pmull2         RP.1q,H_l.2d,POLY.2d
&gt;     eor            H_h.16b,H_h.16b,H_l.16b
&gt;     eor            D.16b,H_h.16b,RP.16b
&gt;     ext            D.16b,D.16b,D.16b,#8
&gt;
&gt; Ldone:
&gt;     rev64          D.16b,D.16b
&gt;     st1            {D.16b},[X]
&gt;     ret
&gt; EPILOGUE(_nettle_gcm_hash)
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201217080836</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-12-17 08:08:36-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; I made a merge request in the main repo that enables optimized GHASH on
&gt; AArch64 architecture.

Nice! I've had a quick first look. For the organization, I think aarch64
assembly should go in it's own directory, arm64/, like it's done for x86
and sparc.

I wonder which assembly files we should use if target host is aarch64,
but ABI=32? I guess the arm/v6/ code can be used unconditionally. Can
we also use arm/neon/ code unconditionally?

Do you agre with aiming for a release pretty soon, including the new
powerpc64 code, but no aarch64 code?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201219094857</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-12-19 09:48:57-0400</timestampReceived><subject>Re: Release of Nettle-3.7?</subject><body>

On Sat, Dec 19, 2020 at 4:44 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; Amos Jeffries &lt;squid3@treenet.co.nz&gt; writes:
&gt;
&gt; &gt; I would have though this needs a soname bump. Otherwise software built
&gt; &gt; to use bcrypt might try to link to the old version with same soname.
&gt;
&gt; My understanding is that one usually doesn't bump the soname when adding
&gt; new functions.

Also see https://www.gnu.org/software/libtool/manual/html_node/Updating-version-info.html.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201219100205</emailId><senderName>Andreas Metzler</senderName><senderEmail>ametzler@bebt.de</senderEmail><timestampReceived>2020-12-19 10:02:05-0400</timestampReceived><subject>Re: Release of Nettle-3.7?</subject><body>

On 2020-12-19 Niels Möller wrote:
&gt; Amos Jeffries &lt;squid3@treenet.co.nz&gt; writes:

&gt; &gt; I would have though this needs a soname bump. Otherwise software built
&gt; &gt; to use bcrypt might try to link to the old version with same soname.

&gt; My understanding is that one usually doesn't bump the soname when adding
&gt; new functions. 

[...]
&gt; Then the soname only ensures that upgrading *the library* doesn't break
&gt; installed and working applications. Upgrading an application (to a new
&gt; version depending on new library functions) could break, and require
&gt; library to be upgraded first. Preventing that kind of breakage has to be
&gt; prevented by other means, e.g., dependencies in the packaging system.

Hello Niels,

that mirrors my understanding perfectly. Adding functions does not
require a soname bump; removing functions or changing the number or
type of arguments a function expects does[1].

cu Andreas

[1] With versioned symbols a library can provide both the old version of
a symbol for applications built against earlier library versions and the
newer interface for freshly linked apps to avoid breaking legacy apps
and therefore avoid a soname bump in most cases. However this effort
only pays off when a soname bump would bring loads of pain, i.e. glibc.
-- 
`What a good friend you are to him, Dr. Maturin. His other friends are
so grateful to you.'
`I sew his ears on from time to time, sure'
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201219100650</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-12-19 10:06:50-0400</timestampReceived><subject>Re: Release of Nettle-3.7?</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; Also see https://www.gnu.org/software/libtool/manual/html_node/Updating-version-info.html.

It's not entirely clear to me how libtool versions maps to soname, but
from looking at GMP, I guess the number embedded in the soname is
current - age. So for gmp-6.1.2, the libtool version is 13:2:3, current
- age = 13 - 3 = 10, and soname is libgmp10.so.

Is that right? If so, the case

2. Programs using the previous version may use the new version as
   drop-in replacement, but programs using the new version may use APIs
   not present in the previous one. In other words, a program linking
   against the new version may fail with "unresolved symbols" if linking
   against the old version at runtime: set revision to 0, bump current
   and age.

would always leave soname unchanged, since the bump of both current and
age cancel out when construction the soname.

The recent release of gmp-6.2.0 is of this form, and has libtool version
14:0:4, 14 - 4 = 10.

Am I getting the libtool covnentions right?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201221184535</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2020-12-21 18:45:35-0400</timestampReceived><subject>Re: Release of Nettle-3.7?</subject><body>

Hello Niels,

On Sat, Dec 19, 2020 at 09:51:45AM +0100, Niels Möller wrote:

&gt; &gt; Porting over the basic
&gt; &gt; IF_[LB]E mechanism from chacha-core-internal was easy and fixed up the
&gt; &gt; first of the three interleaved blocks right away. For the other two I am
&gt; &gt; still in the process of wrapping my head around how the interleaving
&gt; &gt; works and how it would need some adjustment for BE.
&gt; The 3-way functions don't do anything fancy, just each of the three
&gt; blocks represented in separate registers, and same instruction sequence
&gt; as for the 1-way version, duplicated threee times and interleaved.

I've got the tests passing for chacha now. Apart from the
straightforward porting-over of the BE shift and reverse-on-store logic
from chacha20-core-internal.asm special treatment is necessary for the
part of the state that's treated as a 64-bit counter. The two 32-bit
words it's comprised of are in host-endianness but consecutive order. So
they get reversed by the BE load. This is actually the case for all
32-bit operands throughout the routine on BE (and for
chacha-core-internal also) and cancels itself out on the final store.
But for the 64-bit counter it needs to be taken into account for the
addition to produce correct results.

See the attached patch for my current approach to fixing it, which is
explicit transposing, adding and then transposing again to be as
transposed as the other operands. I wonder if the surrounding C code
could be changed to supply that part of the state as a 64-bit doubleword
in host endianness to the assembler routine to cut down on adjustment.

Alternatively, could the 64-bit operation be broken down into two 32-bit
operations which implicitly adjust to the transposed 32-bit words on BE?

&gt; The 2-way version (for ARM, that's salsa only) tries to be a bit more
&gt; clever, with registers representing either odd or even words from both
&gt; blocks.

For a start this also needs adjustment for the 64-bit counter treatment.

&gt; Not sure how endianness affects the code to move words around.

The routine "suffers" from the same effect as chacha: The 32-bit input
operands are in host order in memory and their individual values end up
correctly in the registers. But since vldm loads consecutive 64-bit
values, it ends up transposing 32-bit words that comprise the 64-bit
register value. After the initial swap and transpose operations, the X
and Y matrices are basically correctly filled but flipped two ways.

I've tried to document what I see in the registers on armeb to get a
handle on how to proceed:

 	vtrn.32	X0, Y3		C X0:  0  0  2  2  Y3:  1  1  3  3
 	vtrn.32	X1, Y0		C X1:  4  4  6  6  Y0:  5  5  7  7
-	vtrn.32	X2, Y1		C X2:  8  8 10 10  Y1:  9  9  1  1 &lt;- typo?
+	vtrn.32	X2, Y1		C X2:  8  8 10 10  Y1:  9  9 11 11
 	vtrn.32	X3, Y2		C X3: 12 12 14 14  Y2: 13 13 15 15
+				C BE:
+				C X0:  3  3  1  1  Y3:  2  2  0  0
+				C X1:  7  7  5  5  Y0:  6  6  4  4
+				C X2: 11 11  9  9  Y1: 10 10  8  8
+				C X3: 15 15 13 13  Y2: 14 14 12 12
 
 
        C Swap, to get
        C X0:  0 10  Y0:  5 15
        C X1:  4 14  Y1:  9  3
        C X2:  8  2  Y2: 13  7
        C X3: 12  6  Y3:  1 11
        vswp    D1REG(X0), D1REG(X2)
        vswp    D1REG(X1), D1REG(X3)
        vswp    D1REG(Y0), D1REG(Y2)
        vswp    D1REG(Y1), D1REG(Y3)

+	C BE:
+	C X0: 11  1  Y0: 14  4
+	C X1: 15  5  Y1:  2  8
+	C X2:  3  9  Y2:  6 12
+	C X3:  7 13  Y3: 10  0

I wonder if the code working on them contains some symmetry that could
be exploited to (with minimal changes) get correct results on these
transposed matrices.

Otherwise I wonder if it would be possible for both chacha and salsa to
change the actual loading and storing so there's no transposing of
32-bit operands. I looked at vld4.32 but that does some fancy
de-interleaving and needs two operations to load four q registers.

Otherwise we'd need a lot of vrev64.u32s to basically revert the 32-bit
transposition happening upon load and save to end up with identical
matrices to LE.
-- 
Michael

["chacha-3core-armeb.diff" (text/plain)]

diff --git a/arm/neon/chacha-3core.asm b/arm/neon/chacha-3core.asm
index bd1cf63c..14a06a7a 100644
--- a/arm/neon/chacha-3core.asm
+++ b/arm/neon/chacha-3core.asm
@@ -69,8 +69,17 @@ PROLOGUE(_nettle_chacha_3core)
 	adr	r12, .Lcount1
 	vld1.64 {Z3}, [r12]
 
+	C The two words of the state treated as 64-bit counter here appear
+	C reversed to a big-endian machine and need to be switched before
+	C adding to it. Results need to be reverted back so the rest of the
+	C 32-bit operations can be applied as before.
+IF_BE(`	vrev64.u32	Z3, Z3
+	vrev64.u32	X3, X3')
 	vadd.i64	Y3, X3, Z3	C Increment 64-bit counter
 	vadd.i64	Z3, Y3, Z3
+IF_BE(`	vrev64.u32	Z3, Z3
+	vrev64.u32	X3, X3
+	vrev64.u32	Y3, Y3')
 
 .Lshared_entry:
 	vmov	Y0, X0
@@ -122,33 +131,39 @@ PROLOGUE(_nettle_chacha_3core)
 
 	vadd.i32	X2, X2, X3
 	 vsri.u32	Y3, T0, #24
-	  vext.32	X3, X3, X3, #3
+IF_LE(`	  vext.32	X3, X3, X3, #3')
+IF_BE(`	  vext.32	X3, X3, X3, #1')
 	  vshl.i32	Z3, T1, #8
 	veor		T0, X1, X2
 	 vadd.i32	Y2, Y2, Y3
 	  vsri.u32	Z3, T1, #24
-	   vext.32	Y3, Y3, Y3, #3
+IF_LE(`	   vext.32	Y3, Y3, Y3, #3')
+IF_BE(`	   vext.32	Y3, Y3, Y3, #1')
 	vshl.i32	X1, T0, #7
 	 veor		T1, Y1, Y2
 	  vadd.i32	Z2, Z2, Z3
 	vsri.u32	X1, T0, #25
 	 vshl.i32	Y1, T1, #7
 	  veor		T0, Z1, Z2
-	   vext.32	X1, X1, X1, #1
+IF_LE(`	   vext.32	X1, X1, X1, #1')
+IF_BE(`	   vext.32	X1, X1, X1, #3')
 	 vsri.u32	Y1, T1, #25
 	  vshl.i32	Z1, T0, #7
 	   vext.32	Y2, Y2, Y2, #2
-	   vext.32	Y1, Y1, Y1, #1
+IF_LE(`	   vext.32	Y1, Y1, Y1, #1')
+IF_BE(`	   vext.32	Y1, Y1, Y1, #3')
 	  vsri.u32	Z1, T0, #25
 	   vext.32	X2, X2, X2, #2
 
 	C Second QROUND
 	vadd.i32	X0, X0, X1
 	   vext.32	Z2, Z2, Z2, #2
-	   vext.32	Z1, Z1, Z1, #1
+IF_LE(`	   vext.32	Z1, Z1, Z1, #1')
+IF_BE(`	   vext.32	Z1, Z1, Z1, #3')
 	veor		X3, X3, X0
 	 vadd.i32	Y0, Y0, Y1
-	   vext.32	Z3, Z3, Z3, #3
+IF_LE(`	   vext.32	Z3, Z3, Z3, #3')
+IF_BE(`	   vext.32	Z3, Z3, Z3, #1')
 	vrev32.16	X3, X3		C lrot 16
 	 veor		Y3, Y3, Y0
 	  vadd.i32	Z0, Z0, Z1
@@ -181,31 +196,37 @@ PROLOGUE(_nettle_chacha_3core)
 
 	vadd.i32	X2, X2, X3
 	 vsri.u32	Y3, T0, #24
-	   vext.32	X3, X3, X3, #1
+IF_LE(`	   vext.32	X3, X3, X3, #1')
+IF_BE(`	   vext.32	X3, X3, X3, #3')
 	  vshl.i32	Z3, T1, #8
 	veor		T0, X1, X2
 	   vext.32	X2, X2, X2, #2
 	 vadd.i32	Y2, Y2, Y3
-	   vext.32	Y3, Y3, Y3, #1
+IF_LE(`	   vext.32	Y3, Y3, Y3, #1')
+IF_BE(`	   vext.32	Y3, Y3, Y3, #3')
 	  vsri.u32	Z3, T1, #24
 	vshl.i32	X1, T0, #7
 	 veor		T1, Y1, Y2
 	   vext.32	Y2, Y2, Y2, #2
 	  vadd.i32	Z2, Z2, Z3
-	   vext.32	Z3, Z3, Z3, #1
+IF_LE(`	   vext.32	Z3, Z3, Z3, #1')
+IF_BE(`	   vext.32	Z3, Z3, Z3, #3')
 	vsri.u32	X1, T0, #25
 	 vshl.i32	Y1, T1, #7
 	  veor		T0, Z1, Z2
 	   vext.32	Z2, Z2, Z2, #2
-	   vext.32	X1, X1, X1, #3
+IF_LE(`	   vext.32	X1, X1, X1, #3')
+IF_BE(`	   vext.32	X1, X1, X1, #1')
 	 vsri.u32	Y1, T1, #25
 	  vshl.i32	Z1, T0, #7
-	   vext.32	Y1, Y1, Y1, #3
+IF_LE(`	   vext.32	Y1, Y1, Y1, #3')
+IF_BE(`	   vext.32	Y1, Y1, Y1, #1')
 	  vsri.u32	Z1, T0, #25
 
 	subs	ROUNDS, ROUNDS, #2
 
-	   vext.32	Z1, Z1, Z1, #3
+IF_LE(`	   vext.32	Z1, Z1, Z1, #3')
+IF_BE(`	   vext.32	Z1, Z1, Z1, #1')
 
 	bhi	.Loop
 
@@ -218,11 +239,23 @@ PROLOGUE(_nettle_chacha_3core)
 	vadd.i32	X1, X1, T1
 	vadd.i32	X2, X2, T2
 	vadd.i32	X3, X3, T3
+
+	C caller expects result little-endian
+IF_BE(`	vrev32.u8	X0, X0
+	vrev32.u8	X1, X1
+	vrev32.u8	X2, X2
+	vrev32.u8	X3, X3')
 	vstmia	DST!, {X0,X1,X2,X3}
 
 	vadd.i32	Y0, Y0, T0
 	vadd.i32	Y1, Y1, T1
 	vadd.i32	Y2, Y2, T2
+
+	C caller expects result little-endian
+IF_BE(`	vrev32.u8	Y0, Y0
+	vrev32.u8	Y1, Y1
+	vrev32.u8	Y2, Y2
+	vrev32.u8	Y3, Y3')
 	vstmia	DST!, {Y0,Y1,Y2,Y3}
 
 	vadd.i32	Z0, Z0, T0
@@ -231,6 +264,11 @@ PROLOGUE(_nettle_chacha_3core)
 
 	vpop	{q4,q5,q6,q7}
 
+	C caller expects result little-endian
+IF_BE(`	vrev32.u8	Z0, Z0
+	vrev32.u8	Z1, Z1
+	vrev32.u8	Z2, Z2
+	vrev32.u8	Z3, Z3')
 	vstm	DST, {Z0,Z1,Z2,Z3}
 	bx	lr
 EPILOGUE(_nettle_chacha_3core)

["salsa20-2core-wip.diff" (text/plain)]

diff --git a/arm/neon/salsa20-2core.asm b/arm/neon/salsa20-2core.asm
index d622edd6..d247800b 100644
--- a/arm/neon/salsa20-2core.asm
+++ b/arm/neon/salsa20-2core.asm
@@ -64,13 +64,22 @@ PROLOGUE(_nettle_salsa20_2core)
 	vmov	Y3, X0
 	vld1.64 {Y1}, [r12]
 	vmov	Y0, X1
+IF_BE(`	vrev64.u32	Y1, Y1
+	vrev64.u32	X2, X2')
 	vadd.i64 Y1, Y1, X2	C Increment counter
+IF_BE(`	vrev64.u32	Y1, Y1
+	vrev64.u32	X2, X2')
 	vmov	Y2, X3
 
 	vtrn.32	X0, Y3		C X0:  0  0  2  2  Y3:  1  1  3  3
 	vtrn.32	X1, Y0		C X1:  4  4  6  6  Y0:  5  5  7  7
-	vtrn.32	X2, Y1		C X2:  8  8 10 10  Y1:  9  9  1  1
+	vtrn.32	X2, Y1		C X2:  8  8 10 10  Y1:  9  9 11 11
 	vtrn.32	X3, Y2		C X3: 12 12 14 14  Y2: 13 13 15 15
+				C BE:
+				C X0:  3  3  1  1  Y3:  2  2  0  0
+				C X1:  7  7  5  5  Y0:  6  6  4  4
+				C X2: 11 11  9  9  Y1: 10 10  8  8
+				C X3: 15 15 13 13  Y2: 14 14 12 12
 
 	C Swap, to get
 	C X0:  0 10  Y0:  5 15
@@ -82,6 +91,12 @@ PROLOGUE(_nettle_salsa20_2core)
 	vswp	D1REG(Y0), D1REG(Y2)
 	vswp	D1REG(Y1), D1REG(Y3)
 
+	C BE:
+	C X0: 11  1  Y0: 14  4
+	C X1: 15  5  Y1:  2  8
+	C X2:  3  9  Y2:  6 12
+	C X3:  7 13  Y3: 10  0
+
 .Loop:
 C Register layout (A is first block, B is second block)
 C
@@ -196,7 +211,11 @@ C Add in the original context
 	vstmia	DST!, {X0,X1,X2,X3}
 	vld1.64 {X0}, [r12]
 	vadd.i32	T0, T0, Y3
+IF_BE(`	vrev64.u32	X0, X0
+	vrev64.u32	T2, T2')
 	vadd.i64	T2, T2, X0
+IF_BE(`	vrev64.u32	X0, X0
+	vrev64.u32	T2, T2')
 	vadd.i32	T1, T1, Y0
 	vadd.i32	T2, T2, Y1
 	vadd.i32	T3, T3, Y2

[Attachment #5 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20201221201625</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-12-21 20:16:25-0400</timestampReceived><subject>Re: Release of Nettle-3.7?</subject><body>

Michael Weiser &lt;michael.weiser@gmx.de&gt; writes:

&gt; See the attached patch for my current approach to fixing it, which is
&gt; explicit transposing, adding and then transposing again to be as
&gt; transposed as the other operands. 

I haven't yet read the code, but I have some comments based on your
description only.

&gt; I wonder if the surrounding C code
&gt; could be changed to supply that part of the state as a 64-bit doubleword
&gt; in host endianness to the assembler routine to cut down on adjustment.

I think it will be a bit cumbersum to change the interface to the C
code.

&gt; Alternatively, could the 64-bit operation be broken down into two 32-bit
&gt; operations which implicitly adjust to the transposed 32-bit words on BE?

Maybe. But we still need to propagate the carry, can that be done in a
better way than transpose, 64-bit add, transpose?

&gt; I've tried to document what I see in the registers on armeb to get a
&gt; handle on how to proceed:
&gt;
&gt;  	vtrn.32	X0, Y3		C X0:  0  0  2  2  Y3:  1  1  3  3
&gt;  	vtrn.32	X1, Y0		C X1:  4  4  6  6  Y0:  5  5  7  7
&gt; -	vtrn.32	X2, Y1		C X2:  8  8 10 10  Y1:  9  9  1  1 &lt;- typo?
&gt; +	vtrn.32	X2, Y1		C X2:  8  8 10 10  Y1:  9  9 11 11

Indeed a typo. I just checked in the fix, thanks!

&gt;  	vtrn.32	X3, Y2		C X3: 12 12 14 14  Y2: 13 13 15 15
&gt; +				C BE:
&gt; +				C X0:  3  3  1  1  Y3:  2  2  0  0
&gt; +				C X1:  7  7  5  5  Y0:  6  6  4  4
&gt; +				C X2: 11 11  9  9  Y1: 10 10  8  8
&gt; +				C X3: 15 15 13 13  Y2: 14 14 12 12

Also, it's somewhat important to keep track of which block a word
belongs to. In the LE code, X0 really is A0 B0 A2 B2, where A refers to
the first block, and B to the second.

What's the layout before the transpose, immediately after load? I'd
guess you get X0: 1 0 3 2?   

For the little endian code, the transpose can be viewed as

  X0:  A0 A1 A2 A3
         /     /    denotes elements swapped.
  Y3:  B0 B1 B2 B3

If instead we start with the order 1 0 3 2, we get the same result (but
with registers swapped) if we do

  Y3:  B1 B0 B3 B2
         \     \
  X0:  A1 A0 A3 A2

So I would expect there's some clever way to get the BE case to work
with about the same number of transpose instructions, even if initial
word order is somewhat different.

&gt; I wonder if the code working on them contains some symmetry that could
&gt; be exploited to (with minimal changes) get correct results on these
&gt; transposed matrices.

At least, both blocks are treated equally (except that the initial
counter addition is done to only the second block, and that the final result
is written in the right order. So it doesn't matter if X0 contains A0 B0
A2 B2 or B0 A0 B2 A2. And unlike the one-way code, we only use 

  vext32 ... #2

to rotate data between rounds, never #1 or #3.

&gt; Otherwise I wonder if it would be possible for both chacha and salsa to
&gt; change the actual loading and storing so there's no transposing of
&gt; 32-bit operands. I looked at vld4.32 but that does some fancy
&gt; de-interleaving and needs two operations to load four q registers.

The new powerpc code uses load and store instructions that behave the
same in this respect, for both BE and LE. But not sure if there's any
easy way on ARM. I'm not that familiar with the more special load and
store instructions. Would vst2.32 be useful in some way for the final
store (and vst3.32 for chacha-3core)?

&gt; Otherwise we'd need a lot of vrev64.u32s to basically revert the 32-bit
&gt; transposition happening upon load and save to end up with identical
&gt; matrices to LE.

If that's an easier way to get it working, I think it's a good start.
I'd expect that's still give a reasonable speedup over the 1-way
version.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201225170248</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2020-12-25 17:02:48-0400</timestampReceived><subject>Re: Release of Nettle-3.7?</subject><body>

Hello Niels,

On Mon, Dec 21, 2020 at 09:16:25PM +0100, Niels Möller wrote:

&gt; What's the layout before the transpose, immediately after load? I'd
&gt; guess you get X1: 1 0 3 2?   

TL;DR: Yes, it is. I abandoned this approach for now though, since I
found some options to eliminate the word transposition effect of
vldm/vstm in the first place (see below).

Longer story for completeness: It seems I ran afoul gdb's way of
displaying registers in memory endianness again. I knew all this once
already.[1] I should likely do this more often than every couple of
years. ;)

[1] https://marc.info/?l=nettle-bugs&amp;m=152436948907236&amp;w=2

On LE I get after the initial load:

Breakpoint 1, _nettle_salsa20_2core () at salsa20-2core.s:39
39              vldm    r1, {q0,q1,q2,q3}
(gdb) s
40              adr     r12, .Lcount1
(gdb) i r q0 q1 q2 q3
q0             {u8 = {0x0, 0x0, 0x0, 0x0, 0x1, 0x0, 0x0, 0x0, 0x2, 0x0, 0x0, 0x0, \
0x3, 0x0, 0x0, 0x0},  u16 = {0x0, 0x0, 0x1, 0x0, 0x2, 0x0, 0x3, 0x0},
		u32 = {0x0, 0x1, 0x2, 0x3},
		u64 = {0x100000000, 0x300000002}, f32 = {0x0, 0x0, 0x0, 0x0}, f64 = {0x0, 0x0}}
q1             {u8 = {0x4, 0x0, 0x0, 0x0, 0x5, 0x0, 0x0, 0x0, 0x6, 0x0, 0x0, 0x0, \
0x7, 0x0, 0x0, 0x0},  u16 = {0x4, 0x0, 0x5, 0x0, 0x6, 0x0, 0x7, 0x0},
		u32 = {0x4, 0x5, 0x6, 0x7},
		u64 = {0x500000004, 0x700000006}, f32 = {0x0, 0x0, 0x0, 0x0}, f64 = {0x0, 0x0}}
q2             {u8 = {0xff, 0xff, 0xff, 0xff, 0x9, 0x0, 0x0, 0x0, 0xa, 0x0, 0x0, 0x0, \
0xb, 0x0, 0x0, 0x0},  u16 = {0xffff, 0xffff, 0x9, 0x0, 0xa, 0x0, 0xb, 0x0},
		u32 = {0xffffffff, 0x9, 0xa, 0xb},
		u64 = {0x9ffffffff, 0xb0000000a}, f32 = {0x0, 0x0, 0x0, 0x0}, f64 = {0x0, 0x0}}
q3             {u8 = {0xc, 0x0, 0x0, 0x0, 0xd, 0x0, 0x0, 0x0, 0xe, 0x0, 0x0, 0x0, \
0xf, 0x0, 0x0, 0x0},  u16 = {0xc, 0x0, 0xd, 0x0, 0xe, 0x0, 0xf, 0x0},
		u32 = {0xc, 0xd, 0xe, 0xf},
		u64 = {0xd0000000c, 0xf0000000e}, f32 = {0x0, 0x0, 0x0, 0x0}, f64 = {0x0, 0x0}}

On the u8 representation we can see that gdb prints them as if they were
stored little-endian in memory. That's why the u32 representaion
actually matches up with our expectations.

On BE I get:

Breakpoint 1, _nettle_salsa20_2core () at salsa20-2core.s:39
39              vldm    r1, {q0,q1,q2,q3}
(gdb) s
40              adr     r12, .Lcount1
(gdb) i r q0 q1 q2 q3
q0             {u8 = {0x0, 0x0, 0x0, 0x2, 0x0, 0x0, 0x0, 0x3, 0x0, 0x0, 0x0, 0x0, \
0x0, 0x0, 0x0, 0x1},  u16 = {0x0, 0x2, 0x0, 0x3, 0x0, 0x0, 0x0, 0x1},
		u32 = {0x2, 0x3, 0x0, 0x1},
		u64 = {0x200000003, 0x1}, f32 = {0x0, 0x0, 0x0, 0x0}, f64 = {0x0, 0x0}}
q1             {u8 = {0x0, 0x0, 0x0, 0x6, 0x0, 0x0, 0x0, 0x7, 0x0, 0x0, 0x0, 0x4, \
0x0, 0x0, 0x0, 0x5},  u16 = {0x0, 0x6, 0x0, 0x7, 0x0, 0x4, 0x0, 0x5},
		u32 = {0x6, 0x7, 0x4, 0x5},
		u64 = {0x600000007, 0x400000005}, f32 = {0x0, 0x0, 0x0, 0x0}, f64 = {0x0, 0x0}}
q2             {u8 = {0x0, 0x0, 0x0, 0xa, 0x0, 0x0, 0x0, 0xb, 0xff, 0xff, 0xff, 0xff, \
0x0, 0x0, 0x0, 0x9},  u16 = {0x0, 0xa, 0x0, 0xb, 0xffff, 0xffff, 0x0, 0x9},
		u32 = {0xa, 0xb, 0xffffffff, 0x9},
		u64 = {0xa0000000b, 0xffffffff00000009}, f32 = {0x0, 0x0, 0x0, 0x0}, f64 = {0x0, \
0x0}} q3             {u8 = {0x0, 0x0, 0x0, 0xe, 0x0, 0x0, 0x0, 0xf, 0x0, 0x0, 0x0, \
0xc, 0x0, 0x0, 0x0, 0xd},  u16 = {0x0, 0xe, 0x0, 0xf, 0x0, 0xc, 0x0, 0xd},
		u32 = {0xe, 0xf, 0xc, 0xd},
		u64 = {0xe0000000f, 0xc0000000d}, f32 = {0x0, 0x0, 0x0, 0x0}, f64 = {0x0, 0x0}}

Here gdb prints them as if they were stored in big-endian order in
memory. So we have to read them in reverse to compare them to the LE
output.

That would mean, if we read the LE output for q0.u32 as 0 1 2 3, the
equivalent BE output would read 1 0 3 2 just as you guessed. So you're
right and all my notes in the code are likely wrong because I read the
output the wrong way around (again).

&gt; &gt; Otherwise I wonder if it would be possible for both chacha and salsa to
&gt; &gt; change the actual loading and storing so there's no transposing of
&gt; &gt; 32-bit operands. I looked at vld4.32 but that does some fancy
&gt; &gt; de-interleaving and needs two operations to load four q registers.
&gt; The new powerpc code uses load and store instructions that behave the
&gt; same in this respect, for both BE and LE. But not sure if there's any
&gt; easy way on ARM. I'm not that familiar with the more special load and
&gt; store instructions. Would vst2.32 be useful in some way for the final
&gt; store (and vst3.32 for chacha-3core)?

For this I have found two candidates, once I wrapped my head around the
(de-)interleaving part of VLDn/VSTn:

Option 1: VLDn.dt/VSTn.dt[2, C.13.5, page C-63]: It turns out, the n in
VLDn/VSTn is the number of interleaved elements and the .dt is the
width/datatype of those elements. So vld2.32 loads 32-bit operands from
memory which it assumes to be two interleaved vectors. So it sends
odd-numbered elements to one register and even-numbered to another. We
don't need nor want that. That's where vld1/vst1 come in: They do no
(de-)interleaving, just sequential loading or storing of elements. (It's
already in use in umac-nh.asm but I didn't remember.)

The number of elements it loads only depends on the number of registers
given. So vld1.64 {q0, q1}, [r1] does not mean "load one 64-bit operand
into some part of q0 or q1" but "load 64-bit operands sequentially
without deinterleaving until q0 and q1 are 'full'", i.e. four of them.

So for our case where we have a matrix of 32-bit words in host
endianness that we need to load sequentially into q registers without
any transposing we can use vld1.32 {q0, q1}, [r1].

This is also a drop-in fix for the 64-bit counter addition.

The drawback compared to vldm is that we need to issue two operations to
load four q registers because each vld1/vst1 can only work with up to
four d (i.e. two q) registers. This also means that we need to increment
the base address for the second load which requires a scratch register
if we want to keep the original value for later reference.

Regarding performance I found a document from ARM for the Cortex-A8
which had some cycle numbers[2]. According to it, two vld1's should take
(at worst/no alignment) six cycles where vldm would run five cycles for the
same amount of registers. This doesn't include any mov necessary to
initialise the base address scratch register. The element size (e.g. .8
vs. .64) doesn't seem to play into it at all. It gets faster with better
alignment. Here's a quick calculation with a bit of code for
illustration:

C vst1.8 because caller expects results little-endian
C speed:
C 1 q register == 2 d registers, doc talks d registers
C vstm: (number of registers/2) + mod(number of registers, 2) + 1 == (8/2) + mod(8, \
2) + 1 == 4 + 0 + 1 = 5 cycles C vst1.8: 2ops each 4-reg unaligned: 2*3 == 6 cycles \
(plus potentially mov to set up address counter) IF_LE(`	vstm    DST, {X0,X1,X2,X3}')
IF_BE(`	vst1.8  {X0,X1}, [DST]!
	vst1.8  {X2,X3}, [DST]')

My feeling is that it doesn't matter much because it happens outside the
main loop.

Attached are two patches be-neon-asm-2.diff and
0002-arm-Unify-neon-asm-for-big-and-little-endian-modes.patch for
illustration what using those intructions would look like. An armeb CI
run is at https://gitlab.com/michaelweiser/nettle/-/jobs/932123909.

As expected, all the special treatment of transposed operands can just
go away because it doesn't happen any more. Also, vld1.32 (for
sequential loads of 32-bit operands in host-endianness) and vld1.8 (for
sequential store of register contents to get an implicit little-endian
store without any vrev32.u8s) works the same on LE as well as BE. So we
could use those as separate BE implementation and leave the LE code
conditionalized but otherwise intact or we could unify the code to work
for both cases without difference.

Option 2: By coincidence I found that vldm/vstm can work with s
registers originally intended for use with VFP. They're just a different
view of the d0-d15 or q0-q7 registers. When giving s registers as
arguments to vldm/vstm they start to behave identically to vst1.32, i.e.
load/save 32-bit words sequentially.

The drawback is that only q0 through q7 are mapped as s0 through s31. So
we cannot use that mechanism to load directly into the higher eight q
registers. The attached patch be-neon-asm-1.diff showcases what using
those would look like. Where necessary, I loaded or stored via s0-s15 (i.e.
q0-q3) using vmov or the already presetn vrev32s. Since that routinely
clobbers those lower registers, I needed to add a second reload of the
original context into T0-T3 in salsa20-2core.asm.

Also, it's not entirely clear to me from the documentation if this will
work on every ARM core that supports NEON. The NEON programmer's
guide[3] states that VLDM/VSTM is a shared VFP/NEON instruction and s
registers *can* be specified. I read that to mean that it will work on
every NEON core. It appears that every core that has NEON also has at
least VFP3 but I've found no definite statement to that effect.  Some
sources speak of NEON as an extension to VFP but I've found no
confirmation by ARM.

Also it does not get rid of all those vrev32.u8s before store on BE. All
in all, option 1 (vld1/vst1) seems more straightforward and elegant to
me. We could also oppotunistically use both approaches where they fit
best, i.e. vldm/vstm when working with q0-q7 and vld1.{8,32} for q8-q15.

[2] https://static.docs.arm.com/den0018/a/DEN0018A_neon_programmers_guide_en.pdf
[3] https://developer.arm.com/documentation/ddi0344/b/instruction-cycle-timing/instruction-specific-scheduling-for-neon-instructions/neon-load-store-instructions
                
-- 
Happy holidays,
Michael


["be-neon-asm-1.diff" (text/plain)]

diff --git a/arm/neon/chacha-3core.asm b/arm/neon/chacha-3core.asm
index bd1cf63c..65638fad 100644
--- a/arm/neon/chacha-3core.asm
+++ b/arm/neon/chacha-3core.asm
@@ -64,10 +64,10 @@ define(`T3', `q7')
 	C _chacha_3core(uint32_t *dst, const uint32_t *src, unsigned rounds)
 
 PROLOGUE(_nettle_chacha_3core)
-	vldm	SRC, {X0,X1,X2,X3}
+	vldm	SRC, {s0-s15}
 	vpush	{q4,q5,q6,q7}
 	adr	r12, .Lcount1
-	vld1.64 {Z3}, [r12]
+	vld1.32 {Z3}, [r12]
 
 	vadd.i64	Y3, X3, Z3	C Increment 64-bit counter
 	vadd.i64	Z3, Y3, Z3
@@ -213,17 +213,31 @@ PROLOGUE(_nettle_chacha_3core)
 	vadd.i32	Y3, Y3, T2
 	vadd.i32	Z3, Z3, T3
 
-	vldm	SRC, {T0,T1,T2,T3}
+	vldm	SRC, {s16-s31}
 	vadd.i32	X0, X0, T0
 	vadd.i32	X1, X1, T1
 	vadd.i32	X2, X2, T2
 	vadd.i32	X3, X3, T3
-	vstmia	DST!, {X0,X1,X2,X3}
+
+	C caller expects result little-endian
+IF_BE(`	vrev32.u8	X0, X0
+	vrev32.u8	X1, X1
+	vrev32.u8	X2, X2
+	vrev32.u8	X3, X3')
+	vstmia	DST!, {s0-s15}
 
 	vadd.i32	Y0, Y0, T0
 	vadd.i32	Y1, Y1, T1
 	vadd.i32	Y2, Y2, T2
-	vstmia	DST!, {Y0,Y1,Y2,Y3}
+
+IF_LE(`	vstmia	DST!, {Y0,Y1,Y2,Y3}')
+	C caller expects result little-endian and there's not single word
+	C access to high q registers
+IF_BE(`	vrev32.u8	X0, Y0
+	vrev32.u8	X1, Y1
+	vrev32.u8	X2, Y2
+	vrev32.u8	X3, Y3
+	vstmia	DST!, {s0-s15}')
 
 	vadd.i32	Z0, Z0, T0
 	vadd.i32	Z1, Z1, T1
@@ -231,15 +245,20 @@ PROLOGUE(_nettle_chacha_3core)
 
 	vpop	{q4,q5,q6,q7}
 
-	vstm	DST, {Z0,Z1,Z2,Z3}
+IF_LE(`	vstm	DST, {Z0,Z1,Z2,Z3}')
+IF_BE(`	vrev32.u8	X0, Z0
+	vrev32.u8	X1, Z1
+	vrev32.u8	X2, Z2
+	vrev32.u8	X3, Z3
+	vstm	DST, {s0-s15}')
 	bx	lr
 EPILOGUE(_nettle_chacha_3core)
 
 PROLOGUE(_nettle_chacha_3core32)
-	vldm	SRC, {X0,X1,X2,X3}
+	vldm	SRC, {s0-s15}
 	vpush	{q4,q5,q6,q7}
 	adr	r12, .Lcount1
-	vld1.64 {Z3}, [r12]
+	vld1.32 {Z3}, [r12]
 
 	vadd.i32	Y3, X3, Z3	C Increment 32-bit counter
 	vadd.i32	Z3, Y3, Z3
diff --git a/arm/neon/chacha-core-internal.asm b/arm/neon/chacha-core-internal.asm
index b0a775bd..8e72c6b0 100644
--- a/arm/neon/chacha-core-internal.asm
+++ b/arm/neon/chacha-core-internal.asm
@@ -83,7 +83,7 @@ define(`QROUND', `
 	C _chacha_core(uint32_t *dst, const uint32_t *src, unsigned rounds)
 
 PROLOGUE(_nettle_chacha_core)
-	vldm	SRC, {X0,X1,X2,X3}
+	vldm	SRC, {s0-s15}
 
 	vmov	S0, X0
 	vmov	S1, X1
@@ -96,15 +96,6 @@ PROLOGUE(_nettle_chacha_core)
 	C	 8  9 10 11	X2
 	C	12 13 14 15	X3
 
-	C Input rows big-endian:
-	C	 1  0  3  2	X0
-	C	 5  4  7  6	X1
-	C	 9  8 11 10	X2
-	C	13 12 15 14	X3
-	C even and odd columns switched because
-	C vldm loads consecutive doublewords and
-	C switches words inside them to make them BE
-
 .Loop:
 	QROUND(X0, X1, X2, X3)
 
@@ -113,29 +104,17 @@ PROLOGUE(_nettle_chacha_core)
 	C	 5  6  7  4  &gt;&gt;&gt; 3
 	C	10 11  8  9  &gt;&gt;&gt; 2
 	C	15 12 13 14  &gt;&gt;&gt; 1
-
-	C In big-endian rotate rows, to get
-	C	 1  0  3  2
-	C	 6  5  4  7  &gt;&gt;&gt; 1
-	C	11 10  9  8  &gt;&gt;&gt; 2
-	C	12 15 14 13  &gt;&gt;&gt; 3
-	C different number of elements needs to be
-	C extracted on BE because of different column order
-IF_LE(`	vext.32	X1, X1, X1, #1')
-IF_BE(`	vext.32	X1, X1, X1, #3')
+	vext.32	X1, X1, X1, #1
 	vext.32	X2, X2, X2, #2
-IF_LE(`	vext.32	X3, X3, X3, #3')
-IF_BE(`	vext.32	X3, X3, X3, #1')
+	vext.32	X3, X3, X3, #3
 
 	QROUND(X0, X1, X2, X3)
 
 	subs	ROUNDS, ROUNDS, #2
 	C Inverse rotation
-IF_LE(`	vext.32	X1, X1, X1, #3')
-IF_BE(`	vext.32	X1, X1, X1, #1')
+	vext.32	X1, X1, X1, #3
 	vext.32	X2, X2, X2, #2
-IF_LE(`	vext.32	X3, X3, X3, #1')
-IF_BE(`	vext.32	X3, X3, X3, #3')
+	vext.32	X3, X3, X3, #1
 
 	bhi	.Loop
 
@@ -150,7 +129,7 @@ IF_BE(`	vrev32.u8	X0, X0
 	vrev32.u8	X2, X2
 	vrev32.u8	X3, X3')
 
-	vstm	DST, {X0,X1,X2,X3}
+	vstm	DST, {s0-s15}
 	bx	lr
 EPILOGUE(_nettle_chacha_core)
 
diff --git a/arm/neon/salsa20-2core.asm b/arm/neon/salsa20-2core.asm
index d622edd6..efd2626d 100644
--- a/arm/neon/salsa20-2core.asm
+++ b/arm/neon/salsa20-2core.asm
@@ -38,18 +38,18 @@ define(`SRC', `r1')
 define(`ROUNDS', `r2')
 
 C State, even elements in X, odd elements in Y
-define(`X0', `q0')
-define(`X1', `q1')
-define(`X2', `q2')
-define(`X3', `q3')
-define(`Y0', `q8')
-define(`Y1', `q9')
-define(`Y2', `q10')
-define(`Y3', `q11')
-define(`T0', `q12')
-define(`T1', `q13')
-define(`T2', `q14')
-define(`T3', `q15')
+define(`X0', `q8')
+define(`X1', `q9')
+define(`X2', `q10')
+define(`X3', `q11')
+define(`Y0', `q12')
+define(`Y1', `q13')
+define(`Y2', `q14')
+define(`Y3', `q15')
+define(`T0', `q0')
+define(`T1', `q1')
+define(`T2', `q2')
+define(`T3', `q3')
 
 	.text
 	.align 4
@@ -58,18 +58,23 @@ define(`T3', `q15')
 
 	C _salsa20_2core(uint32_t *dst, const uint32_t *src, unsigned rounds)
 PROLOGUE(_nettle_salsa20_2core)
-	vldm	SRC, {X0,X1,X2,X3}
+IF_LE(`	vldm	SRC, {X0,X1,X2,X3}')
+IF_BE(`	vldm	SRC, {s0-s15}
+	vmov	X0, T0
+	vmov	X1, T1
+	vmov	X2, T2
+	vmov	X3, T3')
 	adr	r12, .Lcount1
 
 	vmov	Y3, X0
-	vld1.64 {Y1}, [r12]
+	vld1.32 {Y1}, [r12]
 	vmov	Y0, X1
 	vadd.i64 Y1, Y1, X2	C Increment counter
 	vmov	Y2, X3
 
 	vtrn.32	X0, Y3		C X0:  0  0  2  2  Y3:  1  1  3  3
 	vtrn.32	X1, Y0		C X1:  4  4  6  6  Y0:  5  5  7  7
-	vtrn.32	X2, Y1		C X2:  8  8 10 10  Y1:  9  9  1  1
+	vtrn.32	X2, Y1		C X2:  8  8 10 10  Y1:  9  9 11 11
 	vtrn.32	X3, Y2		C X3: 12 12 14 14  Y2: 13 13 15 15
 
 	C Swap, to get
@@ -180,7 +185,7 @@ C Inverse swaps and transpositions
 	vswp	D1REG(Y0), D1REG(Y2)
 	vswp	D1REG(Y1), D1REG(Y3)
 
-	vldm	SRC, {T0,T1,T2,T3}
+	vldm	SRC, {s0-s15}
 
 	vtrn.32	X0, Y3
 	vtrn.32	X1, Y0
@@ -193,14 +198,24 @@ C Add in the original context
 	vadd.i32	X2, X2, T2
 	vadd.i32	X3, X3, T3
 
-	vstmia	DST!, {X0,X1,X2,X3}
-	vld1.64 {X0}, [r12]
+IF_LE(`	vstmia	DST!, {X0,X1,X2,X3}')
+IF_BE(`	vrev32.u8	T0, X0
+	vrev32.u8	T1, X1
+	vrev32.u8	T2, X2
+	vrev32.u8	T3, X3
+	vstmia	DST!, {s0-s15}')
+	vld1.32 {X0}, [r12]
+IF_BE(`	vldm	SRC, {s0-s15}')
 	vadd.i32	T0, T0, Y3
 	vadd.i64	T2, T2, X0
 	vadd.i32	T1, T1, Y0
 	vadd.i32	T2, T2, Y1
 	vadd.i32	T3, T3, Y2
 
-	vstm	DST, {T0,T1,T2,T3}
+IF_BE(`	vrev32.u8	T0, T0
+	vrev32.u8	T1, T1
+	vrev32.u8	T2, T2
+	vrev32.u8	T3, T3')
+	vstm	DST, {s0-s15}
 	bx	lr
 EPILOGUE(_nettle_salsa20_2core)
diff --git a/arm/neon/salsa20-core-internal.asm b/arm/neon/salsa20-core-internal.asm
index d59d7b80..5f8ed15c 100644
--- a/arm/neon/salsa20-core-internal.asm
+++ b/arm/neon/salsa20-core-internal.asm
@@ -86,7 +86,18 @@ define(`QROUND', `
 	C _salsa20_core(uint32_t *dst, const uint32_t *src, unsigned rounds)
 
 PROLOGUE(_nettle_salsa20_core)
-	vldm	SRC, {X0,X1,X2,X3}
+	C FIXME: Construct in some other way?
+	adr	r12, .Lmasks
+IF_LE(`	vldm	r12, {M0101, M0110, M0011}')
+	C we need to load single words to avoid word-swapping by
+	C d-register loads and have no single word access to high q
+	C registers here
+IF_BE(`	vldm	r12, {s0-s11}
+	vmov	M0101, X0
+	vmov	M0110, X1
+	vmov	M0011, X2')
+
+	vldm	SRC, {s0-s15}
 
 	C Input rows little-endian:
 	C	 0  1  2  3	X0
@@ -99,24 +110,6 @@ PROLOGUE(_nettle_salsa20_core)
 	C	 8 13  2  7
 	C	12  1  6 11
 
-	C Input rows big-endian:
-	C	 1  0  3  2	X0
-	C	 5  4  7  6	X1
-	C	 9  8 11 10	X2
-	C	13 12 15 14	X3
-	C even and odd columns switched because
-	C vldm loads consecutive doublewords and
-	C switches words inside them to make them BE
-	C Permuted to:
-	C	 5  0 15 10
-	C	 9  4  3 14
-	C	13  8  7  2
-	C	 1 12 11  6
-
-	C FIXME: Construct in some other way?
-	adr	r12, .Lmasks
-	vldm	r12, {M0101, M0110, M0011}
-
 	vmov	S1, X1
 	vmov	S2, X2
 	vmov	S3, X3
@@ -160,29 +153,17 @@ PROLOGUE(_nettle_salsa20_core)
 	C	 3  4  9 14  &gt;&gt;&gt; 1
 	C	 2  7  8 13  &gt;&gt;&gt; 2
 	C	 1  6 11 12  &gt;&gt;&gt; 3
-
-	C In big-endian rotate rows, to get
-	C	 5  0 15 10
-	C	 4  3 14  9  &gt;&gt;&gt; 3
-	C	 7  2 13  8  &gt;&gt;&gt; 2
-	C	 6  1 12 11  &gt;&gt;&gt; 1
-	C different number of elements needs to be
-	C extracted on BE because of different column order
-IF_LE(`	vext.32	X1, X1, X1, #3')
-IF_BE(`	vext.32	X1, X1, X1, #1')
+	vext.32	X1, X1, X1, #3
 	vext.32	X2, X2, X2, #2
-IF_LE(`	vext.32	X3, X3, X3, #1')
-IF_BE(`	vext.32	X3, X3, X3, #3')
+	vext.32	X3, X3, X3, #1
 
 	QROUND(X0, X3, X2, X1)
 
 	subs	ROUNDS, ROUNDS, #2
 	C Inverse rotation
-IF_LE(`	vext.32	X1, X1, X1, #1')
-IF_BE(`	vext.32	X1, X1, X1, #3')
+	vext.32	X1, X1, X1, #1
 	vext.32	X2, X2, X2, #2
-IF_LE(`	vext.32	X3, X3, X3, #3')
-IF_BE(`	vext.32	X3, X3, X3, #1')
+	vext.32	X3, X3, X3, #3
 
 	bhi	.Loop
 
@@ -202,7 +183,7 @@ IF_BE(`	vext.32	X3, X3, X3, #1')
 	vbit	X2, X3, M0101
 	vbit	X3, T1, M0101
 
-	vld1.64	{T0}, [SRC]
+	vld1.32	{T0}, [SRC]
 	vadd.u32	X0, X0, T0
 	vadd.u32	X1, X1, S1
 	vadd.u32	X2, X2, S2
@@ -214,7 +195,7 @@ IF_BE(`	vrev32.u8	X0, X0
 	vrev32.u8	X2, X2
 	vrev32.u8	X3, X3')
 
-	vstm	DST, {X0,X1,X2,X3}
+	vstm	DST, {s0-s15}
 	bx	lr
 EPILOGUE(_nettle_salsa20_core)
 

["be-neon-asm-2.diff" (text/plain)]

diff --git a/arm/neon/chacha-3core.asm b/arm/neon/chacha-3core.asm
index bd1cf63c..b6d74ff7 100644
--- a/arm/neon/chacha-3core.asm
+++ b/arm/neon/chacha-3core.asm
@@ -64,10 +64,13 @@ define(`T3', `q7')
 	C _chacha_3core(uint32_t *dst, const uint32_t *src, unsigned rounds)
 
 PROLOGUE(_nettle_chacha_3core)
-	vldm	SRC, {X0,X1,X2,X3}
+IF_LE(`	vldm	SRC, {X0,X1,X2,X3}')
+IF_BE(`	mov	r12, SRC
+	vld1.32	{X0,X1}, [r12]!
+	vld1.32	{X2,X3}, [r12]')
 	vpush	{q4,q5,q6,q7}
 	adr	r12, .Lcount1
-	vld1.64 {Z3}, [r12]
+	vld1.32 {Z3}, [r12]
 
 	vadd.i64	Y3, X3, Z3	C Increment 64-bit counter
 	vadd.i64	Z3, Y3, Z3
@@ -213,17 +216,24 @@ PROLOGUE(_nettle_chacha_3core)
 	vadd.i32	Y3, Y3, T2
 	vadd.i32	Z3, Z3, T3
 
-	vldm	SRC, {T0,T1,T2,T3}
+IF_LE(`	vldm	SRC, {T0,T1,T2,T3}')
+IF_BE(`	vld1.32	{T0,T1}, [SRC]!		C SRC changed!
+	vld1.32	{T2,T3}, [SRC]')
 	vadd.i32	X0, X0, T0
 	vadd.i32	X1, X1, T1
 	vadd.i32	X2, X2, T2
 	vadd.i32	X3, X3, T3
-	vstmia	DST!, {X0,X1,X2,X3}
+	C vst1.8 because caller expects results little-endian
+IF_LE(`	vstmia	DST!, {X0,X1,X2,X3}')
+IF_BE(`	vst1.8	{X0,X1}, [DST]!
+	vst1.8	{X2,X3}, [DST]!')
 
 	vadd.i32	Y0, Y0, T0
 	vadd.i32	Y1, Y1, T1
 	vadd.i32	Y2, Y2, T2
-	vstmia	DST!, {Y0,Y1,Y2,Y3}
+IF_LE(`	vstmia	DST!, {Y0,Y1,Y2,Y3}')
+IF_BE(`	vst1.8	{Y0,Y1}, [DST]!
+	vst1.8	{Y2,Y3}, [DST]!')
 
 	vadd.i32	Z0, Z0, T0
 	vadd.i32	Z1, Z1, T1
@@ -231,15 +241,20 @@ PROLOGUE(_nettle_chacha_3core)
 
 	vpop	{q4,q5,q6,q7}
 
-	vstm	DST, {Z0,Z1,Z2,Z3}
+IF_LE(`	vstm	DST, {Z0,Z1,Z2,Z3}')
+IF_BE(`	vst1.8	{Z0,Z1}, [DST]!
+	vst1.8	{Z2,Z3}, [DST]')
 	bx	lr
 EPILOGUE(_nettle_chacha_3core)
 
 PROLOGUE(_nettle_chacha_3core32)
-	vldm	SRC, {X0,X1,X2,X3}
+IF_LE(`	vldm	SRC, {X0,X1,X2,X3}')
+IF_BE(` mov	r12, SRC
+	vld1.32	{X0,X1}, [r12]!
+	vld1.32	{X2,X3}, [r12]')
 	vpush	{q4,q5,q6,q7}
 	adr	r12, .Lcount1
-	vld1.64 {Z3}, [r12]
+	vld1.32 {Z3}, [r12]
 
 	vadd.i32	Y3, X3, Z3	C Increment 32-bit counter
 	vadd.i32	Z3, Y3, Z3
diff --git a/arm/neon/chacha-core-internal.asm b/arm/neon/chacha-core-internal.asm
index b0a775bd..6613df82 100644
--- a/arm/neon/chacha-core-internal.asm
+++ b/arm/neon/chacha-core-internal.asm
@@ -83,7 +83,9 @@ define(`QROUND', `
 	C _chacha_core(uint32_t *dst, const uint32_t *src, unsigned rounds)
 
 PROLOGUE(_nettle_chacha_core)
-	vldm	SRC, {X0,X1,X2,X3}
+IF_LE(`	vldm	SRC, {X0,X1,X2,X3}')
+IF_BE(`	vld1.32	{X0,X1}, [SRC]!		C SRC changed!
+	vld1.32	{X2,X3}, [SRC]')
 
 	vmov	S0, X0
 	vmov	S1, X1
@@ -96,15 +98,6 @@ PROLOGUE(_nettle_chacha_core)
 	C	 8  9 10 11	X2
 	C	12 13 14 15	X3
 
-	C Input rows big-endian:
-	C	 1  0  3  2	X0
-	C	 5  4  7  6	X1
-	C	 9  8 11 10	X2
-	C	13 12 15 14	X3
-	C even and odd columns switched because
-	C vldm loads consecutive doublewords and
-	C switches words inside them to make them BE
-
 .Loop:
 	QROUND(X0, X1, X2, X3)
 
@@ -113,29 +106,17 @@ PROLOGUE(_nettle_chacha_core)
 	C	 5  6  7  4  &gt;&gt;&gt; 3
 	C	10 11  8  9  &gt;&gt;&gt; 2
 	C	15 12 13 14  &gt;&gt;&gt; 1
-
-	C In big-endian rotate rows, to get
-	C	 1  0  3  2
-	C	 6  5  4  7  &gt;&gt;&gt; 1
-	C	11 10  9  8  &gt;&gt;&gt; 2
-	C	12 15 14 13  &gt;&gt;&gt; 3
-	C different number of elements needs to be
-	C extracted on BE because of different column order
-IF_LE(`	vext.32	X1, X1, X1, #1')
-IF_BE(`	vext.32	X1, X1, X1, #3')
+	vext.32	X1, X1, X1, #1
 	vext.32	X2, X2, X2, #2
-IF_LE(`	vext.32	X3, X3, X3, #3')
-IF_BE(`	vext.32	X3, X3, X3, #1')
+	vext.32	X3, X3, X3, #3
 
 	QROUND(X0, X1, X2, X3)
 
 	subs	ROUNDS, ROUNDS, #2
 	C Inverse rotation
-IF_LE(`	vext.32	X1, X1, X1, #3')
-IF_BE(`	vext.32	X1, X1, X1, #1')
+	vext.32	X1, X1, X1, #3
 	vext.32	X2, X2, X2, #2
-IF_LE(`	vext.32	X3, X3, X3, #1')
-IF_BE(`	vext.32	X3, X3, X3, #3')
+	vext.32	X3, X3, X3, #1
 
 	bhi	.Loop
 
@@ -144,13 +125,15 @@ IF_BE(`	vext.32	X3, X3, X3, #3')
 	vadd.u32	X2, X2, S2
 	vadd.u32	X3, X3, S3
 
-	C caller expects result little-endian
-IF_BE(`	vrev32.u8	X0, X0
-	vrev32.u8	X1, X1
-	vrev32.u8	X2, X2
-	vrev32.u8	X3, X3')
+	C vst1.8 because caller expects results little-endian
+	C speed: https://developer.arm.com/documentation/ddi0344/b/instruction-cycle-timing/ \
instruction-specific-scheduling-for-neon-instructions/neon-load-store-instructions \
+	C 1 q register == 2 d registers, doc talks d registers +	C vstm: (number of \
registers/2) + mod(number of registers, 2) + 1 == (8/2) + mod(8, 2) + 1 == 4 + 0 + 1 \
= 5 cycles +	C vst1.8: 2ops each 4-reg unaligned: 2*3 == 6 cycles (plus potentially \
mov to set up address counter) +IF_LE(`	vstm	DST, {X0,X1,X2,X3}')
+IF_BE(`	vst1.8	{X0,X1}, [DST]!
+	vst1.8	{X2,X3}, [DST]')
 
-	vstm	DST, {X0,X1,X2,X3}
 	bx	lr
 EPILOGUE(_nettle_chacha_core)
 
diff --git a/arm/neon/salsa20-2core.asm b/arm/neon/salsa20-2core.asm
index d622edd6..c094ed58 100644
--- a/arm/neon/salsa20-2core.asm
+++ b/arm/neon/salsa20-2core.asm
@@ -58,11 +58,14 @@ define(`T3', `q15')
 
 	C _salsa20_2core(uint32_t *dst, const uint32_t *src, unsigned rounds)
 PROLOGUE(_nettle_salsa20_2core)
-	vldm	SRC, {X0,X1,X2,X3}
+IF_LE(`	vldm	SRC, {X0,X1,X2,X3}')
+IF_BE(`	mov	r12, SRC
+	vld1.32	{X0,X1}, [r12]!
+	vld1.32	{X2,X3}, [r12]')
 	adr	r12, .Lcount1
 
 	vmov	Y3, X0
-	vld1.64 {Y1}, [r12]
+	vld1.32 {Y1}, [r12]
 	vmov	Y0, X1
 	vadd.i64 Y1, Y1, X2	C Increment counter
 	vmov	Y2, X3
@@ -180,7 +183,9 @@ C Inverse swaps and transpositions
 	vswp	D1REG(Y0), D1REG(Y2)
 	vswp	D1REG(Y1), D1REG(Y3)
 
-	vldm	SRC, {T0,T1,T2,T3}
+IF_LE(`	vldm	SRC, {T0,T1,T2,T3}')
+IF_BE(`	vld1.32	{T0,T1}, [SRC]!		C SRC changed!
+	vld1.32	{T2,T3}, [SRC]')
 
 	vtrn.32	X0, Y3
 	vtrn.32	X1, Y0
@@ -193,14 +198,19 @@ C Add in the original context
 	vadd.i32	X2, X2, T2
 	vadd.i32	X3, X3, T3
 
-	vstmia	DST!, {X0,X1,X2,X3}
-	vld1.64 {X0}, [r12]
+C vst1.8 because caller expects results little-endian
+IF_LE(`	vstmia	DST!, {X0,X1,X2,X3}')
+IF_BE(`	vst1.8	{X0,X1}, [DST]!
+	vst1.8	{X2,X3}, [DST]!')
+	vld1.32 {X0}, [r12]
 	vadd.i32	T0, T0, Y3
 	vadd.i64	T2, T2, X0
 	vadd.i32	T1, T1, Y0
 	vadd.i32	T2, T2, Y1
 	vadd.i32	T3, T3, Y2
 
-	vstm	DST, {T0,T1,T2,T3}
+IF_LE(`	vstm	DST, {T0,T1,T2,T3}')
+IF_BE(`	vst1.8	{T0,T1}, [DST]!
+	vst1.8	{T2,T3}, [DST]')
 	bx	lr
 EPILOGUE(_nettle_salsa20_2core)
diff --git a/arm/neon/salsa20-core-internal.asm b/arm/neon/salsa20-core-internal.asm
index d59d7b80..9d2578e5 100644
--- a/arm/neon/salsa20-core-internal.asm
+++ b/arm/neon/salsa20-core-internal.asm
@@ -86,7 +86,10 @@ define(`QROUND', `
 	C _salsa20_core(uint32_t *dst, const uint32_t *src, unsigned rounds)
 
 PROLOGUE(_nettle_salsa20_core)
-	vldm	SRC, {X0,X1,X2,X3}
+IF_LE(`	vldm	SRC, {X0,X1,X2,X3}')
+IF_BE(`	mov	r12, SRC
+	vld1.32	{X0,X1}, [r12]!
+	vld1.32	{X2,X3}, [r12]')
 
 	C Input rows little-endian:
 	C	 0  1  2  3	X0
@@ -99,23 +102,11 @@ PROLOGUE(_nettle_salsa20_core)
 	C	 8 13  2  7
 	C	12  1  6 11
 
-	C Input rows big-endian:
-	C	 1  0  3  2	X0
-	C	 5  4  7  6	X1
-	C	 9  8 11 10	X2
-	C	13 12 15 14	X3
-	C even and odd columns switched because
-	C vldm loads consecutive doublewords and
-	C switches words inside them to make them BE
-	C Permuted to:
-	C	 5  0 15 10
-	C	 9  4  3 14
-	C	13  8  7  2
-	C	 1 12 11  6
-
 	C FIXME: Construct in some other way?
 	adr	r12, .Lmasks
-	vldm	r12, {M0101, M0110, M0011}
+IF_LE(`	vldm	r12, {M0101, M0110, M0011}')
+IF_BE(`	vld1.32	{M0101, M0110}, [r12]!
+	vld1.32	{M0011}, [r12]')
 
 	vmov	S1, X1
 	vmov	S2, X2
@@ -160,29 +151,17 @@ PROLOGUE(_nettle_salsa20_core)
 	C	 3  4  9 14  &gt;&gt;&gt; 1
 	C	 2  7  8 13  &gt;&gt;&gt; 2
 	C	 1  6 11 12  &gt;&gt;&gt; 3
-
-	C In big-endian rotate rows, to get
-	C	 5  0 15 10
-	C	 4  3 14  9  &gt;&gt;&gt; 3
-	C	 7  2 13  8  &gt;&gt;&gt; 2
-	C	 6  1 12 11  &gt;&gt;&gt; 1
-	C different number of elements needs to be
-	C extracted on BE because of different column order
-IF_LE(`	vext.32	X1, X1, X1, #3')
-IF_BE(`	vext.32	X1, X1, X1, #1')
+	vext.32	X1, X1, X1, #3
 	vext.32	X2, X2, X2, #2
-IF_LE(`	vext.32	X3, X3, X3, #1')
-IF_BE(`	vext.32	X3, X3, X3, #3')
+	vext.32	X3, X3, X3, #1
 
 	QROUND(X0, X3, X2, X1)
 
 	subs	ROUNDS, ROUNDS, #2
 	C Inverse rotation
-IF_LE(`	vext.32	X1, X1, X1, #1')
-IF_BE(`	vext.32	X1, X1, X1, #3')
+	vext.32	X1, X1, X1, #1
 	vext.32	X2, X2, X2, #2
-IF_LE(`	vext.32	X3, X3, X3, #3')
-IF_BE(`	vext.32	X3, X3, X3, #1')
+	vext.32	X3, X3, X3, #3
 
 	bhi	.Loop
 
@@ -202,19 +181,16 @@ IF_BE(`	vext.32	X3, X3, X3, #1')
 	vbit	X2, X3, M0101
 	vbit	X3, T1, M0101
 
-	vld1.64	{T0}, [SRC]
+	vld1.32	{T0}, [SRC]
 	vadd.u32	X0, X0, T0
 	vadd.u32	X1, X1, S1
 	vadd.u32	X2, X2, S2
 	vadd.u32	X3, X3, S3
 
-	C caller expects result little-endian
-IF_BE(`	vrev32.u8	X0, X0
-	vrev32.u8	X1, X1
-	vrev32.u8	X2, X2
-	vrev32.u8	X3, X3')
-
-	vstm	DST, {X0,X1,X2,X3}
+	C vst1.8 because caller expects results little-endian
+IF_LE(`	vstm	DST, {X0,X1,X2,X3}')
+IF_BE(`	vst1.8	{X0,X1}, [DST]!
+	vst1.8	{X2,X3}, [DST]')
 	bx	lr
 EPILOGUE(_nettle_salsa20_core)
 


["0002-arm-Unify-neon-asm-for-big-and-little-endian-modes.patch" (text/x-diff)]

From 07c7ea6d62b33aa0c3e176c0e54ffc409fd78516 Mon Sep 17 00:00:00 2001
From: Michael Weiser &lt;michael.weiser@gmx.de&gt;
Date: Fri, 25 Dec 2020 17:13:52 +0100
Subject: [PATCH 2/2] arm: Unify neon asm for big- and little-endian modes

Switch arm neon assemlber routines to endianness-agnostic loads and
stores where possible to avoid modifications to the rest of the code.
This involves switching to vld1.32 for loading consecutive 32-bit words
in host endianness as well as vst1.8 for storing back to memory in
little-endian order as required by the caller.

Signed-off-by: Michael Weiser &lt;michael.weiser@gmx.de&gt;
---
 arm/neon/chacha-3core.asm          | 25 +++++++++-----
 arm/neon/chacha-core-internal.asm  | 41 +++++------------------
 arm/neon/salsa20-2core.asm         | 18 ++++++----
 arm/neon/salsa20-core-internal.asm | 53 ++++++++----------------------
 4 files changed, 50 insertions(+), 87 deletions(-)

diff --git a/arm/neon/chacha-3core.asm b/arm/neon/chacha-3core.asm
index bd1cf63c..35989d50 100644
--- a/arm/neon/chacha-3core.asm
+++ b/arm/neon/chacha-3core.asm
@@ -64,10 +64,12 @@ define(`T3', `q7')
 	C _chacha_3core(uint32_t *dst, const uint32_t *src, unsigned rounds)
 
 PROLOGUE(_nettle_chacha_3core)
-	vldm	SRC, {X0,X1,X2,X3}
+	mov	r12, SRC
+	vld1.32	{X0,X1}, [r12]!
+	vld1.32	{X2,X3}, [r12]
 	vpush	{q4,q5,q6,q7}
 	adr	r12, .Lcount1
-	vld1.64 {Z3}, [r12]
+	vld1.32 {Z3}, [r12]
 
 	vadd.i64	Y3, X3, Z3	C Increment 64-bit counter
 	vadd.i64	Z3, Y3, Z3
@@ -213,17 +215,21 @@ PROLOGUE(_nettle_chacha_3core)
 	vadd.i32	Y3, Y3, T2
 	vadd.i32	Z3, Z3, T3
 
-	vldm	SRC, {T0,T1,T2,T3}
+	vld1.32	{T0,T1}, [SRC]!		C SRC changed!
+	vld1.32	{T2,T3}, [SRC]
 	vadd.i32	X0, X0, T0
 	vadd.i32	X1, X1, T1
 	vadd.i32	X2, X2, T2
 	vadd.i32	X3, X3, T3
-	vstmia	DST!, {X0,X1,X2,X3}
+	C vst1.8 because caller expects results little-endian
+	vst1.8	{X0,X1}, [DST]!
+	vst1.8	{X2,X3}, [DST]!
 
 	vadd.i32	Y0, Y0, T0
 	vadd.i32	Y1, Y1, T1
 	vadd.i32	Y2, Y2, T2
-	vstmia	DST!, {Y0,Y1,Y2,Y3}
+	vst1.8	{Y0,Y1}, [DST]!
+	vst1.8	{Y2,Y3}, [DST]!
 
 	vadd.i32	Z0, Z0, T0
 	vadd.i32	Z1, Z1, T1
@@ -231,15 +237,18 @@ PROLOGUE(_nettle_chacha_3core)
 
 	vpop	{q4,q5,q6,q7}
 
-	vstm	DST, {Z0,Z1,Z2,Z3}
+	vst1.8	{Z0,Z1}, [DST]!
+	vst1.8	{Z2,Z3}, [DST]
 	bx	lr
 EPILOGUE(_nettle_chacha_3core)
 
 PROLOGUE(_nettle_chacha_3core32)
-	vldm	SRC, {X0,X1,X2,X3}
+	mov	r12, SRC
+	vld1.32	{X0,X1}, [r12]!
+	vld1.32	{X2,X3}, [r12]
 	vpush	{q4,q5,q6,q7}
 	adr	r12, .Lcount1
-	vld1.64 {Z3}, [r12]
+	vld1.32 {Z3}, [r12]
 
 	vadd.i32	Y3, X3, Z3	C Increment 32-bit counter
 	vadd.i32	Z3, Y3, Z3
diff --git a/arm/neon/chacha-core-internal.asm b/arm/neon/chacha-core-internal.asm
index b0a775bd..4e53289b 100644
--- a/arm/neon/chacha-core-internal.asm
+++ b/arm/neon/chacha-core-internal.asm
@@ -83,7 +83,8 @@ define(`QROUND', `
 	C _chacha_core(uint32_t *dst, const uint32_t *src, unsigned rounds)
 
 PROLOGUE(_nettle_chacha_core)
-	vldm	SRC, {X0,X1,X2,X3}
+	vld1.32	{X0,X1}, [SRC]!		C SRC changed!
+	vld1.32	{X2,X3}, [SRC]
 
 	vmov	S0, X0
 	vmov	S1, X1
@@ -96,15 +97,6 @@ PROLOGUE(_nettle_chacha_core)
 	C	 8  9 10 11	X2
 	C	12 13 14 15	X3
 
-	C Input rows big-endian:
-	C	 1  0  3  2	X0
-	C	 5  4  7  6	X1
-	C	 9  8 11 10	X2
-	C	13 12 15 14	X3
-	C even and odd columns switched because
-	C vldm loads consecutive doublewords and
-	C switches words inside them to make them BE
-
 .Loop:
 	QROUND(X0, X1, X2, X3)
 
@@ -113,29 +105,17 @@ PROLOGUE(_nettle_chacha_core)
 	C	 5  6  7  4  &gt;&gt;&gt; 3
 	C	10 11  8  9  &gt;&gt;&gt; 2
 	C	15 12 13 14  &gt;&gt;&gt; 1
-
-	C In big-endian rotate rows, to get
-	C	 1  0  3  2
-	C	 6  5  4  7  &gt;&gt;&gt; 1
-	C	11 10  9  8  &gt;&gt;&gt; 2
-	C	12 15 14 13  &gt;&gt;&gt; 3
-	C different number of elements needs to be
-	C extracted on BE because of different column order
-IF_LE(`	vext.32	X1, X1, X1, #1')
-IF_BE(`	vext.32	X1, X1, X1, #3')
+	vext.32	X1, X1, X1, #1
 	vext.32	X2, X2, X2, #2
-IF_LE(`	vext.32	X3, X3, X3, #3')
-IF_BE(`	vext.32	X3, X3, X3, #1')
+	vext.32	X3, X3, X3, #3
 
 	QROUND(X0, X1, X2, X3)
 
 	subs	ROUNDS, ROUNDS, #2
 	C Inverse rotation
-IF_LE(`	vext.32	X1, X1, X1, #3')
-IF_BE(`	vext.32	X1, X1, X1, #1')
+	vext.32	X1, X1, X1, #3
 	vext.32	X2, X2, X2, #2
-IF_LE(`	vext.32	X3, X3, X3, #1')
-IF_BE(`	vext.32	X3, X3, X3, #3')
+	vext.32	X3, X3, X3, #1
 
 	bhi	.Loop
 
@@ -144,13 +124,8 @@ IF_BE(`	vext.32	X3, X3, X3, #3')
 	vadd.u32	X2, X2, S2
 	vadd.u32	X3, X3, S3
 
-	C caller expects result little-endian
-IF_BE(`	vrev32.u8	X0, X0
-	vrev32.u8	X1, X1
-	vrev32.u8	X2, X2
-	vrev32.u8	X3, X3')
-
-	vstm	DST, {X0,X1,X2,X3}
+	vst1.8	{X0,X1}, [DST]!
+	vst1.8	{X2,X3}, [DST]
 	bx	lr
 EPILOGUE(_nettle_chacha_core)
 
diff --git a/arm/neon/salsa20-2core.asm b/arm/neon/salsa20-2core.asm
index d622edd6..233fc2e1 100644
--- a/arm/neon/salsa20-2core.asm
+++ b/arm/neon/salsa20-2core.asm
@@ -58,11 +58,13 @@ define(`T3', `q15')
 
 	C _salsa20_2core(uint32_t *dst, const uint32_t *src, unsigned rounds)
 PROLOGUE(_nettle_salsa20_2core)
-	vldm	SRC, {X0,X1,X2,X3}
+	mov	r12, SRC
+	vld1.32	{X0,X1}, [r12]!
+	vld1.32	{X2,X3}, [r12]
 	adr	r12, .Lcount1
 
 	vmov	Y3, X0
-	vld1.64 {Y1}, [r12]
+	vld1.32 {Y1}, [r12]
 	vmov	Y0, X1
 	vadd.i64 Y1, Y1, X2	C Increment counter
 	vmov	Y2, X3
@@ -180,7 +182,8 @@ C Inverse swaps and transpositions
 	vswp	D1REG(Y0), D1REG(Y2)
 	vswp	D1REG(Y1), D1REG(Y3)
 
-	vldm	SRC, {T0,T1,T2,T3}
+	vld1.32	{T0,T1}, [SRC]!		C SRC changed!
+	vld1.32	{T2,T3}, [SRC]
 
 	vtrn.32	X0, Y3
 	vtrn.32	X1, Y0
@@ -193,14 +196,17 @@ C Add in the original context
 	vadd.i32	X2, X2, T2
 	vadd.i32	X3, X3, T3
 
-	vstmia	DST!, {X0,X1,X2,X3}
-	vld1.64 {X0}, [r12]
+C vst1.8 because caller expects results little-endian
+	vst1.8	{X0,X1}, [DST]!
+	vst1.8	{X2,X3}, [DST]!
+	vld1.32 {X0}, [r12]
 	vadd.i32	T0, T0, Y3
 	vadd.i64	T2, T2, X0
 	vadd.i32	T1, T1, Y0
 	vadd.i32	T2, T2, Y1
 	vadd.i32	T3, T3, Y2
 
-	vstm	DST, {T0,T1,T2,T3}
+	vst1.8	{T0,T1}, [DST]!
+	vst1.8	{T2,T3}, [DST]
 	bx	lr
 EPILOGUE(_nettle_salsa20_2core)
diff --git a/arm/neon/salsa20-core-internal.asm b/arm/neon/salsa20-core-internal.asm
index d59d7b80..1b0f9fde 100644
--- a/arm/neon/salsa20-core-internal.asm
+++ b/arm/neon/salsa20-core-internal.asm
@@ -86,7 +86,9 @@ define(`QROUND', `
 	C _salsa20_core(uint32_t *dst, const uint32_t *src, unsigned rounds)
 
 PROLOGUE(_nettle_salsa20_core)
-	vldm	SRC, {X0,X1,X2,X3}
+	mov	r12, SRC
+	vld1.32	{X0,X1}, [r12]!
+	vld1.32	{X2,X3}, [r12]
 
 	C Input rows little-endian:
 	C	 0  1  2  3	X0
@@ -99,23 +101,10 @@ PROLOGUE(_nettle_salsa20_core)
 	C	 8 13  2  7
 	C	12  1  6 11
 
-	C Input rows big-endian:
-	C	 1  0  3  2	X0
-	C	 5  4  7  6	X1
-	C	 9  8 11 10	X2
-	C	13 12 15 14	X3
-	C even and odd columns switched because
-	C vldm loads consecutive doublewords and
-	C switches words inside them to make them BE
-	C Permuted to:
-	C	 5  0 15 10
-	C	 9  4  3 14
-	C	13  8  7  2
-	C	 1 12 11  6
-
 	C FIXME: Construct in some other way?
 	adr	r12, .Lmasks
-	vldm	r12, {M0101, M0110, M0011}
+	vld1.32	{M0101, M0110}, [r12]!
+	vld1.32	{M0011}, [r12]
 
 	vmov	S1, X1
 	vmov	S2, X2
@@ -160,29 +149,17 @@ PROLOGUE(_nettle_salsa20_core)
 	C	 3  4  9 14  &gt;&gt;&gt; 1
 	C	 2  7  8 13  &gt;&gt;&gt; 2
 	C	 1  6 11 12  &gt;&gt;&gt; 3
-
-	C In big-endian rotate rows, to get
-	C	 5  0 15 10
-	C	 4  3 14  9  &gt;&gt;&gt; 3
-	C	 7  2 13  8  &gt;&gt;&gt; 2
-	C	 6  1 12 11  &gt;&gt;&gt; 1
-	C different number of elements needs to be
-	C extracted on BE because of different column order
-IF_LE(`	vext.32	X1, X1, X1, #3')
-IF_BE(`	vext.32	X1, X1, X1, #1')
+	vext.32	X1, X1, X1, #3
 	vext.32	X2, X2, X2, #2
-IF_LE(`	vext.32	X3, X3, X3, #1')
-IF_BE(`	vext.32	X3, X3, X3, #3')
+	vext.32	X3, X3, X3, #1
 
 	QROUND(X0, X3, X2, X1)
 
 	subs	ROUNDS, ROUNDS, #2
 	C Inverse rotation
-IF_LE(`	vext.32	X1, X1, X1, #1')
-IF_BE(`	vext.32	X1, X1, X1, #3')
+	vext.32	X1, X1, X1, #1
 	vext.32	X2, X2, X2, #2
-IF_LE(`	vext.32	X3, X3, X3, #3')
-IF_BE(`	vext.32	X3, X3, X3, #1')
+	vext.32	X3, X3, X3, #3
 
 	bhi	.Loop
 
@@ -202,19 +179,15 @@ IF_BE(`	vext.32	X3, X3, X3, #1')
 	vbit	X2, X3, M0101
 	vbit	X3, T1, M0101
 
-	vld1.64	{T0}, [SRC]
+	vld1.32	{T0}, [SRC]
 	vadd.u32	X0, X0, T0
 	vadd.u32	X1, X1, S1
 	vadd.u32	X2, X2, S2
 	vadd.u32	X3, X3, S3
 
-	C caller expects result little-endian
-IF_BE(`	vrev32.u8	X0, X0
-	vrev32.u8	X1, X1
-	vrev32.u8	X2, X2
-	vrev32.u8	X3, X3')
-
-	vstm	DST, {X0,X1,X2,X3}
+	C vst1.8 because caller expects results little-endian
+	vst1.8	{X0,X1}, [DST]!
+	vst1.8	{X2,X3}, [DST]
 	bx	lr
 EPILOGUE(_nettle_salsa20_core)
 
-- 
2.29.2


[Attachment #6 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20201225214819</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-12-25 21:48:19-0400</timestampReceived><subject>Re: Release of Nettle-3.7?</subject><body>

Michael Weiser &lt;michael.weiser@gmx.de&gt; writes:

&gt; Longer story for completeness: It seems I ran afoul gdb's way of
&gt; displaying registers in memory endianness again. I knew all this once
&gt; already.[1] I should likely do this more often than every couple of
&gt; years. ;)

I'm always confused by the conventions for ordering of the components of
vector registers. When I write out values in code comments, I try to use
the order in which the elements appeared in memory.

&gt; So for our case where we have a matrix of 32-bit words in host
&gt; endianness that we need to load sequentially into q registers without
&gt; any transposing we can use vld1.32 {q0, q1}, [r1].
&gt;
&gt; This is also a drop-in fix for the 64-bit counter addition.

Sounds good.

&gt; The drawback compared to vldm is that we need to issue two operations to
&gt; load four q registers because each vld1/vst1 can only work with up to
&gt; four d (i.e. two q) registers. This also means that we need to increment
&gt; the base address for the second load which requires a scratch register
&gt; if we want to keep the original value for later reference.

Since we have plenty of registers available, (including r3 which seems
unused and free to clobber), I'd suggest using

   define(`SRCp32', `r3')

and an

   add SRCp32, SRC, #32

in function entry, and then leave both SRC and SRCp32 unmodified for the
rest of the function.

&gt; Regarding performance I found a document from ARM for the Cortex-A8
&gt; which had some cycle numbers[2]. According to it, two vld1's should take
&gt; (at worst/no alignment) six cycles where vldm would run five cycles for the
&gt; same amount of registers. [...]

&gt; My feeling is that it doesn't matter much because it happens outside the
&gt; main loop.

If it's just a cycle or two per call, I think it's ok.

&gt; As expected, all the special treatment of transposed operands can just
&gt; go away because it doesn't happen any more. Also, vld1.32 (for
&gt; sequential loads of 32-bit operands in host-endianness) and vld1.8 (for
&gt; sequential store of register contents to get an implicit little-endian
&gt; store without any vrev32.u8s) works the same on LE as well as BE.

Neat. Use of vld1.8 is worth a commment in the code (and/or arm/README).

&gt; Option 2: By coincidence I found that vldm/vstm can work with s
&gt; registers originally intended for use with VFP. They're just a different
&gt; view of the d0-d15 or q0-q7 registers. When giving s registers as
&gt; arguments to vldm/vstm they start to behave identically to vst1.32, i.e.
&gt; load/save 32-bit words sequentially.
[...]
&gt; Also, it's not entirely clear to me from the documentation if this will
&gt; work on every ARM core that supports NEON. The NEON programmer's
&gt; guide[3] states that VLDM/VSTM is a shared VFP/NEON instruction and s
&gt; registers *can* be specified. I read that to mean that it will work on
&gt; every NEON core. It appears that every core that has NEON also has at
&gt; least VFP3 but I've found no definite statement to that effect.  Some
&gt; sources speak of NEON as an extension to VFP but I've found no
&gt; confirmation by ARM.

That sounds a bit complicated, and since there's no great benefit over
vld1, maybe best to stay away from that?

&gt; All in all, option 1 (vld1/vst1) seems more straightforward and
&gt; elegant to me.

Sounds good to me too.

&gt; From 07c7ea6d62b33aa0c3e176c0e54ffc409fd78516 Mon Sep 17 00:00:00 2001
&gt; From: Michael Weiser &lt;michael.weiser@gmx.de&gt;
&gt; Date: Fri, 25 Dec 2020 17:13:52 +0100
&gt; Subject: [PATCH 2/2] arm: Unify neon asm for big- and little-endian modes
&gt;
&gt; Switch arm neon assemlber routines to endianness-agnostic loads and
&gt; stores where possible to avoid modifications to the rest of the code.
&gt; This involves switching to vld1.32 for loading consecutive 32-bit words
&gt; in host endianness as well as vst1.8 for storing back to memory in
&gt; little-endian order as required by the caller.

I like this approach. It would be nice if you coudl benchmark it on
little-endian, to verify that there's no unexpectedly large speed
regression (a regression of just cycle or two per block, if that's at
all measurable, is ok, I think).

&gt;  PROLOGUE(_nettle_chacha_3core)
&gt; -	vldm	SRC, {X0,X1,X2,X3}
&gt; +	mov	r12, SRC
&gt; +	vld1.32	{X0,X1}, [r12]!
&gt; +	vld1.32	{X2,X3}, [r12]

My suggestion is to do this as

	add SRCp32, SRC, #32
	vld1.32	{X0,X1}, [SRC]
	vld1.32	{X2,X3}, [SRCp32]

and reuse SRCp32 for the second load of the same data, further down
(assuming r3 really is free to use for this purpose; if we have to save
and restore a register to do this, your approach with temporary use of
r12 seems better). Another option, with no need for an extra registerm
is to just use post-increment, modifying SRC here. And either explicitly
subtract 32, or use opposite load order and pre-decrement for the second
load.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201229220021</emailId><senderName>Michael Weiser</senderName><senderEmail>michael.weiser@gmx.de</senderEmail><timestampReceived>2020-12-29 22:00:21-0400</timestampReceived><subject>Re: Release of Nettle-3.7?</subject><body>

Hello Niels,

On Fri, Dec 25, 2020 at 10:48:19PM +0100, Niels Möller wrote:

&gt; Since we have plenty of registers available, (including r3 which seems
&gt; unused and free to clobber), I'd suggest using

&gt; define(`SRCp32', `r3')

&gt; and an

&gt; add SRCp32, SRC, #32

&gt; in function entry, and then leave both SRC and SRCp32 unmodified for the
&gt; rest of the function.

I've done that and according to nettle-benchmark it saves one to two
cycles per block compared to the mov+postincrement approach.

&gt; &gt; As expected, all the special treatment of transposed operands can just
&gt; &gt; go away because it doesn't happen any more. Also, vld1.32 (for
&gt; &gt; sequential loads of 32-bit operands in host-endianness) and vld1.8 (for
&gt; &gt; sequential store of register contents to get an implicit little-endian
&gt; &gt; store without any vrev32.u8s) works the same on LE as well as BE.
&gt; Neat. Use of vld1.8 is worth a commment in the code (and/or arm/README).

I added those where it seemed to make sense. It was already in the
README but I've extended it a bit with the new findings.

&gt; &gt; Option 2: By coincidence I found that vldm/vstm can work with s
&gt; &gt; registers originally intended for use with VFP. They're just a different
&gt; That sounds a bit complicated, and since there's no great benefit over
&gt; vld1, maybe best to stay away from that?

Also, interestingly, when I use vldm to s regs wherever possible (see
second attached patch), it doesn't give any speedup. It saves the
scratch register in all routines I've touched, though. In general, it
seems that add+2*vld1.32 is exactly the same number of cycles as the
equivalent vldm.

&gt; &gt; Switch arm neon assemlber routines to endianness-agnostic loads and
&gt; &gt; stores where possible to avoid modifications to the rest of the code.
&gt; &gt; This involves switching to vld1.32 for loading consecutive 32-bit words
&gt; &gt; in host endianness as well as vst1.8 for storing back to memory in
&gt; &gt; little-endian order as required by the caller.
&gt; I like this approach. It would be nice if you coudl benchmark it on
&gt; little-endian, to verify that there's no unexpectedly large speed
&gt; regression (a regression of just cycle or two per block, if that's at
&gt; all measurable, is ok, I think).

It comes out at around seven cycles per block slowdown for chacha-3core
and five for salsa20-2core. I trace this to vst1.8. It's just slower
than vstm (in contrast to vldm vs. vld1.32). I managed to save a
cumulative two cycles by rescheduling instructions so that there's no
two consecutive vst1.8s which seems to avoid stalls in the pipeline or
bus access waits (at least on my machine). Element width (8 vs. 32 vs.
64) doesn't seem to play into it. Alignment can't be used to improve
performance: The tests immediately bus error when giving a :64
alignment hint to vst1.8.

Baseline with --disable-assembler comes in with these numbers on my
Cubieboard2 with 1GHz Allwinner A20 which is a Cortex-A7 implementation:

[michael@c2-le:~/nettle/build-noasm/examples] LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1000000000 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   30.43       31.34      2005.82
            chacha      decrypt   30.41       31.36      2006.89

   chacha_poly1305      encrypt   23.57       40.47      2589.77
   chacha_poly1305      decrypt   23.55       40.50      2592.15
   chacha_poly1305       update  104.42        9.13       584.51

           salsa20      encrypt   35.10       27.17      1738.73
           salsa20      decrypt   35.10       27.17      1738.75

        salsa20r12      encrypt   50.12       19.03      1217.75
        salsa20r12      decrypt   50.15       19.01      1216.93

(BTW: Am I using the benchmark correctly, particularly the frequency
parameter?)

Baseline unmodified assembler routines (without --enable-fat) come in
at:

[michael@c2-le:~/nettle/build-orig/examples] LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1000000000 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   63.06       15.12       967.83
            chacha      decrypt   63.06       15.12       967.82

   chacha_poly1305      encrypt   39.18       24.34      1557.72
   chacha_poly1305      decrypt   39.18       24.34      1557.96
   chacha_poly1305       update  104.38        9.14       584.75

           salsa20      encrypt   62.15       15.34       982.04
           salsa20      decrypt   62.07       15.36       983.33

        salsa20r12      encrypt   92.69       10.29       658.48
        salsa20r12      decrypt   92.70       10.29       658.43

Attached unified code (patch 0001) comes in like this:

[michael@c2-le:~/nettle/build-unified-add/examples] LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1000000000 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   62.61       15.23       974.79
            chacha      decrypt   62.62       15.23       974.72

   chacha_poly1305      encrypt   39.14       24.36      1559.28
   chacha_poly1305      decrypt   39.18       24.34      1558.00
   chacha_poly1305       update  103.65        9.20       588.88

           salsa20      encrypt   61.80       15.43       987.65
           salsa20      decrypt   61.81       15.43       987.51

        salsa20r12      encrypt   91.88       10.38       664.30
        salsa20r12      decrypt   91.91       10.38       664.07

What's nice is that the same code gives very consistent numbers on BE
(no idea what's going on with poly1305 though):

[michael@c2-be:~/nettle/build-unified-add/examples] LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1000000000 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   62.56       15.25       975.69
            chacha      decrypt   62.62       15.23       974.68

   chacha_poly1305      encrypt   38.40       24.83      1589.32
   chacha_poly1305      decrypt   38.40       24.83      1589.38
   chacha_poly1305       update   99.92        9.54       610.86

           salsa20      encrypt   61.80       15.43       987.58
           salsa20      decrypt   61.81       15.43       987.41

        salsa20r12      encrypt   91.90       10.38       664.14
        salsa20r12      decrypt   91.93       10.37       663.92

As said, the second patch (switching back to vldm via s regs where
possible) doesn't change these numbers at all (but saves a register).

(What's nice about my boards it that due to missing power-saving and
frequency-scaling functionality they give very, very consistent numbers
across multiple runs.)

My first reflex is that 400Kbyte/s for chacha and 350Kbyte/s for salsa20
is relevant enough to keep separate implementations for LE and BE in the
code *or* dig deeper into why vst1.8 is so much slower.

Do you (or anybody else) have a hardware arm board for testing, possibly
with a Cortex A8 or A9 implementation to see how it behaves there?

I have a couple of RasPis and little- and big-endian pine64s (aarch64)
gathering dust in a box which I could fire up for some testing (not sure
about 32-bit support on the pine64s, though).

&gt; and reuse SRCp32 for the second load of the same data, further down
&gt; (assuming r3 really is free to use for this purpose; if we have to save

I read AAPCS as saying that r3 can be used as scratch register inbetween
subroutine calls. Since we don't to subroutine calls, its use should be
fine.

I've got one side-track which might point to some peculiarity of my
machine: The unmodified assembler code *without* chacha-3core and
salsa20-2core (files moved out of the way before configure) is no faster
or even slower than what the C compiler produces:

[michael@c2-le:~/nettle/build-no23core/examples] LD_LIBRARY_PATH=../.lib \
./nettle-benchmark -f 1000000000 chacha salsa20

         Algorithm         mode Mbyte/s cycles/byte cycles/block

            chacha      encrypt   31.35       30.42      1946.66
            chacha      decrypt   31.34       30.43      1947.30

   chacha_poly1305      encrypt   24.10       39.57      2532.24
   chacha_poly1305      decrypt   24.10       39.57      2532.21
   chacha_poly1305       update  104.42        9.13       584.53

           salsa20      encrypt   30.38       31.39      2008.96
           salsa20      decrypt   30.39       31.38      2008.34

        salsa20r12      encrypt   47.00       20.29      1298.56
        salsa20r12      decrypt   47.01       20.29      1298.25

Does this seem reasonable or does it point to some flaw in my
benchmarking or system software/hardware? (I've done my best using gdb
to verify that the asm routines are in use. Unfortunately,
nettle-benchmark is resisting attempts to ltrace or gdb-debug it, so I
diagnosed the testsuite tests instead.)
-- 
Thanks,
Michael


["0001-arm-Unify-neon-asm-for-big-and-little-endian-modes.patch" (text/x-diff)]

From d5030256fb01e7fc74f7c42987d70c98e6dfc0db Mon Sep 17 00:00:00 2001
From: Michael Weiser &lt;michael.weiser@gmx.de&gt;
Date: Fri, 25 Dec 2020 17:13:52 +0100
Subject: [PATCH 1/2] arm: Unify neon asm for big- and little-endian modes

Switch arm neon assembler routines to endianness-agnostic loads and
stores where possible to avoid modifications to the rest of the code.
This involves switching to vld1.32 for loading consecutive 32-bit words
in host endianness as well as vst1.8 for storing back to memory in
little-endian order as required by the caller. Where necessary, r3 is
used to store the precalculated offset into the source vector for the
secondary load operations.

This incurs a performance penalty of around seven cycles per block for
chacha-3core and five per block for salsa20-2core. These seems to stem
from each vst1.x taking a cycle longer than the equivalent compound
vldm.

vst1.x (at least on the Allwinner A20 Cortex-A7 implementation) seems to
interfer with itself on subsequent calls, slowing it down. So we
reschedule some instructions to do stores as soon as results become
available to have some other calculations or loads before the next
vst1.x. This reliably saves two additional cycles per block on salsa20
and chacha which would otherwise be incurred.

vld1.x does not seem to suffer from this or at least not to a level
where two consecutive vld1.x run slower than an equivalent vldm.
Rescheduling them similarly did not improve performance beyond that of
vldm.

Signed-off-by: Michael Weiser &lt;michael.weiser@gmx.de&gt;
---
 arm/README                         | 14 +++++++-
 arm/neon/chacha-3core.asm          | 32 ++++++++++++-----
 arm/neon/chacha-core-internal.asm  | 45 +++++++----------------
 arm/neon/salsa20-2core.asm         | 25 +++++++++----
 arm/neon/salsa20-core-internal.asm | 57 +++++++++---------------------
 5 files changed, 84 insertions(+), 89 deletions(-)

diff --git a/arm/README b/arm/README
index 1ba54e0d..03149002 100644
--- a/arm/README
+++ b/arm/README
@@ -70,12 +70,24 @@ If data is to be processed with bit operations only, endianness can be ignored
 because byte-swapping on load and store will cancel each other out. Shifts
 however have to be inverted. See arm/memxor.asm for an example.
 
-3. vld1.8
+3. v{ld,st}1.{8,32}
 
 NEON's vld instruction can be used to produce endianness-neutral code. vld1.8
 will load a byte sequence into a register regardless of memory endianness. This
 can be used to process byte sequences. See arm/neon/umac-nh.asm for example.
 
+In the same fashion, vst1.8 can be used do a little-endian store. See
+arm/neon/salsa and chacha routines for examples.
+
+NOTE: vst1.x (at least on the Allwinner A20 Cortex-A7 implementation) seems to
+interfer with itself on subsequent calls, slowing it down. This can be avoided
+by putting calculcations or loads inbetween two vld1.x stores.
+
+Similarly, vld1.32 is used in chacha and salsa routines where 32-bit operands
+are stored in host-endianness in RAM but need to be loaded sequentially without
+the distortion introduced by vldm/vstm. Consecutive vld1.x instructions do not
+seem to suffer from slowdown similar to vst1.x.
+
 4. vldm/vstm
 
 Care has to be taken when using vldm/vstm because they have two non-obvious
diff --git a/arm/neon/chacha-3core.asm b/arm/neon/chacha-3core.asm
index bd1cf63c..f9497c09 100644
--- a/arm/neon/chacha-3core.asm
+++ b/arm/neon/chacha-3core.asm
@@ -36,6 +36,7 @@ ifelse(`
 define(`DST', `r0')
 define(`SRC', `r1')
 define(`ROUNDS', `r2')
+define(`SRCp32', `r3')
 
 C State, X, Y and Z representing consecutive blocks
 define(`X0', `q0')
@@ -64,10 +65,13 @@ define(`T3', `q7')
 	C _chacha_3core(uint32_t *dst, const uint32_t *src, unsigned rounds)
 
 PROLOGUE(_nettle_chacha_3core)
-	vldm	SRC, {X0,X1,X2,X3}
+	C loads using vld1.32 to be endianness-neutral wrt consecutive 32-bit words
+	add	SRCp32, SRC, #32
+	vld1.32	{X0,X1}, [SRC]
+	vld1.32	{X2,X3}, [SRCp32]
 	vpush	{q4,q5,q6,q7}
 	adr	r12, .Lcount1
-	vld1.64 {Z3}, [r12]
+	vld1.32 {Z3}, [r12]
 
 	vadd.i64	Y3, X3, Z3	C Increment 64-bit counter
 	vadd.i64	Z3, Y3, Z3
@@ -213,33 +217,45 @@ PROLOGUE(_nettle_chacha_3core)
 	vadd.i32	Y3, Y3, T2
 	vadd.i32	Z3, Z3, T3
 
-	vldm	SRC, {T0,T1,T2,T3}
+	vld1.32	{T0,T1}, [SRC]
 	vadd.i32	X0, X0, T0
 	vadd.i32	X1, X1, T1
+
+	C vst1.8 because caller expects results little-endian
+	C interleave loads, calculations and stores to save cycles on stores
+	vst1.8	{X0,X1}, [DST]!
+
+	vld1.32	{T2,T3}, [SRCp32]
 	vadd.i32	X2, X2, T2
 	vadd.i32	X3, X3, T3
-	vstmia	DST!, {X0,X1,X2,X3}
+	vst1.8	{X2,X3}, [DST]!
 
 	vadd.i32	Y0, Y0, T0
 	vadd.i32	Y1, Y1, T1
+	vst1.8	{Y0,Y1}, [DST]!
+
 	vadd.i32	Y2, Y2, T2
-	vstmia	DST!, {Y0,Y1,Y2,Y3}
+	vst1.8	{Y2,Y3}, [DST]!
 
 	vadd.i32	Z0, Z0, T0
 	vadd.i32	Z1, Z1, T1
+	vst1.8	{Z0,Z1}, [DST]!
+
 	vadd.i32	Z2, Z2, T2
 
 	vpop	{q4,q5,q6,q7}
 
-	vstm	DST, {Z0,Z1,Z2,Z3}
+	vst1.8	{Z2,Z3}, [DST]
 	bx	lr
 EPILOGUE(_nettle_chacha_3core)
 
 PROLOGUE(_nettle_chacha_3core32)
-	vldm	SRC, {X0,X1,X2,X3}
+	add	SRCp32, SRC, #32
+	vld1.32	{X0,X1}, [SRC]
+	vld1.32	{X2,X3}, [SRCp32]
 	vpush	{q4,q5,q6,q7}
 	adr	r12, .Lcount1
-	vld1.64 {Z3}, [r12]
+	vld1.32 {Z3}, [r12]
 
 	vadd.i32	Y3, X3, Z3	C Increment 32-bit counter
 	vadd.i32	Z3, Y3, Z3
diff --git a/arm/neon/chacha-core-internal.asm b/arm/neon/chacha-core-internal.asm
index b0a775bd..914815f2 100644
--- a/arm/neon/chacha-core-internal.asm
+++ b/arm/neon/chacha-core-internal.asm
@@ -83,7 +83,9 @@ define(`QROUND', `
 	C _chacha_core(uint32_t *dst, const uint32_t *src, unsigned rounds)
 
 PROLOGUE(_nettle_chacha_core)
-	vldm	SRC, {X0,X1,X2,X3}
+	C loads using vld1.32 to be endianness-neutral wrt consecutive 32-bit words
+	vld1.32	{X0,X1}, [SRC]!		C SRC changed!
+	vld1.32	{X2,X3}, [SRC]
 
 	vmov	S0, X0
 	vmov	S1, X1
@@ -96,15 +98,6 @@ PROLOGUE(_nettle_chacha_core)
 	C	 8  9 10 11	X2
 	C	12 13 14 15	X3
 
-	C Input rows big-endian:
-	C	 1  0  3  2	X0
-	C	 5  4  7  6	X1
-	C	 9  8 11 10	X2
-	C	13 12 15 14	X3
-	C even and odd columns switched because
-	C vldm loads consecutive doublewords and
-	C switches words inside them to make them BE
-
 .Loop:
 	QROUND(X0, X1, X2, X3)
 
@@ -113,44 +106,30 @@ PROLOGUE(_nettle_chacha_core)
 	C	 5  6  7  4  &gt;&gt;&gt; 3
 	C	10 11  8  9  &gt;&gt;&gt; 2
 	C	15 12 13 14  &gt;&gt;&gt; 1
-
-	C In big-endian rotate rows, to get
-	C	 1  0  3  2
-	C	 6  5  4  7  &gt;&gt;&gt; 1
-	C	11 10  9  8  &gt;&gt;&gt; 2
-	C	12 15 14 13  &gt;&gt;&gt; 3
-	C different number of elements needs to be
-	C extracted on BE because of different column order
-IF_LE(`	vext.32	X1, X1, X1, #1')
-IF_BE(`	vext.32	X1, X1, X1, #3')
+	vext.32	X1, X1, X1, #1
 	vext.32	X2, X2, X2, #2
-IF_LE(`	vext.32	X3, X3, X3, #3')
-IF_BE(`	vext.32	X3, X3, X3, #1')
+	vext.32	X3, X3, X3, #3
 
 	QROUND(X0, X1, X2, X3)
 
 	subs	ROUNDS, ROUNDS, #2
 	C Inverse rotation
-IF_LE(`	vext.32	X1, X1, X1, #3')
-IF_BE(`	vext.32	X1, X1, X1, #1')
+	vext.32	X1, X1, X1, #3
 	vext.32	X2, X2, X2, #2
-IF_LE(`	vext.32	X3, X3, X3, #1')
-IF_BE(`	vext.32	X3, X3, X3, #3')
+	vext.32	X3, X3, X3, #1
 
 	bhi	.Loop
 
 	vadd.u32	X0, X0, S0
 	vadd.u32	X1, X1, S1
+
+	C vst1.8 because caller expects results little-endian
+	vst1.8	{X0,X1}, [DST]!
+
 	vadd.u32	X2, X2, S2
 	vadd.u32	X3, X3, S3
 
-	C caller expects result little-endian
-IF_BE(`	vrev32.u8	X0, X0
-	vrev32.u8	X1, X1
-	vrev32.u8	X2, X2
-	vrev32.u8	X3, X3')
-
-	vstm	DST, {X0,X1,X2,X3}
+	vst1.8	{X2,X3}, [DST]
 	bx	lr
 EPILOGUE(_nettle_chacha_core)
 
diff --git a/arm/neon/salsa20-2core.asm b/arm/neon/salsa20-2core.asm
index b3fe7e94..e90147ed 100644
--- a/arm/neon/salsa20-2core.asm
+++ b/arm/neon/salsa20-2core.asm
@@ -36,6 +36,7 @@ ifelse(`
 define(`DST', `r0')
 define(`SRC', `r1')
 define(`ROUNDS', `r2')
+define(`SRCp32', `r3')
 
 C State, even elements in X, odd elements in Y
 define(`X0', `q0')
@@ -58,11 +59,14 @@ define(`T3', `q15')
 
 	C _salsa20_2core(uint32_t *dst, const uint32_t *src, unsigned rounds)
 PROLOGUE(_nettle_salsa20_2core)
-	vldm	SRC, {X0,X1,X2,X3}
+	C loads using vld1.32 to be endianness-neutral wrt consecutive 32-bit words
+	add	SRCp32, SRC, #32
+	vld1.32	{X0,X1}, [SRC]
+	vld1.32	{X2,X3}, [SRCp32]
 	adr	r12, .Lcount1
 
 	vmov	Y3, X0
-	vld1.64 {Y1}, [r12]
+	vld1.32 {Y1}, [r12]
 	vmov	Y0, X1
 	vadd.i64 Y1, Y1, X2	C Increment counter
 	vmov	Y2, X3
@@ -180,7 +184,8 @@ C Inverse swaps and transpositions
 	vswp	D1REG(Y0), D1REG(Y2)
 	vswp	D1REG(Y1), D1REG(Y3)
 
-	vldm	SRC, {T0,T1,T2,T3}
+	vld1.32	{T0,T1}, [SRC]
+	vld1.32	{T2,T3}, [SRCp32]
 
 	vtrn.32	X0, Y3
 	vtrn.32	X1, Y0
@@ -190,17 +195,23 @@ C Inverse swaps and transpositions
 C Add in the original context
 	vadd.i32	X0, X0, T0
 	vadd.i32	X1, X1, T1
+
+C vst1.8 because caller expects results little-endian
+C interleave loads, calculations and stores to save cycles on stores
+	vst1.8	{X0,X1}, [DST]!
+
 	vadd.i32	X2, X2, T2
 	vadd.i32	X3, X3, T3
+	vst1.8	{X2,X3}, [DST]!
 
-	vstmia	DST!, {X0,X1,X2,X3}
-	vld1.64 {X0}, [r12]
+	vld1.32 {X0}, [r12]
 	vadd.i32	T0, T0, Y3
 	vadd.i64	T2, T2, X0
 	vadd.i32	T1, T1, Y0
+	vst1.8	{T0,T1}, [DST]!
+
 	vadd.i32	T2, T2, Y1
 	vadd.i32	T3, T3, Y2
-
-	vstm	DST, {T0,T1,T2,T3}
+	vst1.8	{T2,T3}, [DST]
 	bx	lr
 EPILOGUE(_nettle_salsa20_2core)
diff --git a/arm/neon/salsa20-core-internal.asm b/arm/neon/salsa20-core-internal.asm
index d59d7b80..9f691a14 100644
--- a/arm/neon/salsa20-core-internal.asm
+++ b/arm/neon/salsa20-core-internal.asm
@@ -36,6 +36,7 @@ ifelse(`
 define(`DST', `r0')
 define(`SRC', `r1')
 define(`ROUNDS', `r2')
+define(`SRCp32', `r3')
 
 define(`X0', `q0')
 define(`X1', `q1')
@@ -86,7 +87,10 @@ define(`QROUND', `
 	C _salsa20_core(uint32_t *dst, const uint32_t *src, unsigned rounds)
 
 PROLOGUE(_nettle_salsa20_core)
-	vldm	SRC, {X0,X1,X2,X3}
+	C loads using vld1.32 to be endianness-neutral wrt consecutive 32-bit words
+	add	SRCp32, SRC, #32
+	vld1.32	{X0,X1}, [SRC]
+	vld1.32	{X2,X3}, [SRCp32]
 
 	C Input rows little-endian:
 	C	 0  1  2  3	X0
@@ -99,23 +103,10 @@ PROLOGUE(_nettle_salsa20_core)
 	C	 8 13  2  7
 	C	12  1  6 11
 
-	C Input rows big-endian:
-	C	 1  0  3  2	X0
-	C	 5  4  7  6	X1
-	C	 9  8 11 10	X2
-	C	13 12 15 14	X3
-	C even and odd columns switched because
-	C vldm loads consecutive doublewords and
-	C switches words inside them to make them BE
-	C Permuted to:
-	C	 5  0 15 10
-	C	 9  4  3 14
-	C	13  8  7  2
-	C	 1 12 11  6
-
 	C FIXME: Construct in some other way?
 	adr	r12, .Lmasks
-	vldm	r12, {M0101, M0110, M0011}
+	vld1.32	{M0101, M0110}, [r12]!
+	vld1.32	{M0011}, [r12]
 
 	vmov	S1, X1
 	vmov	S2, X2
@@ -160,29 +151,17 @@ PROLOGUE(_nettle_salsa20_core)
 	C	 3  4  9 14  &gt;&gt;&gt; 1
 	C	 2  7  8 13  &gt;&gt;&gt; 2
 	C	 1  6 11 12  &gt;&gt;&gt; 3
-
-	C In big-endian rotate rows, to get
-	C	 5  0 15 10
-	C	 4  3 14  9  &gt;&gt;&gt; 3
-	C	 7  2 13  8  &gt;&gt;&gt; 2
-	C	 6  1 12 11  &gt;&gt;&gt; 1
-	C different number of elements needs to be
-	C extracted on BE because of different column order
-IF_LE(`	vext.32	X1, X1, X1, #3')
-IF_BE(`	vext.32	X1, X1, X1, #1')
+	vext.32	X1, X1, X1, #3
 	vext.32	X2, X2, X2, #2
-IF_LE(`	vext.32	X3, X3, X3, #1')
-IF_BE(`	vext.32	X3, X3, X3, #3')
+	vext.32	X3, X3, X3, #1
 
 	QROUND(X0, X3, X2, X1)
 
 	subs	ROUNDS, ROUNDS, #2
 	C Inverse rotation
-IF_LE(`	vext.32	X1, X1, X1, #1')
-IF_BE(`	vext.32	X1, X1, X1, #3')
+	vext.32	X1, X1, X1, #1
 	vext.32	X2, X2, X2, #2
-IF_LE(`	vext.32	X3, X3, X3, #3')
-IF_BE(`	vext.32	X3, X3, X3, #1')
+	vext.32	X3, X3, X3, #3
 
 	bhi	.Loop
 
@@ -202,19 +181,17 @@ IF_BE(`	vext.32	X3, X3, X3, #1')
 	vbit	X2, X3, M0101
 	vbit	X3, T1, M0101
 
-	vld1.64	{T0}, [SRC]
+	vld1.32	{T0}, [SRC]
 	vadd.u32	X0, X0, T0
 	vadd.u32	X1, X1, S1
+
+	C vst1.8 because caller expects results little-endian
+	vst1.8	{X0,X1}, [DST]!
+
 	vadd.u32	X2, X2, S2
 	vadd.u32	X3, X3, S3
 
-	C caller expects result little-endian
-IF_BE(`	vrev32.u8	X0, X0
-	vrev32.u8	X1, X1
-	vrev32.u8	X2, X2
-	vrev32.u8	X3, X3')
-
-	vstm	DST, {X0,X1,X2,X3}
+	vst1.8	{X2,X3}, [DST]
 	bx	lr
 EPILOGUE(_nettle_salsa20_core)
 
-- 
2.29.2


["0002-arm-Use-vldm-to-s-regs-where-possbile.patch" (text/x-diff)]

From 68b069504c34d773439d7ef4cb2b38d0a2af5ce8 Mon Sep 17 00:00:00 2001
From: Michael Weiser &lt;michael.weiser@gmx.de&gt;
Date: Tue, 29 Dec 2020 20:35:43 +0100
Subject: [PATCH 2/2] arm: Use vldm to s regs where possbile

Doesn't yield performance increase though.
---
 arm/neon/chacha-3core.asm          | 14 ++++----------
 arm/neon/chacha-core-internal.asm  |  5 ++---
 arm/neon/salsa20-2core.asm         | 12 +++++-------
 arm/neon/salsa20-core-internal.asm |  7 ++-----
 4 files changed, 13 insertions(+), 25 deletions(-)

diff --git a/arm/neon/chacha-3core.asm b/arm/neon/chacha-3core.asm
index f9497c09..32cffa3d 100644
--- a/arm/neon/chacha-3core.asm
+++ b/arm/neon/chacha-3core.asm
@@ -36,7 +36,6 @@ ifelse(`
 define(`DST', `r0')
 define(`SRC', `r1')
 define(`ROUNDS', `r2')
-define(`SRCp32', `r3')
 
 C State, X, Y and Z representing consecutive blocks
 define(`X0', `q0')
@@ -65,10 +64,8 @@ define(`T3', `q7')
 	C _chacha_3core(uint32_t *dst, const uint32_t *src, unsigned rounds)
 
 PROLOGUE(_nettle_chacha_3core)
-	C loads using vld1.32 to be endianness-neutral wrt consecutive 32-bit words
-	add	SRCp32, SRC, #32
-	vld1.32	{X0,X1}, [SRC]
-	vld1.32	{X2,X3}, [SRCp32]
+	C load to s regs to be endianness-neutral wrt consecutive 32-bit words
+	vldm	SRC, {s0-s15}
 	vpush	{q4,q5,q6,q7}
 	adr	r12, .Lcount1
 	vld1.32 {Z3}, [r12]
@@ -217,7 +214,7 @@ PROLOGUE(_nettle_chacha_3core)
 	vadd.i32	Y3, Y3, T2
 	vadd.i32	Z3, Z3, T3
 
-	vld1.32	{T0,T1}, [SRC]
+	vldm	SRC, {s16-s31}
 	vadd.i32	X0, X0, T0
 	vadd.i32	X1, X1, T1
 
@@ -225,7 +222,6 @@ PROLOGUE(_nettle_chacha_3core)
 	C interleave loads, calculations and stores to save cycles on stores
 	vst1.8	{X0,X1}, [DST]!
 
-	vld1.32	{T2,T3}, [SRCp32]
 	vadd.i32	X2, X2, T2
 	vadd.i32	X3, X3, T3
 	vst1.8	{X2,X3}, [DST]!
@@ -250,9 +246,7 @@ PROLOGUE(_nettle_chacha_3core)
 EPILOGUE(_nettle_chacha_3core)
 
 PROLOGUE(_nettle_chacha_3core32)
-	add	SRCp32, SRC, #32
-	vld1.32	{X0,X1}, [SRC]
-	vld1.32	{X2,X3}, [SRCp32]
+	vldm	SRC, {s0-s15}
 	vpush	{q4,q5,q6,q7}
 	adr	r12, .Lcount1
 	vld1.32 {Z3}, [r12]
diff --git a/arm/neon/chacha-core-internal.asm b/arm/neon/chacha-core-internal.asm
index 914815f2..a4b77122 100644
--- a/arm/neon/chacha-core-internal.asm
+++ b/arm/neon/chacha-core-internal.asm
@@ -83,9 +83,8 @@ define(`QROUND', `
 	C _chacha_core(uint32_t *dst, const uint32_t *src, unsigned rounds)
 
 PROLOGUE(_nettle_chacha_core)
-	C loads using vld1.32 to be endianness-neutral wrt consecutive 32-bit words
-	vld1.32	{X0,X1}, [SRC]!		C SRC changed!
-	vld1.32	{X2,X3}, [SRC]
+	C load to s regs to be endianness-neutral wrt consecutive 32-bit words
+	vldm	SRC, {s0-s15}
 
 	vmov	S0, X0
 	vmov	S1, X1
diff --git a/arm/neon/salsa20-2core.asm b/arm/neon/salsa20-2core.asm
index e90147ed..ac09af69 100644
--- a/arm/neon/salsa20-2core.asm
+++ b/arm/neon/salsa20-2core.asm
@@ -36,7 +36,6 @@ ifelse(`
 define(`DST', `r0')
 define(`SRC', `r1')
 define(`ROUNDS', `r2')
-define(`SRCp32', `r3')
 
 C State, even elements in X, odd elements in Y
 define(`X0', `q0')
@@ -59,10 +58,8 @@ define(`T3', `q15')
 
 	C _salsa20_2core(uint32_t *dst, const uint32_t *src, unsigned rounds)
 PROLOGUE(_nettle_salsa20_2core)
-	C loads using vld1.32 to be endianness-neutral wrt consecutive 32-bit words
-	add	SRCp32, SRC, #32
-	vld1.32	{X0,X1}, [SRC]
-	vld1.32	{X2,X3}, [SRCp32]
+	C load to s regs to be endianness-neutral wrt consecutive 32-bit words
+	vldm	SRC, {s0-s15}
 	adr	r12, .Lcount1
 
 	vmov	Y3, X0
@@ -184,8 +181,9 @@ C Inverse swaps and transpositions
 	vswp	D1REG(Y0), D1REG(Y2)
 	vswp	D1REG(Y1), D1REG(Y3)
 
-	vld1.32	{T0,T1}, [SRC]
-	vld1.32	{T2,T3}, [SRCp32]
+	C loads using vld1.32 to be endianness-neutral wrt consecutive 32-bit words
+	vld1.32	{T0,T1}, [SRC]!		C SRC changed!
+	vld1.32	{T2,T3}, [SRC]
 
 	vtrn.32	X0, Y3
 	vtrn.32	X1, Y0
diff --git a/arm/neon/salsa20-core-internal.asm b/arm/neon/salsa20-core-internal.asm
index 9f691a14..83ef263d 100644
--- a/arm/neon/salsa20-core-internal.asm
+++ b/arm/neon/salsa20-core-internal.asm
@@ -36,7 +36,6 @@ ifelse(`
 define(`DST', `r0')
 define(`SRC', `r1')
 define(`ROUNDS', `r2')
-define(`SRCp32', `r3')
 
 define(`X0', `q0')
 define(`X1', `q1')
@@ -87,10 +86,8 @@ define(`QROUND', `
 	C _salsa20_core(uint32_t *dst, const uint32_t *src, unsigned rounds)
 
 PROLOGUE(_nettle_salsa20_core)
-	C loads using vld1.32 to be endianness-neutral wrt consecutive 32-bit words
-	add	SRCp32, SRC, #32
-	vld1.32	{X0,X1}, [SRC]
-	vld1.32	{X2,X3}, [SRCp32]
+	C load to s regs to be endianness-neutral wrt consecutive 32-bit words
+	vldm	SRC, {s0-s15}
 
 	C Input rows little-endian:
 	C	 0  1  2  3	X0
-- 
2.29.2


[Attachment #5 (text/plain)]

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20201230201224</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-12-30 20:12:24-0400</timestampReceived><subject>Re: Release of Nettle-3.7?</subject><body>

Michael Weiser &lt;michael.weiser@gmx.de&gt; writes:

&gt; It comes out at around seven cycles per block slowdown for chacha-3core
&gt; and five for salsa20-2core. I trace this to vst1.8. It's just slower
&gt; than vstm (in contrast to vldm vs. vld1.32). I managed to save a
&gt; cumulative two cycles by rescheduling instructions so that there's no
&gt; two consecutive vst1.8s which seems to avoid stalls in the pipeline or
&gt; bus access waits (at least on my machine). Element width (8 vs. 32 vs.
&gt; 64) doesn't seem to play into it. 

Thanks for investigating. Maybe keep some IF_BE / IF_LE just for the
store instructions, to stay with vstm on little-endian?

&gt; (BTW: Am I using the benchmark correctly, particularly the frequency
&gt; parameter?)

I think it's right. But it's a floating point number, so -f 1e9 for 1
GHz should work too.

&gt; Alignment can't be used to improve
&gt; performance: The tests immediately bus error when giving a :64
&gt; alignment hint to vst1.8.

Unfortunately, I'm not aware of any nice and portable way to enforce
alignment from the calling C code.
 
&gt; Do you (or anybody else) have a hardware arm board for testing, possibly
&gt; with a Cortex A8 or A9 implementation to see how it behaves there?

I have access to the GMP test systems on
https://gmplib.org/devel/testsystems, but little time to benchmark
things in the near future. 

&gt; I've got one side-track which might point to some peculiarity of my
&gt; machine: The unmodified assembler code *without* chacha-3core and
&gt; salsa20-2core (files moved out of the way before configure) is no faster
&gt; or even slower than what the C compiler produces:

[...]

&gt; Does this seem reasonable or does it point to some flaw in my
&gt; benchmarking or system software/hardware? 

That's unexpected. In principle I guess it's possible for the C compiler
to generate great vectorized code, but that seems a bit unlikely. Do you
get the same results if you build Nettle-3.6? 

From ChangeLog comments, it seems I got 45% speedup for Salsa20,
compared to the C implementation, when I wrote the original neon
assembly code. At the time, benchmarked on a pandaboard (cortex a9), if
I remember correctly.

Is it for a fat build? If so, it's possibly that the fat setup logic
selects the C implementation is this hacked setup (but on the other
hand, I'd guess a fat build may just failed at link time if these files
are removed).

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201220171421</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-12-20 17:14:21-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

On Sat, Dec 19, 2020 at 9:05 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Do you have any idea how common such old systems might be?
&gt;

I don't have a specific number but I think using that old versions of glibc
is uncommon specially for POWER8 and above processors considering those
versions are more than 8 years old.

Maybe add a configure check for getauxval, and either fail at configure
&gt; time if --enable-fat is specified but we can't support it, or fall back
&gt; to assuming that none of the optional features are present at runtime?
&gt;
&gt; Some preprocessor check of glibc version in fat-ppc.c could work too, if
&gt; that's simpler.
&gt;

That's what I ended up with, I made a new merge request for these changes
and closed the old one.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201220172235</emailId><senderName>David Edelsohn</senderName><senderEmail>dje.gcc@gmail.com</senderEmail><timestampReceived>2020-12-20 17:22:35-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

On Sun, Dec 20, 2020 at 12:14 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt; wrote:
&gt;
&gt; On Sat, Dec 19, 2020 at 9:05 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; &gt; Do you have any idea how common such old systems might be?
&gt; &gt;
&gt;
&gt; I don't have a specific number but I think using that old versions of glibc
&gt; is uncommon specially for POWER8 and above processors considering those
&gt; versions are more than 8 years old.

PPC64LE Linux is the primary focus of Linux on Power.  The PPC64LE ABI
specifies Power8 as the minimum ISA.  GLIBC 2.16 or higher will be
available on all such PPC64LE Linux systems.  I doubt that an older,
PPC64 Linux big endian system would install the latest libgcrypt and
that configuration only is in maintenance mode for customers.

Again, it's your choice, but I would not invest a lot of effort to
support such a rare, old configuration that is unlikely to use a new
release of libgcrypt.

Thanks, David
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201221072920</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-12-21 07:29:20-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt;&gt; Some preprocessor check of glibc version in fat-ppc.c could work too, if
&gt;&gt; that's simpler.
&gt;&gt;
&gt;
&gt; That's what I ended up with, I made a new merge request for these changes
&gt; and closed the old one.

Thanks, looks pretty good. I added a few minor comments on the mr
(https://git.lysator.liu.se/nettle/nettle/-/merge_requests/16 for
reference).

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201221151821</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-12-21 15:18:21-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

On Mon, Dec 21, 2020 at 9:29 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Thanks, looks pretty good. I added a few minor comments on the mr
&gt; (https://git.lysator.liu.se/nettle/nettle/-/merge_requests/16 for
&gt; reference).
&gt;

Thank you, I made a commit with the changes.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201201235058</emailId><senderName>George Wilson</senderName><senderEmail>gcwilson@linux.ibm.com</senderEmail><timestampReceived>2020-12-01 23:50:58-0400</timestampReceived><subject>Re: Fwd: [PowerPC] GCM optimization</subject><body>

On Tue, Dec 01, 2020 at 07:55:05PM +0200, Maamoun TK wrote:
&gt; Hi George,
&gt; I'll start writing a white paper called "Optimizing Galois-Counter-Mode on
&gt; PowerPC Architecture Processors". Once I finish the first draft I'll send
&gt; it to Neils to review it.
&gt; 
&gt; 
&gt; &gt; What do you need from the IBM side?  I may be able to help.  We'd
&gt; &gt; definitely
&gt; &gt; like to support you and Niels in publishing your results.
&gt; &gt;
&gt; 
&gt; I have a couple of questions:
&gt; Should we send the paper to you when we make sure everything is ready for
&gt; publishing?

Yes, we'd love to review it.  I may be able to get someone from IBM Research
interested in participating as well to hopefully get deeper crypto and math
perspectives.

&gt; Can you participate as a supervisor to make some decisions like mentioning
&gt; arm implementation results of the research or making comparison with intel
&gt; white papers which used for x86, ARM, and PowerPC GCM implementations in
&gt; OpenSSL library?

Gladly.

&gt; 
&gt; regards,
&gt; Mamone

-- 
George Wilson
IBM Linux Technology Center
Security Development
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201219095531</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-12-19 09:55:31-0400</timestampReceived><subject>Re: CPU feature detection for Nettle-3.7?</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; https://lists.lysator.liu.se/pipermail/nettle-bugs/2020/008762.html

If you don't use --enable-fat, there will be no runtime detection.
That's exactly as intended. Maybe your real problem is

"On other platforms, --enable-fat causes
 SHA to be built even when the compiler does not support SHA. To avoid
 the compile error I dropped --enable-fat."

Can you give some more details of that error? The C compiler shouldn't
need to know anything about the sha or aes instructions, so your checks
of compiler support doesn't seem that relevant. The *assembler* needs to
recognize the instructions, and that could potentially be worked around
by coding instructions as equivalent byte sequences instead.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201221162212</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-12-21 16:22:12-0400</timestampReceived><subject>Re: [AArch64] Optimize GHASH</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; Thank you, I made a commit with the changes.

Thanks! Merged now.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201226170053</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-12-26 17:00:53-0400</timestampReceived><subject>Re: Make --enable-fat the default? (was: Re: Release of Nettle-3.7?)</subject><body>

Since there are many variants of architectures, some are supported and
others could be supported in the future, it becomes a little annoying for
end-users to browse the configurable options and enable specific options to
get maximum speed for corresponding algorithms so here --enable-fat comes
in handy. I like the idea of making --enable-fat default to get over the
case that the user didn't notice it or unaware of its advantages and
disadvantages and therefore hesitant to choose it, so I think it's a good
time to enable fat option by default if things are stable in assembly side,
you got my vote.

regards,
Mamone

On Sat, Dec 26, 2020 at 6:13 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; nisse@lysator.liu.se (Niels Möller) writes:
&gt;
&gt; &gt; Hi, I wonder if it would make sense to try to cut a release pretty soon
&gt; &gt; (and without any arm64 changes)? Previous release was made end of April,
&gt; &gt; and there's been quite a few improvements since then.
&gt;
&gt; I've pushed a couple of changes to increase version numbers, and add to
&gt; the NEWS file.
&gt;
&gt; One question: Is this a good time to make --enable-fat the default? It's
&gt; been available for a couple of versions, I think using it is quite
&gt; common, and I've not heard about any problems (except build failures if
&gt; assembler doesn't recognize newish instructions, which at least isn't
&gt; subtle).
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt; _______________________________________________
&gt; nettle-bugs mailing list
&gt; nettle-bugs@lists.lysator.liu.se
&gt; http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201228145811</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-12-28 14:58:11-0400</timestampReceived><subject>Re: Failing gnutls tests</subject><body>

Andreas Metzler &lt;ametzler@bebt.de&gt; writes:

&gt; On 2020-12-28 Niels Möller &lt;nisse-SamgB31n2u5IcsJQ0EH25Q@public.gmane.org&gt; wrote:
&gt;&gt; Hi, recent gnutls tests on the gitlab ci system all fail the test
&gt;&gt; "testpkcs11.sh". See e.g.,
&gt;&gt; https://gitlab.com/gnutls/nettle/-/jobs/932664781. First failure was an
&gt;&gt; a merge commit with a minor ppc-related fix.
&gt;
&gt;&gt; And it looks like gnutls' own pipelines have been failing for a month or
&gt;&gt; so too, see https://gitlab.com/gnutls/gnutls/-/pipelines. Any gnutls
&gt;&gt; people on the list who could have a look?
&gt;
&gt; Hello Niels,
&gt;
&gt; that is &lt;https://gitlab.com/gnutls/gnutls/-/issues/1135&gt;.

Thanks, then I know it's not some subtle problem in the nettle-gnutls
interaction.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201230202943</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-12-30 20:29:43-0400</timestampReceived><subject>Re: Release of Nettle-3.7?</subject><body>

On Tue, Dec 29, 2020 at 5:15 PM Michael Weiser &lt;michael.weiser@gmx.de&gt; wrote:
&gt;
&gt; ...
&gt; Do you (or anybody else) have a hardware arm board for testing, possibly
&gt; with a Cortex A8 or A9 implementation to see how it behaves there?

I've got a Wnadboard/Cortex-A9 and Tinkerboard/Cortex-A17 hanging off
the internet with SSH access.

Send over your authotized_keys if you want access.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201104194433</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-11-04 19:44:33-0400</timestampReceived><subject>Re: SHA1 Collision Detection</subject><body>

Justus Winter &lt;justus@sequoia-pgp.org&gt; writes:

&gt; I think hashing should be fallible.  If a collision attack is detected,
&gt; no digest should be produced, because the digest has none of the
&gt; properties that we usually associate with a hash digest.

I disagree; a hash function is a well defined function (in the
mathematical sense) regardless of attacks on some of its assumed
cryptographic properties.

Also, if we add a return value indicating success or failure, I would
expect that applications either ignore it anyway (there's currently no
circumstances when nettle's sha256_digest function could sensibly fail,
so why add code to check for that?), or attempt to handle errors,
resulting in code clutter and error "handling" code with no test
coverage.

&gt; If we come up with a new API anyway, we should make all hash functions
&gt; fallible, because sooner or later, any algorithm may fall.

In my view, the proposed "counter cryptanalysis" feature is specific to
known attacks on MD5, SHA1 and hash functions with similar structure.
And once we see a second-preimage attack (rather than a collision
attack) on a hash function, that kind of detection will be less useful.

I've had a quick look at the paper,
https://marc-stevens.nl/research/papers/C13-S.pdf, and I think it makes
some sense to add to Nettle. It's neat that the detection will trigger
when processing either one of the two colliding messages, and I can see
a real benefit in checking for that as part of verification of old sha1
signatures.

If you want to move forward with this, I would suggest to 

* Select a new name, preferably less unwieldy than
  "sha1_collision_detection". Just sha1_cd might do, but I'm also happy
  with something sligthly longer.

* Only do detection, no builtin substitution. An application that wants
  to, e.g., replace suspicious hash values with a truncated sha256 or
  sha3 hash or the like, can do its own hashing of the message itself in
  parallel with sha1. Exactly what digest output to produce on failure,
  I'm not sure. Maybe produce the regular sha1 digest. Maybe leave the
  output area unchanged, similar to how rsa_sec_decrypt handles failure.
  Then one mode of using it would be to unconditionally initialize the
  digest area with a truncated sha256 hash, then call sha1_cd_digest,
  and ignore the return value.

* See if it needs it's own context struct, struct sha1_cd_ctx, or if it
  can reuse sha1_ctx. If we want to provide a return value from
  sha1_cd_digest to reflect processing of the entire message, we will
  likely need an extended context with a flag to record if collisions
  were detected by some preceding sha1_cd_update call. If we provide
  return values for both sha1_cd_update and sha1_cd_digest (and expect
  applications using this feature to check them all), we might be able
  to get away with using the same struct sha1_ctx.

* Add colliding inputs to the testsuite, both for regular sha1, and for
  testing the new feature. There are tests exhibiting collisions in
  md5-test.c, but I don't think the sha1-tests.c has been touched since
  https://shattered.io/static/shattered.pdf was published.

* Consider how to deal with future changes to the list of known attack
  patterns. If a Nettle upgrade may change the result sha1_cd_digest, we
  might need to provide a version number for the counter-cryptanalysis
  used.

* Consider if it's worth doing also for md5?

Regards,
/Niels


-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201109184318</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-11-09 18:43:18-0400</timestampReceived><subject>Re: Modular inversion via powering</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; The code for curve25519 and curve448 has been using powering to invert
&gt; for a long time. I've now spent some time writing specific powering code
&gt; for the five secp curves as well. I've found fairly efficient addition
&gt; chains where powering for a prime of n bits needs n-1 squarings and
&gt; about a dozen multiplies. (I don't know what the *optimal* addition
&gt; chains are, if you know of tools for that, let me know).

[...]

&gt; I will merge these changes to master in a week or two, if no problems
&gt; show up

Before doing this merge, I've made some changes to the modulo p reduce
functions (mod and redc, with both C and assembly implementations). They
can now store the final result at a different location than the
clobbered input area. Then, the ecc_mod_mul and ecc_mod_sqr functions
are also changed to have separates result area, different from the
(larger) scratch area. This makes the allocation puzzle when using the
ecc_mod_* functions a lot simpler, resulting in reduced scratch need for
lots of functions, and elimination of a few copy operations.

Merging those changes is now on the master-updates branch. When this is
in, the new code on the optimize-ecc-invert branch can likely be
simplified a bit before merging.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201111210943</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-11-11 21:09:43-0400</timestampReceived><subject>Re: [PATCH] "PowerPC" Detect VSX support on AIX and FreeBSD</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; ---
&gt;  fat-ppc.c | 25 +++++++++++++++++++++----
&gt;  1 file changed, 21 insertions(+), 4 deletions(-)

Thanks, merged to the master branch now.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201218204108</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-12-18 20:41:08-0400</timestampReceived><subject>CPU feature detection for Nettle-3.7?</subject><body>

On Tue, Dec 15, 2020 at 10:47 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; Hi, I wonder if it would make sense to try to cut a release pretty soon
&gt; (and without any arm64 changes)? Previous release was made end of April,
&gt; and there's been quite a few improvements since then.

It would be nice if cpu feature detection for fat builds made it into
the next release. It is easier than arm64, and it is needed to avoid
crashes at runtime.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201219085857</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-12-19 08:58:57-0400</timestampReceived><subject>Re: CPU feature detection for Nettle-3.7?</subject><body>

Jeffrey Walton &lt;noloader@gmail.com&gt; writes:

&gt; It would be nice if cpu feature detection for fat builds made it into
&gt; the next release. It is easier than arm64, and it is needed to avoid
&gt; crashes at runtime.

Can you be more specific on what the problem is? I'm aware of only one
problem, and that's fat-arm.c relying on /proc/cpuinfo. Switching to
using getauxval has been suggested. Blockers as I recall:

(i) it wasn't clear how to use getauxval to figure out if we're running
    on armv6 or older, and

(ii) it wasn't clear what's the right way to do it on android. 

So this could surely be improved, but I'm not aware of any easy fix.

Regards,
/Niels


-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201219090659</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-12-19 09:06:59-0400</timestampReceived><subject>Re: CPU feature detection for Nettle-3.7?</subject><body>

On Sat, Dec 19, 2020 at 3:58 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; Jeffrey Walton &lt;noloader@gmail.com&gt; writes:
&gt;
&gt; &gt; It would be nice if cpu feature detection for fat builds made it into
&gt; &gt; the next release. It is easier than arm64, and it is needed to avoid
&gt; &gt; crashes at runtime.
&gt;
&gt; Can you be more specific on what the problem is? I'm aware of only one
&gt; problem, and that's fat-arm.c relying on /proc/cpuinfo. Switching to
&gt; using getauxval has been suggested. Blockers as I recall:

https://lists.lysator.liu.se/pipermail/nettle-bugs/2020/008762.html

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201128185937</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-11-28 18:59:37-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; On Wed, Nov 25, 2020 at 10:13 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
&gt; wrote:
&gt;
&gt;&gt; I'll make a pull request for fat build support.

The gcm code is now merged to the master branch. Thanks!

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201130234443</emailId><senderName>George Wilson</senderName><senderEmail>gcwilson@linux.ibm.com</senderEmail><timestampReceived>2020-11-30 23:44:43-0400</timestampReceived><subject>Re: Fwd: [PowerPC] GCM optimization</subject><body>

On Thu, Nov 12, 2020 at 07:45:14PM +0200, Maamoun TK wrote:
&gt; ---------- Forwarded message ---------
&gt; From: Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
&gt; Date: Thu, Nov 12, 2020 at 7:42 PM
&gt; Subject: Re: [PowerPC] GCM optimization
&gt; To: Niels Möller &lt;nisse@lysator.liu.se&gt;
&gt; 
&gt; 
&gt; On Thu, Nov 12, 2020 at 6:40 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt; 
&gt; &gt; I gave it a test run on gcc112 in the gcc compile farm, and speedup of
&gt; &gt; gcm update seems to be 26 times(!) compared to the C version.
&gt; &gt;
&gt; 
&gt; That's reasonable, I got similar speedup on more stable POWER instances
&gt; than gcc compile farm.
&gt; 
&gt; 
&gt; &gt; Where would that documentation be published? In the Nettle manual, as
&gt; &gt; some IBM white paper, or as a more-or-less academic paper, e.g., on
&gt; &gt; arxiv? I will not be able to spend much time on writing, but I'd be
&gt; &gt; happy to review.
&gt; &gt;
&gt; 
&gt; I'll start writing the papers once I got more details from IBM, similar to
&gt; intel documents, the document will be academic and practical at the same

Hi Mamone,

What do you need from the IBM side?  I may be able to help.  We'd definitely
like to support you and Niels in publishing your results.

&gt; time, I'll dive into finite field equations to demonstrate how we get there
&gt; as well as I'll add a practical example to clarify the preference of this
&gt; method in addition to the expected speedup of this method. My
&gt; intention that other crypto libraries could take advantage of this document
&gt; or maybe be a starting point for further improvements to the algorithm so
&gt; I'm checking if IBM would publish or approve such a document the same as
&gt; intel.
&gt; 
&gt; 
&gt; &gt; I have a sketch of ARM Neon code doing the equivalent of two vpmsumd,
&gt; &gt; with reasonable parallelism. Quite a lot of instructions needed.
&gt; &gt;
&gt; 
&gt; If you don't have much time, you can send it here and I'll continue from
&gt; that point. I'm planning to compare the new method with the usual method
&gt; with and without the karatsuba algorithm.
&gt; 
&gt; &gt; +C Alignment of gcm_key table elements, which is declared in gcm.h
&gt; &gt; &gt; +define(`TableElemAlign', `0x100')
&gt; &gt;
&gt; &gt; I still find this large constant puzzling. If I try
&gt; &gt;
&gt; &gt;   struct gcm_key key;
&gt; &gt;   printf("sizeof (key): %zd, sizeof(key.h[0]): %zd\n", sizeof(key),
&gt; &gt; sizeof(key.h[0]));
&gt; &gt;
&gt; &gt; (I added it to the start of test_main in gcm-test.c) and run on the
&gt; &gt; gcc112 machine, I get
&gt; &gt;
&gt; &gt;   sizeof (key): 4096, sizeof(key.h[0]): 16
&gt; &gt;
&gt; &gt; Which is what I'd expect, with elements of size 16 bytes, not 256 bytes.
&gt; &gt;
&gt; &gt; I haven't yet had the time to read the code carefully.
&gt; &gt;
&gt; 
&gt; You see, the alignment of each element is 0x100 (256). The table has 16
&gt; elements and you got the size of the table 4096 which is reasonable because
&gt; 16*256=4096
&gt; 
&gt; regards,
&gt; Mamone
&gt; _______________________________________________
&gt; nettle-bugs mailing list
&gt; nettle-bugs@lists.lysator.liu.se
&gt; http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

-- 
George Wilson
IBM Linux Technology Center
Security Development
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201011174727</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-10-11 17:47:27-0400</timestampReceived><subject>Re: GCM with ARM Neon (was: Re: [PATCH] "PowerPC64" GCM support)</subject><body>

On Sun, Oct 11, 2020 at 1:42 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; nisse@lysator.liu.se (Niels Möller) writes:
&gt;
&gt; &gt; So if we have the input in register A (loaded from memory with no
&gt; &gt; processing besides ensuring proper *byte* order), and precompute two
&gt; &gt; values, M representing b_1(x) x^64 + c_1(x), and L representing b_0(x)
&gt; &gt; x^64 + d_1(x)), then we get the two halves above with two vpmsumd,
&gt; &gt;
&gt; &gt;   vpmsumd R, M, A
&gt; &gt;   vpmsumd F, L, A
&gt; &gt;
&gt; &gt; When doing more than one block at a time, I think it's easiest to
&gt; &gt; accumulate the R and F values separately.
&gt;
&gt; BTW, I wonder if similar organization would make sense for Arm Neon.
&gt; Now, Neon doesn't have vpmsumd, the widest carryless multiplication
&gt; available is vmull.p8, which is an 8-bit to 15-bit multiply, 8 in
&gt; parallel...

I may be mistaken, but I believe 64-bit poly multiplies are available.
Or they are available on Aarch64 with Crypto extensions.

I'm not aware of poly multiplies on other ARM arches, like ARMv6 or
ARMv7 with NEON.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201011182050</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-10-11 18:20:50-0400</timestampReceived><subject>Re: GCM with ARM Neon</subject><body>

On Sun, Oct 11, 2020 at 2:03 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; Jeffrey Walton &lt;noloader@gmail.com&gt; writes:
&gt;
&gt; &gt; I may be mistaken, but I believe 64-bit poly multiplies are available.
&gt; &gt; Or they are available on Aarch64 with Crypto extensions.
&gt;
&gt; I'm looking in the Arm Instruction Set Reference Guide, labeled version
&gt; 1.0, 2018.
&gt;
&gt; It includes a section on cryptographic instructions, but that's aes,
&gt; sha1 and sha256, no carry-less multiplication.
&gt;
&gt; But I may well be missing something, I'm not really familiar with
&gt; Aarch64.
&gt;
&gt; &gt; I'm not aware of poly multiplies on other ARM arches, like ARMv6 or
&gt; &gt; ARMv7 with NEON.
&gt;
&gt; I think the "p8" SIMD datatype and vmull.p8 have been part of the Neon
&gt; instruction set for a long time, at least since I wrote my first ARM
&gt; code back in 2013. It's just a bit annoyning that one needs so many of
&gt; them to do a wide multiply.

Oh, you're right. There is a vmull for NEON.

According to an early NEON programming guide from ARM
(https://static.docs.arm.com/den0018/a/DEN0018A_neon_programmers_guide_en.pdf),
the widest you can perform is P16 poly multiply.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201226161331</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-12-26 16:13:31-0400</timestampReceived><subject>Make --enable-fat the default? (was: Re: Release of Nettle-3.7?)</subject><body>

nisse@lysator.liu.se (Niels Möller) writes:

&gt; Hi, I wonder if it would make sense to try to cut a release pretty soon
&gt; (and without any arm64 changes)? Previous release was made end of April,
&gt; and there's been quite a few improvements since then.

I've pushed a couple of changes to increase version numbers, and add to
the NEWS file.

One question: Is this a good time to make --enable-fat the default? It's
been available for a couple of versions, I think using it is quite
common, and I've not heard about any problems (except build failures if
assembler doesn't recognize newish instructions, which at least isn't
subtle).

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201023163811</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-10-23 16:38:11-0400</timestampReceived><subject>Modular inversion via powering</subject><body>

Hi,

Nettle includes a function for side-channel silent modular inversion,
which asymptotically is O(n^2), like binary gcd but slower by a pretty
large constant factor.

For prime moduli, inversion can also be done via a^{-1} = a^{p-2} (mod
p). That's asymptotically O(n^3) (if the underlying multiplies are done
with the basic O(n^2) algorithm), but it may nevertheless be faster than
the other method for numbers of the size used for Nettle's elliptic
curves.

The code for curve25519 and curve448 has been using powering to invert
for a long time. I've now spent some time writing specific powering code
for the five secp curves as well. I've found fairly efficient addition
chains where powering for a prime of n bits needs n-1 squarings and
about a dozen multiplies. (I don't know what the *optimal* addition
chains are, if you know of tools for that, let me know).

Code is on the branch optimize-ecc-invert. However, there's some risk
the new code is slower on some platforms, in particular platforms
with slow multiplication.  

The main benchmark is 

  ./examples/hogweed-benchmark ecdsa

To get numbers for just the changed function, one can run 

  ./examples-ecc-benchmark

and look at the modinv column. Please compare performance between this
branch and master, on the platforms that are important to you. 

And to get relevant numbers, make sure to build using a recent GMP
library; performance when built with mini-gmp is not so important.

I will merge these changes to master in a week or two, if no problems
show up

I've benchmarked on one recent and one older x86_64 machine, and on
raspberry-pi version 1 (the slowest ARM machine I had easy access to).
I've seen improvements in ecdsa signing performance for all the secp
curves, ranging from 5% up to 20% depending on curve and platform.

Not all inversions are rewritten. I haven't changed the modq inversion
which is needed for ecdsa, and I haven't changed the code for the two
supported gost curves.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201228101000</emailId><senderName>Niels =?utf-8?Q?M=C3=B6ller?=</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-12-28 10:10:00-0400</timestampReceived><subject>Failing gnutls tests</subject><body>

Hi, recent gnutls tests on the gitlab ci system all fail the test
"testpkcs11.sh". See e.g.,
https://gitlab.com/gnutls/nettle/-/jobs/932664781. First failure was an
a merge commit with a minor ppc-related fix.

And it looks like gnutls' own pipelines have been failing for a month or
so too, see https://gitlab.com/gnutls/gnutls/-/pipelines. Any gnutls
people on the list who could have a look?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.

_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201228125920</emailId><senderName>Andreas Metzler</senderName><senderEmail>ametzler@bebt.de</senderEmail><timestampReceived>2020-12-28 12:59:20-0400</timestampReceived><subject>Re: Failing gnutls tests</subject><body>

On 2020-12-28 Niels Möller &lt;nisse-SamgB31n2u5IcsJQ0EH25Q@public.gmane.org&gt; wrote:
&gt; Hi, recent gnutls tests on the gitlab ci system all fail the test
&gt; "testpkcs11.sh". See e.g.,
&gt; https://gitlab.com/gnutls/nettle/-/jobs/932664781. First failure was an
&gt; a merge commit with a minor ppc-related fix.

&gt; And it looks like gnutls' own pipelines have been failing for a month or
&gt; so too, see https://gitlab.com/gnutls/gnutls/-/pipelines. Any gnutls
&gt; people on the list who could have a look?

Hello Niels,

that is &lt;https://gitlab.com/gnutls/gnutls/-/issues/1135&gt;.

cu Andreas
-- 
`What a good friend you are to him, Dr. Maturin. His other friends are
so grateful to you.'
`I sew his ears on from time to time, sure'
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201110175519</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-11-10 17:55:19-0400</timestampReceived><subject>[PATCH] "PowerPC" Detect VSX support on AIX and FreeBSD</subject><body>

---
 fat-ppc.c | 25 +++++++++++++++++++++----
 1 file changed, 21 insertions(+), 4 deletions(-)

diff --git a/fat-ppc.c b/fat-ppc.c
index 2bfd649f..ec971706 100644
--- a/fat-ppc.c
+++ b/fat-ppc.c
@@ -43,8 +43,13 @@
 #if defined(_AIX)
 # include &lt;sys/systemcfg.h&gt;
 #elif defined(__linux__)
+# include &lt;asm/cputable.h&gt;
 # include &lt;sys/auxv.h&gt;
 #elif defined(__FreeBSD__)
+# include &lt;machine/cpu.h&gt;
+# ifdef PPC_FEATURE2_HAS_VEC_CRYPTO
+# define PPC_FEATURE2_VEC_CRYPTO PPC_FEATURE2_HAS_VEC_CRYPTO
+# endif
 # if __FreeBSD__ &gt;= 12
 #  include &lt;sys/auxv.h&gt;
 # else
@@ -58,7 +63,13 @@
 #include "gcm.h"
 #include "fat-setup.h"

-/* Define from arch/powerpc/include/uapi/asm/cputable.h in Linux kernel */
+/* Defines from arch/powerpc/include/uapi/asm/cputable.h in Linux kernel */
+#ifndef PPC_FEATURE_HAS_ALTIVEC
+#define PPC_FEATURE_HAS_ALTIVEC 0x10000000
+#endif
+#ifndef PPC_FEATURE_HAS_VSX
+#define PPC_FEATURE_HAS_VSX 0x00000080
+#endif
 #ifndef PPC_FEATURE2_VEC_CRYPTO
 #define PPC_FEATURE2_VEC_CRYPTO 0x02000000
 #endif
@@ -96,8 +107,10 @@ get_ppc_features (struct ppc_features *features)
       }
   else
     {
-#if defined(_AIX) &amp;&amp; defined(__power_8_andup)
-      features-&gt;have_crypto_ext = __power_8_andup() != 0 ? 1 : 0;
+#if defined(_AIX)
+      features-&gt;have_crypto_ext
+ = _system_configuration.implementation &gt;= 0x10000u;
+      features-&gt;have_altivec = _system_configuration.vmx_version &gt; 1;
 #else
       unsigned long hwcap = 0;
       unsigned long hwcap2 = 0;
@@ -106,9 +119,13 @@ get_ppc_features (struct ppc_features *features)
       hwcap2 = getauxval(AT_HWCAP2);
 # elif defined(__FreeBSD__)
 #  if __FreeBSD__ &gt;= 12
+      elf_aux_info(AT_HWCAP, &amp;hwcap, sizeof(hwcap));
       elf_aux_info(AT_HWCAP2, &amp;hwcap2, sizeof(hwcap2));
 #  else
-      size_t len = sizeof(hwcap2);
+      size_t len;
+      len = sizeof(hwcap);
+      sysctlbyname("hw.cpu_features", &amp;hwcap, &amp;len, NULL, 0);
+      len = sizeof(hwcap2);
       sysctlbyname("hw.cpu_features2", &amp;hwcap2, &amp;len, NULL, 0);
 #  endif
 # endif

-- 
2.17.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201111001741</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-11-11 00:17:41-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

I think I mislabeled the percentage of performance comparison, the new
method achieved 27.7% reduction in time on POWER8 that corresponds to 37.9%
increase in performance.

On Tue, Nov 10, 2020 at 6:25 AM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
wrote:

&gt; This implementation takes advantage of research made by Niels M��ller to
&gt; optimize GCM on PowerPC, this optimization yields a +27.7% performance
&gt; boost on POWER8 over the previous implementation that was based on intel
&gt; documents. The performance comparison is made by processing 4 blocks per
&gt; loop without any further optimizations.
&gt; I made some documentations between the lines but I suggest writing a
&gt; document similar to the intel ones that go into more details and clarify
&gt; the preference of this method. I'm also curious if this method can also
&gt; make a difference in other architectures like ARM, I'm planning to try it
&gt; out for ARM to figure that out.
&gt; ---
&gt;  configure.ac              |   6 +-
&gt;  gcm.c                     |  49 +++--
&gt;  powerpc64/p8/gcm-hash.asm | 502
&gt; ++++++++++++++++++++++++++++++++++++++++++++++
&gt;  3 files changed, 542 insertions(+), 15 deletions(-)
&gt;  create mode 100644 powerpc64/p8/gcm-hash.asm
&gt;
&gt; diff --git a/configure.ac b/configure.ac
&gt; index 2a47f940..20f7cf74 100644
&gt; --- a/configure.ac
&gt; +++ b/configure.ac
&gt; @@ -497,7 +497,7 @@ asm_replace_list="aes-encrypt-internal.asm
&gt; aes-decrypt-internal.asm \
&gt;   sha3-permute.asm umac-nh.asm umac-nh-n.asm machine.m4"
&gt;
&gt;  # Assembler files which generate additional object files if they are used.
&gt; -asm_nettle_optional_list="gcm-hash8.asm cpuid.asm \
&gt; +asm_nettle_optional_list="gcm-hash.asm gcm-hash8.asm cpuid.asm \
&gt;    aes-encrypt-internal-2.asm aes-decrypt-internal-2.asm memxor-2.asm \
&gt;    chacha-3core.asm chacha-core-internal-2.asm salsa20-2core.asm \
&gt;    salsa20-core-internal-2.asm sha1-compress-2.asm sha256-compress-2.asm \
&gt; @@ -621,9 +621,9 @@ AH_VERBATIM([HAVE_NATIVE],
&gt;  #undef HAVE_NATIVE_ecc_secp384r1_redc
&gt;  #undef HAVE_NATIVE_ecc_secp521r1_modp
&gt;  #undef HAVE_NATIVE_ecc_secp521r1_redc
&gt; -#undef HAVE_NATIVE_gcm_init_key8
&gt; +#undef HAVE_NATIVE_gcm_init_key
&gt; +#undef HAVE_NATIVE_gcm_hash
&gt;  #undef HAVE_NATIVE_gcm_hash8
&gt; -#undef HAVE_NATIVE_gcm_fill
&gt;  #undef HAVE_NATIVE_salsa20_core
&gt;  #undef HAVE_NATIVE_salsa20_2core
&gt;  #undef HAVE_NATIVE_fat_salsa20_2core
&gt; diff --git a/gcm.c b/gcm.c
&gt; index 48b3e75a..81981c1c 100644
&gt; --- a/gcm.c
&gt; +++ b/gcm.c
&gt; @@ -140,6 +140,19 @@ gcm_gf_mul (union nettle_block16 *x, const union
&gt; nettle_block16 *table)
&gt;    memcpy (x-&gt;b, Z.b, sizeof(Z));
&gt;  }
&gt;  # elif GCM_TABLE_BITS == 8
&gt; +#  if HAVE_NATIVE_gcm_init_key
&gt; +
&gt; +#define gcm_init_key _nettle_gcm_init_key
&gt; +void
&gt; +_nettle_gcm_init_key (union nettle_block16 *table);
&gt; +#  endif /* HAVE_NATIVE_gcm_init_key */
&gt; +#  if HAVE_NATIVE_gcm_hash
&gt; +
&gt; +#define gcm_hash _nettle_gcm_hash
&gt; +void
&gt; +_nettle_gcm_hash (const struct gcm_key *key, union nettle_block16 *x,
&gt; +   size_t length, const uint8_t *data);
&gt; +#  endif /* HAVE_NATIVE_gcm_hash */
&gt;  #  if HAVE_NATIVE_gcm_hash8
&gt;
&gt;  #define gcm_hash _nettle_gcm_hash8
&gt; @@ -228,6 +241,29 @@ gcm_gf_mul (union nettle_block16 *x, const union
&gt; nettle_block16 *table)
&gt;  /* Increment the rightmost 32 bits. */
&gt;  #define INC32(block) INCREMENT(4, (block.b) + GCM_BLOCK_SIZE - 4)
&gt;
&gt; +#ifndef gcm_init_key
&gt; +static void
&gt; +gcm_init_key(union nettle_block16 *table)
&gt; +{
&gt; +#if GCM_TABLE_BITS
&gt; +  /* Middle element if GCM_TABLE_BITS &gt; 0, otherwise the first
&gt; +     element */
&gt; +  unsigned i = (1&lt;&lt;GCM_TABLE_BITS)/2;
&gt; +
&gt; +  /* Algorithm 3 from the gcm paper. First do powers of two, then do
&gt; +     the rest by adding. */
&gt; +  while (i /= 2)
&gt; +    block16_mulx_ghash(&amp;table[i], &amp;table[2*i]);
&gt; +  for (i = 2; i &lt; 1&lt;&lt;GCM_TABLE_BITS; i *= 2)
&gt; +    {
&gt; +      unsigned j;
&gt; +      for (j = 1; j &lt; i; j++)
&gt; + block16_xor3(&amp;table[i+j], &amp;table[i], &amp;table[j]);
&gt; +    }
&gt; +#endif
&gt; +}
&gt; +#endif /* !gcm_init_key */
&gt; +
&gt;  /* Initialization of GCM.
&gt;   * @ctx: The context of GCM
&gt;   * @cipher: The context of the underlying block cipher
&gt; @@ -245,18 +281,7 @@ gcm_set_key(struct gcm_key *key,
&gt;    memset(key-&gt;h[0].b, 0, GCM_BLOCK_SIZE);
&gt;    f (cipher, GCM_BLOCK_SIZE, key-&gt;h[i].b, key-&gt;h[0].b);
&gt;
&gt; -#if GCM_TABLE_BITS
&gt; -  /* Algorithm 3 from the gcm paper. First do powers of two, then do
&gt; -     the rest by adding. */
&gt; -  while (i /= 2)
&gt; -    block16_mulx_ghash(&amp;key-&gt;h[i], &amp;key-&gt;h[2*i]);
&gt; -  for (i = 2; i &lt; 1&lt;&lt;GCM_TABLE_BITS; i *= 2)
&gt; -    {
&gt; -      unsigned j;
&gt; -      for (j = 1; j &lt; i; j++)
&gt; - block16_xor3(&amp;key-&gt;h[i+j], &amp;key-&gt;h[i],&amp;key-&gt;h[j]);
&gt; -    }
&gt; -#endif
&gt; +  gcm_init_key(key-&gt;h);
&gt;  }
&gt;
&gt;  #ifndef gcm_hash
&gt; diff --git a/powerpc64/p8/gcm-hash.asm b/powerpc64/p8/gcm-hash.asm
&gt; new file mode 100644
&gt; index 00000000..e79fbdc2
&gt; --- /dev/null
&gt; +++ b/powerpc64/p8/gcm-hash.asm
&gt; @@ -0,0 +1,502 @@
&gt; +C powerpc64/p8/gcm-hash.asm
&gt; +
&gt; +ifelse(`
&gt; +   Copyright (C) 2020 Niels M��ller and Mamone Tarsha
&gt; +   This file is part of GNU Nettle.
&gt; +
&gt; +   GNU Nettle is free software: you can redistribute it and/or
&gt; +   modify it under the terms of either:
&gt; +
&gt; +     * the GNU Lesser General Public License as published by the Free
&gt; +       Software Foundation; either version 3 of the License, or (at your
&gt; +       option) any later version.
&gt; +
&gt; +   or
&gt; +
&gt; +     * the GNU General Public License as published by the Free
&gt; +       Software Foundation; either version 2 of the License, or (at your
&gt; +       option) any later version.
&gt; +
&gt; +   or both in parallel, as here.
&gt; +
&gt; +   GNU Nettle is distributed in the hope that it will be useful,
&gt; +   but WITHOUT ANY WARRANTY; without even the implied warranty of
&gt; +   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
&gt; +   General Public License for more details.
&gt; +
&gt; +   You should have received copies of the GNU General Public License and
&gt; +   the GNU Lesser General Public License along with this program.  If
&gt; +   not, see http://www.gnu.org/licenses/.
&gt; +')
&gt; +
&gt; +C Alignment of gcm_key table elements, which is declared in gcm.h
&gt; +define(`TableElemAlign', `0x100')
&gt; +
&gt; +C Register usage:
&gt; +
&gt; +define(`SP', `r1')
&gt; +define(`TOCP', `r2')
&gt; +
&gt; +define(`TABLE', `r3')
&gt; +
&gt; +define(`ZERO', `v0')
&gt; +define(`B1', `v1')
&gt; +define(`EMSB', `v16')
&gt; +define(`POLY', `v17')
&gt; +define(`POLY_L', `v1')
&gt; +
&gt; +define(`H', `v2')
&gt; +define(`H2', `v3')
&gt; +define(`H3', `v4')
&gt; +define(`H4', `v5')
&gt; +define(`H1M', `v6')
&gt; +define(`H1L', `v7')
&gt; +define(`H2M', `v8')
&gt; +define(`H2L', `v9')
&gt; +define(`Hl', `v10')
&gt; +define(`Hm', `v11')
&gt; +define(`Hp', `v12')
&gt; +define(`Hl2', `v13')
&gt; +define(`Hm2', `v14')
&gt; +define(`Hp2', `v15')
&gt; +define(`R', `v13')
&gt; +define(`F', `v14')
&gt; +define(`T', `v15')
&gt; +define(`R2', `v16')
&gt; +define(`F2', `v17')
&gt; +define(`T2', `v18')
&gt; +
&gt; +define(`LE_TEMP', `v18')
&gt; +define(`LE_MASK', `v19')
&gt; +
&gt; +.file "gcm-hash.asm"
&gt; +
&gt; +.text
&gt; +
&gt; +    C void gcm_init_key (union gcm_block *table)
&gt; +
&gt; +C This function populates the gcm table as the following layout
&gt; +C
&gt; *******************************************************************************
&gt; +C | H1M = (H1 div x������)||((H1 mod x������) �� (x������+x��� �+x��� �+x������)) div x������
&gt;        |
&gt; +C | H1L = (H1 mod x������)||(((H1 mod x������) �� (x��� �+x��� �+x������)) mod x������) + (H1
&gt; div x������) |
&gt; +C |
&gt;       |
&gt; +C | H2M = (H2 div x������)||((H2 mod x������) �� (x������+x��� �+x��� �+x������)) div x������
&gt;        |
&gt; +C | H2L = (H2 mod x������)||(((H2 mod x������) �� (x��� �+x��� �+x������)) mod x������) + (H2
&gt; div x������) |
&gt; +C |
&gt;       |
&gt; +C | H3M = (H3 div x������)||((H3 mod x������) �� (x������+x��� �+x��� �+x������)) div x������
&gt;        |
&gt; +C | H3L = (H3 mod x������)||(((H3 mod x������) �� (x��� �+x��� �+x������)) mod x������) + (H3
&gt; div x������) |
&gt; +C |
&gt;       |
&gt; +C | H4M = (H3 div x������)||((H4 mod x������) �� (x������+x��� �+x��� �+x������)) div x������
&gt;        |
&gt; +C | H4L = (H3 mod x������)||(((H4 mod x������) �� (x��� �+x��� �+x������)) mod x������) + (H4
&gt; div x������) |
&gt; +C
&gt; *******************************************************************************
&gt; +
&gt; +define(`FUNC_ALIGN', `5')
&gt; +PROLOGUE(_nettle_gcm_init_key)
&gt; +    DATA_LOAD_VEC(POLY,.polynomial,r7)           C
&gt; 0xC2000000000000000000000000000001
&gt; +IF_LE(`
&gt; +    li             r8,0
&gt; +    lvsl           LE_MASK,0,r8                  C
&gt; 0x000102030405060708090A0B0C0D0E0F
&gt; +    vspltisb       LE_TEMP,0x07                  C
&gt; 0x07070707070707070707070707070707
&gt; +    vxor           LE_MASK,LE_MASK,LE_TEMP       C
&gt; 0x07060504030201000F0E0D0C0B0A0908
&gt; +')
&gt; +
&gt; +    C 'H' is assigned by gcm_set_key() to the middle element of the table
&gt; +    li             r10,8*TableElemAlign
&gt; +    lxvd2x         VSR(H),r10,TABLE              C load 'H'
&gt; +    C byte-reverse of each doubleword permuting on little-endian mode
&gt; +IF_LE(`
&gt; +    vperm          H,H,H,LE_MASK
&gt; +')
&gt; +
&gt; +    C --- calculate H = H &lt;&lt; 1 mod P(X), P(X) = (x � ����+x � ����+x � ����+x � � �+1)
&gt; ---
&gt; +
&gt; +    vupkhsb        EMSB,H                        C extend most
&gt; significant bit to first byte
&gt; +    vspltisb       B1,1                          C
&gt; 0x01010101010101010101010101010101
&gt; +    vspltb         EMSB,EMSB,0                   C first byte
&gt; quadword-extend
&gt; +    vsl            H,H,B1                        C H = H &lt;&lt; 1
&gt; +    vand           EMSB,EMSB,POLY                C EMSB &amp;=
&gt; 0xC2000000000000000000000000000001
&gt; +    vxor           ZERO,ZERO,ZERO                C
&gt; 0x00000000000000000000000000000000
&gt; +    vxor           H,H,EMSB                      C H ^= EMSB
&gt; +
&gt; +    C --- calculate H^2 = H*H ---
&gt; +
&gt; +    xxmrghd        VSR(POLY_L),VSR(ZERO),VSR(POLY) C
&gt; 0x0000000000000000C200000000000000
&gt; +
&gt; +    C --- Hp = (H mod x������) / x������ mod P(X) ---
&gt; +    C --- Hp = (H mod x������) �� (x������+x��� �+x��� �+x������) mod P(X), deg(Hp) ��� 127 ---
&gt; +    C --- Hp = (H mod x������) �� (x������+x��� �+x��� �+x������) ---
&gt; +    vpmsumd        Hp,H,POLY_L                   C Hp = (H mod x������) ��
&gt; (x��� �+x��� �+x������)
&gt; +    xxmrgld        VSR(Hl),VSR(H),VSR(ZERO)      C Hl = (H mod x������) �� x������
&gt; +    xxswapd        VSR(Hm),VSR(H)
&gt; +    vxor           Hl,Hl,Hp                      C Hl = Hl + Hp
&gt; +    vxor           Hm,Hm,Hp                      C Hm = Hm + Hp
&gt; +    xxmrghd        VSR(H1M),VSR(H),VSR(Hl)       C H1M = (H div x������)||(Hl
&gt; div x������)
&gt; +    xxmrgld        VSR(H1L),VSR(H),VSR(Hm)       C H1L = (H mod x������)||(Hl
&gt; mod x������)
&gt; +
&gt; +    vpmsumd        F,H1L,H                       C F = (H1Lh �� Hh) +
&gt; (H1Ll �� Hl)
&gt; +    vpmsumd        R,H1M,H                       C R = (H1Mh �� Hh) +
&gt; (H1Ml �� Hl)
&gt; +
&gt; +    C --- rduction ---
&gt; +    vpmsumd        T,F,POLY_L                    C T = (F mod x������) ��
&gt; (x��� �+x��� �+x������)
&gt; +    xxswapd        VSR(H2),VSR(F)
&gt; +    vxor           R,R,T                         C R = R + T
&gt; +    vxor           H2,R,H2
&gt; +
&gt; +    xxmrgld        VSR(Hl),VSR(H2),VSR(ZERO)
&gt; +    xxswapd        VSR(Hm),VSR(H2)
&gt; +    vpmsumd        Hp,H2,POLY_L
&gt; +    vxor           Hl,Hl,Hp
&gt; +    vxor           Hm,Hm,Hp
&gt; +    xxmrghd        VSR(H2M),VSR(H2),VSR(Hl)
&gt; +    xxmrgld        VSR(H2L),VSR(H2),VSR(Hm)
&gt; +
&gt; +    C store H1M, H1L, H2M, H2L
&gt; +    li             r8,1*TableElemAlign
&gt; +    li             r9,2*TableElemAlign
&gt; +    li             r10,3*TableElemAlign
&gt; +    stxvd2x        VSR(H1M),0,TABLE
&gt; +    stxvd2x        VSR(H1L),r8,TABLE
&gt; +    stxvd2x        VSR(H2M),r9,TABLE
&gt; +    stxvd2x        VSR(H2L),r10,TABLE
&gt; +
&gt; +    C --- calculate H^3 = H^1*H^2, H^4 = H^2*H^2 ---
&gt; +
&gt; +    vpmsumd        F,H1L,H2
&gt; +    vpmsumd        F2,H2L,H2
&gt; +    vpmsumd        R,H1M,H2
&gt; +    vpmsumd        R2,H2M,H2
&gt; +
&gt; +    vpmsumd        T,F,POLY_L
&gt; +    vpmsumd        T2,F2,POLY_L
&gt; +    xxswapd        VSR(H3),VSR(F)
&gt; +    xxswapd        VSR(H4),VSR(F2)
&gt; +    vxor           R,R,T
&gt; +    vxor           R2,R2,T2
&gt; +    vxor           H3,R,H3
&gt; +    vxor           H4,R2,H4
&gt; +
&gt; +    xxmrgld        VSR(Hl),VSR(H3),VSR(ZERO)
&gt; +    xxmrgld        VSR(Hl2),VSR(H4),VSR(ZERO)
&gt; +    xxswapd        VSR(Hm),VSR(H3)
&gt; +    xxswapd        VSR(Hm2),VSR(H4)
&gt; +    vpmsumd        Hp,H3,POLY_L
&gt; +    vpmsumd        Hp2,H4,POLY_L
&gt; +    vxor           Hl,Hl,Hp
&gt; +    vxor           Hl2,Hl2,Hp2
&gt; +    vxor           Hm,Hm,Hp
&gt; +    vxor           Hm2,Hm2,Hp2
&gt; +    xxmrghd        VSR(H1M),VSR(H3),VSR(Hl)
&gt; +    xxmrghd        VSR(H2M),VSR(H4),VSR(Hl2)
&gt; +    xxmrgld        VSR(H1L),VSR(H3),VSR(Hm)
&gt; +    xxmrgld        VSR(H2L),VSR(H4),VSR(Hm2)
&gt; +
&gt; +    C store H3M, H3L, H4M, H4L
&gt; +    li             r7,4*TableElemAlign
&gt; +    li             r8,5*TableElemAlign
&gt; +    li             r9,6*TableElemAlign
&gt; +    li             r10,7*TableElemAlign
&gt; +    stxvd2x        VSR(H1M),r7,TABLE
&gt; +    stxvd2x        VSR(H1L),r8,TABLE
&gt; +    stxvd2x        VSR(H2M),r9,TABLE
&gt; +    stxvd2x        VSR(H2L),r10,TABLE
&gt; +
&gt; +    blr
&gt; +EPILOGUE(_nettle_gcm_init_key)
&gt; +
&gt; +define(`TABLE', `r3')
&gt; +define(`X', `r4')
&gt; +define(`LENGTH', `r5')
&gt; +define(`DATA', `r6')
&gt; +
&gt; +define(`ZERO', `v16')
&gt; +define(`POLY', `v17')
&gt; +define(`POLY_L', `v0')
&gt; +
&gt; +define(`D', `v1')
&gt; +define(`C0', `v2')
&gt; +define(`C1', `v3')
&gt; +define(`C2', `v4')
&gt; +define(`C3', `v5')
&gt; +define(`H1M', `v6')
&gt; +define(`H1L', `v7')
&gt; +define(`H2M', `v8')
&gt; +define(`H2L', `v9')
&gt; +define(`H3M', `v10')
&gt; +define(`H3L', `v11')
&gt; +define(`H4M', `v12')
&gt; +define(`H4L', `v13')
&gt; +define(`R', `v14')
&gt; +define(`F', `v15')
&gt; +define(`R2', `v16')
&gt; +define(`F2', `v17')
&gt; +define(`R3', `v18')
&gt; +define(`F3', `v20')
&gt; +define(`R4', `v21')
&gt; +define(`F4', `v22')
&gt; +define(`T', `v23')
&gt; +
&gt; +define(`LE_TEMP', `v18')
&gt; +define(`LE_MASK', `v19')
&gt; +
&gt; +    C void gcm_hash (const struct gcm_key *key, union gcm_block *x,
&gt; +    C                size_t length, const uint8_t *data)
&gt; +
&gt; +define(`FUNC_ALIGN', `5')
&gt; +PROLOGUE(_nettle_gcm_hash)
&gt; +    DATA_LOAD_VEC(POLY,.polynomial,r7)
&gt; +IF_LE(`
&gt; +    li             r8,0
&gt; +    lvsl           LE_MASK,0,r8
&gt; +    vspltisb       LE_TEMP,0x07
&gt; +    vxor           LE_MASK,LE_MASK,LE_TEMP
&gt; +')
&gt; +    vxor           ZERO,ZERO,ZERO
&gt; +    xxmrghd        VSR(POLY_L),VSR(ZERO),VSR(POLY)
&gt; +
&gt; +    lxvd2x         VSR(D),0,X                    C load 'X' pointer
&gt; +    C byte-reverse of each doubleword permuting on little-endian mode
&gt; +IF_LE(`
&gt; +    vperm          D,D,D,LE_MASK
&gt; +')
&gt; +
&gt; +    C --- process 4 blocks '128-bit each' per one loop ---
&gt; +
&gt; +    srdi           r7,LENGTH,6                   C 4-blocks loop count
&gt; 'LENGTH / (4 * 16)'
&gt; +    cmpldi         r7,0
&gt; +    beq            L2x
&gt; +
&gt; +    mtctr          r7                            C assign counter
&gt; register to loop count
&gt; +
&gt; +    C store non-volatile vector registers
&gt; +    addi           r8,SP,-64
&gt; +    stvx           20,0,r8
&gt; +    addi           r8,r8,16
&gt; +    stvx           21,0,r8
&gt; +    addi           r8,r8,16
&gt; +    stvx           22,0,r8
&gt; +    addi           r8,r8,16
&gt; +    stvx           23,0,r8
&gt; +
&gt; +    C load table elements
&gt; +    li             r8,1*TableElemAlign
&gt; +    li             r9,2*TableElemAlign
&gt; +    li             r10,3*TableElemAlign
&gt; +    lxvd2x         VSR(H1M),0,TABLE
&gt; +    lxvd2x         VSR(H1L),r8,TABLE
&gt; +    lxvd2x         VSR(H2M),r9,TABLE
&gt; +    lxvd2x         VSR(H2L),r10,TABLE
&gt; +    li             r7,4*TableElemAlign
&gt; +    li             r8,5*TableElemAlign
&gt; +    li             r9,6*TableElemAlign
&gt; +    li             r10,7*TableElemAlign
&gt; +    lxvd2x         VSR(H3M),r7,TABLE
&gt; +    lxvd2x         VSR(H3L),r8,TABLE
&gt; +    lxvd2x         VSR(H4M),r9,TABLE
&gt; +    lxvd2x         VSR(H4L),r10,TABLE
&gt; +
&gt; +    li             r8,0x10
&gt; +    li             r9,0x20
&gt; +    li             r10,0x30
&gt; +.align 5
&gt; +L4x_loop:
&gt; +    C input loading
&gt; +    lxvd2x         VSR(C0),0,DATA                C load C0
&gt; +    lxvd2x         VSR(C1),r8,DATA               C load C1
&gt; +    lxvd2x         VSR(C2),r9,DATA               C load C2
&gt; +    lxvd2x         VSR(C3),r10,DATA              C load C3
&gt; +
&gt; +IF_LE(`
&gt; +    vperm          C0,C0,C0,LE_MASK
&gt; +    vperm          C1,C1,C1,LE_MASK
&gt; +    vperm          C2,C2,C2,LE_MASK
&gt; +    vperm          C3,C3,C3,LE_MASK
&gt; +')
&gt; +
&gt; +    C previous digest combining
&gt; +    vxor           C0,C0,D
&gt; +
&gt; +    C polynomial multiplication
&gt; +    vpmsumd        F2,H3L,C1
&gt; +    vpmsumd        R2,H3M,C1
&gt; +    vpmsumd        F3,H2L,C2
&gt; +    vpmsumd        R3,H2M,C2
&gt; +    vpmsumd        F4,H1L,C3
&gt; +    vpmsumd        R4,H1M,C3
&gt; +    vpmsumd        F,H4L,C0
&gt; +    vpmsumd        R,H4M,C0
&gt; +
&gt; +    C deferred recombination of partial products
&gt; +    vxor           F3,F3,F4
&gt; +    vxor           R3,R3,R4
&gt; +    vxor           F,F,F2
&gt; +    vxor           R,R,R2
&gt; +    vxor           F,F,F3
&gt; +    vxor           R,R,R3
&gt; +
&gt; +    C reduction
&gt; +    vpmsumd        T,F,POLY_L
&gt; +    xxswapd        VSR(D),VSR(F)
&gt; +    vxor           R,R,T
&gt; +    vxor           D,R,D
&gt; +
&gt; +    addi           DATA,DATA,0x40
&gt; +    bdnz           L4x_loop
&gt; +
&gt; +    C restore non-volatile vector registers
&gt; +    addi           r8,SP,-64
&gt; +    lvx            20,0,r8
&gt; +    addi           r8,r8,16
&gt; +    lvx            21,0,r8
&gt; +    addi           r8,r8,16
&gt; +    lvx            22,0,r8
&gt; +    addi           r8,r8,16
&gt; +    lvx            23,0,r8
&gt; +
&gt; +    clrldi         LENGTH,LENGTH,58              C 'set the high-order 58
&gt; bits to zeros'
&gt; +L2x:
&gt; +    C --- process 2 blocks ---
&gt; +
&gt; +    srdi           r7,LENGTH,5                   C 'LENGTH / (2 * 16)'
&gt; +    cmpldi         r7,0
&gt; +    beq            L1x
&gt; +
&gt; +    C load table elements
&gt; +    li             r8,1*TableElemAlign
&gt; +    li             r9,2*TableElemAlign
&gt; +    li             r10,3*TableElemAlign
&gt; +    lxvd2x         VSR(H1M),0,TABLE
&gt; +    lxvd2x         VSR(H1L),r8,TABLE
&gt; +    lxvd2x         VSR(H2M),r9,TABLE
&gt; +    lxvd2x         VSR(H2L),r10,TABLE
&gt; +
&gt; +    C input loading
&gt; +    li             r10,0x10
&gt; +    lxvd2x         VSR(C0),0,DATA                C load C0
&gt; +    lxvd2x         VSR(C1),r10,DATA              C load C1
&gt; +
&gt; +IF_LE(`
&gt; +    vperm          C0,C0,C0,LE_MASK
&gt; +    vperm          C1,C1,C1,LE_MASK
&gt; +')
&gt; +
&gt; +    C previous digest combining
&gt; +    vxor           C0,C0,D
&gt; +
&gt; +    C polynomial multiplication
&gt; +    vpmsumd        F2,H1L,C1
&gt; +    vpmsumd        R2,H1M,C1
&gt; +    vpmsumd        F,H2L,C0
&gt; +    vpmsumd        R,H2M,C0
&gt; +
&gt; +    C deferred recombination of partial products
&gt; +    vxor           F,F,F2
&gt; +    vxor           R,R,R2
&gt; +
&gt; +    C reduction
&gt; +    vpmsumd        T,F,POLY_L
&gt; +    xxswapd        VSR(D),VSR(F)
&gt; +    vxor           R,R,T
&gt; +    vxor           D,R,D
&gt; +
&gt; +    addi           DATA,DATA,0x20
&gt; +    clrldi         LENGTH,LENGTH,59              C 'set the high-order 59
&gt; bits to zeros'
&gt; +L1x:
&gt; +    C --- process 1 block ---
&gt; +
&gt; +    srdi           r7,LENGTH,4                   C 'LENGTH / (1 * 16)'
&gt; +    cmpldi         r7,0
&gt; +    beq            Lmod
&gt; +
&gt; +    C load table elements
&gt; +    li             r8,1*TableElemAlign
&gt; +    lxvd2x         VSR(H1M),0,TABLE
&gt; +    lxvd2x         VSR(H1L),r8,TABLE
&gt; +
&gt; +    C input loading
&gt; +    lxvd2x         VSR(C0),0,DATA                C load C0
&gt; +
&gt; +IF_LE(`
&gt; +    vperm          C0,C0,C0,LE_MASK
&gt; +')
&gt; +
&gt; +    C previous digest combining
&gt; +    vxor           C0,C0,D
&gt; +
&gt; +    C polynomial multiplication
&gt; +    vpmsumd        F,H1L,C0
&gt; +    vpmsumd        R,H1M,C0
&gt; +
&gt; +    C reduction
&gt; +    vpmsumd        T,F,POLY_L
&gt; +    xxswapd        VSR(D),VSR(F)
&gt; +    vxor           R,R,T
&gt; +    vxor           D,R,D
&gt; +
&gt; +    addi           DATA,DATA,0x10
&gt; +    clrldi         LENGTH,LENGTH,60              C 'set the high-order 60
&gt; bits to zeros'
&gt; +Lmod:
&gt; +    C --- process the modulo bytes, padding the low-order bytes with
&gt; zeros ---
&gt; +
&gt; +    cmpldi         LENGTH,0
&gt; +    beq            Ldone
&gt; +
&gt; +    C load table elements
&gt; +    li             r8,1*TableElemAlign
&gt; +    lxvd2x         VSR(H1M),0,TABLE
&gt; +    lxvd2x         VSR(H1L),r8,TABLE
&gt; +
&gt; +    C push every modulo byte to the stack and load them with padding into
&gt; vector register
&gt; +    vxor           ZERO,ZERO,ZERO
&gt; +    addi           r8,SP,-16
&gt; +    stvx           ZERO,0,r8
&gt; +Lstb_loop:
&gt; +    subic.         LENGTH,LENGTH,1
&gt; +    lbzx           r7,LENGTH,DATA
&gt; +    stbx           r7,LENGTH,r8
&gt; +    bne            Lstb_loop
&gt; +    lxvd2x         VSR(C0),0,r8
&gt; +
&gt; +IF_LE(`
&gt; +    vperm          C0,C0,C0,LE_MASK
&gt; +')
&gt; +
&gt; +    C previous digest combining
&gt; +    vxor           C0,C0,D
&gt; +
&gt; +    C polynomial multiplication
&gt; +    vpmsumd        F,H1L,C0
&gt; +    vpmsumd        R,H1M,C0
&gt; +
&gt; +    C reduction
&gt; +    vpmsumd        T,F,POLY_L
&gt; +    xxswapd        VSR(D),VSR(F)
&gt; +    vxor           R,R,T
&gt; +    vxor           D,R,D
&gt; +
&gt; +Ldone:
&gt; +    C byte-reverse of each doubleword permuting on little-endian mode
&gt; +IF_LE(`
&gt; +    vperm          D,D,D,LE_MASK
&gt; +')
&gt; +    stxvd2x        VSR(D),0,X                    C store digest 'D'
&gt; +
&gt; +    blr
&gt; +EPILOGUE(_nettle_gcm_hash)
&gt; +
&gt; +.data
&gt; +    C 0xC2000000000000000000000000000001
&gt; +.polynomial:
&gt; +.align 4
&gt; +IF_BE(`
&gt; +.byte 0xC2
&gt; +.rept 14
&gt; +.byte 0x00
&gt; +.endr
&gt; +.byte 0x01
&gt; +',`
&gt; +.byte 0x01
&gt; +.rept 14
&gt; +.byte 0x00
&gt; +.endr
&gt; +.byte 0xC2
&gt; +')
&gt;
&gt; --
&gt; 2.17.1
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201112174514</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-11-12 17:45:14-0400</timestampReceived><subject>Fwd: [PowerPC] GCM optimization</subject><body>

---------- Forwarded message ---------
From: Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
Date: Thu, Nov 12, 2020 at 7:42 PM
Subject: Re: [PowerPC] GCM optimization
To: Niels Möller &lt;nisse@lysator.liu.se&gt;


On Thu, Nov 12, 2020 at 6:40 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; I gave it a test run on gcc112 in the gcc compile farm, and speedup of
&gt; gcm update seems to be 26 times(!) compared to the C version.
&gt;

That's reasonable, I got similar speedup on more stable POWER instances
than gcc compile farm.


&gt; Where would that documentation be published? In the Nettle manual, as
&gt; some IBM white paper, or as a more-or-less academic paper, e.g., on
&gt; arxiv? I will not be able to spend much time on writing, but I'd be
&gt; happy to review.
&gt;

I'll start writing the papers once I got more details from IBM, similar to
intel documents, the document will be academic and practical at the same
time, I'll dive into finite field equations to demonstrate how we get there
as well as I'll add a practical example to clarify the preference of this
method in addition to the expected speedup of this method. My
intention that other crypto libraries could take advantage of this document
or maybe be a starting point for further improvements to the algorithm so
I'm checking if IBM would publish or approve such a document the same as
intel.


&gt; I have a sketch of ARM Neon code doing the equivalent of two vpmsumd,
&gt; with reasonable parallelism. Quite a lot of instructions needed.
&gt;

If you don't have much time, you can send it here and I'll continue from
that point. I'm planning to compare the new method with the usual method
with and without the karatsuba algorithm.

&gt; +C Alignment of gcm_key table elements, which is declared in gcm.h
&gt; &gt; +define(`TableElemAlign', `0x100')
&gt;
&gt; I still find this large constant puzzling. If I try
&gt;
&gt;   struct gcm_key key;
&gt;   printf("sizeof (key): %zd, sizeof(key.h[0]): %zd\n", sizeof(key),
&gt; sizeof(key.h[0]));
&gt;
&gt; (I added it to the start of test_main in gcm-test.c) and run on the
&gt; gcc112 machine, I get
&gt;
&gt;   sizeof (key): 4096, sizeof(key.h[0]): 16
&gt;
&gt; Which is what I'd expect, with elements of size 16 bytes, not 256 bytes.
&gt;
&gt; I haven't yet had the time to read the code carefully.
&gt;

You see, the alignment of each element is 0x100 (256). The table has 16
elements and you got the size of the table 4096 which is reasonable because
16*256=4096

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201201175505</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-12-01 17:55:05-0400</timestampReceived><subject>Re: Fwd: [PowerPC] GCM optimization</subject><body>

Hi George,
I'll start writing a white paper called "Optimizing Galois-Counter-Mode on
PowerPC Architecture Processors". Once I finish the first draft I'll send
it to Neils to review it.


&gt; What do you need from the IBM side?  I may be able to help.  We'd
&gt; definitely
&gt; like to support you and Niels in publishing your results.
&gt;

I have a couple of questions:
Should we send the paper to you when we make sure everything is ready for
publishing?
Can you participate as a supervisor to make some decisions like mentioning
arm implementation results of the research or making comparison with intel
white papers which used for x86, ARM, and PowerPC GCM implementations in
OpenSSL library?

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201111162435</emailId><senderName>George Wilson</senderName><senderEmail>gcwilson@linux.ibm.com</senderEmail><timestampReceived>2020-11-11 16:24:35-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

On Wed, Nov 11, 2020 at 02:17:41AM +0200, Maamoun TK wrote:
&gt; I think I mislabeled the percentage of performance comparison, the new
&gt; method achieved 27.7% reduction in time on POWER8 that corresponds to 37.9%
&gt; increase in performance.

Hi Maamoun,

Many thanks to you and Niels.  We plan to test this on POWER9.

&gt; 
&gt; On Tue, Nov 10, 2020 at 6:25 AM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
&gt; wrote:
&gt; 
&gt; &gt; This implementation takes advantage of research made by Niels M��ller to
&gt; &gt; optimize GCM on PowerPC, this optimization yields a +27.7% performance
&gt; &gt; boost on POWER8 over the previous implementation that was based on intel
&gt; &gt; documents. The performance comparison is made by processing 4 blocks per
&gt; &gt; loop without any further optimizations.
&gt; &gt; I made some documentations between the lines but I suggest writing a
&gt; &gt; document similar to the intel ones that go into more details and clarify
&gt; &gt; the preference of this method. I'm also curious if this method can also
&gt; &gt; make a difference in other architectures like ARM, I'm planning to try it
&gt; &gt; out for ARM to figure that out.
&gt; &gt; ---
&gt; &gt;  configure.ac              |   6 +-
&gt; &gt;  gcm.c                     |  49 +++--
&gt; &gt;  powerpc64/p8/gcm-hash.asm | 502
&gt; &gt; ++++++++++++++++++++++++++++++++++++++++++++++
&gt; &gt;  3 files changed, 542 insertions(+), 15 deletions(-)
&gt; &gt;  create mode 100644 powerpc64/p8/gcm-hash.asm
&gt; &gt;
&gt; &gt; diff --git a/configure.ac b/configure.ac
&gt; &gt; index 2a47f940..20f7cf74 100644
&gt; &gt; --- a/configure.ac
&gt; &gt; +++ b/configure.ac
&gt; &gt; @@ -497,7 +497,7 @@ asm_replace_list="aes-encrypt-internal.asm
&gt; &gt; aes-decrypt-internal.asm \
&gt; &gt;   sha3-permute.asm umac-nh.asm umac-nh-n.asm machine.m4"
&gt; &gt;
&gt; &gt;  # Assembler files which generate additional object files if they are used.
&gt; &gt; -asm_nettle_optional_list="gcm-hash8.asm cpuid.asm \
&gt; &gt; +asm_nettle_optional_list="gcm-hash.asm gcm-hash8.asm cpuid.asm \
&gt; &gt;    aes-encrypt-internal-2.asm aes-decrypt-internal-2.asm memxor-2.asm \
&gt; &gt;    chacha-3core.asm chacha-core-internal-2.asm salsa20-2core.asm \
&gt; &gt;    salsa20-core-internal-2.asm sha1-compress-2.asm sha256-compress-2.asm \
&gt; &gt; @@ -621,9 +621,9 @@ AH_VERBATIM([HAVE_NATIVE],
&gt; &gt;  #undef HAVE_NATIVE_ecc_secp384r1_redc
&gt; &gt;  #undef HAVE_NATIVE_ecc_secp521r1_modp
&gt; &gt;  #undef HAVE_NATIVE_ecc_secp521r1_redc
&gt; &gt; -#undef HAVE_NATIVE_gcm_init_key8
&gt; &gt; +#undef HAVE_NATIVE_gcm_init_key
&gt; &gt; +#undef HAVE_NATIVE_gcm_hash
&gt; &gt;  #undef HAVE_NATIVE_gcm_hash8
&gt; &gt; -#undef HAVE_NATIVE_gcm_fill
&gt; &gt;  #undef HAVE_NATIVE_salsa20_core
&gt; &gt;  #undef HAVE_NATIVE_salsa20_2core
&gt; &gt;  #undef HAVE_NATIVE_fat_salsa20_2core
&gt; &gt; diff --git a/gcm.c b/gcm.c
&gt; &gt; index 48b3e75a..81981c1c 100644
&gt; &gt; --- a/gcm.c
&gt; &gt; +++ b/gcm.c
&gt; &gt; @@ -140,6 +140,19 @@ gcm_gf_mul (union nettle_block16 *x, const union
&gt; &gt; nettle_block16 *table)
&gt; &gt;    memcpy (x-&gt;b, Z.b, sizeof(Z));
&gt; &gt;  }
&gt; &gt;  # elif GCM_TABLE_BITS == 8
&gt; &gt; +#  if HAVE_NATIVE_gcm_init_key
&gt; &gt; +
&gt; &gt; +#define gcm_init_key _nettle_gcm_init_key
&gt; &gt; +void
&gt; &gt; +_nettle_gcm_init_key (union nettle_block16 *table);
&gt; &gt; +#  endif /* HAVE_NATIVE_gcm_init_key */
&gt; &gt; +#  if HAVE_NATIVE_gcm_hash
&gt; &gt; +
&gt; &gt; +#define gcm_hash _nettle_gcm_hash
&gt; &gt; +void
&gt; &gt; +_nettle_gcm_hash (const struct gcm_key *key, union nettle_block16 *x,
&gt; &gt; +   size_t length, const uint8_t *data);
&gt; &gt; +#  endif /* HAVE_NATIVE_gcm_hash */
&gt; &gt;  #  if HAVE_NATIVE_gcm_hash8
&gt; &gt;
&gt; &gt;  #define gcm_hash _nettle_gcm_hash8
&gt; &gt; @@ -228,6 +241,29 @@ gcm_gf_mul (union nettle_block16 *x, const union
&gt; &gt; nettle_block16 *table)
&gt; &gt;  /* Increment the rightmost 32 bits. */
&gt; &gt;  #define INC32(block) INCREMENT(4, (block.b) + GCM_BLOCK_SIZE - 4)
&gt; &gt;
&gt; &gt; +#ifndef gcm_init_key
&gt; &gt; +static void
&gt; &gt; +gcm_init_key(union nettle_block16 *table)
&gt; &gt; +{
&gt; &gt; +#if GCM_TABLE_BITS
&gt; &gt; +  /* Middle element if GCM_TABLE_BITS &gt; 0, otherwise the first
&gt; &gt; +     element */
&gt; &gt; +  unsigned i = (1&lt;&lt;GCM_TABLE_BITS)/2;
&gt; &gt; +
&gt; &gt; +  /* Algorithm 3 from the gcm paper. First do powers of two, then do
&gt; &gt; +     the rest by adding. */
&gt; &gt; +  while (i /= 2)
&gt; &gt; +    block16_mulx_ghash(&amp;table[i], &amp;table[2*i]);
&gt; &gt; +  for (i = 2; i &lt; 1&lt;&lt;GCM_TABLE_BITS; i *= 2)
&gt; &gt; +    {
&gt; &gt; +      unsigned j;
&gt; &gt; +      for (j = 1; j &lt; i; j++)
&gt; &gt; + block16_xor3(&amp;table[i+j], &amp;table[i], &amp;table[j]);
&gt; &gt; +    }
&gt; &gt; +#endif
&gt; &gt; +}
&gt; &gt; +#endif /* !gcm_init_key */
&gt; &gt; +
&gt; &gt;  /* Initialization of GCM.
&gt; &gt;   * @ctx: The context of GCM
&gt; &gt;   * @cipher: The context of the underlying block cipher
&gt; &gt; @@ -245,18 +281,7 @@ gcm_set_key(struct gcm_key *key,
&gt; &gt;    memset(key-&gt;h[0].b, 0, GCM_BLOCK_SIZE);
&gt; &gt;    f (cipher, GCM_BLOCK_SIZE, key-&gt;h[i].b, key-&gt;h[0].b);
&gt; &gt;
&gt; &gt; -#if GCM_TABLE_BITS
&gt; &gt; -  /* Algorithm 3 from the gcm paper. First do powers of two, then do
&gt; &gt; -     the rest by adding. */
&gt; &gt; -  while (i /= 2)
&gt; &gt; -    block16_mulx_ghash(&amp;key-&gt;h[i], &amp;key-&gt;h[2*i]);
&gt; &gt; -  for (i = 2; i &lt; 1&lt;&lt;GCM_TABLE_BITS; i *= 2)
&gt; &gt; -    {
&gt; &gt; -      unsigned j;
&gt; &gt; -      for (j = 1; j &lt; i; j++)
&gt; &gt; - block16_xor3(&amp;key-&gt;h[i+j], &amp;key-&gt;h[i],&amp;key-&gt;h[j]);
&gt; &gt; -    }
&gt; &gt; -#endif
&gt; &gt; +  gcm_init_key(key-&gt;h);
&gt; &gt;  }
&gt; &gt;
&gt; &gt;  #ifndef gcm_hash
&gt; &gt; diff --git a/powerpc64/p8/gcm-hash.asm b/powerpc64/p8/gcm-hash.asm
&gt; &gt; new file mode 100644
&gt; &gt; index 00000000..e79fbdc2
&gt; &gt; --- /dev/null
&gt; &gt; +++ b/powerpc64/p8/gcm-hash.asm
&gt; &gt; @@ -0,0 +1,502 @@
&gt; &gt; +C powerpc64/p8/gcm-hash.asm
&gt; &gt; +
&gt; &gt; +ifelse(`
&gt; &gt; +   Copyright (C) 2020 Niels M��ller and Mamone Tarsha
&gt; &gt; +   This file is part of GNU Nettle.
&gt; &gt; +
&gt; &gt; +   GNU Nettle is free software: you can redistribute it and/or
&gt; &gt; +   modify it under the terms of either:
&gt; &gt; +
&gt; &gt; +     * the GNU Lesser General Public License as published by the Free
&gt; &gt; +       Software Foundation; either version 3 of the License, or (at your
&gt; &gt; +       option) any later version.
&gt; &gt; +
&gt; &gt; +   or
&gt; &gt; +
&gt; &gt; +     * the GNU General Public License as published by the Free
&gt; &gt; +       Software Foundation; either version 2 of the License, or (at your
&gt; &gt; +       option) any later version.
&gt; &gt; +
&gt; &gt; +   or both in parallel, as here.
&gt; &gt; +
&gt; &gt; +   GNU Nettle is distributed in the hope that it will be useful,
&gt; &gt; +   but WITHOUT ANY WARRANTY; without even the implied warranty of
&gt; &gt; +   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
&gt; &gt; +   General Public License for more details.
&gt; &gt; +
&gt; &gt; +   You should have received copies of the GNU General Public License and
&gt; &gt; +   the GNU Lesser General Public License along with this program.  If
&gt; &gt; +   not, see http://www.gnu.org/licenses/.
&gt; &gt; +')
&gt; &gt; +
&gt; &gt; +C Alignment of gcm_key table elements, which is declared in gcm.h
&gt; &gt; +define(`TableElemAlign', `0x100')
&gt; &gt; +
&gt; &gt; +C Register usage:
&gt; &gt; +
&gt; &gt; +define(`SP', `r1')
&gt; &gt; +define(`TOCP', `r2')
&gt; &gt; +
&gt; &gt; +define(`TABLE', `r3')
&gt; &gt; +
&gt; &gt; +define(`ZERO', `v0')
&gt; &gt; +define(`B1', `v1')
&gt; &gt; +define(`EMSB', `v16')
&gt; &gt; +define(`POLY', `v17')
&gt; &gt; +define(`POLY_L', `v1')
&gt; &gt; +
&gt; &gt; +define(`H', `v2')
&gt; &gt; +define(`H2', `v3')
&gt; &gt; +define(`H3', `v4')
&gt; &gt; +define(`H4', `v5')
&gt; &gt; +define(`H1M', `v6')
&gt; &gt; +define(`H1L', `v7')
&gt; &gt; +define(`H2M', `v8')
&gt; &gt; +define(`H2L', `v9')
&gt; &gt; +define(`Hl', `v10')
&gt; &gt; +define(`Hm', `v11')
&gt; &gt; +define(`Hp', `v12')
&gt; &gt; +define(`Hl2', `v13')
&gt; &gt; +define(`Hm2', `v14')
&gt; &gt; +define(`Hp2', `v15')
&gt; &gt; +define(`R', `v13')
&gt; &gt; +define(`F', `v14')
&gt; &gt; +define(`T', `v15')
&gt; &gt; +define(`R2', `v16')
&gt; &gt; +define(`F2', `v17')
&gt; &gt; +define(`T2', `v18')
&gt; &gt; +
&gt; &gt; +define(`LE_TEMP', `v18')
&gt; &gt; +define(`LE_MASK', `v19')
&gt; &gt; +
&gt; &gt; +.file "gcm-hash.asm"
&gt; &gt; +
&gt; &gt; +.text
&gt; &gt; +
&gt; &gt; +    C void gcm_init_key (union gcm_block *table)
&gt; &gt; +
&gt; &gt; +C This function populates the gcm table as the following layout
&gt; &gt; +C
&gt; &gt; *******************************************************************************
&gt; &gt; +C | H1M = (H1 div x������)||((H1 mod x������) �� (x������+x��� �+x��� �+x������)) div x������
&gt; &gt;        |
&gt; &gt; +C | H1L = (H1 mod x������)||(((H1 mod x������) �� (x��� �+x��� �+x������)) mod x������) + (H1
&gt; &gt; div x������) |
&gt; &gt; +C |
&gt; &gt;       |
&gt; &gt; +C | H2M = (H2 div x������)||((H2 mod x������) �� (x������+x��� �+x��� �+x������)) div x������
&gt; &gt;        |
&gt; &gt; +C | H2L = (H2 mod x������)||(((H2 mod x������) �� (x��� �+x��� �+x������)) mod x������) + (H2
&gt; &gt; div x������) |
&gt; &gt; +C |
&gt; &gt;       |
&gt; &gt; +C | H3M = (H3 div x������)||((H3 mod x������) �� (x������+x��� �+x��� �+x������)) div x������
&gt; &gt;        |
&gt; &gt; +C | H3L = (H3 mod x������)||(((H3 mod x������) �� (x��� �+x��� �+x������)) mod x������) + (H3
&gt; &gt; div x������) |
&gt; &gt; +C |
&gt; &gt;       |
&gt; &gt; +C | H4M = (H3 div x������)||((H4 mod x������) �� (x������+x��� �+x��� �+x������)) div x������
&gt; &gt;        |
&gt; &gt; +C | H4L = (H3 mod x������)||(((H4 mod x������) �� (x��� �+x��� �+x������)) mod x������) + (H4
&gt; &gt; div x������) |
&gt; &gt; +C
&gt; &gt; *******************************************************************************
&gt; &gt; +
&gt; &gt; +define(`FUNC_ALIGN', `5')
&gt; &gt; +PROLOGUE(_nettle_gcm_init_key)
&gt; &gt; +    DATA_LOAD_VEC(POLY,.polynomial,r7)           C
&gt; &gt; 0xC2000000000000000000000000000001
&gt; &gt; +IF_LE(`
&gt; &gt; +    li             r8,0
&gt; &gt; +    lvsl           LE_MASK,0,r8                  C
&gt; &gt; 0x000102030405060708090A0B0C0D0E0F
&gt; &gt; +    vspltisb       LE_TEMP,0x07                  C
&gt; &gt; 0x07070707070707070707070707070707
&gt; &gt; +    vxor           LE_MASK,LE_MASK,LE_TEMP       C
&gt; &gt; 0x07060504030201000F0E0D0C0B0A0908
&gt; &gt; +')
&gt; &gt; +
&gt; &gt; +    C 'H' is assigned by gcm_set_key() to the middle element of the table
&gt; &gt; +    li             r10,8*TableElemAlign
&gt; &gt; +    lxvd2x         VSR(H),r10,TABLE              C load 'H'
&gt; &gt; +    C byte-reverse of each doubleword permuting on little-endian mode
&gt; &gt; +IF_LE(`
&gt; &gt; +    vperm          H,H,H,LE_MASK
&gt; &gt; +')
&gt; &gt; +
&gt; &gt; +    C --- calculate H = H &lt;&lt; 1 mod P(X), P(X) = (x � ����+x � ����+x � ����+x � � �+1)
&gt; &gt; ---
&gt; &gt; +
&gt; &gt; +    vupkhsb        EMSB,H                        C extend most
&gt; &gt; significant bit to first byte
&gt; &gt; +    vspltisb       B1,1                          C
&gt; &gt; 0x01010101010101010101010101010101
&gt; &gt; +    vspltb         EMSB,EMSB,0                   C first byte
&gt; &gt; quadword-extend
&gt; &gt; +    vsl            H,H,B1                        C H = H &lt;&lt; 1
&gt; &gt; +    vand           EMSB,EMSB,POLY                C EMSB &amp;=
&gt; &gt; 0xC2000000000000000000000000000001
&gt; &gt; +    vxor           ZERO,ZERO,ZERO                C
&gt; &gt; 0x00000000000000000000000000000000
&gt; &gt; +    vxor           H,H,EMSB                      C H ^= EMSB
&gt; &gt; +
&gt; &gt; +    C --- calculate H^2 = H*H ---
&gt; &gt; +
&gt; &gt; +    xxmrghd        VSR(POLY_L),VSR(ZERO),VSR(POLY) C
&gt; &gt; 0x0000000000000000C200000000000000
&gt; &gt; +
&gt; &gt; +    C --- Hp = (H mod x������) / x������ mod P(X) ---
&gt; &gt; +    C --- Hp = (H mod x������) �� (x������+x��� �+x��� �+x������) mod P(X), deg(Hp) ��� 127 ---
&gt; &gt; +    C --- Hp = (H mod x������) �� (x������+x��� �+x��� �+x������) ---
&gt; &gt; +    vpmsumd        Hp,H,POLY_L                   C Hp = (H mod x������) ��
&gt; &gt; (x��� �+x��� �+x������)
&gt; &gt; +    xxmrgld        VSR(Hl),VSR(H),VSR(ZERO)      C Hl = (H mod x������) �� x������
&gt; &gt; +    xxswapd        VSR(Hm),VSR(H)
&gt; &gt; +    vxor           Hl,Hl,Hp                      C Hl = Hl + Hp
&gt; &gt; +    vxor           Hm,Hm,Hp                      C Hm = Hm + Hp
&gt; &gt; +    xxmrghd        VSR(H1M),VSR(H),VSR(Hl)       C H1M = (H div x������)||(Hl
&gt; &gt; div x������)
&gt; &gt; +    xxmrgld        VSR(H1L),VSR(H),VSR(Hm)       C H1L = (H mod x������)||(Hl
&gt; &gt; mod x������)
&gt; &gt; +
&gt; &gt; +    vpmsumd        F,H1L,H                       C F = (H1Lh �� Hh) +
&gt; &gt; (H1Ll �� Hl)
&gt; &gt; +    vpmsumd        R,H1M,H                       C R = (H1Mh �� Hh) +
&gt; &gt; (H1Ml �� Hl)
&gt; &gt; +
&gt; &gt; +    C --- rduction ---
&gt; &gt; +    vpmsumd        T,F,POLY_L                    C T = (F mod x������) ��
&gt; &gt; (x��� �+x��� �+x������)
&gt; &gt; +    xxswapd        VSR(H2),VSR(F)
&gt; &gt; +    vxor           R,R,T                         C R = R + T
&gt; &gt; +    vxor           H2,R,H2
&gt; &gt; +
&gt; &gt; +    xxmrgld        VSR(Hl),VSR(H2),VSR(ZERO)
&gt; &gt; +    xxswapd        VSR(Hm),VSR(H2)
&gt; &gt; +    vpmsumd        Hp,H2,POLY_L
&gt; &gt; +    vxor           Hl,Hl,Hp
&gt; &gt; +    vxor           Hm,Hm,Hp
&gt; &gt; +    xxmrghd        VSR(H2M),VSR(H2),VSR(Hl)
&gt; &gt; +    xxmrgld        VSR(H2L),VSR(H2),VSR(Hm)
&gt; &gt; +
&gt; &gt; +    C store H1M, H1L, H2M, H2L
&gt; &gt; +    li             r8,1*TableElemAlign
&gt; &gt; +    li             r9,2*TableElemAlign
&gt; &gt; +    li             r10,3*TableElemAlign
&gt; &gt; +    stxvd2x        VSR(H1M),0,TABLE
&gt; &gt; +    stxvd2x        VSR(H1L),r8,TABLE
&gt; &gt; +    stxvd2x        VSR(H2M),r9,TABLE
&gt; &gt; +    stxvd2x        VSR(H2L),r10,TABLE
&gt; &gt; +
&gt; &gt; +    C --- calculate H^3 = H^1*H^2, H^4 = H^2*H^2 ---
&gt; &gt; +
&gt; &gt; +    vpmsumd        F,H1L,H2
&gt; &gt; +    vpmsumd        F2,H2L,H2
&gt; &gt; +    vpmsumd        R,H1M,H2
&gt; &gt; +    vpmsumd        R2,H2M,H2
&gt; &gt; +
&gt; &gt; +    vpmsumd        T,F,POLY_L
&gt; &gt; +    vpmsumd        T2,F2,POLY_L
&gt; &gt; +    xxswapd        VSR(H3),VSR(F)
&gt; &gt; +    xxswapd        VSR(H4),VSR(F2)
&gt; &gt; +    vxor           R,R,T
&gt; &gt; +    vxor           R2,R2,T2
&gt; &gt; +    vxor           H3,R,H3
&gt; &gt; +    vxor           H4,R2,H4
&gt; &gt; +
&gt; &gt; +    xxmrgld        VSR(Hl),VSR(H3),VSR(ZERO)
&gt; &gt; +    xxmrgld        VSR(Hl2),VSR(H4),VSR(ZERO)
&gt; &gt; +    xxswapd        VSR(Hm),VSR(H3)
&gt; &gt; +    xxswapd        VSR(Hm2),VSR(H4)
&gt; &gt; +    vpmsumd        Hp,H3,POLY_L
&gt; &gt; +    vpmsumd        Hp2,H4,POLY_L
&gt; &gt; +    vxor           Hl,Hl,Hp
&gt; &gt; +    vxor           Hl2,Hl2,Hp2
&gt; &gt; +    vxor           Hm,Hm,Hp
&gt; &gt; +    vxor           Hm2,Hm2,Hp2
&gt; &gt; +    xxmrghd        VSR(H1M),VSR(H3),VSR(Hl)
&gt; &gt; +    xxmrghd        VSR(H2M),VSR(H4),VSR(Hl2)
&gt; &gt; +    xxmrgld        VSR(H1L),VSR(H3),VSR(Hm)
&gt; &gt; +    xxmrgld        VSR(H2L),VSR(H4),VSR(Hm2)
&gt; &gt; +
&gt; &gt; +    C store H3M, H3L, H4M, H4L
&gt; &gt; +    li             r7,4*TableElemAlign
&gt; &gt; +    li             r8,5*TableElemAlign
&gt; &gt; +    li             r9,6*TableElemAlign
&gt; &gt; +    li             r10,7*TableElemAlign
&gt; &gt; +    stxvd2x        VSR(H1M),r7,TABLE
&gt; &gt; +    stxvd2x        VSR(H1L),r8,TABLE
&gt; &gt; +    stxvd2x        VSR(H2M),r9,TABLE
&gt; &gt; +    stxvd2x        VSR(H2L),r10,TABLE
&gt; &gt; +
&gt; &gt; +    blr
&gt; &gt; +EPILOGUE(_nettle_gcm_init_key)
&gt; &gt; +
&gt; &gt; +define(`TABLE', `r3')
&gt; &gt; +define(`X', `r4')
&gt; &gt; +define(`LENGTH', `r5')
&gt; &gt; +define(`DATA', `r6')
&gt; &gt; +
&gt; &gt; +define(`ZERO', `v16')
&gt; &gt; +define(`POLY', `v17')
&gt; &gt; +define(`POLY_L', `v0')
&gt; &gt; +
&gt; &gt; +define(`D', `v1')
&gt; &gt; +define(`C0', `v2')
&gt; &gt; +define(`C1', `v3')
&gt; &gt; +define(`C2', `v4')
&gt; &gt; +define(`C3', `v5')
&gt; &gt; +define(`H1M', `v6')
&gt; &gt; +define(`H1L', `v7')
&gt; &gt; +define(`H2M', `v8')
&gt; &gt; +define(`H2L', `v9')
&gt; &gt; +define(`H3M', `v10')
&gt; &gt; +define(`H3L', `v11')
&gt; &gt; +define(`H4M', `v12')
&gt; &gt; +define(`H4L', `v13')
&gt; &gt; +define(`R', `v14')
&gt; &gt; +define(`F', `v15')
&gt; &gt; +define(`R2', `v16')
&gt; &gt; +define(`F2', `v17')
&gt; &gt; +define(`R3', `v18')
&gt; &gt; +define(`F3', `v20')
&gt; &gt; +define(`R4', `v21')
&gt; &gt; +define(`F4', `v22')
&gt; &gt; +define(`T', `v23')
&gt; &gt; +
&gt; &gt; +define(`LE_TEMP', `v18')
&gt; &gt; +define(`LE_MASK', `v19')
&gt; &gt; +
&gt; &gt; +    C void gcm_hash (const struct gcm_key *key, union gcm_block *x,
&gt; &gt; +    C                size_t length, const uint8_t *data)
&gt; &gt; +
&gt; &gt; +define(`FUNC_ALIGN', `5')
&gt; &gt; +PROLOGUE(_nettle_gcm_hash)
&gt; &gt; +    DATA_LOAD_VEC(POLY,.polynomial,r7)
&gt; &gt; +IF_LE(`
&gt; &gt; +    li             r8,0
&gt; &gt; +    lvsl           LE_MASK,0,r8
&gt; &gt; +    vspltisb       LE_TEMP,0x07
&gt; &gt; +    vxor           LE_MASK,LE_MASK,LE_TEMP
&gt; &gt; +')
&gt; &gt; +    vxor           ZERO,ZERO,ZERO
&gt; &gt; +    xxmrghd        VSR(POLY_L),VSR(ZERO),VSR(POLY)
&gt; &gt; +
&gt; &gt; +    lxvd2x         VSR(D),0,X                    C load 'X' pointer
&gt; &gt; +    C byte-reverse of each doubleword permuting on little-endian mode
&gt; &gt; +IF_LE(`
&gt; &gt; +    vperm          D,D,D,LE_MASK
&gt; &gt; +')
&gt; &gt; +
&gt; &gt; +    C --- process 4 blocks '128-bit each' per one loop ---
&gt; &gt; +
&gt; &gt; +    srdi           r7,LENGTH,6                   C 4-blocks loop count
&gt; &gt; 'LENGTH / (4 * 16)'
&gt; &gt; +    cmpldi         r7,0
&gt; &gt; +    beq            L2x
&gt; &gt; +
&gt; &gt; +    mtctr          r7                            C assign counter
&gt; &gt; register to loop count
&gt; &gt; +
&gt; &gt; +    C store non-volatile vector registers
&gt; &gt; +    addi           r8,SP,-64
&gt; &gt; +    stvx           20,0,r8
&gt; &gt; +    addi           r8,r8,16
&gt; &gt; +    stvx           21,0,r8
&gt; &gt; +    addi           r8,r8,16
&gt; &gt; +    stvx           22,0,r8
&gt; &gt; +    addi           r8,r8,16
&gt; &gt; +    stvx           23,0,r8
&gt; &gt; +
&gt; &gt; +    C load table elements
&gt; &gt; +    li             r8,1*TableElemAlign
&gt; &gt; +    li             r9,2*TableElemAlign
&gt; &gt; +    li             r10,3*TableElemAlign
&gt; &gt; +    lxvd2x         VSR(H1M),0,TABLE
&gt; &gt; +    lxvd2x         VSR(H1L),r8,TABLE
&gt; &gt; +    lxvd2x         VSR(H2M),r9,TABLE
&gt; &gt; +    lxvd2x         VSR(H2L),r10,TABLE
&gt; &gt; +    li             r7,4*TableElemAlign
&gt; &gt; +    li             r8,5*TableElemAlign
&gt; &gt; +    li             r9,6*TableElemAlign
&gt; &gt; +    li             r10,7*TableElemAlign
&gt; &gt; +    lxvd2x         VSR(H3M),r7,TABLE
&gt; &gt; +    lxvd2x         VSR(H3L),r8,TABLE
&gt; &gt; +    lxvd2x         VSR(H4M),r9,TABLE
&gt; &gt; +    lxvd2x         VSR(H4L),r10,TABLE
&gt; &gt; +
&gt; &gt; +    li             r8,0x10
&gt; &gt; +    li             r9,0x20
&gt; &gt; +    li             r10,0x30
&gt; &gt; +.align 5
&gt; &gt; +L4x_loop:
&gt; &gt; +    C input loading
&gt; &gt; +    lxvd2x         VSR(C0),0,DATA                C load C0
&gt; &gt; +    lxvd2x         VSR(C1),r8,DATA               C load C1
&gt; &gt; +    lxvd2x         VSR(C2),r9,DATA               C load C2
&gt; &gt; +    lxvd2x         VSR(C3),r10,DATA              C load C3
&gt; &gt; +
&gt; &gt; +IF_LE(`
&gt; &gt; +    vperm          C0,C0,C0,LE_MASK
&gt; &gt; +    vperm          C1,C1,C1,LE_MASK
&gt; &gt; +    vperm          C2,C2,C2,LE_MASK
&gt; &gt; +    vperm          C3,C3,C3,LE_MASK
&gt; &gt; +')
&gt; &gt; +
&gt; &gt; +    C previous digest combining
&gt; &gt; +    vxor           C0,C0,D
&gt; &gt; +
&gt; &gt; +    C polynomial multiplication
&gt; &gt; +    vpmsumd        F2,H3L,C1
&gt; &gt; +    vpmsumd        R2,H3M,C1
&gt; &gt; +    vpmsumd        F3,H2L,C2
&gt; &gt; +    vpmsumd        R3,H2M,C2
&gt; &gt; +    vpmsumd        F4,H1L,C3
&gt; &gt; +    vpmsumd        R4,H1M,C3
&gt; &gt; +    vpmsumd        F,H4L,C0
&gt; &gt; +    vpmsumd        R,H4M,C0
&gt; &gt; +
&gt; &gt; +    C deferred recombination of partial products
&gt; &gt; +    vxor           F3,F3,F4
&gt; &gt; +    vxor           R3,R3,R4
&gt; &gt; +    vxor           F,F,F2
&gt; &gt; +    vxor           R,R,R2
&gt; &gt; +    vxor           F,F,F3
&gt; &gt; +    vxor           R,R,R3
&gt; &gt; +
&gt; &gt; +    C reduction
&gt; &gt; +    vpmsumd        T,F,POLY_L
&gt; &gt; +    xxswapd        VSR(D),VSR(F)
&gt; &gt; +    vxor           R,R,T
&gt; &gt; +    vxor           D,R,D
&gt; &gt; +
&gt; &gt; +    addi           DATA,DATA,0x40
&gt; &gt; +    bdnz           L4x_loop
&gt; &gt; +
&gt; &gt; +    C restore non-volatile vector registers
&gt; &gt; +    addi           r8,SP,-64
&gt; &gt; +    lvx            20,0,r8
&gt; &gt; +    addi           r8,r8,16
&gt; &gt; +    lvx            21,0,r8
&gt; &gt; +    addi           r8,r8,16
&gt; &gt; +    lvx            22,0,r8
&gt; &gt; +    addi           r8,r8,16
&gt; &gt; +    lvx            23,0,r8
&gt; &gt; +
&gt; &gt; +    clrldi         LENGTH,LENGTH,58              C 'set the high-order 58
&gt; &gt; bits to zeros'
&gt; &gt; +L2x:
&gt; &gt; +    C --- process 2 blocks ---
&gt; &gt; +
&gt; &gt; +    srdi           r7,LENGTH,5                   C 'LENGTH / (2 * 16)'
&gt; &gt; +    cmpldi         r7,0
&gt; &gt; +    beq            L1x
&gt; &gt; +
&gt; &gt; +    C load table elements
&gt; &gt; +    li             r8,1*TableElemAlign
&gt; &gt; +    li             r9,2*TableElemAlign
&gt; &gt; +    li             r10,3*TableElemAlign
&gt; &gt; +    lxvd2x         VSR(H1M),0,TABLE
&gt; &gt; +    lxvd2x         VSR(H1L),r8,TABLE
&gt; &gt; +    lxvd2x         VSR(H2M),r9,TABLE
&gt; &gt; +    lxvd2x         VSR(H2L),r10,TABLE
&gt; &gt; +
&gt; &gt; +    C input loading
&gt; &gt; +    li             r10,0x10
&gt; &gt; +    lxvd2x         VSR(C0),0,DATA                C load C0
&gt; &gt; +    lxvd2x         VSR(C1),r10,DATA              C load C1
&gt; &gt; +
&gt; &gt; +IF_LE(`
&gt; &gt; +    vperm          C0,C0,C0,LE_MASK
&gt; &gt; +    vperm          C1,C1,C1,LE_MASK
&gt; &gt; +')
&gt; &gt; +
&gt; &gt; +    C previous digest combining
&gt; &gt; +    vxor           C0,C0,D
&gt; &gt; +
&gt; &gt; +    C polynomial multiplication
&gt; &gt; +    vpmsumd        F2,H1L,C1
&gt; &gt; +    vpmsumd        R2,H1M,C1
&gt; &gt; +    vpmsumd        F,H2L,C0
&gt; &gt; +    vpmsumd        R,H2M,C0
&gt; &gt; +
&gt; &gt; +    C deferred recombination of partial products
&gt; &gt; +    vxor           F,F,F2
&gt; &gt; +    vxor           R,R,R2
&gt; &gt; +
&gt; &gt; +    C reduction
&gt; &gt; +    vpmsumd        T,F,POLY_L
&gt; &gt; +    xxswapd        VSR(D),VSR(F)
&gt; &gt; +    vxor           R,R,T
&gt; &gt; +    vxor           D,R,D
&gt; &gt; +
&gt; &gt; +    addi           DATA,DATA,0x20
&gt; &gt; +    clrldi         LENGTH,LENGTH,59              C 'set the high-order 59
&gt; &gt; bits to zeros'
&gt; &gt; +L1x:
&gt; &gt; +    C --- process 1 block ---
&gt; &gt; +
&gt; &gt; +    srdi           r7,LENGTH,4                   C 'LENGTH / (1 * 16)'
&gt; &gt; +    cmpldi         r7,0
&gt; &gt; +    beq            Lmod
&gt; &gt; +
&gt; &gt; +    C load table elements
&gt; &gt; +    li             r8,1*TableElemAlign
&gt; &gt; +    lxvd2x         VSR(H1M),0,TABLE
&gt; &gt; +    lxvd2x         VSR(H1L),r8,TABLE
&gt; &gt; +
&gt; &gt; +    C input loading
&gt; &gt; +    lxvd2x         VSR(C0),0,DATA                C load C0
&gt; &gt; +
&gt; &gt; +IF_LE(`
&gt; &gt; +    vperm          C0,C0,C0,LE_MASK
&gt; &gt; +')
&gt; &gt; +
&gt; &gt; +    C previous digest combining
&gt; &gt; +    vxor           C0,C0,D
&gt; &gt; +
&gt; &gt; +    C polynomial multiplication
&gt; &gt; +    vpmsumd        F,H1L,C0
&gt; &gt; +    vpmsumd        R,H1M,C0
&gt; &gt; +
&gt; &gt; +    C reduction
&gt; &gt; +    vpmsumd        T,F,POLY_L
&gt; &gt; +    xxswapd        VSR(D),VSR(F)
&gt; &gt; +    vxor           R,R,T
&gt; &gt; +    vxor           D,R,D
&gt; &gt; +
&gt; &gt; +    addi           DATA,DATA,0x10
&gt; &gt; +    clrldi         LENGTH,LENGTH,60              C 'set the high-order 60
&gt; &gt; bits to zeros'
&gt; &gt; +Lmod:
&gt; &gt; +    C --- process the modulo bytes, padding the low-order bytes with
&gt; &gt; zeros ---
&gt; &gt; +
&gt; &gt; +    cmpldi         LENGTH,0
&gt; &gt; +    beq            Ldone
&gt; &gt; +
&gt; &gt; +    C load table elements
&gt; &gt; +    li             r8,1*TableElemAlign
&gt; &gt; +    lxvd2x         VSR(H1M),0,TABLE
&gt; &gt; +    lxvd2x         VSR(H1L),r8,TABLE
&gt; &gt; +
&gt; &gt; +    C push every modulo byte to the stack and load them with padding into
&gt; &gt; vector register
&gt; &gt; +    vxor           ZERO,ZERO,ZERO
&gt; &gt; +    addi           r8,SP,-16
&gt; &gt; +    stvx           ZERO,0,r8
&gt; &gt; +Lstb_loop:
&gt; &gt; +    subic.         LENGTH,LENGTH,1
&gt; &gt; +    lbzx           r7,LENGTH,DATA
&gt; &gt; +    stbx           r7,LENGTH,r8
&gt; &gt; +    bne            Lstb_loop
&gt; &gt; +    lxvd2x         VSR(C0),0,r8
&gt; &gt; +
&gt; &gt; +IF_LE(`
&gt; &gt; +    vperm          C0,C0,C0,LE_MASK
&gt; &gt; +')
&gt; &gt; +
&gt; &gt; +    C previous digest combining
&gt; &gt; +    vxor           C0,C0,D
&gt; &gt; +
&gt; &gt; +    C polynomial multiplication
&gt; &gt; +    vpmsumd        F,H1L,C0
&gt; &gt; +    vpmsumd        R,H1M,C0
&gt; &gt; +
&gt; &gt; +    C reduction
&gt; &gt; +    vpmsumd        T,F,POLY_L
&gt; &gt; +    xxswapd        VSR(D),VSR(F)
&gt; &gt; +    vxor           R,R,T
&gt; &gt; +    vxor           D,R,D
&gt; &gt; +
&gt; &gt; +Ldone:
&gt; &gt; +    C byte-reverse of each doubleword permuting on little-endian mode
&gt; &gt; +IF_LE(`
&gt; &gt; +    vperm          D,D,D,LE_MASK
&gt; &gt; +')
&gt; &gt; +    stxvd2x        VSR(D),0,X                    C store digest 'D'
&gt; &gt; +
&gt; &gt; +    blr
&gt; &gt; +EPILOGUE(_nettle_gcm_hash)
&gt; &gt; +
&gt; &gt; +.data
&gt; &gt; +    C 0xC2000000000000000000000000000001
&gt; &gt; +.polynomial:
&gt; &gt; +.align 4
&gt; &gt; +IF_BE(`
&gt; &gt; +.byte 0xC2
&gt; &gt; +.rept 14
&gt; &gt; +.byte 0x00
&gt; &gt; +.endr
&gt; &gt; +.byte 0x01
&gt; &gt; +',`
&gt; &gt; +.byte 0x01
&gt; &gt; +.rept 14
&gt; &gt; +.byte 0x00
&gt; &gt; +.endr
&gt; &gt; +.byte 0xC2
&gt; &gt; +')
&gt; &gt;
&gt; &gt; --
&gt; &gt; 2.17.1
&gt; &gt;
&gt; _______________________________________________
&gt; nettle-bugs mailing list
&gt; nettle-bugs@lists.lysator.liu.se
&gt; http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

-- 
George Wilson
IBM Linux Technology Center
Security Development
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201112164011</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-11-12 16:40:11-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; This implementation takes advantage of research made by Niels Möller to
&gt; optimize GCM on PowerPC, this optimization yields a +27.7% performance
&gt; boost on POWER8 over the previous implementation that was based on intel
&gt; documents. The performance comparison is made by processing 4 blocks per
&gt; loop without any further optimizations.

Hi, the patch didn't apply cleanly due to email line breaks (maybe try
posting as a text attachment next time?), but I've applied it
semi-manually, and pushed it to a branch ppc-gcm.

I gave it a test run on gcc112 in the gcc compile farm, and speedup of
gcm update seems to be 26 times(!) compared to the C version.

&gt; I made some documentations between the lines but I suggest writing a
&gt; document similar to the intel ones that go into more details and clarify
&gt; the preference of this method.

Where would that documentation be published? In the Nettle manual, as
some IBM white paper, or as a more-or-less academic paper, e.g., on
arxiv? I will not be able to spend much time on writing, but I'd be
happy to review.

&gt; I'm also curious if this method can also
&gt; make a difference in other architectures like ARM, I'm planning to try it
&gt; out for ARM to figure that out.

I have a sketch of ARM Neon code doing the equivalent of two vpmsumd,
with reasonable parallelism. Quite a lot of instructions needed.

Regards,
/Niels

&gt; +C Alignment of gcm_key table elements, which is declared in gcm.h
&gt; +define(`TableElemAlign', `0x100')

I still find this large constant puzzling. If I try

  struct gcm_key key;
  printf("sizeof (key): %zd, sizeof(key.h[0]): %zd\n", sizeof(key), sizeof(key.h[0]));

(I added it to the start of test_main in gcm-test.c) and run on the
gcc112 machine, I get

  sizeof (key): 4096, sizeof(key.h[0]): 16

Which is what I'd expect, with elements of size 16 bytes, not 256 bytes.

I haven't yet had the time to read the code carefully.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201112214925</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-11-12 21:49:25-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

I reuploaded the patch as attachment since it didn't apply due to email
line breaks, I also fixed the gcm table alignment issue, Thanks to Niels
M��ller.

On Tue, Nov 10, 2020 at 6:25 AM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
wrote:

&gt; This implementation takes advantage of research made by Niels M��ller to
&gt; optimize GCM on PowerPC, this optimization yields a +27.7% performance
&gt; boost on POWER8 over the previous implementation that was based on intel
&gt; documents. The performance comparison is made by processing 4 blocks per
&gt; loop without any further optimizations.
&gt; I made some documentations between the lines but I suggest writing a
&gt; document similar to the intel ones that go into more details and clarify
&gt; the preference of this method. I'm also curious if this method can also
&gt; make a difference in other architectures like ARM, I'm planning to try it
&gt; out for ARM to figure that out.
&gt; ---
&gt;  configure.ac              |   6 +-
&gt;  gcm.c                     |  49 +++--
&gt;  powerpc64/p8/gcm-hash.asm | 502
&gt; ++++++++++++++++++++++++++++++++++++++++++++++
&gt;  3 files changed, 542 insertions(+), 15 deletions(-)
&gt;  create mode 100644 powerpc64/p8/gcm-hash.asm
&gt;
&gt; diff --git a/configure.ac b/configure.ac
&gt; index 2a47f940..20f7cf74 100644
&gt; --- a/configure.ac
&gt; +++ b/configure.ac
&gt; @@ -497,7 +497,7 @@ asm_replace_list="aes-encrypt-internal.asm
&gt; aes-decrypt-internal.asm \
&gt;   sha3-permute.asm umac-nh.asm umac-nh-n.asm machine.m4"
&gt;
&gt;  # Assembler files which generate additional object files if they are used.
&gt; -asm_nettle_optional_list="gcm-hash8.asm cpuid.asm \
&gt; +asm_nettle_optional_list="gcm-hash.asm gcm-hash8.asm cpuid.asm \
&gt;    aes-encrypt-internal-2.asm aes-decrypt-internal-2.asm memxor-2.asm \
&gt;    chacha-3core.asm chacha-core-internal-2.asm salsa20-2core.asm \
&gt;    salsa20-core-internal-2.asm sha1-compress-2.asm sha256-compress-2.asm \
&gt; @@ -621,9 +621,9 @@ AH_VERBATIM([HAVE_NATIVE],
&gt;  #undef HAVE_NATIVE_ecc_secp384r1_redc
&gt;  #undef HAVE_NATIVE_ecc_secp521r1_modp
&gt;  #undef HAVE_NATIVE_ecc_secp521r1_redc
&gt; -#undef HAVE_NATIVE_gcm_init_key8
&gt; +#undef HAVE_NATIVE_gcm_init_key
&gt; +#undef HAVE_NATIVE_gcm_hash
&gt;  #undef HAVE_NATIVE_gcm_hash8
&gt; -#undef HAVE_NATIVE_gcm_fill
&gt;  #undef HAVE_NATIVE_salsa20_core
&gt;  #undef HAVE_NATIVE_salsa20_2core
&gt;  #undef HAVE_NATIVE_fat_salsa20_2core
&gt; diff --git a/gcm.c b/gcm.c
&gt; index 48b3e75a..81981c1c 100644
&gt; --- a/gcm.c
&gt; +++ b/gcm.c
&gt; @@ -140,6 +140,19 @@ gcm_gf_mul (union nettle_block16 *x, const union
&gt; nettle_block16 *table)
&gt;    memcpy (x-&gt;b, Z.b, sizeof(Z));
&gt;  }
&gt;  # elif GCM_TABLE_BITS == 8
&gt; +#  if HAVE_NATIVE_gcm_init_key
&gt; +
&gt; +#define gcm_init_key _nettle_gcm_init_key
&gt; +void
&gt; +_nettle_gcm_init_key (union nettle_block16 *table);
&gt; +#  endif /* HAVE_NATIVE_gcm_init_key */
&gt; +#  if HAVE_NATIVE_gcm_hash
&gt; +
&gt; +#define gcm_hash _nettle_gcm_hash
&gt; +void
&gt; +_nettle_gcm_hash (const struct gcm_key *key, union nettle_block16 *x,
&gt; +   size_t length, const uint8_t *data);
&gt; +#  endif /* HAVE_NATIVE_gcm_hash */
&gt;  #  if HAVE_NATIVE_gcm_hash8
&gt;
&gt;  #define gcm_hash _nettle_gcm_hash8
&gt; @@ -228,6 +241,29 @@ gcm_gf_mul (union nettle_block16 *x, const union
&gt; nettle_block16 *table)
&gt;  /* Increment the rightmost 32 bits. */
&gt;  #define INC32(block) INCREMENT(4, (block.b) + GCM_BLOCK_SIZE - 4)
&gt;
&gt; +#ifndef gcm_init_key
&gt; +static void
&gt; +gcm_init_key(union nettle_block16 *table)
&gt; +{
&gt; +#if GCM_TABLE_BITS
&gt; +  /* Middle element if GCM_TABLE_BITS &gt; 0, otherwise the first
&gt; +     element */
&gt; +  unsigned i = (1&lt;&lt;GCM_TABLE_BITS)/2;
&gt; +
&gt; +  /* Algorithm 3 from the gcm paper. First do powers of two, then do
&gt; +     the rest by adding. */
&gt; +  while (i /= 2)
&gt; +    block16_mulx_ghash(&amp;table[i], &amp;table[2*i]);
&gt; +  for (i = 2; i &lt; 1&lt;&lt;GCM_TABLE_BITS; i *= 2)
&gt; +    {
&gt; +      unsigned j;
&gt; +      for (j = 1; j &lt; i; j++)
&gt; + block16_xor3(&amp;table[i+j], &amp;table[i], &amp;table[j]);
&gt; +    }
&gt; +#endif
&gt; +}
&gt; +#endif /* !gcm_init_key */
&gt; +
&gt;  /* Initialization of GCM.
&gt;   * @ctx: The context of GCM
&gt;   * @cipher: The context of the underlying block cipher
&gt; @@ -245,18 +281,7 @@ gcm_set_key(struct gcm_key *key,
&gt;    memset(key-&gt;h[0].b, 0, GCM_BLOCK_SIZE);
&gt;    f (cipher, GCM_BLOCK_SIZE, key-&gt;h[i].b, key-&gt;h[0].b);
&gt;
&gt; -#if GCM_TABLE_BITS
&gt; -  /* Algorithm 3 from the gcm paper. First do powers of two, then do
&gt; -     the rest by adding. */
&gt; -  while (i /= 2)
&gt; -    block16_mulx_ghash(&amp;key-&gt;h[i], &amp;key-&gt;h[2*i]);
&gt; -  for (i = 2; i &lt; 1&lt;&lt;GCM_TABLE_BITS; i *= 2)
&gt; -    {
&gt; -      unsigned j;
&gt; -      for (j = 1; j &lt; i; j++)
&gt; - block16_xor3(&amp;key-&gt;h[i+j], &amp;key-&gt;h[i],&amp;key-&gt;h[j]);
&gt; -    }
&gt; -#endif
&gt; +  gcm_init_key(key-&gt;h);
&gt;  }
&gt;
&gt;  #ifndef gcm_hash
&gt; diff --git a/powerpc64/p8/gcm-hash.asm b/powerpc64/p8/gcm-hash.asm
&gt; new file mode 100644
&gt; index 00000000..e79fbdc2
&gt; --- /dev/null
&gt; +++ b/powerpc64/p8/gcm-hash.asm
&gt; @@ -0,0 +1,502 @@
&gt; +C powerpc64/p8/gcm-hash.asm
&gt; +
&gt; +ifelse(`
&gt; +   Copyright (C) 2020 Niels M��ller and Mamone Tarsha
&gt; +   This file is part of GNU Nettle.
&gt; +
&gt; +   GNU Nettle is free software: you can redistribute it and/or
&gt; +   modify it under the terms of either:
&gt; +
&gt; +     * the GNU Lesser General Public License as published by the Free
&gt; +       Software Foundation; either version 3 of the License, or (at your
&gt; +       option) any later version.
&gt; +
&gt; +   or
&gt; +
&gt; +     * the GNU General Public License as published by the Free
&gt; +       Software Foundation; either version 2 of the License, or (at your
&gt; +       option) any later version.
&gt; +
&gt; +   or both in parallel, as here.
&gt; +
&gt; +   GNU Nettle is distributed in the hope that it will be useful,
&gt; +   but WITHOUT ANY WARRANTY; without even the implied warranty of
&gt; +   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
&gt; +   General Public License for more details.
&gt; +
&gt; +   You should have received copies of the GNU General Public License and
&gt; +   the GNU Lesser General Public License along with this program.  If
&gt; +   not, see http://www.gnu.org/licenses/.
&gt; +')
&gt; +
&gt; +C Alignment of gcm_key table elements, which is declared in gcm.h
&gt; +define(`TableElemAlign', `0x100')
&gt; +
&gt; +C Register usage:
&gt; +
&gt; +define(`SP', `r1')
&gt; +define(`TOCP', `r2')
&gt; +
&gt; +define(`TABLE', `r3')
&gt; +
&gt; +define(`ZERO', `v0')
&gt; +define(`B1', `v1')
&gt; +define(`EMSB', `v16')
&gt; +define(`POLY', `v17')
&gt; +define(`POLY_L', `v1')
&gt; +
&gt; +define(`H', `v2')
&gt; +define(`H2', `v3')
&gt; +define(`H3', `v4')
&gt; +define(`H4', `v5')
&gt; +define(`H1M', `v6')
&gt; +define(`H1L', `v7')
&gt; +define(`H2M', `v8')
&gt; +define(`H2L', `v9')
&gt; +define(`Hl', `v10')
&gt; +define(`Hm', `v11')
&gt; +define(`Hp', `v12')
&gt; +define(`Hl2', `v13')
&gt; +define(`Hm2', `v14')
&gt; +define(`Hp2', `v15')
&gt; +define(`R', `v13')
&gt; +define(`F', `v14')
&gt; +define(`T', `v15')
&gt; +define(`R2', `v16')
&gt; +define(`F2', `v17')
&gt; +define(`T2', `v18')
&gt; +
&gt; +define(`LE_TEMP', `v18')
&gt; +define(`LE_MASK', `v19')
&gt; +
&gt; +.file "gcm-hash.asm"
&gt; +
&gt; +.text
&gt; +
&gt; +    C void gcm_init_key (union gcm_block *table)
&gt; +
&gt; +C This function populates the gcm table as the following layout
&gt; +C
&gt; *******************************************************************************
&gt; +C | H1M = (H1 div x������)||((H1 mod x������) �� (x������+x��� �+x��� �+x������)) div x������
&gt;        |
&gt; +C | H1L = (H1 mod x������)||(((H1 mod x������) �� (x��� �+x��� �+x������)) mod x������) + (H1
&gt; div x������) |
&gt; +C |
&gt;       |
&gt; +C | H2M = (H2 div x������)||((H2 mod x������) �� (x������+x��� �+x��� �+x������)) div x������
&gt;        |
&gt; +C | H2L = (H2 mod x������)||(((H2 mod x������) �� (x��� �+x��� �+x������)) mod x������) + (H2
&gt; div x������) |
&gt; +C |
&gt;       |
&gt; +C | H3M = (H3 div x������)||((H3 mod x������) �� (x������+x��� �+x��� �+x������)) div x������
&gt;        |
&gt; +C | H3L = (H3 mod x������)||(((H3 mod x������) �� (x��� �+x��� �+x������)) mod x������) + (H3
&gt; div x������) |
&gt; +C |
&gt;       |
&gt; +C | H4M = (H3 div x������)||((H4 mod x������) �� (x������+x��� �+x��� �+x������)) div x������
&gt;        |
&gt; +C | H4L = (H3 mod x������)||(((H4 mod x������) �� (x��� �+x��� �+x������)) mod x������) + (H4
&gt; div x������) |
&gt; +C
&gt; *******************************************************************************
&gt; +
&gt; +define(`FUNC_ALIGN', `5')
&gt; +PROLOGUE(_nettle_gcm_init_key)
&gt; +    DATA_LOAD_VEC(POLY,.polynomial,r7)           C
&gt; 0xC2000000000000000000000000000001
&gt; +IF_LE(`
&gt; +    li             r8,0
&gt; +    lvsl           LE_MASK,0,r8                  C
&gt; 0x000102030405060708090A0B0C0D0E0F
&gt; +    vspltisb       LE_TEMP,0x07                  C
&gt; 0x07070707070707070707070707070707
&gt; +    vxor           LE_MASK,LE_MASK,LE_TEMP       C
&gt; 0x07060504030201000F0E0D0C0B0A0908
&gt; +')
&gt; +
&gt; +    C 'H' is assigned by gcm_set_key() to the middle element of the table
&gt; +    li             r10,8*TableElemAlign
&gt; +    lxvd2x         VSR(H),r10,TABLE              C load 'H'
&gt; +    C byte-reverse of each doubleword permuting on little-endian mode
&gt; +IF_LE(`
&gt; +    vperm          H,H,H,LE_MASK
&gt; +')
&gt; +
&gt; +    C --- calculate H = H &lt;&lt; 1 mod P(X), P(X) = (x � ����+x � ����+x � ����+x � � �+1)
&gt; ---
&gt; +
&gt; +    vupkhsb        EMSB,H                        C extend most
&gt; significant bit to first byte
&gt; +    vspltisb       B1,1                          C
&gt; 0x01010101010101010101010101010101
&gt; +    vspltb         EMSB,EMSB,0                   C first byte
&gt; quadword-extend
&gt; +    vsl            H,H,B1                        C H = H &lt;&lt; 1
&gt; +    vand           EMSB,EMSB,POLY                C EMSB &amp;=
&gt; 0xC2000000000000000000000000000001
&gt; +    vxor           ZERO,ZERO,ZERO                C
&gt; 0x00000000000000000000000000000000
&gt; +    vxor           H,H,EMSB                      C H ^= EMSB
&gt; +
&gt; +    C --- calculate H^2 = H*H ---
&gt; +
&gt; +    xxmrghd        VSR(POLY_L),VSR(ZERO),VSR(POLY) C
&gt; 0x0000000000000000C200000000000000
&gt; +
&gt; +    C --- Hp = (H mod x������) / x������ mod P(X) ---
&gt; +    C --- Hp = (H mod x������) �� (x������+x��� �+x��� �+x������) mod P(X), deg(Hp) ��� 127 ---
&gt; +    C --- Hp = (H mod x������) �� (x������+x��� �+x��� �+x������) ---
&gt; +    vpmsumd        Hp,H,POLY_L                   C Hp = (H mod x������) ��
&gt; (x��� �+x��� �+x������)
&gt; +    xxmrgld        VSR(Hl),VSR(H),VSR(ZERO)      C Hl = (H mod x������) �� x������
&gt; +    xxswapd        VSR(Hm),VSR(H)
&gt; +    vxor           Hl,Hl,Hp                      C Hl = Hl + Hp
&gt; +    vxor           Hm,Hm,Hp                      C Hm = Hm + Hp
&gt; +    xxmrghd        VSR(H1M),VSR(H),VSR(Hl)       C H1M = (H div x������)||(Hl
&gt; div x������)
&gt; +    xxmrgld        VSR(H1L),VSR(H),VSR(Hm)       C H1L = (H mod x������)||(Hl
&gt; mod x������)
&gt; +
&gt; +    vpmsumd        F,H1L,H                       C F = (H1Lh �� Hh) +
&gt; (H1Ll �� Hl)
&gt; +    vpmsumd        R,H1M,H                       C R = (H1Mh �� Hh) +
&gt; (H1Ml �� Hl)
&gt; +
&gt; +    C --- rduction ---
&gt; +    vpmsumd        T,F,POLY_L                    C T = (F mod x������) ��
&gt; (x��� �+x��� �+x������)
&gt; +    xxswapd        VSR(H2),VSR(F)
&gt; +    vxor           R,R,T                         C R = R + T
&gt; +    vxor           H2,R,H2
&gt; +
&gt; +    xxmrgld        VSR(Hl),VSR(H2),VSR(ZERO)
&gt; +    xxswapd        VSR(Hm),VSR(H2)
&gt; +    vpmsumd        Hp,H2,POLY_L
&gt; +    vxor           Hl,Hl,Hp
&gt; +    vxor           Hm,Hm,Hp
&gt; +    xxmrghd        VSR(H2M),VSR(H2),VSR(Hl)
&gt; +    xxmrgld        VSR(H2L),VSR(H2),VSR(Hm)
&gt; +
&gt; +    C store H1M, H1L, H2M, H2L
&gt; +    li             r8,1*TableElemAlign
&gt; +    li             r9,2*TableElemAlign
&gt; +    li             r10,3*TableElemAlign
&gt; +    stxvd2x        VSR(H1M),0,TABLE
&gt; +    stxvd2x        VSR(H1L),r8,TABLE
&gt; +    stxvd2x        VSR(H2M),r9,TABLE
&gt; +    stxvd2x        VSR(H2L),r10,TABLE
&gt; +
&gt; +    C --- calculate H^3 = H^1*H^2, H^4 = H^2*H^2 ---
&gt; +
&gt; +    vpmsumd        F,H1L,H2
&gt; +    vpmsumd        F2,H2L,H2
&gt; +    vpmsumd        R,H1M,H2
&gt; +    vpmsumd        R2,H2M,H2
&gt; +
&gt; +    vpmsumd        T,F,POLY_L
&gt; +    vpmsumd        T2,F2,POLY_L
&gt; +    xxswapd        VSR(H3),VSR(F)
&gt; +    xxswapd        VSR(H4),VSR(F2)
&gt; +    vxor           R,R,T
&gt; +    vxor           R2,R2,T2
&gt; +    vxor           H3,R,H3
&gt; +    vxor           H4,R2,H4
&gt; +
&gt; +    xxmrgld        VSR(Hl),VSR(H3),VSR(ZERO)
&gt; +    xxmrgld        VSR(Hl2),VSR(H4),VSR(ZERO)
&gt; +    xxswapd        VSR(Hm),VSR(H3)
&gt; +    xxswapd        VSR(Hm2),VSR(H4)
&gt; +    vpmsumd        Hp,H3,POLY_L
&gt; +    vpmsumd        Hp2,H4,POLY_L
&gt; +    vxor           Hl,Hl,Hp
&gt; +    vxor           Hl2,Hl2,Hp2
&gt; +    vxor           Hm,Hm,Hp
&gt; +    vxor           Hm2,Hm2,Hp2
&gt; +    xxmrghd        VSR(H1M),VSR(H3),VSR(Hl)
&gt; +    xxmrghd        VSR(H2M),VSR(H4),VSR(Hl2)
&gt; +    xxmrgld        VSR(H1L),VSR(H3),VSR(Hm)
&gt; +    xxmrgld        VSR(H2L),VSR(H4),VSR(Hm2)
&gt; +
&gt; +    C store H3M, H3L, H4M, H4L
&gt; +    li             r7,4*TableElemAlign
&gt; +    li             r8,5*TableElemAlign
&gt; +    li             r9,6*TableElemAlign
&gt; +    li             r10,7*TableElemAlign
&gt; +    stxvd2x        VSR(H1M),r7,TABLE
&gt; +    stxvd2x        VSR(H1L),r8,TABLE
&gt; +    stxvd2x        VSR(H2M),r9,TABLE
&gt; +    stxvd2x        VSR(H2L),r10,TABLE
&gt; +
&gt; +    blr
&gt; +EPILOGUE(_nettle_gcm_init_key)
&gt; +
&gt; +define(`TABLE', `r3')
&gt; +define(`X', `r4')
&gt; +define(`LENGTH', `r5')
&gt; +define(`DATA', `r6')
&gt; +
&gt; +define(`ZERO', `v16')
&gt; +define(`POLY', `v17')
&gt; +define(`POLY_L', `v0')
&gt; +
&gt; +define(`D', `v1')
&gt; +define(`C0', `v2')
&gt; +define(`C1', `v3')
&gt; +define(`C2', `v4')
&gt; +define(`C3', `v5')
&gt; +define(`H1M', `v6')
&gt; +define(`H1L', `v7')
&gt; +define(`H2M', `v8')
&gt; +define(`H2L', `v9')
&gt; +define(`H3M', `v10')
&gt; +define(`H3L', `v11')
&gt; +define(`H4M', `v12')
&gt; +define(`H4L', `v13')
&gt; +define(`R', `v14')
&gt; +define(`F', `v15')
&gt; +define(`R2', `v16')
&gt; +define(`F2', `v17')
&gt; +define(`R3', `v18')
&gt; +define(`F3', `v20')
&gt; +define(`R4', `v21')
&gt; +define(`F4', `v22')
&gt; +define(`T', `v23')
&gt; +
&gt; +define(`LE_TEMP', `v18')
&gt; +define(`LE_MASK', `v19')
&gt; +
&gt; +    C void gcm_hash (const struct gcm_key *key, union gcm_block *x,
&gt; +    C                size_t length, const uint8_t *data)
&gt; +
&gt; +define(`FUNC_ALIGN', `5')
&gt; +PROLOGUE(_nettle_gcm_hash)
&gt; +    DATA_LOAD_VEC(POLY,.polynomial,r7)
&gt; +IF_LE(`
&gt; +    li             r8,0
&gt; +    lvsl           LE_MASK,0,r8
&gt; +    vspltisb       LE_TEMP,0x07
&gt; +    vxor           LE_MASK,LE_MASK,LE_TEMP
&gt; +')
&gt; +    vxor           ZERO,ZERO,ZERO
&gt; +    xxmrghd        VSR(POLY_L),VSR(ZERO),VSR(POLY)
&gt; +
&gt; +    lxvd2x         VSR(D),0,X                    C load 'X' pointer
&gt; +    C byte-reverse of each doubleword permuting on little-endian mode
&gt; +IF_LE(`
&gt; +    vperm          D,D,D,LE_MASK
&gt; +')
&gt; +
&gt; +    C --- process 4 blocks '128-bit each' per one loop ---
&gt; +
&gt; +    srdi           r7,LENGTH,6                   C 4-blocks loop count
&gt; 'LENGTH / (4 * 16)'
&gt; +    cmpldi         r7,0
&gt; +    beq            L2x
&gt; +
&gt; +    mtctr          r7                            C assign counter
&gt; register to loop count
&gt; +
&gt; +    C store non-volatile vector registers
&gt; +    addi           r8,SP,-64
&gt; +    stvx           20,0,r8
&gt; +    addi           r8,r8,16
&gt; +    stvx           21,0,r8
&gt; +    addi           r8,r8,16
&gt; +    stvx           22,0,r8
&gt; +    addi           r8,r8,16
&gt; +    stvx           23,0,r8
&gt; +
&gt; +    C load table elements
&gt; +    li             r8,1*TableElemAlign
&gt; +    li             r9,2*TableElemAlign
&gt; +    li             r10,3*TableElemAlign
&gt; +    lxvd2x         VSR(H1M),0,TABLE
&gt; +    lxvd2x         VSR(H1L),r8,TABLE
&gt; +    lxvd2x         VSR(H2M),r9,TABLE
&gt; +    lxvd2x         VSR(H2L),r10,TABLE
&gt; +    li             r7,4*TableElemAlign
&gt; +    li             r8,5*TableElemAlign
&gt; +    li             r9,6*TableElemAlign
&gt; +    li             r10,7*TableElemAlign
&gt; +    lxvd2x         VSR(H3M),r7,TABLE
&gt; +    lxvd2x         VSR(H3L),r8,TABLE
&gt; +    lxvd2x         VSR(H4M),r9,TABLE
&gt; +    lxvd2x         VSR(H4L),r10,TABLE
&gt; +
&gt; +    li             r8,0x10
&gt; +    li             r9,0x20
&gt; +    li             r10,0x30
&gt; +.align 5
&gt; +L4x_loop:
&gt; +    C input loading
&gt; +    lxvd2x         VSR(C0),0,DATA                C load C0
&gt; +    lxvd2x         VSR(C1),r8,DATA               C load C1
&gt; +    lxvd2x         VSR(C2),r9,DATA               C load C2
&gt; +    lxvd2x         VSR(C3),r10,DATA              C load C3
&gt; +
&gt; +IF_LE(`
&gt; +    vperm          C0,C0,C0,LE_MASK
&gt; +    vperm          C1,C1,C1,LE_MASK
&gt; +    vperm          C2,C2,C2,LE_MASK
&gt; +    vperm          C3,C3,C3,LE_MASK
&gt; +')
&gt; +
&gt; +    C previous digest combining
&gt; +    vxor           C0,C0,D
&gt; +
&gt; +    C polynomial multiplication
&gt; +    vpmsumd        F2,H3L,C1
&gt; +    vpmsumd        R2,H3M,C1
&gt; +    vpmsumd        F3,H2L,C2
&gt; +    vpmsumd        R3,H2M,C2
&gt; +    vpmsumd        F4,H1L,C3
&gt; +    vpmsumd        R4,H1M,C3
&gt; +    vpmsumd        F,H4L,C0
&gt; +    vpmsumd        R,H4M,C0
&gt; +
&gt; +    C deferred recombination of partial products
&gt; +    vxor           F3,F3,F4
&gt; +    vxor           R3,R3,R4
&gt; +    vxor           F,F,F2
&gt; +    vxor           R,R,R2
&gt; +    vxor           F,F,F3
&gt; +    vxor           R,R,R3
&gt; +
&gt; +    C reduction
&gt; +    vpmsumd        T,F,POLY_L
&gt; +    xxswapd        VSR(D),VSR(F)
&gt; +    vxor           R,R,T
&gt; +    vxor           D,R,D
&gt; +
&gt; +    addi           DATA,DATA,0x40
&gt; +    bdnz           L4x_loop
&gt; +
&gt; +    C restore non-volatile vector registers
&gt; +    addi           r8,SP,-64
&gt; +    lvx            20,0,r8
&gt; +    addi           r8,r8,16
&gt; +    lvx            21,0,r8
&gt; +    addi           r8,r8,16
&gt; +    lvx            22,0,r8
&gt; +    addi           r8,r8,16
&gt; +    lvx            23,0,r8
&gt; +
&gt; +    clrldi         LENGTH,LENGTH,58              C 'set the high-order 58
&gt; bits to zeros'
&gt; +L2x:
&gt; +    C --- process 2 blocks ---
&gt; +
&gt; +    srdi           r7,LENGTH,5                   C 'LENGTH / (2 * 16)'
&gt; +    cmpldi         r7,0
&gt; +    beq            L1x
&gt; +
&gt; +    C load table elements
&gt; +    li             r8,1*TableElemAlign
&gt; +    li             r9,2*TableElemAlign
&gt; +    li             r10,3*TableElemAlign
&gt; +    lxvd2x         VSR(H1M),0,TABLE
&gt; +    lxvd2x         VSR(H1L),r8,TABLE
&gt; +    lxvd2x         VSR(H2M),r9,TABLE
&gt; +    lxvd2x         VSR(H2L),r10,TABLE
&gt; +
&gt; +    C input loading
&gt; +    li             r10,0x10
&gt; +    lxvd2x         VSR(C0),0,DATA                C load C0
&gt; +    lxvd2x         VSR(C1),r10,DATA              C load C1
&gt; +
&gt; +IF_LE(`
&gt; +    vperm          C0,C0,C0,LE_MASK
&gt; +    vperm          C1,C1,C1,LE_MASK
&gt; +')
&gt; +
&gt; +    C previous digest combining
&gt; +    vxor           C0,C0,D
&gt; +
&gt; +    C polynomial multiplication
&gt; +    vpmsumd        F2,H1L,C1
&gt; +    vpmsumd        R2,H1M,C1
&gt; +    vpmsumd        F,H2L,C0
&gt; +    vpmsumd        R,H2M,C0
&gt; +
&gt; +    C deferred recombination of partial products
&gt; +    vxor           F,F,F2
&gt; +    vxor           R,R,R2
&gt; +
&gt; +    C reduction
&gt; +    vpmsumd        T,F,POLY_L
&gt; +    xxswapd        VSR(D),VSR(F)
&gt; +    vxor           R,R,T
&gt; +    vxor           D,R,D
&gt; +
&gt; +    addi           DATA,DATA,0x20
&gt; +    clrldi         LENGTH,LENGTH,59              C 'set the high-order 59
&gt; bits to zeros'
&gt; +L1x:
&gt; +    C --- process 1 block ---
&gt; +
&gt; +    srdi           r7,LENGTH,4                   C 'LENGTH / (1 * 16)'
&gt; +    cmpldi         r7,0
&gt; +    beq            Lmod
&gt; +
&gt; +    C load table elements
&gt; +    li             r8,1*TableElemAlign
&gt; +    lxvd2x         VSR(H1M),0,TABLE
&gt; +    lxvd2x         VSR(H1L),r8,TABLE
&gt; +
&gt; +    C input loading
&gt; +    lxvd2x         VSR(C0),0,DATA                C load C0
&gt; +
&gt; +IF_LE(`
&gt; +    vperm          C0,C0,C0,LE_MASK
&gt; +')
&gt; +
&gt; +    C previous digest combining
&gt; +    vxor           C0,C0,D
&gt; +
&gt; +    C polynomial multiplication
&gt; +    vpmsumd        F,H1L,C0
&gt; +    vpmsumd        R,H1M,C0
&gt; +
&gt; +    C reduction
&gt; +    vpmsumd        T,F,POLY_L
&gt; +    xxswapd        VSR(D),VSR(F)
&gt; +    vxor           R,R,T
&gt; +    vxor           D,R,D
&gt; +
&gt; +    addi           DATA,DATA,0x10
&gt; +    clrldi         LENGTH,LENGTH,60              C 'set the high-order 60
&gt; bits to zeros'
&gt; +Lmod:
&gt; +    C --- process the modulo bytes, padding the low-order bytes with
&gt; zeros ---
&gt; +
&gt; +    cmpldi         LENGTH,0
&gt; +    beq            Ldone
&gt; +
&gt; +    C load table elements
&gt; +    li             r8,1*TableElemAlign
&gt; +    lxvd2x         VSR(H1M),0,TABLE
&gt; +    lxvd2x         VSR(H1L),r8,TABLE
&gt; +
&gt; +    C push every modulo byte to the stack and load them with padding into
&gt; vector register
&gt; +    vxor           ZERO,ZERO,ZERO
&gt; +    addi           r8,SP,-16
&gt; +    stvx           ZERO,0,r8
&gt; +Lstb_loop:
&gt; +    subic.         LENGTH,LENGTH,1
&gt; +    lbzx           r7,LENGTH,DATA
&gt; +    stbx           r7,LENGTH,r8
&gt; +    bne            Lstb_loop
&gt; +    lxvd2x         VSR(C0),0,r8
&gt; +
&gt; +IF_LE(`
&gt; +    vperm          C0,C0,C0,LE_MASK
&gt; +')
&gt; +
&gt; +    C previous digest combining
&gt; +    vxor           C0,C0,D
&gt; +
&gt; +    C polynomial multiplication
&gt; +    vpmsumd        F,H1L,C0
&gt; +    vpmsumd        R,H1M,C0
&gt; +
&gt; +    C reduction
&gt; +    vpmsumd        T,F,POLY_L
&gt; +    xxswapd        VSR(D),VSR(F)
&gt; +    vxor           R,R,T
&gt; +    vxor           D,R,D
&gt; +
&gt; +Ldone:
&gt; +    C byte-reverse of each doubleword permuting on little-endian mode
&gt; +IF_LE(`
&gt; +    vperm          D,D,D,LE_MASK
&gt; +')
&gt; +    stxvd2x        VSR(D),0,X                    C store digest 'D'
&gt; +
&gt; +    blr
&gt; +EPILOGUE(_nettle_gcm_hash)
&gt; +
&gt; +.data
&gt; +    C 0xC2000000000000000000000000000001
&gt; +.polynomial:
&gt; +.align 4
&gt; +IF_BE(`
&gt; +.byte 0xC2
&gt; +.rept 14
&gt; +.byte 0x00
&gt; +.endr
&gt; +.byte 0x01
&gt; +',`
&gt; +.byte 0x01
&gt; +.rept 14
&gt; +.byte 0x00
&gt; +.endr
&gt; +.byte 0xC2
&gt; +')
&gt;
&gt; --
&gt; 2.17.1
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201114165438</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-11-14 16:54:38-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; +Lmod:
&gt; +    C --- process the modulo bytes, padding the low-order bytes with zeros
&gt; ---
&gt; +
&gt; +    cmpldi         LENGTH,0
&gt; +    beq            Ldone
&gt; +
&gt; +    C load table elements
&gt; +    li             r8,1*TableElemAlign
&gt; +    lxvd2x         VSR(H1M),0,TABLE
&gt; +    lxvd2x         VSR(H1L),r8,TABLE
&gt; +
&gt; +    C push every modulo byte to the stack and load them with padding into
&gt; vector register
&gt; +    vxor           ZERO,ZERO,ZERO
&gt; +    addi           r8,SP,-16
&gt; +    stvx           ZERO,0,r8
&gt; +Lstb_loop:
&gt; +    subic.         LENGTH,LENGTH,1
&gt; +    lbzx           r7,LENGTH,DATA
&gt; +    stbx           r7,LENGTH,r8
&gt; +    bne            Lstb_loop
&gt; +    lxvd2x         VSR(C0),0,r8

It's always a bit annoying to have to deal with leftovers like this
in the assembly code. Can we avoid having to store it to memory and read
back? I can see three other approaches:

1. Loop, reading a byte at a time, and shift into a target register. I
   guess we would need to assemble the bytes in a regular register, and
   then transfer the final value to a vector register. Is that
   expensive?

2. Round the address down to make it aligned, read an aligned word and,
   only if needed, the next word. And shift and mask to get the needed
   bytes. I think it is fine to read a few bytes outside of the input
   area, as long as the reads do *not* cross any word boundary (and
   hence a potential page boundary). We do things like this in some
   other places, but then for reading unaligned data in general, not
   just leftover parts.

3. Adapt the internal C/asm interface, so that the assembly routine only
   needs to handle complete blocks. It could provide a gcm_gf_mul, and
   let the C code handle partial blocks using memxor + gcm_gf_mul.

I would guess (1) or maybe (3) is the most reasonable. I don't think
performance is that important, since it looks like for each message,
this case can happen only for the last call to gcm_update and the last
call to gcm_encrypt/gcm_decrypt.

What about test coverage? It looks like we have test cases for sizes up
to 8 blocks, and for partial blocks, so I guess that should be fine?

Reards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201114181129</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-11-14 18:11:29-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

For the first approach I can think of this method:
lxvd2x      VSR(C0),0,DATA
IF_LE(`
vperm       C0,C0,C0,LE_MASK
')
slwi        LENGTH,LENGTH,4     (Shift left 4 bitls because vsro get
bit[121:124])
vspltisb    v10,-1
(0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF)
mtvrwz      v11,LENGTH             (LENGTH in bit[57:60])
xxspltd     VSR(v11),VSR(v11),0 (LENGTH in bit[121:124])
vsro        v10,v10,v11                  (Sift right by octet)
vnot        v10,v10
vand        C0,C0,v10

I recommend the third approach so we don't have to deal with the leftover
bytes in the upcoming implementations but the problem is that
gcm_init_key() initialize the table for the compatible gcm_hash() function,
that means we can't process the remaining bytes using gcm_gf_mul() of
gcm_gf_shift_8() because its table potentially has not been initialized, so
I'm thinking of keeping gcm_gf_mul() of the one that don't need table
(where GCM_TABLE_BITS == 0) and always process the remaining bytes with
this function.

The test coverage is fine, I can't think of any potential untested cases.

regards,
Mamone


On Sat, Nov 14, 2020 at 6:54 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt; +Lmod:
&gt; &gt; +    C --- process the modulo bytes, padding the low-order bytes with
&gt; zeros
&gt; &gt; ---
&gt; &gt; +
&gt; &gt; +    cmpldi         LENGTH,0
&gt; &gt; +    beq            Ldone
&gt; &gt; +
&gt; &gt; +    C load table elements
&gt; &gt; +    li             r8,1*TableElemAlign
&gt; &gt; +    lxvd2x         VSR(H1M),0,TABLE
&gt; &gt; +    lxvd2x         VSR(H1L),r8,TABLE
&gt; &gt; +
&gt; &gt; +    C push every modulo byte to the stack and load them with padding
&gt; into
&gt; &gt; vector register
&gt; &gt; +    vxor           ZERO,ZERO,ZERO
&gt; &gt; +    addi           r8,SP,-16
&gt; &gt; +    stvx           ZERO,0,r8
&gt; &gt; +Lstb_loop:
&gt; &gt; +    subic.         LENGTH,LENGTH,1
&gt; &gt; +    lbzx           r7,LENGTH,DATA
&gt; &gt; +    stbx           r7,LENGTH,r8
&gt; &gt; +    bne            Lstb_loop
&gt; &gt; +    lxvd2x         VSR(C0),0,r8
&gt;
&gt; It's always a bit annoying to have to deal with leftovers like this
&gt; in the assembly code. Can we avoid having to store it to memory and read
&gt; back? I can see three other approaches:
&gt;
&gt; 1. Loop, reading a byte at a time, and shift into a target register. I
&gt;    guess we would need to assemble the bytes in a regular register, and
&gt;    then transfer the final value to a vector register. Is that
&gt;    expensive?
&gt;
&gt; 2. Round the address down to make it aligned, read an aligned word and,
&gt;    only if needed, the next word. And shift and mask to get the needed
&gt;    bytes. I think it is fine to read a few bytes outside of the input
&gt;    area, as long as the reads do *not* cross any word boundary (and
&gt;    hence a potential page boundary). We do things like this in some
&gt;    other places, but then for reading unaligned data in general, not
&gt;    just leftover parts.
&gt;
&gt; 3. Adapt the internal C/asm interface, so that the assembly routine only
&gt;    needs to handle complete blocks. It could provide a gcm_gf_mul, and
&gt;    let the C code handle partial blocks using memxor + gcm_gf_mul.
&gt;
&gt; I would guess (1) or maybe (3) is the most reasonable. I don't think
&gt; performance is that important, since it looks like for each message,
&gt; this case can happen only for the last call to gcm_update and the last
&gt; call to gcm_encrypt/gcm_decrypt.
&gt;
&gt; What about test coverage? It looks like we have test cases for sizes up
&gt; to 8 blocks, and for partial blocks, so I guess that should be fine?
&gt;
&gt; Reards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201117211026</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-11-17 21:10:26-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

I replaced the method of using the stack to handle the leftovers with the
first approach, also I changed some vector registers in the defines because
I defined `LE_MASK' in a non-volatile register which is not
always preserved.

This patch is built on the top ppc-gcm branch.

regards,
Mamone

On Sat, Nov 14, 2020 at 8:11 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
wrote:

&gt; For the first approach I can think of this method:
&gt; lxvd2x      VSR(C0),0,DATA
&gt; IF_LE(`
&gt; vperm       C0,C0,C0,LE_MASK
&gt; ')
&gt; slwi        LENGTH,LENGTH,4     (Shift left 4 bitls because vsro get
&gt; bit[121:124])
&gt; vspltisb    v10,-1
&gt; (0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF)
&gt; mtvrwz      v11,LENGTH             (LENGTH in bit[57:60])
&gt; xxspltd     VSR(v11),VSR(v11),0 (LENGTH in bit[121:124])
&gt; vsro        v10,v10,v11                  (Sift right by octet)
&gt; vnot        v10,v10
&gt; vand        C0,C0,v10
&gt;
&gt; I recommend the third approach so we don't have to deal with the leftover
&gt; bytes in the upcoming implementations but the problem is that
&gt; gcm_init_key() initialize the table for the compatible gcm_hash() function,
&gt; that means we can't process the remaining bytes using gcm_gf_mul() of
&gt; gcm_gf_shift_8() because its table potentially has not been initialized, so
&gt; I'm thinking of keeping gcm_gf_mul() of the one that don't need table
&gt; (where GCM_TABLE_BITS == 0) and always process the remaining bytes with
&gt; this function.
&gt;
&gt; The test coverage is fine, I can't think of any potential untested cases.
&gt;
&gt; regards,
&gt; Mamone
&gt;
&gt;
&gt; On Sat, Nov 14, 2020 at 6:54 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt;&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;&gt;
&gt;&gt; &gt; +Lmod:
&gt;&gt; &gt; +    C --- process the modulo bytes, padding the low-order bytes with
&gt;&gt; zeros
&gt;&gt; &gt; ---
&gt;&gt; &gt; +
&gt;&gt; &gt; +    cmpldi         LENGTH,0
&gt;&gt; &gt; +    beq            Ldone
&gt;&gt; &gt; +
&gt;&gt; &gt; +    C load table elements
&gt;&gt; &gt; +    li             r8,1*TableElemAlign
&gt;&gt; &gt; +    lxvd2x         VSR(H1M),0,TABLE
&gt;&gt; &gt; +    lxvd2x         VSR(H1L),r8,TABLE
&gt;&gt; &gt; +
&gt;&gt; &gt; +    C push every modulo byte to the stack and load them with padding
&gt;&gt; into
&gt;&gt; &gt; vector register
&gt;&gt; &gt; +    vxor           ZERO,ZERO,ZERO
&gt;&gt; &gt; +    addi           r8,SP,-16
&gt;&gt; &gt; +    stvx           ZERO,0,r8
&gt;&gt; &gt; +Lstb_loop:
&gt;&gt; &gt; +    subic.         LENGTH,LENGTH,1
&gt;&gt; &gt; +    lbzx           r7,LENGTH,DATA
&gt;&gt; &gt; +    stbx           r7,LENGTH,r8
&gt;&gt; &gt; +    bne            Lstb_loop
&gt;&gt; &gt; +    lxvd2x         VSR(C0),0,r8
&gt;&gt;
&gt;&gt; It's always a bit annoying to have to deal with leftovers like this
&gt;&gt; in the assembly code. Can we avoid having to store it to memory and read
&gt;&gt; back? I can see three other approaches:
&gt;&gt;
&gt;&gt; 1. Loop, reading a byte at a time, and shift into a target register. I
&gt;&gt;    guess we would need to assemble the bytes in a regular register, and
&gt;&gt;    then transfer the final value to a vector register. Is that
&gt;&gt;    expensive?
&gt;&gt;
&gt;&gt; 2. Round the address down to make it aligned, read an aligned word and,
&gt;&gt;    only if needed, the next word. And shift and mask to get the needed
&gt;&gt;    bytes. I think it is fine to read a few bytes outside of the input
&gt;&gt;    area, as long as the reads do *not* cross any word boundary (and
&gt;&gt;    hence a potential page boundary). We do things like this in some
&gt;&gt;    other places, but then for reading unaligned data in general, not
&gt;&gt;    just leftover parts.
&gt;&gt;
&gt;&gt; 3. Adapt the internal C/asm interface, so that the assembly routine only
&gt;&gt;    needs to handle complete blocks. It could provide a gcm_gf_mul, and
&gt;&gt;    let the C code handle partial blocks using memxor + gcm_gf_mul.
&gt;&gt;
&gt;&gt; I would guess (1) or maybe (3) is the most reasonable. I don't think
&gt;&gt; performance is that important, since it looks like for each message,
&gt;&gt; this case can happen only for the last call to gcm_update and the last
&gt;&gt; call to gcm_encrypt/gcm_decrypt.
&gt;&gt;
&gt;&gt; What about test coverage? It looks like we have test cases for sizes up
&gt;&gt; to 8 blocks, and for partial blocks, so I guess that should be fine?
&gt;&gt;
&gt;&gt; Reards,
&gt;&gt; /Niels
&gt;&gt;
&gt;&gt; --
&gt;&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt;&gt; Internet email is subject to wholesale government surveillance.
&gt;&gt;
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201117232014</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-11-17 23:20:14-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

Another patch for register defines. I apologize for that.

regards,
Mamone

On Tue, Nov 17, 2020 at 11:10 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
wrote:

&gt; I replaced the method of using the stack to handle the leftovers with the
&gt; first approach, also I changed some vector registers in the defines because
&gt; I defined `LE_MASK' in a non-volatile register which is not
&gt; always preserved.
&gt;
&gt; This patch is built on the top ppc-gcm branch.
&gt;
&gt; regards,
&gt; Mamone
&gt;
&gt; On Sat, Nov 14, 2020 at 8:11 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
&gt; wrote:
&gt;
&gt;&gt; For the first approach I can think of this method:
&gt;&gt; lxvd2x      VSR(C0),0,DATA
&gt;&gt; IF_LE(`
&gt;&gt; vperm       C0,C0,C0,LE_MASK
&gt;&gt; ')
&gt;&gt; slwi        LENGTH,LENGTH,4     (Shift left 4 bitls because vsro get
&gt;&gt; bit[121:124])
&gt;&gt; vspltisb    v10,-1
&gt;&gt; (0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF)
&gt;&gt; mtvrwz      v11,LENGTH             (LENGTH in bit[57:60])
&gt;&gt; xxspltd     VSR(v11),VSR(v11),0 (LENGTH in bit[121:124])
&gt;&gt; vsro        v10,v10,v11                  (Sift right by octet)
&gt;&gt; vnot        v10,v10
&gt;&gt; vand        C0,C0,v10
&gt;&gt;
&gt;&gt; I recommend the third approach so we don't have to deal with the leftover
&gt;&gt; bytes in the upcoming implementations but the problem is that
&gt;&gt; gcm_init_key() initialize the table for the compatible gcm_hash() function,
&gt;&gt; that means we can't process the remaining bytes using gcm_gf_mul() of
&gt;&gt; gcm_gf_shift_8() because its table potentially has not been initialized, so
&gt;&gt; I'm thinking of keeping gcm_gf_mul() of the one that don't need table
&gt;&gt; (where GCM_TABLE_BITS == 0) and always process the remaining bytes with
&gt;&gt; this function.
&gt;&gt;
&gt;&gt; The test coverage is fine, I can't think of any potential untested cases.
&gt;&gt;
&gt;&gt; regards,
&gt;&gt; Mamone
&gt;&gt;
&gt;&gt;
&gt;&gt; On Sat, Nov 14, 2020 at 6:54 PM Niels Möller &lt;nisse@lysator.liu.se&gt;
&gt;&gt; wrote:
&gt;&gt;
&gt;&gt;&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;&gt;&gt;
&gt;&gt;&gt; &gt; +Lmod:
&gt;&gt;&gt; &gt; +    C --- process the modulo bytes, padding the low-order bytes with
&gt;&gt;&gt; zeros
&gt;&gt;&gt; &gt; ---
&gt;&gt;&gt; &gt; +
&gt;&gt;&gt; &gt; +    cmpldi         LENGTH,0
&gt;&gt;&gt; &gt; +    beq            Ldone
&gt;&gt;&gt; &gt; +
&gt;&gt;&gt; &gt; +    C load table elements
&gt;&gt;&gt; &gt; +    li             r8,1*TableElemAlign
&gt;&gt;&gt; &gt; +    lxvd2x         VSR(H1M),0,TABLE
&gt;&gt;&gt; &gt; +    lxvd2x         VSR(H1L),r8,TABLE
&gt;&gt;&gt; &gt; +
&gt;&gt;&gt; &gt; +    C push every modulo byte to the stack and load them with padding
&gt;&gt;&gt; into
&gt;&gt;&gt; &gt; vector register
&gt;&gt;&gt; &gt; +    vxor           ZERO,ZERO,ZERO
&gt;&gt;&gt; &gt; +    addi           r8,SP,-16
&gt;&gt;&gt; &gt; +    stvx           ZERO,0,r8
&gt;&gt;&gt; &gt; +Lstb_loop:
&gt;&gt;&gt; &gt; +    subic.         LENGTH,LENGTH,1
&gt;&gt;&gt; &gt; +    lbzx           r7,LENGTH,DATA
&gt;&gt;&gt; &gt; +    stbx           r7,LENGTH,r8
&gt;&gt;&gt; &gt; +    bne            Lstb_loop
&gt;&gt;&gt; &gt; +    lxvd2x         VSR(C0),0,r8
&gt;&gt;&gt;
&gt;&gt;&gt; It's always a bit annoying to have to deal with leftovers like this
&gt;&gt;&gt; in the assembly code. Can we avoid having to store it to memory and read
&gt;&gt;&gt; back? I can see three other approaches:
&gt;&gt;&gt;
&gt;&gt;&gt; 1. Loop, reading a byte at a time, and shift into a target register. I
&gt;&gt;&gt;    guess we would need to assemble the bytes in a regular register, and
&gt;&gt;&gt;    then transfer the final value to a vector register. Is that
&gt;&gt;&gt;    expensive?
&gt;&gt;&gt;
&gt;&gt;&gt; 2. Round the address down to make it aligned, read an aligned word and,
&gt;&gt;&gt;    only if needed, the next word. And shift and mask to get the needed
&gt;&gt;&gt;    bytes. I think it is fine to read a few bytes outside of the input
&gt;&gt;&gt;    area, as long as the reads do *not* cross any word boundary (and
&gt;&gt;&gt;    hence a potential page boundary). We do things like this in some
&gt;&gt;&gt;    other places, but then for reading unaligned data in general, not
&gt;&gt;&gt;    just leftover parts.
&gt;&gt;&gt;
&gt;&gt;&gt; 3. Adapt the internal C/asm interface, so that the assembly routine only
&gt;&gt;&gt;    needs to handle complete blocks. It could provide a gcm_gf_mul, and
&gt;&gt;&gt;    let the C code handle partial blocks using memxor + gcm_gf_mul.
&gt;&gt;&gt;
&gt;&gt;&gt; I would guess (1) or maybe (3) is the most reasonable. I don't think
&gt;&gt;&gt; performance is that important, since it looks like for each message,
&gt;&gt;&gt; this case can happen only for the last call to gcm_update and the last
&gt;&gt;&gt; call to gcm_encrypt/gcm_decrypt.
&gt;&gt;&gt;
&gt;&gt;&gt; What about test coverage? It looks like we have test cases for sizes up
&gt;&gt;&gt; to 8 blocks, and for partial blocks, so I guess that should be fine?
&gt;&gt;&gt;
&gt;&gt;&gt; Reards,
&gt;&gt;&gt; /Niels
&gt;&gt;&gt;
&gt;&gt;&gt; --
&gt;&gt;&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt;&gt;&gt; Internet email is subject to wholesale government surveillance.
&gt;&gt;&gt;
&gt;&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201119110121</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-11-19 11:01:21-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

The result of benchmark this implementation on POWER9.

&gt; *****************************************************************************************************************************|
&gt; 
&gt; vs. lookup table based C implementation       | vs. hardware acceleration
using Intel optimization documents                |
&gt; -----------------------------------------------|-----------------------------------------------------------------------------|
&gt; 
&gt; 2288% increase in performance                 | 44.48% increase in
performance                                              |
&gt; *****************************************************************************************************************************|
&gt; 

regards,
Mamone

On Wed, Nov 11, 2020 at 6:24 PM George Wilson &lt;gcwilson@linux.ibm.com&gt;
wrote:

&gt; On Wed, Nov 11, 2020 at 02:17:41AM +0200, Maamoun TK wrote:
&gt; &gt; I think I mislabeled the percentage of performance comparison, the new
&gt; &gt; method achieved 27.7% reduction in time on POWER8 that corresponds to
&gt; 37.9%
&gt; &gt; increase in performance.
&gt; 
&gt; Hi Maamoun,
&gt; 
&gt; Many thanks to you and Niels.  We plan to test this on POWER9.
&gt; 
&gt; &gt; 
&gt; &gt; On Tue, Nov 10, 2020 at 6:25 AM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
&gt; &gt; wrote:
&gt; &gt; 
&gt; &gt; &gt; This implementation takes advantage of research made by Niels M��ller to
&gt; &gt; &gt; optimize GCM on PowerPC, this optimization yields a +27.7% performance
&gt; &gt; &gt; boost on POWER8 over the previous implementation that was based on
&gt; intel
&gt; &gt; &gt; documents. The performance comparison is made by processing 4 blocks
&gt; per
&gt; &gt; &gt; loop without any further optimizations.
&gt; &gt; &gt; I made some documentations between the lines but I suggest writing a
&gt; &gt; &gt; document similar to the intel ones that go into more details and
&gt; clarify
&gt; &gt; &gt; the preference of this method. I'm also curious if this method can also
&gt; &gt; &gt; make a difference in other architectures like ARM, I'm planning to try
&gt; it
&gt; &gt; &gt; out for ARM to figure that out.
&gt; &gt; &gt; ---
&gt; &gt; &gt; configure.ac              |   6 +-
&gt; &gt; &gt; gcm.c                     |  49 +++--
&gt; &gt; &gt; powerpc64/p8/gcm-hash.asm | 502
&gt; &gt; &gt; ++++++++++++++++++++++++++++++++++++++++++++++
&gt; &gt; &gt; 3 files changed, 542 insertions(+), 15 deletions(-)
&gt; &gt; &gt; create mode 100644 powerpc64/p8/gcm-hash.asm
&gt; &gt; &gt; 
&gt; &gt; &gt; diff --git a/configure.ac b/configure.ac
&gt; &gt; &gt; index 2a47f940..20f7cf74 100644
&gt; &gt; &gt; --- a/configure.ac
&gt; &gt; &gt; +++ b/configure.ac
&gt; &gt; &gt; @@ -497,7 +497,7 @@ asm_replace_list="aes-encrypt-internal.asm
&gt; &gt; &gt; aes-decrypt-internal.asm \
&gt; &gt; &gt; sha3-permute.asm umac-nh.asm umac-nh-n.asm machine.m4"
&gt; &gt; &gt; 
&gt; &gt; &gt; # Assembler files which generate additional object files if they are
&gt; used.
&gt; &gt; &gt; -asm_nettle_optional_list="gcm-hash8.asm cpuid.asm \
&gt; &gt; &gt; +asm_nettle_optional_list="gcm-hash.asm gcm-hash8.asm cpuid.asm \
&gt; &gt; &gt; aes-encrypt-internal-2.asm aes-decrypt-internal-2.asm memxor-2.asm \
&gt; &gt; &gt; chacha-3core.asm chacha-core-internal-2.asm salsa20-2core.asm \
&gt; &gt; &gt; salsa20-core-internal-2.asm sha1-compress-2.asm
&gt; sha256-compress-2.asm \
&gt; &gt; &gt; @@ -621,9 +621,9 @@ AH_VERBATIM([HAVE_NATIVE],
&gt; &gt; &gt; #undef HAVE_NATIVE_ecc_secp384r1_redc
&gt; &gt; &gt; #undef HAVE_NATIVE_ecc_secp521r1_modp
&gt; &gt; &gt; #undef HAVE_NATIVE_ecc_secp521r1_redc
&gt; &gt; &gt; -#undef HAVE_NATIVE_gcm_init_key8
&gt; &gt; &gt; +#undef HAVE_NATIVE_gcm_init_key
&gt; &gt; &gt; +#undef HAVE_NATIVE_gcm_hash
&gt; &gt; &gt; #undef HAVE_NATIVE_gcm_hash8
&gt; &gt; &gt; -#undef HAVE_NATIVE_gcm_fill
&gt; &gt; &gt; #undef HAVE_NATIVE_salsa20_core
&gt; &gt; &gt; #undef HAVE_NATIVE_salsa20_2core
&gt; &gt; &gt; #undef HAVE_NATIVE_fat_salsa20_2core
&gt; &gt; &gt; diff --git a/gcm.c b/gcm.c
&gt; &gt; &gt; index 48b3e75a..81981c1c 100644
&gt; &gt; &gt; --- a/gcm.c
&gt; &gt; &gt; +++ b/gcm.c
&gt; &gt; &gt; @@ -140,6 +140,19 @@ gcm_gf_mul (union nettle_block16 *x, const union
&gt; &gt; &gt; nettle_block16 *table)
&gt; &gt; &gt; memcpy (x-&gt;b, Z.b, sizeof(Z));
&gt; &gt; &gt; }
&gt; &gt; &gt; # elif GCM_TABLE_BITS == 8
&gt; &gt; &gt; +#  if HAVE_NATIVE_gcm_init_key
&gt; &gt; &gt; +
&gt; &gt; &gt; +#define gcm_init_key _nettle_gcm_init_key
&gt; &gt; &gt; +void
&gt; &gt; &gt; +_nettle_gcm_init_key (union nettle_block16 *table);
&gt; &gt; &gt; +#  endif /* HAVE_NATIVE_gcm_init_key */
&gt; &gt; &gt; +#  if HAVE_NATIVE_gcm_hash
&gt; &gt; &gt; +
&gt; &gt; &gt; +#define gcm_hash _nettle_gcm_hash
&gt; &gt; &gt; +void
&gt; &gt; &gt; +_nettle_gcm_hash (const struct gcm_key *key, union nettle_block16 *x,
&gt; &gt; &gt; +   size_t length, const uint8_t *data);
&gt; &gt; &gt; +#  endif /* HAVE_NATIVE_gcm_hash */
&gt; &gt; &gt; #  if HAVE_NATIVE_gcm_hash8
&gt; &gt; &gt; 
&gt; &gt; &gt; #define gcm_hash _nettle_gcm_hash8
&gt; &gt; &gt; @@ -228,6 +241,29 @@ gcm_gf_mul (union nettle_block16 *x, const union
&gt; &gt; &gt; nettle_block16 *table)
&gt; &gt; &gt; /* Increment the rightmost 32 bits. */
&gt; &gt; &gt; #define INC32(block) INCREMENT(4, (block.b) + GCM_BLOCK_SIZE - 4)
&gt; &gt; &gt; 
&gt; &gt; &gt; +#ifndef gcm_init_key
&gt; &gt; &gt; +static void
&gt; &gt; &gt; +gcm_init_key(union nettle_block16 *table)
&gt; &gt; &gt; +{
&gt; &gt; &gt; +#if GCM_TABLE_BITS
&gt; &gt; &gt; +  /* Middle element if GCM_TABLE_BITS &gt; 0, otherwise the first
&gt; &gt; &gt; +     element */
&gt; &gt; &gt; +  unsigned i = (1&lt;&lt;GCM_TABLE_BITS)/2;
&gt; &gt; &gt; +
&gt; &gt; &gt; +  /* Algorithm 3 from the gcm paper. First do powers of two, then do
&gt; &gt; &gt; +     the rest by adding. */
&gt; &gt; &gt; +  while (i /= 2)
&gt; &gt; &gt; +    block16_mulx_ghash(&amp;table[i], &amp;table[2*i]);
&gt; &gt; &gt; +  for (i = 2; i &lt; 1&lt;&lt;GCM_TABLE_BITS; i *= 2)
&gt; &gt; &gt; +    {
&gt; &gt; &gt; +      unsigned j;
&gt; &gt; &gt; +      for (j = 1; j &lt; i; j++)
&gt; &gt; &gt; + block16_xor3(&amp;table[i+j], &amp;table[i], &amp;table[j]);
&gt; &gt; &gt; +    }
&gt; &gt; &gt; +#endif
&gt; &gt; &gt; +}
&gt; &gt; &gt; +#endif /* !gcm_init_key */
&gt; &gt; &gt; +
&gt; &gt; &gt; /* Initialization of GCM.
&gt; &gt; &gt; * @ctx: The context of GCM
&gt; &gt; &gt; * @cipher: The context of the underlying block cipher
&gt; &gt; &gt; @@ -245,18 +281,7 @@ gcm_set_key(struct gcm_key *key,
&gt; &gt; &gt; memset(key-&gt;h[0].b, 0, GCM_BLOCK_SIZE);
&gt; &gt; &gt; f (cipher, GCM_BLOCK_SIZE, key-&gt;h[i].b, key-&gt;h[0].b);
&gt; &gt; &gt; 
&gt; &gt; &gt; -#if GCM_TABLE_BITS
&gt; &gt; &gt; -  /* Algorithm 3 from the gcm paper. First do powers of two, then do
&gt; &gt; &gt; -     the rest by adding. */
&gt; &gt; &gt; -  while (i /= 2)
&gt; &gt; &gt; -    block16_mulx_ghash(&amp;key-&gt;h[i], &amp;key-&gt;h[2*i]);
&gt; &gt; &gt; -  for (i = 2; i &lt; 1&lt;&lt;GCM_TABLE_BITS; i *= 2)
&gt; &gt; &gt; -    {
&gt; &gt; &gt; -      unsigned j;
&gt; &gt; &gt; -      for (j = 1; j &lt; i; j++)
&gt; &gt; &gt; - block16_xor3(&amp;key-&gt;h[i+j], &amp;key-&gt;h[i],&amp;key-&gt;h[j]);
&gt; &gt; &gt; -    }
&gt; &gt; &gt; -#endif
&gt; &gt; &gt; +  gcm_init_key(key-&gt;h);
&gt; &gt; &gt; }
&gt; &gt; &gt; 
&gt; &gt; &gt; #ifndef gcm_hash
&gt; &gt; &gt; diff --git a/powerpc64/p8/gcm-hash.asm b/powerpc64/p8/gcm-hash.asm
&gt; &gt; &gt; new file mode 100644
&gt; &gt; &gt; index 00000000..e79fbdc2
&gt; &gt; &gt; --- /dev/null
&gt; &gt; &gt; +++ b/powerpc64/p8/gcm-hash.asm
&gt; &gt; &gt; @@ -0,0 +1,502 @@
&gt; &gt; &gt; +C powerpc64/p8/gcm-hash.asm
&gt; &gt; &gt; +
&gt; &gt; &gt; +ifelse(`
&gt; &gt; &gt; +   Copyright (C) 2020 Niels M��ller and Mamone Tarsha
&gt; &gt; &gt; +   This file is part of GNU Nettle.
&gt; &gt; &gt; +
&gt; &gt; &gt; +   GNU Nettle is free software: you can redistribute it and/or
&gt; &gt; &gt; +   modify it under the terms of either:
&gt; &gt; &gt; +
&gt; &gt; &gt; +     * the GNU Lesser General Public License as published by the Free
&gt; &gt; &gt; +       Software Foundation; either version 3 of the License, or (at
&gt; your
&gt; &gt; &gt; +       option) any later version.
&gt; &gt; &gt; +
&gt; &gt; &gt; +   or
&gt; &gt; &gt; +
&gt; &gt; &gt; +     * the GNU General Public License as published by the Free
&gt; &gt; &gt; +       Software Foundation; either version 2 of the License, or (at
&gt; your
&gt; &gt; &gt; +       option) any later version.
&gt; &gt; &gt; +
&gt; &gt; &gt; +   or both in parallel, as here.
&gt; &gt; &gt; +
&gt; &gt; &gt; +   GNU Nettle is distributed in the hope that it will be useful,
&gt; &gt; &gt; +   but WITHOUT ANY WARRANTY; without even the implied warranty of
&gt; &gt; &gt; +   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
&gt; &gt; &gt; +   General Public License for more details.
&gt; &gt; &gt; +
&gt; &gt; &gt; +   You should have received copies of the GNU General Public License
&gt; and
&gt; &gt; &gt; +   the GNU Lesser General Public License along with this program.  If
&gt; &gt; &gt; +   not, see http://www.gnu.org/licenses/.
&gt; &gt; &gt; +')
&gt; &gt; &gt; +
&gt; &gt; &gt; +C Alignment of gcm_key table elements, which is declared in gcm.h
&gt; &gt; &gt; +define(`TableElemAlign', `0x100')
&gt; &gt; &gt; +
&gt; &gt; &gt; +C Register usage:
&gt; &gt; &gt; +
&gt; &gt; &gt; +define(`SP', `r1')
&gt; &gt; &gt; +define(`TOCP', `r2')
&gt; &gt; &gt; +
&gt; &gt; &gt; +define(`TABLE', `r3')
&gt; &gt; &gt; +
&gt; &gt; &gt; +define(`ZERO', `v0')
&gt; &gt; &gt; +define(`B1', `v1')
&gt; &gt; &gt; +define(`EMSB', `v16')
&gt; &gt; &gt; +define(`POLY', `v17')
&gt; &gt; &gt; +define(`POLY_L', `v1')
&gt; &gt; &gt; +
&gt; &gt; &gt; +define(`H', `v2')
&gt; &gt; &gt; +define(`H2', `v3')
&gt; &gt; &gt; +define(`H3', `v4')
&gt; &gt; &gt; +define(`H4', `v5')
&gt; &gt; &gt; +define(`H1M', `v6')
&gt; &gt; &gt; +define(`H1L', `v7')
&gt; &gt; &gt; +define(`H2M', `v8')
&gt; &gt; &gt; +define(`H2L', `v9')
&gt; &gt; &gt; +define(`Hl', `v10')
&gt; &gt; &gt; +define(`Hm', `v11')
&gt; &gt; &gt; +define(`Hp', `v12')
&gt; &gt; &gt; +define(`Hl2', `v13')
&gt; &gt; &gt; +define(`Hm2', `v14')
&gt; &gt; &gt; +define(`Hp2', `v15')
&gt; &gt; &gt; +define(`R', `v13')
&gt; &gt; &gt; +define(`F', `v14')
&gt; &gt; &gt; +define(`T', `v15')
&gt; &gt; &gt; +define(`R2', `v16')
&gt; &gt; &gt; +define(`F2', `v17')
&gt; &gt; &gt; +define(`T2', `v18')
&gt; &gt; &gt; +
&gt; &gt; &gt; +define(`LE_TEMP', `v18')
&gt; &gt; &gt; +define(`LE_MASK', `v19')
&gt; &gt; &gt; +
&gt; &gt; &gt; +.file "gcm-hash.asm"
&gt; &gt; &gt; +
&gt; &gt; &gt; +.text
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C void gcm_init_key (union gcm_block *table)
&gt; &gt; &gt; +
&gt; &gt; &gt; +C This function populates the gcm table as the following layout
&gt; &gt; &gt; +C
&gt; &gt; &gt; 
&gt; *******************************************************************************
&gt; &gt; &gt; +C | H1M = (H1 div x������)||((H1 mod x������) �� (x������+x��� �+x��� \
&gt; &gt; &gt; �+x������)) div x������ |
&gt; &gt; &gt; +C | H1L = (H1 mod x������)||(((H1 mod x������) �� (x��� �+x��� �+x������)) mod \
&gt; &gt; &gt; x������) + (H1 div x������) |
&gt; &gt; &gt; +C |
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; +C | H2M = (H2 div x������)||((H2 mod x������) �� (x������+x��� �+x��� \
&gt; &gt; &gt; �+x������)) div x������ |
&gt; &gt; &gt; +C | H2L = (H2 mod x������)||(((H2 mod x������) �� (x��� �+x��� �+x������)) mod \
&gt; &gt; &gt; x������) + (H2 div x������) |
&gt; &gt; &gt; +C |
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; +C | H3M = (H3 div x������)||((H3 mod x������) �� (x������+x��� �+x��� \
&gt; &gt; &gt; �+x������)) div x������ |
&gt; &gt; &gt; +C | H3L = (H3 mod x������)||(((H3 mod x������) �� (x��� �+x��� �+x������)) mod \
&gt; &gt; &gt; x������) + (H3 div x������) |
&gt; &gt; &gt; +C |
&gt; &gt; &gt; &gt; 
&gt; &gt; &gt; +C | H4M = (H3 div x������)||((H4 mod x������) �� (x������+x��� �+x��� \
&gt; &gt; &gt; �+x������)) div x������ |
&gt; &gt; &gt; +C | H4L = (H3 mod x������)||(((H4 mod x������) �� (x��� �+x��� �+x������)) mod \
&gt; &gt; &gt; x������) + (H4 div x������) |
&gt; &gt; &gt; +C
&gt; &gt; &gt; 
&gt; *******************************************************************************
&gt; &gt; &gt; +
&gt; &gt; &gt; +define(`FUNC_ALIGN', `5')
&gt; &gt; &gt; +PROLOGUE(_nettle_gcm_init_key)
&gt; &gt; &gt; +    DATA_LOAD_VEC(POLY,.polynomial,r7)           C
&gt; &gt; &gt; 0xC2000000000000000000000000000001
&gt; &gt; &gt; +IF_LE(`
&gt; &gt; &gt; +    li             r8,0
&gt; &gt; &gt; +    lvsl           LE_MASK,0,r8                  C
&gt; &gt; &gt; 0x000102030405060708090A0B0C0D0E0F
&gt; &gt; &gt; +    vspltisb       LE_TEMP,0x07                  C
&gt; &gt; &gt; 0x07070707070707070707070707070707
&gt; &gt; &gt; +    vxor           LE_MASK,LE_MASK,LE_TEMP       C
&gt; &gt; &gt; 0x07060504030201000F0E0D0C0B0A0908
&gt; &gt; &gt; +')
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C 'H' is assigned by gcm_set_key() to the middle element of the
&gt; table
&gt; &gt; &gt; +    li             r10,8*TableElemAlign
&gt; &gt; &gt; +    lxvd2x         VSR(H),r10,TABLE              C load 'H'
&gt; &gt; &gt; +    C byte-reverse of each doubleword permuting on little-endian mode
&gt; &gt; &gt; +IF_LE(`
&gt; &gt; &gt; +    vperm          H,H,H,LE_MASK
&gt; &gt; &gt; +')
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C --- calculate H = H &lt;&lt; 1 mod P(X), P(X) =
&gt; (x � ����+x � ����+x � ����+x � � �+1)
&gt; &gt; &gt; ---
&gt; &gt; &gt; +
&gt; &gt; &gt; +    vupkhsb        EMSB,H                        C extend most
&gt; &gt; &gt; significant bit to first byte
&gt; &gt; &gt; +    vspltisb       B1,1                          C
&gt; &gt; &gt; 0x01010101010101010101010101010101
&gt; &gt; &gt; +    vspltb         EMSB,EMSB,0                   C first byte
&gt; &gt; &gt; quadword-extend
&gt; &gt; &gt; +    vsl            H,H,B1                        C H = H &lt;&lt; 1
&gt; &gt; &gt; +    vand           EMSB,EMSB,POLY                C EMSB &amp;=
&gt; &gt; &gt; 0xC2000000000000000000000000000001
&gt; &gt; &gt; +    vxor           ZERO,ZERO,ZERO                C
&gt; &gt; &gt; 0x00000000000000000000000000000000
&gt; &gt; &gt; +    vxor           H,H,EMSB                      C H ^= EMSB
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C --- calculate H^2 = H*H ---
&gt; &gt; &gt; +
&gt; &gt; &gt; +    xxmrghd        VSR(POLY_L),VSR(ZERO),VSR(POLY) C
&gt; &gt; &gt; 0x0000000000000000C200000000000000
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C --- Hp = (H mod x������) / x������ mod P(X) ---
&gt; &gt; &gt; +    C --- Hp = (H mod x������) �� (x������+x��� �+x��� �+x������) mod P(X), \
&gt; &gt; &gt; deg(Hp) ���
&gt; 127 ---
&gt; &gt; &gt; +    C --- Hp = (H mod x������) �� (x������+x��� �+x��� �+x������) ---
&gt; &gt; &gt; +    vpmsumd        Hp,H,POLY_L                   C Hp = (H mod x������) ��
&gt; &gt; &gt; (x��� �+x��� �+x������)
&gt; &gt; &gt; +    xxmrgld        VSR(Hl),VSR(H),VSR(ZERO)      C Hl = (H mod x������) ��
&gt; x������
&gt; &gt; &gt; +    xxswapd        VSR(Hm),VSR(H)
&gt; &gt; &gt; +    vxor           Hl,Hl,Hp                      C Hl = Hl + Hp
&gt; &gt; &gt; +    vxor           Hm,Hm,Hp                      C Hm = Hm + Hp
&gt; &gt; &gt; +    xxmrghd        VSR(H1M),VSR(H),VSR(Hl)       C H1M = (H div
&gt; x������)||(Hl
&gt; &gt; &gt; div x������)
&gt; &gt; &gt; +    xxmrgld        VSR(H1L),VSR(H),VSR(Hm)       C H1L = (H mod
&gt; x������)||(Hl
&gt; &gt; &gt; mod x������)
&gt; &gt; &gt; +
&gt; &gt; &gt; +    vpmsumd        F,H1L,H                       C F = (H1Lh �� Hh) +
&gt; &gt; &gt; (H1Ll �� Hl)
&gt; &gt; &gt; +    vpmsumd        R,H1M,H                       C R = (H1Mh �� Hh) +
&gt; &gt; &gt; (H1Ml �� Hl)
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C --- rduction ---
&gt; &gt; &gt; +    vpmsumd        T,F,POLY_L                    C T = (F mod x������) ��
&gt; &gt; &gt; (x��� �+x��� �+x������)
&gt; &gt; &gt; +    xxswapd        VSR(H2),VSR(F)
&gt; &gt; &gt; +    vxor           R,R,T                         C R = R + T
&gt; &gt; &gt; +    vxor           H2,R,H2
&gt; &gt; &gt; +
&gt; &gt; &gt; +    xxmrgld        VSR(Hl),VSR(H2),VSR(ZERO)
&gt; &gt; &gt; +    xxswapd        VSR(Hm),VSR(H2)
&gt; &gt; &gt; +    vpmsumd        Hp,H2,POLY_L
&gt; &gt; &gt; +    vxor           Hl,Hl,Hp
&gt; &gt; &gt; +    vxor           Hm,Hm,Hp
&gt; &gt; &gt; +    xxmrghd        VSR(H2M),VSR(H2),VSR(Hl)
&gt; &gt; &gt; +    xxmrgld        VSR(H2L),VSR(H2),VSR(Hm)
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C store H1M, H1L, H2M, H2L
&gt; &gt; &gt; +    li             r8,1*TableElemAlign
&gt; &gt; &gt; +    li             r9,2*TableElemAlign
&gt; &gt; &gt; +    li             r10,3*TableElemAlign
&gt; &gt; &gt; +    stxvd2x        VSR(H1M),0,TABLE
&gt; &gt; &gt; +    stxvd2x        VSR(H1L),r8,TABLE
&gt; &gt; &gt; +    stxvd2x        VSR(H2M),r9,TABLE
&gt; &gt; &gt; +    stxvd2x        VSR(H2L),r10,TABLE
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C --- calculate H^3 = H^1*H^2, H^4 = H^2*H^2 ---
&gt; &gt; &gt; +
&gt; &gt; &gt; +    vpmsumd        F,H1L,H2
&gt; &gt; &gt; +    vpmsumd        F2,H2L,H2
&gt; &gt; &gt; +    vpmsumd        R,H1M,H2
&gt; &gt; &gt; +    vpmsumd        R2,H2M,H2
&gt; &gt; &gt; +
&gt; &gt; &gt; +    vpmsumd        T,F,POLY_L
&gt; &gt; &gt; +    vpmsumd        T2,F2,POLY_L
&gt; &gt; &gt; +    xxswapd        VSR(H3),VSR(F)
&gt; &gt; &gt; +    xxswapd        VSR(H4),VSR(F2)
&gt; &gt; &gt; +    vxor           R,R,T
&gt; &gt; &gt; +    vxor           R2,R2,T2
&gt; &gt; &gt; +    vxor           H3,R,H3
&gt; &gt; &gt; +    vxor           H4,R2,H4
&gt; &gt; &gt; +
&gt; &gt; &gt; +    xxmrgld        VSR(Hl),VSR(H3),VSR(ZERO)
&gt; &gt; &gt; +    xxmrgld        VSR(Hl2),VSR(H4),VSR(ZERO)
&gt; &gt; &gt; +    xxswapd        VSR(Hm),VSR(H3)
&gt; &gt; &gt; +    xxswapd        VSR(Hm2),VSR(H4)
&gt; &gt; &gt; +    vpmsumd        Hp,H3,POLY_L
&gt; &gt; &gt; +    vpmsumd        Hp2,H4,POLY_L
&gt; &gt; &gt; +    vxor           Hl,Hl,Hp
&gt; &gt; &gt; +    vxor           Hl2,Hl2,Hp2
&gt; &gt; &gt; +    vxor           Hm,Hm,Hp
&gt; &gt; &gt; +    vxor           Hm2,Hm2,Hp2
&gt; &gt; &gt; +    xxmrghd        VSR(H1M),VSR(H3),VSR(Hl)
&gt; &gt; &gt; +    xxmrghd        VSR(H2M),VSR(H4),VSR(Hl2)
&gt; &gt; &gt; +    xxmrgld        VSR(H1L),VSR(H3),VSR(Hm)
&gt; &gt; &gt; +    xxmrgld        VSR(H2L),VSR(H4),VSR(Hm2)
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C store H3M, H3L, H4M, H4L
&gt; &gt; &gt; +    li             r7,4*TableElemAlign
&gt; &gt; &gt; +    li             r8,5*TableElemAlign
&gt; &gt; &gt; +    li             r9,6*TableElemAlign
&gt; &gt; &gt; +    li             r10,7*TableElemAlign
&gt; &gt; &gt; +    stxvd2x        VSR(H1M),r7,TABLE
&gt; &gt; &gt; +    stxvd2x        VSR(H1L),r8,TABLE
&gt; &gt; &gt; +    stxvd2x        VSR(H2M),r9,TABLE
&gt; &gt; &gt; +    stxvd2x        VSR(H2L),r10,TABLE
&gt; &gt; &gt; +
&gt; &gt; &gt; +    blr
&gt; &gt; &gt; +EPILOGUE(_nettle_gcm_init_key)
&gt; &gt; &gt; +
&gt; &gt; &gt; +define(`TABLE', `r3')
&gt; &gt; &gt; +define(`X', `r4')
&gt; &gt; &gt; +define(`LENGTH', `r5')
&gt; &gt; &gt; +define(`DATA', `r6')
&gt; &gt; &gt; +
&gt; &gt; &gt; +define(`ZERO', `v16')
&gt; &gt; &gt; +define(`POLY', `v17')
&gt; &gt; &gt; +define(`POLY_L', `v0')
&gt; &gt; &gt; +
&gt; &gt; &gt; +define(`D', `v1')
&gt; &gt; &gt; +define(`C0', `v2')
&gt; &gt; &gt; +define(`C1', `v3')
&gt; &gt; &gt; +define(`C2', `v4')
&gt; &gt; &gt; +define(`C3', `v5')
&gt; &gt; &gt; +define(`H1M', `v6')
&gt; &gt; &gt; +define(`H1L', `v7')
&gt; &gt; &gt; +define(`H2M', `v8')
&gt; &gt; &gt; +define(`H2L', `v9')
&gt; &gt; &gt; +define(`H3M', `v10')
&gt; &gt; &gt; +define(`H3L', `v11')
&gt; &gt; &gt; +define(`H4M', `v12')
&gt; &gt; &gt; +define(`H4L', `v13')
&gt; &gt; &gt; +define(`R', `v14')
&gt; &gt; &gt; +define(`F', `v15')
&gt; &gt; &gt; +define(`R2', `v16')
&gt; &gt; &gt; +define(`F2', `v17')
&gt; &gt; &gt; +define(`R3', `v18')
&gt; &gt; &gt; +define(`F3', `v20')
&gt; &gt; &gt; +define(`R4', `v21')
&gt; &gt; &gt; +define(`F4', `v22')
&gt; &gt; &gt; +define(`T', `v23')
&gt; &gt; &gt; +
&gt; &gt; &gt; +define(`LE_TEMP', `v18')
&gt; &gt; &gt; +define(`LE_MASK', `v19')
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C void gcm_hash (const struct gcm_key *key, union gcm_block *x,
&gt; &gt; &gt; +    C                size_t length, const uint8_t *data)
&gt; &gt; &gt; +
&gt; &gt; &gt; +define(`FUNC_ALIGN', `5')
&gt; &gt; &gt; +PROLOGUE(_nettle_gcm_hash)
&gt; &gt; &gt; +    DATA_LOAD_VEC(POLY,.polynomial,r7)
&gt; &gt; &gt; +IF_LE(`
&gt; &gt; &gt; +    li             r8,0
&gt; &gt; &gt; +    lvsl           LE_MASK,0,r8
&gt; &gt; &gt; +    vspltisb       LE_TEMP,0x07
&gt; &gt; &gt; +    vxor           LE_MASK,LE_MASK,LE_TEMP
&gt; &gt; &gt; +')
&gt; &gt; &gt; +    vxor           ZERO,ZERO,ZERO
&gt; &gt; &gt; +    xxmrghd        VSR(POLY_L),VSR(ZERO),VSR(POLY)
&gt; &gt; &gt; +
&gt; &gt; &gt; +    lxvd2x         VSR(D),0,X                    C load 'X' pointer
&gt; &gt; &gt; +    C byte-reverse of each doubleword permuting on little-endian mode
&gt; &gt; &gt; +IF_LE(`
&gt; &gt; &gt; +    vperm          D,D,D,LE_MASK
&gt; &gt; &gt; +')
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C --- process 4 blocks '128-bit each' per one loop ---
&gt; &gt; &gt; +
&gt; &gt; &gt; +    srdi           r7,LENGTH,6                   C 4-blocks loop count
&gt; &gt; &gt; 'LENGTH / (4 * 16)'
&gt; &gt; &gt; +    cmpldi         r7,0
&gt; &gt; &gt; +    beq            L2x
&gt; &gt; &gt; +
&gt; &gt; &gt; +    mtctr          r7                            C assign counter
&gt; &gt; &gt; register to loop count
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C store non-volatile vector registers
&gt; &gt; &gt; +    addi           r8,SP,-64
&gt; &gt; &gt; +    stvx           20,0,r8
&gt; &gt; &gt; +    addi           r8,r8,16
&gt; &gt; &gt; +    stvx           21,0,r8
&gt; &gt; &gt; +    addi           r8,r8,16
&gt; &gt; &gt; +    stvx           22,0,r8
&gt; &gt; &gt; +    addi           r8,r8,16
&gt; &gt; &gt; +    stvx           23,0,r8
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C load table elements
&gt; &gt; &gt; +    li             r8,1*TableElemAlign
&gt; &gt; &gt; +    li             r9,2*TableElemAlign
&gt; &gt; &gt; +    li             r10,3*TableElemAlign
&gt; &gt; &gt; +    lxvd2x         VSR(H1M),0,TABLE
&gt; &gt; &gt; +    lxvd2x         VSR(H1L),r8,TABLE
&gt; &gt; &gt; +    lxvd2x         VSR(H2M),r9,TABLE
&gt; &gt; &gt; +    lxvd2x         VSR(H2L),r10,TABLE
&gt; &gt; &gt; +    li             r7,4*TableElemAlign
&gt; &gt; &gt; +    li             r8,5*TableElemAlign
&gt; &gt; &gt; +    li             r9,6*TableElemAlign
&gt; &gt; &gt; +    li             r10,7*TableElemAlign
&gt; &gt; &gt; +    lxvd2x         VSR(H3M),r7,TABLE
&gt; &gt; &gt; +    lxvd2x         VSR(H3L),r8,TABLE
&gt; &gt; &gt; +    lxvd2x         VSR(H4M),r9,TABLE
&gt; &gt; &gt; +    lxvd2x         VSR(H4L),r10,TABLE
&gt; &gt; &gt; +
&gt; &gt; &gt; +    li             r8,0x10
&gt; &gt; &gt; +    li             r9,0x20
&gt; &gt; &gt; +    li             r10,0x30
&gt; &gt; &gt; +.align 5
&gt; &gt; &gt; +L4x_loop:
&gt; &gt; &gt; +    C input loading
&gt; &gt; &gt; +    lxvd2x         VSR(C0),0,DATA                C load C0
&gt; &gt; &gt; +    lxvd2x         VSR(C1),r8,DATA               C load C1
&gt; &gt; &gt; +    lxvd2x         VSR(C2),r9,DATA               C load C2
&gt; &gt; &gt; +    lxvd2x         VSR(C3),r10,DATA              C load C3
&gt; &gt; &gt; +
&gt; &gt; &gt; +IF_LE(`
&gt; &gt; &gt; +    vperm          C0,C0,C0,LE_MASK
&gt; &gt; &gt; +    vperm          C1,C1,C1,LE_MASK
&gt; &gt; &gt; +    vperm          C2,C2,C2,LE_MASK
&gt; &gt; &gt; +    vperm          C3,C3,C3,LE_MASK
&gt; &gt; &gt; +')
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C previous digest combining
&gt; &gt; &gt; +    vxor           C0,C0,D
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C polynomial multiplication
&gt; &gt; &gt; +    vpmsumd        F2,H3L,C1
&gt; &gt; &gt; +    vpmsumd        R2,H3M,C1
&gt; &gt; &gt; +    vpmsumd        F3,H2L,C2
&gt; &gt; &gt; +    vpmsumd        R3,H2M,C2
&gt; &gt; &gt; +    vpmsumd        F4,H1L,C3
&gt; &gt; &gt; +    vpmsumd        R4,H1M,C3
&gt; &gt; &gt; +    vpmsumd        F,H4L,C0
&gt; &gt; &gt; +    vpmsumd        R,H4M,C0
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C deferred recombination of partial products
&gt; &gt; &gt; +    vxor           F3,F3,F4
&gt; &gt; &gt; +    vxor           R3,R3,R4
&gt; &gt; &gt; +    vxor           F,F,F2
&gt; &gt; &gt; +    vxor           R,R,R2
&gt; &gt; &gt; +    vxor           F,F,F3
&gt; &gt; &gt; +    vxor           R,R,R3
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C reduction
&gt; &gt; &gt; +    vpmsumd        T,F,POLY_L
&gt; &gt; &gt; +    xxswapd        VSR(D),VSR(F)
&gt; &gt; &gt; +    vxor           R,R,T
&gt; &gt; &gt; +    vxor           D,R,D
&gt; &gt; &gt; +
&gt; &gt; &gt; +    addi           DATA,DATA,0x40
&gt; &gt; &gt; +    bdnz           L4x_loop
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C restore non-volatile vector registers
&gt; &gt; &gt; +    addi           r8,SP,-64
&gt; &gt; &gt; +    lvx            20,0,r8
&gt; &gt; &gt; +    addi           r8,r8,16
&gt; &gt; &gt; +    lvx            21,0,r8
&gt; &gt; &gt; +    addi           r8,r8,16
&gt; &gt; &gt; +    lvx            22,0,r8
&gt; &gt; &gt; +    addi           r8,r8,16
&gt; &gt; &gt; +    lvx            23,0,r8
&gt; &gt; &gt; +
&gt; &gt; &gt; +    clrldi         LENGTH,LENGTH,58              C 'set the
&gt; high-order 58
&gt; &gt; &gt; bits to zeros'
&gt; &gt; &gt; +L2x:
&gt; &gt; &gt; +    C --- process 2 blocks ---
&gt; &gt; &gt; +
&gt; &gt; &gt; +    srdi           r7,LENGTH,5                   C 'LENGTH / (2 * 16)'
&gt; &gt; &gt; +    cmpldi         r7,0
&gt; &gt; &gt; +    beq            L1x
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C load table elements
&gt; &gt; &gt; +    li             r8,1*TableElemAlign
&gt; &gt; &gt; +    li             r9,2*TableElemAlign
&gt; &gt; &gt; +    li             r10,3*TableElemAlign
&gt; &gt; &gt; +    lxvd2x         VSR(H1M),0,TABLE
&gt; &gt; &gt; +    lxvd2x         VSR(H1L),r8,TABLE
&gt; &gt; &gt; +    lxvd2x         VSR(H2M),r9,TABLE
&gt; &gt; &gt; +    lxvd2x         VSR(H2L),r10,TABLE
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C input loading
&gt; &gt; &gt; +    li             r10,0x10
&gt; &gt; &gt; +    lxvd2x         VSR(C0),0,DATA                C load C0
&gt; &gt; &gt; +    lxvd2x         VSR(C1),r10,DATA              C load C1
&gt; &gt; &gt; +
&gt; &gt; &gt; +IF_LE(`
&gt; &gt; &gt; +    vperm          C0,C0,C0,LE_MASK
&gt; &gt; &gt; +    vperm          C1,C1,C1,LE_MASK
&gt; &gt; &gt; +')
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C previous digest combining
&gt; &gt; &gt; +    vxor           C0,C0,D
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C polynomial multiplication
&gt; &gt; &gt; +    vpmsumd        F2,H1L,C1
&gt; &gt; &gt; +    vpmsumd        R2,H1M,C1
&gt; &gt; &gt; +    vpmsumd        F,H2L,C0
&gt; &gt; &gt; +    vpmsumd        R,H2M,C0
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C deferred recombination of partial products
&gt; &gt; &gt; +    vxor           F,F,F2
&gt; &gt; &gt; +    vxor           R,R,R2
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C reduction
&gt; &gt; &gt; +    vpmsumd        T,F,POLY_L
&gt; &gt; &gt; +    xxswapd        VSR(D),VSR(F)
&gt; &gt; &gt; +    vxor           R,R,T
&gt; &gt; &gt; +    vxor           D,R,D
&gt; &gt; &gt; +
&gt; &gt; &gt; +    addi           DATA,DATA,0x20
&gt; &gt; &gt; +    clrldi         LENGTH,LENGTH,59              C 'set the
&gt; high-order 59
&gt; &gt; &gt; bits to zeros'
&gt; &gt; &gt; +L1x:
&gt; &gt; &gt; +    C --- process 1 block ---
&gt; &gt; &gt; +
&gt; &gt; &gt; +    srdi           r7,LENGTH,4                   C 'LENGTH / (1 * 16)'
&gt; &gt; &gt; +    cmpldi         r7,0
&gt; &gt; &gt; +    beq            Lmod
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C load table elements
&gt; &gt; &gt; +    li             r8,1*TableElemAlign
&gt; &gt; &gt; +    lxvd2x         VSR(H1M),0,TABLE
&gt; &gt; &gt; +    lxvd2x         VSR(H1L),r8,TABLE
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C input loading
&gt; &gt; &gt; +    lxvd2x         VSR(C0),0,DATA                C load C0
&gt; &gt; &gt; +
&gt; &gt; &gt; +IF_LE(`
&gt; &gt; &gt; +    vperm          C0,C0,C0,LE_MASK
&gt; &gt; &gt; +')
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C previous digest combining
&gt; &gt; &gt; +    vxor           C0,C0,D
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C polynomial multiplication
&gt; &gt; &gt; +    vpmsumd        F,H1L,C0
&gt; &gt; &gt; +    vpmsumd        R,H1M,C0
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C reduction
&gt; &gt; &gt; +    vpmsumd        T,F,POLY_L
&gt; &gt; &gt; +    xxswapd        VSR(D),VSR(F)
&gt; &gt; &gt; +    vxor           R,R,T
&gt; &gt; &gt; +    vxor           D,R,D
&gt; &gt; &gt; +
&gt; &gt; &gt; +    addi           DATA,DATA,0x10
&gt; &gt; &gt; +    clrldi         LENGTH,LENGTH,60              C 'set the
&gt; high-order 60
&gt; &gt; &gt; bits to zeros'
&gt; &gt; &gt; +Lmod:
&gt; &gt; &gt; +    C --- process the modulo bytes, padding the low-order bytes with
&gt; &gt; &gt; zeros ---
&gt; &gt; &gt; +
&gt; &gt; &gt; +    cmpldi         LENGTH,0
&gt; &gt; &gt; +    beq            Ldone
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C load table elements
&gt; &gt; &gt; +    li             r8,1*TableElemAlign
&gt; &gt; &gt; +    lxvd2x         VSR(H1M),0,TABLE
&gt; &gt; &gt; +    lxvd2x         VSR(H1L),r8,TABLE
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C push every modulo byte to the stack and load them with padding
&gt; into
&gt; &gt; &gt; vector register
&gt; &gt; &gt; +    vxor           ZERO,ZERO,ZERO
&gt; &gt; &gt; +    addi           r8,SP,-16
&gt; &gt; &gt; +    stvx           ZERO,0,r8
&gt; &gt; &gt; +Lstb_loop:
&gt; &gt; &gt; +    subic.         LENGTH,LENGTH,1
&gt; &gt; &gt; +    lbzx           r7,LENGTH,DATA
&gt; &gt; &gt; +    stbx           r7,LENGTH,r8
&gt; &gt; &gt; +    bne            Lstb_loop
&gt; &gt; &gt; +    lxvd2x         VSR(C0),0,r8
&gt; &gt; &gt; +
&gt; &gt; &gt; +IF_LE(`
&gt; &gt; &gt; +    vperm          C0,C0,C0,LE_MASK
&gt; &gt; &gt; +')
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C previous digest combining
&gt; &gt; &gt; +    vxor           C0,C0,D
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C polynomial multiplication
&gt; &gt; &gt; +    vpmsumd        F,H1L,C0
&gt; &gt; &gt; +    vpmsumd        R,H1M,C0
&gt; &gt; &gt; +
&gt; &gt; &gt; +    C reduction
&gt; &gt; &gt; +    vpmsumd        T,F,POLY_L
&gt; &gt; &gt; +    xxswapd        VSR(D),VSR(F)
&gt; &gt; &gt; +    vxor           R,R,T
&gt; &gt; &gt; +    vxor           D,R,D
&gt; &gt; &gt; +
&gt; &gt; &gt; +Ldone:
&gt; &gt; &gt; +    C byte-reverse of each doubleword permuting on little-endian mode
&gt; &gt; &gt; +IF_LE(`
&gt; &gt; &gt; +    vperm          D,D,D,LE_MASK
&gt; &gt; &gt; +')
&gt; &gt; &gt; +    stxvd2x        VSR(D),0,X                    C store digest 'D'
&gt; &gt; &gt; +
&gt; &gt; &gt; +    blr
&gt; &gt; &gt; +EPILOGUE(_nettle_gcm_hash)
&gt; &gt; &gt; +
&gt; &gt; &gt; +.data
&gt; &gt; &gt; +    C 0xC2000000000000000000000000000001
&gt; &gt; &gt; +.polynomial:
&gt; &gt; &gt; +.align 4
&gt; &gt; &gt; +IF_BE(`
&gt; &gt; &gt; +.byte 0xC2
&gt; &gt; &gt; +.rept 14
&gt; &gt; &gt; +.byte 0x00
&gt; &gt; &gt; +.endr
&gt; &gt; &gt; +.byte 0x01
&gt; &gt; &gt; +',`
&gt; &gt; &gt; +.byte 0x01
&gt; &gt; &gt; +.rept 14
&gt; &gt; &gt; +.byte 0x00
&gt; &gt; &gt; +.endr
&gt; &gt; &gt; +.byte 0xC2
&gt; &gt; &gt; +')
&gt; &gt; &gt; 
&gt; &gt; &gt; --
&gt; &gt; &gt; 2.17.1
&gt; &gt; &gt; 
&gt; &gt; _______________________________________________
&gt; &gt; nettle-bugs mailing list
&gt; &gt; nettle-bugs@lists.lysator.liu.se
&gt; &gt; http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs
&gt; 
&gt; --
&gt; George Wilson
&gt; IBM Linux Technology Center
&gt; Security Development
&gt; 
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs


</body></email><email><emailId>20201121153219</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-11-21 15:32:19-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; For the first approach I can think of this method:
&gt; lxvd2x      VSR(C0),0,DATA
&gt; IF_LE(`
&gt; vperm       C0,C0,C0,LE_MASK
&gt; ')
&gt; slwi        LENGTH,LENGTH,4     (Shift left 4 bitls because vsro get
&gt; bit[121:124])
&gt; vspltisb    v10,-1
&gt; (0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF)
&gt; mtvrwz      v11,LENGTH             (LENGTH in bit[57:60])
&gt; xxspltd     VSR(v11),VSR(v11),0 (LENGTH in bit[121:124])
&gt; vsro        v10,v10,v11                  (Sift right by octet)
&gt; vnot        v10,v10
&gt; vand        C0,C0,v10

I'm having some difficulty following along. Is this a loop, part of a
loop, or is there some vector load instruction that lets you pass a byte
length?

&gt; I recommend the third approach so we don't have to deal with the leftover
&gt; bytes in the upcoming implementations but the problem is that
&gt; gcm_init_key() initialize the table for the compatible gcm_hash()
&gt; function,

If we go this way, the power assembly file would have to provide an
implementation of gcm_gf_mul, compatible with its gcm_init_key. It would
do essentially the same thing as the single-block part of gcm_hash. But
approach 1 is fine too, if it doesn't get too complicated.

Your recent mails have not included actual patches, neither inline, nor
as attachments. E.g.,
https://lists.lysator.liu.se/pipermail/nettle-bugs/2020/009234.html. (The
mailist software might discard some attachments, but content-type:
text/x-patch and the like should be fine). If your mail client doesn't
cooperate, feel free to create a pull request on git.lysator.liu.se
instead (and ping the list).

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201122150243</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-11-22 15:02:43-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

On Sat, Nov 21, 2020 at 5:32 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Is this a loop, part of a
&gt; loop, or is there some vector load instruction that lets you pass a byte
&gt; length?
&gt;

It generates a mask compatible with the length of leftovers, for example if
the length is 1 then the mask generated is
0xFF000000000000000000000000000000 then the mask is ANDed with the vector
register of leftovers to clear the extra unneeded bytes. It's not exactly
like the first approach but it avoids using stack and handles the leftovers
inside the assembly implementation, sorry for mixing up.


&gt;
&gt; &gt; I recommend the third approach so we don't have to deal with the leftover
&gt; &gt; bytes in the upcoming implementations but the problem is that
&gt; &gt; gcm_init_key() initialize the table for the compatible gcm_hash()
&gt; &gt; function,
&gt;
&gt; If we go this way, the power assembly file would have to provide an
&gt; implementation of gcm_gf_mul, compatible with its gcm_init_key. It would
&gt; do essentially the same thing as the single-block part of gcm_hash. But
&gt; approach 1 is fine too, if it doesn't get too complicated.
&gt;
&gt; Your recent mails have not included actual patches, neither inline, nor
&gt; as attachments. E.g.,
&gt; https://lists.lysator.liu.se/pipermail/nettle-bugs/2020/009234.html. (The
&gt; mailist software might discard some attachments, but content-type:
&gt; text/x-patch and the like should be fine). If your mail client doesn't
&gt; cooperate, feel free to create a pull request on git.lysator.liu.se
&gt; instead (and ping the list).
&gt;

I made a merge request in git.lysator.liu.se, it ended up easier for me to
push patches to the repository in this way, I hope you don't mind dealing
with the future patches the same way.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201028013005</emailId><senderName>Guido Vranken</senderName><senderEmail>guidovranken@gmail.com</senderEmail><timestampReceived>2020-10-28 01:30:05-0400</timestampReceived><subject>Blowfish integer overshift (undefined behavior)</subject><body>

Hi all,

My project is Cryptofuzz (https://github.com/guidovranken/cryptofuzz) which
uses differential fuzzing to find correctness bugs (and memory bugs as
well) in popular cryptographic libraries.

It has bindings for Nettle and it tests many of the library's features:
https://github.com/guidovranken/cryptofuzz/blob/master/modules/nettle/module.cpp

I've been running this on Google's OSS-Fuzz (
https://github.com/google/oss-fuzz) for a while, and today it found a bug
in the blowfish key setter function.

Niels and other maintainers (if any), if you would like to be notified by
e-mail of bugs found by Cryptofuzz, please send me your e-mail address and
I will add you to the project. The e-mail address needs to be linked to a
Google account in order to access the dashboard at oss-fuzz.com.

Bug reproducer below:

-------
#include &lt;nettle/blowfish.h&gt;

int main(void)
{
    const unsigned char key[] = {0xec, 0x00, 0x3a, 0x06, 0x73, 0x61, 0x74,
0x20, 0x74, 0xab, 0xe2, 0xc6, 0x61, 0x8b, 0x98, 0x89};
    struct blowfish_ctx ctx;
    blowfish_set_key(&amp;ctx, sizeof(key), key);
    return 0;
}
-------

If you compile with Clang and -fsanitize=undefined, this will print:

blowfish.c:388:22: runtime error: left shift of 236 by 24 places cannot be
represented in type 'int'

Explicit casting around the shifted values will fix this.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201122151816</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-11-22 15:18:16-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

On Fri, Nov 20, 2020 at 3:39 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt; wrote:
&gt;
&gt; ---------- Forwarded message ---------
&gt; From: Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
&gt; Date: Thu, Nov 12, 2020 at 7:42 PM
&gt; Subject: Re: [PowerPC] GCM optimization
&gt; To: Niels Möller &lt;nisse@lysator.liu.se&gt;
&gt;
&gt; On Thu, Nov 12, 2020 at 6:40 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:
&gt;
&gt; &gt; I gave it a test run on gcc112 in the gcc compile farm, and speedup of
&gt; &gt; gcm update seems to be 26 times(!) compared to the C version.
&gt; &gt;
&gt;
&gt; That's reasonable, I got similar speedup on more stable POWER instances
&gt; than gcc compile farm.
&gt;
&gt; &gt; Where would that documentation be published? In the Nettle manual, as
&gt; &gt; some IBM white paper, or as a more-or-less academic paper, e.g., on
&gt; &gt; arxiv? I will not be able to spend much time on writing, but I'd be
&gt; &gt; happy to review.
&gt; &gt;
&gt;
&gt; I'll start writing the papers once I got more details from IBM, similar to
&gt; intel documents, the document will be academic and practical at the same
&gt; time, I'll dive into finite field equations to demonstrate how we get there
&gt; as well as I'll add a practical example to clarify the preference of this
&gt; method in addition to the expected speedup of this method. My
&gt; intention that other crypto libraries could take advantage of this document
&gt; or maybe be a starting point for further improvements to the algorithm so
&gt; I'm checking if IBM would publish or approve such a document the same as
&gt; intel.

You might want to ping Steven Munroe for feedback. He's an IBM
old-timer who usually helps with implementations and technical
editing. He has amazing knowledge of the POWER chips. He also has a
GitHub with some nice POWER libraries. He has been CC'd.

Munroe also helped with
https://github.com/noloader/POWER8-crypto/blob/master/power8-crypto.pdf.
We wrote it because IBM documentation sucks. As far as I know there is
no IBM documentation (expect a blog post that explains some of Andy
Polyakov's OpenSSL code).

If you want to add information to the power8-crypto.pdf doc, then we
can make you an author and collaborator for check-ins. As a
collaborator, you won't have to waste time with patches and asking
permission. Just edit the doc like a wiki page.

The power8-crypto.pdf is written in DocBook. The DocBook setup for
Fedora and Ubuntu is in the document
https://github.com/noloader/POWER8-crypto/blob/master/docbook.pdf.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201122164752</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-11-22 16:47:52-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

Thank you, I'll take a look at the document.

regards,
Mamone

On Sun, Nov 22, 2020 at 5:18 PM Jeffrey Walton &lt;noloader@gmail.com&gt; wrote:

&gt; On Fri, Nov 20, 2020 at 3:39 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
&gt; wrote:
&gt; &gt;
&gt; &gt; ---------- Forwarded message ---------
&gt; &gt; From: Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
&gt; &gt; Date: Thu, Nov 12, 2020 at 7:42 PM
&gt; &gt; Subject: Re: [PowerPC] GCM optimization
&gt; &gt; To: Niels Möller &lt;nisse@lysator.liu.se&gt;
&gt; &gt;
&gt; &gt; On Thu, Nov 12, 2020 at 6:40 PM Niels Möller &lt;nisse@lysator.liu.se&gt;
&gt; wrote:
&gt; &gt;
&gt; &gt; &gt; I gave it a test run on gcc112 in the gcc compile farm, and speedup of
&gt; &gt; &gt; gcm update seems to be 26 times(!) compared to the C version.
&gt; &gt; &gt;
&gt; &gt;
&gt; &gt; That's reasonable, I got similar speedup on more stable POWER instances
&gt; &gt; than gcc compile farm.
&gt; &gt;
&gt; &gt; &gt; Where would that documentation be published? In the Nettle manual, as
&gt; &gt; &gt; some IBM white paper, or as a more-or-less academic paper, e.g., on
&gt; &gt; &gt; arxiv? I will not be able to spend much time on writing, but I'd be
&gt; &gt; &gt; happy to review.
&gt; &gt; &gt;
&gt; &gt;
&gt; &gt; I'll start writing the papers once I got more details from IBM, similar
&gt; to
&gt; &gt; intel documents, the document will be academic and practical at the same
&gt; &gt; time, I'll dive into finite field equations to demonstrate how we get
&gt; there
&gt; &gt; as well as I'll add a practical example to clarify the preference of this
&gt; &gt; method in addition to the expected speedup of this method. My
&gt; &gt; intention that other crypto libraries could take advantage of this
&gt; document
&gt; &gt; or maybe be a starting point for further improvements to the algorithm so
&gt; &gt; I'm checking if IBM would publish or approve such a document the same as
&gt; &gt; intel.
&gt;
&gt; You might want to ping Steven Munroe for feedback. He's an IBM
&gt; old-timer who usually helps with implementations and technical
&gt; editing. He has amazing knowledge of the POWER chips. He also has a
&gt; GitHub with some nice POWER libraries. He has been CC'd.
&gt;
&gt; Munroe also helped with
&gt; https://github.com/noloader/POWER8-crypto/blob/master/power8-crypto.pdf.
&gt; We wrote it because IBM documentation sucks. As far as I know there is
&gt; no IBM documentation (expect a blog post that explains some of Andy
&gt; Polyakov's OpenSSL code).
&gt;
&gt; If you want to add information to the power8-crypto.pdf doc, then we
&gt; can make you an author and collaborator for check-ins. As a
&gt; collaborator, you won't have to waste time with patches and asking
&gt; permission. Just edit the doc like a wiki page.
&gt;
&gt; The power8-crypto.pdf is written in DocBook. The DocBook setup for
&gt; Fedora and Ubuntu is in the document
&gt; https://github.com/noloader/POWER8-crypto/blob/master/docbook.pdf.
&gt;
&gt; Jeff
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201110042536</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-11-10 04:25:36-0400</timestampReceived><subject>[PowerPC] GCM optimization</subject><body>

This implementation takes advantage of research made by Niels M��ller to
optimize GCM on PowerPC, this optimization yields a +27.7% performance
boost on POWER8 over the previous implementation that was based on intel
documents. The performance comparison is made by processing 4 blocks per
loop without any further optimizations.
I made some documentations between the lines but I suggest writing a
document similar to the intel ones that go into more details and clarify
the preference of this method. I'm also curious if this method can also
make a difference in other architectures like ARM, I'm planning to try it
out for ARM to figure that out.
---
 configure.ac              |   6 +-
 gcm.c                     |  49 +++--
 powerpc64/p8/gcm-hash.asm | 502
++++++++++++++++++++++++++++++++++++++++++++++
 3 files changed, 542 insertions(+), 15 deletions(-)
 create mode 100644 powerpc64/p8/gcm-hash.asm

diff --git a/configure.ac b/configure.ac
index 2a47f940..20f7cf74 100644
--- a/configure.ac
+++ b/configure.ac
@@ -497,7 +497,7 @@ asm_replace_list="aes-encrypt-internal.asm
aes-decrypt-internal.asm \
  sha3-permute.asm umac-nh.asm umac-nh-n.asm machine.m4"

 # Assembler files which generate additional object files if they are used.
-asm_nettle_optional_list="gcm-hash8.asm cpuid.asm \
+asm_nettle_optional_list="gcm-hash.asm gcm-hash8.asm cpuid.asm \
   aes-encrypt-internal-2.asm aes-decrypt-internal-2.asm memxor-2.asm \
   chacha-3core.asm chacha-core-internal-2.asm salsa20-2core.asm \
   salsa20-core-internal-2.asm sha1-compress-2.asm sha256-compress-2.asm \
@@ -621,9 +621,9 @@ AH_VERBATIM([HAVE_NATIVE],
 #undef HAVE_NATIVE_ecc_secp384r1_redc
 #undef HAVE_NATIVE_ecc_secp521r1_modp
 #undef HAVE_NATIVE_ecc_secp521r1_redc
-#undef HAVE_NATIVE_gcm_init_key8
+#undef HAVE_NATIVE_gcm_init_key
+#undef HAVE_NATIVE_gcm_hash
 #undef HAVE_NATIVE_gcm_hash8
-#undef HAVE_NATIVE_gcm_fill
 #undef HAVE_NATIVE_salsa20_core
 #undef HAVE_NATIVE_salsa20_2core
 #undef HAVE_NATIVE_fat_salsa20_2core
diff --git a/gcm.c b/gcm.c
index 48b3e75a..81981c1c 100644
--- a/gcm.c
+++ b/gcm.c
@@ -140,6 +140,19 @@ gcm_gf_mul (union nettle_block16 *x, const union
nettle_block16 *table)
   memcpy (x-&gt;b, Z.b, sizeof(Z));
 }
 # elif GCM_TABLE_BITS == 8
+#  if HAVE_NATIVE_gcm_init_key
+
+#define gcm_init_key _nettle_gcm_init_key
+void
+_nettle_gcm_init_key (union nettle_block16 *table);
+#  endif /* HAVE_NATIVE_gcm_init_key */
+#  if HAVE_NATIVE_gcm_hash
+
+#define gcm_hash _nettle_gcm_hash
+void
+_nettle_gcm_hash (const struct gcm_key *key, union nettle_block16 *x,
+   size_t length, const uint8_t *data);
+#  endif /* HAVE_NATIVE_gcm_hash */
 #  if HAVE_NATIVE_gcm_hash8

 #define gcm_hash _nettle_gcm_hash8
@@ -228,6 +241,29 @@ gcm_gf_mul (union nettle_block16 *x, const union
nettle_block16 *table)
 /* Increment the rightmost 32 bits. */
 #define INC32(block) INCREMENT(4, (block.b) + GCM_BLOCK_SIZE - 4)

+#ifndef gcm_init_key
+static void
+gcm_init_key(union nettle_block16 *table)
+{
+#if GCM_TABLE_BITS
+  /* Middle element if GCM_TABLE_BITS &gt; 0, otherwise the first
+     element */
+  unsigned i = (1&lt;&lt;GCM_TABLE_BITS)/2;
+
+  /* Algorithm 3 from the gcm paper. First do powers of two, then do
+     the rest by adding. */
+  while (i /= 2)
+    block16_mulx_ghash(&amp;table[i], &amp;table[2*i]);
+  for (i = 2; i &lt; 1&lt;&lt;GCM_TABLE_BITS; i *= 2)
+    {
+      unsigned j;
+      for (j = 1; j &lt; i; j++)
+ block16_xor3(&amp;table[i+j], &amp;table[i], &amp;table[j]);
+    }
+#endif
+}
+#endif /* !gcm_init_key */
+
 /* Initialization of GCM.
  * @ctx: The context of GCM
  * @cipher: The context of the underlying block cipher
@@ -245,18 +281,7 @@ gcm_set_key(struct gcm_key *key,
   memset(key-&gt;h[0].b, 0, GCM_BLOCK_SIZE);
   f (cipher, GCM_BLOCK_SIZE, key-&gt;h[i].b, key-&gt;h[0].b);

-#if GCM_TABLE_BITS
-  /* Algorithm 3 from the gcm paper. First do powers of two, then do
-     the rest by adding. */
-  while (i /= 2)
-    block16_mulx_ghash(&amp;key-&gt;h[i], &amp;key-&gt;h[2*i]);
-  for (i = 2; i &lt; 1&lt;&lt;GCM_TABLE_BITS; i *= 2)
-    {
-      unsigned j;
-      for (j = 1; j &lt; i; j++)
- block16_xor3(&amp;key-&gt;h[i+j], &amp;key-&gt;h[i],&amp;key-&gt;h[j]);
-    }
-#endif
+  gcm_init_key(key-&gt;h);
 }

 #ifndef gcm_hash
diff --git a/powerpc64/p8/gcm-hash.asm b/powerpc64/p8/gcm-hash.asm
new file mode 100644
index 00000000..e79fbdc2
--- /dev/null
+++ b/powerpc64/p8/gcm-hash.asm
@@ -0,0 +1,502 @@
+C powerpc64/p8/gcm-hash.asm
+
+ifelse(`
+   Copyright (C) 2020 Niels M��ller and Mamone Tarsha
+   This file is part of GNU Nettle.
+
+   GNU Nettle is free software: you can redistribute it and/or
+   modify it under the terms of either:
+
+     * the GNU Lesser General Public License as published by the Free
+       Software Foundation; either version 3 of the License, or (at your
+       option) any later version.
+
+   or
+
+     * the GNU General Public License as published by the Free
+       Software Foundation; either version 2 of the License, or (at your
+       option) any later version.
+
+   or both in parallel, as here.
+
+   GNU Nettle is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received copies of the GNU General Public License and
+   the GNU Lesser General Public License along with this program.  If
+   not, see http://www.gnu.org/licenses/.
+')
+
+C Alignment of gcm_key table elements, which is declared in gcm.h
+define(`TableElemAlign', `0x100')
+
+C Register usage:
+
+define(`SP', `r1')
+define(`TOCP', `r2')
+
+define(`TABLE', `r3')
+
+define(`ZERO', `v0')
+define(`B1', `v1')
+define(`EMSB', `v16')
+define(`POLY', `v17')
+define(`POLY_L', `v1')
+
+define(`H', `v2')
+define(`H2', `v3')
+define(`H3', `v4')
+define(`H4', `v5')
+define(`H1M', `v6')
+define(`H1L', `v7')
+define(`H2M', `v8')
+define(`H2L', `v9')
+define(`Hl', `v10')
+define(`Hm', `v11')
+define(`Hp', `v12')
+define(`Hl2', `v13')
+define(`Hm2', `v14')
+define(`Hp2', `v15')
+define(`R', `v13')
+define(`F', `v14')
+define(`T', `v15')
+define(`R2', `v16')
+define(`F2', `v17')
+define(`T2', `v18')
+
+define(`LE_TEMP', `v18')
+define(`LE_MASK', `v19')
+
+.file "gcm-hash.asm"
+
+.text
+
+    C void gcm_init_key (union gcm_block *table)
+
+C This function populates the gcm table as the following layout
+C
*******************************************************************************
+C | H1M = (H1 div x������)||((H1 mod x������) �� (x������+x��� �+x��� �+x������)) div x������
     |
+C | H1L = (H1 mod x������)||(((H1 mod x������) �� (x��� �+x��� �+x������)) mod x������) + (H1 div
x������) |
+C |
      |
+C | H2M = (H2 div x������)||((H2 mod x������) �� (x������+x��� �+x��� �+x������)) div x������
     |
+C | H2L = (H2 mod x������)||(((H2 mod x������) �� (x��� �+x��� �+x������)) mod x������) + (H2 div
x������) |
+C |
      |
+C | H3M = (H3 div x������)||((H3 mod x������) �� (x������+x��� �+x��� �+x������)) div x������
     |
+C | H3L = (H3 mod x������)||(((H3 mod x������) �� (x��� �+x��� �+x������)) mod x������) + (H3 div
x������) |
+C |
      |
+C | H4M = (H3 div x������)||((H4 mod x������) �� (x������+x��� �+x��� �+x������)) div x������
     |
+C | H4L = (H3 mod x������)||(((H4 mod x������) �� (x��� �+x��� �+x������)) mod x������) + (H4 div
x������) |
+C
*******************************************************************************
+
+define(`FUNC_ALIGN', `5')
+PROLOGUE(_nettle_gcm_init_key)
+    DATA_LOAD_VEC(POLY,.polynomial,r7)           C
0xC2000000000000000000000000000001
+IF_LE(`
+    li             r8,0
+    lvsl           LE_MASK,0,r8                  C
0x000102030405060708090A0B0C0D0E0F
+    vspltisb       LE_TEMP,0x07                  C
0x07070707070707070707070707070707
+    vxor           LE_MASK,LE_MASK,LE_TEMP       C
0x07060504030201000F0E0D0C0B0A0908
+')
+
+    C 'H' is assigned by gcm_set_key() to the middle element of the table
+    li             r10,8*TableElemAlign
+    lxvd2x         VSR(H),r10,TABLE              C load 'H'
+    C byte-reverse of each doubleword permuting on little-endian mode
+IF_LE(`
+    vperm          H,H,H,LE_MASK
+')
+
+    C --- calculate H = H &lt;&lt; 1 mod P(X), P(X) = (x � ����+x � ����+x � ����+x � � �+1) ---
+
+    vupkhsb        EMSB,H                        C extend most significant
bit to first byte
+    vspltisb       B1,1                          C
0x01010101010101010101010101010101
+    vspltb         EMSB,EMSB,0                   C first byte
quadword-extend
+    vsl            H,H,B1                        C H = H &lt;&lt; 1
+    vand           EMSB,EMSB,POLY                C EMSB &amp;=
0xC2000000000000000000000000000001
+    vxor           ZERO,ZERO,ZERO                C
0x00000000000000000000000000000000
+    vxor           H,H,EMSB                      C H ^= EMSB
+
+    C --- calculate H^2 = H*H ---
+
+    xxmrghd        VSR(POLY_L),VSR(ZERO),VSR(POLY) C
0x0000000000000000C200000000000000
+
+    C --- Hp = (H mod x������) / x������ mod P(X) ---
+    C --- Hp = (H mod x������) �� (x������+x��� �+x��� �+x������) mod P(X), deg(Hp) ��� 127 ---
+    C --- Hp = (H mod x������) �� (x������+x��� �+x��� �+x������) ---
+    vpmsumd        Hp,H,POLY_L                   C Hp = (H mod x������) ��
(x��� �+x��� �+x������)
+    xxmrgld        VSR(Hl),VSR(H),VSR(ZERO)      C Hl = (H mod x������) �� x������
+    xxswapd        VSR(Hm),VSR(H)
+    vxor           Hl,Hl,Hp                      C Hl = Hl + Hp
+    vxor           Hm,Hm,Hp                      C Hm = Hm + Hp
+    xxmrghd        VSR(H1M),VSR(H),VSR(Hl)       C H1M = (H div x������)||(Hl
div x������)
+    xxmrgld        VSR(H1L),VSR(H),VSR(Hm)       C H1L = (H mod x������)||(Hl
mod x������)
+
+    vpmsumd        F,H1L,H                       C F = (H1Lh �� Hh) + (H1Ll
�� Hl)
+    vpmsumd        R,H1M,H                       C R = (H1Mh �� Hh) + (H1Ml
�� Hl)
+
+    C --- rduction ---
+    vpmsumd        T,F,POLY_L                    C T = (F mod x������) ��
(x��� �+x��� �+x������)
+    xxswapd        VSR(H2),VSR(F)
+    vxor           R,R,T                         C R = R + T
+    vxor           H2,R,H2
+
+    xxmrgld        VSR(Hl),VSR(H2),VSR(ZERO)
+    xxswapd        VSR(Hm),VSR(H2)
+    vpmsumd        Hp,H2,POLY_L
+    vxor           Hl,Hl,Hp
+    vxor           Hm,Hm,Hp
+    xxmrghd        VSR(H2M),VSR(H2),VSR(Hl)
+    xxmrgld        VSR(H2L),VSR(H2),VSR(Hm)
+
+    C store H1M, H1L, H2M, H2L
+    li             r8,1*TableElemAlign
+    li             r9,2*TableElemAlign
+    li             r10,3*TableElemAlign
+    stxvd2x        VSR(H1M),0,TABLE
+    stxvd2x        VSR(H1L),r8,TABLE
+    stxvd2x        VSR(H2M),r9,TABLE
+    stxvd2x        VSR(H2L),r10,TABLE
+
+    C --- calculate H^3 = H^1*H^2, H^4 = H^2*H^2 ---
+
+    vpmsumd        F,H1L,H2
+    vpmsumd        F2,H2L,H2
+    vpmsumd        R,H1M,H2
+    vpmsumd        R2,H2M,H2
+
+    vpmsumd        T,F,POLY_L
+    vpmsumd        T2,F2,POLY_L
+    xxswapd        VSR(H3),VSR(F)
+    xxswapd        VSR(H4),VSR(F2)
+    vxor           R,R,T
+    vxor           R2,R2,T2
+    vxor           H3,R,H3
+    vxor           H4,R2,H4
+
+    xxmrgld        VSR(Hl),VSR(H3),VSR(ZERO)
+    xxmrgld        VSR(Hl2),VSR(H4),VSR(ZERO)
+    xxswapd        VSR(Hm),VSR(H3)
+    xxswapd        VSR(Hm2),VSR(H4)
+    vpmsumd        Hp,H3,POLY_L
+    vpmsumd        Hp2,H4,POLY_L
+    vxor           Hl,Hl,Hp
+    vxor           Hl2,Hl2,Hp2
+    vxor           Hm,Hm,Hp
+    vxor           Hm2,Hm2,Hp2
+    xxmrghd        VSR(H1M),VSR(H3),VSR(Hl)
+    xxmrghd        VSR(H2M),VSR(H4),VSR(Hl2)
+    xxmrgld        VSR(H1L),VSR(H3),VSR(Hm)
+    xxmrgld        VSR(H2L),VSR(H4),VSR(Hm2)
+
+    C store H3M, H3L, H4M, H4L
+    li             r7,4*TableElemAlign
+    li             r8,5*TableElemAlign
+    li             r9,6*TableElemAlign
+    li             r10,7*TableElemAlign
+    stxvd2x        VSR(H1M),r7,TABLE
+    stxvd2x        VSR(H1L),r8,TABLE
+    stxvd2x        VSR(H2M),r9,TABLE
+    stxvd2x        VSR(H2L),r10,TABLE
+
+    blr
+EPILOGUE(_nettle_gcm_init_key)
+
+define(`TABLE', `r3')
+define(`X', `r4')
+define(`LENGTH', `r5')
+define(`DATA', `r6')
+
+define(`ZERO', `v16')
+define(`POLY', `v17')
+define(`POLY_L', `v0')
+
+define(`D', `v1')
+define(`C0', `v2')
+define(`C1', `v3')
+define(`C2', `v4')
+define(`C3', `v5')
+define(`H1M', `v6')
+define(`H1L', `v7')
+define(`H2M', `v8')
+define(`H2L', `v9')
+define(`H3M', `v10')
+define(`H3L', `v11')
+define(`H4M', `v12')
+define(`H4L', `v13')
+define(`R', `v14')
+define(`F', `v15')
+define(`R2', `v16')
+define(`F2', `v17')
+define(`R3', `v18')
+define(`F3', `v20')
+define(`R4', `v21')
+define(`F4', `v22')
+define(`T', `v23')
+
+define(`LE_TEMP', `v18')
+define(`LE_MASK', `v19')
+
+    C void gcm_hash (const struct gcm_key *key, union gcm_block *x,
+    C                size_t length, const uint8_t *data)
+
+define(`FUNC_ALIGN', `5')
+PROLOGUE(_nettle_gcm_hash)
+    DATA_LOAD_VEC(POLY,.polynomial,r7)
+IF_LE(`
+    li             r8,0
+    lvsl           LE_MASK,0,r8
+    vspltisb       LE_TEMP,0x07
+    vxor           LE_MASK,LE_MASK,LE_TEMP
+')
+    vxor           ZERO,ZERO,ZERO
+    xxmrghd        VSR(POLY_L),VSR(ZERO),VSR(POLY)
+
+    lxvd2x         VSR(D),0,X                    C load 'X' pointer
+    C byte-reverse of each doubleword permuting on little-endian mode
+IF_LE(`
+    vperm          D,D,D,LE_MASK
+')
+
+    C --- process 4 blocks '128-bit each' per one loop ---
+
+    srdi           r7,LENGTH,6                   C 4-blocks loop count
'LENGTH / (4 * 16)'
+    cmpldi         r7,0
+    beq            L2x
+
+    mtctr          r7                            C assign counter register
to loop count
+
+    C store non-volatile vector registers
+    addi           r8,SP,-64
+    stvx           20,0,r8
+    addi           r8,r8,16
+    stvx           21,0,r8
+    addi           r8,r8,16
+    stvx           22,0,r8
+    addi           r8,r8,16
+    stvx           23,0,r8
+
+    C load table elements
+    li             r8,1*TableElemAlign
+    li             r9,2*TableElemAlign
+    li             r10,3*TableElemAlign
+    lxvd2x         VSR(H1M),0,TABLE
+    lxvd2x         VSR(H1L),r8,TABLE
+    lxvd2x         VSR(H2M),r9,TABLE
+    lxvd2x         VSR(H2L),r10,TABLE
+    li             r7,4*TableElemAlign
+    li             r8,5*TableElemAlign
+    li             r9,6*TableElemAlign
+    li             r10,7*TableElemAlign
+    lxvd2x         VSR(H3M),r7,TABLE
+    lxvd2x         VSR(H3L),r8,TABLE
+    lxvd2x         VSR(H4M),r9,TABLE
+    lxvd2x         VSR(H4L),r10,TABLE
+
+    li             r8,0x10
+    li             r9,0x20
+    li             r10,0x30
+.align 5
+L4x_loop:
+    C input loading
+    lxvd2x         VSR(C0),0,DATA                C load C0
+    lxvd2x         VSR(C1),r8,DATA               C load C1
+    lxvd2x         VSR(C2),r9,DATA               C load C2
+    lxvd2x         VSR(C3),r10,DATA              C load C3
+
+IF_LE(`
+    vperm          C0,C0,C0,LE_MASK
+    vperm          C1,C1,C1,LE_MASK
+    vperm          C2,C2,C2,LE_MASK
+    vperm          C3,C3,C3,LE_MASK
+')
+
+    C previous digest combining
+    vxor           C0,C0,D
+
+    C polynomial multiplication
+    vpmsumd        F2,H3L,C1
+    vpmsumd        R2,H3M,C1
+    vpmsumd        F3,H2L,C2
+    vpmsumd        R3,H2M,C2
+    vpmsumd        F4,H1L,C3
+    vpmsumd        R4,H1M,C3
+    vpmsumd        F,H4L,C0
+    vpmsumd        R,H4M,C0
+
+    C deferred recombination of partial products
+    vxor           F3,F3,F4
+    vxor           R3,R3,R4
+    vxor           F,F,F2
+    vxor           R,R,R2
+    vxor           F,F,F3
+    vxor           R,R,R3
+
+    C reduction
+    vpmsumd        T,F,POLY_L
+    xxswapd        VSR(D),VSR(F)
+    vxor           R,R,T
+    vxor           D,R,D
+
+    addi           DATA,DATA,0x40
+    bdnz           L4x_loop
+
+    C restore non-volatile vector registers
+    addi           r8,SP,-64
+    lvx            20,0,r8
+    addi           r8,r8,16
+    lvx            21,0,r8
+    addi           r8,r8,16
+    lvx            22,0,r8
+    addi           r8,r8,16
+    lvx            23,0,r8
+
+    clrldi         LENGTH,LENGTH,58              C 'set the high-order 58
bits to zeros'
+L2x:
+    C --- process 2 blocks ---
+
+    srdi           r7,LENGTH,5                   C 'LENGTH / (2 * 16)'
+    cmpldi         r7,0
+    beq            L1x
+
+    C load table elements
+    li             r8,1*TableElemAlign
+    li             r9,2*TableElemAlign
+    li             r10,3*TableElemAlign
+    lxvd2x         VSR(H1M),0,TABLE
+    lxvd2x         VSR(H1L),r8,TABLE
+    lxvd2x         VSR(H2M),r9,TABLE
+    lxvd2x         VSR(H2L),r10,TABLE
+
+    C input loading
+    li             r10,0x10
+    lxvd2x         VSR(C0),0,DATA                C load C0
+    lxvd2x         VSR(C1),r10,DATA              C load C1
+
+IF_LE(`
+    vperm          C0,C0,C0,LE_MASK
+    vperm          C1,C1,C1,LE_MASK
+')
+
+    C previous digest combining
+    vxor           C0,C0,D
+
+    C polynomial multiplication
+    vpmsumd        F2,H1L,C1
+    vpmsumd        R2,H1M,C1
+    vpmsumd        F,H2L,C0
+    vpmsumd        R,H2M,C0
+
+    C deferred recombination of partial products
+    vxor           F,F,F2
+    vxor           R,R,R2
+
+    C reduction
+    vpmsumd        T,F,POLY_L
+    xxswapd        VSR(D),VSR(F)
+    vxor           R,R,T
+    vxor           D,R,D
+
+    addi           DATA,DATA,0x20
+    clrldi         LENGTH,LENGTH,59              C 'set the high-order 59
bits to zeros'
+L1x:
+    C --- process 1 block ---
+
+    srdi           r7,LENGTH,4                   C 'LENGTH / (1 * 16)'
+    cmpldi         r7,0
+    beq            Lmod
+
+    C load table elements
+    li             r8,1*TableElemAlign
+    lxvd2x         VSR(H1M),0,TABLE
+    lxvd2x         VSR(H1L),r8,TABLE
+
+    C input loading
+    lxvd2x         VSR(C0),0,DATA                C load C0
+
+IF_LE(`
+    vperm          C0,C0,C0,LE_MASK
+')
+
+    C previous digest combining
+    vxor           C0,C0,D
+
+    C polynomial multiplication
+    vpmsumd        F,H1L,C0
+    vpmsumd        R,H1M,C0
+
+    C reduction
+    vpmsumd        T,F,POLY_L
+    xxswapd        VSR(D),VSR(F)
+    vxor           R,R,T
+    vxor           D,R,D
+
+    addi           DATA,DATA,0x10
+    clrldi         LENGTH,LENGTH,60              C 'set the high-order 60
bits to zeros'
+Lmod:
+    C --- process the modulo bytes, padding the low-order bytes with zeros
---
+
+    cmpldi         LENGTH,0
+    beq            Ldone
+
+    C load table elements
+    li             r8,1*TableElemAlign
+    lxvd2x         VSR(H1M),0,TABLE
+    lxvd2x         VSR(H1L),r8,TABLE
+
+    C push every modulo byte to the stack and load them with padding into
vector register
+    vxor           ZERO,ZERO,ZERO
+    addi           r8,SP,-16
+    stvx           ZERO,0,r8
+Lstb_loop:
+    subic.         LENGTH,LENGTH,1
+    lbzx           r7,LENGTH,DATA
+    stbx           r7,LENGTH,r8
+    bne            Lstb_loop
+    lxvd2x         VSR(C0),0,r8
+
+IF_LE(`
+    vperm          C0,C0,C0,LE_MASK
+')
+
+    C previous digest combining
+    vxor           C0,C0,D
+
+    C polynomial multiplication
+    vpmsumd        F,H1L,C0
+    vpmsumd        R,H1M,C0
+
+    C reduction
+    vpmsumd        T,F,POLY_L
+    xxswapd        VSR(D),VSR(F)
+    vxor           R,R,T
+    vxor           D,R,D
+
+Ldone:
+    C byte-reverse of each doubleword permuting on little-endian mode
+IF_LE(`
+    vperm          D,D,D,LE_MASK
+')
+    stxvd2x        VSR(D),0,X                    C store digest 'D'
+
+    blr
+EPILOGUE(_nettle_gcm_hash)
+
+.data
+    C 0xC2000000000000000000000000000001
+.polynomial:
+.align 4
+IF_BE(`
+.byte 0xC2
+.rept 14
+.byte 0x00
+.endr
+.byte 0x01
+',`
+.byte 0x01
+.rept 14
+.byte 0x00
+.endr
+.byte 0xC2
+')

-- 
2.17.1
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201122212636</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-11-22 21:26:36-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; It generates a mask compatible with the length of leftovers, for example if
&gt; the length is 1 then the mask generated is
&gt; 0xFF000000000000000000000000000000 then the mask is ANDed with the vector
&gt; register of leftovers to clear the extra unneeded bytes. It's not exactly
&gt; like the first approach but it avoids using stack and handles the leftovers
&gt; inside the assembly implementation, sorry for mixing up.

I see. I'm a bit worried that it may read to far. E.g, assume that
leftover size to read is 5 bytes, and those 5 bytes start at address
1ffffff8. Then the final

   lxvd2x VSR(C0),0,DATA

will read 16 bytes from memory, including a few bytes starting at
address 20000000, which may result in a segfault. Getting this right
would need approach 2, "Round the address down to make it aligned, read
an aligned word and, only if needed, the next word. And shift and mask
to get the needed bytes."

I would expect that the simplest is to go with approach two: Have a loop
to read a byte at the time, and shift into a register.

&gt; I made a merge request in git.lysator.liu.se, it ended up easier for me to
&gt; push patches to the repository in this way, I hope you don't mind dealing
&gt; with the future patches the same way.

Thanks, that's fine. But you may need to ping me, since I don't look at
the gitlab web interface that often.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201125053229</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-11-25 05:32:29-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

 I'm not aware of a simple way to accomplish either approaches on POWER8, I
recommend to use allocated stack buffer to assist handling leftovers rather
than making it complicated or we can use POWER9 specific instruction
'lxvll' which can used to load vector with length passed to general
register as parameter, it also work on both endian modes without any
post-loading operations, another benefit from switching to POWER ISA 3.0 is
that we can use 'lxvb16x/stxvb16x' to load/store input and output data
instead of 'lxvd2x/stxvd2x' instructions, this eliminate the need for
post-loading/pre-storing permuting operations on little-endian mode.

regards,
Mamone

On Sun, Nov 22, 2020 at 11:26 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt; It generates a mask compatible with the length of leftovers, for example
&gt; if
&gt; &gt; the length is 1 then the mask generated is
&gt; &gt; 0xFF000000000000000000000000000000 then the mask is ANDed with the vector
&gt; &gt; register of leftovers to clear the extra unneeded bytes. It's not exactly
&gt; &gt; like the first approach but it avoids using stack and handles the
&gt; leftovers
&gt; &gt; inside the assembly implementation, sorry for mixing up.
&gt;
&gt; I see. I'm a bit worried that it may read to far. E.g, assume that
&gt; leftover size to read is 5 bytes, and those 5 bytes start at address
&gt; 1ffffff8. Then the final
&gt;
&gt;    lxvd2x VSR(C0),0,DATA
&gt;
&gt; will read 16 bytes from memory, including a few bytes starting at
&gt; address 20000000, which may result in a segfault. Getting this right
&gt; would need approach 2, "Round the address down to make it aligned, read
&gt; an aligned word and, only if needed, the next word. And shift and mask
&gt; to get the needed bytes."
&gt;
&gt; I would expect that the simplest is to go with approach two: Have a loop
&gt; to read a byte at the time, and shift into a register.
&gt;
&gt; &gt; I made a merge request in git.lysator.liu.se, it ended up easier for me
&gt; to
&gt; &gt; push patches to the repository in this way, I hope you don't mind dealing
&gt; &gt; with the future patches the same way.
&gt;
&gt; Thanks, that's fine. But you may need to ping me, since I don't look at
&gt; the gitlab web interface that often.
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201125081528</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-11-25 08:15:28-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt;  I'm not aware of a simple way to accomplish either approaches on POWER8, I
&gt; recommend to use allocated stack buffer 

Let's leave that as is, then. Do you want to make another pull request
with only the fixes for register usage?

&gt; to assist handling leftovers rather
&gt; than making it complicated or we can use POWER9 specific instruction
&gt; 'lxvll' which can used to load vector with length passed to general
&gt; register as parameter, it also work on both endian modes without any
&gt; post-loading operations, another benefit from switching to POWER ISA 3.0 is
&gt; that we can use 'lxvb16x/stxvb16x' to load/store input and output data
&gt; instead of 'lxvd2x/stxvd2x' instructions, this eliminate the need for
&gt; post-loading/pre-storing permuting operations on little-endian mode.

I was thinking of something similar to how the unaligned input is
handled in arm/v6/sha1-compress.asm. And then, to handle leftovers at the
end, one would need to compare leftover size with the alignment related
address bits, to decide whether or not to load one more word. But perhaps
only worth the effort if there's a performance advantage in avoiding
unaligned loads also in the main loop.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201125153407</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-11-25 15:34:07-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

On Wed, Nov 25, 2020 at 10:15 AM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; Let's leave that as is, then. Do you want to make another pull request
&gt; with only the fixes for register usage?
&gt;

Sure. I updated the pull request.


&gt; I was thinking of something similar to how the unaligned input is
&gt; handled in arm/v6/sha1-compress.asm. And then, to handle leftovers at the
&gt; end, one would need to compare leftover size with the alignment related
&gt; address bits, to decide whether or not to load one more word. But perhaps
&gt; only worth the effort if there's a performance advantage in avoiding
&gt; unaligned loads also in the main loop.
&gt;

Yes, it makes sense to avoid unaligned loads in the main loop by checking
low-order bits of address, but still I can't imagine it would be more
simple in this case. Allocating stack buffers used very often along the
lifespan of process and I think it's ok to be used for this purpose.

regards,
Mamone
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201125163254</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-11-25 16:32:54-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; Sure. I updated the pull request.

Thanks. Merged (first time I try the merge button on gitlab).

&gt; Yes, it makes sense to avoid unaligned loads in the main loop by checking
&gt; low-order bits of address, but still I can't imagine it would be more
&gt; simple in this case. Allocating stack buffers used very often along the
&gt; lifespan of process and I think it's ok to be used for this purpose.

It's no big problem, it just seems slightly wasteful with an extra round
of load and store to memory.

We could revisit it if we ever get to rearranging the loads for the main loop.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201125192126</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-11-25 19:21:26-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

Niels Möller &lt;nisse@lysator.liu.se&gt; writes:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt;&gt; Sure. I updated the pull request.
&gt;
&gt; Thanks. Merged (first time I try the merge button on gitlab).

It remains to wire it up for fat-ppc.c. Anything else that is missing?

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201125201324</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-11-25 20:13:24-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

On Wed, Nov 25, 2020 at 9:21 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

It remains to wire it up for fat-ppc.c. Anything else that is missing?
&gt;

No, I'll make a pull request for fat build support.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201125215806</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-11-25 21:58:06-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

On Wed, Nov 25, 2020 at 10:13 PM Maamoun TK &lt;maamoun.tk@googlemail.com&gt;
wrote:

&gt; I'll make a pull request for fat build support.
&gt;

Done!
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201126063655</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-11-26 06:36:55-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt;&gt; I'll make a pull request for fat build support.
&gt;&gt;
&gt;
&gt; Done!

I added two comments on the merge request. 

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201126191338</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-11-26 19:13:38-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

Niels Möller &lt;nisse@lysator.liu.se&gt; writes:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt;&gt;&gt; I'll make a pull request for fat build support.
&gt;&gt;&gt;
&gt;&gt;
&gt;&gt; Done!
&gt;
&gt; I added two comments on the merge request. 

I reorganized the ifdefs a bit more, and pushed to the ppc-gcm
branch. Tested on gcc112. Please try it out.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201126202419</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-11-26 20:24:19-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

Great. It works on PowerPC with configure options "./configure",
"./configure --enable-power-crypto-ext", and  "./configure --enable-fat"
and get the expected results.

However, there are two warning popped up when configured with
--enable-power-crypto-ext

gcm.c: In function ‘nettle_gcm_set_key':
gcm.c:287:3: warning: implicit declaration of function
‘_nettle_gcm_init_key'; did you mean ‘nettle_gcm_set_key'?
[-Wimplicit-function-declaration]
  287 |   _nettle_gcm_init_key(key-&gt;h);
      |   ^~~~~~~~~~~~~~~~~~~~
      |   nettle_gcm_set_key
gcm.c:287:3: warning: nested extern declaration of ‘_nettle_gcm_init_key'
[-Wnested-externs]
gcm.c: In function ‘gcm_hash_sizes':
gcm.c:325:3: warning: implicit declaration of function ‘_nettle_gcm_hash';
did you mean ‘nettle_get_hashes'? [-Wimplicit-function-declaration]
  325 |   _nettle_gcm_hash(key, x, GCM_BLOCK_SIZE, buffer);
      |   ^~~~~~~~~~~~~~~~
      |   nettle_get_hashes
gcm.c:325:3: warning: nested extern declaration of ‘_nettle_gcm_hash'
[-Wnested-externs]

To suppress these warnings we need to declare a prototype for
_nettle_gcm_init_key() and _nettle_gcm_hash() if "HAVE_NATIVE_gcm_init_key"
and "HAVE_NATIVE_gcm_hash" are defined respectively.

Also, I think an error will pop up in x86_64 build if gcm_hash8 is enabled,
we can fix this error by replacing the line 156 "#define gcm_hash
_nettle_gcm_hash8" with "#define _nettle_gcm_hash _nettle_gcm_hash8"

Let me know if you want me to make a pull request for these changes.

regards,
Mamone

On Thu, Nov 26, 2020 at 9:13 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Niels Möller &lt;nisse@lysator.liu.se&gt; writes:
&gt;
&gt; &gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt; &gt;
&gt; &gt;&gt;&gt; I'll make a pull request for fat build support.
&gt; &gt;&gt;&gt;
&gt; &gt;&gt;
&gt; &gt;&gt; Done!
&gt; &gt;
&gt; &gt; I added two comments on the merge request.
&gt;
&gt; I reorganized the ifdefs a bit more, and pushed to the ppc-gcm
&gt; branch. Tested on gcc112. Please try it out.
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201126214109</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-11-26 21:41:09-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; To suppress these warnings we need to declare a prototype for
&gt; _nettle_gcm_init_key() and _nettle_gcm_hash() if "HAVE_NATIVE_gcm_init_key"
&gt; and "HAVE_NATIVE_gcm_hash" are defined respectively.

Could be fixed in the new gcm-internal.h file. (I don't quite like that
it needs any ifdefs around the declarations; the reason I had to add
that was that I'd like to have the definitions be static in the case
that it's all defined in C, and then it conflicts with non-static
declarations in this file).

&gt; Also, I think an error will pop up in x86_64 build if gcm_hash8 is enabled,
&gt; we can fix this error by replacing the line 156 "#define gcm_hash
&gt; _nettle_gcm_hash8" with "#define _nettle_gcm_hash _nettle_gcm_hash8"

You're right, it's broken on x86_64.

&gt; Let me know if you want me to make a pull request for these changes.

If you can help out with that, that's much appreciated.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201127090343</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-11-27 09:03:43-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

I made a pull request in the repository.

regards,
Mamone

On Thu, Nov 26, 2020 at 11:41 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:
&gt;
&gt; &gt; To suppress these warnings we need to declare a prototype for
&gt; &gt; _nettle_gcm_init_key() and _nettle_gcm_hash() if
&gt; "HAVE_NATIVE_gcm_init_key"
&gt; &gt; and "HAVE_NATIVE_gcm_hash" are defined respectively.
&gt;
&gt; Could be fixed in the new gcm-internal.h file. (I don't quite like that
&gt; it needs any ifdefs around the declarations; the reason I had to add
&gt; that was that I'd like to have the definitions be static in the case
&gt; that it's all defined in C, and then it conflicts with non-static
&gt; declarations in this file).
&gt;
&gt; &gt; Also, I think an error will pop up in x86_64 build if gcm_hash8 is
&gt; enabled,
&gt; &gt; we can fix this error by replacing the line 156 "#define gcm_hash
&gt; &gt; _nettle_gcm_hash8" with "#define _nettle_gcm_hash _nettle_gcm_hash8"
&gt;
&gt; You're right, it's broken on x86_64.
&gt;
&gt; &gt; Let me know if you want me to make a pull request for these changes.
&gt;
&gt; If you can help out with that, that's much appreciated.
&gt;
&gt; Regards,
&gt; /Niels
&gt;
&gt; --
&gt; Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
&gt; Internet email is subject to wholesale government surveillance.
&gt;
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201127181318</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-11-27 18:13:18-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; I made a pull request in the repository.

Merged, thanks! I wonder if gcm-internal.h can be cut down a bit, to 

  /* Functions available only in some configurations */
  void
  _nettle_gcm_init_key (union nettle_block16 *table);
  
  void
  _nettle_gcm_hash(const struct gcm_key *key, union nettle_block16 *x,
                   size_t length, const uint8_t *data);
  
  #if HAVE_NATIVE_fat_gcm_init_key
  void
  _nettle_gcm_init_key_c (union nettle_block16 *table);
  #endif
  
  #if HAVE_NATIVE_fat_gcm_hash
  void
  _nettle_gcm_hash_c (const struct gcm_key *key, union nettle_block16 *x,
                      size_t length, const uint8_t *data);
  #endif

(it's only the _c-functions that are static in some configurations, and
need ifdefs). I've tested on gcc112, configurations
--enable-power-crypto-ext, --enable-fat, and --disable-assembly, and I
see no warnings or errors.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201127193152</emailId><senderName>Maamoun TK</senderName><senderEmail>maamoun.tk@googlemail.com</senderEmail><timestampReceived>2020-11-27 19:31:52-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

On Fri, Nov 27, 2020 at 8:13 PM Niels Möller &lt;nisse@lysator.liu.se&gt; wrote:

&gt; I wonder if gcm-internal.h can be cut down a bit, to
&gt;
&gt;   /* Functions available only in some configurations */
&gt;   void
&gt;   _nettle_gcm_init_key (union nettle_block16 *table);
&gt;
&gt;   void
&gt;   _nettle_gcm_hash(const struct gcm_key *key, union nettle_block16 *x,
&gt;                    size_t length, const uint8_t *data);


But if HAVE_NATIVE_gcm_init_key and HAVE_NATIVE_gcm_hash are not defined,
there are no definitions for _nettle_gcm_init_key() and _nettle_gcm_hash()
respectively. Maybe it doesn't yield a warning or error because it's ok for
the compiler to have a prototype declaration without function definition.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201128085502</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-11-28 08:55:02-0400</timestampReceived><subject>Re: [PowerPC] GCM optimization</subject><body>

Maamoun TK &lt;maamoun.tk@googlemail.com&gt; writes:

&gt; But if HAVE_NATIVE_gcm_init_key and HAVE_NATIVE_gcm_hash are not defined,
&gt; there are no definitions for _nettle_gcm_init_key() and _nettle_gcm_hash()
&gt; respectively. Maybe it doesn't yield a warning or error because it's ok for
&gt; the compiler to have a prototype declaration without function definition.

It's harmless to declare a function that's neither defined nor used.

Regards,
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201228131621</emailId><senderName>Jeffrey Walton</senderName><senderEmail>noloader@gmail.com</senderEmail><timestampReceived>2020-12-28 13:16:21-0400</timestampReceived><subject>Re: Failing gnutls tests</subject><body>

On Mon, Dec 28, 2020 at 7:59 AM Andreas Metzler &lt;ametzler@bebt.de&gt; wrote:
&gt;
&gt; On 2020-12-28 Niels Möller &lt;nisse-SamgB31n2u5IcsJQ0EH25Q@public.gmane.org&gt; wrote:
&gt; &gt; Hi, recent gnutls tests on the gitlab ci system all fail the test
&gt; &gt; "testpkcs11.sh". See e.g.,
&gt; &gt; https://gitlab.com/gnutls/nettle/-/jobs/932664781. First failure was an
&gt; &gt; a merge commit with a minor ppc-related fix.
&gt;
&gt; &gt; And it looks like gnutls' own pipelines have been failing for a month or
&gt; &gt; so too, see https://gitlab.com/gnutls/gnutls/-/pipelines. Any gnutls
&gt; &gt; people on the list who could have a look?
&gt;
&gt; Hello Niels,
&gt;
&gt; that is &lt;https://gitlab.com/gnutls/gnutls/-/issues/1135&gt;.

And also https://gitlab.com/gnutls/gnutls/-/issues/1136.

Jeff
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email><email><emailId>20201029190714</emailId><senderName>Niels_Möller</senderName><senderEmail>nisse@lysator.liu.se</senderEmail><timestampReceived>2020-10-29 19:07:14-0400</timestampReceived><subject>Re: Blowfish integer overshift (undefined behavior)</subject><body>

Guido Vranken &lt;guidovranken@gmail.com&gt; writes:

&gt; If you compile with Clang and -fsanitize=undefined, this will print:
&gt;
&gt; blowfish.c:388:22: runtime error: left shift of 236 by 24 places cannot be
&gt; represented in type 'int'
&gt;
&gt; Explicit casting around the shifted values will fix this.

I've pushed a fix, see
https://git.lysator.liu.se/nettle/nettle/-/commit/4c8b0cdd97ffec3ae3f8d995afdfccbc261b3c79.

Thanks for the report.
/Niels

-- 
Niels Möller. PGP-encrypted email is preferred. Keyid 368C6677.
Internet email is subject to wholesale government surveillance.
_______________________________________________
nettle-bugs mailing list
nettle-bugs@lists.lysator.liu.se
http://lists.lysator.liu.se/mailman/listinfo/nettle-bugs

</body></email></emails>